{
  "Assets/Scripts/InventorySystem/CHANGELOG.html": {
    "href": "Assets/Scripts/InventorySystem/CHANGELOG.html",
    "title": "| Inventory System",
    "summary": "[1.0.0] - 2025-07-31 First Release Includes IInventory, IEquipmentInventory and IItem Includes runtime test suite"
  },
  "Assets/Scripts/InventorySystem/README.html": {
    "href": "Assets/Scripts/InventorySystem/README.html",
    "title": "Inventory System | Inventory System",
    "summary": "Inventory System"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [2.0.8] - 2025-05-29 Fixed Samples will now use appropriate material colors in projects using HDRP or URP. Install the com.unity.shadergraph package to show the materials correctly for built-in render pipeline projects. [2.0.7] - 2025-04-09 Changed The minimum supported editor version is Unity 6 LTS. Compatibility with Unity 2023.2 is no longer guaranteed going forward. Fixed Baking NavMeshSurface no longer fails when the game object name has invalid file name characters. [2.0.6] - 2025-02-04 Added New OffMesh Link Converter tool in the Window > AI > Navigation Updater window to help you automatically replace OffMesh Links with NavMesh Links in the scenes and prefabs of your project. Fixed Fixed a regression that caused controls in the navigation scene view overlay popup to display on top of one another when foldouts were open. (Requires Unity 6000.0.22f1 or newer) The AI Navigation overlay was rarely needed upon the initial installation of the package. Now it is hidden by default and you can enable it through the Overlay Menu. Fixed a regression that caused the Editor to allocate unnecessary memory on some platforms, when the project contained package test files. [2.0.5] - 2024-11-18 Fixed NavMesh Link would not update when switching from the Not Walkable area type to any other area type in the inspector. (NAVB-87) A few documentation paragraphs and links were not accurate. [2.0.4] - 2024-08-30 Fixed NavMesh Modifier was not overriding the area type in a NavMesh built from within an Awake() method (NAVB-39) [2.0.3] - 2024-07-16 Changed The ends of the NavMesh Link are solely determined by the Transforms they reference. If a link's end doesn't reference a Transform, it is placed in the scene according to the local Point position set for it. This differs from version 2.0.0 where the Point was used together with, and relative to, the end's Transform, which always pointed to some GameObject. NavMesh Links saved using version 2.0.0 will now find their endpoints in different positions compared to where they would be in version 2.0.0. NavMesh Links saved with versions earlier than 2.0.0 remain unaffected and will continue to function with their existing data as they used to. NavMesh Links saved with version 2.0.0 upgrade automatically to the correct format. Any link endpoint that has previously been defined by a position relative to a GameObject will now reference a new GameObject created as a child of the original transform and moved to the same world position that the endpoint had before. To modify the cost of an individual NavMesh Link you can now select \"Cost Override\" in the Inspector and then input the new value. NavMesh Links that are saved with this version cannot be loaded correctly with earlier versions of the package. Improved the user manual pages that describe the NavMesh Link and the NavMesh Surface components. Fixed Fixed navigation objects created from the GameObject menu being created in the scene instead of a prefab hierarchy when in prefab isolation mode. Fixed creation of navigation objects from the GameObject menu resulting in more than one operation on the undo stack. In accordance with other workflows, creating navigation objects from the GameObject menu now places them directly at the parent's position, instead of at the center of the scene view, when a parent is selected. Fixed regression whereby changing NavMeshLink activated or cost modifier properties in the Inspector would not update the link while in play mode. Added missing tooltips and support for localization throughout Inspector UI. The Navigation window was sometimes issuing errors related to the .png file used as icon. Added a cleanup step for Navigation components static data, so that the components support entering play mode without any domain reload. Fixed warnings in the console when undoing creation of navigation objects from the GameObject menu. Swapping the start and end points of a NavMeshLink via the Inspector now supports undo and redo. Moving the GameObject via the Re-center operation in the NavMesh Link Inspector now supports undo and redo. The deprecated properties autoUpdatePositions, biDirectional, costOverride and the deprecated UpdatePositions method of NavMeshLink correctly map now one-to-one to the members autoUpdate, bidirectional, costModifier and UpdateLink. This change removes any values that were stored by a serialized object specifically for the deprecated properties. Updated the use of several methods that have been moved between classes as of 2023.3. Added missing documentation for method parameters in NavMeshComponentsGUIUtility. [2.0.2] - 2024-07-02 Version not published. [2.0.1] - 2023-12-06 Version not published. [2.0.0] - 2023-10-17 NavMesh Link sets incorrect endpoint transforms and positions. Use version 2.0.3 instead. Fixed When the \"Auto Update Position\" option of NavMeshLink is enabled, the link now correctly updates the connection in the next frame after any of the link's ends change their world position. [2.0.0-pre.4] - 2023-09-28 Fixed Long warning popping up when user starts playmode while editing a prefab that contains NavMesh components (NAVB-47) [2.0.0-pre.3] - 2023-05-31 Added New activated property in NavMeshLink, useful to control whether agents are allowed to traverse the link New occupied property in NavMeshLink, useful to determine whether an agent is using the link New startTransform, endTransform properties in NavMeshLink, useful to define the ends of the link through Transform references as an alternative to points in 3D space New autoUpdatePositions, biDirectional, costOverride properties and the UpdatePositions() method, introduced as \"deprecated\" in order to facilitate the upgrade from OffMeshLinks Changed The costModifier property is now of type float, as expected by the Navigation system. Fixed Published the missing API reference documentation for the properties made available with 2022.2 Removed The \"Navigation (Obsolete)\" window has been removed. This in turn removes the deprecated abilities to enable the \"Navigation Static\" flag on scene objects and to bake a single NavMesh embedded in the scene. [1.1.3] - 2023-04-13 Changed Remove some unnecessary files from the package [1.1.2] - 2023-04-03 Changed The AI Navigation overlay in the scene view remembers which sections have been collapsed Updated a large part of the documentation to reflect the current functionality [1.1.1] - 2022-10-21 Changed Clarified the information text displayed by the NavMesh Updater [1.1.0-pre.2] - 2022-08-09 Changed The Dungeon scene included in the package samples now uses tile prefabs that contain a NavMeshSurface component instead of the NavMeshPrefabInstance script. The Drop Plank scene included in the package samples now has a NavMeshSurface component and the NavMeshSurfaceUpdater script on the geometry, as well as the DynamicNavMeshObject script on the Plank prefab for dynamically updating the NavMesh when new Planks are instantiated. The offset when instantiating Planks in the Drop Plank scene has been reduced. The Sliding Window Infinite and the Sliding Window Terrain scenes included in the package samples now use the NavMeshSurfaceVolumeUpdater script instead of the LocalNavMeshBuilder and NavMeshSourceTag scripts for dynamically updating the NavMesh. The Modify Mesh scene included in the package samples now uses a NavMeshSurface component on the Mesh Tool for dynamically updating the NavMesh instead of the LocalNavMeshBuilder and NavMeshSourceTag scripts. The MeshTool script now uses the Update() method of NavMeshSurface for updating the NavMesh whenever the mesh is modified. Fixed The Drop Plank scene included in the package samples now destroys instantiated Planks that have fallen off the edge. Missing agent type references in the samples. Removed The NavMeshPrefabInstance and NavMeshPrefabInstanceEditor scripts from the package samples were removed. The prefab editing scene 7b_dungeon_tile_prefabs from the package samples was removed. The tiles can now be edited directly as prefabs. The LocalNavMeshBuilder and NavMeshSourceTag scripts from the package samples were removed. [1.1.0-pre.1] - 2022-04-27 Added NavMeshSurface supports links generation. NavMeshSurface supports HeightMesh baking. New package Navigation window adapting the obsolete Unity Navigation window functionalities to the package workflow. Changed NavMeshSurface is using the Background Tasks window to report the baking progress Minimum supported version is increased to Unity 2022.2 [1.0.0-exp.4] - 2021-07-19 Changed Documentation updated with changes from Unity manual Test scripts moved into namespaces Unity.AI.Navigation.Tests and Unity.AI.Navigation.Editor.Tests [1.0.0-exp.3] - 2021-06-16 Fixed An assembly definition in the package sample was referencing an invalid AsmDef [1.0.0-exp.2] - 2021-05-19 Fixed Baking a NavMeshSurface with a bounding volume was not detecting the geometry nearby the bounds (1027006) Changed New note in the documentation about the bounding volume of a NavMeshSurface [1.0.0-exp.1] - 2021-04-06 This is the first release of the AI Navigation package. It contains the scripts that were previously known as NavMeshComponents and it adds a few improvements. Fixed Disabling a NavMeshLink component in the Editor does not remove the link Added New minRegionArea property in NavMeshSurface that prevents small isolated patches from being built in the NavMesh Documentation for the new minRegionArea property Changed Documentation updated Script namespaces changed to Unity.AI.Navigation.* The license has changed. The folder structure has changed in accordance to the requirements of the Unity standards for packages."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AboutAgents.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AboutAgents.html",
    "title": "About NavMesh agents | Inventory System",
    "summary": "About NavMesh agents The NavMesh agent is a GameObject that is represented by an upright cylinder whose size is specified by the Radius and Height properties. The cylinder moves with the GameObject, but remains upright even if the GameObject rotates. The shape of the cylinder is used to detect and respond to collisions with other agents and obstacles. When the anchor point of the GameObject is not at the base of the cylinder, use the Base Offset property to specify the height difference. The height and radius of the cylinder are specified in the Navigation window and the NavMesh Agent component properties of the individual agents. Navigation window settings describe how all the NavMesh Agents collide and avoid static world geometry. To keep memory on budget and CPU load at a reasonable level, you can only specify one size in the bake settings. NavMesh Agent component properties values describe how the agent collides with moving obstacles and other agents. Typically you set the size of the agent with the same values in both places. However, you might, give a heavy soldier a larger radius, so that other agents leave more space around your soldier. Otherwise, your soldier avoids the environment in the same manner as the other agents. Additional resources Create a NavMesh Agent NavMesh Agent component reference NavMesh Agent scripting reference Navigation Agent Types Build a HeightMesh for Accurate Character Placement"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AboutObstacles.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AboutObstacles.html",
    "title": "About NavMesh Obstacles | Inventory System",
    "summary": "About NavMesh Obstacles NavMesh Obstacles can affect the NavMesh Agent’s navigation during the game in two ways: Obstructing When Carve is not enabled, the default behavior of the NavMesh Obstacle is similar to that of a Collider. NavMesh Agents try to avoid collisions with the NavMesh Obstacle, and when close, they collide with the NavMesh Obstacle. Obstacle avoidance behavior is very basic, and has a short radius. As such, the NavMesh Agent might not be able to find its way around in an environment cluttered with NavMesh Obstacles. This mode is best used in cases where the obstacle is constantly moving (for example, a vehicle or player character). Carving When Carve is enabled, the obstacle carves a hole in the NavMesh when stationary. When moving, the obstacle is an obstruction. When a hole is carved into the NavMesh, the pathfinder is able to navigate the NavMesh Agent around locations cluttered with obstacles, or find another route if the current path gets blocked by an obstacle. It’s good practice to turn on carving for NavMesh Obstacles that generally block navigation but can be moved by the player or other game events like explosions (for example, crates or barrels). Logic for moving NavMesh Obstacles Unity treats the NavMesh Obstacle as moving when it has moved more than the distance set by the Carve > Move Threshold. When the NavMesh Obstacle moves, the carved hole also moves. However, to reduce CPU overhead, the hole is only recalculated when necessary. The result of this calculation is available in the next frame update. The recalculation logic has two options: Only carve when the NavMesh Obstacle is stationary Carve when the NavMesh Obstacle has moved Only carve when the NavMesh Obstacle is stationary This is the default behavior. To enable it, tick the NavMesh Obstacle component’s Carve Only Stationary checkbox. In this mode, when the NavMesh Obstacle moves, the carved hole is removed. When the NavMesh Obstacle has stopped moving and has been stationary for more than the time set by Carving Time To Stationary, it is treated as stationary and the carved hole is updated again. While the NavMesh Obstacle is moving, the NavMesh Agents avoid it using collision avoidance, but don’t plan paths around it. Carve Only Stationary is generally the best choice in terms of performance, and is a good match when the GameObject associated with the NavMesh Obstacle is controlled by physics. Carve when the NavMesh Obstacle has moved To enable this mode, clear the NavMesh Obstacle component’s Carve Only Stationary checkbox. When this is cleared, the carved hole is updated when the obstacle has moved more than the distance set by Carving Move Threshold. This mode is useful for large, slowly moving obstacles (for example, a tank that is being avoided by infantry). Note When using NavMesh query methods, you should take into account that there is a one-frame delay between changing a NavMesh Obstacle and the effect that change has on the NavMesh. Additional Resources Create a NavMesh Obstacle Inner Workings of the Navigation System NavMesh Obstacle scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AreasAndCosts.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/AreasAndCosts.html",
    "title": "Navigation Areas and Costs | Inventory System",
    "summary": "Navigation Areas and Costs The Navigation Area defines how difficult it is to walk across a specific area. This is important for finding the path with the lowest total cost. In addition, each NavMesh Agent has an Area Mask which you can use to specify which areas the agent can move on. In the example above the area types are used for two common use cases: The Water area is made more costly to walk through by assigning it a higher cost, to deal with a scenario where walking in shallow water is slower. The Door area is made accessible to specific characters, to create a scenario where humans can walk through doors, but zombies cannot. You can assign the area type to every object that is included in the NavMesh baking. In addition, each NavMesh Link has a property to specify the area type. Pathfinding Cost In a nutshell, the cost allows you to control which areas the pathfinder favors when finding a path. For example, if you set the cost of an area to 3.0, traveling across that area is considered to be three times longer than alternative routes. To fully understand how the cost works, let’s take a look at how the pathfinder works. Nodes and links visited during pathfinding. Unity uses A* to calculate the shortest path on the NavMesh. A* works on a graph of connected nodes. The algorithm starts from the nearest node to the path start and visits the connect nodes until the destination is reached. Since the Unity navigation representation is a mesh of polygons, the first thing the pathfinder needs to do is to place a point on each polygon, which is the location of the node. The shortest path is then calculated between these nodes. The yellow dots and lines in the above picture shows how the nodes and links are placed on the NavMesh, and in which order they are traversed during the A*. The cost to move between two nodes depends on the distance to travel and the cost associated with the area type of the polygon under the link, that is, distance * cost. In practice this means, that if the cost of an area is 2.0, the distance across such polygon will appear to be twice as long. The A* algorithm requires that all costs must be larger than 1.0. The effect of the costs on the resulting path can be hard to tune, especially for longer paths. The best way to approach costs is to treat them as hints. For example, if you want the agents to not use NavMesh Links too often, you could increase their cost. But it can be challenging to tune a behavior where the agents prefer to walk on sidewalks. Another thing you may notice on some levels is that the pathfinder does not always choose the shortest path. The reason for this is the node placement. The effect can be noticeable in scenarios where big open areas are next to tiny obstacles, which results in a navigation mesh with very big and small polygons. In such cases the nodes on the big polygons may get placed anywhere in the big polygon and from the pathfinder’s point of view it looks like a detour. The cost per area type can be set globally in the Areas tab, or you can override them per agent using a script. Area Types The area types are specified in the Navigation Window’s Areas tab. There are 29 custom types, and 3 built-in types: Walkable, Not Walkable, and Jump. Walkable is a generic area type which specifies that the area can be walked on. Not Walkable is a generic area type which prevents navigation. It is useful for cases where you want to mark certain object to be an obstacle, but without getting NavMesh on top of it. Jump is an area type that is assigned to all auto-generated NavMesh Links. If several objects of different area types are overlapping, the resulting NavMesh area type will generally be the one with the highest index. There is one exception however: Not Walkable always takes precedence. Which can be helpful if you need to block out an area. Area Mask Each agent has an Area Mask which describes which areas it can use when navigating. The area mask can be set in the agent properties, or the bitmask can be manipulated using a script at runtime. The area mask is useful when you want only certain types characters to be able to walk through an area. For example, in a zombie evasion game, you could mark the area under each door with a Door area type, and uncheck the Door area from the zombie character’s Area Mask. Additional resources Create a NavMesh NavMesh Modifier component reference NavMesh Modifier Volume component reference NavMeshAgent.areaMask scripting reference NavMeshAgent.SetAreaCost() scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CouplingAnimationAndNavigation.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CouplingAnimationAndNavigation.html",
    "title": "Couple Animation and Navigation | Inventory System",
    "summary": "Couple Animation and Navigation The goal of this document is to guide you to setup navigating humanoid characters to move using the navigation system. We’ll be using Unity’s built-in systems for animation and navigation along with custom scripting to achieve this. It’s assumed you’re familiar with the basics of Unity and the Mecanim animation system. An example project is available — so you don’t have to add scripts or set up animations and animation controller from scratch: NavigationAnimation_53.zip Works with Unity 5.3+ Creating the Animation Controller To get a responsive and versatile animation controller — covering a wide range of movements — we need a set of animations moving in different directions. This is sometimes referred to as a strafe-set. In addition to the move animations we need an animation for the standing character. We proceed by arranging the strafe-set in a 2D blend tree — choose blend type: 2D Simple Directional and place animations using Compute Positions > Velocity XZ For blending control we add two float parameters velx and vely, and assign them to the blend tree. Here we’ll be placing 7 run animations — each with a different velocity. In addition to the forwards (+ left/right) and backwards (+ left/right) we also use an animation clip for running on the spot. The latter is highlighted in the center of the 2D blend map below. The reason for having an animation running on the spot is two-fold, firstly it preserves the style of running when blended with the other animations. Secondly the animation prevents foot-sliding when blending. Then we add the idle animation clip in its own node (Idle). We now have two discrete animation states that we couple with 2 transitions. To control the switch between the moving and idle states we add a boolean control parameter move. Then disable the Has Exit Time property on the transitions. This allows the transition to trigger at any time during the animation. Transition time should be set to around 0.10 second to get a responsive transition. Now place the new created animation controller on the character you want to move. Press play and select the character in the Hierarchy window. You can now manually control the animation values in the Animator window and change the move state and velocity. The next step is to create other means of controlling the animation parameters. Navigation Control Place a NavMeshAgent component on the character and adjust the radius, height and to match the character - additionally change the speed property to match the maximum speed in the animation blend tree. Create a NavMesh for the Scene you’ve placed the character in. Next we need to tell the character where to navigate to. This typically is very specific to the application. Here we choose a click to move behavior — the character moved to the point in the world where the user has clicked on the screen. // ClickToMove.cs using UnityEngine; using UnityEngine.AI; [RequireComponent (typeof (NavMeshAgent))] public class ClickToMove : MonoBehaviour { RaycastHit hitInfo = new RaycastHit(); NavMeshAgent agent; void Start () { agent = GetComponent<NavMeshAgent> (); } void Update () { if(Input.GetMouseButtonDown(0)) { Ray ray = Camera.main.ScreenPointToRay(Input.mousePosition); if (Physics.Raycast(ray.origin, ray.direction, out hitInfo)) agent.destination = hitInfo.point; } } } Pressing play now — and clicking around in the scene — you’ll see the character move around in the scene. However — the animations don’t match the movement at all. We need to communicate the state and velocity of the agent to the animation controller. To transfer the velocity and state info from the agent to the animation controller we will add another script. // LocomotionSimpleAgent.cs using UnityEngine; using UnityEngine.AI; [RequireComponent (typeof (NavMeshAgent))] [RequireComponent (typeof (Animator))] public class LocomotionSimpleAgent : MonoBehaviour { Animator anim; NavMeshAgent agent; Vector2 smoothDeltaPosition = Vector2.zero; Vector2 velocity = Vector2.zero; void Start () { anim = GetComponent<Animator> (); agent = GetComponent<NavMeshAgent> (); // Don’t update position automatically agent.updatePosition = false; } void Update () { Vector3 worldDeltaPosition = agent.nextPosition - transform.position; // Map 'worldDeltaPosition' to local space float dx = Vector3.Dot (transform.right, worldDeltaPosition); float dy = Vector3.Dot (transform.forward, worldDeltaPosition); Vector2 deltaPosition = new Vector2 (dx, dy); // Low-pass filter the deltaMove float smooth = Mathf.Min(1.0f, Time.deltaTime/0.15f); smoothDeltaPosition = Vector2.Lerp (smoothDeltaPosition, deltaPosition, smooth); // Update velocity if time advances if (Time.deltaTime > 1e-5f) velocity = smoothDeltaPosition / Time.deltaTime; bool shouldMove = velocity.magnitude > 0.5f && agent.remainingDistance > agent.radius; // Update animation parameters anim.SetBool(\"move\", shouldMove); anim.SetFloat (\"velx\", velocity.x); anim.SetFloat (\"vely\", velocity.y); GetComponent<LookAt>().lookAtTargetPosition = agent.steeringTarget + transform.forward; } void OnAnimatorMove () { // Update position to agent position transform.position = agent.nextPosition; } } This script deserves a little explanation. It’s placed on the character — which has an Animator and a NavMeshAgent component attached — as well as the click to move script above. First the script tells the agent not to update the character position automatically. We handle the position update that last in the script. The orientation is updated by the agent. The animation blend is controlled by reading the agent velocity. It is transformed into a relative velocity (based on character orientation) — and then smoothed. The transformed horizontal velocity components are then passed to the Animator and additionally the state switching between idle and moving is controlled by the speed (i.e. velocity magnitude). In the OnAnimatorMove() callback we update the position of the character to match the NavMeshAgent. Playing the scene again gives show that animation matches the movement to as close as possible. Improving the Quality of the Navigating Character To improve the quality of the animated and navigating character we will explore a couple of options. Looking Having the character to look and turn towards points of interest is important to convey attention and anticipation. We’ll use the animation systems LookAt API. This calls for another script. // LookAt.cs using UnityEngine; using System.Collections; [RequireComponent (typeof (Animator))] public class LookAt : MonoBehaviour { public Transform head = null; public Vector3 lookAtTargetPosition; public float lookAtCoolTime = 0.2f; public float lookAtHeatTime = 0.2f; public bool looking = true; private Vector3 lookAtPosition; private Animator animator; private float lookAtWeight = 0.0f; void Start () { if (!head) { Debug.LogError(\"No head transform - LookAt disabled\"); enabled = false; return; } animator = GetComponent<Animator> (); lookAtTargetPosition = head.position + transform.forward; lookAtPosition = lookAtTargetPosition; } void OnAnimatorIK () { lookAtTargetPosition.y = head.position.y; float lookAtTargetWeight = looking ? 1.0f : 0.0f; Vector3 curDir = lookAtPosition - head.position; Vector3 futDir = lookAtTargetPosition - head.position; curDir = Vector3.RotateTowards(curDir, futDir, 6.28f * Time.deltaTime, float.PositiveInfinity); lookAtPosition = head.position + curDir; float blendTime = lookAtTargetWeight > lookAtWeight ? lookAtHeatTime : lookAtCoolTime; lookAtWeight = Mathf.MoveTowards (lookAtWeight, lookAtTargetWeight, Time.deltaTime / blendTime); animator.SetLookAtWeight (lookAtWeight, 0.2f, 0.5f, 0.7f, 0.5f); animator.SetLookAtPosition (lookAtPosition); } } Add the script to the character and assign the head property to the head transform in your characters transform hierarchy. The LookAt script has no notion of navigation control — so to control where to look we go back to the LocomotionSimpleAgent.cs script and add a couple of lines to control the looking. Add the end of Update() add: LookAt lookAt = GetComponent<LookAt> (); if (lookAt) lookAt.lookAtTargetPosition = agent.steeringTarget + transform.forward; This will tell the LookAt script to set the point of interest to approximately the next corner along the path or — if no corners — to the end of the path. Try it out. Animation Driven Character using Navigation The character has so far been controlled completely by the position dictated by the agent. This ensures that the avoidance of other characters and obstacles translates directly to the character position. However it may lead to foot-sliding if the animation doesn’t cover the proposed velocity. Here we’ll relax the constraint of the character a bit. Basically we’ll be trading the avoidance quality for animation quality. Replace the OnAnimatorMove() callback on the LocomotionSimpleAgent.cs script replace the line with the following void OnAnimatorMove () { // Update position based on animation movement using navigation surface height Vector3 position = anim.rootPosition; position.y = agent.nextPosition.y; transform.position = position; } When trying this out you may notice the that character can now drift away from the agent position (green wireframe cylinder) . You may need to limit that character animation drift. This can be done either by pulling the agent towards the character — or pull the character towards the agent position. Add the following at the end of the Update() method on the script LocomotionSimpleAgent.cs. // Pull character towards agent if (worldDeltaPosition.magnitude > agent.radius) transform.position = agent.nextPosition - 0.9f * worldDeltaPosition; Or — if you want the agent to follow the character. // Pull agent towards character if (worldDeltaPosition.magnitude > agent.radius) agent.nextPosition = transform.position + 0.9f * worldDeltaPosition; What works best very much depends on the specific use-case. Conclusion We have set up a character that moves using the navigation system and animates accordingly. Tweaking the numbers of blend time, look-at weights etc. can improve the looks — and is a good way to further explore this setup."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMesh.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMesh.html",
    "title": "Create a NavMesh | Inventory System",
    "summary": "Create a NavMesh You need to create a NavMesh to define an area of your scene within which a character can navigate intelligently. To create a NavMesh do the following: Select the scene geometry where you want to add the NavMesh. In the Inspector window, click Add Component. Select Navigation > NavMesh Surface. In the NavMesh Surface component, specify the necessary settings. For details on the available settings, refer to NavMesh Surface component. When you are finished, click Bake. The NavMesh is generated and displayed in the scene as a blue overlay on the underlying scene geometry whenever the Navigation window is open and visible. You can bake the NavMesh again to update it each time you make changes to either the scene geometry, the NavMesh modifiers, the properties of the NavMesh Surface component, or the settings of the selected agent type. To permanently remove a NavMesh from your project, do one of the following: Click the Clear button in the NavMesh Surface inspector. Delete the NavMesh asset file in the Project window. If you choose to remove the NavMesh Surface component itself from the GameObject, the asset file is not deleted, even though the NavMesh is no longer present in the scene. Additional resources Navigation window Create a NavMeshAgent NavMesh Surface component Navigation Areas and Costs Build a HeightMesh for Accurate Character Placement"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshAgent.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshAgent.html",
    "title": "Create a NavMesh Agent | Inventory System",
    "summary": "Create a NavMesh Agent Once you have a NavMesh baked for your level it is time to create a character which can navigate the Scene. We’re going to build our prototype agent from a cylinder and set it in motion. This is done using a NavMesh Agent component and a simple script. First let’s create the character: Create a cylinder: GameObject > 3D Object > Cylinder. The default cylinder dimensions (height 2 and radius 0.5) are good for a humanoid shaped agent, so we will leave them as they are. Add a NavMesh Agent component: Component > Navigation > NavMesh Agent. Now you have simple NavMesh Agent set up ready to receive commands! When you start to experiment with a NavMesh Agent, you most likely are going to adjust its dimensions for your character size and speed. The NavMesh Agent component handles both the pathfinding and the movement control of a character. In your scripts, navigation can be as simple as setting the desired destination point - the NavMesh Agent can handle everything from there on. // MoveTo.cs using UnityEngine; using UnityEngine.AI; public class MoveTo : MonoBehaviour { public Transform goal; void Start () { NavMeshAgent agent = GetComponent<NavMeshAgent>(); agent.destination = goal.position; } } Next we need to build a simple script which allows you to send your character to the destination specified by another Game Object, and a Sphere which will be the destination to move to: Create a new C# script (MoveTo.cs) and replace its contents with the above script. Assign the MoveTo script to the character you’ve just created. Create a sphere, this will be the destination the agent will move to. Move the sphere away from the character to a location that is close to the NavMesh surface. Select the character, locate the MoveTo script, and assign the Sphere to the Goal property. Press Play; you should see the agent navigating to the location of the sphere. To sum it up, in your script, you will need to get a reference to the NavMesh Agent component and then to set the agent in motion, you just need to assign a position to its destination property. The Navigation How Tos will give you further examples on how to solve common gameplay scenarios with the NavMesh Agent. Additional resources Create a NavMesh Navigation HowTos Inner Workings of the Navigation System Navigation agent configurations NavMesh Agent component reference NavMesh Agent scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshLink.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshLink.html",
    "title": "Create a NavMesh Link | Inventory System",
    "summary": "Create a NavMesh Link Use NavMesh Links when you want to create paths that cross outside of the walkable navigation mesh surface. For example, you can set up NavMesh Links to allow agents to jump over a ditch or a fence, or to open a door before walking through it. To do this, you first need to add a NavMesh Link component to a GameObject in your scene. Then you position each end of the link at either a point in the scene or at the position of a GameObject that you choose to reference. When the ends are in place over the NavMesh, the Link creates a navigation connection that the NavMesh Agent can follow. We’re going to add an NavMesh Link component to describe a jump from the upper platform to the ground. First create two cylinders: Game Object > 3D Object > Cylinder. Scale the cylinders to (0.1, 0.05, 0.1) to make it easier to work with them. Move the first cylinder to the edge of the top platform, close to the NavMesh surface. Place the second cylinder on the ground, close to the NavMesh, at the location where the link should land. Select the first cylinder and add a NavMesh Link component to it. In the inspector, select Add Component > Navigation > NavMesh Link. In the Start Transform field, assign the first cylinder. In the End Transform field, assign the second cylinder. Now you have a functioning NavMesh Link set up. Pathfinding returns the path going through the NavMesh link if that path is shorter than walking along the NavMesh. You can use any GameObject in the scene to hold the NavMesh link component, for example a fence prefab can contain the NavMesh link component. Similarly you can use any GameObject with a Transform as the start, or end, marker. To learn about all the NavMesh Link properties that you can tweak, refer to the NavMesh Link component reference. The NavMesh bake process can detect and create common jump-across and drop-down links automatically. Refer to the settings of NavMesh Surface for more details. How to troubleshoot a link that does not work If the agent does not traverse a NavMesh Link make sure that both end points are connected correctly to the NavMesh. To check the state of the connection make sure to enable the Show NavMesh debug visualization in the AI Navigation overlay. When the link has no width, a properly connected end point shows a circle around the access point in the scene view. If the link has width, the link shows a dark segment on the edge that connects properly to the NavMesh, or a gray line if the edge does not connect to the NavMesh. If both ends connect to the NavMesh, the wide link shows an additional solid transparent rectangle that fills the space between the link edges. The NavMesh link also shows an arc line between the ends, with an arrow at each end where the agent can exit the link. The arc line is colored black if at least one end is connected, or it is colored gray if none of the ends is connected to the NavMesh. No agent or path can traverse a link that has the Activated property disabled. In that situation the link shows in the scene with a red color. Make sure to enable the Activated property when you want agents to be able to move through the link. Another common cause of why an agent does not traverse a NavMesh Link is that the NavMesh Agent’s Area Mask does not include the NavMesh Link’s area type. Additional resources NavMesh Link component reference Navigation HowTos Sample 7 - Dungeon NavMesh Link scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshObstacle.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateNavMeshObstacle.html",
    "title": "Create a NavMesh Obstacle | Inventory System",
    "summary": "Create a NavMesh Obstacle NavMesh Obstacle components can be used to describe obstacles the agents should avoid while navigating. For example the agents should avoid physics controlled objects, such as crates and barrels while moving. We’re going to add a crate to block the pathway at the top of the level. First create a cube to depict the crate: Game Object > 3D Object > Cube. Move the cube to the platform at the top, the default size of the cube is good for a crate so leave it as it is. Add a NavMesh Obstacle component to the cube. Choose Add Component from the inspector and choose Navigation > NavMesh Obstacle. Set the shape of the obstacle to box, changing the shape will automatically fit the center and size to the render mesh. Add a Rigid body to the obstacle. Choose Add Component from the inspector and choose Physics > Rigid Body. Finally turn on the Carve setting from the NavMesh Obstacle inspector so that the agent knows to find a path around the obstacle. Now we have a working crate that is physics controlled, and which the AI knows how to avoid while navigating. Additional resources Inner Workings of the Navigation System NavMesh Obstacle component reference NavMesh Obstacle scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateOffMeshLink.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/CreateOffMeshLink.html",
    "title": "Create an Off-mesh Link | Inventory System",
    "summary": "Create an Off-mesh Link Important The OffMesh Link component is deprecated and no longer supported. The Add Component menu no longer contains the Off-Mesh Link component. Use the NavMesh Link component instead. Off-Mesh Links are used to create paths crossing outside the walkable navigation mesh surface. For example, jumping over a ditch or a fence, or opening a door before walking through it, can be all described as Off-mesh links. We’re going to add an Off-Mesh Link component to describe a jump from the upper platform to the ground. First create two cylinders: Game Object > 3D Object > cylinder. You can scale the cylinders to (0.1, 0.5, 0.1) to make it easier to work with them. Move the first cylinder at the edge of the top platform, close to the NavMesh surface. Place the second cylinder on the ground, close to the NavMesh, at the location where the link should land. Select the first cylinder cylinder and add an Off-Mesh Link component to it. Choose Add Component from the inspector and choose Navigation > OffMesh Link. Assign the first cylinder in the Start field and the second cylinder in the End field. Now you have a functioning Off-Mesh Link set up! If the path via the off-mesh link is shorter than via walking along the NavMesh, the off-mesh link will be used. You can use any game object in the Scene to hold the Off-Mesh link component, for example a fence prefab could contain the off-mesh link component. Similarly you can use any game object with a Transform as the start and end marker. The NavMesh bake process can detect and create common jump-across and drop-down links automatically. Take a look at Building Off-Mesh Links Automatically for more details. Details If the agent does not traverse an OffMesh link make sure that both end points are connected correctly. A properly connected end point should show a circle around the access point. Another common cause is that the NavMesh Agent’s Area Mask does not have the OffMesh Link’s area included. Additional resources Navigation HowTos Off-Mesh Link component (deprecated) reference Off-Mesh Link (deprecated) scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Glossary.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Glossary.html",
    "title": "Glossary | Inventory System",
    "summary": "Glossary Animation blend tree Used for continuous blending between similar Animation Clips based on float Animation Parameters. More info Animation clip Animation data that can be used for animated characters or simple animations. An animation clip is one piece of motion, such as (one specific instance of) “Idle”, “Walk” or “Run”. More info Animation parameters Used to communicate between scripting and the Animator Controller. Some parameters can be set in scripting and used by the controller, while other parameters are based on Custom Curves in Animation Clips and can be sampled using the scripting API. More info Animator window The window where the Animator Controller is visualized and edited. More info Collider An invisible shape that is used to handle physical collisions for an object. A collider doesn’t need to be exactly the same shape as the object’s mesh - a rough approximation is often more efficient and indistinguishable in gameplay. More info Collision A collision occurs when the physics engine detects that the colliders of two GameObjects make contact or overlap, and at least one has a Rigidbody component and is in motion. More info GameObject The fundamental object in Unity scenes, which can represent characters, props, scenery, cameras, waypoints, and more. More info HeightMesh A navmesh that contains additional data that is used to more accurately determine the height at any point along the navmesh. More info Hierarchy Unity uses the concept of parent-child hierarchies, or parenting, to group GameObjects. An object can contain other GameObjects that inherit its properties. More info Input Geometry The geometry to consider when baking the navmesh. More info Inspector A Unity window that displays information about the currently selected GameObject, asset or project settings, allowing you to inspect and edit the values. More info Mesh The main graphics primitive of Unity. Meshes make up a large part of your 3D worlds. Unity supports triangulated or Quadrangulated polygon meshes. Nurbs, Nurms, Subdiv surfaces must be converted to polygons. More info NavMesh A mesh that Unity generates to approximate the walkable areas and obstacles in your environment for path finding and AI-controlled navigation. More info Prefab An asset type that allows you to store a GameObject complete with components and properties. The prefab acts as a template from which you can create new object instances in the scene. More info Rasterization The process of generating an image by calculating pixels for each polygon or triangle in the geometry. This is an alternative to ray tracing. Rigidbody A component that allows a GameObject to be affected by simulated gravity and other forces. More info Root motion Motion of character’s root node, whether it’s controlled by the animation itself or externally. More info Scene A Scene contains the environments and menus of your game. Think of each unique Scene file as a unique level. In each Scene, you place your environments, obstacles, and decorations, essentially designing and building your game in pieces. More info Scripts A piece of code that allows you to create your own Components, trigger game events, modify Component properties over time and respond to user input in any way you like. More info Terrain The landscape in your scene. A Terrain GameObject adds a large flat plane to your scene and you can use the Terrain’s Inspector window to create a detailed landscape. More info Unity unit The unit size used in Unity projects. By default, 1 Unity unit is 1 meter. To use a different scale, set the Scale Factor in the Import Settings when importing assets. More info Voxel A 3D pixel. More info"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/HeightMesh.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/HeightMesh.html",
    "title": "Build a HeightMesh for Accurate Character Placement | Inventory System",
    "summary": "Build a HeightMesh for Accurate Character Placement Use a HeightMesh to place your character more accurately on walkable surfaces during navigation. During navigation, the NavMesh Agent is constrained on the surface of the NavMesh. Since the NavMesh is an approximation of the walkable space, some features are evened out when the NavMesh is built. For example, stairs may appear as a slope in the NavMesh. If your game requires accurate placement of the agent, you can either add a HeightMesh to your NavMesh, or build a HeightMesh when you bake the NavMesh. Note It takes extra memory and runtime processing to build a HeightMesh, therefore, it will take longer to bake the NavMesh. To add a HeightMesh to your NavMesh: Open your scene in the Editor. Select the scene geometry or GameObject that contains your NavMesh. In the Inspector, expand the NavMesh Surface component, if necessary. In the NavMesh Surface component, expand the Advanced section, then select Build Height Mesh. When you are finished, click Bake. The NavMesh is generated and displayed as a blue overlay and the HeightMesh as a pink overlay. To build a HeightMesh when you bake the NavMesh: Follow the instructions to Create a NavMesh. In the NavMesh Surface component, select Build Height Mesh. When you are finished, click Bake. The NavMesh is generated and displayed as a blue overlay and the HeightMesh as a pink overlay. Additional resources Create a NavMesh NavMesh Surface component reference Sample 8 - Heightmesh"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/MixingComponents.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/MixingComponents.html",
    "title": "Use NavMesh Agent with Other Components | Inventory System",
    "summary": "Use NavMesh Agent with Other Components You can use NavMesh Agent, NavMesh Obstacle and NavMesh Link components with other Unity components too. Here’s a list of dos and don’ts when mixing different components together. NavMesh Agent and Physics You don’t need to add physics colliders to NavMesh Agents for them to avoid each other That is, the navigation system simulates agents and their reaction to obstacles and the static world. Here the static world is the baked NavMesh. If you want a NavMesh Agent to push around physics objects or use physics triggers: Add a Collider component (if not present) Add Rigidbody component Turn on kinematic (Is Kinematic) - this is important! Kinematic means that the rigid body is controlled by something else than the physics simulation If both NavMesh Agent and Rigidbody (non-kinematic) are active at the same time, you have race condition Both components may try to move the agent at the same time which leads to undefined behavior You can use a NavMesh Agent to move e.g. a player character, without physics Set players agent’s avoidance priority to a small number (high priority), to allow the player to brush through crowds Move the player agent using NavMeshAgent.velocity, so that other agents can predict the player movement to avoid the player. NavMesh Agent and Animator NavMesh Agent and Animator with Root Motion can cause race condition Both components try to move the transform each frame Two possible solutions Information should always flow in one direction Either agent moves the character and animations follows Or animation moves the character based on simulated result Otherwise you’ll end up having a hard to debug feedback loop Animation follows agent Use the NavMeshAgent.velocity as input to the Animator to roughly match the agent’s movement to the animations Robust and simple to implement, will result in foot sliding where animations cannot match the velocity Agent follows animation Disable NavMeshAgent.updatePosition and NavMeshAgent.updateRotation to detach the simulation from the game objects locations Use the difference between the simulated agent’s position (NavMeshAgent.nextPosition) and animation root (Animator.rootPosition) to calculate controls for the animations See Coupling Animation and Navigation for more details NavMesh Agent and NavMesh Obstacle Do not mix well! Enabling both will make the agent trying to avoid itself If carving is enabled in addition, the agent tries to constantly remap to the edge of the carved hole, even more erroneous behavior ensues Make sure only one of them are active at any given time Deceased state, you may turn off the agent and turn on the obstacle to force other agents to avoid it Alternatively you can use priorities to make certain agents to be avoided more NavMesh Obstacle and Physics If you want physics controlled object to affect NavMesh Agent’s behavior Add NavMesh Obstacle component to the object which agent should be aware of, this allows the avoidance system to reason about the obstacle If a game object has a Rigidbody and a NavMesh Obstacle attached, the obstacle’s velocity is obtained from the Rigidbody automatically This allows NavMesh Agents to predict and avoid the moving obstacle"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavAgentPatrol.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavAgentPatrol.html",
    "title": "Make an Agent Patrol Between a Set of Points | Inventory System",
    "summary": "Make an Agent Patrol Between a Set of Points Many games feature NPCs that patrol automatically around the playing area. The navigation system can be used to implement this behavior but it is slightly more involved than standard pathfinding - merely using the shortest path between two points makes for a limited and predictable patrol route. You can get a more convincing patrol pattern by keeping a set of key points that are “useful” for the NPC to pass through and visiting them in some kind of sequence. For example, in a maze, you might place the key patrol points at junctions and corners to ensure the agent checks every corridor. For an office building, the key points might be the individual offices and other rooms. A maze with key patrol points marked The ideal sequence of patrol points depends on the way you want the NPCs to behave. For example, a robot would probably just visit the points in a methodical order while a human guard might try to catch the player out by using a more random pattern. You can implement the simple behavior of the robot with the code shown below. The patrol points are supplied to the script using a public array of Transforms. This array can be assigned from the inspector using GameObjects to mark the points’ positions. The GotoNextPoint function sets the destination point for the agent (which also starts it moving) and then selects the new destination that will be used on the next call. As it stands, the code cycles through the points in the sequence they occur in the array but you can easily modify this, say by using Random.Range to choose an array index at random. In the Update function, the script checks how close the agent is to the destination using the remainingDistance property. When this distance is very small, a call to GotoNextPoint is made to start the next leg of the patrol. // Patrol.cs using UnityEngine; using UnityEngine.AI; using System.Collections; public class Patrol : MonoBehaviour { public Transform[] points; private int destPoint = 0; private NavMeshAgent agent; void Start () { agent = GetComponent<NavMeshAgent>(); // Disabling auto-braking allows for continuous movement // between points (i.e. the agent doesn't slow down as it // approaches a destination point). agent.autoBraking = false; GotoNextPoint(); } void GotoNextPoint() { // Returns if no points have been set up if (points.Length == 0) return; // Set the agent to go to the currently selected destination. agent.destination = points[destPoint].position; // Choose the next point in the array as the destination, // cycling to the start if necessary. destPoint = (destPoint + 1) % points.Length; } void Update () { // Choose the next destination point when the agent gets // close to the current one. if (!agent.pathPending && agent.remainingDistance < 0.5f) GotoNextPoint(); } }"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavEditorPreferences.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavEditorPreferences.html",
    "title": "AI Navigation preferences reference | Inventory System",
    "summary": "AI Navigation preferences reference Use the AI Navigation preferences to specify how the navigation meshes (NavMesh and HeightMesh) display in the Scene view. The AI Navigation preferences are located in the Preferences window. To open the AI Navigation preferences, do the following: In the main menu, go to Edit > Preferences. Select AI Navigation. The following table describes the controls available in the AI Navigation preferences tab. Control Description Selected Surfaces Opacity Specify the opacity of the displayed meshes (NavMesh and HeightMesh) for NavMesh Surface instances that are part of the current selection hierarchy. Unselected Surfaces Opacity Specify the opacity of displayed meshes (NavMesh and HeightMesh) for NavMesh Surface instances that are outside of the current selection hierarchy. Height Mesh Color Set the color used to display the HeightMesh. Reset to Defaults Set all the NavMesh Visualization Settings parameters to their default value. Note The NavMesh is represented in the colors described in the Areas tab of the Navigation window. That color palette cannot be modified. Additional resources Preferences window AI Navigation overlay"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavHowTos.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavHowTos.html",
    "title": "Navigation How-Tos | Inventory System",
    "summary": "Navigation How-Tos The following topics describe a set of techniques, and include code samples, to implement common tasks in navigation. As with all code in our documentation, you are free to use these samples for any purpose without crediting Unity. Topic Description Tell a NavMeshAgent to Move to a Destination Set a destination for a NavMesh agent. Move an Agent to a Position Clicked by the Mouse Use a mouse click to set the destination for a NavMesh agent. Make an Agent Patrol Between a Set of Points Set patrol points for a NavMesh agent. Couple Animation and Navigation Integrate animation into your navigation."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavInnerWorkings.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavInnerWorkings.html",
    "title": "Inner Workings of the Navigation System | Inventory System",
    "summary": "Inner Workings of the Navigation System When you want to intelligently move characters in your game (or agents as they are called in AI circles), you have to solve two problems: how to reason about the level to find the destination, then how to move there. These two problems are tightly coupled, but quite different in nature. The problem of reasoning about the level is more global and static, in that it takes into account the whole Scene. Moving to the destination is more local and dynamic, it only considers the direction to move and how to prevent collisions with other moving agents. Walkable Areas The navigation system needs its own data to represent the walkable areas in a game scene. The walkable areas define the places in the scene where the agent can stand and move. In Unity the agents are described as cylinders. The walkable area is built automatically from the geometry in the scene by testing the locations where the agent can stand. Then the locations are connected to a surface laying on top of the scene geometry. This surface is called the navigation mesh (NavMesh for short). The NavMesh stores this surface as convex polygons. Convex polygons are a useful representation, since we know that there are no obstructions between any two points inside a polygon. In addition to the polygon boundaries, we store information about which polygons are neighbors to each other. This allows us to reason about the whole walkable area. Finding Paths To find a path between two locations in the scene, we first need to map the start and destination locations to their nearest polygons. Then we start searching from the start location, visiting all the neighbors until we reach the destination polygon. Tracing the visited polygons allows us to find the sequence of polygons which will lead from the start to the destination. A common algorithm to find the path is A* (pronounced “A star”), which is what Unity uses. Following the Path The sequence of polygons which describe the path from the start to the destination polygon is called a corridor. The agent will reach the destination by always steering towards the next visible corner of the corridor. If you have a simple game where only one agent moves in the scene, it is fine to find all the corners of the corridor in one swoop and animate the character to move along the line segments connecting the corners. When dealing with multiple agents moving at the same time, they will need to deviate from the original path when avoiding each other. Trying to correct such deviations using a path consisting of line segments soon becomes very difficult and error prone. Since the agent movement in each frame is quite small, we can use the connectivity of the polygons to fix up the corridor in case we need to take a little detour. Then we quickly find the next visible corner to steer towards. Avoiding Obstacles The steering logic takes the position of the next corner and based on that figures out a desired direction and speed (or velocity) needed to reach the destination. Using the desired velocity to move the agent can lead to collision with other agents. Obstacle avoidance chooses a new velocity which balances between moving in the desired direction and preventing future collisions with other agents and edges of the navigation mesh. Unity is using reciprocal velocity obstacles (RVO) to predict and prevent collisions. Moving the Agent Finally after steering and obstacle avoidance the final velocity is calculated. In Unity the agents are simulated using a simple dynamic model, which also takes into account acceleration to allow more natural and smooth movement. At this stage you can feed the velocity from the simulated agent to the animation system to move the character using root motion, or let the navigation system take care of that. Once the agent has been moved using either method, the simulated agent location is moved and constrained to NavMesh. This last small step is important for robust navigation. Global and Local One of the most important things to understand about navigation is the difference between global and local navigation. Global navigation is used to find the corridor across the world. Finding a path across the world is a costly operation requiring quite a lot of processing power and memory. The linear list of polygons describing the path is a flexible data structure for steering, and it can be locally adjusted as the agent’s position moves. Local navigation tries to figure out how to efficiently move towards the next corner without colliding with other agents or moving objects. Two Cases for Obstacles Many applications of navigation require other types of obstacles rather than just other agents. These could be the usual crates and barrels in a shooter game, or vehicles. The obstacles can be handled using local obstacle avoidance or global pathfinding. When an obstacle is moving, it is best handled using local obstacles avoidance. This way the agent can predictively avoid the obstacle. When the obstacle becomes stationary, and can be considered to block the path of all agents, the obstacles should affect the global navigation, that is, the navigation mesh. Changing the NavMesh is called carving. The process detects which parts of the obstacle touches the NavMesh and carves holes into the NavMesh. This is a computationally expensive operation, which is yet another compelling reason, why moving obstacles should be handled using collision avoidance. You can use local collision avoidance to steer around sparsely scattered obstacles too. Since the algorithm is local, it only considers the next immediate collisions, and cannot steer around traps or handle cases where an obstacle blocks a path. Use carving to solve these cases. About shortcuts between positions on NavMeshes The connections between the NavMesh polygons are described using links inside the pathfinding system. Sometimes it is necessary to let the agent navigate across places which are not walkable, for example, jumping over a fence, or traversing through a closed door. These cases need to know the location of the action. You can annotate these actions with the NavMesh Link component, which tells the pathfinder that a route exists through the specified link. Your code can later access this link and perform the special action as the agent follows the path. About Voxels The NavMesh bake process uses voxelization to build the NavMesh from arbitrary level geometry. The algorithm first rasterizes the scene into voxels, then it extracts the walkable surfaces, then finally, turns the walkable surfaces into a navigation mesh. Voxels are the cells in a regular 3D grid where the scene geometry overlaps with that grid. The grid cells have a width and a length of Voxel Size and a height that is half of that width. To increase the accuracy of the resulting NavMesh shape, reduce the Voxel Size so that the 3D grid can rasterize finer details from the scene geometry. The time it takes to process the scene geometry is proportional to the number of voxels that the geometry occupies. When the NavMesh Surface uses a small voxel size, it generally creates the NavMesh more slowly than when it uses a larger voxel size. If you want to create the NavMesh faster, and you can no longer reduce the number of scene objects to process, you can increase the voxel size. With that modification, the resulting NavMesh matches the scene geometry with lower accuracy, both at the edges around obstacles and in the elevation relative to the ground. To extend the NavMesh Surface through narrow passages, such as doors, and to maintain a quick baking time, choose the voxel size such that 3 voxels fit one Agent radius (6 per diameter). The NavMesh Surface uses this size by default. For big open areas, using 1 or 2 voxels per radius speeds up baking. Tight indoor spots are better suited to smaller voxels, for example 4 to 6 voxels per radius. More than 8 voxels per radius does not usually provide much additional benefit."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshAgent.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshAgent.html",
    "title": "NavMesh Agent component reference | Inventory System",
    "summary": "NavMesh Agent component reference The NavMesh Agent component allows you to create characters (agents) that avoid each other as they move through a scene. Agents use the NavMesh to navigate through the space of the game and avoid each other and other moving obstacles. You can use the scripting API of the NavMesh Agent to handle pathfinding and spatial reasoning. To use the NavMesh Agent component, add it to a GameObject: Select the GameObject that represents your agent. In the Inspector, click Add Component. Select Navigation > NavMesh Agent. The NavMesh Agent component is displayed in the Inspector window. You can use this component to create NavMesh agents. For more details, see Create a NavMesh Agent. For more information about NavMesh agents, see About NavMesh agents. The following tables describe the properties available in the NavMesh agent component. Property Description Agent type Select the type of agent you want to create. This allows the agent to move along any NavMesh created for the selected agent type. Base offset Specify the offset of the collision cylinder in relation to the transform pivot point. Steering Property Description Speed Set the maximum speed (in Unity units per second) at which the agent can move along a path. Angular Speed Set the maximum rotation speed (in degrees per second) of the agent. Acceleration Set the maximum acceleration (in Unity units per second squared). Stopping Distance Specify how close the agent can get to its destination. The agent stops when it arrives this close to the destination location. Auto Braking Specify if the agent slows down as it approaches its destination. When enabled, the agent slows down as it approaches the destination. Disable this if you want the agent to move smoothly between multiple points (for example, if the agent is a guard on patrol). Obstacle Avoidance Property Description Radius Specify the distance from the agent's center that is used to calculate collisions between the agent and other GameObjects. Height Specify the height clearance that the agent needs to pass below an obstacle that is overhead. For example, the minimum height of a doorway or tunnel. Quality Select the obstacle avoidance quality. If you have a high number of agents, you can reduce the obstacle avoidance quality to reduce performance costs. If you set obstacle avoidance quality to none, then collisions resolve, but other agents and obstacles are not actively avoided. Priority Specify how agents behave as they avoid each other. Agents avoid other agents of higher priority and ignore other agents of lower priority. The value should be in the range 0–99 where lower numbers indicate higher priority. Path Finding Property Description Auto Traverse OffMesh Link Specify whether or not the agent automatically traverses NavMesh links or OffMesh links (deprecated). When enabled, the agent automatically traverses NavMesh links. Disable Auto Traverse OffMesh Link if you want to use animation or a specific way to traverse NavMesh links. Auto Repath Specify what the agent does when it reaches the end of a partial path. When there is no path to the destination, Unity generates a partial path to the reachable location that is closest to the destination. If this property is enabled, when the agent reaches the end of a partial path it tries again to find a path to the destination. Area Mask Specify which area types the agent considers as it tries to find a path. You can select multiple options. When you prepare meshes for NavMesh baking, you can set each mesh's area type. For example, you can mark stairs with a special area type, and restrict some agent types from using the stairs. Additional resources Create a NavMesh Agent About NavMesh agents Inner Workings of the Navigation System NavMesh Agent scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshBuildingComponents.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshBuildingComponents.html",
    "title": "NavMesh Building Components | Inventory System",
    "summary": "NavMesh Building Components The NavMesh-building components provide you with controls that allow you to automatically generate and use NavMeshes at runtime and in the Unity Editor. Here we introduce four high level components for the navigation system: NavMesh Surface - Use for building and enabling a NavMesh surface for one type of Agent. NavMesh Modifier - Use for affecting the NavMesh generation of NavMesh area types based on the transform hierarchy. NavMesh Modifier Volume - Use for affecting the NavMesh generation of NavMesh area types based on volume. NavMesh Link - Use for connecting the same or different NavMesh surfaces for one type of Agent."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshLink.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshLink.html",
    "title": "NavMesh Link component reference | Inventory System",
    "summary": "NavMesh Link component reference Use the NavMesh Link component to connect different NavMeshes built for the same agent type. The link can be a line from one point to another (no width), or a span (with width). If the link is a span (with width), the Agent uses the nearest location along the entry edge to cross the link. For example, you can use the NavMesh Link component to connect a NavMesh that represents a building’s interior to a NavMesh that represents the building’s exterior. You can't overlap separate NavMeshes to create a link between them. To use the NavMesh Link you can either add it to your scene as a GameObject or add it to an existing GameObject as a component. To add a NavMesh Link to your scene as a GameObject, do the following: From the main menu go to GameObject > AI > NavMesh Link. The NavMesh Link component is displayed in the Inspector window. To add the NavMesh Link component to an existing GameObject, do the following: Select the GameObject you want to add the component to. In the Inspector select Add Component, then select Navigation > NavMesh Link. The NavMesh Link component is displayed in the Inspector window. Property Description Agent Type Specify which Agent type can use the link. Start Transform Select the GameObject that represents the start location of the link. This object is tracked by the middle of the link's start edge. Start Point Specify the start point of the link, relative to the GameObject's world-space position and orientation. The three values define the point's X, Y, and Z coordinates. Neither transform scale nor shear affect this point. The link uses this start position only when Start Transform does not reference any object. End Transform Select the GameObject that represents the end location of the link. This GameObject is tracked by the middle of the link's end edge. End Point Specify the end point of the link, relative to the GameObject's world-space position and orientation. The three values define the point's X, Y, and Z coordinates. Neither transform scale nor shear affect this point. The link uses this end position only when End Transform does not reference any object. Swap Swap the start and end points and swap the start and end transforms. Re-Center Origin Move the GameObject to the center point of the link and align the transform’s forward axis with the end point. Width Specify the width of the link. You can also drag the handles at the side of the link to adjust the width. Note: The GameObject's scale does not affect the width of the link. Cost Override Choose how to assign the cost to move across the link. Select Cost Override to set the cost value directly in the adjacent number field. Deselect Cost Override for the cost of the Area type to become the cost of moving over the NavMesh link. In this case the adjacent number field is disabled and not used. Path finding uses the cost in conjunction with the distance between the start and end positions in world space. For more information, refer to Areas and costs. Auto Update Positions Update the positions of the link's ends automatically when any of the GameObject transform, the start transform or the end transform change position. Bidirectional Control the direction NavMesh Agents move across the link. When you select this checkbox, NavMesh Agents can move across the link in both directions (from the start point to the end point, and from the end point to the start point). When you clear this checkbox, NavMesh Agents can only move across the link in one direction (from the start point to the end point). Area Type The area type of the NavMesh Link. The area type allows you to apply a common traversal cost to similar area types and prevent certain characters from accessing the NavMesh Link based on the agent’s Area Mask. For more information about area types and traversal costs, refer to Areas and costs. Area Type > Walkable Make the link walkable for the affected agent types. This is the default option. Area Type > Not Walkable Prevent the affected agent types from crossing the link. Links with a Not Walkable area type do not connect to any NavMesh. Area Type > Jump Change the area type of the link to Jump. This is the type that is assigned to all auto-generated NavMesh links. Area Type > Open Area Settings Open the Areas tab of the Navigation window to define new area types or modify existing ones. Activated Allow agents and queries to use the link in pathfinding. Select Activated to display the link's gizmo in the Scene view with black lines. Deselect Activated to display the link's gizmo in the Scene view with red lines. To adjust the ends of the link directly from the scene view you can drag the yellow handler gizmos at each end. A yellow cube represents the Point position for that end. In the opposite arrangement where the link references an object, a yellow sphere represents the Transform position of the referenced object. If you move the yellow sphere, the referenced object moves along to the same position. To adjust the width of the link you can drag the orange dot handler gizmos placed on the sides of the link, at one third of the distance from the start to the end. To display the handles, enable the NavMesh Link gizmo and select the GameObject. For more information on gizmos, refer to Gizmos menu. Additional resources About Agents Areas and costs OffMesh Link component (deprecated) reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshModifier.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshModifier.html",
    "title": "NavMesh Modifier component reference | Inventory System",
    "summary": "NavMesh Modifier component reference Use the NavMesh Modifier component to adjust the behavior of a GameObject when the NavMesh is baked at runtime. The NavMesh Modifier component affects the NavMesh during the generation process only. This means the NavMesh is updated to reflect any changes to NavMesh Modifier components when you bake the NavMesh. Use the available properties to specify changes in behavior and any limits to those changes. To use the NavMesh Modifier component, add it to a GameObject as follows: Select the GameObject whose effect on the NavMesh you want to modify. In the Inspector, select Add Component, then select Navigation > NavMesh Modifier. The NavMesh Modifier component is displayed in the Inspector window. The NavMesh Modifier can also affect the NavMesh generation process hierarchically. This means that the GameObject the component is attached to, as well as all its children, are affected. In addition, you can place another NavMesh Modifier further down the hierarchy to override the NavMesh Modifier that is further up the hierarchy. To apply the NavMesh Modifier hierarchically, select the Apply To Children property. Note The NavMesh Modifier component replaces the legacy Navigation Static setting which you could enable from the Objects tab of the Navigation window and the Static flags dropdown on the GameObject. The NavMesh Modifier component is available for baking at runtime, whereas the Navigation Static flags were available in the Editor only. The following table describes the properties available in the NavMesh Modifier component. Property Description Mode Specify whether to consider or ignore the affected GameObject(s). Mode > Add or Modify Object Consider the affected GameObject(s) when building the NavMesh. Mode > Remove Object Ignore the affected object(s) when building the NavMesh for the specified agent type. Affected Agents Specify which agents the NavMesh Modifier affects. For example, you can choose to have certain obstacles be ignored by specific agents. Affected Agents > All Modify the behavior of all agents. Affected Agents > None Exclude all agents from the modified behavior. Apply to Children Apply the configuration to the child hierarchy of the GameObject. To override this component's influence further down the hierarchy, add another NavMesh Modifier component. Override Area Change the area type for the affected GameObject(s). If you want to change the area type, select the checkbox then select the new area type in the Area Type dropdown. If you do not want to change the area type, clear the checkbox. Override Area > Area Type Select the new area type you want to apply from the dropdown. Override Generate Links Force the NavMesh bake process to either include or ignore the affected GameObject(s) when you generate links. Override Generate Links > Generate Links Specify whether or not to include the affected GameObject(s) when you generate links. To include the GameObject(s) when you generate links in the NavMesh bake process, select this checkbox. To ignore the GameObject(s) when you generate links in the NavMesh bake process, clear this checkbox. Additional resources Create a NavMesh Navigation Areas and Costs Navigation Agent Types"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshModifierVolume.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshModifierVolume.html",
    "title": "NavMesh Modifier Volume component reference | Inventory System",
    "summary": "NavMesh Modifier Volume component reference Use the NavMesh Modifier Volume component to change the area type of any NavMeshes within a defined region. The available properties allow you to define the affected region and specify the change in area type that you want. However, the modifier volume only affects the NavMeshes that are being newly built for the selected agent types. It has no effect on NavMeshes that already exist in the scene or in that volume and no effect on NavMeshes that get built for unaffected agent types. You need to add the NavMesh Modifier Volume component to a GameObject. Though you can add the NavMesh Modifier Volume component to any GameObject in your scene, you typically add it to the GameObject that's associated with the NavMesh you want to affect. To add the NavMesh Modifier Volume component to a GameObject, do the following: Select the GameObject you want to use. In the Inspector, select Add Component > Navigation > NavMesh Modifier Volume. The NavMesh Modifier Volume component is displayed in the Inspector window. To change the area type of an entire GameObject, use the NavMesh Modifier component instead. NavMesh Modifier Volume is useful when you need to assign an area type to part of your NavMesh that might not be represented as separate geometry. For example, you can use NavMesh Modifier Volume to make part of your NavMesh non-walkable or more difficult to cross. The NavMesh Modifier Volume always assigns its area type when it overlaps with NavMesh Modifier objects, even if the area type of the volume has a lower index. When multiple volumes intersect, the area type with the highest index value out of all of them takes precedence. The exception to these rules is that the built-in Not Walkable area type assigned to any of the overlapping components is always the most important. The NavMesh Modifier Volume affects the NavMesh generation process. As a result, the NavMesh is updated to reflect any changes to NavMesh Modifier Volumes. The following table describes the properties available in the NavMesh Modifier Volume component. Property Description Edit Volume Toggle the ability to edit the size of the volume in the Scene view. To modify the size of the volume as needed, select Edit Volume. A wire box with handles, representing the volume, is displayed in the Scene view. Drag the handles to modify the size of the volume. Size Specify the dimensions of the NavMesh Modifier Volume, defined by XYZ measurements. Center Specify the center of the NavMesh Modifier Volume relative to the center of the GameObject, defined by XYZ coordinates. Area Type Select the area type that the NavMesh Modifier Volume applies to NavMeshes within the defined region. The available options include all of the area types that have a cost defined in the Areas tab of the Navigation window. Area Type > Open Area Settings Open the Areas tab of the Navigation window to define new area types or modify existing ones. Affected Agents Select the agent types for which the NavMesh Modifier Volume change applies. For example, you can make the selected NavMesh Modifier Volume a danger zone for specific agent types only. The available options include all of the agent types defined on the Agents tab of the Navigation window. Affected Agents > All Apply the change to all of the defined agent types whether now or in the future. Affected Agents > None Don't apply the change to any of the defined agent types. Affected Agents > Defined area types Apply the change to the selected agent types. You can select more than one agent type. Additional resources Create a NavMesh Navigation Areas and Costs Navigation Agent Types"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshObstacle.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshObstacle.html",
    "title": "NavMesh Obstacle component reference | Inventory System",
    "summary": "NavMesh Obstacle component reference The NavMesh Obstacle component allows you to define obstacles that NavMesh Agents should avoid as they navigate the world (for example, barrels or crates controlled by the physics system). It contains properties that allow you to define the size, shape, and behavior of the obstacle. To use the NavMesh component you need to add it to a game object as follows: Select the GameObject you want to use as an obstacle. In the Inspector select Add Component, then select Navigation > NavMesh Obstacle. The NavMesh Obstacle component is displayed in the Inspector window. You can use this component to create NavMesh obstacles. For more information, see Create a NavMesh Obstacle. For more information on NavMesh obstacles and how to use them, see About NavMesh obstacles. The following table describes the properties available in the NavMesh Obstacle component. Property Description Shape Specify the shape of the obstacle geometry. Choose whichever one best fits the shape of the object. Shape > Box Select a cube-shaped geometry for the obstacle. Shape > Capsule Select a 3D oval-shaped geometry for the obstacle. Center Specify the center of the box relative to the transform position. Size Specify the size of the box. This property is visible only when Shape is set to Box. Center Specify the center of the capsule relative to the transform position. Radius Specify the radius of the capsule. This property is visible only when Shape is set to Capsule. Height Specify the height of the capsule. This property is visible only when Shape is set to Capsule. Carve Allow the NavMesh Obstacle to create a hole in the NavMesh. When selected, the NavMesh obstacle carves a hole in the NavMesh. When deselected, the NavMesh obstacle does not carve a hole in the NavMesh. Carve > Move Threshold Set the threshold distance for updating a moving carved hole. Unity treats the NavMesh obstacle as moving when it has moved more than the distance set by the Move Threshold. This property is available only when Carve is selected. Carve > Time To Stationary Specify the time (in seconds) to wait until the obstacle is treated as stationary. This property is available only when Carve is selected. Carve > Carve Only Stationary Specify when the obstacle is carved. This property is available only when Carve is selected. Additional resources About NavMesh obstacles Create a NavMesh Obstacle Inner Workings of the Navigation System NavMesh Obstacle scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshSurface.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMeshSurface.html",
    "title": "NavMesh Surface component reference | Inventory System",
    "summary": "NavMesh Surface component reference Use the NavMesh Surface component to define and build a NavMesh for a specific type of NavMesh Agent in your scene. Use the available properties to specify the type of NavMesh Agent that can use the NavMesh, the area type to assign to the generated NavMesh, and the geometry to use when you bake the NavMesh. To use the NavMesh Surface component, apply it to the GameObject on which you want to build the NavMesh. To apply the NavMesh Surface component to a GameObject, do the following: Select the GameObject. In the Inspector, select Add Component > Navigation > NavMesh Surface. The Inspector window displays the NavMesh Surface component. In the NavMesh Surface component, you can click Bake to generate the NavMesh for the current settings and scene geometry. The resulting NavMesh data replaces any NavMesh that NavMesh Surface already contains, if that is the case. A Scene can contain multiple NavMesh surfaces. You can add the NavMesh Surface component to any GameObject in your scene. This is useful for when you want to use the GameObject parenting hierarchy to define which GameObjects contribute to the NavMesh. Only the NavMesh Surface components that are enabled and part of active GameObjects load their NavMesh data into the navigation system. You can unload NavMesh data from the scene by disabling either the NavMesh Surface that contains it or the GameObject that the NavMesh Surface is attached to. The following table describes the properties available in the NavMesh Surface component. Use the main settings for the NavMesh Surface component to filter the input geometry on a broad scale. Use the NavMesh Modifier component to adjust how Unity treats input geometry on a per-GameObject basis. Property Description Agent Type Select the type of NavMesh Agent that can use the NavMesh. Default Area Specify the area type to assign to the generated NavMesh. The area types define how difficult it is for agents to move across the NavMesh. The available options include all of the area types defined on the Areas tab of the Navigation window. There are 29 custom area types and 3 built-in area types: Default Area > Walkable Make the NavMesh walkable for the assigned Agent type. (This is the default option.) Default Area > Not Walkable Prevent the specified Agent type from crossing this surface unless there is a GameObject that overrides the area type. Default Area > Jump This option is used for automatically generated links. For more details about area types, refer to Navigation Areas and Costs. Generate Links Automatically generate links between objects that the NavMesh Surface collects when you bake the NavMesh. If you select Generate Links, NavMesh Surface attempts to generate links between any collected GameObjects when you bake the NavMesh. If you do not select Generate Links, NavMesh Surface doesn't attempt to generate any links between the collected GameObjects when you bake the NavMesh. Refer to the Links Generation section for more information. Use Geometry Select which geometry to use when you bake the NavMesh. Use Geometry > Render Meshes Use geometry from Render Meshes and Terrains. Use Geometry > Physics Colliders Use geometry from Colliders and Terrains. Agents can move closer to the edge of the physical bounds of the environment with this option than they can with the Render Meshes option. For more information on Colliders, refer to Introduction to collision. NavMesh Data (Read-only) Locate the asset file where the NavMesh is stored. The text box displays None when the NavMesh Surface does not contain NavMesh data. The text box displays Missing if you delete the asset file from the Project window and don't use Clear first. Clear Remove the asset file where the NavMesh is stored. Use this button also when you plan to remove the component. Bake Bake a NavMesh with the current settings. When you bake the NavMesh, it automatically excludes GameObjects that have a NavMesh Agent or NavMesh Obstacle. They are dynamic users of the NavMesh and don't contribute to the process. Unity stores the NavMesh data in an asset file. The NavMesh Data property displays a reference to the asset file. Object collection Use the Object Collection settings to define which GameObjects to use when you bake the NavMesh. | Property | Description | |---|---| | Collect Objects | Define which GameObjects to use when you bake the NavMesh. | | Collect Objects > All Game Objects | Use all active GameObjects in the scene. (This is the default option.) | | Collect Objects > Volume | Use all active GameObjects that overlap the bounding volume. Geometry that is located outside of the bounding volume but within the agent radius is included when you bake the NavMesh. | | Collect Objects > Current Object Hierarchy | Use the GameObject that the NavMesh Surface component is placed on and all active GameObjects which are children of this GameObject. | | Collect Objects > NavMeshModifier Component Only | Use any GameObjects in the scene that have a NavMesh Modifier attached to them and, if their Apply To Children option is turned on, use their child objects as well. | | Include Layers | Select the layers for which GameObjects are included in the bake process. In addition to Collect Objects, this allows for further exclusion of specific GameObjects from the bake process (for example, effects or animated characters). This is set to Everything by default, but you can toggle options on (denoted by a check mark) or off, individually. | Furthermore, you can use the NavMesh Modifier component to designate more precisely the objects, and their hierarchies, that the NavMesh Surface can or cannot collect. Advanced Settings Use the Advanced settings section to customize the following additional properties: Property Description Override Voxel Size Control how accurately Unity processes the input geometry when you bake the NavMesh. This is a trade-off between speed and accuracy. The default size is one third of the Agent radius, which translates into 3 voxels per Agent radius. This voxel size allows the capture of narrow passages, such as doors, and maintains a quick baking time. For big open areas, you can use 1 or 2 voxels per radius to speed up baking. Tight indoor spots are better suited to smaller voxels, for example 4 to 6 voxels per radius. More than 8 voxels per radius doesn't usually provide much additional benefit. To change the default size, select this checkbox. In the Voxel Size field, specify the size of the voxels to use when you bake the NavMesh. Voxel Size Specify the size, in world units, of the voxels to use when you bake the NavMesh. This property is only available if you select the Override Voxel Size option. Override Tile Size Change the default Tile Size of the NavMesh. To make the bake process parallel and memory efficient, the Scene is divided into tiles for baking. The white lines visible on the NavMesh are tile boundaries. The default tile size is 256 voxels, which provides a good trade-off between memory use and NavMesh fragmentation. To change this default tile size, select this checkbox. In the Tile Size field, specify the number of voxels you want the tile size to be. The smaller the tiles, the more fragmented the NavMesh is. This can sometimes cause non-optimal paths. NavMesh carving also operates on tiles. If you have a lot of obstacles in your scene, you can often speed up carving by making the tile size smaller (for example around 64 to 128 voxels). For more information, refer to Carving. If you plan to bake the NavMesh at runtime, use a smaller tile size to keep the maximum memory use low. Tile Size Specify the desired Tile Size in voxels. This property is only available if you select the Override Tile Size option. Minimum Region Area Remove small regions that are disconnected from the larger NavMesh. The process that builds the NavMesh doesn't retain the stretches of the mesh that have a surface size smaller than the specified value. Note: Some areas might not get removed despite the Minimum Region Area parameter. The NavMesh is built in parallel as a grid of tiles. If an area straddles a tile boundary, the area isn't removed. The reason for this is that the area pruning step takes place at a stage in the build process when the surrounding tiles aren't accessible. Build Height Mesh Generate additional data that specifies the height of the surface at each point on the NavMesh. Select this option to generate HeightMesh data. Clear this option if you do not want to generate HeightMesh data. For more information, refer to Build a HeightMesh for Accurate Character Placement. Additional resources About NavMesh agents Build a HeightMesh for Accurate Character Placement Links Generation Carving Hierarchy Create a NavMesh agent Navigation areas and costs Navigation agent configurations NavMesh Modifier component reference NavMesh Modifier Volume component reference Physics Colliders Terrains"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMoveToClickPoint.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMoveToClickPoint.html",
    "title": "Move an Agent to a Position Clicked by the Mouse | Inventory System",
    "summary": "Move an Agent to a Position Clicked by the Mouse This script lets you choose the destination point on the NavMesh by clicking the mouse on the object’s surface. The position of the click is determined by a raycast, rather like pointing a laser beam at the object to see where it hits (see the page Rays from the Camera for a full description of this technique). Since the GetComponent function is fairly slow to execute, the script stores its result in a variable during the Start function rather than call it repeatedly in Update. // MoveToClickPoint.cs using UnityEngine; using UnityEngine.AI; public class MoveToClickPoint : MonoBehaviour { NavMeshAgent agent; void Start() { agent = GetComponent<NavMeshAgent>(); } void Update() { if (Input.GetMouseButtonDown(0)) { RaycastHit hit; if (Physics.Raycast(Camera.main.ScreenPointToRay(Input.mousePosition), out hit, 100)) { agent.destination = hit.point; } } } }"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMoveToDestination.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavMoveToDestination.html",
    "title": "Tell a NavMeshAgent to Move to a Destination | Inventory System",
    "summary": "Tell a NavMeshAgent to Move to a Destination You can tell an agent to start calculating a path simply by setting the NavMeshAgent.destination property with the point you want the agent to move to. As soon as the calculation is finished, the agent will automatically move along the path until it reaches its destination. The following code implements a simple class that uses a GameObject to mark the target point which gets assigned to the destination property in the Start function. Note that the script assumes you have already added and configured the NavMeshAgent component from the editor. // MoveDestination.cs using UnityEngine; using UnityEngine.AI; public class MoveDestination : MonoBehaviour { public Transform goal; void Start () { NavMeshAgent agent = GetComponent<NavMeshAgent>(); agent.destination = goal.position; } }"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationOverlay.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationOverlay.html",
    "title": "AI Navigation overlay reference | Inventory System",
    "summary": "AI Navigation overlay reference The AI Navigation overlay allows you to control the display of NavMesh surfaces, agents, and GameObjects in the Scene view. You can use it to help you debug any issues with AI Navigation and pathfinding. Use the Overlay Menu to show or hide the AI Navigation overlay. It docks to the lower right corner of the Scene view by default. To reposition the overlay, click and drag its handle. Surfaces This section controls the way NavMesh Surface instances are displayed. The following table describes the controls available in the Surfaces section of the overlay. Control Description Show Only Selected Display only the surfaces part of the current scene selection hierarchy. You can set the opacity of the selected and non-selected surfaces in the Preferences window. For more details, refer to AI Navigation preferences. Show NavMesh Display navigation meshes for the relevant surfaces. The colors used to display this mesh are the ones defined for the area types. Show HeightMesh Display HeightMeshes (surface precise elevation information) for the relevant surfaces. Agents This section controls the displayed information for the currently selected NavMesh Agents. The following table describes the controls available in the Agents section of the overlay. Control Description Show Path Polygons Display the NavMesh polygons part of the agent's path in a darker color. Show Path Query Nodes Display the path nodes explored during the pathfinding query in yellow. Show Neighbors Display the collision avoidance neighbors (dynamic obstacles) relative to the agent. Show Walls Display the collision avoidance walls (static obstacles) for an agent. Show Avoidance Show the different positions sampled during the collision avoidance process. Obstacles This section controls the displayed information for the currently selected NavMesh Obstacles. The following table describes the controls available in the Obstacles section of the overlay. Control Description Show Carve Hull Display the convex shape that is used to carve the NavMesh. Additional resources Overlays - How to use and work with overlays."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationOverview.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationOverview.html",
    "title": "Navigation Overview | Inventory System",
    "summary": "Navigation Overview This section provides details on how to build NavMeshes for your Scene or prefabs, and create NavMesh agents, NavMesh obstacles and NavMesh links. Topic Description Create a NavMesh Define the area(s) of your scene where a character can navigate intelligently. Create a NavMesh agent Create a character to navigate your scene. Create a NavMesh obstacle Create obstacles for the agents to avoid as they navigate your scene. Create a NavMesh link Create navigation shortcuts that cannot be represented by a walkable surface. Using NavMesh Agent with other components Best practices when using navigation components along with other Unity components. Advanced navigation how-tos Advanced techniques to implement common tasks in navigation."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationSystem.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationSystem.html",
    "title": "Navigation System in Unity | Inventory System",
    "summary": "Navigation System in Unity This section describes the key concepts necessary to use AI Navigation in Unity. It contains the following topics: Topic Description Inner Workings of the Navigation System Understand how the different elements of the AI Navigation system work together. About Agents Learn about NavMesh agents. About Obstacles Learn about NavMesh obstacles. Navigation Areas and Costs Understand the purpose of navigation areas and why you would use one type of area over another."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationWindow.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/NavigationWindow.html",
    "title": "Navigation window reference | Inventory System",
    "summary": "Navigation window reference Use the Navigation window to specify the types of NavMesh agents and areas used in your scenes. To get to the Navigation window, in the main menu go to Window > AI > Navigation. Agents tab The Agents tab contains properties that allow you to define the type of agents that you use in your scenes. Property Description Agent Types Select an agent type to modify. Click the \"+\" icon to add an agent type. Click the \"-\" icon to remove the currently selected agent type. Name Specify the name of the type of agent. Radius Define how close the agent center can get to a wall or a ledge. Height Specify the height of this type of agent in Unity units. Step Height Specify the maximum step height that this type of agent can climb. Max Slope Specify how steep of a ramp the agent can walk up. Type a value, in degrees, in the text box or drag the slider to adjust the value. Generated Links The following table describes the properties that define the limits of this agent type with respect to generated links. Property Description Drop Height Specify the maximum height from which this agent type can jump down. Jump Distance Specify the maximum distance of jump-across links for this agent type. Areas tab The Areas tab contains properties that allow you to specify how difficult it is to walk across the different area types used in your scenes. There are 29 custom area types, and 3 built-in area types: Walkable is a generic area type which specifies that the area can be walked on. Not Walkable is a generic area type which prevents navigation. It is useful for cases where you want to mark a certain object to be an obstacle, but you don't want to put a NavMesh on top of it. Jump is an area type that is assigned to all auto-generated links that connect NavMeshes. The following table describes the properties available on the Areas tab. Property Description Name Specify a name for the area type. Cost Specify the cost of traveling across this area. Costs are multipliers applied to the distance traveled across an area. A cost of 2 means an area is twice as difficult to cross as an area with a cost of 1. The default value is 1. Additional resources About NavMesh agents Create a NavMesh agent Navigation Areas and costs"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/OffMeshLink.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/OffMeshLink.html",
    "title": "OffMesh Link component reference | Inventory System",
    "summary": "OffMesh Link component reference Important The OffMesh Link component is deprecated and no longer supported. Use the NavMesh Link component instead. Use OffMesh Link components to incorporate navigation shortcuts, which can't be represented using a walkable surface, into your scene. For example, with OffMesh links, an agent can jump over a ditch or a fence, or open a door then walk through it. OffMesh Links only apply to the Humanoid agent type, so if the NavMeshes in your scene use a different agent type, the OffMesh Link won't create a link between them. The following table describes the properties available in the OffMesh Link component: Property Description Start Select the GameObject that represents the start location of the link. End Select the GameObject that represents the end location of the link. Cost Override Override the cost to move across the link. If the Cost Override value is negative, the cost of the Navigation Area type is used. If the Cost Override value is non-negative, the cost of moving over the link is equal to the Cost Override value multiplied by the length of the link. The length of the link is the distance between the start and end points of the link. Bidirectional Control the direction NavMesh Agents move across the link. When you select this checkbox, NavMesh Agents can move across the link in both directions (from the start to the end, and from the end to the start). When you clear this checkbox, NavMesh Agents can only move across the link in one direction (from the start to the end). Activated Allow the link to be used in pathfinding. Auto Update Positions Reconnect the OffMesh link to the NavMesh if you move the end points. If disabled, the link stays at its start location even if the end points move. Navigation Area Specify the area type of the OffMesh Link. Use the area type to apply a common traversal cost to similar area types and prevent certain characters from crossing the link based on the agent’s Area Mask. Navigation Area > Walkable Make the link walkable for the affected agent types. This is the default option. Navigation Area > Not Walkable Prevent the affected agent types from crossing the link. Navigation Area > Jump Change the area type of the link to Jump. Additional resources NavMesh Link component reference Create Off-Mesh Links (deprecated) Off-Mesh Link (deprecated) scripting reference"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Reference.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Reference.html",
    "title": "Navigation user interface | Inventory System",
    "summary": "Navigation user interface The Navigation user interface consists of the Navigation window, AI Navigation overlay, AI Navigation Editor Preferences and several components for building a NavMesh. The NavMesh building components provide you with additional controls that allow you to generate and use NavMeshes at runtime and in the Unity Editor. Topic Description Navigation window Define the types of agents and areas in your game world. AI Navigation preferences Customize the navigation debug visualization. AI Navigation overlay Display navigation debug visualization. NavMesh Agent component Define the characters that you want to navigate the game world. NavMesh Surface component Build and enable a NavMesh surface for one type of Agent. NavMesh Modifier component Adjust the behavior of a GameObject when the NavMesh is baked at runtime. NavMesh Modifier Volume component Control the generation of NavMesh area types based on volume. NavMesh Obstacle component Define moving obstacles that NavMesh Agents avoid as they navigate your game world. NavMesh Link component Connect the NavMesh surfaces for each type of agent."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Samples.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/Samples.html",
    "title": "Navigation Samples | Inventory System",
    "summary": "Navigation Samples The following sample scenes are included with the AI Navigation package: Multiple Agent Sizes: Demonstrates how a different radius on an agent type can change the way agents navigate through the same scene. Drop Plank: Demonstrates dynamically changing walkable paths by allowing the player to add walkable planks by pressing space. Free Orientation: Demonstrates a controllable agent that can walk on a tilted plane. Sliding Window Infinite: Demonstrates a controllable agent that can walk through a dynamically created world that gets updated to simulate infinity as the agent walks through it. The NavMesh is only built in some set bounds that follow the agent. Sliding Window Terrain: Demonstrates a controllable agent that can walk through a terrain for which the NavMesh is only generated within a set distance of the agent. Modify Mesh: Demonstrates agents walking aimlessly on planes whose mesh can be modified dynamically by the player. Dungeon: Demonstrates a controllable agent that can walk through a maze generated from pre-baked tiles that connect to each other at runtime. The link traversal animation can be modified with some presets (teleport, normal speed, parabola, curve). Height Mesh: Demonstrates two agents walking down stairs. The environment on the left uses NavMeshSurface with a Height Mesh which allows the agent to snap to each step in the stairs as it goes down. The environment on the right uses a NavMeshSurface with no Height Mesh; the agent simply slides down the stairs. Install com.unity.shadergraph when you import the samples into a project that uses the Built-in Render Pipeline."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Navigation and Pathfinding What's new Upgrade Navigation System in Unity Inner Workings of the Navigation System About Agents About Obstacles Navigation Areas and Costs Navigation overview Create a NavMesh Create a NavMesh agent Create a NavMesh obstacle Create a NavMesh link Use NavMesh Agents with other components Build a HeightMesh for Accurate Character Placement Advanced navigation how-tos Tell a NavMesh agent to move to a destination Move an agent to a position clicked by the mouse Make an agent patrol between a set of points Couple animation and navigation Navigation interface AI Navigation editor preferences AI Navigation overlay Navigation window NavMesh Agent component NavMesh Link component NavMesh Modifier component NavMesh Modifier Volume component NavMesh Obstacle component NavMesh Surface component OffMesh Link component (deprecated) Navigation Samples Glossary"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/UpgradeGuide.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/UpgradeGuide.html",
    "title": "Upgrade projects for use with AI Navigation package | Inventory System",
    "summary": "Upgrade projects for use with AI Navigation package Navigation and Pathfinding in Unity is handled by the AI Navigation package as of Unity 2022.2. If you have projects that were created with the Navigation feature in previous versions of Unity, the AI Navigation package is automatically installed and added to your project. You can then do one of the following: Continue to use your projects as they are Convert your projects to use the new package Remove old component scripts If your project uses the NavMesh Surface, NavMesh Modifier, NavMesh Modifier Volume or NavMesh Link components defined by scripts downloaded from Unity’s NavMeshComponents GitHub repository, then remove those scripts and any associated files before you add the AI Navigation package to your project. If you don’t remove these scripts, you might get conflicts and errors related to these components in the Console. The new components mirror the same behavior as the old components do in your project except when using the following components: The NavMesh Surface component now includes an option to use only the objects that have a NavMesh Modifier in the baking process. You can now specify whether or not to apply the NavMesh Modifier component to child objects in the hierarchy. Convert your project If you want to use the new package you need to convert your project(s). As part of the conversion process, the Navigation Updater makes the following changes: Any NavMesh that was previously baked and embedded in the scene is now referenced from a NavMesh Surface component created on a new GameObject called Navigation. Any object that was marked with Navigation Static now has a NavMesh Modifier component with the appropriate settings. The updater can also convert OffMesh Link components to NavMesh Link components. Refer to Convert OffMesh Link to NavMesh Link for more information. To convert your project do the following: In the main menu go to Window > AI > Navigation Updater. In the Navigation Updater window, select which kind of data to convert. In the Navigation Updater window, verify that NavMesh Scene Converter is selected. Select the data you want to convert. Click Convert Assets to complete the conversion. Create new agent types If the NavMeshes in different scenes are baked with different agent settings then you need to create new agent types to match those settings. To create the agent types do the following: In the main menu go to Window > AI > Navigation. Select Agents. Create new entries and specify the relevant settings. Assign new agent types When you have created the new agent types you then need to assign them as follows: Assign the newly created agent types to their respective NavMesh Surfaces in the Navigation GameObject created for that scene. Assign the agent types to the NavMesh Agents intended to use that NavMesh. To find the settings that were used for each existing NavMesh, select the NavMesh .asset file in the Project window. The NavMesh settings will be displayed in the Inspector. Create NavMesh Links instead of OffMesh Links The OffMesh Link component was originally designed to work with only the Humanoid agent type. Now it has been deprecated. Your project can still use this component but you can no longer add it from the editor. You are encouraged to use the NavMesh Link component instead. It has the same properties as OffMesh Link, and a few additional ones: agent type, width, and two positions that can define the ends. To replace an OffMesh Link component with a NavMesh Link component do the following: Select the GameObject that has the OffMesh Link component. The GameObject can be in a scene or a prefab. Add a NavMesh Link component. Assign to the NavMesh Link the same properties as the OffMesh Link. Remove the OffMesh Link from the GameObject. Save the scene or prefab as needed. Convert OffMesh Links to NavMesh Links To ease the transition from OffMesh Link to NavMesh Link, the package comes with an upgrade utility to automatically change any OffMesh Link component into a NavMesh Link component. The upgrade utility scans all scenes and prefabs in the project to find all instances of OffMesh Link components. To convert OffMesh Link components to NavMesh Link components do the following: From the main menu go to Window > AI > Navigation Updater. In the Navigation Updater window, verify that OffMesh Link Converter is checked. Select Initialize Converters to detect and display the prefabs and scenes that are eligible for conversion. Deselect any items you do not want to convert. Select Convert Assets to complete the conversion. Do note that the upgrade utility will not replace OffMeshLink with NavMeshLink in scripts. Refer to the following section for information on how to perform this upgrade manually. Replace OffMeshLink with NavMeshLink in scripts In your scripts you can replace any occurrence of the OffMeshLink class with the NavMeshLink class. The scripts will continue to work as before, as long as the NavMeshLink component exists on the affected GameObjects. The OffMeshLink properties autoUpdatePositions, biDirectional, costOverride and the method UpdatePositions() have equivalents in the NavMeshLink component. You can substitute those class members in places where you use them in scripts, or you can accept the suggestion from the Script Updating Consent utility to do the same thing. This utility runs when the editor reloads the scripts in the project."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/index.html",
    "title": "AI Navigation | Inventory System",
    "summary": "AI Navigation The navigation system allows you to create characters that can intelligently move around the game world. These characters use navigation meshes that are created automatically from your Scene geometry. Dynamic obstacles allow you to alter the navigation of the characters at runtime, while NavMesh links let you build specific actions like opening doors or jumping over gaps or down from a ledge. This section describes Unity's navigation and pathfinding systems in detail. The following table describes the main topics of the AI Navigation package documentation. Topic Description What's new See what's changed in the latest version of the AI Navigation package. Upgrade Convert your projects to work with the new navigation system. Navigation System Understand the key concepts necessary to use AI Navigation in Unity. Navigation Overview Create NavMeshes, agents, links, and obstacles with this package. Navigation Interface Learn about the interface of the Navigation components in this package. Samples Learn about the sample projects included with this package. Glossary View AI Navigation terminology definitions. Additional resources A guide on using the new AI Navigation package in Unity 2022 LTS and above Navigation tutorials Getting Started with AI Pathfinding Navigation Meshes Working with NavMesh Agents 3D Game Kit and 3D Game Kit Lite - Sample projects that include navigation The Explorer: 3D Game Kit - Tutorial about the sample project Enemies in the 3D Game Kit A Deeper Look at Enemies Decorating in 3D Game Kit Unity Discussions - Navigation topics on the Unity forums Unity Knowledge Base"
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Documentation~/whats-new.html",
    "title": "What's new in AI Navigation version 2.0.0 | Inventory System",
    "summary": "What's new in AI Navigation version 2.0.0 The main updates in this release include: Added New option to specify the end points of a NavMeshLink through Transform references. New NavMeshLink.activated property that gets or sets whether agents can use the link. Updated The NavMeshLink.costModifier property is now a float. The OffMeshLink component has been deprecated. You can no longer add it to GameObjects from the Add Component menu. Instead, you can now use a NavMeshLink component just as you would have used an OffMeshLink component in previous versions. For a full list of changes and updates in this version, see the AI Navigation package changelog."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.ai.navigation copyright © 2016 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/README.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/README.html",
    "title": "About AI Navigation | Inventory System",
    "summary": "About AI Navigation The AI Navigation package makes available the following tools for working with navigation in Unity: The Navigation window The NavMesh Updater window The AI Naigation overlay in the scene view The visualization in the scene view of the NavMeshes, links, obstacles, agents and their gizmos used for editing The authoring part of the components that exist in the com.unity.modules.ai core module (i.e. NavMeshAgent, NavMeshObstacle, OffMeshLink) Four components that comprise the high level controls for creating data for the navigation system: NavMeshSurface – for building and enabling a NavMesh surface for one agent type. NavMeshModifier – affects the NavMesh generation of NavMesh area types, based on the transform hierarchy. NavMeshModifierVolume – affects the NavMesh generation of NavMesh area types, based on volume. NavMeshLink – connects same or different NavMesh surfaces for one agent type. Using AI Navigation For detailed information on how to use the package, see the User manual. You can add it to your project by installing it from the list in the Package Manager window or by specifying its name com.unity.ai.navigation. Alternatively, you can add an entry with the package name directly in the project manifest. Version 2.0.0 of the package is available as of Unity 2023.2. Notice on the Change of License With effect from 8th December 2020 this package is licensed under the Unity Companion License for Unity-dependent projects. Prior to the 8th December 2020 this package was licensed under MIT and all use of the package content prior to 8th December 2020 is licensed under MIT."
  },
  "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Samples~/README.html": {
    "href": "Library/PackageCache/com.unity.ai.navigation@eb5635ad590d/Samples~/README.html",
    "title": "Navigation Samples | Inventory System",
    "summary": "Navigation Samples The Navigation Samples showcase various usages of the NavMesh. They contain eight samples: Multiple Agent Sizes: Demonstrates how a different radius on an agent type can change the way agents navigate through the same scene. Drop Plank: Demonstrates dynamically changing walkable paths by allowing the player to add walkable planks by pressing space. Free Orientation: Demonstrates a controllable agent that can walk on a tilted plane. Sliding Window Infinite: Demonstrates a controllable agent that can walk through a dynamically created world that gets updated to simulate infinity as the agent walks through it. The NavMesh is only built in some set bounds that follow the agent. Sliding Window Terrain: Demonstrates a controllable agent that can walk through a terrain for which the NavMesh is only generated within a set distance of the agent. Modify Mesh: Demonstrates agents walking aimlessly on planes whose mesh can be modified dynamically by the player. Dungeon: Demonstrates a controllable agent that can walk through a maze generated from pre-baked tiles that connect to each other at runtime. The link traversal animation can be modified with some presets (teleport, normal speed, parabola, curve). Height Mesh: Demonstrates two agents walking down stairs. The environment on the left uses NavMeshSurface with a Height Mesh which allows the agent to snap to each step in the stairs as it goes down. The environment on the right uses a NavMeshSurface with no Height Mesh; the agent simply slides down the stairs. Note that some of these samples require that the Packages/manifest.json file of your project references the following default modules: \"com.unity.modules.physics\": \"1.0.0\", \"com.unity.modules.terrain\": \"1.0.0\", \"com.unity.modules.terrainphysics\": \"1.0.0\" If the samples are being imported into a project that uses the Built-In Render Pipeline, you’ll also need to install com.unity.shadergraph. Introduction to NavMesh The Navigation package allows you to set up pathfinding AI in your Unity project. Two fundamental concepts of pathfinding are (1) agents and (2) world representation. An agent is a game entity that travels autonomously between two points in a scene. In Unity, a GameObject can be turned into a navigation agent by adding a NavMeshAgent component to it. World representation is what allows the pathfinding program of an agent to understand the traversable surfaces of a world. It is a simplification of a 3D world. In Unity, a traversable surface is represented as a mesh of polygons which we refer to as NavMesh. To convert some or all of the geometry in your scene into a surface that is traversable by an agent, you can use the NavMeshSurface component. However, you must also generate the data of the NavMeshSurface by using the Bake button in the Inspector. The process of baking is what actually creates a representation of the geometry in your scene that agents and their pathfinding program can understand. Whenever there are modifications done to the scene's geometry that can impact the navigation, the related NavMeshSurface component must be rebaked. The baking process is not done automatically because it can be a long process depending on the size and complexity of the input geometry. Note that baking cannot be done from the Inspector during Playmode. In order for an agent to move, it must know its destination. In Unity, the destination of a NavMeshAgent can be set through code with the destination property or the SetDestination() method. You can find an example of this in the ClickToMove script. For more information, refer to the AI Navigation package manual. Agent Types The following agent types are created and used by the samples: 1. Name: Humanoid for Navigation Sample Radius: 0.5 Height: 2.0 Step Height: 0.75 Max Slope: 45 2. Name: Ogre for Navigation Sample Radius: 1.0 Height: 2.0 Step Height: 0.4 Max Slope: 36"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [1.8.21] - 2025-03-19 update EmbeddedLinux argument syntax to support newer clang versions Added Added LLVM 19 Support Added stack protector AOT settings options. Removed Fixed Fixed hashing error that could occur when an assembly contained a type reference with a \"module\" resolution scope Fixed internal compiler error when using a FixedStringNBytes value in an interpolated string Fixed a crash caused by assigning null to a Span Fixed \"Unable to resolve the method\" error that occurred when two or more methods had the same name, one of the methods contained a generic parameter, and the generic parameter type had two or more generic arguments Fixed handling of stackalloced arrays with initial values for newer versions of Visual Studio When building for Android with the Mono scripting backend, arm64-v8a symbols could be incorrectly included in the output, even though Mono for Android only supports armv7. This is now fixed. Fixed compiler crash that could happen when using an interface method that had a default implementation defined in another interface Fixed cropping of tooltips in the inspector. Fixed rare \"Unhandled exception. System.InvalidCastException: Unable to cast object of type 'System.IO.MemoryStream' to type 'System.Text.StringBuilder'\" error that could occur during Burst compilation Fixed a BC1054 error that could occur if a struct with a pointer-to-generic-parameter-typed field was used as a generic argument to an interface type Fixed compiler crash when trying to use the Span<T>(T[]) or Span<T>(T[],int,int) constructors Changed EmbeddedLinux SSE4 default Known Issues With LLVM 19, Burst's alias analysis is more conservative than it needs to be which may result in performance reductions in Burst compiled code. This is will be addressed in the next Burst release. Note that at this time, Burst by default uses LLVM 18. [1.8.19] - 2025-01-17 Changed Source file checksums are now included in pdb debugging files, so that Visual Studio can warn when source files differ from when the pdb was built Added support for HashCode.Combine Fixed Fixed hash generation error for derived default interface methods Fixed resolution of local variable types in generic default interface methods Fixed crash that could occur when a target method of BurstCompiler.CompileFunctionPointer was already decorated with [MonoPInvokeCallback]. If this existing attribute existed in a namespace other than AOT, Burst's IL postprocessor would add a second [MonoPInvokeCallback], resulting in a runtime crash on IL2CPP. Fix crash when trying to Burst compile a project without any Bursted code with debug info enabled, when it has already been compiled without debug info before. Fixed BC1055: Unable to resolve the definition of the method ... errors when compiling code using in method parameters for multiple CPU targets Fixed an issue preventing debugging of managed methods that use direct call, regardless of whether Burst compilation is manually disabled Fixed a rare concurrency issue in the entry point finder. Added [Android] Support for 16Kb page sizes Removed Known Issues [1.8.18] - 2024-09-04 Added Added the UNITY_BURST_DISABLE_COMPILATION environment variable as an alternative to the --burst-disable-compilation command-line argument Removed Changed Fixed Static fields used in static constructors were sometimes incorrectly set to read only, despite being written. Fixed a case of the editor getting stuck loading during a domain reload if Burst was set to synchronous compilation Fixed hashing bug that could occur when method signatures differed only by generic parameter count Branches within if (cpufeaturesupported) blocks could cause the transform pass to miss identify which blocks are supporting which features, leading to errors at compile time about intrinsics not being in matching blocks. Fixed 'cannot open input file ucrt.lib' error when building for Universal Windows Platform and targeting SDK 10.0.26100.0 Known Issues [1.8.17] - 2024-07-22 Added Removed Changed Improved performance of Burst-compiled code in the Windows x64 Editor by only emitting context-saving code when the code being compiled contains a throw Improved error message for pointer-like types in non-readonly static fields ARM 32-bit is no longer built for Universal Windows Platform when targeting SDK 10.0.26100.0 or newer Fixed Fixed another compiler crash caused by faulty alias analysis BurstAotSettings files are no longer written to disk unless default settings are changed Fixed the BurstDebugInformation_DoNotShip folder not being saved outside the player build folder for Embedded Linux and QNX platforms Fixed direct negation of enums was not correctly promoting the underlying type, causing wrong results. Fixed that Mathf.Approximately would return the wrong result approximately all of the time Fixed an issue with default interface methods which would result in compiler errors due to IL corruption. Creating a project with a space in the path would cause burst to fail on windows arm64. Fixed 'Failed to find Windows SDK' error when targeting the latest installed Windows SDK version for Universal Windows Platform builds Known Issues [1.8.16] - 2024-05-29 Fixed Fixed compiler crash caused by faulty alias analysis [1.8.15] - 2024-05-10 Added Removed Changed Fixed An issue with auto promotion from bool to float that can occur with newer Roslyn. Fixed compilation error when trying to use MemoryMarshal.GetReference on Spans Fixed crash caused by faulty no-alias analysis Fix build error when Product Name contains illegal path characters. Improved the compilation time for projects with many assemblies/assembly-define symbols Known Issues [1.8.14] - 2024-04-04 Fixed Fixed burst sometimes throwing FileNotFoundException Fixed incorrect handling of [Conditional] attributes in some circumstances Fixed that some or all scripting symbol defines wouldn't be known by Burst in player builds Added Removed Changed [1.8.13] - 2024-02-29 Added Added clearer diagnostic error for certain bad usages of IsSupportedXXX intrinsics. Added support for Burst with the visionOS Simulator SDK. Added support for Windows Arm64. Fixed Fixed InvalidCompilerException when usage of IsSupportedXXX intrinsic results in no branches being generated. Fixed information in documentation regarding scheduling generic jobs through generic methods. Fixed a crash caused by arithmetic or bitwise negation on native integers followed by a cast to a pointer. Fixed that the burst debug information folder would sometimes be saved in project root folder. Fixed System.ArgumentNullException exception in ILPostProcessing when encountering a library using mscorlib Fixed an issue where if two modules were referencing the same external method (dllImport) an internal compiler error could occur - \"Burst internal compiler error: Burst.Compiler.IL.CompilerException: Error while verifying module: DISubprogram attached to more than one function\" Fixed \"Failed to find entry-points: ... An item with the same key has already been added\" error that could occur in the presence of precompiled (usually obfuscated) assemblies that contained methods overloaded only by return type Removed Changed Known Issues [1.8.12] - 2024-01-02 Fixed Fixed the managed fallback for bursts intrinsic functions cvt_ss2si, cvtss_si32, and cvtss_si64 to follow midpoint rounding standard of nearest even. Fixed an issue where use of certain intrinsics could cause a compile error even if properly guarded by the appropriate IsXXXSupported property. If an exception is thrown from burst compiled code in the Editor on Windows there was potential for certain callee saved registers to be corrupted. In order to fix this ( editor only - player builds are unaffected), we now save some additional context on each entry point. Fixed burst not differentiating between overloaded generic functions such as T foo(int val) and T foo(T val) when the function calls are foo(1); foo (1). Burst would previously only compile the T foo(T val) function. Fixed android builds throwing a NullReferenceException. Fixed arithmetic and bitwise negation on native integers. Fixed an issue where underflows of nint and nuint at compile time would lead to incorrect code. Burst recompiles assemblies due to hashes mismatching because of the way assembly defines are combined into the hash. Fixed constant SHUFFLE function not seen as a constant when called indirectly through a FunctionPointer Added Removed Changed Update default LLVM to version 16 Known Issues [1.8.11] - 2023-11-16 Added Burst support for Apple visionOS [1.8.10] - 2023-11-02 Fixed Fixed the Burst Inspector not displaying target methods if namespace/class contained the method name. Linking libstdc++/libc++ statically on HMI platforms Fixed an issue that caused an empty variable to be returned if it is between a zero initializer Native debug information would fail to reflect the contents of parameters to functions. For native debug information, type symbols can now be referenced using :: separator between namespaces (C++ style) - E.g. Example.Type becomes Example::Type. Fixed that changing certain player build platform settings (like SDK version) would not trigger Burst to recompile Fixed invalid burst string formats leading to internal compiler error. Fixed QNX player builds on 32-bit ARM Fixed an error thrown by the Burst Inspector when opening a non-static job with special characters in its name Fixed an issue that caused alignments for global values to be wrong, which could lead to a rare AVX2 specific crash. Added Added support for System.Math functions Acosh, Asinh, Atanh, Cbrt, CopySign, Log2, SinCos, FusedMultiplyAdd, and ILogB Removed Remove all code specific to DOTS Runtime Changed Use mimalloc as our native allocator on Windows to speed up concurrently executing LLVM work Known Issues [1.8.9] - 2023-09-22 Changed Minor behind-the-scenes changes that should not affect users. [1.8.8] - 2023-07-24 Fixed Fixed error when trying to use direct call to a nested protected class Fixed that converting a negated unsigned type to a float would produce a mismatching value in Burst versus .Net/Mono Fixed that the Burst Inspector handled negation of unsigned types differently than .Net for static readonly fields or static constructors Fixed Burst sometimes returning wrong value for static readonly fields or static constructors. Fixed a possible source of invalid alignment, avx2 storing to stack was given a slot with the wrong alignment. Fixed System.NotImplementedException: Unimplemented Instruction Extension Tail_ error when the code contained tail-calls Fixed wrong alignment for v128 when doing an indirect access. Fix compiler crash when compiling different assemblies that define methods or types with the exact same name and namespace Fixed using Armv9 target in the Burst Inspector not formatting the assembly. Fixed that jobs wouldn't be Burst compiled for player builds with high stripping Fixed burst not being able to find external function leading to crashing the Editor Prevented Burst emitting errors even when Burst was disabled via the --burst-disable-compilation command line option Under some conditions (if the error in compilation occurred in a location that didn't have valid debug information), building a player might not generate any files, and not display any errors. Fixed uint to float conversion edge-case Fixed syntax highlight missing for some ARM instructions. Added Added support for default interface methods Added ability to support hashing against different target frameworks. Added support for string interpolation in exception messages Removed Changed Fixed a compile-time performance regression in 1.8.7 that could result in slower Burst compilation and increased memory usage during compilation Direct call is now correctly disabled for methods that are decorated with both [BurstCompile] and [UnmanagedCallersOnly] attributes (such methods shouldn't be called directly from managed code) Add support for Math.Clamp (this API is available when Api Compatibility Level is set to .NET Standard 2.1) Known Issues [1.8.7] - 2023-06-07 Added Add proper license attribution for MUSL and SLEEF libraries. Removed Changed Changed focus for initial Burst Inspector focus to actually get the search hit in focus. Fixed Fix QNX builds using the qnxInstallationPath editor build setting Fixed an issue causing source file handles to be left open (preventing saving in an ide, if in debug scripting mode and the file is used in the burst path). Fixed an issue when targeting multiple cpu architectures (e.g. SSE2 & AVX2) that under some circumstances would lead to code attempting to execute paths not designed for that cpu. Fixed an issue that caused builds to fail due to the System.Diagnostics.Tracing assembly not being found Fixed a warning that occurred when opening Burst AOT Settings while in Play Mode Fixed a hashing error that could occur when an operator overload method is used as a Burst entry point Fixed crash on linux if debug logging was enabled. Fixed \"The specified path is not of a legal form (empty)\" error Calls to methods with multiple [Conditional] attributes are now kept if any one of the conditions are met Fixed Burst implementation of IntPtr.GetHashCode() being different than .Net Fixed an issue that caused the digits and MidpointRounding parameters of Math.Round be ignored Known Issues [1.8.4] - 2023-03-20 Fixed Fixed possible deadlock when compiling after domain reload Fixed incorrect codegen when having multiple try-finally blocks inside another try-finally block (for example from foreach loops) Domain completed stall when switching between debug/release scripting modes when burst compilation is needed for items in the new domain. Fixed \"An item with the same key has already been added\" compiler error that could occur when duplicate field names were present in obfuscated assemblies Fixed \"Failed to find entry-points: Mono.Cecil.AssemblyResolutionException: Failed to resolve assembly\" error that was displayed when Burst tried to compile an assembly that had C# compilation errors Fixed code-gen issue where side-effects before a conditional throw would be ignored Burst managed breakpoints might fail to work, after a domain reload. Fixed that some changes made to versioned assemblies wouldn't get picked up and compiled by Burst Fixed line highlight and register highlight not clearing when Burst Inspector settings change. Fixed Burst compilation error relating to UnityEngine.Assertions.Assert.Fail when doing player builds with high stripping settings Fixed a BadImageFormatException error that could occur in some player builds Neon intrinsics: fixed default target CPU for Arm Mac Standalone builds Fixed MethodDecoderException when trying to call CompileFunctionPointer on a nested static method Fixed incorrect pdb path for AoT dll libraries Fixed inaccurate stacktraces when throwing an exception from Burst in specific cases Fixed \"An item with the same key has already been added\" hashing error that could occur if obfuscators changed nested type names to have the same name and different namespaces Added Add support for ChromeOS in Unity versions 2020.3 and 2019.4. Windows/ARM64 targeting support Removed Changed Changed Burst Inspector input handling so that arrow-keys can be used to select in search boxes. Made Burst Inspector's target job load asynchronous. Known Issues [1.8.3] - 2023-01-30 Added Added selection of line and highlight of selected line and selected lines register usage. FunctionPointer ()::Invoke usage is now checked and patched to ensure the calling convention is compatible with burst. Added SIMD smell test to the Burst Inspector, highlighting ARM or x86-64 SIMD instruction differently depending on whether they work for packed or scalar inputs. Added a toggle for filtering out \".Generated\" jobs from the Burst Inspector target job list. Added a Burst AOT setting for the kind of debug information generated for player builds Fixed Fixed AoT linking error on Windows Link based linkers when file paths (typically user names/home folders) contain non-ASCII characters. Fixed ARM vector registers not being highlighted. Fixed Burst Inspector sometimes throwing ArugmentOutOfRangeException when copying without color-tags from assembly that is colored. Fixes error when calling direct call method from background thread without having previously called a BurstCompiler API from the main thread Fixes \"Plain Without Debug Information\" outputting assembly with debug information. Fixed a hashing error that could occur when a struct implements a generic interface multiple times with different generic parameters An issue that could cause function pointers to point to the wrong burst function, if a domain reload occurs and a compilation started before the reload, completes soon after. Fixed bug in a small set of managed fallback versions of intrinsics, where the bitwise representation of float values would not be maintained Fixed player build error that could occur if the project contains an assembly whose name doesn't match the assembly filename Crashes on 32bit cpus when an entry point with byvalue paramaters was called, when using dispatch (multiple supported cpu targets). Fixed module verification errors when using overloaded functions as function pointers Fixed an issue the definition order of overloaded methods with function pointer parameters would decide which overload was actually being used Fixed compiler AccessViolationException that could occur when compiling two or more types with the same name but different source assemblies Burst now updates its list of assembly paths if they change, for instance - adding packages that contain precompiled assemblies. Fixed a stall that could occur at Editor shutdown Fixed BC1361 error when trying to compile large static readonly arrays. Fixed compilation error when using CompileFunctionPointer from Burst in code compiled with Roslyn on .NET 7+ Fixed a BadImageFormatException error that could occur in DOTS Runtime builds Fixed the inspector job tree view splitting jobs, with '.' in their parameters. Fixed internal compiler error when implcitly converting an array to a Span Fixed managed fallback implementation of Sse4_2.cmpestrs \"LLVM IR Optimisation Diagnostics\" tab in Burst Inspector was blank if \"Native Debug Mode Compilation\" was enabled; this is now fixed Fixed burst tree view items leading to wrong job if some jobs where hidden from view by filter or similar. Fixed \"Callee/caller attribute ABI did not match!\" error that could occur in certain player builds when calling an entry point that had at least one struct-by-value parameter Fixed namespace collision that could occur between Unity.Burst.Cecil.dll and the com.unity.nuget.mono-cecil package Enum values cast to integers in a format string previously output the enum type name; now the integer value is correctly output Fix Burst compilation on QNX Arm Fixed visual artifact in Burst Inspector, where block of enhanced code was cut at the bottom. Fixed compiler crash when invoking FunctionPointers based on a generic delegate in DOTS Runtime Fixed internal compiler error that occurred when creating debug metadata from certain obfuscated dlls Fixed \"Assertion failed on expression: \"exception == SCRIPTING_NULL\" errors and editor crash when the project path contained multi-byte Unicode characters Changed Changed burst inspector source location comments from \"===\" to either \";\" or \"#\" depending on the given assembly kind. Changed horizontal code focus in the Burst Inspector to only scroll when branches fill more than half the space Changes so target job list in the Burst Inspector is a fold-able/expandable tree view, instead of a simple list. Improved how optimisation remarks are displayed in the \"LLVM IR Optimisation Diagnostics\" tab in Burst Inspector to make them more useful Burst now only generates full debug information when \"Native Debug Mode Compilation\" and script debug information is enabled Removed Known Issues [1.8.2] - 2022-11-18 Added Changed Fixed Fixed an issue where sometimes the wrong body of an overloaded entrypoint would be used Failing to link if ; in path Fixed Burst being disabled in the Editor after changing script optimization mode (i.e. from Release to Debug or vica-versa) C# Debug information was incorrectly ignored for methods that had multiple source files. This caused native debug information to be dropped for code generated methods, and prevented the disabling of burst for such methods when a managed break point was set in Unity 2022.2 or greater (see https://docs.unity3d.com/Packages/com.unity.burst@1.8/manual/debugging-profiling-tools.html). Pointer addition of byte would incorrectly sign extend the byte, instead of zero extend. lib_burst_generated.txt was not being output. Player stripping levels higher than minimal would fail to build with burst if they used String.Formatters, String Copy, or BurstDiscard. Fixed error when building player caused by calling an entrypoint method from within other Burst-compiled code iOS/tvOS burst libraries are now using explicit min os version, as configured in player settings. Fixed Burst AOT setting \"Enable Optimizations\" not being applied in player builds Fixed player builds not being recompiled when changing only Burst AOT settings (and changing nothing else) in Unity 2022.2+ Error caused by the MonoDebuggerHandling.dll requiring VCRuntime to be installed. Removed Known Issues [1.8.1] - 2022-10-12 Added Added a custom lld wrapper, to save package space in transit and on disk. Added hover box information for assembly instructions. Changed Upgraded Burst to use LLVM Version 14.0.6 by default, bringing the latest optimization improvements from the LLVM project. Ensured our executables and libraries on macOS and Linux are stripped to reduce package size. Changed how we handle domain reloads within Burst to avoid paying a 250ms cost on each domain reload when using Burst. With the relaxation in Unity 2022.2 or newer that we can call CompileFunctionPointer from a background thread, we now use this mechanism in Burst to handle Direct Call methods, resulting in a cost saving during Domain Reload. Added a categorized index of Neon intrinsics supported in Burst to the Manual Changed the documentation so that it is super clear that exceptions in player builds cause the application to abort. Fixed Fixed a compiler crash that could occur with code that followed the pattern Debug.Log($\"{variable}\") Compiling with line only debug information could cause a compiler crash on certain platforms PDB path associated with windows player dll had the wrong filename, resulting in broken symbols. Fixed documentation issues with Neon intrinsics where the comparison operation would not match the actual one Fixed bug that could occur when swapping large structs by value Fixed \"Unable to resolve type T. Reason: Unknown.\" error when accessing a field of a struct referenced via a pointer behind a reference. Fixed some arm64 instructions not being labelled as instructions. If burst is disabled, and an assembly is changed, burst won't recompile that assembly once burst is re-enabled. Removed Known Issues [1.8.0] - 2022-09-13 Added Added experimental atomic and/or operations to Burst. Changed math.fmod in combination with a Burst job compiled with FloatPrecision.Low will now generate a more optimized low-precision version of the function. Burst now respects the checkbox \"Enable Armv9 Security Features for Arm64\" in the Player settings, making Android builds generate PAC/BTI instructions if enabled. In Burst AOT Settings, only the relevant CPU Architectures dropdowns for the current build target and architecture are now displayed The callstack of the invalid external call is now included when reporting BC1091 Changed so code is focused when branch arrows are present. Changed so Burst reported errors are not collapsible. Removed Fixed An Internal Compiler Error that could occur if a function that requires a struct ret (due to ABI) has been discarded by other logic. Fixed a bug with locally declared array variables in functions where storing null into them could cause invalid codegen. Fixed a bug in Burst player builds where sufficiently complicated Bursted code could cause a deadlock deep within LLVM. Fixed that UWP builds wouldn't respect the specified \"Target SDK Version\" and \"Visual Studio Version\" settings Fixed Burst inspector sometimes freezing when selecting between blocks. Fixed the Burst Inspector sometimes becoming unresponsive when selecting text. Fixed a race condition with the Burst log timings such that previously reported results could be included in subsequently reported timings. Fixed the managed fallbacks for bzhi and bextr to match what the native hardware instructions do. Fixed a bug in the static readonly constant expression evaluation (what we call the IL interpreter) whereby it would not truncate unsigned integers correctly. Fixed that compilation would have full debug info forced on Fixed incorrect code-gen when a function is both used normally and as a function-pointer Known Issues The PDB path associated with the Windows Player dll is incorrect, resulting in broken symbols. [1.8.0-pre.2] - 2022-08-03 Fixed Fixed hashing bug that could occur when a function pointer type is used in a method parameter Fix selection and copying of folded blocks Fixed hashing error that could occur in the presence of multiple synthesized explicit interface implementations with the same name and signature Fixed a compiler crash if users used __refvalue or __arglist in Burst. Neither of these are supported, but now we will nicely tell you via a compiler error that they aren't supported. Fixed a compiler error when trying to acquire the function pointer of a generic function from Bursted code. Fix some ARM branch instructions not being processed as such. Using a function only through a C# function pointer could cause a crash Whitespace changes in ILPP'd assemblies would not be detected. Issue where a warning could be generated about the debug information version mismatching warning: ignoring debug info with an invalid version (0) during link. Interface methods where not being hashed correctly for constrained types, which would result in burst failing to recompile code that had changed in an implementation class. Fixed a safety check bug with Span/ReadOnlySpan and Slice(start, length) where if start + length was equal to the Length of the original span, the safety check would incorrectly report an out-of-bounds access. Linking issue when exports differ only by module. Disabling Burst from the command line via --burst-disable-compilation no longer results in Burst errors when building a player for Android Corrupted binary could be produced on M1 if there was not enough space for UUID+codesign injection. ;'s in paths would cause burst to fail. Note - Also requires a fix in the Editor, so if your project has ;'s in its path, the workaround is to remove the ; from the folder name for now. Fixed error when compiling assemblies with spaces in their names Fixed access violation race condition bug Fixed a bug where static fields in generic types could in some situations be initialized with the incorrect value Fixed last line in Burst Inspector not being select-able using the mouse cursor. Fix error that occurs with a specific formulation of IL, using xx with an early out escape and unbalanced calculation stack. (Object reference not set to an instance of ... in CollectBlock.ToVisitOrder) Changed Changed burst inspector toggles to popup menus. Removed label from burst inspector popup menu into the menu itself. Used explicit namespace for UnityEditor.PackageManager.Events to avoid conflicts. Improved \"hashing\" performance. This is the part of Burst that determines whether anything significant has changed in .NET assemblies, and therefore whether that assembly to be compiled. Entry point function names weren't always included in crash callstacks; now they are Search pattern from previous job is not carried over to the new. Changed so block of 1 line cannot be folded in the Burst Inspector Added Setting a breakpoint in an attached managed debugger (Rider/VS Unity Debugger...) on a method that is burst compiled, will switch off the burst code path for that method, allowing it to be debugged as normal. Added toggle to filter Unity tests on and off. Assembly is now searchable either through CTRL + f or the contex menu associated with the inspector view. Search options include case sensitivity, whole word match, and regex. Intrinsic support for UnsafeUtility.IsNativeContainerType Added an actual definition for HPC# in the package docs. Check that calling convention is correctly set to Cdecl for functions whose addresses are taken via ldftn. Added focus on current job in the burst inspector. Added copy to burst inspector, which ignores underlying color tags. Removed Known Issues [1.8.0-pre.1] - 2022-05-06 Changed Always preserve frame pointers in Burst. This results in a neglible performance hit (less than 0.5% in benchmarks), but ensures that stack recovery for stack traces is always possible. Class libraries are now built with netstandard 2.0 The minimum Xcode version to build for iOS, iPadOS, and tvOS with Burst is now 12.0.0. Upgraded Burst to use LLVM Version 13.0.1 by default, bringing the latest optimization improvements from the LLVM project. Fixed \"error while hashing\" message that could appear during compilation Made Burst explicitly check for any compilation requests that came from AssemblyBuilder, and do not compile these with Burst. These exist outside the normal compilation pipeline, and Burst could not support them (but we now explicitly check for that case). Made Burst's ILPP 22% faster by caching dependent assemblies that the being-processed assembly uses. Changed how we process static readonly fields in static constructors such that we'll allow more computational budget per static field. This fixes the case where having too many static readonly variables in a single static constructor could fail to compile, while they would work if each was in their own static constructors. Collapsed block of code in burst inspector now shows the blocks first line of code. Upgraded Burst to use LLVM Version 14.0.0 by default, bringing the latest optimization improvements from the LLVM project. Changed the default alignment for SharedStatic's from 4 to 16. Added Branches now highlights when you hover them. Branches are clickable; directing the view to the other end of the branch when clicked. Added support for the System.Runtime.CompilerServices.IsExternalInit workaround documented here into Burst when used in 2022.1+. Enabled keyboard navigation in the right pane of the burst inspector. Added version number to debug metadata for llvm Experimental support for Armv9 SVE2 CPU target for Android Added a Target Arm64 CPU setting in Burst AOT Settings for Android Removed Removed the requirement that BurstLoader has to initialize BurstReflection during a domain reload, making BurstLoader setup 2x faster during domain reloads. Fixed Error if install in build folder is used without ever using a regular build. Fixed a performance regression with IJobParallelFor where vectorization didn't happen for cases where it previously would have. Fixed a compiler miscompile if you loaded a static readonly v128 and passed it straight to a function as an argument. Removed implicit dependencies to pre-compile binaries in CodeGen which would otherwise cause assembly resolution conflicts. Fixed a Unity 2021.2 and newer bug that manifested with UWP builds - we were using the wrong unityaot folder in the Unity editor distribution with Burst. Fixed a really subtle caching bug in the compiler where if you had a job that compiled successfully at least once, then it failed (you used managed state for instance), then you closed the editor and restarted, if the compiler threads started in precisely a strange combination then Burst might accidentally never recompile the job which failed previously. Fixed potential hang in Editor when compiling a Burst entry point method that is defined in a generic class Fix for the X.pdb: The process cannot access the file because it is being used by another process issue our users were seeing. We were taking a FileShare.Read lock, when we needed to take FileShare.ReadWrite. Fixed a bug where the compiler would reject a try/finally statement if it was the first thing in a method Fixed a performance regression affecting some vectorization in Burst 1.7+ (LLVM 12+). Inspector performance regression. Improved UWP linker error message to clarify which VS components need to be installed for UWP Fixed a bug that meant Burst was accidentally enabled in secondary Unity processes, including the asset import worker and out-of-process profiler (see changelog entry for 1.6.0-pre.1 for more context around this) Keybindings for copy and selection did not depend on OS. Right pane vertical scrollbar not always showing correctly. Inspector font style changing when entering and exiting play mode. Fixed access violation error that could occur when reading from a static readonly variable Made --burst-force-sync-compilation command-line option actually work Fixed a bug that was exposed by a Script Updater running against the Entities tests, whereby if some sort of pre-domain-reload code (some sort of teardown like thing) called into Burst, the script updater could have caused Burst to purge valid function pointers, resulting in us trying to execute a DLL location that we had already unloaded. Fixed a super rare bug whereby if you kicked off two compilations very close together (most likely when running Unity in some sort of headless build-a-player mode), Burst could throw an exception on a burst hash cache file being locked by the process. Fix a bug where if you had a long running compilation and a new compilation came in, some threads in the thread pool could (if unlucky) block trying to dirty the assembly in our Burst caching infrastructure while waiting for the compilation to complete. Fix a bug where codegen differences could occur when using a local vector variable that was being captured by reference and passed to a called function, versus when it wasn't. Fixed an exception that could occur if you had the Burst AOT Settings menu docked in the Editor, and then did a player build. Trying to change any of the Burst AOT Settings would throw an exception (unless you closed and reopened the Burst AOT Settings). Fixed a bug where we could leave background tasks around forever when we had actually completed them (could only happen if two re-compilation requests arrived close together, meaning we'd cancel the first but never report to the background tasks that we had cancelled them!). Fix the Burst link.xml output to preserve C# methods we rely on, alongside the static constructors that we preserved previously. Fixed errors when working with paths containing special characters Fixed a bug where if you used FloatMode.Fast with math.pow, where the y argument to math.pow was actually sourced from an integer, illegal codegen would be generated (LLVM would try and call out to powf from the cstdlib). Worked around an ordering issue with post-processing in 2020.3 and earlier by deferring the early compilation of script assemblies in the editor until the entire pipeline has completed. Fixed a bug in 2022.1+ where calling Debug.Log in a static constructor would result in a Burst failure. Fixed another rare case of the file-is-locked bug where the Burst IL Post Processor could incorrectly hold a file lock on a pdb. Fixed a bug when calling profiling CreateMarker on iOS, Burst could fail at runtime saying it was unable to find CreateMarker__Unmanaged. Fixed that the crc32_u64 second parameter should have been a ulong. Added a new ulong variant and marked the old long variant as [Obsolete]. Fixed a bug where using ReinterpretStore(someIndex, (ushort)someValue) could cause an internal compiler error in Burst. Fixed a potential deadlock whereby if Burst was compiling in the background (the background tasks window showed Burst in it) and a user switched from release to debug in the editor, Burst could cause a deadlock. A potential issue with the debug info mover pass, that meant it only affected the first entry point in a module Fixed hashing error that could occur with unbound generic type Fixed a bug where if you had synchronous compilation on a job, disabled Burst compilation and entered playmode, then exited playmode, and finally re-enabled Burst compilation, a hang could occur. Fixed a bug where toggling Burst enable <-> disable during a playmode execution using Burst, and then attaching the managed debugger, could cause an editor crash. Fixed a memory leak where during hashing we'd pin a GC object and never unpin and free it. Fix burst inspector sometimes stalling during loading for script reloads. Fixed a super rare bug where Burst could hit an internal error with System.InvalidOperationException: Nullable object must have a value. Fixed a regression where out parameters of C# 9.0 function pointers weren't working in Burst. Fixed internal compiler error when encountering a calli with closed generics Fixed bug in static constructor ordering in the presence of indirect dependencies between static constructors (i.e. static constructor -> static method -> static constructor) that could result in a runtime crash Added workaround for \"cannot dlopen until fork() handlers have completed\" issue seen in macOS 12.3 Fixed compiler crash when trying to dynamically call BurstCompiler.CompileFunctionPointer in Burst-compiled code Fix compiler crash when the only usage of a static field was in a formatted exception string Fixed burst inspector sometimes not rendering text or rendering text on top of other text. Fixed selection rendering off-by-one error at last line of each block. Fixed a bug with Span and ReadOnlySpan types where if the indices used were not already 32-bit signed integers, an internal compiler error would occur if running with safety checks enabled. Fixed a really convoluted bug that could manifest in Burst returning out of date cached libraries, which would manifest as random exceptions in Burst jobs/function-pointers (users deleting the BurstCache would workaround the bug). Known Issues [1.7.0-pre.2] - 2021-12-06 Changed Improved the compiler performance when doing large struct copies by detecting more cases where a load/store can be safely converted to a move-memory operation. Used BuildReport::summary::subtarget to detect headless (server) player builds on 2022.1+. Don't move pdbs out of build folder for UWP builds. Changed how we display the timings when a user has the Show Timings option enabled in the Burst menu, by cleaning up and presenting the information in a (hopefully!) clearer way. Fixed Fixed constant folding when using Hint.Likely or Hint.Unlikely intrinsics - the compiler is now able to fold these calls away entirely if the input value is constant. Fixed an internal compiler error when casting a void* to a pointer-to-vector and then access the element. One Definition Rule optimisation would break if multiple modules shared static constructors due to an issue with sharing code but not data. Fixed type initialization error, and invalid log messages about needing to add [MonoPInvokeCallback] to be compatible with IL2CPP, that could occur in a player build with Burst disabled ILPP issue for dots runtime whereby a calli patch could generate bad IL if the first instruction replaced was the target of a branch. Fixed a bug where fixed used in conjunction with Span or ReadOnlySpan would cause a compiler error. Fixed a codegen issue with Unity 2021.2 and System.Buffer.MemoryCopy. Fixed compiler crash when trying to load a generic static field Fixed \"UnityException: CompileAsyncDelegateMethod can only be called from the main thread.\" error that was logged in standalone players when the first invocation of a direct-call method was from a background thread Fix the very rare bug whereby the Burst Hash Cache files (*.bhc) will sometimes cause an exception in the editor log. Fixed the documentation to note that the System.Runtime.CompilerServices attributes [CallerLineNumber], [CallerMemberName], and [CallerFilePath] work with Burst, with the restriction that you cannot format the [CallerMemberName], and [CallerFilePath] strings yet. Fixed an issue where with optimizations disabled, using half conversions on platforms that did not natively support half could cause linker errors. Fix error when trying to Direct Call a method belonging to a private nested type Fixed some memory leaks between the C# and C++ parts of the Burst compiler, and added some CI tooling to ensure this doesn't happen again. Fixed a bug where our [BurstCompile] job finding code would not find methods in generic base classes in places where we knew the concrete-generic type (for instance struct Foo<T> { [BurstCompile] struct MyJob : IJob { void Execute() {} } }, struct Bar<T> : Foo<T> {}, and struct Haz : Bar<int> {} - we wouldn't find the concrete Foo<int>::MyJob in Burst). Fixed editor crash when trying to debug a DirectCalled method Fixed a bug whereby complicated try/finally nesting could trip up the compiler. Fixed a bug in the fixed string processing whereby we'd miscompile a fixed string that was within a struct inside a SharedStatic (depending on how it was used). Fixed a bug in the entry-point finding code whereby we wouldn't correctly resolve a nested generic struct's job if it was within a concrete generic class that was outwith the root assembly set. Added Ability to partially select and copy text in the burst inspector. Right clicking the inspector view reveals a context menu, allowing selecting all text and copying selection. Removed The button \"Copy to Clipboard\". Removed Newtonsoft.Json as a dependency Known Issues [1.7.0-pre.1] - 2021-10-21 Fixed Fixed an issue where dsym folders would be not be copied across to the DoNotShip folder when building a multi architecture build for mac os. Fixed bug that could lead to \"Failed to resolve method with name hash X and signature hash Y\" compiler error Fixed compiler error that occurred when calling BurstCompiler.CompileFunctionPointer with a delegate type that was decorated with a custom attribute Linking would fail on non-Windows platforms if the project folder contained a single-quote Fixed the \"could not find path tempburstlibs\" error message popping up when building for Android and Burst is disabled Fixed bug that could lead to incorrect compiler errors for calls to GetHashCode from a generic type Incorrect conversions between signed and unsigned vector types Detects if the simulator is the target of a player build for iOS/tvOS and disables burst, as at present this configuration is not supported by burst. [SkipLocalsInit] now correctly doesn't zero-initialize variables in a function (previously it only avoided zero-initialization of stackalloc created variables). Fixed a bug whereby sometimes some LLVM intrinsics could be incorrectly marked as unused causing invalid codegen with calls to math.acos. The cache for pdbs was becoming stale. This caused issues with wrong source information being shown in the inspector, and potentially wrong debug information being generated for bursted code in editor sessions. Missing output messages from some tools when a failure occurred. Fixed a bug with sqrt_ps for 128-bit types where it would crash the compiler. ArgumentOutOfRangeException due to _renderBlockStart and _renderBlockEnd not being probably initialized when all blocks were above the scroll position. Arrows were rendered even though they were not within the current view. Made it save the actual line numbers for code blocks in _blockLine even when the block is below the view. Removed the starting newline character when copying, and when rendering plain assembly kind. Fixed a bug where a player build that had multiple assemblies that had structs declared with the same name and same contents but different [BurstCompile] methods in them, would wrongly only pick a single struct to Burst-compile. Crash in burst module initialization if multiple modules are compiled and then linked in a different order. Fixed our platform documentation to accurately reflect the current supported platforms with Burst. Inspector menu buttons were seen as available, even though they were not supported, when viewing i.e. .NET IL code. Burst will now handle projects special characters in their project-name Static constructor sorting didn't account for dependencies within calls' IL Static constructor cyclic checks also included method calls when this is not necessary and fails on burst runtime logging code Fixed the bug @tertle found when loading a vector from a struct pointer that is marked as in. Fixed that implicitly casting a scalar half to a vector type would cause the compiler to crash Fixed a crash that could occur when loading legacy Burst AOT settings and then entering play mode Stack overflow caused by placement of alloca under certain function transforms. linker errors on macOS due to long command lines, swapped to using filelists for inputs. Fixed issue that could cause bcl.exe to fail with an exit code of 1 but not output any compilation errors Added Added support for DOTS Runtime running / loading .Net Core assemblies. Added support for System.Span<T> and System.ReadOnlySpan<T> within Bursted code. These types are not allowed as entry-point arguments. Folding/collapsing code in inspector Branch arrows (can be switched off) Automatically collapses less important blocks of disasssembly (focuses on code). Burst now generates a link.xml automatically to avoid issues with stripping causing missing symbols at runtime from static constructor usage. Removed Removed the Use Platform SDK Linker option from Burst AOT Settings for desktop platforms. Removed the player build BC1370 exception warnings as users only found them annoying. Changed Made the cost of initializing Direct Call methods for execution 33x faster during domain reload. Upgraded Burst to use LLVM Version 12.0.0 by default, bringing the latest optimization improvements from the LLVM project. Change the optimization pipeline to run the loop unroller exclusively after the loop vectorizer. This improves codegen in a lot of cases (mostly because the SLP vectorizer is unable to vectorize all the code that the loop unroller could have). Intrinsics: Neon vst1 APIs are now fully supported Made fmod and floating-point modulus use a faster algorithm to improve performance. Made the SharedStatic initialization cost during static constructor initialization time 13.3x faster. Improved iteration time by triggering Burst compilation immediately after .NET assemblies have been compiled Upgraded the minimum supported PS4 SDK to 8.00. Updated the minimum Xcode required for Burst to compile for the Apple iOS/tvOS plaforms to 12.0. Burst now waits for all threads to complete on shutdown, rather than performing a thread abort, as that could lead to a race condition with Dispose. Known Issues Burst does not work correctly when a project has a semi-colon in its name [1.6.0-pre.3] - 2021-07-27 Fixed Fixed a bug where methods with the same name and namespace, but in different assemblies, could resolve to the wrong method. Burst no longer logs a warning when opening the standalone Profiler Fixed an UnauthorizedAccessException that could occur when using Burst in players built for the macOS App Sandbox Fixed a bug that could cause an incorrect compilation error when using a primitive type as a generic argument in a static method entry point Crash due to member function debug information on tvOS. Fix documentation to make clear that ref / out parameters are supported on [BurstDiscard] methods. Fixed a NullReferenceException in the Burst compiler when multi-dimensional arrays were used. The compiler now produces a correct error message telling users that multi-dimensional arrays are not supported by Burst. Fixed DOTS Runtime Job Marshalling behaviour to properly handle marshalling generic Job types when not all closed forms of the generic type require marshalling. Fixed a Burst package warning in our editor compiler integration with respect to BuildOptions.EnableHeadlessMode. Fixed small race which could cause an unexpected exception when finishing a standalone compilation task. Building for Apple Silicon architecture on macOS would produce a universal binary, now it behaves correctly. tvOS/iOS and other statically linked platforms would fail to burst compile if the burst compiled code contained references to functions that were [DllImport(\"__Internal\")], due to a mismatch in calling convention. Fixed a bug whereby if you had $\"{too} {many} {fixed} {string} {formatted} {arguments}\" in a string formatter, Burst wouldn't be able to correctly understand how to transform this for the purposes of logging or fixed-string construction. Fixed where Unity.Burst.CompilerServices.Constant.IsConstantExpression is evaluated to be later in the compilation pipeline, to let it catch more constant expressions (for instance post-inlining). Rare non zero return code from bcl after successfully building.. Only check assembly cache when the main-thread is requesting some Burst code - meaning that kicking off eager compilation is 1.6x faster than before. stackalloc byte[] with an array initializer was previously only supported when the stackalloc size was 8 or less. Sizes greater than 8 are now supported. Fixed an error that could occur with the form \"System.InvalidOperationException: Could not find burst.initialize function in library 'SomeLibrary'\" Fixed incorrect runtime behavior that could occur when casting a pointer to a generic type Fixed a bug where stackalloc's could be wrongly hoisted out of loops. Added [Preserve] attribute to prevent stripping a compiler service call Fixed incorrect compiler error that could occur when casting a pointer to a generic type and then calling a method with generic parameters Fixed incorrect compiler error that could occur with explicit-layout structs when setting a Size smaller than the natural struct size Added Universal (Apple Silicon + X64) versions of extra build tools Add Android x86_64 and re-enable x86 support Added support for having [MarshalAs(UnmanagedType.U1)] or [MarshalAs(UnmanagedType.I1)] on a bool external function parameter. Neon intrinsics: Added vst1* experimental APIs Added a global player build setting to let users specify the default optimization choice for Burst. Native support for Apple Silicon. Added support for StructLayoutAttribute.Pack Additional notes about BurstCompiler.CompileFunctionPointer<T> regarding; avoid wrapping in another open generic method, and interoperability with IL2CPP. Removed Removed the Enable Safety Checks option for player builds, since it didn't actually enable safety checks in containers, which are editor only in Unity. Changed Changed how we link object files for iOS and tvOS platforms such that Burst will now create the object file and hand it off to XCode for linking only. Assembly-level attributes (such as [assembly: RegisterGenericJobType]) are now scanned for generic job types to compile Fixed a regression that caused eager-compilation at Editor startup to be slower than it should have been math.f16tof32 now uses hardware intrinsics where available (AVX2 / NEON). half to float or double vector conversions now produce more optimal codegen. Burst Inspector now remembers scroll position between domain reloads Changed how we schedule Burst eager compilation threads. Previously we'd spawn at most 8 of the threads, and only allow 2 to make progress while in the Editor (to ensure the editor UX/UI was as responsive as possible). Instead we now spawn number_of_cores - 1 threads at a lower thread priority, ensuring that any computing power slack can be consumed to speed up Burst compilation. On a 24 core machine this resulted in 2.5x reduction in time taken for Burst to fully compile a large project. Fixed a potential error related to duplicate symbols when calling BurstCompiler.CompileFunctionPointer from inside Burst code Improved performance of checking the cache to see if methods have already been compiled For player builds : lib_burst_generated.txt, pdbs (in non development mode) and dysm folders are now placed into a xxx_BurstDebugInformation_DoNotShip folder alongside the data folder, this is to ensure it is easy to remove the files that you should not ship with your player. Known Issues Code that previously mixed managed or non-readonly static fields with Burst compiled code will now fail to compile. [1.6.0-pre.2] - 2021-04-15 Fixed Fixed obsolete API in package code. [1.6.0-pre.1] - 2021-04-14 Changed Start 1.6 release cycle Changed how we resolve function references in the compiler to improve resolving an existing function reference by 3x. Improve how we handle generic resolution in Cecil to cache the strictly resolved generic types and save a bunch of time in the compiler. Exception strings no longer contain the entry-point name of the job/function-pointer that caused the throw. This change was required because the Burst compiler has to produce deterministic results from any given compile, which is fundamentally opposed to per-entry-point function derivations. Changed how SLEEF global variables for trig functions are pulled into Burst to reduce duplications. Changed how exceptions throw types and messages are stored in our Burst binaries to reduce binary size. Constant array data is now named after the static field it belongs to in assembly Upgraded Burst to use LLVM Version 11.0.1 by default, bringing the latest optimization improvements from the LLVM project. The Unity.Burst.Intrinsics.Common.Pause intrinsic is no longer experimental. DOTS Runtime shares the logging code path with the general case Armv8.2 Neon intrinsics are now fully supported Disable threading within the lld linker instances we use for in-editor and desktop cross compilation, because we're already threading seperate process instances of lld and it results in lot of OS context switching. Tweaked how the IL Post Processed 'direct call' Burst function pointers are compiled so that the compilation is deferred until they are needed (previously we'd enqueue them all for compilation on a domain reload). Changed Burst minimum editor version to 2019.4 Use rpmalloc as our native allocator on Windows to speed up concurrently executing LLVM work. When Burst has previously compiled a method, and neither the assembly containing that method nor any of that assembly's dependencies have changed, it was possible after a domain reload for the Mono version of the method to be used for a short time before being replaced by the Burst version. This has now been improved such that the Burst version will be used immediately. Improved iteration speed by reducing the time it takes for Burst to check if any Burst-compilable code has changed Change our link step to not use response files if the command line was smaller enough, saving the cost of the round-trip to the disk. Made half <-> float / double conversions use native hardware where possible (Arm or AVX2 targets). In order to prevent conflicts with the main Unity process, Burst is now inactive in secondary Unity processes, including the asset import worker and out-of-process profiler. This means that in those secondary processes, code that would normally be Burst-compiled will now run under Mono. In a future release of Burst, we hope to lift this restriction and allow Burst-compiled code to run in secondary Unity processes. Fixed Fixed a bug in LLVM that it would incorrectly convert some memset -> memcpy if both pointers derived from the same memory address, and where one indexed into the 0th element of the pointer. Fixed namespace issue triggering a warning in the editor. Made math.shuffle compile correctly when non-constant ShuffleComponent's are used. Fixed alignment issues associated with xxHash3 on ArmV7 (case 1288992) Fixed managed implementation of sub_ss intrinsic Fixed a bug that occurred when an explicitly laid out struct was used by a dup instruction, which caused an internal compiler error. Fixes DOTS Runtime JobProducer Bursting code to support JobProducers with multiple generic arguments, complex job wrapper and generic jobs. Fixed a bug where if a user had defined multiple implicit or explicit casts, the compiler could resolve to the wrong cast. Fixed a bug where explicitly casting from an int to IntPtr would not sign extend the value. String interpolation issues when using Dots / Tiny runtime. Fixed managed implementations of blend_epi32 and mm256_blend_epi32 intrinsics on Mono Fixed a bug where loading from a vector within a struct, that was got from a NativeArray using an indexer, would cause the compiler to crash. Fixed an issue where Burst would erroneously error on BurstCompile.CompileFunctionPointer calls when building for the DOTS Runtime. clang segmentation fault on iOS when member function debug information was emitted, it is disabled for this platform now. Intrinsics: Neon - fixed vget_low and vget_high producing suboptimal code Private [BurstCompile] methods no longer throw MethodAccessException Fixed a bug where the Burst post-processing for direct call would cause duplicate function pointers to be compiled, wasting compile time in the editor and caused an Editor launch stall. Corrected 'Enable safety checks tooltip`. Fixed a minor debug information bug where built-in types with methods (like System.Int32) would generate incorrect debug information. Fixed a very obscure bug where if you had a function-pointer that was called from another function-pointer of job, and that function-pointer happened to be compiled in a player build in the same bucket as the caller, and the no-alias cloning analysis identified that it could clone the original function-pointer to enable more aliasing optimizations, it could create a duplicate symbol error. Revert to internal linkage for Android X86 (32bit) to ensure ABI compliance. Fixed compilation errors when targeting Arm CPUs and using some of the Intel intrinsics Added PreserveAttribute to prevent the internal log from being stripped in il2cpp builds. IL Function Pointer Invoke Transformation updated to handle transforms that affect instructions that are the destination of a branch. IL Function Pointer Invoke Transformation now uses correct runtime library for dots runtime. Fixed compilation errors when targeting Intel CPUs and using some of the Arm Neon intrinsics Fixed a bug where eager-compilation could pick up out-of-date global Burst menu options for compiling. Fixed a bug where the progress bar would report double the amount of pending compile jobs if a user changed the Burst options while background compilation was going on. Fixed some intrinsics not checking target CPU against required CPU, so it was possible to use some intrinsics without an IsXXXSupported check Fixed a bug where having any [DllImport] in a class that used the Direct Call mechanism could result in an illegal CompileFunctionPointer call being produced by our post processor. Fixed an issue where if a user used a math function (like cos, sin, etc) then LLVM would preserve both the scalar and vector implementations even if they were trivially dead, causing us to inject otherwise dead functions into the resulting binary. PDB debug information for instance methods that also used struct return were incorrect. When generating Line Table only debug information, an unreachable could occur due to a missing check. Fixed the 1.5 restriction that Direct Call methods can only be called from the main thread, now they work when called from any thread. Internal Compiler Error if a call was discarded (via BurstDiscard for example), but the callsites required an ABI transform e.g. struct return. Fixed a bug with using multiple IsXXXSupported intrinsics in the same boolean condition would fail. Broken link restored for known issues with debugging and profiling. The Direct Call injected delegate now has a unique suffix to avoid type-name clashes. Dots runtime function pointer transform has been simplified, making it less brittle and fixing some bad IL generation. Fixed crashes on 32 bit windows when calling function pointers from managed code and using IL2CPP. Fixed a possible DivideByZeroException due to race condition in TermInfoDriver initialization code. Fixed a bug where the multi-CPU dispatcher (used for player builds targetting multiple CPU architectures) could end up generating invalid instructions. Gracefully handle failing to find a particular assembly in the ILPP to prevent an ICE. function calls using in modifiers on blittable structs where being treated as non blittable. crash when extracting sequence point information for error reporting/debug information generation. Direct Call extension methods that only differ on argument types are now supported (previously Burst's AssemblyLoader would complain about multiple matches). Fixed a regression where managed static fields, in static constructors that would also be compiled with Burst, could cause a compile time failure for mixing managed and unmanaged state. Added Added links to blog posts from the burst team to the Burst documentation. Intrinsics: Neon - Added support for basic vld1 APIs Can now call BurstCompiler.CompileFunctionPointer() in Burst code Add support for the C# 8.0 construct default(T) is null to Burst by transforming the generated Box + 'is the box non-null?' at compile time. Make it possible to get a pointer to UTF-8 encoded string literal data in HPC# code via StringLiteral.UTF8() Add an OptimizeFor option to [BurstCompile], allowing users to say they want fast code, small code, or fastly compiled code. Known issue with Windows Native Debuggers and Dll numbers + workarounds. Assemblies are now allowed to have an [assembly: BurstCompile()] attribute to let users specify compile options that should apply assembly wide (for instance [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)]). Automatically add [UnmanagedFunctionPointer(CallingConvention.Cdecl)] to any delegates that are used for BurstCompiler.CompileFunctionPointer<>() or error if the delegate has the attribute and it is not Cdecl. Source location metadata into hash cache. Added support for having [return: MarshalAs(UnmanagedType.U1)] or [return: MarshalAs(UnmanagedType.I1)] on a bool return external function. An additional warning about delegates being used by BurstCompiler.CompileFunctionPointer that are not decorated as expected. In most cases, Burst will automatically add the C-declaration attribute in IL Post Processing, but if the usage of CompileFunctionPointer is abstracted away behind an open generic implementation, then Burst will not be able to automatically correct the delegate declaration, and thus this warning will fire. new burst_TargetPlatform_EmbeddedLinux new AotNativeLinkEmbeddedLinux for EmbeddedLinux Added a new OptimizeFor mode Balanced. This becomes the default optimization mode, and trades off slightly lower maximum performance for much faster compile times. Added experimental half precision floating point type f16 Added experimental support for half precision floating point Arm Neon intrinsics Removed Known Issues Direct Call methods only execute using Burst after an initial execution of them on the main-thread. Notes BurstAotCompiler integration done using reflection and raw values, since the platform will only be officially available for 2021.2+ and we special customer versions (shadow branches) for 2019.4 & 2020.3. AotNativeLinkEmbeddedLinux implementation gets the toolchain from environment vars. [1.5.0-pre.2] - 2020-12-01 Added Removed Changed Fixed Fixed a failure on linux builds where libdl.so cannot be found. Known Issues [1.5.0-pre.1] - 2020-11-26 Added New intrinsics Hint.Likely, Hint.Unlikely, and Hint.Assume to let our users tell the compiler some additional information which could aid optimization. New Bmi1 and Bmi2 x86 intrinsics. These are gated on AVX2 being supported to keep the feature sets that Burst has to support small. You can now select explicit x86/x64 architecture SIMD target for Universal Windows Platform. Added Apple silicon and macOS universal binaries support to Burst. An extra alloca hoisting step to ensure that allocas that occur deep within functions are correctly allocated in the function entry block (which LLVM requires for optimization purposes). Added the missing clflush intrinsic to the SSE2 intrinsics. An optimize-for-size option to bcl to let select users focus the optimization passes to create smaller executables. Added a Unity.Burst.CompilerServices.SkipLocalsInitAttribute attribute that lets developers tell the compiler that stack-allocations do not need to be zero initialized for a given function. Added a new attribute [IgnoreWarnings] that can be specified per method, for users that really want the compiler to be quiet. Support for RDMA, crypto, dotprod Armv8.2-A Neon intrinsics An error message if attempting to BurstCompiler.CompileFunctionPointer() on a multicast delegate, since this is not supported in Burst. Burst detects removal of the burst package in 2020.2 editors and beyond, and displays a dialog asking the user to restart the editor. Added a pass that will classify and remove dead loops for improved code generation. Add support for using ValueTuple types like (int, float) from within Burst code, as long as the types do not enter or escape the Burst function boundaries. Added a new intrinsic Unity.Burst.CompilerServices.Constant.IsConstantExpression that will return true if an expression is known to be a compile-time constant in Bursted code. Added support for PlayMode / Desktop Standalone Players to load additional burst compiled libraries for use in Modding. Add support for calling Burst code directly from C# without using function pointers. In Unity 2020.2 and above, you can now call new ProfilerMarker(\"MarkerName\") from Burst code Add a compiler error if a ldobj tries to source its address to load from a non-pointer/non-reference. C# frontends should never generate this pattern, but we did see it with code generation. Fixed Fixed an issue where a function with a [return: AssumeRange(13, 42)] could lose this information during inlining. Storing into Lo64 or Hi64 would cause a compiler exception. Hitting a ldobj of a pointer-to-vector would incorrectly load the vector rather than the pointer.Burst only generates unaligned stores. Fix that the parameter to mm256_set1_epi8 should be a byte instead of a char. Fix sqrt_ss would fail because LLVM version later than 6 changed the encoding. Fixed the comi*_ss intrinsics which would generate invalid code. Pdb location for player builds is now linked relative to the final lib_burst_generated.dll, this allows the crashdump utility to access the symbols and provide better callstacks. Support negative intrinsics features checks to enable usage like if (!IsSse41Supported) return;. Clean up linker temp response files on successful build Wasm ABI issue with pointers Pause intrinsic in wasm (ignored) fmod expansion to sleef for wasm The AOT option for disabling optimizations now actually disables optimizations in player builds. Fix a bug where a static readonly variable that was a System.Guid would result in an internal compiler error. bitmask intrinsic was broken on non intel platforms When \"Enable Compilation\" was unchecked in the Burst menu, Burst was incorrectly enabled after an Editor restart. This is now fixed. Fixed a bug where a cloned function (say through no-aliasing propagation cloning) would re-create any global variables used rather than use the original variable. If the only reference to an external function was discarded, don't attempt to add it to the burst initialisation block (which caused on ICE on prior versions). Fixed a case where extracting a FixedString4096 from a parent struct could cause very slow compile times. Fixed a poor error message when a generic unsupported type (like a class or an auto-layout struct) combined with an unsupported managed array (like (int, float)[]) wouldn't give the user any context on where the code went wrong. Fixed a bug where if you used an enum argument to a function to index into a fixed array, a codegen error would occur. If targeting multiple iOS architectures, produce a combined burst library containing all architectures, this fixes \"New Build System\" on xcode version 12. Static method parameters are now validated correctly during eager-compilation Fixed permissions error when running lipo tool to combine libraries. Fixed compiler error that could occur when calling a [BurstDiscard] method with an argument that is also used elsewhere in the method Fixed an issue that could prevent the Editor from shutting down Fixed an internal compiler error when nested managed static readonly arrays were used (produces a proper Burst error instead now). Fixed a bug whereby for platforms that require us to write intermediate LLVM bitcode files, UTF paths would be incorrectly handled. Correctly marked Neon intrinsics vmovn_high_* as ArmV7 and not ArmV8 On windows, the pdb location for burst cached dll's now points to the correct path. Native debuggers attached to the Editor should now locate the symbols without requiring adding the Library/Burst/JitCache folder to the symbol search. Re-enabled BC1370 exception warnings but only for player builds. Fixed a bug whereby if you had an assembly that was guarded by UNITY_SERVER, Burst would be unable to find the assembly when Server Build was ticked. When \"Enable Compilation\" was unchecked in the Burst menu, Burst was incorrectly enabled after an Editor restart. This is now actually fixed. static readonly array with enum elements would cause the compiler to crash. Fixed managed (reference) implementation of mm256_cvttps_epi32 (case 1288563) Debug information for instance methods is now correctly scoped. This means instance variables can now be inspected correctly. Removed Removed support for XCode SDKs less than version 11.0.0. Removed support for platform SDKs that used the older LLVM 6 and 7 in the codebase to significantly simply our code and reduce the package size. Changed Minimum SDK version for iOS/tvOS increased to 13. See https://developer.apple.com/news/?id=03042020b for details. When using \"Executable Only\" build type on Universal Windows Platform, Burst will now only generate code for a single CPU architecture that you're building for. The inliner heuristics have been modified to inline less functions, but improve compile times and reduce executable size. The minimum XCode SDK required to compile for iOS/iPadOS/tvOS is now 11.0.0. We now copy the lib_burst_generated.pdb into the root of the player build (in addition to being alongside the lib_burst_generated.dll), this allows the unity crash handler to resolve the callstacks from burst code. Made Arm Neon intrinsics fully supported (removed the guarding define) Improved eager-compilation performance Improved Burst Inspector loading time Improved Burst initialization time If an argument to a BurstDiscard method is discarded, and that argument is a method call, then a warning is now generated to indicate the function call no longer happens. Changed how struct-return and indirect arguments use stack allocations to significantly reduce stack usage and improve performance in these cases. Improved the compilers ability to deduce dead memory operations (memcpy, memset, etc) to improve performance. Improved error message seen when scheduling Burst compilation during domain reload Open-generic static methods are not supported by Burst, but they were previously visible in Burst Inspector - they are now hidden In Burst Inspector, the \"Safety Checks\" checkbox now defaults to unchecked Burst Inspector no longer loses the search filter and \"Safety Checks\" option after domain reload Changed exception throws to allow more vectorization chances surrounding them. Upgraded Burst to use LLVM Version 11.0.0 by default, bringing the latest optimization improvements from the LLVM project. Eager-compilation is now cancelled when script compilation starts, to prevent spurious errors related to recompiled assemblies Strings can now be passed between methods within Burst code. Previously, string literals used for e.g. Debug.Log calls could only appear in the same method where they were used; now the string literal can be in one method, and passed to another method via a string parameter. Transitioning from burst disabled to burst enabled in editor, will perform a re-initialise of some internal state in use by Direct Call methods. Improved the performance of in-compiler hashing by 1.2x. Improved our hashing performance some more by re-using fixed-sized buffers in the compiler to improve eager-compilation / warm-cache costs by 1.25x. Improved compile time by ~37% on big projects by reworking some core compiler infrastructure. Known Issues In player builds, exceptions can report the wrong job that they were thrown from. [1.4.0-preview.4] - 2020-08-17 Fixed Fixed a bug introduced in 1.4.0-preview.3 that prevented some UnityEngine.Debug methods (such as DrawLine) from being called Fixed compiler error when explicit-layout struct contains a field which is itself an empty struct Fixed a bug that if you used more than four arguments in a function declared within another function, and then implicitly captured a few variables, Burst would map the variables wrongly. Changed Bump com.unity.mathematics to 1.2.1 version [1.4.0-preview.3] - 2020-08-06 Added VS 2017 support for platform that needs it. Added first batch of Arm Neon intrinsics. Currently, only ArmV8 (AArch64) targets are supported. The supported intrinsics include all ArmV7 and ArmV8 ones. Removed Changed In versions of Unity older than 2019.3, changing the following options in the Burst menu now requires the Editor to be restarted: Enable Compilation, Safety Checks, and Native Debug Mode Compilation. In versions of Unity older than 2019.3, previously-compiled methods will not be recompiled after changing those options, which could lead to undefined behavior where methods may or may not be compiled with the correct options. This change removes that possibility. Improved performance of \"eager-compilation\" (scheduling compilation immediately after assemblies are changed) by cancelling queued eager-compilation when entering play mode with Synchronous Compilation unchecked Improved performance of eager-compilation by not eager-compiling test assemblies Asserts that are currently discarded no longer discard arguments with potential side effects. Fixed We no longer attempt to replace the debug metadata multiple times for a given export. Fixed a subtle codegen bug that could occur when the target is an Arm or AArch64 CPU with vectors of 3 elements. Inspector slow down when scrolling/moving the window on large listings. Fixed a bug where a stfld into an element of a vector could deduce the wrong type for the underlying vector. Fixed a potential error when running the linker with a failure on lld command. If path to the package contained spaces, then native command execution could fail. This would manifiest as weird errors with 'lld' or 'vswhere' or other native tools. Fixed Debug.Log by re-enabling it when used in function pointers or jobs. Fixed errors when opening Inspector with a non-public Execute method on a job producer type Known Issues [1.4.0-preview.2] - 2020-07-01 Added Removed Changed The Burst Inspector no longer uses JIT compilation. The code it shows is now compiled the same way as for editor / player usage. Warnings are hidden in the inspector view Fixed Fixed potential error that could occur when unloading cached libraries Known Issues [1.4.0-preview.1] - 2020-06-26 Added Experimental support for tvOS Add intrinsics support for AtomicSafetyHandle.NewStaticSafetyId<T> A new option [BurstCompile(DisableSafetyChecks = true)] that allows per job or function-pointer disabling of safety checks. This allows users to have blessed code run fast always. Improve Editor experience by scheduling compilation immediately after assemblies are changed, instead of waiting until Play Mode is entered. Improved our aliasing detection to allow DynamicBuffer structs to be easily vectorizable. Added a compiler warning for any use of throwing an exception from a method not guarded by [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")]. Since exceptions in Burst are only supported in the editor, this provides a useful warning to users who may be relying on try/catch behaviors for control-flow which is not supported in final game builds. Burst compilation status is now displayed in the Background Tasks window in Unity 2020.1 and above (click the spinner in the bottom-right of the Editor to open this window). Upgraded Burst to use LLVM Version 10.0.0 by default, bringing the latest optimization improvements from the LLVM project. Add support for try/finally and using/foreach for IDisposable patterns. Add BurstCompiler.IsEnabled API. Add syntax colouring for LLVM IR and Optimized IR panels in the inspector Removed Changed Made the compiler better at constant-folding complex static readonly constructors. Bursted DOTS Runtime Jobs are now decorated with [NativePInvokeCallback] instead of [MonoPInvokeCallback] which could generate callback wrappers which could cause native code to inadvertently interop with the managed VM. The Burst menu-item Safety Checks has been changed to a modal choice of Off, On, and Force On. Force On will overwrite any user job or function-pointer with DisableSafetyChecks = true. To avoid users falling into the consistent trap of having Safety Checks set to Off, any reload of the Editor will issue a warning telling the user that Safety Checks have been reset to On. Use platform provided memory intrinsics for iOS, tvOS, WASM, and console platforms. Updated Cross Compilation Tooling To LLVM 10 The command line option --burst-disable-compilation is now disabling entirely Burst, including the AppDomain. Fixed Fixed incorrect struct layout for certain configurations of explicit-layout structs with overlapping fields Fixes a caching issue where stale cached libraries may have been used if a project was copied to a different folder, or Unity was upgraded to a newer version Burst will now error if a cpblk was used to copy into a [ReadOnly] parameter or field. Fixed a bug where the mm256_cvtepi32_ps intrinsic would crash the compiler. Fixed a bug with constant expressions that could cause a compile-time hang. Debug symbols are now output when using the native toolchain on mac. Sleef fallback to scalar float for WASM. ABI struct ret/by val for trivial aggregates for WASM is now respected. Fixed a bug with float/double vector constructors of Unity.Mathematics that take half or half vector parameters. Debug information for anonymous structs could be created partially multiple times for the same type. Filter symbol warnings to prevent them reaching logs. Fixed an issue where UNITY_DOTSPLAYER builds not building for NET_DOTS would be unable to compile do to references to UnityEngine. Fixed handling of conversion from signed integer to pointer which caused issues as discovered by Zuntatos on the forums. Allow to call [BurstCompile] functions from other [BurstCompile] functions IntPtr.Size now correctly returns int32 size (rather than UInt64) - fixes an assert. Burst package has been upgraded popup could fire erroneously under shutdown conditions. Fixed an issue preventing player builds to succeed when burst compilation is disabled. Debug symbols for function names on some platforms are no longer hashes. Job Entry point symbols should now reflect the job name and type rather than a hash in callstacks/native profilers Job entry points without symbols now use the Execute location rather than pointing to unknown/unknown Dwarf symbols from multiple modules (e.g. multithreaded AOT compilation) now have correct compilation unit information. Known Issues Output of Debug.Log is temporarily disabled in Burst Function Pointers/Jobs to avoid a deadlock on a domain reload. A fix for the Unity editor is being developed. [1.3.0-preview.12] - 2020-05-05 Fixed Fix an issue when changing the base type of an enum that would not trigger a new compilation and would keep code previously compiled, leading to potential memory corruptions or crashes. Fixed a subtle AArch64 ABI bug with struct-return's (structs that are returned via a pointer argument) that was found by our partners at Arm. Fix an issue that was preventing Debug.Log to be used from a Job in Unity 2020.1 Changed JIT cache is now cleared when changing Burst version [1.3.0-preview.11] - 2020-04-30 Fixed Fix potentially different hashes returned from BurstRuntime.GetHashCode32/64 if called from different assemblies. Fixed an issue where Burst was misidentifying F16C supporting CPUs as AVX2. SDK level bumped for MacOS to ensure notarization requests are compatable. Fixed a typo m256_cvtsi256_si32 -> mm256_cvtsi256_si32 and m256_cvtsi256_si64 -> mm256_cvtsi256_si64. The compiler is now generating a proper compiler error if a managed type used directly or indirectly with SharedStatic . Fixed a bug where implicitly stack allocated variables (var foo = new Foo();) in Burst were not being zero initialized, so any field of the variable that was not initialized during construction would have undefined values. Fix potential race condition when accessing on-disk library cache Fixed a bug where Burst was sometimes producing invalid code for iOS 11.0.3+. Added Added support for System.Threading.Volatile methods Read and Write, and for the System.Threading.Thread.MemoryBarrier method. New FMA X86 intrinsics. These are gated on AVX2 support, as our AVX2 detection requires the AVX2, FMA, and F16C features. UnsafeUtility.MemCmp now maps to a Burst optimal memory comparison path that uses vectorization. Removed Changed Known Issues [1.3.0-preview.10] - 2020-04-21 Fixed Fix negation of integer types smaller than 32 bits. Fixed a bug where optimizer generated calls to ldexp would be incorrectly deduced when deterministic floating-point was enabled. Swapped private linkage for internal linkage on functions, this fixes duplicate symbol issues on some targets. variable scopes should now encompass the whole scope. variables in parent scopes should now be present in locals windows. Native plugin location for windows has changed in 2019.3.9f1. If you are on an older version of 2019.3 you will need to upgrade for burst to work in windows standalone players. Added an error if Assert.AreEqual or Assert.AreNotEqual were called with different typed arguments. Fixed a bug where doing an explicit cast to a Unity.Mathematics vector type where the source was a scalar would fail to compile. Fix issue when converting large unsigned integer values to double or float. Fix an invalid value returned from a conditional where one type is an int32 and the other type would be a byte extended to an int32. Button layout of disassembly toolbar tweaked. Copy to clipboard now copies exactly what is shown in the inspector window (including enhancements and colours if shown) AVX2 now generates the correct AVX2 256-bit wide SLEEF functions instead of the FMA-optimized 128-bit variants. Added Anonymous types are now named in debug information. XCode/LLDB debugging of burst compiled code is now possible on macOS. Added some extra documentation about how to enable AVX/AVX2 in AOT builds, and how we gate some functionality on multiple instruction sets to reduce the combinations exposed underneath. Optimized external functions (like UnsafeUtility.Malloc) such that if they are called multiple times the function-pointer address is cached. Add support for string interpolation (e.g $\"This is a string with an {arg1} and {arg2}\"). Add support for Debug.Log(object) (e.g Debug.Log(\"Hello Log!\");). Add support for string assignment to Unity.Collections.FixedString (e.g \"FixedString128 test = \"Hello FixedString!\"). If burst detects a package update, it now prompts a restart of Unity (via dialog). The restart was always required, but could be missed/forgotten. Better error message for unsupported static readonly arrays. Link to native debugging video to Presentations section of docs. Fixes a bug where in parameters of interfaces could sometimes confuse the Burst inspector. Removed Changed iOS builds for latest xcode versions will now use LLVM version 9. Burst AOT Settings now lets you specify the exact targets you want to compile for - so you could create a player with SSE2, AVX, and AVX2 (EG. without SSE4 support if you choose to). Improve speed of opening Burst Inspector by up to 2x. Provided a better error message when structs with static readonly fields were a mix of managed/unmanaged which Burst doesn't support. Tidied up the known issues section in the docs a little. Enhanced disassembly option has been expanded to allow better control of what is shown, and allow a reduction in the amount of debug metadata shown. Load Burst Inspector asynchronously to avoid locking-up Editor. Documented restrictions on argument and return types for DllImport, internal calls, and function pointers. Known Issues [1.3.0-preview.9] - 2020-04-01 Changed Improved the compile time performance when doing UnsafeUtility.ReadArrayElement or UnsafeUtility.WriteArrayElement with large structs. Made some compile-time improvements when indirect arguments (those whose types are too big that they have to be passed by reference) that reduced our compile time by 3.61% on average. Fixed Fixed a bug where storing a default to a pointer that was generic would cause an LLVM verifier error. Fixed an obscure bug in how struct layouts that had dependencies on each other were resolved. Fixed a bug as found by @iamarugin where LLVM would introduce ldexp/ldexpf during optimizations that LLD would not be able to resolve. Fixed a bug where the compiler would not promote sub-integer types to integers when doing scalar-by-vector math (like multiplies). Added Variable scopes are now constructed for debug information. A new setting to Burst AOT Settings that allows debug symbols to be generated even in a non development standalone build. Removed Known Issues [1.3.0-preview.8] - 2020-03-24 Added Double math builtins in Unity.Mathematics now use double vector implementations from SLEEF. Fixed a bug with lzcnt, tzcnt, and countbits which when called with long types could produce invalid codegen. New F16C X86 intrinsics. These are gated on AVX2 support, as our AVX2 detection requires the AVX2, FMA, and F16C features. Add user documentation about generic jobs and restrictions. Add new experimental compiler intrinsics Loop.ExpectVectorized() and Loop.ExpectNotVectorized() that let users express assumptions about loop vectorization, and have those assumptions validated at compile-time.Enabled with UNITY_BURST_EXPERIMENTAL_LOOP_INTRINSICS. Changed Changed how Unity.Mathematics functions behave during loop vectorization and constant folding to substantially improve code generation. Our SSE4.2 support was implicitly dependent on the POPCNT extended instruction set, but this was not reflected in our CPU identification code. This is now fixed so that SSE4.2 is gated on SSE4.2 and POPCNT support. The popcnt intrinsics now live in their own static class Unity.Burst.Intrinsics.Popcnt to match the new F16C intrinsics. Deferred when we load the SLEEF builtins to where they are actually used, decreasing compile time with Burst by 4.29% on average. Fixed Fix an issue where a generic job instance (e.g MyGenericJob<int>) when used through a generic argument of a method or type would not be detected by the Burst compiler when building a standalone player. [DlIimport(\"__Internal\")] for iOS now handled correctly. Fixes crashes when using native plugins on iOS. Removed Known Issues [1.3.0-preview.7] - 2020-03-16 Added Added additional diagnostic for tracking Visual Studio location failures. Added an override to bypass link.exe discovery under certain conditions. Added a ldloc -> stloc optimization which improves compile times. More documentation on function pointers, specifically some performance considerations to be aware of when using them. Removed Changed Updated tools used for determining Visual Studio locations. Fixed Embedded Portable PDB handling improved. Fixed a case where our load/store optimizer would inadvertently combine a load/store into a cpblk where there were intermediate memory operations that should have been considered. Fixed a bug where the no-alias analysis would, through chains of complicated pointer math, deduce that a no-alias return (like from UnsafeUtility.Malloc) would not alias with itself. No longer log missing MonoPInvokeCallbackAttribute when running tests. Known Issues [1.3.0-preview.6] - 2020-03-12 Added Experimental support for Prefetch, allowing users to request from the memory subsystem pointer addresses they intend to hit next. This functionality is guarded by the UNITY_BURST_EXPERIMENTAL_PREFETCH_INTRINSIC preprocessor define. Fixed Fix SSE maxps intrinsic would emit maxss [1.3.0-preview.5] - 2020-03-11 Fixed MemCpy and MemSet performance regression in Burst 1.3.0.preview.4 (as was spotted by @tertle) has been fixed. Fix a crash when loading assembly with PublicKeyToken starting with a digit. Better handling of MonoPInvokeCallbackAttribute: no check for the namespace, don't print message on Mono builds. Changed Improved error message for typeof usage. [1.3.0-preview.4] - 2020-03-02 Added Debug information for types. Debug information for local variables. Debug information for function parameters. Support for fixed statements. These are useful when interacting with fixed buffers in structs, to get at the pointer data underneath. A fast-math optimization for comparisons that benefits the BurstBenchmarks that nxrightthere has put together. DOTS Runtime Jobs will now generate both MarshalToBurst and MarshalFromBurst functions when job structs in .Net builds are not blittable. DOTS Runtime Job Marshalling generation is now controllable via the commandline switch --generate-job-marshalling-methods. Removed Changed Made it clear that the Burst aliasing intrinsics are tied to optimizations being enabled for a compilation. Restore unwind information for all builds. Print a info message if compiling a function pointer with missing MonoPInvokeCallback attribute (this can lead to runtime issues on IL2CPP with Burst disabled). The message will be converted to a warning in future releases. Fixed Fixed an issue where DOTS Runtime generated job marshalling functiosn may throw a FieldAccessException when scheduling private and internal job structs. Fix a bug that prevented entry point method names (and their declaring type names) from having a leading underscore. vector/array/pointer debug data now utilizes the correct size information. DOTS Runtime will now only generate job marshaling functions on Windows, as all other platforms rely on Mono which does not require job marshalling. ldobj / stobj of large structs being copied to stack-allocated variables could cause compile-time explosions that appeared to the user like the compiler had hung. Worked around these by turning them into memcpy's underneath in LLVM. Don't always use latest tool chain on certain platforms. Fix a crash when compiling job or function pointer that was previously cached, then unloaded, then reloaded. Fixed compiler error in array element access when index type is not Int32. Fix set1_xxx style x86 intrinsics generated compile time errors. Known Issues Native debugger feature is only available on windows host platform at the moment. [1.3.0-preview.3] - 2020-02-12 Changed Changed how the inliner chooses to inline functions to give the compiler much more say over inlining decisions based on heuristics. Updated AOT requirements to be clearer about cross platform support. Added 1.3.0-preview.1 added support for desktop cross compilation, but the changelog forgot to mention it. Removed Fixed Documentation for the command line options to unity contained extra - Burst now exclusively uses the <project>/Temp/Burst folder for any temporary files it requires during compilation. Fix a regression that could break usage of native plugins. Known Issues [1.3.0-preview.2] - 2020-02-10 Fixed Fix the error Burst failed to compile the function pointer Int32 DoGetCSRTrampoline() that could happen when loading a project using Burst with Burst disabled. [1.3.0-preview.1] - 2020-02-04 Added Enabled lower precision variants for pow, sin, cos, log, log2, log10, exp, exp2, and exp10 when BurstPrecision.Low is specified. Add CPU minimum and maximum target for desktop platforms Standalone Player builds. Append a newline between IRPassDiagnostic messages, fixes pass diagnostics readability in the inspector. Add a new attribute [AssumeRange] that lets users tag function parameters and returns of an integer type with a constrained range that the value is allowed to inhabit. NativeArray.Length and NativeSlice.Length have automatic detection that the property is always positive. This assumption feeds into the optimizer and can produce better codegen. Enabled support for DOTS Runtime SharedStatics. Due to the nature of DOTS Runtime, only the generic versions of SharedStatic.GetOrCreate<TContext> are supported. Add a new intrinsic Unity.Burst.Intrinsics.Common.Pause() which causes a thread pause to occur for the current thread. This is useful for spin-locks to stop over contention on the lock. Add some new Burst aliasing deductions to substantially improve the aliasing detection in the compiler, resulting in better codegen. Add syntax colouring to WASM. Add IsCreated to the FunctionPointer class to allow checks on whether a given function pointer has a valid (non null) pointer within it. Add AVX2 intrinsics Add some missing intrinsics from SSE, SSE2 and AVX Added explicit X86 intrinsics from SSE-AVX2. AVX and AVX2 CPU targets are now available for x64 AOT builds. Allow handle structs (structs with a single pointer/integer in them) to be inside another struct as long as they are the single member, as these require no ABI pain. Added support for Interlocked.Read. Added a new intrinsic Common.umul128 which lets you get the low and high components of a 64-bit multiplication. This is especially useful for things like large hash creation. Menu option to allow all burst jobs to be more easily debugged in a native debugger. Removed Changed Upgraded Burst to use LLVM Version 9.0.1 by default, bringing the latest optimization improvements from the LLVM project. Upgraded Burst to use SLEEF 3.4.1, bringing the latest performance improvements to mathematics functions as used in Burst. Improved Burst performance in the Editor by caching compiled libraries on-disk, meaning that in subsequent runs of the Editor, assemblies that haven't changed won't be recompiled. Update the documentation of CompileSynchronously to advise against any general use of setting CompileSynchronously = true. Take the Unity.Burst.CompilerServices.Aliasing intrinsics out of experimental. These intrinsics form part of our strategy to give users more insight into how the compiler understands their code, by producing compiler errors when user expectations are not met. Questions like 'Does A alias with B?' can now be definitively answered for developers. See the Aliasing Checks section of the Burst documentation for information. Align disassembly instruction output in Inspector (x86/x64 only). Renamed m128 to v128. Renamed m256 to v256. BurstCompile(Debug=true), now modifies the burst code generator (reducing some optimisations) in order to allow a better experience in debugging in a native debugger. Fixed Fix a bug where floating-point != comparisons were using a stricter NaN-aware comparison than was required. Fix inspector for ARMV7_NEON target. Fix some issues with Burst AOT Settings, including changing the settings to be Enable rather than Disable. Fix an issue where WASM was being incorrectly shown in the disassembly view. Fixed an issue where if the Unity.Entities.StaticTypeRegistry assembly wasn't present in a build, Burst would throw a NullReferenceException. Fix issue with type conversion in m128/m256 table initializers. Fix inspector source line information (and source debug information) from being lost depending on inlining. Fix occasional poor code generation for on stack AVX2 variables. Fix xor_ps was incorrectly downcoded. Fix reference version of AVX2 64-bit variable shifts intrinsics. Fix reference version of SSE4.2 cmpestrz. Fix bitwise correctness issue with SSE4.2/AVX explicit rounding in CEIL mode for negative numbers that round to zero (was not correctly computing negative zero like the h/w). Fix calls to SHUFFLE, SHUFFLE_PS and similar macro-like functions would not work in non-entrypoint functions. Source location information was offset by one on occasions. Debug metadata is now tracked on branch/switch instructions. Fix poor error reporting when intrinsic immediates were not specified as literals. Fix basic loads and stores (using explicit calls) were not unaligned and sometimes non-temporal when they shouldn't be. Removed the <>c__DisplayClass_ infix that was inserted into every Entities.ForEach in the Burst inspector to clean up the user experience when searching for Entities.ForEach jobs. Fix background compile errors accessing X86 MXCSR from job threads. Fix possible ExecutionEngineException when resolving external functions. Fix linker output not being propagated through to the Editor console. Known Issues [1.2.0-preview.9] - 2019-11-06 Fix compilation requests being lost when using asynchronous compilation. Prevent Burst compilation being toggled on while in play mode, either via \"Enable Compilation\" menu item or programmatically - was previously technically possible but produced unpredictable results. [1.2.0-preview.8] - 2019-11-01 Fix a NullReferenceException happening in a call stack involving CecilExtensions.IsDelegate(...). [1.2.0-preview.7] - 2019-10-30 Many improvements to the Inspector: New assembly syntax colorization! Fix issue with menu settings being modified when opening the Inspector. Make compile targets left pane resizable. Fix vertical scrollbar size. Add automatic refresh when selecting a target to compile. Fix an issue where ref readonly of a struct type, returned from a function, would cause a compiler crash. Add support for Interlocked.Exchange and Interlocked.CompareExchange for float and double arguments. Fix bug preventing iOS builds from working, if burst is disabled in AOT Settings. [1.2.0-preview.6] - 2019-10-16 New multi-threaded compilation support when building a standalone player. Improve BurstCompiler.CompileFunctionPointer to compile asynchronously function pointers in the Editor. Improve of error codes and messages infrastructure. Upgraded Burst to use LLVM Version 8.0.1 by default, bringing the latest optimization improvements from the LLVM project. Fix issue with libtinfo5 missing on Linux. Fix possible NullReferenceException when an entry point function is calling another empty function. Fix an exception occurring while calculating the size of a struct with indirect dependencies to itself. Fix potential failure when loading MDB debugging file. Fix linker issue with folder containing spaces. Fix issue with package validation by removing ifdef around namespaces. Fix issue with an internal compiler exception related to an empty stack. [1.2.0-preview.5] - 2019-09-23 Fix crashing issue during the shutdown of the editor. [1.2.0-preview.4] - 2019-09-20 Fix a logging issue on shutdown. [1.2.0-preview.3] - 2019-09-20 Fix potential logging of an error while shutting down the editor. [1.2.0-preview.2] - 2019-09-20 New multi-threaded compilation of jobs/function pointers in the editor. Improve caching of compiled jobs/function pointers. Fix a caching issue where some jobs/function pointers would not be updated in the editor when updating their code. Fix an issue where type initializers with interdependencies were not executed in the correct order. Fix an issue with Failed to resolve assembly Windows, Version=255.255.255.255... when building for Xbox One. Fix compilation error on ARM32 when calling an external function. Fix an issue with function pointers that would generate invalid code if a non-blittable type is used in a struct passed by ref. Fix an issue with function pointers that would generate invalid code in case containers/pointers passed to the function are memory aliased. Report a compiler error if a function pointer is trying to be compiled without having the [BurstCompile] attribute on the method and owning type. [1.2.0-preview.1] - 2019-09-09 Fix assembly caching issue, cache usage now conservative (Deals with methods that require resolving multiple assemblies prior to starting the compilation - generics). Fix Mac OS compatibility of Burst (10.10 and up) - fixes undefined symbol futimens. [1.1.3-preview.3] - 2019-09-02 Query android API target level from player settings when building android standalone players. Add calli opcode support to support bindings to native code. [1.1.3-preview.2] - 2019-08-29 Fix to allow calling [BurstDiscard] functions from static constructors. Correctly error if a DLLImport function uses a struct passed by value, but allow handle structs (structs with a single pointer/integer in them) as these require no ABI pain. Upgraded Burst to use LLVM Version 8 by default, bringing the latest optimisation improvements from the LLVM project. Added support for multiple LLVM versions, this does increase the package size, however it allows us to retain compatability with platforms that still require older versions of LLVM. Fix bug in assembly caching, subsequent runs should now correctly use cached jit code as appropriate. Add support for Lumin platform [1.1.3-preview.1] - 2019-08-26 Add support for use of the MethodImpl(MethodImplOptions.NoOptimization) on functions. Fix an issue whereby static readonly vector variables could not be constructed unless using the constructor whose number of elements matched the width of the vector. Fix an issue whereby static readonly vector variables could not be struct initialized. Improve codegen for structs with explicit layout and overlapping fields. Fix a bug causing SSE4 instructions to be run on unsupported processors. Fix an issue where storing a pointer would fail as our type normalizer would cast the pointer to an i8. Begin to add Burst-specific aliasing information by instructing LLVM on our stack-allocation and global variables rules. [1.1.2] - 2019-07-26 Fix an issue where non-readonly static variable would not fail in Burst while they are not supported. Fix issue with char comparison against an integer. Add partial support for C# char type. Improve codegen for struct layout with simple explicit layout. Fix NullReferenceException when using a static variable with a generic declaring type. Fix issue with stackalloc not clearing the allocated stack memory as it is done in .NET CLR. [1.1.1] - 2019-07-11 Fix a compiler error when using a vector type as a generic argument of a NativeHashMap container. Disable temporarily SharedStatic/Execution mode for current 2019.3 alpha8 and before. Fix detection of Android NDK for Unity 2019.3. Update documentation for known issues. [1.1.0] - 2019-07-09 Fix detection of Android NDK for Unity 2019.3. Update documentation for known issues. [1.1.0-preview.4] - 2019-07-05 Burst will now report a compilation error when writing to a [ReadOnly] container/variable. Fix regression with nested generics resolution for interface calls. Fix issue for UWP with Burst generating non appcert compliant binaries. Fix issue when reading/writing vector types to a field of an explicit layout. Fix build issue on iOS, use only hash names for platforms with clang toolchain to mitigate issues with long names in LLVM IR. Allow calls to intrinsic functions (e.g System.Math.Log) inside static constructors. Improve performance when detecting if a method needs to be recompiled at JIT time. Fix an issue with explicit struct layout and vector types. [1.1.0-preview.3] - 2019-06-28 Fix issue with generic resolution that could fail. Add support for readonly static data through generic instances. Add internal support for SharedStatic<T> for TypeManager. Add intrinsic support for math.bitmask. [1.1.0-preview.2] - 2019-06-20 Fix issue where uninitialized values would be loaded instead for native containers containing big structs. Fix issue where noalias analysis would fail for native containers containing big structs. Fix issue when calling \"internal\" methods that take bool parameters. Add support for MethodImplOptions.AggressiveInlining to force inlining. Fix issue in ABITransform that would cause compilation errors with certain explicit struct layouts. Disable debug information generation for PS4 due to IR compatability issue with latest SDK. Implemented an assembly level cache for JIT compilation to improve iteration times in the Editor. Implement a hard cap on the length of symbols to avoid problems for platforms that ingest IR for AOT. Add support for FunctionPointer<T> usable from Burst Jobs via BurstCompiler.CompileFunctionPointer<T>. Add BurstCompiler.Options to allow to control/enable/disable Burst jobs compilation/run at runtime. Add BurstRuntime.GetHashCode32<T> and GetHashCode64<T> to allow to generate a hash code for a specified time from a Burst job. [1.0.0] - 2019-04-16 Release stable version. [1.0.0-preview.14] - 2019-04-15 Bump to mathematics 1.0.1 Fix android ndk check on windows when using the builtin toolchain. Fix crash when accessing a field of a struct with an explicit layout through an embedded struct. Fix null pointer exception on building for android if editor version is less than 2019.1. Workaround IR compatibility issue with AOT builds on IOS. [1.0.0-preview.13] - 2019-04-12 Fix linker error on symbol $___check_bounds already defined. Fix StructLayout Explicit size calculation and backing storage. [1.0.0-preview.12] - 2019-04-09 Fix crash when accessing a NativeArray and performing in-place operations (e.g nativeArray[i] += 121;). [1.0.0-preview.11] - 2019-04-08 Improve error logging for builder player with Burst. Fix NullReferenceException when storing to a field which is a generic type. [1.0.0-preview.10] - 2019-04-05 Update known issues in the user manual. Improve user manual documentation about debugging, [BurstDiscard] attribute, CPU architectures supported... Fix an issue where Burst callbacks could be sent to the editor during shutdowns, causing an editor crash. Improve error messages for external tool chains when building for AOT. [1.0.0-preview.9] - 2019-04-03 Fix an auto-vectorizer issue not correctly detecting the safe usage of NativeArray access when performing in-place operations (e.g nativeArray[i] += 121;). Add support for dynamic dispatch of functions based on CPU features available at runtime. Fix issue when running SSE4 instructions on a pre-SSE4 CPU. Fix write access to NativeArray<bool>. Remove dependencies to C runtime for Windows/Linux build players (for lib_burst_generated.so/.dll). Updated API documentation. Update User manual. Static link some libraries into the Burst llvm wrapper to allow better support for some linux distros. [1.0.0-preview.8] - 2019-03-28 Fix for iOS symbol names growing too long, reduced footprint of function names via pretty printer and a hash. [1.0.0-preview.7] - 2019-03-28 Burst will now only generate debug information for AOT when targeting a Development Build. Added support for locating the build tools (standalone) for generating AOT builds on windows, without having to install Visual Studio complete. Fix Log Timings was incorrectly being passed along to AOT builds, causing them to fail. Fix editor crash if Burst aborted compilation half way through (because editor was being closed). Fix issue with job compilation that could be disabled when using the Burst inspector. Fix issue with spaces in certain paths (e.g. ANDROID_NDK_ROOT) when building for AOT. Restore behavior of compiling ios projects from windows with Burst, (Burst does not support cross compiling for ios) - we still generate a valid output project, but with no Burst code. Add support for Android embedded NDK. Fix issue where certain control flow involving object construction would crash the compiler in release mode. [1.0.0-preview.6] - 2019-03-17 Fix invalid codegen with deep nested conditionals. Fix issue with Burst menu \"Enable Compilation\" to also disable cache jobs. Improve handling of PS4 toolchain detection. [1.0.0-preview.5] - 2019-03-16 Fix regression with JIT caching that was not properly recompiling changed methods. Remove NativeDumpFlags from public API. Remove usage of PropertyChangingEventHandler to avoid conflicts with custom Newtonsoft.Json. Fix issue when a job could implement multiple job interfaces (IJob, IJobParallelFor...) but only the first one would be compiled. [1.0.0-preview.4] - 2019-03-15 Fix \"Error while verifying module: Invalid bitcast\" that could happen with return value in the context of deep nested conditionals. Fix support for AOT compilation with float precision/mode. Fix fast math for iOS/PS4. Fix issue with double not using optimized intrinsics for scalars. Fix issue when loading a MDB file was failing when building a standalone player. Fix no-alias analysis that would be disabled in a standalone player if only one of the method was failing. Fix bug with explicit layout struct returned as a pointer by a property but creating an invalid store. Change FloatPrecision.Standard defaulting from FloatPrecision.High (ULP1) to FloatPrecision.Medium (ULP3.5). [1.0.0-preview.3] - 2019-03-14 Fix compilation issue with uTiny builds. [1.0.0-preview.2] - 2019-03-13 Fix no-alias warning spamming when building a standalone player. Improve the layout of the options/buttons for the inspector so that they at least attempt to layout better when the width is too small for all the buttons. Fix formatting of error messages so the Unity Console can correctly parse the location as a clickable item (Note however it does not appear to allow double clicking on absolute paths). Change Burst menu to Jobs/Burst. Improve order of menu items. Fix for AOTSettings bug related to StandaloneWindows vs StandaloneWindows64. [1.0.0-preview.1] - 2019-03-11 Fix regression when resolving the type of generic used in a field. Fix linker for XboxOne, UWP. Fix performance codegen when using large structs. Fix codegen when a recursive function is involved with platform dependent ABI transformations. [0.2.4-preview.50] - 2019-02-27 Fix meta file conflict. Fix changelog format. [0.2.4-preview.49] - 2019-02-27 Move back com.unity.burst.experimental for function pointers support, but use internal modifier for this API. Restructure package for validation. [0.2.4-preview.48] - 2019-02-26 Move back com.unity.burst.experimental for function pointers support, but use internal modifier for this API. [0.2.4-preview.47] - 2019-02-26 Fix an issue during publish stage which was preventing to release the binaries. [0.2.4-preview.46] - 2019-02-26 iOS player builds now use static linkage (to support TestFlight) - Minimum supported Unity versions are 2018.3.6f1 or 2019.1.0b4. Fix a warning in Burst AOT settings. Enable forcing synchronous job compilation from menu. [0.2.4-preview.45] - 2019-02-07 Disable Burst AOT settings support for unity versions before 2019.1. [0.2.4-preview.44] - 2019-02-06 Fix incorrect conversions when performing subtraction with enums and floats. Fix compatability issue with future unity versions. Fix bug with ldfld bitcast on structs with explicit layouts. Guard against an issue resolving debug locations if the scope is global. [0.2.4-preview.43] - 2019-02-01 Add preliminary support for Burst AOT settings in the player settings. Move BurstCompile (delegate/function pointers support) from com.unity.burst package to com.unity.burst.experimental package. Fix issue with stackalloc allocating a pointer size for the element type resulting in possible StackOverflowException. Add support for disabling Burst compilation from Unity editor with the command line argument --burst-disable-compilation . Add support for forcing synchronous compilation from Unity editor with the command line argument --burst-force-sync-compilation. Fix a compiler crash when generating debugging information. Fix invalid codegen involving ternary operator [0.2.4-preview.42] - 2019-01-22 Fix a compilation error when implicit/explicit operators are used returning different type for the same input type. [0.2.4-preview.41] - 2019-01-17 Fix codegen issue with Interlocked.Decrement that was instead performing an increment. Fix codegen issue for an invalid layout of struct with nested recursive pointer references. Fix for Fogbugz case : https://fogbugz.unity3d.com/f/cases/1109514/. Fix codegen issue with ref bool on a method argument creating a compiler exception. [0.2.4-preview.40] - 2018-12-19 Fix bug when a write to a pointer type of an argument of a generic function. Breaking change of API: Accuracy -> FloatPrecision, and Support => FloatMode. Add FloatMode.Deterministic mode with early preview of deterministic mathematical functions. Fix bug with fonts in inspector being incorrectly reloaded. [0.2.4-preview.39] - 2018-12-06 Add preview support for readonly static arrays typically used for LUT. Fix an issue with generics incorrectly being resolved in certain situations. Fix ARM32/ARM64 compilation issues for some instructions. Fix ARM compilation issues on UWP. Fix issue with math.compress. Add support for ldnull for storing a managed null reference to a ref field (e.g for DisposeSentinel). [0.2.4-preview.38] - 2018-11-17 Fix issue when converting an unsigned integer constant to a larger unsigned integer (e.g (ulong)uint.MaxValue). Fix crash in editor when IRAnalysis can return an empty string . Fix potential crash of Cecil when reading symbols from assembly definition. [0.2.4-preview.37] - 2018-11-08 Fix a crash on Linux and MacOS in the editor with dlopen crashing when trying to load burst-llvm (linux). [0.2.4-preview.36] - 2018-11-08 Fix a crash on Linux and MacOS in the editor with dlopen crashing when trying to load burst-llvm (mac). [0.2.4-preview.35] - 2018-10-31 Try to fix a crash on macosx in the editor when a job is being compiled by Burst at startup time. Fix Burst accidentally resolving reference assemblies. Add support for Burst for ARM64 when building UWP player. [0.2.4-preview.34] - 2018-10-12 Fix compiler exception with an invalid cast that could occur when using pinned variables (e.g int32& resolved to int32** instead of int32*). [0.2.4-preview.33] - 2018-10-10 Fix a compiler crash with methods incorrectly being marked as external and throwing an exception related to ABI. [0.2.4-preview.32] - 2018-10-04 Fix codegen and linking errors for ARM when using mathematical functions on plain floats. Add support for vector types GetHashCode. Add support for DllImport (only compatible with Unity 2018.2.12f1+ and 2018.3.0b5+). Fix codegen when converting uint to int when used in a binary operation. [0.2.4-preview.31] - 2018-09-24 Fix codegen for fmodf to use inline functions instead. Add extended disassembly output to the Burst inspector. Fix generic resolution through de-virtualize methods. Fix bug when accessing float3.zero. Prevents static constructors being considered intrinsics. Fix NoAlias attribute checking when generics are used. [0.2.4-preview.30] - 2018-09-11 Fix IsValueType throwing a NullReferenceException in case of using generics. Fix discovery for Burst inspector/AOT methods inheriting from IJobProcessComponentData or interfaces with generics. Add [NoAlias] attribute. Improved codegen for csum. Improved codegen for abs(int). Improved codegen for abs on floatN/doubleN. [0.2.4-preview.29] - 2018-09-07 Fix issue when calling an explicit interface method not being matched through a generic constraint. Fix issue with or/and binary operation on a bool returned by a function. [0.2.4-preview.28] - 2018-09-05 Fix a compilation issue when storing a bool returned from a function to a component of a bool vector. Fix AOT compilation issue with a duplicated dictionary key. Fix settings of ANDROID_NDK_ROOT if it is not setup in Unity Editor. [0.2.4-preview.27] - 2018-09-03 Improve detection of jobs within nested generics for AOT/Burst inspector. Fix compiler bug of comparison of a pointer to null pointer. Fix crash compilation of sincos on ARM (neon/AARCH64). Fix issue when using a pointer to a VectorType resulting in an incorrect access of a vector type. Add support for doubles (preview). Improve AOT compiler error message/details if the compiler is failing before the linker. [0.2.4-preview.26] - 2018-08-21 Added support for cosh, sinh and tanh. [0.2.4-preview.25] - 2018-08-16 Fix warning in unity editor. [0.2.4-preview.24] - 2018-08-15 Improve codegen of math.compress. Improve codegen of math.asfloat/asint/asuint. Improve codegen of math.csum for int4. Improve codegen of math.count_bits. Support for lzcnt and tzcnt intrinsics. Fix AOT compilation errors for PS4 and XboxOne. Fix an issue that could cause wrong code generation for some unsafe ptr operations. [0.2.4-preview.23] - 2018-07-31 Fix bug with switch case to support not only int32. [0.2.4-preview.22] - 2018-07-31 Fix issue with pointers comparison not supported. Fix a StackOverflow exception when calling an interface method through a generic constraint on a nested type where the declaring type is a generic. Fix an issue with EntityCommandBuffer.CreateEntity/AddComponent that could lead to ArgumentException/IndexOutOfRangeException. [0.2.4-preview.21] - 2018-07-25 Correct issue with Android AOT compilation being unable to find the NDK. [0.2.4-preview.20] - 2018-07-05 Prepare the user documentation for a public release. [0.2.4-preview.19] - 2018-07-02 Fix compilation error with generics when types are coming from different assemblies. [0.2.4-preview.18] - 2018-06-26 Add support for subtracting pointers. [0.2.4-preview.17] - 2018-06-25 Bump only to force a new version pushed. [0.2.4-preview.16] - 2018-06-25 Fix AOT compilation errors. [0.2.4-preview.15] - 2018-06-25 Fix crash for certain access to readonly static variable. Fix StackOverflowException when using a generic parameter type into an interface method. [0.2.4-preview.14] - 2018-06-23 Fix an issue with package structure that was preventing Burst to work in Unity. [0.2.4-preview.13] - 2018-06-22 Add support for Burst timings menu. Improve codegen for sin/cos. Improve codegen when using swizzles on vector types. Add support for sincos intrinsic. Fix AOT deployment. [0.2.4-preview.12] - 2018-06-13 Fix a bug in codegen that was collapsing methods overload of System.Threading.Interlocked to the same method. [0.2.4-preview.11] - 2018-06-05 Fix exception in codegen when accessing readonly static fields from different control flow paths. [0.2.4-preview.10] - 2018-06-04 Fix a potential stack overflow issue when a generic parameter constraint on a type is also referencing another generic parameter through a generic interface constraint Update to latest Unity.Mathematics: Fix order of parameters and codegen for step functions. [0.2.4-preview.9] - 2018-05-29 Fix bug when casting an IntPtr to an enum pointer that was causing an invalid codegen exception. [0.2.4-preview.8] - 2018-05-24 Breaking change: Move Unity.Jobs.Accuracy/Support to Unity.Burst. Deprecate ComputeJobOptimizationAttribute in favor of BurstCompileAttribute. Fix bug when using enum with a different type than int. Fix bug with IL stind that could lead to a memory corruption. [0.2.4-preview.7] - 2018-05-22 Add support for nested structs in SOA native arrays. Add support for arbitrary sized elements in full SOA native arrays. Fix bug with conversion from signed/unsigned integers to signed numbers (integers & floats). Add support for substracting pointers at IL level. Improve codegen with pointers arithmetic to avoid checking for overflows. [0.2.4-preview.6] - 2018-05-11 Remove bool1 from mathematics and add proper support in Burst. Add support for ARM platforms in the Burst inspector UI. [0.2.4-preview.5] - 2018-05-09 Add support for readonly static fields. Add support for stackalloc. Fix potential crash on MacOSX when using memset is used indirectly. Fix crash when trying to write to a bool1*. Fix bug with EnableBurstCompilation checkbox not working in Unity Editor. [0.2.4-preview.4] - 2018-05-03 Fix an issue on Windows with DllNotFoundException occurring when trying to load burst-llvm.dll from a user profile containing unicode characters in the folder path. Fix an internal compiler error occurring with IL dup instruction. [0.2.4-preview.3] - 2018-05-03 Add support for struct with an explicit layout. Fix noalias regression (that was preventing the auto-vectorizer to work correctly on basic loops). [0.2.3] - 2018-03-21 Improve error messages for static field access. Improve collecting of compilable job by trying to collect concrete job type instances (issue #23). [0.2.2] - 2018-03-19 Improve error messages in case using is or as cast in C#. Improve error messages if a static delegate instance is used. Fix codegen error when converting a byte/ushort to a float."
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Burst compiler Get started C# language support HPC# overview Static read-only fields and static constructor support String support Calling Burst-compiled code Function pointers C#/.NET type support C#/.NET System namespace support DllImport and internal calls SharedStatic struct Burst compilation Marking code for Burst compilation Excluding code from Burst compilation Defining Burst options for an assembly Burst compilation in Play mode Generic jobs Compilation warnings reference Burst intrinsics Burst intrinsics Common class Processor specific SIMD extensions Arm Neon intrinsics reference Editor reference Burst menu reference Burst Inspector window reference Building your project Burst AOT Settings reference Optimization Debugging and profiling tools Loop vectorization Memory aliasing NoAlias attribute Aliasing and the job system AssumeRange attribute Hint intrinsic Constant intrinsic SkipLocalsInit attribute Modding support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing-job-system.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing-job-system.html",
    "title": "Aliasing and the job system | Inventory System",
    "summary": "Aliasing and the job system Unity's job system infrastructure has some limitations on what can alias within a job struct: Structs attributed with [NativeContainer] (for example, NativeArray and NativeSlice) that are members of a job struct don't alias. Job struct members with the [NativeDisableContainerSafetyRestriction] attribute can alias with other members. This is because this attribute explicitly opts in to this kind of aliasing. Pointers to structs attributed with [NativeContainer] can't appear in other structs attributed with [NativeContainer]. For example, you can't have a NativeArray<NativeSlice<T>>. The following example job shows how these limitations work in practice: [BurstCompile] private struct MyJob : IJob { public NativeArray<float> a; public NativeArray<float> b; public NativeSlice<int> c; [NativeDisableContainerSafetyRestriction] public NativeArray<byte> d; public void Execute() { ... } } a, b, and c don't alias with each other. d can alias with a, b, or c. Tip If you're used to working with C/C++'s Type Based Alias Analysis (TBAA), then you might assume that because d has a different type from a, b, or c, it shouldn't alias. However, in C#, pointers don't have any assumptions that pointing to a different type results in no aliasing. This is why d is assumed to alias with a, b, or c. Additional resources Memory aliasing NoAlias attribute Job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing-noalias.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing-noalias.html",
    "title": "NoAlias attribute | Inventory System",
    "summary": "NoAlias attribute Use the [NoAlias] attribute to give Burst additional information on the aliasing of pointers and structs. In most use cases, you won't need to use the [NoAlias] attribute. You don't need to apply it to a struct definition that already has a [NativeContainer] attribute or to fields in job structs because in these cases Burst infers the no-alias information. The [NoAlias] attribute is exposed so that you can construct complex data structures where Burst can't infer the aliasing. If you use the [NoAlias] attribute on a pointer that could alias with another, it might result in undefined behavior and make it hard to track down bugs. You can use this attribute in the following ways: On a function parameter it signifies that the parameter doesn't alias with any other parameter to the function. On a struct field it signifies that the field doesn't alias with any other [NoAlias] field of the struct. On a struct it signifies that the address of the struct can't appear within the struct itself. On a function return value it signifies that the returned pointer doesn't alias with any other pointer returned from the same function. NoAlias function parameter The following is an example of aliasing: int Foo(ref int a, ref int b) { b = 13; a = 42; return b; } For this, Burst produces the following assembly: mov dword ptr [rdx], 13 mov dword ptr [rcx], 42 mov eax, dword ptr [rdx] ret This means that Burst does the following: Stores 13 into b. Stores 42 into a. Reloads the value from b to return it. Burst has to reload b because it doesn't know whether a and b are backed by the same memory or not. Add the [NoAlias] attribute to the code to change this: int Foo([NoAlias] ref int a, ref int b) { b = 13; a = 42; return b; } For this, Burst produces the following assembly: mov dword ptr [rdx], 13 mov dword ptr [rcx], 42 mov eax, 13 ret In this case, the load from b has been replaced with moving the constant 13 into the return register. NoAlias struct field The following example is the same as the previous, but applied to a struct: struct Bar { public NativeArray<int> a; public NativeArray<float> b; } int Foo(ref Bar bar) { bar.b[0] = 42.0f; bar.a[0] = 13; return (int)bar.b[0]; } For this, Burst produces the following assembly: mov rax, qword ptr [rcx + 16] mov dword ptr [rax], 1109917696 mov rcx, qword ptr [rcx] mov dword ptr [rcx], 13 cvttss2si eax, dword ptr [rax] ret In this case, Burst does the following: Loads the address of the data in b into rax. Stores 42 into it (1109917696 is 0x42280000, which is 42.0f). Loads the address of the data in a into rcx. Stores 13 into it. Reloads the data in b and converts it to an integer for returning. If you know that the two NativeArrays aren't backed by the same memory, you can change the code to the following: struct Bar { [NoAlias] public NativeArray<int> a; [NoAlias] public NativeArray<float> b; } int Foo(ref Bar bar) { bar.b[0] = 42.0f; bar.a[0] = 13; return (int)bar.b[0]; } If you attribute both a and b with [NoAlias] it tells Burst that they don't alias with each other within the struct, which produces the following assembly: mov rax, qword ptr [rcx + 16] mov dword ptr [rax], 1109917696 mov rax, qword ptr [rcx] mov dword ptr [rax], 13 mov eax, 42 ret This means that Burst can return the integer constant 42. NoAlias struct Burst assumes that the pointer to a struct doesn't appear within the struct itself. However, there are cases where this isn't true: unsafe struct CircularList { public CircularList* next; public CircularList() { // The 'empty' list just points to itself. next = this; } } Lists are one of the few structures where it's normal to have the pointer to the struct accessible from somewhere within the struct itself. The following example indicates where [NoAlias] on a struct can help: unsafe struct Bar { public int i; public void* p; } float Foo(ref Bar bar) { *(int*)bar.p = 42; return ((float*)bar.p)[bar.i]; } This produces the following assembly: mov rax, qword ptr [rcx + 8] mov dword ptr [rax], 42 mov rax, qword ptr [rcx + 8] mov ecx, dword ptr [rcx] movss xmm0, dword ptr [rax + 4*rcx] ret In this case, Burst: Loads p into rax. Stores 42 into p. Loads p into rax again. Loads i into ecx. Returns the index into p by i. In this situation, Burst loads p twice. This is because it doesn't know if p points to the address of the struct bar. Once it stores 42 into p it has to reload the address of p from bar, which is a costly operation. Add [NoAlias] to prevent this: [NoAlias] unsafe struct Bar { public int i; public void* p; } float Foo(ref Bar bar) { *(int*)bar.p = 42; return ((float*)bar.p)[bar.i]; } This produces the following assembly: mov rax, qword ptr [rcx + 8] mov dword ptr [rax], 42 mov ecx, dword ptr [rcx] movss xmm0, dword ptr [rax + 4*rcx] ret In this situation, Burst only loads the address of p once, because [NoAlias] tells it that p can't be the pointer to bar. NoAlias function return Some functions can only return a unique pointer. For instance, malloc only returns a unique pointer. In this case, [return:NoAlias] gives some useful information to Burst. Important Only use [return: NoAlias] on functions that are guaranteed to produce a unique pointer. For example, with bump-allocations, or with things like malloc. Burst aggressively inlines functions for performance considerations, so with small functions, Burst inlines them into their parents to produce the same result without the attribute. The following example uses a bump allocator backed with a stack allocation: // Only ever returns a unique address into the stackalloc'ed memory. // We've made this no-inline because Burst will always try and inline // small functions like these, which would defeat the purpose of this // example [MethodImpl(MethodImplOptions.NoInlining)] unsafe int* BumpAlloc(int* alloca) { int location = alloca[0]++; return alloca + location; } unsafe int Func() { int* alloca = stackalloc int[128]; // Store our size at the start of the alloca. alloca[0] = 1; int* ptr1 = BumpAlloc(alloca); int* ptr2 = BumpAlloc(alloca); *ptr1 = 42; *ptr2 = 13; return *ptr1; } This produces the following assembly: push rsi push rdi push rbx sub rsp, 544 lea rcx, [rsp + 36] movabs rax, offset memset mov r8d, 508 xor edx, edx call rax mov dword ptr [rsp + 32], 1 movabs rbx, offset \"BumpAlloc(int* alloca)\" lea rsi, [rsp + 32] mov rcx, rsi call rbx mov rdi, rax mov rcx, rsi call rbx mov dword ptr [rdi], 42 mov dword ptr [rax], 13 mov eax, dword ptr [rdi] add rsp, 544 pop rbx pop rdi pop rsi ret The key things that Burst does: Has ptr1 in rdi. Has ptr2 in rax. Stores 42 into ptr1. Stores 13 into ptr2. Loads ptr1 again to return it. If you add the [return: NoAlias] attribute: [MethodImpl(MethodImplOptions.NoInlining)] [return: NoAlias] unsafe int* BumpAlloc(int* alloca) { int location = alloca[0]++; return alloca + location; } unsafe int Func() { int* alloca = stackalloc int[128]; // Store our size at the start of the alloca. alloca[0] = 1; int* ptr1 = BumpAlloc(alloca); int* ptr2 = BumpAlloc(alloca); *ptr1 = 42; *ptr2 = 13; return *ptr1; } It produces the following assembly: push rsi push rdi push rbx sub rsp, 544 lea rcx, [rsp + 36] movabs rax, offset memset mov r8d, 508 xor edx, edx call rax mov dword ptr [rsp + 32], 1 movabs rbx, offset \"BumpAlloc(int* alloca)\" lea rsi, [rsp + 32] mov rcx, rsi call rbx mov rdi, rax mov rcx, rsi call rbx mov dword ptr [rdi], 42 mov dword ptr [rax], 13 mov eax, 42 add rsp, 544 pop rbx pop rdi pop rsi ret In this case, Burst doesn't reload ptr2, and moves 42 into the return register. Additional resources Memory aliasing Aliasing and the job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/aliasing.html",
    "title": "Memory aliasing | Inventory System",
    "summary": "Memory aliasing Memory aliasing is a way to tell Burst how your code uses data. This can improve and optimize the performance of your application. Memory aliasing happens when locations in the memory overlap each other. The following example shows a job that copies data from an input array to an output array: [BurstCompile] private struct CopyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public void Execute() { for (int i = 0; i < Input.Length; i++) { Output[i] = Input[i]; } } } No memory aliasing If the arrays Input and Output don't overlap, which means that their respective memory location doesn't overlap, the code returns the following result after running this job on a sample input/output: Memory with no aliasing If Burst is noalias aware, it can work at the scalar level to optimize the previous scalar loop. It does this through a process called vectorizing, where it rewrites the loop to process elements in a small batch. For example, Burst could work at vector level in 4 by 4 elements: Memory with no aliasing vectorized Memory aliasing If the Output array overlaps the Input array by one element (for example Output[0] points to Input[1]), then this means that the memory is aliasing. This gives the following result when you run CopyJob without the auto vectorizer: Memory with aliasing If Burst isn't aware of the memory aliasing, it tries to auto vectorize the loop, which results in the following: Memory with aliasing and invalid vectorized code The result of this code is invalid and might lead to bugs if Burst can't identify them. Generated code In the CopyJob example, there is an x64 assembly targeted at AVX2 in its loop. The instruction vmovups moves 8 floats, so a single auto vectorized loop moves 4 × 8 floats, which equals 32 floats copied per loop iteration, instead of just one: .LBB0_4: vmovups ymm0, ymmword ptr [rcx - 96] vmovups ymm1, ymmword ptr [rcx - 64] vmovups ymm2, ymmword ptr [rcx - 32] vmovups ymm3, ymmword ptr [rcx] vmovups ymmword ptr [rdx - 96], ymm0 vmovups ymmword ptr [rdx - 64], ymm1 vmovups ymmword ptr [rdx - 32], ymm2 vmovups ymmword ptr [rdx], ymm3 sub rdx, -128 sub rcx, -128 add rsi, -32 jne .LBB0_4 test r10d, r10d je .LBB0_8 The following example shows the same Burst compiled loop, but Burst's aliasing is artificially disabled: .LBB0_2: mov r8, qword ptr [rcx] mov rdx, qword ptr [rcx + 16] cdqe mov edx, dword ptr [rdx + 4*rax] mov dword ptr [r8 + 4*rax], edx inc eax cmp eax, dword ptr [rcx + 8] jl .LBB0_2 The result is entirely scalar and runs approximately 32 times slower than the highly optimized, vectorized variant that the original alias analysis produces. Function cloning For function calls where Burst knows about the aliasing between parameters to the function, Burst can infer the aliasing. It can then propagate this onto the called function to improve optimization: [MethodImpl(MethodImplOptions.NoInlining)] int Bar(ref int a, ref int b) { a = 42; b = 13; return a; } int Foo() { var a = 53; var b = -2; return Bar(ref a, ref b); } The assembly for Bar would be: mov dword ptr [rcx], 42 mov dword ptr [rdx], 13 mov eax, dword ptr [rcx] ret This is because Burst doesn't know the aliasing of a and b within the Bar function. This is in line with what other compiler technologies do with this code snippet. Burst is smarter than this though. Through a process of function cloning, Burst creates a copy of Bar where it knows that the aliasing properties of a and b don't alias. It then replaces the original call to Bar with a call to the copy. This results in the following assembly: mov dword ptr [rcx], 42 mov dword ptr [rdx], 13 mov eax, 42 ret In this scenario, Burst doesn't perform the second load from a. Aliasing checks Because aliasing is key to Burst's ability to optimize for performance, there are some aliasing intrinsics: Unity.Burst.CompilerServices.Aliasing.ExpectAliased expects that the two pointers do alias, and generates a compiler error if not. Unity.Burst.CompilerServices.Aliasing.ExpectNotAliased expects that the two pointers don't alias, and generates a compiler error if not. An example: using static Unity.Burst.CompilerServices.Aliasing; [BurstCompile] private struct CopyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute() { // NativeContainer attributed structs (like NativeArray) cannot alias with each other in a job struct! ExpectNotAliased(Input.getUnsafePtr(), Output.getUnsafePtr()); // NativeContainer structs cannot appear in other NativeContainer structs. ExpectNotAliased(in Input, in Output); ExpectNotAliased(in Input, Input.getUnsafePtr()); ExpectNotAliased(in Input, Output.getUnsafePtr()); ExpectNotAliased(in Output, Input.getUnsafePtr()); ExpectNotAliased(in Output, Output.getUnsafePtr()); // But things definitely alias with themselves! ExpectAliased(in Input, in Input); ExpectAliased(Input.getUnsafePtr(), Input.getUnsafePtr()); ExpectAliased(in Output, in Output); ExpectAliased(Output.getUnsafePtr(), Output.getUnsafePtr()); } } These checks only run when optimizations are enabled, because proper aliasing deduction is intrinsically linked to the optimizer's ability to see through functions via inlining. Additional resources NoAlias attribute Aliasing and the job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/building-aot-settings.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/building-aot-settings.html",
    "title": "Burst AOT Settings reference | Inventory System",
    "summary": "Burst AOT Settings reference To control Burst's AOT compilation, use the Burst AOT Settings section of the Project Settings window (Edit > Project Settings > Burst AOT Settings). These settings control Burst compilation in Player builds only. To configure Burst compilation in the Unity Editor, refer to Burst menu reference. Setting Function Target Platform Displays the current platform. To change the platform: • For Editor versions 6 and later, go to File > Build Profiles • For Editor versions earlier than 6, go to File > Build Settings. You can define different Burst AOT settings for each platform. Enable Burst Compilation Enable this setting to turn Burst compilation on. Disable this setting to deactivate Burst compilation for the selected platform. Enable Optimizations Enable this setting to activate Burst optimizations. Force Debug Information Enable this setting to make Burst generate debug information. This adds debug symbols to your project, even in release builds of your project, so that when you load it in a debugger you can see file and line information. Use Platform SDK Linker (Windows, macOS, and Linux builds only) Disables cross compilation support. When you enable this setting, you must use platform-specific tools for your target platform. Only enable this setting for debugging purposes. For more information, refer to Platforms with cross compilation disabled. Target 32Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for 32 bit builds. By default, SSE2 and SSE4 are selected. Target 64Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for 64-bit builds. By default, SSE2 and SSE4 are selected. Target Arm 64Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for Arm 64-bit builds. By default, ARMV8A is selected. Optimize For Select which optimization settings to compile Burst code for. For more information see OptimizeFor. Performance Optimizes the job to run as fast as possible. Size Optimizes to make the code generation as small as possible. Fast Compilation Compiles code as fast as possible, with minimal optimization. Burst doesn't perform any vectorization, inlining, or loop optimizations. Balanced (Default) Optimizes for code that runs fast but keeps compile time as low as possible. Disabled Warnings Specify a semi-colon separated list of Burst warning numbers to disable the warnings for a player build. Unity shares this setting across all platforms. This can be useful if you want to ignore specific compilation warnings while testing your application. Stack Protector (Displayed if the architecture is supported) Select the stack protector level. Stack Protector Buffer Size (Displayed if the architecture is supported) The stack protector buffer size threshold. The CPU Architecture setting is only supported for Windows, macOS, Linux and Android. Unity builds a Player that supports the CPU architectures you've selected. Burst generates a special dispatch into the module, so that the code generated detects the CPU the target platform uses and selects the appropriate CPU architecture at runtime. The Stack Protector Settings The Stack Protector option governs whether stack protectors are applied. Functions with stack protectors have a \"canary\" value added to the stack frame, which is then verified upon the function's return. The idea is that a buffer overflow would alter the canary value before reaching the return address, helping to detect and prevent exploitation. When Off is selected, no stack protectors are emitted. The values Basic, Strong and All differ in what heuristic is used to determine for which functions stack protectors are generated. These options correspond to clang's options --fstack-protector, --fstack-protector-strong and --fstack-protector-all, respectively. The Stack Protector Buffer Size is a threshold value used by the heuristics both to determine if a function is considered vulnerable and to guide layout of the arrays and structures on the stack. Optimize For setting Note Any OptimizeFor setting is the global default optimization setting for any Burst job or function-pointer. If any assembly level BurstCompile, or a specific Burst job or function-pointer has an OptimizeFor setting, it overrides the global optimization setting for those jobs. To control how Burst optimizes your code, use the Optimize For setting in the Editor, or use the OptimizeFor field: [BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] public struct MyJob : IJob { // ... } Additional resources Building your project Editor reference Project Settings"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/building-projects.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/building-projects.html",
    "title": "Building your project | Inventory System",
    "summary": "Building your project When you build your project, Burst compiles your code and creates a single dynamic library in the Plugins folder for the platform you're targeting. For example, on Windows, the path is Data/Plugins/lib_burst_generated.dll. Note If your target platform is iOS, Unity instead generates a static library to meet Apple's submission requirements for TestFlight. The job system runtime loads the generated library the first time a Burst compiled method is invoked. To control Burst's AOT compilation, use the settings in the Burst AOT Settings section of the Player Settings window (Edit > Player Settings > Burst AOT Settings). For more information, refer to Burst AOT Settings reference. Platforms without cross compilation If you're compiling for a non-desktop platform, Burst compilation requires specific platform compilation tools (similar to IL2CPP). By default, desktop platforms (macOS, Linux, Windows) don't need external toolchain support, unless you enable the Use Platform SDK Linker setting in the Burst AOT Settings. The table below lists the level of support for AOT compilation on each platform. If you select an invalid target (one with missing tools, or unsupported), Unity doesn't use Burst compilation, but still builds the target without Burst optimizations. Note Burst supports cross-compilation between desktop platforms (macOS/Linux/Windows) by default. Host Editor platform Target Player platform Supported CPU architectures External toolchain requirements Windows Windows x86 (SSE2, SSE4) x64 (SSE2, SSE4, AVX, AVX2) None Windows Universal Windows Platform x86 (SSE2, SSE4) x64 (SSE2, SSE4, AVX, AVX2) ARM32 (Thumb2, Neon32) ARMV8 AARCH64 Note: A UWP build always compiles all four targets. Visual Studio 2017 Universal Windows Platform Development Workflow C++ Universal Platform Tools Windows Android x86 SSE2 ARMV7 (Thumb2, Neon32) ARMV8 AARCH64 (ARMV8A, ARMV8A_HALFFP, ARMV9A) Android NDK Important: Use the Android NDK that you install through Unity Hub (via Add Component). Burst falls back to the one that the ANDROID_NDK_ROOT environment variable specifies if the Unity external tools settings aren't configured. Windows Magic Leap 2 ARMV8 AARCH64 From Unity 6, Magic Leap 2 requires the OpenXR plugin. Windows Xbox One x64 SSE4 Microsoft GDK Windows Xbox Series x64 AVX2 Microsoft GDK Windows PlayStation 4 x64 SSE4 Minimum PS4 SDK version 8.00 Windows PlayStation 5 x64 AVX2 Minimum PS5 SDK version 2.00 Windows Nintendo Switch ARMV8 AARCH64 None macOS macOS x64 (SSE2, SSE4, AVX, AVX2), Apple Silicon None macOS iOS ARM32 Thumb2/Neon32, ARMV8 AARCH64 Xcode with command line tools installed (xcode-select --install) macOS Android x86 SSE2 ARMV7 (Thumb2, Neon32) ARMV8 AARCH64 (ARMV8A, ARMV8A_HALFFP, ARMV9A) Android NDK Important: Use the Android NDK that you install through Unity Hub (via Add Component). Burst falls back to the one that the ANDROID_NDK_ROOT environment variable specifies if the Unity external tools settings aren't configured. macOS Magic Leap 2 ARMV8 AARCH64 From Unity 6, Magic Leap 2 requires the OpenXR plugin. Linux Linux x64 (SSE2, SSE4, AVX, AVX2) None The maximum target CPU is hardcoded per platform. For standalone builds that target desktop platforms (Windows/Linux/macOS) you can choose the supported targets via the Burst AOT Settings Projects that don't use Burst Some projects can't use Burst as the compiler: iOS projects from the Windows Editor Android projects from the Linux Editor Xcode projects generated from the Create Xcode Project option Multiple Burst targets When Burst compiles multiple target platforms during a build, it has to perform separate compilations. For example, if you want to compile X64_SSE2 and X64_SSE4, Burst has to do two separate compilations to generate code for each of the targets you choose. To keep the combinations of targets to a minimum, Burst target platforms require multiple processor instruction sets underneath: SSE4.2 is gated on having SSE4.2 and POPCNT instruction sets. AVX2 is gated on having AVX2, FMA, F16C, BMI1, and BMI2 instruction sets. ARMV8A is a basic Armv8-A CPU target ARMV8A_HALFFP is ARMV8A plus the following extensions: fullfp16, dotprod, crypto, crc, rdm, lse. In practice, this means Cortex A75/A55 and later cores. ARMV9A is ARMV8A_HALFFP plus SVE2 support. In practice, this means Cortex X2/A710/A510 and later cores. Important: this target is currently experimental. Dynamic dispatch based on runtime CPU features For all x86/x64 CPU desktop platforms, as well as for 64-bit Arm on Android, Burst takes into account the CPU features available at runtime to dispatch jobs to different versions it compiles. For x86 and x64 CPUs, Burst supports SSE2 and SSE4 instruction sets at runtime only. For example, with dynamic CPU dispatch, if your CPU supports SSE3 and below, Burst selects SSE2 automatically. Additional resources Burst AOT Settings reference Editor reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstcompile-assembly.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstcompile-assembly.html",
    "title": "Defining Burst options for an assembly | Inventory System",
    "summary": "Defining Burst options for an assembly Use the [BurstCompile] attribute on an assembly to set options for all Burst jobs and function-pointers within the assembly: [assembly: BurstCompile(CompileSynchronously = true)] For example, if an assembly just contains game code which needs to run quickly, you can use: [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] This means that Burst compiles the code as fast as it possibly can, which means that you can iterate on the game code much more quickly. It also means that other assemblies compile as they did before, which gives you more control on how Burst works with your code. Assembly-level BurstCompile attributes iterate with any job or function-pointer attribute, and also with any globally set options from the Burst Editor menu. Burst prioritizes assembly level attributes in the following order: Editor menu settings take precedence. For example, if you enable Native Debug Compilation from the Burst menu, Burst always compiles your code ready for debugging. Burst checks any BurstCompile attribute on a job or function-pointer. If you have CompileSynchronously = true in BurstCompile, then Burst compiles synchronously Otherwise, Burst sources any remaining settings from any assembly level attribute. For example: [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] // This job will be optimized for fast-compilation, because the per-assembly BurstCompile asked for it [BurstCompile] struct AJob : IJob { // ... } // This job will be optimized for size, because the per-job BurstCompile asked for it [BurstCompile(OptimizeFor = OptimizeFor.Size)] struct BJob : IJob { // ... } Additional resources Marking code for Burst compilation [BurstCompile] attribute API reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstcompile.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstcompile.html",
    "title": "Marking code for Burst compilation | Inventory System",
    "summary": "Marking code for Burst compilation Apply the [BurstCompile] attribute to the parts of your code you want Burst to compile. You can apply the [BurstCompile] attribute to the following: Jobs: When you apply [BurstCompile] to a job definition, Burst compiles everything within the job. For more information on jobs, refer to Job system in the Unity Manual. Classes: Apply [BurstCompile] to a class definition if the class contains static methods that are also marked with [BurstCompile]. Burst can't compile the class itself but only its member methods. Structs: Apply [BurstCompile] to a regular (non-job) struct definition if the struct contains static methods that are also marked with [BurstCompile]. Static methods: Apply [BurstCompile] to the method and its parent type. To work with dynamic functions that process data based on other data states, refer to Function pointers. Assemblies: Apply [BurstCompile] to an assembly to set options for all Burst jobs and function-pointers within the assembly. For more information, refer to Defining Burst options for an assembly. Important You don't always need to mark a method with the [BurstCompile] attribute for Burst to compile it. Any method where the program execution switches from managed to Burst-compiled code is referred to as a Burst entry point. If a static entry point method is marked with [BurstCompile], Burst also compiles any methods it calls into, even if they're not marked [BurstCompile]. Configure Burst compilation with parameters You can supply parameters to the [BurstCompile] attribute to modify aspects of compilation and improve Burst's performance. You can use attribute parameters to: Use a different accuracy for math functions (for example, sin, cos). Relax the order of math computations so that Burst can rearrange the floating point calculations. Force a synchronous compilation of a job (only for just-in-time compilation). For example, you can use the [BurstCompile] attribute to change the floating precision and float mode of Burst like so: [BurstCompile(FloatPrecision.Medium, FloatMode.Fast)] FloatPrecision Use the FloatPrecision enumeration to define Burst's floating precision accuracy. Float precision is measured in ulp (unit in the last place or unit of least precision). This is the space between floating-point numbers: the value the least significant digit represents if it's 1. Unity.Burst.FloatPrecision provides the following accuracy: FloatPrecision.Standard: Default value, which is the same as FloatPrecision.Medium. This provides an accuracy of 3.5 ulp. FloatPrecision.High: Provides an accuracy of 1.0 ulp. FloatPrecision.Medium: Provides an accuracy of 3.5 ulp. FloatPrecision.Low: Has an accuracy defined per function, and functions might specify a restricted range of valid inputs. Note: In previous versions of the Burst API, the FloatPrecision enum was named Accuracy. FloatPrecision.Low If you use the FloatPrecision.Low mode, the following functions have a precision of 350.0 ulp. All other functions inherit the ulp from FloatPrecision.Medium. Unity.Mathematics.math.sin(x) Unity.Mathematics.math.cos(x) Unity.Mathematics.math.exp(x) Unity.Mathematics.math.exp2(x) Unity.Mathematics.math.exp10(x) Unity.Mathematics.math.log(x) Unity.Mathematics.math.log2(x) Unity.Mathematics.math.log10(x) Unity.Mathematics.math.pow(x, y) Negative x to the power of a fractional y aren't supported. Unity.Mathematics.math.fmod(x, y) FloatMode Use the FloatMode enumeration to define Burst's floating point math mode. It provides the following modes: FloatMode.Default: Defaults to FloatMode.Strict mode. FloatMode.Strict: Burst doesn't perform any re-arrangement of the calculation and respects special floating point values (such as denormals, NaN). This is the default value. FloatMode.Fast: Burst can perform instruction re-arrangement and use dedicated or less precise hardware SIMD instructions. FloatMode.Deterministic: Unsupported. Deterministic mode is reserved for a future iteration of Burst. For hardware that can support Multiply and Add (e.g mad a * b + c) into a single instruction, you can use FloatMode.Fast to enable this optimization. However, the reordering of these instructions might lead to a lower accuracy. Use FloatMode.Fast for scenarios where the exact order of the calculation and the uniform handling of NaN values aren't required. Additional resources [BurstCompile] attribute API reference Defining Burst options for an assembly"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstdiscard.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-burstdiscard.html",
    "title": "Exclude code from Burst compilation | Inventory System",
    "summary": "Exclude code from Burst compilation By default, Burst compiles all methods in jobs decorated with the [BurstCompile] attribute. But some methods aren't appropriate for Burst compilation. For example, methods that perform logging using managed objects or that check the validity of something only valid in a managed environment can only run in a .NET runtime. In such cases you can use the [BurstDiscard] attribute on a method or property to exclude it from Burst compilation: [BurstCompile] public struct MyJob : IJob { public void Execute() { // Only executed when running from a full .NET runtime // this method call will be discard when compiling this job with // [BurstCompile] attribute MethodToDiscard(); } [BurstDiscard] private static void MethodToDiscard(int arg) { Debug.Log($\"This is a test: {arg}\"); } } Note A method with [BurstDiscard] can't have a return value. You can use a ref or out parameter, which indicates whether the code is running on Burst or managed: [BurstDiscard] private static void SetIfManaged(ref bool b) => b = false; private static bool IsBurst() { var b = true; SetIfManaged(ref b); return b; } Additional resources [BurstDiscard] attribute API reference Marking code for Burst compilation"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-generic-jobs.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-generic-jobs.html",
    "title": "Generic jobs | Inventory System",
    "summary": "Generic jobs While Burst supports generics, it has limited support for generic jobs or function pointers. If you notice that a job runs at full speed in the Editor but not in a built Player, the problem might be related to generic jobs. The following example defines a generic job: // Direct generic job [BurstCompile] struct MyGenericJob<TData> : IJob where TData : struct { public void Execute() { ... } } You can also nest generic jobs: // Nested generic job public class MyGenericSystem<TData> where TData : struct { [BurstCompile] struct MyGenericJob : IJob { public void Execute() { ... } } public void Run() { var myJob = new MyGenericJob(); // implicitly MyGenericSystem<TData>.MyGenericJob myJob.Schedule(); } } Jobs that are Burst-compiled look like this: // Direct Generic Job var myJob = new MyGenericJob<int>(); myJob.Schedule(); // Nested Generic Job var myJobSystem = new MyGenericSystem<float>(); myJobSystem.Run(); In both cases, in a Player build, the Burst compiler detects that it has to compile MyGenericJob<int> and MyGenericJob<float>. This is because the generic jobs (or the type surrounding it for the nested job) are used with fully resolved generic arguments (int and float). However, if these jobs are used indirectly through a generic parameter, the Burst compiler can't detect the jobs it has to compile at Player build time: public static void GenericJobSchedule<TData>() where TData: struct { // Generic argument: Generic Parameter TData // This Job won't be detected by the Burst Compiler at standalone-player build time. var job = new MyGenericJob<TData>(); job.Schedule(); } // The implicit MyGenericJob<int> will run at Editor time in full Burst speed // but won't be detected at standalone-player build time. GenericJobSchedule<int>(); The same restriction applies if you declare the job in the context of a generic parameter that comes from a type: // Generic Parameter TData public class SuperJobSystem<TData> { // Generic argument: Generic Parameter TData // This Job won't be detected by the Burst Compiler at standalone-player build time. public MyGenericJob<TData> MyJob; } If you want to use generic jobs, you must use them directly with fully resolved generic arguments (for example, int, MyOtherStruct). You can't use them with a generic parameter indirection (for example, MyGenericJob<TContext>). Important Burst doesn't support scheduling generic Jobs through generic methods. Function pointers Function pointers are restricted because you can't use a generic delegate through a function pointer with Burst: public delegate void MyGenericDelegate<T>(ref TData data) where TData: struct; var myGenericDelegate = new MyGenericDelegate<int>(MyIntDelegateImpl); // Will fail to compile this function pointer. var myGenericFunctionPointer = BurstCompiler.CompileFunctionPointer<MyGenericDelegate<int>>(myGenericDelegate); This limitation is because of a limitation of the .NET runtime to interop with such delegates. For more information, refer to Function pointers. Additional resources Burst compilation in Play mode Job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-synchronous.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-synchronous.html",
    "title": "Burst compilation in Play mode | Inventory System",
    "summary": "Burst compilation in Play mode When you create a build of your project, Burst compiles all the supported code ahead-of-time (AOT) into a native library which Unity ships with your application. When previewing your application in the Editor's Play mode, Burst provides the following compilation modes: Asynchronous: Parts of your code marked for Burst compilation can run as managed, just-in-time (JIT) compiled code in the .NET runtime while waiting for Burst compilation to complete. This is the default behavior. Synchronous: Parts of your code marked for Burst compilation can only run as Burst-compiled native code and your application must wait for Burst compilation to complete. Synchronous compilation To force synchronous compilation in Play mode, set the CompileSynchronously property to true as follows: [BurstCompile(CompileSynchronously = true)] public struct MyJob : IJob { // ... } Waiting for synchronous compilation affects the current running frame, which can cause hitches and make your application unresponsive. Synchronous compilation is only recommended in the following situations: If you have a long running job that only runs once. The performance of the compiled code might outweigh the downsides of synchronous compilation. If you're profiling a Burst job and want to test the code from the Burst compiler. When you do this, perform a warmup to discard any timing measurements from the first call to the job. This is because the profiling data includes the compilation time and skews the result. To aid with debugging the difference between managed and Burst compiled code. Additional resources Marking code for Burst compilation Generic jobs"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-warnings.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation-warnings.html",
    "title": "Compilation warnings reference | Inventory System",
    "summary": "Compilation warnings reference This page describes common compilation warnings and how to fix them. IgnoreWarning attribute The Unity.Burst.CompilerServices.IgnoreWarningAttribute attribute suppresses warnings for a specific Burst-compiled function. The warnings Burst generates are important to pay attention to, so this attribute should be used sparingly and only when necessary. The sections below describe the specific situations in which you might want to suppress warnings. BC1370 Warning BC1370 produces the message: An exception was thrown from a function without the correct [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] guard... This warning happens if Unity encounters a throw in code that [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] doesn't guard. In the Editor, thrown exceptions are caught and logged to the Console, but in a Player build a throw becomes an abort, which crashes your application. Burst warns you about these exceptions, and advises you to place them in functions guarded with [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] because such functions are not included in Player builds. However, if you want to purposely throw an exception to crash your application, use the IgnoreWarningAttribute to suppress the warnings that Burst provides on the throw: [IgnoreWarning(1370)] int DoSomethingMaybe(int x) { if (x < 0) throw new Exception(\"Dang - sorry I crashed your game!\"); return x * x; } Note This warning is only produced for exceptions that persist into Player builds. Editor-only or debug-only exception throws that aren't compiled into Player builds don't trigger this warning. BC1371 Warning BC1371 produces the message: A call to the method 'xxx' has been discarded, due to its use as an argument to a discarded method... To understand this warning, consider the following example: [BurstDiscard] static void DoSomeManagedStuff(int x) { ///.. only run when Burst compilation is disabled } // A function that computes some result which we need to pass to managed code int BurstCompiledCode(int x,int y) { return y+2*x; } [BurstCompile] void BurstedMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); } When Unity compiles your C# code in release mode, it optimizes and removes the local variable myValue. This means that Burst receives something like the following code: [BurstCompile] void BurstedMethod() { DoSomeManagedStuff(BurstCompiledCode(1,3)); } This makes Burst generate the warning, because Burst discards DoSomeManagedStuff, along with the BurstCompiledCode argument. This means that the BurstCompiledCode function is no longer executed, which generates the warning. If this isn't what you intended then ensure the variable has multiple uses. For example: void IsUsed(ref int x) { // Dummy function to prevent removal } [BurstCompile] void BurstedMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); IsUsed(ref myValue); } Alternatively, if you're happy that the code is being discarded correctly, ignore the warning on the BurstedMethod like so: [IgnoreWarning(1371)] [BurstCompile] void BurstedMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); } Additional resources Unity.Burst.CompilerServices.IgnoreWarningAttribute API reference Marking code for Burst compilation"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/compilation.html",
    "title": "Burst compilation | Inventory System",
    "summary": "Burst compilation Use Burst's custom C# attributes to define which parts of your code Burst compiles. These attributes and their parameters also allow you to configure a range of compilation options to improve Burst performance in different contexts. Topic Description Marking code for Burst compilation Use the [BurstCompile] attribute to mark code for Burst compilation. Use attribute paraeters to customize aspects of Burst compilation and improve performance. Excluding code from Burst compilation Use the [BurstDiscard] attribute to selectively exclude portions of code from Burst compilation. Defining Burst options for an assembly Apply the [BurstCompile] attribute at the assembly level to define Burst compilation options for a whole assembly. Burst compilation in Play mode Burst provides the option to compile asynchronously or synchronously in Play mode. Understand these options and how and when to configure synchronous compilation. Generic jobs Understand important limitations in Burst's support for generic jobs and function pointers. Compilation warnings Fix common compilation warnings. Additional resources C# language support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-common.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-common.html",
    "title": "Burst Intrinsics Common class | Inventory System",
    "summary": "Burst Intrinsics Common class The Unity.Burst.Intrinsics.Common intrinsics are for functionality shared across the hardware targets that Burst supports. Pause Unity.Burst.Intrinsics.Common.Pause is an intrinsic that requests that the CPU pause the current thread. It maps to pause on x86, and yield on ARM. Use it to stop spin locks over contending on an atomic access, which reduces contention and power on that section of code. Prefetch The Unity.Burst.Intrinsics.Common.Prefetch is an experimental intrinsic that provides a hint that Burst should prefetch the memory location into the cache. Because the intrinsic is experimental, you must use the UNITY_BURST_EXPERIMENTAL_PREFETCH_INTRINSIC preprocessor define to get access to it. umul128 Use the Unity.Burst.Intrinsics.Common.umul128 intrinsic to access 128-bit unsigned multiplication. These multiplies are useful for hashing functions. It maps 1:1 with hardware instructions on x86 and ARM targets. InterlockedAnd & InterlockedOr The Unity.Burst.Intrinsics.Common.InterlockedAnd and Unity.Burst.Intrinsics.Common.InterlockedOr are experimental intrinsics that provides atomic and/or operations on int, uint, long, and ulong types. Because these intrinsics are experimental, you must use the UNITY_BURST_EXPERIMENTAL_ATOMIC_INTRINSICS preprocessor define to get access to them. Additional resources Unity.Burst.Intrinsics.Common API reference Processor-specific SIMD extensions Burst Arm Neon intrinsics reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-dllimport.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-dllimport.html",
    "title": "| Inventory System",
    "summary": "DllImport and internal calls To call native functions, use [DllImport]: [DllImport(\"MyNativeLibrary\")] public static extern int Foo(int arg); Burst also supports internal calls implemented inside Unity: // In UnityEngine.Mathf [MethodImpl(MethodImplOptions.InternalCall)] public static extern int ClosestPowerOfTwo(int value); DllImport is only supported for native plug-ins, not platform-dependent libraries like kernel32.dll. For all DllImport and internal calls, you can only use the following types as parameter or return types: Type Supported type Built-in and intrinsic types byte / sbyte short / ushort int / uint long / ulong float double System.IntPtr / System.UIntPtr Unity.Burst.Intrinsics.v64 / Unity.Burst.Intrinsics.v128 / Unity.Burst.Intrinsics.v256 Pointers and references sometype* : Pointer to any of the other types in this list ref sometype : Reference to any of the other types in this list Handle structs unsafe struct MyStruct { void* Ptr; } : Struct containing a single pointer field unsafe struct MyStruct { int Value; } : Struct containing a single integer field Note Passing structs by value isn't supported; you need to pass them through a pointer or reference. The only exception is that handle structs are supported. These are structs that contain a single field of pointer or integer type. Additional resources HPC# overview Burst intrinsics overview"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-neon.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-neon.html",
    "title": "Burst Arm Neon intrinsics reference | Inventory System",
    "summary": "Burst Arm Neon intrinsics reference This page contains an ordered reference for the APIs in Unity.Burst.Intrinsics.Arm.Neon. For information on how to use these, refer to Processor specific SIMD extensions. Intrinsics type creation and conversion Operation Description APIs vcreate Create vector Click here to expand the API list vcreate_f16 vcreate_f32 vcreate_f64 vcreate_s16 vcreate_s32 vcreate_s64 vcreate_s8 vcreate_u16 vcreate_u32 vcreate_u64 vcreate_u8 vdup_n Duplicate (splat) value Click here to expand the API list vdup_n_f32 vdup_n_f64 vdup_n_s16 vdup_n_s32 vdup_n_s64 vdup_n_s8 vdup_n_u16 vdup_n_u32 vdup_n_u64 vdup_n_u8 vdupq_n_f32 vdupq_n_f64 vdupq_n_s16 vdupq_n_s32 vdupq_n_s64 vdupq_n_s8 vdupq_n_u16 vdupq_n_u32 vdupq_n_u64 vdupq_n_u8 vdup_lane Duplicate (splat) vector element Click here to expand the API list vdup_lane_f32 vdup_lane_f64 vdup_lane_s16 vdup_lane_s32 vdup_lane_s64 vdup_lane_s8 vdup_lane_u16 vdup_lane_u32 vdup_lane_u64 vdup_lane_u8 vdup_laneq_f32 vdup_laneq_f64 vdup_laneq_s16 vdup_laneq_s32 vdup_laneq_s64 vdup_laneq_s8 vdup_laneq_u16 vdup_laneq_u32 vdup_laneq_u64 vdup_laneq_u8 vdupq_lane_f32 vdupq_lane_f64 vdupq_lane_s16 vdupq_lane_s32 vdupq_lane_s64 vdupq_lane_s8 vdupq_lane_u16 vdupq_lane_u32 vdupq_lane_u64 vdupq_lane_u8 vdupq_laneq_f32 vdupq_laneq_f64 vdupq_laneq_s16 vdupq_laneq_s32 vdupq_laneq_s64 vdupq_laneq_s8 vdupq_laneq_u16 vdupq_laneq_u32 vdupq_laneq_u64 vdupq_laneq_u8 vdups_lane_f32 vdups_lane_s32 vdups_lane_u32 vdups_laneq_f32 vdups_laneq_s32 vdups_laneq_u32 vdupb_lane_s8 vdupb_lane_u8 vdupb_laneq_s8 vdupb_laneq_u8 vdupd_lane_f64 vdupd_lane_s64 vdupd_lane_u64 vdupd_laneq_f64 vdupd_laneq_s64 vdupd_laneq_u64 vduph_lane_s16 vduph_lane_u16 vduph_laneq_s16 vduph_laneq_u16 vmov_n Duplicate (splat) value Click here to expand the API list vmov_n_f32 vmov_n_f64 vmov_n_s16 vmov_n_s32 vmov_n_s64 vmov_n_s8 vmov_n_u16 vmov_n_u32 vmov_n_u64 vmov_n_u8 vmovq_n_f32 vmovq_n_f64 vmovq_n_s16 vmovq_n_s32 vmovq_n_s64 vmovq_n_s8 vmovq_n_u16 vmovq_n_u32 vmovq_n_u64 vmovq_n_u8 vcopy_lane Insert vector element from another vector element Click here to expand the API list vcopy_lane_f32 vcopy_lane_f64 vcopy_lane_s16 vcopy_lane_s32 vcopy_lane_s64 vcopy_lane_s8 vcopy_lane_u16 vcopy_lane_u32 vcopy_lane_u64 vcopy_lane_u8 vcopy_laneq_f32 vcopy_laneq_f64 vcopy_laneq_s16 vcopy_laneq_s32 vcopy_laneq_s64 vcopy_laneq_s8 vcopy_laneq_u16 vcopy_laneq_u32 vcopy_laneq_u64 vcopy_laneq_u8 vcopyq_lane_f32 vcopyq_lane_f64 vcopyq_lane_s16 vcopyq_lane_s32 vcopyq_lane_s64 vcopyq_lane_s8 vcopyq_lane_u16 vcopyq_lane_u32 vcopyq_lane_u64 vcopyq_lane_u8 vcopyq_laneq_f32 vcopyq_laneq_f64 vcopyq_laneq_s16 vcopyq_laneq_s32 vcopyq_laneq_s64 vcopyq_laneq_s8 vcopyq_laneq_u16 vcopyq_laneq_u32 vcopyq_laneq_u64 vcopyq_laneq_u8 vcombine Join two vectors into a larger vector Click here to expand the API list vcombine_f16 vcombine_f32 vcombine_f64 vcombine_s16 vcombine_s32 vcombine_s64 vcombine_s8 vcombine_u16 vcombine_u32 vcombine_u64 vcombine_u8 vget_high Get the higher half of the vector Click here to expand the API list vget_high_f32 vget_high_f64 vget_high_s16 vget_high_s32 vget_high_s64 vget_high_s8 vget_high_u16 vget_high_u32 vget_high_u64 vget_high_u8 vget_low Get the lower half of the vector Click here to expand the API list vget_low_f32 vget_low_f64 vget_low_s16 vget_low_s32 vget_low_s64 vget_low_s8 vget_low_u16 vget_low_u32 vget_low_u64 vget_low_u8 Arithmetic Operation Description APIs vadd Add Click here to expand the API list vadd_f32 vadd_f64 vadd_s16 vadd_s32 vadd_s64 vadd_s8 vadd_u16 vadd_u32 vadd_u64 vadd_u8 vaddq_f32 vaddq_f64 vaddq_s16 vaddq_s32 vaddq_s64 vaddq_s8 vaddq_u16 vaddq_u32 vaddq_u64 vaddq_u8 vaddd_s64 vaddd_u64 vaddv Add across vector Click here to expand the API list vaddv_f32 vaddv_s16 vaddv_s32 vaddv_s8 vaddv_u16 vaddv_u32 vaddv_u8 vaddvq_f32 vaddvq_f64 vaddvq_s16 vaddvq_s32 vaddvq_s64 vaddvq_s8 vaddvq_u16 vaddvq_u32 vaddvq_u64 vaddvq_u8 vaddl Add long Click here to expand the API list vaddl_s16 vaddl_s32 vaddl_s8 vaddl_u16 vaddl_u32 vaddl_u8 vaddl_high_s16 vaddl_high_s32 vaddl_high_s8 vaddl_high_u16 vaddl_high_u32 vaddl_high_u8 vaddlv Add long across Vector Click here to expand the API list vaddlv_s16 vaddlv_s32 vaddlv_s8 vaddlv_u16 vaddlv_u32 vaddlv_u8 vaddlvq_s16 vaddlvq_s32 vaddlvq_s8 vaddlvq_u16 vaddlvq_u32 vaddlvq_u8 vaddw Add wide Click here to expand the API list vaddw_s16 vaddw_s32 vaddw_s8 vaddw_u16 vaddw_u32 vaddw_u8 vaddw_high_s16 vaddw_high_s32 vaddw_high_s8 vaddw_high_u16 vaddw_high_u32 vaddw_high_u8 vhadd Halving add Click here to expand the API list vhadd_s16 vhadd_s32 vhadd_s8 vhadd_u16 vhadd_u32 vhadd_u8 vhaddq_s16 vhaddq_s32 vhaddq_s8 vhaddq_u16 vhaddq_u32 vhaddq_u8 vrhadd Rounding halving add Click here to expand the API list vrhadd_s16 vrhadd_s32 vrhadd_s8 vrhadd_u16 vrhadd_u32 vrhadd_u8 vrhaddq_s16 vrhaddq_s32 vrhaddq_s8 vrhaddq_u16 vrhaddq_u32 vrhaddq_u8 vqadd Saturating add Click here to expand the API list vqadd_s16 vqadd_s32 vqadd_s64 vqadd_s8 vqadd_u16 vqadd_u32 vqadd_u64 vqadd_u8 vqaddq_s16 vqaddq_s32 vqaddq_s64 vqaddq_s8 vqaddq_u16 vqaddq_u32 vqaddq_u64 vqaddq_u8 vqaddb_s8 vqaddb_u8 vqaddh_s16 vqaddh_u16 vqadds_s32 vqadds_u32 vqaddd_s64 vqaddd_u64 vsqadd Unsigned saturating Accumulate of signed value Click here to expand the API list vsqadd_u16 vsqadd_u32 vsqadd_u64 vsqadd_u8 vsqaddq_u16 vsqaddq_u32 vsqaddq_u64 vsqaddq_u8 vsqaddb_u8 vsqaddh_u16 vsqadds_u32 vsqaddd_u64 vuqadd Signed saturating Accumulate of unsigned value Click here to expand the API list vuqadd_s16 vuqadd_s32 vuqadd_s64 vuqadd_s8 vuqaddq_s16 vuqaddq_s32 vuqaddq_s64 vuqaddq_s8 vuqaddb_s8 vuqaddh_s16 vuqadds_s32 vuqaddd_s64 vaddhn Add returning high narrow Click here to expand the API list vaddhn_s16 vaddhn_s32 vaddhn_s64 vaddhn_u16 vaddhn_u32 vaddhn_u64 vaddhn_high_s16 vaddhn_high_s32 vaddhn_high_s64 vaddhn_high_u16 vaddhn_high_u32 vaddhn_high_u64 vraddhn Rounding add returning high narrow Click here to expand the API list vraddhn_s16 vraddhn_s32 vraddhn_s64 vraddhn_u16 vraddhn_u32 vraddhn_u64 vraddhn_high_s16 vraddhn_high_s32 vraddhn_high_s64 vraddhn_high_u16 vraddhn_high_u32 vraddhn_high_u64 vpadd Add pairwise (vector) Click here to expand the API list vpadd_f32 vpadd_s16 vpadd_s32 vpadd_s8 vpadd_u16 vpadd_u32 vpadd_u8 vpaddq_f32 vpaddq_f64 vpaddq_s16 vpaddq_s32 vpaddq_s64 vpaddq_s8 vpaddq_u16 vpaddq_u32 vpaddq_u64 vpaddq_u8 vpadds_f32 vpaddd_f64 vpaddd_s64 vpaddd_u64 vpaddl Signed add long pairwise Click here to expand the API list vpaddl_s16 vpaddl_s32 vpaddl_s8 vpaddl_u16 vpaddl_u32 vpaddl_u8 vpaddlq_s16 vpaddlq_s32 vpaddlq_s8 vpaddlq_u16 vpaddlq_u32 vpaddlq_u8 vpadal Signed add and accumulate long pairwise Click here to expand the API list vpadal_s16 vpadal_s32 vpadal_s8 vpadal_u16 vpadal_u32 vpadal_u8 vpadalq_s16 vpadalq_s32 vpadalq_s8 vpadalq_u16 vpadalq_u32 vpadalq_u8 vsub Subtract Click here to expand the API list vsub_f32 vsub_f64 vsub_s16 vsub_s32 vsub_s64 vsub_s8 vsub_u16 vsub_u32 vsub_u64 vsub_u8 vsubq_f32 vsubq_f64 vsubq_s16 vsubq_s32 vsubq_s64 vsubq_s8 vsubq_u16 vsubq_u32 vsubq_u64 vsubq_u8 vsubd_s64 vsubd_u64 vsubl Subtract long Click here to expand the API list vsubl_s16 vsubl_s32 vsubl_s8 vsubl_u16 vsubl_u32 vsubl_u8 vsubl_high_s16 vsubl_high_s32 vsubl_high_s8 vsubl_high_u16 vsubl_high_u32 vsubl_high_u8 vsubw Subtract wide Click here to expand the API list vsubw_s16 vsubw_s32 vsubw_s8 vsubw_u16 vsubw_u32 vsubw_u8 vsubw_high_s16 vsubw_high_s32 vsubw_high_s8 vsubw_high_u16 vsubw_high_u32 vsubw_high_u8 vhsub Halving subtract Click here to expand the API list vhsub_s16 vhsub_s32 vhsub_s8 vhsub_u16 vhsub_u32 vhsub_u8 vhsubq_s16 vhsubq_s32 vhsubq_s8 vhsubq_u16 vhsubq_u32 vhsubq_u8 vqsub Saturating subtract Click here to expand the API list vqsub_s16 vqsub_s32 vqsub_s64 vqsub_s8 vqsub_u16 vqsub_u32 vqsub_u64 vqsub_u8 vqsubq_s16 vqsubq_s32 vqsubq_s64 vqsubq_s8 vqsubq_u16 vqsubq_u32 vqsubq_u64 vqsubq_u8 vqsubb_s8 vqsubb_u8 vqsubh_s16 vqsubh_u16 vqsubs_s32 vqsubs_u32 vqsubd_s64 vqsubd_u64 vsubhn Subtract returning high narrow Click here to expand the API list vsubhn_s16 vsubhn_s32 vsubhn_s64 vsubhn_u16 vsubhn_u32 vsubhn_u64 vsubhn_high_s16 vsubhn_high_s32 vsubhn_high_s64 vsubhn_high_u16 vsubhn_high_u32 vsubhn_high_u64 vrsubhn Rounding subtract returning high narrow Click here to expand the API list vrsubhn_s16 vrsubhn_s32 vrsubhn_s64 vrsubhn_u16 vrsubhn_u32 vrsubhn_u64 vrsubhn_high_s16 vrsubhn_high_s32 vrsubhn_high_s64 vrsubhn_high_u16 vrsubhn_high_u32 vrsubhn_high_u64 Multiply Operation Description APIs vmul Multiply (vector) Click here to expand the API list vmul_f32 vmul_f64 vmul_s16 vmul_s32 vmul_s8 vmul_u16 vmul_u32 vmul_u8 vmulq_f32 vmulq_f64 vmulq_s16 vmulq_s32 vmulq_s8 vmulq_u16 vmulq_u32 vmulq_u8 vmul_n Vector multiply by scalar Click here to expand the API list vmul_n_f32 vmul_n_f64 vmul_n_s16 vmul_n_s32 vmul_n_u16 vmul_n_u32 vmulq_n_f32 vmulq_n_f64 vmulq_n_s16 vmulq_n_s32 vmulq_n_u16 vmulq_n_u32 vmul_lane Multiply (vector) Click here to expand the API list vmul_lane_f32 vmul_lane_f64 vmul_lane_s16 vmul_lane_s32 vmul_lane_u16 vmul_lane_u32 vmul_laneq_f32 vmul_laneq_f64 vmul_laneq_s16 vmul_laneq_s32 vmul_laneq_u16 vmul_laneq_u32 vmulq_lane_f32 vmulq_lane_f64 vmulq_lane_s16 vmulq_lane_s32 vmulq_lane_u16 vmulq_lane_u32 vmulq_laneq_f32 vmulq_laneq_f64 vmulq_laneq_s16 vmulq_laneq_s32 vmulq_laneq_u16 vmulq_laneq_u32 vmuls_lane_f32 vmuls_laneq_f32 vmuld_lane_f64 vmuld_laneq_f64 vmull Multiply long (vector) Click here to expand the API list vmull_s16 vmull_s32 vmull_s8 vmull_u16 vmull_u32 vmull_u8 vmull_high_s16 vmull_high_s32 vmull_high_s8 vmull_high_u16 vmull_high_u32 vmull_high_u8 vmull_n Vector long multiply by scalar Click here to expand the API list vmull_n_s16 vmull_n_s32 vmull_n_u16 vmull_n_u32 vmull_high_n_s16 vmull_high_n_s32 vmull_high_n_u16 vmull_high_n_u32 vmull_lane Multiply long (vector) Click here to expand the API list vmull_lane_s16 vmull_lane_s32 vmull_lane_u16 vmull_lane_u32 vmull_laneq_s16 vmull_laneq_s32 vmull_laneq_u16 vmull_laneq_u32 vmull_high_lane_s16 vmull_high_lane_s32 vmull_high_lane_u16 vmull_high_lane_u32 vmull_high_laneq_s16 vmull_high_laneq_s32 vmull_high_laneq_u16 vmull_high_laneq_u32 vmulx Floating-point multiply extended Click here to expand the API list vmulx_f32 vmulx_f64 vmulx_lane_f32 vmulx_lane_f64 vmulx_laneq_f32 vmulx_laneq_f64 vmulxq_f32 vmulxq_f64 vmulxq_lane_f32 vmulxq_lane_f64 vmulxq_laneq_f32 vmulxq_laneq_f64 vmulxs_f32 vmulxs_lane_f32 vmulxs_laneq_f32 vmulxd_f64 vmulxd_lane_f64 vmulxd_laneq_f64 vmla Multiply-add to accumulator (vector) Click here to expand the API list vmla_f32 vmla_f64 vmla_s16 vmla_s32 vmla_s8 vmla_u16 vmla_u32 vmla_u8 vmlaq_f32 vmlaq_f64 vmlaq_s16 vmlaq_s32 vmlaq_s8 vmlaq_u16 vmlaq_u32 vmlaq_u8 vmla_lane Vector multiply accumulate with scalar Click here to expand the API list vmla_lane_f32 vmla_lane_s16 vmla_lane_s32 vmla_lane_u16 vmla_lane_u32 vmla_laneq_f32 vmla_laneq_s16 vmla_laneq_s32 vmla_laneq_u16 vmla_laneq_u32 vmlaq_lane_f32 vmlaq_lane_s16 vmlaq_lane_s32 vmlaq_lane_u16 vmlaq_lane_u32 vmlaq_laneq_f32 vmlaq_laneq_s16 vmlaq_laneq_s32 vmlaq_laneq_u16 vmlaq_laneq_u32 vmla_n Vector multiply accumulate with scalar Click here to expand the API list vmla_n_f32 vmla_n_s16 vmla_n_s32 vmla_n_u16 vmla_n_u32 vmlaq_n_f32 vmlaq_n_s16 vmlaq_n_s32 vmlaq_n_u16 vmlaq_n_u32 vmlal Multiply-accumulate long (vector) Click here to expand the API list vmlal_s16 vmlal_s32 vmlal_s8 vmlal_u16 vmlal_u32 vmlal_u8 vmlal_high_s16 vmlal_high_s32 vmlal_high_s8 vmlal_high_u16 vmlal_high_u32 vmlal_high_u8 vmlal_lane Multiply-accumulate long with scalar Click here to expand the API list vmlal_lane_s16 vmlal_lane_s32 vmlal_lane_u16 vmlal_lane_u32 vmlal_laneq_s16 vmlal_laneq_s32 vmlal_laneq_u16 vmlal_laneq_u32 vmlal_high_lane_s16 vmlal_high_lane_s32 vmlal_high_lane_u16 vmlal_high_lane_u32 vmlal_high_laneq_s16 vmlal_high_laneq_s32 vmlal_high_laneq_u16 vmlal_high_laneq_u32 vmlal_n Multiply-accumulate long with scalar Click here to expand the API list vmlal_n_s16 vmlal_n_s32 vmlal_n_u16 vmlal_n_u32 vmlal_high_n_s16 vmlal_high_n_s32 vmlal_high_n_u16 vmlal_high_n_u32 vmls Multiply-subtract from accumulator (vector) Click here to expand the API list vmls_f32 vmls_f64 vmls_s16 vmls_s32 vmls_s8 vmls_u16 vmls_u32 vmls_u8 vmlsq_f32 vmlsq_f64 vmlsq_s16 vmlsq_s32 vmlsq_s8 vmlsq_u16 vmlsq_u32 vmlsq_u8 vmls_lane Vector multiply subtract with scalar Click here to expand the API list vmls_lane_f32 vmls_lane_s16 vmls_lane_s32 vmls_lane_u16 vmls_lane_u32 vmls_laneq_f32 vmls_laneq_s16 vmls_laneq_s32 vmls_laneq_u16 vmls_laneq_u32 vmlsq_lane_f32 vmlsq_lane_s16 vmlsq_lane_s32 vmlsq_lane_u16 vmlsq_lane_u32 vmlsq_laneq_f32 vmlsq_laneq_s16 vmlsq_laneq_s32 vmlsq_laneq_u16 vmlsq_laneq_u32 vmls_n Vector multiply subtract with scalar Click here to expand the API list vmls_n_f32 vmls_n_s16 vmls_n_s32 vmls_n_u16 vmls_n_u32 vmlsq_n_f32 vmlsq_n_s16 vmlsq_n_s32 vmlsq_n_u16 vmlsq_n_u32 vmlsl Multiply-subtract long (vector) Click here to expand the API list vmlsl_s16 vmlsl_s32 vmlsl_s8 vmlsl_u16 vmlsl_u32 vmlsl_u8 vmlsl_high_s16 vmlsl_high_s32 vmlsl_high_s8 vmlsl_high_u16 vmlsl_high_u32 vmlsl_high_u8 vmlsl_lane Vector multiply-subtract long with scalar Click here to expand the API list vmlsl_lane_s16 vmlsl_lane_s32 vmlsl_lane_u16 vmlsl_lane_u32 vmlsl_laneq_s16 vmlsl_laneq_s32 vmlsl_laneq_u16 vmlsl_laneq_u32 vmlsl_high_lane_s16 vmlsl_high_lane_s32 vmlsl_high_lane_u16 vmlsl_high_lane_u32 vmlsl_high_laneq_s16 vmlsl_high_laneq_s32 vmlsl_high_laneq_u16 vmlsl_high_laneq_u32 vmlsl_n Vector multiply-subtract long with scalar Click here to expand the API list vmlsl_n_s16 vmlsl_n_s32 vmlsl_n_u16 vmlsl_n_u32 vmlsl_high_n_s16 vmlsl_high_n_s32 vmlsl_high_n_u16 vmlsl_high_n_u32 vqdmull Signed saturating doubling multiply long Click here to expand the API list vqdmull_s16 vqdmull_s32 vqdmullh_s16 vqdmulls_s32 vqdmull_high_s16 vqdmull_high_s32 vqdmull_lane Vector saturating doubling multiply long with scalar Click here to expand the API list vqdmull_lane_s16 vqdmull_lane_s32 vqdmull_laneq_s16 vqdmull_laneq_s32 vqdmullh_lane_s16 vqdmullh_laneq_s16 vqdmulls_lane_s32 vqdmulls_laneq_s32 vqdmull_high_lane_s16 vqdmull_high_lane_s32 vqdmull_high_laneq_s16 vqdmull_high_laneq_s32 vqdmull_n Vector saturating doubling multiply long with scalar Click here to expand the API list vqdmull_n_s16 vqdmull_n_s32 vqdmull_high_n_s16 vqdmull_high_n_s32 vqdmulh Saturating doubling multiply returning high half Click here to expand the API list vqdmulh_s16 vqdmulh_s32 vqdmulhq_s16 vqdmulhq_s32 vqdmulhh_s16 vqdmulhs_s32 vqdmulh_lane Vector saturating doubling multiply high by scalar Click here to expand the API list vqdmulh_lane_s16 vqdmulh_lane_s32 vqdmulh_laneq_s16 vqdmulh_laneq_s32 vqdmulhq_lane_s16 vqdmulhq_lane_s32 vqdmulhq_laneq_s16 vqdmulhq_laneq_s32 vqdmulhh_lane_s16 vqdmulhh_laneq_s16 vqdmulhs_lane_s32 vqdmulhs_laneq_s32 vqdmulh_n Vector saturating doubling multiply high by scalar Click here to expand the API list vqdmulh_n_s16 vqdmulh_n_s32 vqdmulhq_n_s16 vqdmulhq_n_s32 vqrdmulh Saturating rounding doubling multiply returning high half Click here to expand the API list vqrdmulh_s16 vqrdmulh_s32 vqrdmulhq_s16 vqrdmulhq_s32 vqrdmulhh_s16 vqrdmulhs_s32 vqrdmulh_lane Vector saturating rounding doubling multiply high with scalar Click here to expand the API list vqrdmulh_lane_s16 vqrdmulh_lane_s32 vqrdmulh_laneq_s16 vqrdmulh_laneq_s32 vqrdmulhq_lane_s16 vqrdmulhq_lane_s32 vqrdmulhq_laneq_s16 vqrdmulhq_laneq_s32 vqrdmulhh_lane_s16 vqrdmulhh_laneq_s16 vqrdmulhs_lane_s32 vqrdmulhs_laneq_s32 vqrdmulh_n Vector saturating rounding doubling multiply high with scalar Click here to expand the API list vqrdmulh_n_s16 vqrdmulh_n_s32 vqrdmulhq_n_s16 vqrdmulhq_n_s32 vqdmlal Saturating doubling multiply-add long Click here to expand the API list vqdmlal_s16 vqdmlal_s32 vqdmlalh_s16 vqdmlals_s32 vqdmlal_high_s16 vqdmlal_high_s32 vqdmlal_lane Vector saturating doubling multiply-accumulate long with scalar Click here to expand the API list vqdmlal_lane_s16 vqdmlal_lane_s32 vqdmlal_laneq_s16 vqdmlal_laneq_s32 vqdmlalh_lane_s16 vqdmlalh_laneq_s16 vqdmlals_lane_s32 vqdmlals_laneq_s32 vqdmlal_high_lane_s16 vqdmlal_high_lane_s32 vqdmlal_high_laneq_s16 vqdmlal_high_laneq_s32 vqdmlal_n Vector saturating doubling multiply-accumulate long with scalar Click here to expand the API list vqdmlal_n_s16 vqdmlal_n_s32 vqdmlal_high_n_s16 vqdmlal_high_n_s32 vqdmlsl Signed saturating doubling multiply-subtract long Click here to expand the API list vqdmlsl_s16 vqdmlsl_s32 vqdmlslh_s16 vqdmlsls_s32 vqdmlsl_high_s16 vqdmlsl_high_s32 vqdmlsl_lane Vector saturating doubling multiply-subtract long with scalar Click here to expand the API list vqdmlsl_lane_s16 vqdmlsl_lane_s32 vqdmlsl_laneq_s16 vqdmlsl_laneq_s32 vqdmlslh_lane_s16 vqdmlslh_laneq_s16 vqdmlsls_lane_s32 vqdmlsls_laneq_s32 vqdmlsl_high_lane_s16 vqdmlsl_high_lane_s32 vqdmlsl_high_laneq_s16 vqdmlsl_high_laneq_s32 vqdmlsl_n Vector saturating doubling multiply-subtract long with scalar Click here to expand the API list vqdmlsl_n_s16 vqdmlsl_n_s32 vqdmlsl_high_n_s16 vqdmlsl_high_n_s32 vqrdmlah Saturating rounding doubling multiply accumulate returning high half (vector) Click here to expand the API list vqrdmlah_s16 vqrdmlah_s32 vqrdmlahq_s16 vqrdmlahq_s32 vqrdmlahh_s16 vqrdmlahs_s32 vqrdmlah_lane Saturating rounding doubling multiply accumulate returning high half (vector) Click here to expand the API list vqrdmlah_lane_s16 vqrdmlah_lane_s32 vqrdmlah_laneq_s16 vqrdmlah_laneq_s32 vqrdmlahq_lane_s16 vqrdmlahq_lane_s32 vqrdmlahq_laneq_s16 vqrdmlahq_laneq_s32 vqrdmlahh_lane_s16 vqrdmlahh_laneq_s16 vqrdmlahs_lane_s32 vqrdmlsh Saturating rounding doubling multiply subtract returning high half (vector) Click here to expand the API list vqrdmlsh_s16 vqrdmlsh_s32 vqrdmlshq_s16 vqrdmlshq_s32 vqrdmlshh_s16 vqrdmlshs_s32 vqrdmlsh_lane Saturating rounding doubling multiply subtract returning high half (vector) Click here to expand the API list vqrdmlsh_lane_s16 vqrdmlsh_lane_s32 vqrdmlsh_laneq_s16 vqrdmlsh_laneq_s32 vqrdmlshq_lane_s16 vqrdmlshq_lane_s32 vqrdmlshq_laneq_s16 vqrdmlshq_laneq_s32 vqrdmlshh_lane_s16 vqrdmlshh_laneq_s16 vqrdmlshs_lane_s32 vfma Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_f32 vfma_f64 vfmaq_f32 vfmaq_f64 vfma_n Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_n_f32 vfma_n_f64 vfmaq_n_f32 vfmaq_n_f64 vfma_lane Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_lane_f32 vfma_lane_f64 vfma_laneq_f32 vfma_laneq_f64 vfmaq_lane_f32 vfmaq_lane_f64 vfmaq_laneq_f32 vfmaq_laneq_f64 vfmas_lane_f32 vfmas_laneq_f32 vfmad_lane_f64 vfmad_laneq_f64 vfms Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_f32 vfms_f64 vfmsq_f32 vfmsq_f64 vfms_n Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_n_f32 vfms_n_f64 vfmsq_n_f32 vfmsq_n_f64 vfms_lane Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_lane_f32 vfms_lane_f64 vfms_laneq_f32 vfms_laneq_f64 vfmsd_lane_f64 vfmsd_laneq_f64 vfmsq_lane_f32 vfmsq_lane_f64 vfmsq_laneq_f32 vfmsq_laneq_f64 vfmss_lane_f32 vfmss_laneq_f32 vdiv Floating-point divide (vector) Click here to expand the API list vdiv_f32 vdiv_f64 vdivq_f32 vdivq_f64 Data processing Operation Description APIs vpmax Maximum pairwise Click here to expand the API list vpmax_f32 vpmax_s16 vpmax_s32 vpmax_s8 vpmax_u16 vpmax_u32 vpmax_u8 vpmaxq_f32 vpmaxq_f64 vpmaxq_s16 vpmaxq_s32 vpmaxq_s8 vpmaxq_u16 vpmaxq_u32 vpmaxq_u8 vpmaxs_f32 vpmaxqd_f64 vpmaxnm Floating-point maximum number pairwise (vector) Click here to expand the API list vpmaxnm_f32 vpmaxnmq_f32 vpmaxnmq_f64 vpmaxnms_f32 vpmaxnmqd_f64 vpmin Minimum pairwise Click here to expand the API list vpmin_f32 vpmin_s16 vpmin_s32 vpmin_s8 vpmin_u16 vpmin_u32 vpmin_u8 vpminq_f32 vpminq_f64 vpminq_s16 vpminq_s32 vpminq_s8 vpminq_u16 vpminq_u32 vpminq_u8 vpmins_f32 vpminqd_f64 vpminnm Floating-point minimum number pairwise (vector) Click here to expand the API list vpminnm_f32 vpminnmq_f32 vpminnmq_f64 vpminnms_f32 vpminnmqd_f64 vabd Absolute difference Click here to expand the API list vabd_f32 vabd_f64 vabd_s16 vabd_s32 vabd_s8 vabd_u16 vabd_u32 vabd_u8 vabdq_f32 vabdq_f64 vabdq_s16 vabdq_s32 vabdq_s8 vabdq_u16 vabdq_u32 vabdq_u8 vabds_f32 vabdd_f64 vabdl Absolute difference long Click here to expand the API list vabdl_s16 vabdl_s32 vabdl_s8 vabdl_u16 vabdl_u32 vabdl_u8 vabdl_high_s16 vabdl_high_s32 vabdl_high_s8 vabdl_high_u16 vabdl_high_u32 vabdl_high_u8 vaba Absolute difference and accumulate Click here to expand the API list vaba_s16 vaba_s32 vaba_s8 vaba_u16 vaba_u32 vaba_u8 vabaq_s16 vabaq_s32 vabaq_s8 vabaq_u16 vabaq_u32 vabaq_u8 vabal Absolute difference and accumulate long Click here to expand the API list vabal_s16 vabal_s32 vabal_s8 vabal_u16 vabal_u32 vabal_u8 vabal_high_s16 vabal_high_s32 vabal_high_s8 vabal_high_u16 vabal_high_u32 vabal_high_u8 vmax Maximum Click here to expand the API list vmax_f32 vmax_f64 vmax_s16 vmax_s32 vmax_s8 vmax_u16 vmax_u32 vmax_u8 vmaxq_f32 vmaxq_f64 vmaxq_s16 vmaxq_s32 vmaxq_s8 vmaxq_u16 vmaxq_u32 vmaxq_u8 vmaxnm Floating-point maximum number Click here to expand the API list vmaxnm_f32 vmaxnm_f64 vmaxnmq_f32 vmaxnmq_f64 vmaxnmv_f32 vmaxnmvq_f32 vmaxnmvq_f64 vmaxv Maximum across vector Click here to expand the API list vmaxv_f32 vmaxv_s16 vmaxv_s32 vmaxv_s8 vmaxv_u16 vmaxv_u32 vmaxv_u8 vmaxvq_f32 vmaxvq_f64 vmaxvq_s16 vmaxvq_s32 vmaxvq_s8 vmaxvq_u16 vmaxvq_u32 vmaxvq_u8 vmin Minimum Click here to expand the API list vmin_f32 vmin_f64 vmin_s16 vmin_s32 vmin_s8 vmin_u16 vmin_u32 vmin_u8 vminq_f32 vminq_f64 vminq_s16 vminq_s32 vminq_s8 vminq_u16 vminq_u32 vminq_u8 vminnm Floating-point minimum number Click here to expand the API list vminnm_f32 vminnm_f64 vminnmq_f32 vminnmq_f64 vminnmv_f32 vminnmvq_f32 vminnmvq_f64 vminv Minimum across vector Click here to expand the API list vminv_f32 vminv_s16 vminv_s32 vminv_s8 vminv_u16 vminv_u32 vminv_u8 vminvq_f32 vminvq_f64 vminvq_s16 vminvq_s32 vminvq_s8 vminvq_u16 vminvq_u32 vminvq_u8 vabs Absolute value Click here to expand the API list vabs_f32 vabs_f64 vabs_s16 vabs_s32 vabs_s64 vabs_s8 vabsq_f32 vabsq_f64 vabsq_s16 vabsq_s32 vabsq_s64 vabsq_s8 vabsd_s64 vqabs Saturating absolute value Click here to expand the API list vqabs_s16 vqabs_s32 vqabs_s64 vqabs_s8 vqabsq_s16 vqabsq_s32 vqabsq_s64 vqabsq_s8 vqabsb_s8 vqabsh_s16 vqabss_s32 vqabsd_s64 vneg Negate Click here to expand the API list vneg_f32 vneg_f64 vneg_s16 vneg_s32 vneg_s64 vneg_s8 vnegd_s64 vnegq_f32 vnegq_f64 vnegq_s16 vnegq_s32 vnegq_s64 vnegq_s8 vqneg Saturating negate Click here to expand the API list vqneg_s16 vqneg_s32 vqneg_s64 vqneg_s8 vqnegq_s16 vqnegq_s32 vqnegq_s64 vqnegq_s8 vqnegb_s8 vqnegh_s16 vqnegs_s32 vqnegd_s64 vcls Count leading sign bits Click here to expand the API list vcls_s16 vcls_s32 vcls_s8 vclsq_s16 vclsq_s32 vclsq_s8 vclz Count leading zero bits Click here to expand the API list vclz_s16 vclz_s32 vclz_s8 vclz_u16 vclz_u32 vclz_u8 vclzq_s16 vclzq_s32 vclzq_s8 vclzq_u16 vclzq_u32 vclzq_u8 vcnt Population count per byte Click here to expand the API list vcnt_s8 vcnt_u8 vcntq_s8 vcntq_u8 vrecpe Reciprocal estimate Click here to expand the API list vrecpe_f32 vrecpe_f64 vrecpe_u32 vrecpeq_f32 vrecpeq_f64 vrecpeq_u32 vrecpes_f32 vrecped_f64 vrecps Reciprocal step Click here to expand the API list vrecps_f32 vrecps_f64 vrecpsq_f32 vrecpsq_f64 vrecpss_f32 vrecpsd_f64 vrecpx Floating-point reciprocal exponent Click here to expand the API list vrecpxd_f64 vrecpxs_f32 vrsqrte Reciprocal square root estimate Click here to expand the API list vrsqrte_f32 vrsqrte_f64 vrsqrte_u32 vrsqrteq_f32 vrsqrteq_f64 vrsqrteq_u32 vrsqrtes_f32 vrsqrted_f64 vrsqrts Reciprocal square root step Click here to expand the API list vrsqrts_f32 vrsqrts_f64 vrsqrtsq_f32 vrsqrtsq_f64 vrsqrtss_f32 vrsqrtsd_f64 vmovn Extract narrow Click here to expand the API list vmovn_s16 vmovn_s32 vmovn_s64 vmovn_u16 vmovn_u32 vmovn_u64 vmovn_high_s16 vmovn_high_s32 vmovn_high_s64 vmovn_high_u16 vmovn_high_u32 vmovn_high_u64 vmovl Extract long Click here to expand the API list vmovl_s16 vmovl_s32 vmovl_s8 vmovl_u16 vmovl_u32 vmovl_u8 vmovl_high_s16 vmovl_high_s32 vmovl_high_s8 vmovl_high_u16 vmovl_high_u32 vmovl_high_u8 vqmovn Saturating extract narrow Click here to expand the API list vqmovn_s16 vqmovn_s32 vqmovn_s64 vqmovn_u16 vqmovn_u32 vqmovn_u64 vqmovn_high_s16 vqmovn_high_s32 vqmovn_high_s64 vqmovn_high_u16 vqmovn_high_u32 vqmovn_high_u64 vqmovnh_s16 vqmovnh_u16 vqmovns_s32 vqmovns_u32 vqmovnd_s64 vqmovnd_u64 vqmovun Signed saturating extract unsigned narrow Click here to expand the API list vqmovun_s16 vqmovun_s32 vqmovun_s64 vqmovun_high_s16 vqmovun_high_s32 vqmovun_high_s64 vqmovunh_s16 vqmovuns_s32 vqmovund_s64 Comparison Operation Description APIs vceq Compare bitwise equal Click here to expand the API list vceq_f32 vceq_f64 vceq_s16 vceq_s32 vceq_s64 vceq_s8 vceq_u16 vceq_u32 vceq_u64 vceq_u8 vceqq_f32 vceqq_f64 vceqq_s16 vceqq_s32 vceqq_s64 vceqq_s8 vceqq_u16 vceqq_u32 vceqq_u64 vceqq_u8 vceqs_f32 vceqd_f64 vceqd_s64 vceqd_u64 vceqz Compare bitwise equal to zero Click here to expand the API list vceqz_f32 vceqz_f64 vceqz_s16 vceqz_s32 vceqz_s64 vceqz_s8 vceqz_u16 vceqz_u32 vceqz_u64 vceqz_u8 vceqzq_f32 vceqzq_f64 vceqzq_s16 vceqzq_s32 vceqzq_s64 vceqzq_s8 vceqzq_u16 vceqzq_u32 vceqzq_u64 vceqzq_u8 vceqzs_f32 vceqzd_f64 vceqzd_s64 vceqzd_u64 vcge Compare greater than or equal Click here to expand the API list vcge_f32 vcge_f64 vcge_s16 vcge_s32 vcge_s64 vcge_s8 vcge_u16 vcge_u32 vcge_u64 vcge_u8 vcgeq_f32 vcgeq_f64 vcgeq_s16 vcgeq_s32 vcgeq_s64 vcgeq_s8 vcgeq_u16 vcgeq_u32 vcgeq_u64 vcgeq_u8 vcges_f32 vcged_f64 vcged_s64 vcged_u64 vcgez Compare greater than or equal to zero Click here to expand the API list vcgez_f32 vcgez_f64 vcgez_s16 vcgez_s32 vcgez_s64 vcgez_s8 vcgezq_f32 vcgezq_f64 vcgezq_s16 vcgezq_s32 vcgezq_s64 vcgezq_s8 vcgezs_f32 vcgezd_f64 vcgezd_s64 vcle Compare less than or equal Click here to expand the API list vcle_f32 vcle_f64 vcle_s16 vcle_s32 vcle_s64 vcle_s8 vcle_u16 vcle_u32 vcle_u64 vcle_u8 vcleq_f32 vcleq_f64 vcleq_s16 vcleq_s32 vcleq_s64 vcleq_s8 vcleq_u16 vcleq_u32 vcleq_u64 vcleq_u8 vcles_f32 vcled_f64 vcled_s64 vcled_u64 vclez Compare less than or equal to zero Click here to expand the API list vclez_f32 vclez_f64 vclez_s16 vclez_s32 vclez_s64 vclez_s8 vclezq_f32 vclezq_f64 vclezq_s16 vclezq_s32 vclezq_s64 vclezq_s8 vclezs_f32 vclezd_f64 vclezd_s64 vcgt Compare greater than Click here to expand the API list vcgt_f32 vcgt_f64 vcgt_s16 vcgt_s32 vcgt_s64 vcgt_s8 vcgt_u16 vcgt_u32 vcgt_u64 vcgt_u8 vcgtq_f32 vcgtq_f64 vcgtq_s16 vcgtq_s32 vcgtq_s64 vcgtq_s8 vcgtq_u16 vcgtq_u32 vcgtq_u64 vcgtq_u8 vcgts_f32 vcgtd_f64 vcgtd_s64 vcgtd_u64 vcgtz Compare greater than zero Click here to expand the API list vcgtz_f32 vcgtz_f64 vcgtz_s16 vcgtz_s32 vcgtz_s64 vcgtz_s8 vcgtzq_f32 vcgtzq_f64 vcgtzq_s16 vcgtzq_s32 vcgtzq_s64 vcgtzq_s8 vcgtzs_f32 vcgtzd_f64 vcgtzd_s64 vclt Compare less than Click here to expand the API list vclt_f32 vclt_f64 vclt_s16 vclt_s32 vclt_s64 vclt_s8 vclt_u16 vclt_u32 vclt_u64 vclt_u8 vcltq_f32 vcltq_f64 vcltq_s16 vcltq_s32 vcltq_s64 vcltq_s8 vcltq_u16 vcltq_u32 vcltq_u64 vcltq_u8 vclts_f32 vcltd_f64 vcltd_s64 vcltd_u64 vcltz Compare less than zero Click here to expand the API list vcltz_f32 vcltz_f64 vcltz_s16 vcltz_s32 vcltz_s64 vcltz_s8 vcltzq_f32 vcltzq_f64 vcltzq_s16 vcltzq_s32 vcltzq_s64 vcltzq_s8 vcltzs_f32 vcltzd_f64 vcltzd_s64 vcage Floating-point absolute compare greater than or equal Click here to expand the API list vcage_f32 vcage_f64 vcageq_f32 vcageq_f64 vcages_f32 vcaged_f64 vcagt Floating-point absolute compare greater than Click here to expand the API list vcagt_f32 vcagt_f64 vcagtq_f32 vcagtq_f64 vcagts_f32 vcagtd_f64 vcale Floating-point absolute compare less than or equal Click here to expand the API list vcale_f32 vcale_f64 vcaleq_f32 vcaleq_f64 vcales_f32 vcaled_f64 vcalt Floating-point absolute compare less than Click here to expand the API list vcalt_f32 vcalt_f64 vcaltq_f32 vcaltq_f64 vcalts_f32 vcaltd_f64 Bitwise Operation Description APIs vtst Test bits nonzero Click here to expand the API list vtst_s16 vtst_s32 vtst_s64 vtst_s8 vtst_u16 vtst_u32 vtst_u64 vtst_u8 vtstd_s64 vtstd_u64 vtstq_s16 vtstq_s32 vtstq_s64 vtstq_s8 vtstq_u16 vtstq_u32 vtstq_u64 vtstq_u8 vmvn Bitwise NOT Click here to expand the API list vmvn_s16 vmvn_s32 vmvn_s8 vmvn_u16 vmvn_u32 vmvn_u8 vmvnq_s16 vmvnq_s32 vmvnq_s8 vmvnq_u16 vmvnq_u32 vmvnq_u8 vand Bitwise AND Click here to expand the API list vand_s16 vand_s32 vand_s64 vand_s8 vand_u16 vand_u32 vand_u64 vand_u8 vandq_s16 vandq_s32 vandq_s64 vandq_s8 vandq_u16 vandq_u32 vandq_u64 vandq_u8 vorr Bitwise OR Click here to expand the API list vorr_s16 vorr_s32 vorr_s64 vorr_s8 vorr_u16 vorr_u32 vorr_u64 vorr_u8 vorrq_s16 vorrq_s32 vorrq_s64 vorrq_s8 vorrq_u16 vorrq_u32 vorrq_u64 vorrq_u8 vorn Bitwise OR NOT Click here to expand the API list vorn_s16 vorn_s32 vorn_s64 vorn_s8 vorn_u16 vorn_u32 vorn_u64 vorn_u8 vornq_s16 vornq_s32 vornq_s64 vornq_s8 vornq_u16 vornq_u32 vornq_u64 vornq_u8 veor Bitwise exclusive OR Click here to expand the API list veor_s16 veor_s32 veor_s64 veor_s8 veor_u16 veor_u32 veor_u64 veor_u8 veorq_s16 veorq_s32 veorq_s64 veorq_s8 veorq_u16 veorq_u32 veorq_u64 veorq_u8 vbic Bitwise bit clear Click here to expand the API list vbic_s16 vbic_s32 vbic_s64 vbic_s8 vbic_u16 vbic_u32 vbic_u64 vbic_u8 vbicq_s16 vbicq_s32 vbicq_s64 vbicq_s8 vbicq_u16 vbicq_u32 vbicq_u64 vbicq_u8 vbsl Bitwise select Click here to expand the API list vbsl_f32 vbsl_f64 vbsl_s16 vbsl_s32 vbsl_s64 vbsl_s8 vbsl_u16 vbsl_u32 vbsl_u64 vbsl_u8 vbslq_f32 vbslq_f64 vbslq_s16 vbslq_s32 vbslq_s64 vbslq_s8 vbslq_u16 vbslq_u32 vbslq_u64 vbslq_u8 Shift Operation Description APIs vshl Shift left (register) Click here to expand the API list vshl_s16 vshl_s32 vshl_s64 vshl_s8 vshl_u16 vshl_u32 vshl_u64 vshl_u8 vshlq_s16 vshlq_s32 vshlq_s64 vshlq_s8 vshlq_u16 vshlq_u32 vshlq_u64 vshlq_u8 vshld_s64 vshld_u64 vqshl Saturating shift left (register) Click here to expand the API list vqshl_s16 vqshl_s32 vqshl_s64 vqshl_s8 vqshl_u16 vqshl_u32 vqshl_u64 vqshl_u8 vqshlq_s16 vqshlq_s32 vqshlq_s64 vqshlq_s8 vqshlq_u16 vqshlq_u32 vqshlq_u64 vqshlq_u8 vqshlb_s8 vqshlb_u8 vqshlh_s16 vqshlh_u16 vqshls_s32 vqshls_u32 vqshld_s64 vqshld_u64 vqshl_n Saturating shift left (immediate) Click here to expand the API list vqshl_n_s16 vqshl_n_s32 vqshl_n_s64 vqshl_n_s8 vqshl_n_u16 vqshl_n_u32 vqshl_n_u64 vqshl_n_u8 vqshlq_n_s16 vqshlq_n_s32 vqshlq_n_s64 vqshlq_n_s8 vqshlq_n_u16 vqshlq_n_u32 vqshlq_n_u64 vqshlq_n_u8 vqshlb_n_s8 vqshlb_n_u8 vqshlh_n_s16 vqshlh_n_u16 vqshls_n_s32 vqshls_n_u32 vqshld_n_s64 vqshld_n_u64 vqshlu_n Saturating shift left unsigned (immediate) Click here to expand the API list vqshlu_n_s16 vqshlu_n_s32 vqshlu_n_s64 vqshlu_n_s8 vqshlub_n_s8 vqshlud_n_s64 vqshluh_n_s16 vqshluq_n_s16 vqshluq_n_s32 vqshluq_n_s64 vqshluq_n_s8 vqshlus_n_s32 vrshl Rounding shift left (register) Click here to expand the API list vrshl_s16 vrshl_s32 vrshl_s64 vrshl_s8 vrshl_u16 vrshl_u32 vrshl_u64 vrshl_u8 vrshlq_s16 vrshlq_s32 vrshlq_s64 vrshlq_s8 vrshlq_u16 vrshlq_u32 vrshlq_u64 vrshlq_u8 vrshld_s64 vrshld_u64 vqrshl Saturating rounding shift left (register) Click here to expand the API list vqrshl_s16 vqrshl_s32 vqrshl_s64 vqrshl_s8 vqrshl_u16 vqrshl_u32 vqrshl_u64 vqrshl_u8 vqrshlq_s16 vqrshlq_s32 vqrshlq_s64 vqrshlq_s8 vqrshlq_u16 vqrshlq_u32 vqrshlq_u64 vqrshlq_u8 vqrshlb_s8 vqrshlb_u8 vqrshlh_s16 vqrshlh_u16 vqrshls_s32 vqrshls_u32 vqrshld_s64 vqrshld_u64 vshl_n Shift left (immediate) Click here to expand the API list vshl_n_s16 vshl_n_s32 vshl_n_s64 vshl_n_s8 vshl_n_u16 vshl_n_u32 vshl_n_u64 vshl_n_u8 vshlq_n_s16 vshlq_n_s32 vshlq_n_s64 vshlq_n_s8 vshlq_n_u16 vshlq_n_u32 vshlq_n_u64 vshlq_n_u8 vshld_n_s64 vshld_n_u64 vshll_n Shift left long (immediate) Click here to expand the API list vshll_n_s16 vshll_n_s32 vshll_n_s8 vshll_n_u16 vshll_n_u32 vshll_n_u8 vshll_high_n_s16 vshll_high_n_s32 vshll_high_n_s8 vshll_high_n_u16 vshll_high_n_u32 vshll_high_n_u8 vshr_n Shift right (immediate) Click here to expand the API list vshr_n_s16 vshr_n_s32 vshr_n_s64 vshr_n_s8 vshr_n_u16 vshr_n_u32 vshr_n_u64 vshr_n_u8 vshrq_n_s16 vshrq_n_s32 vshrq_n_s64 vshrq_n_s8 vshrq_n_u16 vshrq_n_u32 vshrq_n_u64 vshrq_n_u8 vshrd_n_s64 vshrd_n_u64 vrshr_n Rounding right left (register) Click here to expand the API list vrshr_n_s16 vrshr_n_s32 vrshr_n_s64 vrshr_n_s8 vrshr_n_u16 vrshr_n_u32 vrshr_n_u64 vrshr_n_u8 vrshrq_n_s16 vrshrq_n_s32 vrshrq_n_s64 vrshrq_n_s8 vrshrq_n_u16 vrshrq_n_u32 vrshrq_n_u64 vrshrq_n_u8 vrshrd_n_s64 vrshrd_n_u64 vshrn_n Shift right narrow (immediate) Click here to expand the API list vshrn_n_s16 vshrn_n_s32 vshrn_n_s64 vshrn_n_u16 vshrn_n_u32 vshrn_n_u64 vshrn_high_n_s16 vshrn_high_n_s32 vshrn_high_n_s64 vshrn_high_n_u16 vshrn_high_n_u32 vshrn_high_n_u64 vqshrun_n Signed saturating shift right unsigned narrow (immediate) Click here to expand the API list vqshrun_n_s16 vqshrun_n_s32 vqshrun_n_s64 vqshrunh_n_s16 vqshruns_n_s32 vqshrund_n_s64 vqshrun_high_n_s16 vqshrun_high_n_s32 vqshrun_high_n_s64 vqrshrun_n Signed saturating rounded shift right unsigned narrow (immediate) Click here to expand the API list vqrshrun_n_s16 vqrshrun_n_s32 vqrshrun_n_s64 vqrshrunh_n_s16 vqrshruns_n_s32 vqrshrund_n_s64 vqrshrun_high_n_s16 vqrshrun_high_n_s32 vqrshrun_high_n_s64 vqshrn_n Signed saturating shift right narrow (immediate) Click here to expand the API list vqshrn_n_s16 vqshrn_n_s32 vqshrn_n_s64 vqshrn_n_u16 vqshrn_n_u32 vqshrn_n_u64 vqshrnh_n_s16 vqshrnh_n_u16 vqshrns_n_s32 vqshrns_n_u32 vqshrnd_n_s64 vqshrnd_n_u64 vqshrn_high_n_s16 vqshrn_high_n_s32 vqshrn_high_n_s64 vqshrn_high_n_u16 vqshrn_high_n_u32 vqshrn_high_n_u64 vrshrn_n Rounding shift right narrow (immediate) Click here to expand the API list vrshrn_n_s16 vrshrn_n_s32 vrshrn_n_s64 vrshrn_n_u16 vrshrn_n_u32 vrshrn_n_u64 vrshrn_high_n_s16 vrshrn_high_n_s32 vrshrn_high_n_s64 vrshrn_high_n_u16 vrshrn_high_n_u32 vrshrn_high_n_u64 vqrshrn_n Signed saturating rounded shift right narrow (immediate) Click here to expand the API list vqrshrn_n_s16 vqrshrn_n_s32 vqrshrn_n_s64 vqrshrn_n_u16 vqrshrn_n_u32 vqrshrn_n_u64 vqrshrnh_n_s16 vqrshrnh_n_u16 vqrshrns_n_s32 vqrshrns_n_u32 vqrshrnd_n_s64 vqrshrnd_n_u64 vqrshrn_high_n_s16 vqrshrn_high_n_s32 vqrshrn_high_n_s64 vqrshrn_high_n_u16 vqrshrn_high_n_u32 vqrshrn_high_n_u64 vsra_n Signed shift right and accumulate (immediate) Click here to expand the API list vsra_n_s16 vsra_n_s32 vsra_n_s64 vsra_n_s8 vsra_n_u16 vsra_n_u32 vsra_n_u64 vsra_n_u8 vsraq_n_s16 vsraq_n_s32 vsraq_n_s64 vsraq_n_s8 vsraq_n_u16 vsraq_n_u32 vsraq_n_u64 vsraq_n_u8 vsrad_n_s64 vsrad_n_u64 vrsra_n Signed rounding shift right and accumulate (immediate) Click here to expand the API list vrsra_n_s16 vrsra_n_s32 vrsra_n_s64 vrsra_n_s8 vrsra_n_u16 vrsra_n_u32 vrsra_n_u64 vrsra_n_u8 vrsraq_n_s16 vrsraq_n_s32 vrsraq_n_s64 vrsraq_n_s8 vrsraq_n_u16 vrsraq_n_u32 vrsraq_n_u64 vrsraq_n_u8 vrsrad_n_s64 vrsrad_n_u64 vsri_n Shift right and insert (immediate) Click here to expand the API list vsri_n_s16 vsri_n_s32 vsri_n_s64 vsri_n_s8 vsri_n_u16 vsri_n_u32 vsri_n_u64 vsri_n_u8 vsriq_n_s16 vsriq_n_s32 vsriq_n_s64 vsriq_n_s8 vsriq_n_u16 vsriq_n_u32 vsriq_n_u64 vsriq_n_u8 vsrid_n_s64 vsrid_n_u64 vsli_n Shift left and insert (immediate) Click here to expand the API list vsli_n_s16 vsli_n_s32 vsli_n_s64 vsli_n_s8 vsli_n_u16 vsli_n_u32 vsli_n_u64 vsli_n_u8 vsliq_n_s16 vsliq_n_s32 vsliq_n_s64 vsliq_n_s8 vsliq_n_u16 vsliq_n_u32 vsliq_n_u64 vsliq_n_u8 vslid_n_s64 vslid_n_u64 Floating-point Operation Description APIs vcvt Convert to/from another precision or fixed point, rounding towards zero Click here to expand the API list vcvt_f32_f64 vcvt_f32_s32 vcvt_f32_u32 vcvt_f64_f32 vcvt_f64_s64 vcvt_f64_u64 vcvt_s32_f32 vcvt_s64_f64 vcvt_u32_f32 vcvt_u64_f64 vcvtq_f32_s32 vcvtq_f32_u32 vcvtq_f64_s64 vcvtq_f64_u64 vcvtq_s32_f32 vcvtq_s64_f64 vcvtq_u32_f32 vcvtq_u64_f64 vcvts_f32_s32 vcvts_f32_u32 vcvts_s32_f32 vcvts_u32_f32 vcvtd_f64_s64 vcvtd_f64_u64 vcvtd_s64_f64 vcvtd_u64_f64 vcvt_high_f32_f64 vcvt_high_f64_f32 vcvta Convert to integer, rounding to nearest with ties to away Click here to expand the API list vcvta_s32_f32 vcvta_s64_f64 vcvta_u32_f32 vcvta_u64_f64 vcvtad_s64_f64 vcvtad_u64_f64 vcvtaq_s32_f32 vcvtaq_s64_f64 vcvtaq_u32_f32 vcvtaq_u64_f64 vcvtas_s32_f32 vcvtas_u32_f32 vcvtm Convert to integer, rounding towards minus infinity Click here to expand the API list vcvtm_s32_f32 vcvtm_s64_f64 vcvtm_u32_f32 vcvtm_u64_f64 vcvtmq_s32_f32 vcvtmq_s64_f64 vcvtmq_u32_f32 vcvtmq_u64_f64 vcvtms_s32_f32 vcvtms_u32_f32 vcvtmd_s64_f64 vcvtmd_u64_f64 vcvtn Convert to integer, rounding to nearest with ties to even Click here to expand the API list vcvtn_s32_f32 vcvtn_s64_f64 vcvtn_u32_f32 vcvtn_u64_f64 vcvtnq_s32_f32 vcvtnq_s64_f64 vcvtnq_u32_f32 vcvtnq_u64_f64 vcvtns_s32_f32 vcvtns_u32_f32 vcvtnd_s64_f64 vcvtnd_u64_f64 vcvtp Convert to integer, rounding towards plus infinity Click here to expand the API list vcvtp_s32_f32 vcvtp_s64_f64 vcvtp_u32_f32 vcvtp_u64_f64 vcvtpq_s32_f32 vcvtpq_s64_f64 vcvtpq_u32_f32 vcvtpq_u64_f64 vcvtps_s32_f32 vcvtps_u32_f32 vcvtpd_s64_f64 vcvtpd_u64_f64 vcvtx Convert to lower precision, rounding to nearest with ties to odd Click here to expand the API list vcvtx_f32_f64 vcvtx_high_f32_f64 vcvtxd_f32_f64 vcvt_n Convert to/from fixed point, rounding towards zero Click here to expand the API list vcvt_n_f32_s32 vcvt_n_f32_u32 vcvt_n_f64_s64 vcvt_n_f64_u64 vcvt_n_s32_f32 vcvt_n_s64_f64 vcvt_n_u32_f32 vcvt_n_u64_f64 vcvtq_n_f32_s32 vcvtq_n_f32_u32 vcvtq_n_f64_s64 vcvtq_n_f64_u64 vcvtq_n_s32_f32 vcvtq_n_s64_f64 vcvtq_n_u32_f32 vcvtq_n_u64_f64 vcvts_n_f32_s32 vcvts_n_f32_u32 vcvts_n_s32_f32 vcvts_n_u32_f32 vcvtd_n_f64_s64 vcvtd_n_f64_u64 vcvtd_n_s64_f64 vcvtd_n_u64_f64 vrnd Round to Integral, toward zero Click here to expand the API list vrnd_f32 vrnd_f64 vrndq_f32 vrndq_f64 vrnda Round to Integral, with ties to away Click here to expand the API list vrnda_f32 vrnda_f64 vrndaq_f32 vrndaq_f64 vrndi Round to Integral, using current rounding mode Click here to expand the API list vrndi_f32 vrndi_f64 vrndiq_f32 vrndiq_f64 vrndm Round to Integral, towards minus infinity Click here to expand the API list vrndm_f32 vrndm_f64 vrndmq_f32 vrndmq_f64 vrndn Round to Integral, with ties to even Click here to expand the API list vrndn_f32 vrndn_f64 vrndnq_f32 vrndnq_f64 vrndns_f32 vrndp Round to Integral, towards plus infinity Click here to expand the API list vrndp_f32 vrndp_f64 vrndpq_f32 vrndpq_f64 vrndx Round to Integral exact Click here to expand the API list vrndx_f32 vrndx_f64 vrndxq_f32 vrndxq_f64 Load and store Operation Description APIs vld1 Load vector from memory Click here to expand the API list vld1_f32 vld1_f64 vld1_s16 vld1_s32 vld1_s64 vld1_s8 vld1_u16 vld1_u32 vld1_u64 vld1_u8 vld1q_f32 vld1q_f64 vld1q_s16 vld1q_s32 vld1q_s64 vld1q_s8 vld1q_u16 vld1q_u32 vld1q_u64 vld1q_u8 vst1 Store vector to memory Click here to expand the API list vst1_f32 vst1_f64 vst1_s16 vst1_s32 vst1_s64 vst1_s8 vst1_u16 vst1_u32 vst1_u64 vst1_u8 vst1q_f32 vst1q_f64 vst1q_s16 vst1q_s32 vst1q_s64 vst1q_s8 vst1q_u16 vst1q_u32 vst1q_u64 vst1q_u8 vget_lane Get vector element Click here to expand the API list vget_lane_f32 vget_lane_f64 vget_lane_s16 vget_lane_s32 vget_lane_s64 vget_lane_s8 vget_lane_u16 vget_lane_u32 vget_lane_u64 vget_lane_u8 vgetq_lane_f32 vgetq_lane_f64 vgetq_lane_s16 vgetq_lane_s32 vgetq_lane_s64 vgetq_lane_s8 vgetq_lane_u16 vgetq_lane_u32 vgetq_lane_u64 vgetq_lane_u8 vset_lane Set vector element Click here to expand the API list vset_lane_f32 vset_lane_f64 vset_lane_s16 vset_lane_s32 vset_lane_s64 vset_lane_s8 vset_lane_u16 vset_lane_u32 vset_lane_u64 vset_lane_u8 vsetq_lane_f32 vsetq_lane_f64 vsetq_lane_s16 vsetq_lane_s32 vsetq_lane_s64 vsetq_lane_s8 vsetq_lane_u16 vsetq_lane_u32 vsetq_lane_u64 vsetq_lane_u8 Permutation Operation Description APIs vext Extract vector from pair of vectors Click here to expand the API list vext_f32 vext_f64 vext_s16 vext_s32 vext_s64 vext_s8 vext_u16 vext_u32 vext_u64 vext_u8 vextq_f32 vextq_f64 vextq_s16 vextq_s32 vextq_s64 vextq_s8 vextq_u16 vextq_u32 vextq_u64 vextq_u8 vtbl1 Table vector Lookup Click here to expand the API list vtbl1_s8 vtbl1_u8 vtbx1 Table vector lookup extension Click here to expand the API list vtbx1_s8 vtbx1_u8 vqtbl1 Table vector Lookup Click here to expand the API list vqtbl1_s8 vqtbl1_u8 vqtbl1q_s8 vqtbl1q_u8 vqtbx1 Table vector lookup extension Click here to expand the API list vqtbx1_s8 vqtbx1_u8 vqtbx1q_s8 vqtbx1q_u8 vrbit Reverse bit order Click here to expand the API list vrbit_s8 vrbit_u8 vrbitq_s8 vrbitq_u8 vrev16 Reverse elements in 16-bit halfwords Click here to expand the API list vrev16_s8 vrev16_u8 vrev16q_s8 vrev16q_u8 vrev32 Reverse elements in 32-bit words Click here to expand the API list vrev32_s16 vrev32_s8 vrev32_u16 vrev32_u8 vrev32q_s16 vrev32q_s8 vrev32q_u16 vrev32q_u8 vrev64 Reverse elements in 64-bit doublewords Click here to expand the API list vrev64_f32 vrev64_s16 vrev64_s32 vrev64_s8 vrev64_u16 vrev64_u32 vrev64_u8 vrev64q_f32 vrev64q_s16 vrev64q_s32 vrev64q_s8 vrev64q_u16 vrev64q_u32 vrev64q_u8 vtrn1 Transpose vectors (primary) Click here to expand the API list vtrn1_f32 vtrn1_s16 vtrn1_s32 vtrn1_s8 vtrn1_u16 vtrn1_u32 vtrn1_u8 vtrn1q_f32 vtrn1q_f64 vtrn1q_s16 vtrn1q_s32 vtrn1q_s64 vtrn1q_s8 vtrn1q_u16 vtrn1q_u32 vtrn1q_u64 vtrn1q_u8 vtrn2 Transpose vectors (secondary) Click here to expand the API list vtrn2_f32 vtrn2_s16 vtrn2_s32 vtrn2_s8 vtrn2_u16 vtrn2_u32 vtrn2_u8 vtrn2q_f32 vtrn2q_f64 vtrn2q_s16 vtrn2q_s32 vtrn2q_s64 vtrn2q_s8 vtrn2q_u16 vtrn2q_u32 vtrn2q_u64 vtrn2q_u8 vzip1 Zip vectors (primary) Click here to expand the API list vzip1_f32 vzip1_s16 vzip1_s32 vzip1_s8 vzip1_u16 vzip1_u32 vzip1_u8 vzip1q_f32 vzip1q_f64 vzip1q_s16 vzip1q_s32 vzip1q_s64 vzip1q_s8 vzip1q_u16 vzip1q_u32 vzip1q_u64 vzip1q_u8 vzip2 Zip vectors (secondary) Click here to expand the API list vzip2_f32 vzip2_s16 vzip2_s32 vzip2_s8 vzip2_u16 vzip2_u32 vzip2_u8<br/vzip2q_f32 vzip2q_f64 vzip2q_s16 vzip2q_s32 vzip2q_s64 vzip2q_s8 vzip2q_u16 vzip2q_u32 vzip2q_u64 vzip2q_u8 vuzp1 Unzip vectors (primary) Click here to expand the API list vuzp1_f32 vuzp1_s16 vuzp1_s32 vuzp1_s8 vuzp1_u16 vuzp1_u32 vuzp1_u8 vuzp1q_f32 vuzp1q_f64 vuzp1q_s16 vuzp1q_s32 vuzp1q_s64 vuzp1q_s8 vuzp1q_u16 vuzp1q_u32 vuzp1q_u64 vuzp1q_u8 vuzp2 Unzip vectors (secondary) Click here to expand the API list vuzp2_f32 vuzp2_s16 vuzp2_s32 vuzp2_s8 vuzp2_u16 vuzp2_u32 vuzp2_u8 vuzp2q_f32 vuzp2q_f64 vuzp2q_s16 vuzp2q_s32 vuzp2q_s64 vuzp2q_s8 vuzp2q_u16 vuzp2q_u32 vuzp2q_u64 vuzp2q_u8 Cryptographic Operation APIs CRC32 Click here to expand the API list __crc32b __crc32cb __crc32cd __crc32ch __crc32cw __crc32d __crc32h __crc32w SHA1 Click here to expand the API list vsha1cq_u32 vsha1h_u32 vsha1mq_u32 vsha1pq_u32 vsha1su0q_u32 vsha1su1q_u32 SHA256 Click here to expand the API list vsha256h2q_u32 vsha256hq_u32 vsha256su0q_u32 vsha256su1q_u32 AES Click here to expand the API list vaesdq_u8 vaeseq_u8 vaesimcq_u8 vaesmcq_u8 Miscellaneous Operation Description APIs vsqrt Square root Click here to expand the API list vsqrt_f32 vsqrt_f64 vsqrtq_f32 vsqrtq_f64 vdot Dot product Click here to expand the API list vdot_s32 vdot_u32 vdotq_s32 vdotq_u32 vdot_lane Dot product Click here to expand the API list vdot_lane_s32 vdot_lane_u32 vdot_laneq_s32 vdot_laneq_u32 vdotq_lane_s32 vdotq_lane_u32 vdotq_laneq_s32 vdotq_laneq_u32 Additional resources Processor specific SIMD extensions"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-processors.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics-processors.html",
    "title": "Processor specific SIMD extensions | Inventory System",
    "summary": "Processor specific SIMD extensions Burst exposes all Intel SIMD intrinsics from SSE up to and including AVX2 in the Unity.Burst.Intrinsics.X86 family of nested classes. The Unity.Burst.Intrinsics.Arm.Neon class provides intrinsics for Arm Neon's Armv7, Armv8, and Armv8.2 (RDMA, crypto, dotprod). Organizing your code You should statically import these intrinsics because they contain plain static functions: using static Unity.Burst.Intrinsics.X86; using static Unity.Burst.Intrinsics.X86.Sse; using static Unity.Burst.Intrinsics.X86.Sse2; using static Unity.Burst.Intrinsics.X86.Sse3; using static Unity.Burst.Intrinsics.X86.Ssse3; using static Unity.Burst.Intrinsics.X86.Sse4_1; using static Unity.Burst.Intrinsics.X86.Sse4_2; using static Unity.Burst.Intrinsics.X86.Popcnt; using static Unity.Burst.Intrinsics.X86.Avx; using static Unity.Burst.Intrinsics.X86.Avx2; using static Unity.Burst.Intrinsics.X86.Fma; using static Unity.Burst.Intrinsics.X86.F16C; using static Unity.Burst.Intrinsics.X86.Bmi1; using static Unity.Burst.Intrinsics.X86.Bmi2; using static Unity.Burst.Intrinsics.Arm.Neon; Burst CPU intrinsics are translated into specific CPU instructions. However, Burst has a special compiler pass which makes sure that your CPU target set in Burst AOT Settings is compatible with the intrinsics used in your code. This ensures you don't try to call unsupported instructions (for example, AArch64 Neon on an Intel CPU or AVX2 instructions on an SSE4 CPU), which causes the process to abort with an \"Invalid instruction\" exception. A compiler error is generated if the check fails. However, if you want to provide several code paths with different CPU targets, or to make sure your intrinsics code is compatible with any target CPU, you can wrap your intrinsics code with the following property checks: IsNeonSupported IsNeonArmv82FeaturesSupported IsNeonCryptoSupported IsNeonDotProdSupported IsNeonRDMASupported For example: if (IsAvx2Supported) { // Code path for AVX2 instructions } else if (IsSse42Supported) { // Code path for SSE4.2 instructions } else if (IsNeonArmv82FeaturesSupported) { // Code path for Armv8.2 Neon instructions } else if (IsNeonSupported) { // Code path for Arm Neon instructions } else { // Fallback path for everything else } These branches don't affect performance. Burst evaluates the IsXXXSupported properties at compile-time and eliminates unsupported branches as dead code, while the active branch stays there without the if check. Later feature levels implicitly include the previous ones, so you should organize tests from most recent to oldest. Burst emits compile-time errors if you've used intrinsics that aren't part of the current compilation target. Burst doesn't bracket these with a feature level test, which helps you to narrow in on what to put inside a feature test. If you run your application in .NET, Mono or IL2CPP without Burst enabled, all the IsXXXSupported properties return false. However, if you skip the test you can still run a reference version of most intrinsics in Mono (exceptions listed below), which is helpful if you need to use the managed debugger. Reference implementations are slow and only intended for managed debugging. Important There isn't a reference managed implementation of Arm Neon intrinsics. This means that you can't use the technique mentioned in the previous paragraph to step through the intrinsics in Mono. FMA intrinsics that operate on doubles don't have a software fallback because of the inherent complexity of emulating fused 64-bit floating point math. Intrinsics use the types v64 (Arm only), v128 and v256, which represent a 64-bit, 128-bit or 256-bit vector respectively. For example, given a NativeArray<float> and a Lut lookup table of v128 shuffle masks, a code fragment like this performs lane left packing, demonstrating the use of vector load/store reinterpretation and direct intrinsic calls: v128 a = Input.ReinterpretLoad<v128>(i); v128 mask = cmplt_ps(a, Limit); int m = movemask_ps(a); v128 packed = shuffle_epi8(a, Lut[m]); Output.ReinterpretStore(outputIndex, packed); outputIndex += popcnt_u32((uint)m); Intel intrinsics The Intel intrinsics API mirrors the C/C++ Intel instrinsics API, with the following differences: All 128-bit vector types (__m128, __m128i and __m128d) are collapsed into v128 All 256-bit vector types (__m256, __m256i and __m256d) are collapsed into v256 All _mm prefixes on instructions and macros are dropped, because C# has namespaces All bitfield constants (for example, rounding mode selection) are replaced with C# bitflag enum values Arm Neon intrinsics The Arm Neon intrinsics API mirrors the Arm C Language Extensions, with the following differences: All vector types are collapsed into v64 and v128, becoming typeless. This means that the vector type must contain expected element types and count when calling an API. The *x2, *x3, *x4 vector types aren't supported. poly* types aren't supported. reinterpret* functions aren't supported (they aren't needed because of the usage of v64 and v128 vector types). Intrinsic usage is only supported on Armv8 (64-bit) hardware. Burst's CPU intrinsics use typeless vectors. Because of this, Burst doesn't perform any type checks. For example, if you call an intrinsic which processes 4 ints on a vector that was initialized with 4 floats, then there's no compiler error. The vector types have fields that represent every element type, in a union-like struct, which gives you flexibility to use these intrinsics in a way that best fits your code. Arm Neon C intrinsics (ACLE) use typed vectors, for example int32x4_t, and has special APIs (for example, reinterpret_\\*) to convert to a vector of another element type. Burst CPU intrinsics vectors are typeless, so these APIs are not needed. The following APIs provide the equivalent functionality: v64 (Arm Neon only) v128 v256 For a categorized index of Arm Neon intrinsics supported in Burst, refer to the Arm Neon intrinsics reference. Additional resources Arm Neon intrinsics reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-burst-intrinsics.html",
    "title": "Burst intrinsics overview | Inventory System",
    "summary": "Burst intrinsics overview Burst provides low level intrinsics in the Unity.Burst.Intrinsics namespace. This is useful if you know how to write single instruction, multiple data (SIMD) assembly code, and you want to get extra performance from Burst code. For most use cases, you won't need to use these. This section contains the following information Topic Description Burst intrinsics Common class Overview of the Burst.Intrinsics.Common class, which provides functionality shared across the hardware targets that Burst supports. DllImport and internal calls Overview of [DllImport], which is for calling native functions. Processor specific SIMD extensions Overview of the Intel and Arm Neon intrinsics. Arm Neon intrinsics reference Reference of the methods in the Burst.Intrinsics.Arm.Neon class. Additional resources C# language support Burst compilation"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-calling-burst-code.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-calling-burst-code.html",
    "title": "Calling Burst-compiled code | Inventory System",
    "summary": "Calling Burst-compiled code You can call Burst-compiled methods direct from managed code. Calling generic methods or methods whose declaring type is generic isn't supported, otherwise the same rules as for function pointers apply. However, you don't need to worry about the extra boiler plate needed for function pointers. The following example shows a Burst-compiled utility class. Because it uses structs, it passes by reference per the function pointer rules. [BurstCompile] public static class MyBurstUtilityClass { [BurstCompile] public static void BurstCompiled_MultiplyAdd(in float4 mula, in float4 mulb, in float4 add, out float4 result) { result = mula * mulb + add; } } Use this method from managed code like so: public class MyMonoBehaviour : MonoBehaviour { void Start() { var mula = new float4(1, 2, 3, 4); var mulb = new float4(-1,1,-1,1); var add = new float4(99,0,0,0); MyBurstUtilityClass.BurstCompiled_MultiplyAdd(mula, mulb, add, out var result); Debug.Log(result); } } If you attach this script to an object and run it, float4(98f, 2f, -3f, 4f) is printed to the log. Code transformation Burst uses IL Post Processing to automatically transform the code into a function pointer and call. For more information, refer to the documentation on Function pointers. To disable the direct call transformation, addDisableDirectCall = true to the BurstCompile options. This prevents the Post Processor from running on the code: [BurstCompile] public static class MyBurstUtilityClass { [BurstCompile(DisableDirectCall = true)] public static void BurstCompiled_MultiplyAdd(in float4 mula, in float4 mulb, in float4 add, out float4 result) { result = mula * mulb + add; } } Additional resources HPC# Overview Function pointers"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-function-pointers.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-function-pointers.html",
    "title": "Function pointers | Inventory System",
    "summary": "Function pointers To work with dynamic functions that process data based on other data states, use FunctionPointer<T>. Because Burst treats delegates as managed objects, you can't use C# delegates to work with dynamic functions. Support details Function pointers don't support generic delegates. Also, avoid wrapping BurstCompiler.CompileFunctionPointer<T> within another open generic method. If you do this, Burst can't apply required attributes to the delegate, perform additional safety analysis, or perform potential optimizations. Argument and return types are subject to the same restrictions as DllImport and internal calls. For more information, refer to the documentation on DllImport and internal calls. Interoperability with IL2CPP Interoperability of function pointers with IL2CPP requires System.Runtime.InteropServices.UnmanagedFunctionPointerAttribute on the delegate. Set the calling convention to CallingConvention.Cdecl. Burst automatically adds this attribute to delegates that are used with BurstCompiler.CompileFunctionPointer<T>. Using function pointers To use function pointers, identify the static functions that you want Burst to compile and do the following: Add a [BurstCompile] attribute to these functions. Add a [BurstCompile] attribute to the containing type. This helps the Burst compiler find the static methods that have the [BurstCompile] attribute. Declare a delegate to create the \"interface\" of these functions. Add a [MonoPInvokeCallbackAttribute] attribute to the functions to make them compatible with IL2CPP. For example: // Instruct Burst to look for static methods with [BurstCompile] attribute [BurstCompile] class EnclosingType { [BurstCompile] [MonoPInvokeCallback(typeof(Process2FloatsDelegate))] public static float MultiplyFloat(float a, float b) => a * b; [BurstCompile] [MonoPInvokeCallback(typeof(Process2FloatsDelegate))] public static float AddFloat(float a, float b) => a + b; // A common interface for both MultiplyFloat and AddFloat methods public delegate float Process2FloatsDelegate(float a, float b); } Compile these function pointers from regular C# code: // Contains a compiled version of MultiplyFloat with Burst FunctionPointer<Process2FloatsDelegate> mulFunctionPointer = BurstCompiler.CompileFunctionPointer<Process2FloatsDelegate>(MultiplyFloat); // Contains a compiled version of AddFloat with Burst FunctionPointer<Process2FloatsDelegate> addFunctionPointer = BurstCompiler.CompileFunctionPointer<Process2FloatsDelegate>(AddFloat); The [MonoPInvokeCallbackAttribute] is available under the AOT namespace. If for any reason it's not available, you can create it locally by declaring it as follows: public class MonoPInvokeCallbackAttribute : Attribute {​ } For more information on [MonoPInvokeCallbackAttribute] and example usage in the iOS context, refer to Callback from native code in the manual. Using function pointers in a job To use the function pointers directly from a job, pass them to the job struct: // Invoke the function pointers from HPC# jobs var resultMul = mulFunctionPointer.Invoke(1.0f, 2.0f); var resultAdd = addFunctionPointer.Invoke(1.0f, 2.0f); Burst compiles function pointers asynchronously for jobs by default. To force a synchronous compilation of function pointers use [BurstCompile(SynchronousCompilation = true)]. Using function pointers in C# code To use these function pointers from regular C# code, cache the FunctionPointer<T>.Invoke property (which is the delegate instance) to a static field to get the best performance: private readonly static Process2FloatsDelegate mulFunctionPointerInvoke = BurstCompiler.CompileFunctionPointer<Process2FloatsDelegate>(MultiplyFloat).Invoke; // Invoke the delegate from C# var resultMul = mulFunctionPointerInvoke(1.0f, 2.0f); Using Burst-compiled function pointers from C# might be slower than their pure C# version counterparts if the function is too small compared to the overhead of P/Invoke interop. Performance considerations Where possible, use a job over a function pointer to run Burst compiled code, because jobs are more performant. Burst provides better aliasing calculations for jobs because the job safety system has more optimizations by default. You also can't pass most of the [NativeContainer] structs like NativeArray directly to function pointers and must use a job struct to do so. Native container structs contain managed objects for safety checks that the Burst compiler can work around when compiling jobs, but not for function pointers. The following example shows a bad example of how to use function pointers in Burst. The function pointer computes math.sqrt from an input pointer and stores it to an output pointer. MyJob feeds this function pointer sources from two NativeArrays which isn't optimal: ///Bad function pointer example [BurstCompile] public class MyFunctionPointers { public unsafe delegate void MyFunctionPointerDelegate(float* input, float* output); [BurstCompile] public static unsafe void MyFunctionPointer(float* input, float* output) { *output = math.sqrt(*input); } } [BurstCompile] struct MyJob : IJobParallelFor { public FunctionPointer<MyFunctionPointers.MyFunctionPointerDelegate> FunctionPointer; [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index) { var inputPtr = (float*)Input.GetUnsafeReadOnlyPtr(); var outputPtr = (float*)Output.GetUnsafePtr(); FunctionPointer.Invoke(inputPtr + index, outputPtr + index); } } This example isn't optimal for the following reasons: Burst can't vectorize the function pointer because it's being fed a single scalar element. This means that 4-8x performance is lost from a lack of vectorization. The MyJob knows that the Input and Output native arrays can't alias, but this information isn't communicated to the function pointer. There is a non-zero overhead to constantly branching to a function pointer somewhere else in memory. To use a function pointer in an optimal way, always process batches of data in the function pointer, like so: [BurstCompile] public class MyFunctionPointers { public unsafe delegate void MyFunctionPointerDelegate(int count, float* input, float* output); [BurstCompile] public static unsafe void MyFunctionPointer(int count, float* input, float* output) { for (int i = 0; i < count; i++) { output[i] = math.sqrt(input[i]); } } } [BurstCompile] struct MyJob : IJobParallelForBatch { public FunctionPointer<MyFunctionPointers.MyFunctionPointerDelegate> FunctionPointer; [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index, int count) { var inputPtr = (float*)Input.GetUnsafeReadOnlyPtr() + index; var outputPtr = (float*)Output.GetUnsafePtr() + index; FunctionPointer.Invoke(count, inputPtr, outputPtr); } } The modified MyFunctionPointer takes a count of elements to process, and loops over the input and output pointers to do a lot of calculations. The MyJob becomes an IJobParallelForBatch, and the count is passed directly into the function pointer. This is better for performance because: Burst vectorizes the MyFunctionPointer call. Burst processes count items per function pointer, so any overhead of calling the function pointer is reduced by count times. For example, if you run a batch of 128, the function pointer overhead is 1/128th per index of what it was previously. Batching results in a 1.53x performance gain over not batching. However, to get the best possible performance, use a job. This gives Burst the most visibility over what you want it to do, and the most opportunities to optimize: [BurstCompile] struct MyJob : IJobParallelFor { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index) { Output[i] = math.sqrt(Input[i]); } } This runs 1.26x faster than the batched function pointer example, and 1.93x faster than the non-batched function pointer examples. Burst has perfect aliasing knowledge and can make the broadest modifications to the above. This code is also a lot simpler than either of the function pointer cases. Additional resources HPC# Overview Calling Burst-compiled code"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-hpc-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-hpc-overview.html",
    "title": "| Inventory System",
    "summary": "HPC# overview Burst uses a high performance subset of C# called High Performance C# (HPC#). Supported C# features in HPC# HPC# supports most expressions and statements in C#. It supports the following: Supported feature Notes Extension methods. Instance methods of structs. Unsafe code and pointer manipulation. Loading from static read-only fields. For more information, see the documentation on Static read-only fields and static constructors. Regular C# control flows. if else switch case for while break continue ref and out parameters fixed statements Some IL opcodes. cpblk initblk sizeof DLLImport and internal calls. For more information, see the documentation on DLLImport and internal calls. try and finally keywords. Burst also supports the associated IDisposable patterns, using and foreach. If an exception happens in Burst, the behavior is different from .NET. In .NET, if an exception occurs inside a try block, control flow goes to the finally block. However, in Burst, if an exception happens inside or outside a try block, the exception throws as if any finally blocks do not exist. Invoking foreach calls is supported by Burst, but there is a foreach edge case that burst currently does not support (see \"Foreach and While\" section for more details). Strings and ProfilerMarker. For more information, see the documentation on Support for Unity Profiler markers. throw expressions. Burst only supports simple throw patterns, for example, throw new ArgumentException(\"Invalid argument\"). When you use simple patterns like this, Burst extracts the static string exception message and includes it in the generated code. Strings and Debug.Log. Only partially supported. For more information, see the documentation on String support and Debug.Log. Burst also provides alternatives for some C# constructions not directly accessible to HPC#: Function pointers as an alternative to using delegates within HPC# Shared static to access static mutable data from both C# and HPC# Exception expressions Burst supports throw expressions for exceptions. Exceptions thrown in the Editor can be caught by managed code, and are reported in the console window. Exceptions thrown in Player builds always cause the application to abort. Thus with Burst you should only use exceptions for exceptional behavior. To ensure that code doesn't end up relying on exceptions for things like general control flow, Burst produces the following warning on code that tries to throw within a method not attributed with [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")]: Burst warning BC1370: An exception was thrown from a function without the correct [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] guard. Exceptions only work in the editor and so should be protected by this guard Foreach and While Burst supports invoking foreach and while. However, there is an edge case which is currently unsupported - methods that take one or more generic collection parameters T: IEnumerable<U> and invoke foreach or while on at least one of the collections in the method body. To illustrate, the following example methods exemplify this limitation: public static void IterateThroughConcreteCollection(NativeArray<int> list) { foreach (var element in list) { // This works } } public static void IterateThroughGenericCollection<S>(S list) where S : struct, IEnumerable<int> { foreach (var element in list) { // This doesn't work } } Note that the uppermost method IterateThroughConcreteCollection()'s parameter is specified to be a concrete collection type, in this case NativeArray<int>. Because it's concrete iterating through it inside the method will compile in Burst. In the method IterateThroughGenericCollection() below it, however, the parameter is specified to be a generic collection type S. Iterating through S inside the method will therefore not compile in Burst. It will instead throw the following error: Can't call the method (method name) on the generic interface object type (object name). This may be because you are trying to do a foreach over a generic collection of type IEnumerable. Unsupported C# features in HPC# HPC# doesn't support the following C# features: Catching exceptions catch in a try/catch. Storing to static fields except via Shared Static. Any methods related to managed objects, for example, string methods. Additional resources Static read-only fields and static constructor support String support C#/.NET type support C#/.NET System namespace support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-language-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-language-support.html",
    "title": "C# language support | Inventory System",
    "summary": "C# language support Burst supports a subset of C#, which is referred to as High Performance C# (HPC#) in the Unity context. Topic Description HPC# overview Understand how HPC# works with Burst. C#/.NET type support Understand the supported C# features. C#/.NET System namespace support Understand what's supported in the System namespace. Static read-only fields and static constructor support Use static read-only fields and static constructors in Burst code. String support Use strings in Burst code. Calling Burst compiled code Call Burst compiled code from managed code. Function pointers Use function pointers to work with dynamic functions. SharedStatic struct Use SharedStatic to share static mutable data. Additional resources Burst instrinsics overview"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-shared-static.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-shared-static.html",
    "title": "SharedStatic struct | Inventory System",
    "summary": "SharedStatic struct Burst has basic support for accessing static readonly data. However, if you want to share static mutable data between C# and HPC#, use the SharedStatic<T> struct. The following example shows accessing an int static field that both C# and HPC# can change: public abstract class MutableStaticTest { public static readonly SharedStatic<int> IntField = SharedStatic<int>.GetOrCreate<MutableStaticTest, IntFieldKey>(); // Define a Key type to identify IntField private class IntFieldKey {} } C# and HPC# can then access this: // Write to a shared static MutableStaticTest.IntField.Data = 5; // Read from a shared static var value = 1 + MutableStaticTest.IntField.Data; When you use SharedStatic<T>, be aware of the following: The T in SharedStatic<T> defines the data type. To identify a static field, provide a context for it. To do this, create a key for both the containing type (for example, MutableStaticTest in the example above), identify the field (for example, IntFieldKey class in the example above) and pass these classes as generic arguments of SharedStatic<int>.GetOrCreate<MutableStaticTest, IntFieldKey>(). Always initialize the shared static field in C# from a static constructor before accessing it from HPC#. If you don't initialize the data before accessing it, it might lead to an undefined initialization state. Additional resources Calling Burst-compiled code"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-static-read-only-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-static-read-only-support.html",
    "title": "Static read-only fields and static constructor support | Inventory System",
    "summary": "Static read-only fields and static constructor support Burst evaluates all static fields and all static constructors at compile time. It evaluates all the static fields and the static constructors for a given struct together. Burst only supports read-only static fields. A static field that isn't read-only in a Burst-compiled struct causes a compilation error. When Burst fails to evaluate any static field or static constructor, all fields and constructors fail for that struct. When compile-time evaluation fails, Burst falls back to compiling all static initialization code into an initialization function that it calls once at runtime. This means that your code needs to be Burst compatible, or it will fail compilation if it fails compile-time evaluation. An exception to this is that there's limited support for initializing static read-only array fields as long as they're initialized from either an array constructor or from static data: static readonly int[] MyArray0 = { 1, 2, 3, .. }; static readonly int[] MyArray1 = new int[10]; Language support Burst doesn't support calling external functions and function pointers. It supports using the following base language with static read-only fields and constructors: Managed arrays Strings Limited intrinsic support: Unity.Burst.BurstCompiler.IsEnabled Unity.Burst.BurstRuntime.GetHashCode32 Unity.Burst.BurstRuntime.GetHashCode64 Vector type construction Limited intrinsic assertion support: UnityEngine.Debug.Assert NUnit.Framework.Assert.AreEqual NUnit.Framework.Assert.AreNotEqual Simple throw patterns. Any exceptions thrown during evaluation become compiler errors. Additional resources String support C#/.NET type support C#/.NET System namespace support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-string-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-string-support.html",
    "title": "String support | Inventory System",
    "summary": "String support Burst supports string usage in the following scenarios: Debug.Log Assigning a string to the FixedString structs that Unity.Collections provides, for example FixedString128Bytes. The System.Runtime.CompilerServices attributes [CallerLineNumber], [CallerMemberName], and [CallerFilePath] on arguments to Burst functions. However, you can only pass the strings directly to calls to Debug.Log. A string can be either: A string literal. For example: \"This is a string literal\". An interpolated string using $\"This is an integer {value} or using string.Format, where the string to format is also a string literal. For example, Burst supports the following constructions: Logging with a string literal: Debug.Log(\"This a string literal\"); Logging using string interpolation: int value = 256; Debug.Log($\"This is an integer value {value}\"); This is the same as using string.Format directly: int value = 256; Debug.Log(string.Format(\"This is an integer value {0}\", value)); Supported Debug.Log methods Burst supports the following Debug.Log methods: Debug.Log(object) Debug.LogWarning(object) Debug.LogError(object) String interpolation support String interpolation has the following restrictions: The string must be a string literal Burst supports the following string.Format methods: string.Format(string, object) string.Format(string, object, object) string.Format(string, object, object, object) string.Format(string, object[]). Use this for a string interpolation that contains more than three arguments, for example $\"{arg1} {arg2} {arg3} {arg4} {arg5}\". In this case, the object[] array needs to be a constant size and no arguments should involve control flows (for example, $\"This is a {(cond ? arg1 : arg2)}\"). The string must only use value types The string must take only built-in type arguments: char boolean byte / sbyte double float short / ushort int / uint long / ulong Burst supports all vector types (for example int2, float3), except half vector types. For example: var value = new float3(1.0f, 2.0f, 3.0f); // Logs \"This value float3(1f, 2f, 3f)\" Debug.Log($\"This value `{value}`\"); Burst doesn't support ToString() of structs. It displays the full name of the struct instead. For more information, refer to the .NET documentation on String interpolation and Standard numeric format strings. Managed strings You can pass a managed string literal or an interpolated string directly to Debug.Log, but you can't pass a string to a user method or use them as fields in a struct. To pass around or store strings, use one of the FixedString structs in the Unity.Collections package: int value = 256; FixedString128 text = $\"This is an integer value {value} used with FixedString128\"; MyCustomLog(text); // ... // String can be passed as an argument to a method using a FixedString, // but not using directly a managed `string`: public static void MyCustomLog(in FixedString128 log) { Debug.Log(text); } Arguments and specifiers Burst has limited support for string format arguments and specifiers: int value = 256; // Padding left: \"This value ` 256` Debug.Log($\"This value `{value,5}`\"); // Padding right: \"This value `256 ` Debug.Log($\"This value `{value,-5}`\"); // Hexadecimal uppercase: \"This value `00FF` Debug.Log($\"This value `{value:X4}`\"); // Hexadecimal lowercase: \"This value `00ff` Debug.Log($\"This value `{value:x4}`\"); // Decimal with leading-zero: \"This value `0256` Debug.Log($\"This value `{value:D4}`\"); Additional resources HPC# Overview C#/.NET type support C#/.NET System namespace support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-system-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-system-support.html",
    "title": "C#/.NET System namespace support | Inventory System",
    "summary": "C#/.NET System namespace support Burst provides support for some of the System namespace, transforming these into Burst compatible variants in the Burst compiler. System.Math Burst supports all methods that System.Math declares, with the following exceptions: double IEEERemainder(double x, double y) is only supported when Api Compatibility Level is set to .NET Standard 2.1 in project settings System.IntPtr Burst supports all methods of System.IntPtr/System.UIntPtr, including the static fields IntPtr.Zero and IntPtr.Size System.Threading.Interlocked Burst supports atomic memory intrinsics for all methods provided by System.Threading.Interlocked (for example, Interlocked.Increment). Make sure that the source location of the interlocked methods are naturally aligned. For example, the alignment of the pointer is a multiple of the pointed-to-type: [StructLayout(LayoutKind.Explicit)] struct Foo { [FieldOffset(0)] public long a; [FieldOffset(5)] public long b; public long AtomicReadAndAdd() { return Interlocked.Read(ref a) + Interlocked.Read(ref b); } } If the pointer to the struct Foo has an alignment of 8, which is the natural alignment of a long value, the Interlocked.Read of a would be successful because it lies on a naturally aligned address. However, b would not be successful and undefined behavior happens at the load of b as a result. System.Threading.Thread Burst supports the MemoryBarrier method of System.Threading.Thread. System.Threading.Volatile Burst supports the non-generic variants of Read and Write provided by System.Threading.Volatile. System.HashCode Burst supports all methods of HashCode except for HashCode.Add<T>(T, IEqualityComparer<T>). Do note that Burst does not follow .NET's implementation in sense of only being deterministic within a specific operating system process. Additional resources HPC# overview String support C#/.NET type support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-type-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/csharp-type-support.html",
    "title": "C#/.NET type support | Inventory System",
    "summary": "C#/.NET type support Burst works on a subset of .NET that doesn't let you use any managed objects or reference types in your code (classes in C#). The following sections gives more details about the constructs that Burst supports, and any limitations they have. Built-in types Array types Struct types Generic types Vector types Enum types Pointer types Span types Tuple types Built-in types Supported built-in types Burst supports the following built-in types: bool byte/sbyte double float int/uint long/ulong short/ushort Unsupported built-in types Burst doesn't support the following built-in types: char decimal string because this is a managed type Array types Supported array types Burst supports read-only managed arrays loaded from static read-only fields: [BurstCompile] public struct MyJob : IJob { private static readonly int[] _preComputeTable = new int[] { 1, 2, 3, 4 }; public int Index { get; set; } public void Execute() { int x = _preComputeTable[0]; int z = _preComputeTable[Index]; } } However, accessing a static read-only managed array has the following restrictions: You can only use the read-only static managed array directly and can't pass it around, for example as a method argument. C# code that doesn't use jobs shouldn't modify the read-only static array's elements. This is because the Burst compiler makes a read-only copy of the data at compilation time. Multi-dimensional arrays aren't supported. If you've used an unsupported static constructor, Burst produces the error BC1361. For more information on how Burst initializes arrays, see Static readonly fields and static constructors. Unsupported array types Burst doesn't support managed arrays. Instead, use a native container such as NativeArray . Struct types Supported structs Burst supports the following structs: Regular structs with any field with supported types Structs with fixed array fields Note Structs with an explicit layout might generate non-optimal native code. Supported struct layout Burst supports the following struct layouts: LayoutKind.Sequential LayoutKind.Explicit StructLayoutAttribute.Pack StructLayoutAttribute.Size Burst supports System.IntPtr and System.UIntPtr natively as intrinsic structs that directly represent pointers. Generic types Burst supports generic types used with structs. It supports full instantiation of generic calls for generic types that have interface constraints, for example when a struct with a generic parameter needs to implement an interface. Note There are restrictions if you use generic jobs. Vector types Burst can translate vector types from Unity.Mathematics to native SIMD vector types with the following first class support for optimizations: bool2/bool3/bool4 uint2/uint3/uint4 int2/int3/int4 float2/float3/float4 Tip For performance reasons, use the 4 wide types (bool4, uint4, float4, int4, ) over the other types. Enum types Supported enum types Burst supports all enums including enums that have a specific storage type, for example, public enum MyEnum : short. Unsupported enums Burst doesn't support Enum methods, for example Enum.HasFlag. Pointer types Burst supports any pointer types to any Burst supported types Span types Burst supports Span<T> and ReadOnlySpan<T> types in the Unity Editors that support them. You can only use span types in Burst jobs or function-pointers, but not across the interface to them. This is because in C#'s implementation of the span types it supports taking spans into managed data types (like a managed array). For example, the following code is invalid: [BurstCompile] public static void SomeFunctionPointer(Span<int> span) {} This is because Span is used across the managed and Burst boundary. In Burst, span types respect any safety check setting, and only perform performance-intensive checks when safety checks are enabled. Tuple types Burst supports value tuples ValueTuple<T1,T2> in Burst-compiled jobs or static methods, but not across the interface to them. This is because value tuples are of struct layout LayoutKind.Auto. Burst does not support LayoutKind.Auto (to see a list of struct layouts Burst supports see the section Struct types). However, one can use a regular struct to emulate a tuple like so: [BurstCompile] private struct MyTuple { public int item1; public float item2; } Additional resources HPC# overview String support C#/.NET System namespace support"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/debugging-profiling-tools.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/debugging-profiling-tools.html",
    "title": "Debugging and profiling tools | Inventory System",
    "summary": "Debugging and profiling tools The following sections describe how to debug and profile your Burst-compiled code in the Editor and in Player builds. Tip Before attempting to debug Burst-compiled code, enable script debugging for the Editor, or a Player build by following the steps in Debug C# code in Unity. Although you can theoretically debug Burst-compiled code even when the script compilation mode is set to Release, in practice it doesn't work reliably. Breakpoints might be skipped, and variables might not appear in the Locals window, for example. Debugging Burst-compiled code in the Editor To debug Burst-compiled code in the Editor, you can either use a managed debugger or a native debugger. This section explains both options. Attach a managed debugger You can attach a managed debugger such as Visual Studio or JetBrains Rider. This is the same type of debugger you can use to debug regular managed C# code in your Unity project. When you place a breakpoint inside Burst-compiled code, and you have a managed debugger attached, Unity disables Burst automatically for that code path. This allows you to use a managed debugger to debug the managed version of your code. When you remove all breakpoints from that code path, Unity re-enables Burst for that code path. Attach a native debugger You can attach a native debugger such as Visual Studio or Xcode. Before doing so, you need to disable Burst optimizations. You can do this in the following ways: Use the Native Debug Mode Compilation setting in the Editor Burst menu (Jobs > Burst > Native Debug Mode Compilation). Important: This setting disables optimizations across all jobs, which impacts the performance of Burst code. If you want to disable optimizations only for a specific job, use the other option in this list. Add the Debug = true flag to your job, which disables optimizations and enables debugging on that specific job: [BurstCompile(Debug = true)] public struct MyJob : IJob { // ... } Tip Player builds pick up the Debug flag, so you can also use this to debug a Player build. To attach a native debugger to the Unity Editor process, refer to native debugging. Debugging Burst-compiled code in a Player build Because of how Unity builds the code for a Player, you need to tell the debugging tool where to find the symbols. To do this, point the tool to the folder that contains the lib_burst_generated files, which is usually in the Plugins folder. To debug Burst-compiled code in a Player build, you need to attach a native debugger (such as Visual Studio or Xcode) to the player process. Before doing so, you need to: Enable symbol generation. You can do this in either of two ways: Enable the Development Build option before you build the Player, or Enable the Force Debug Information option in Burst AOT Player Settings Disable Burst optimizations. You can do this in either of two ways: Disable the Enable Optimizations option in Burst AOT Player Settings. Important: This setting disables optimizations across all jobs, which impacts the performance of Burst code. If you want to disable optimizations only for a specific job, use the other option in this list. Add the Debug = true flag to your job, which disables optimizations and enables debugging on that specific job: [BurstCompile(Debug = true)] public struct MyJob : IJob { // ... } To attach a native debugger to the player process, refer to native debugging. Native debugging Follow the previous instructions to set up native debugging correctly for the Editor or a Player build. Then, attach a native debugger such as Visual Studio or Xcode. Native debugging limitations Native debuggers can't discover lambda captures on Entity.ForEach, so you can't inspect variables originating from these. Structs that use [StructLayout(LayoutKind=Explicit)] and have overlapping fields are represented by a struct that hides one of the overlaps. Types that are nested, are namespaced in C/C++ style. e.g. namespace Pillow { public struct Spot { public struct SubSpot { public int a; public int b; } public int a; public int b; public SubSpot sub; } You would refer to SubSpot as Pillow::Spot::SubSpot in this case (for instance if you were trying to cast a pointer in a debugger watch window). Code-based breakpoints Burst supports code-based breakpoints through the System.Diagnostics.Debugger.Break method. This method generates a debug trap in your code. You must attach a debugger to your code so that it can intercept the break. Breakpoints trigger whether you've attached a debugger or not. Burst adds information to track local variables, function parameters and breakpoints. If your debugger supports conditional breakpoints, use these over adding breakpoints in your code, because they only fire when you've attached a debugger. Profiling Burst-compiled code Profiling using standalone profiling tools You can use profiling tools (such as Instruments or Superluminal) to profile Burst-compiled code in a Player build. Because of how Unity builds the code for a Player, you need to tell the profiling tool where to find the symbols. To do this, point the tool to the folder that contains the lib_burst_generated files, which is usually in the Plugins folder. Unity Profiler markers To improve the data you get from Unity Profiler (either for Burst-compiled code running in the Editor or in an attached player), you can create Unity Profiler markers from Burst code by calling new ProfilerMarker(\"MarkerName\"): [BurstCompile] private static class ProfilerMarkerWrapper { private static readonly ProfilerMarker StaticMarker = new ProfilerMarker(\"TestStaticBurst\"); [BurstCompile(CompileSynchronously = true)] public static int CreateAndUseProfilerMarker(int start) { using (StaticMarker.Auto()) { var p = new ProfilerMarker(\"TestBurst\"); p.Begin(); var result = 0; for (var i = start; i < start + 100000; i++) { result += i; } p.End(); return result; } } } Additional resources Debug C# code in Unity"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-burst-inspector.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-burst-inspector.html",
    "title": "Burst Inspector window reference | Inventory System",
    "summary": "Burst Inspector window reference The Burst Inspector window displays all the jobs and other Burst compile targets in the project. To open the Burst Inspector window, go to Jobs > Burst > Open Inspector. The Burst Inspector displays all the jobs Burst can compile. It also displays the generated intermediate and native assembly code. When opening a new target job in the Burst Inspector, it will try to focus the assembly directly related to the chosen bursted job. If branch flow arrows are shown and fill more than half of the assembly view, the inspector scrolls horizontally rightwards to focus the code instead of the branches. Burst Inspector with Branch Flow enabled Burst Inspector panes The Compile Targets pane on the left of the window displays an alphabetical list of jobs in the project that Burst can compile. By default jobs either in the Unity namespace or with \".Generated\" in the name are excluded. This can be changed via the toggles Show Unity Namespace and Show \".Generated\" respectively. Disabled jobs in the list don't have the [BurstCompile] attribute. The right output pane of the Burst Inspector window displays options to view the assembly and intermediate code for the job you've selected in the Compile Targets list. To expand or collapse elements of the code, select the colored boxes (some with ellipses). By default the Burst Inspector automatically collapses non-essential blocks, such as most directives and data. It is possible to select lines of assembly. This will highlight the selected line, by underlining it. If this line contains any registers, the usage of these registers will be highlighted throughout the code; note that implicit registers are ignored for this feature. To select and copy the text in this pane, either click and drag with your mouse, or use Shift + arrow keys to select the text. To copy the text, either right-click and select Copy Selection, or press Ctrl + C (Command + C on macOS). Default behavior for the Burst Inspector's copy is to include underlying color tags. To change this, right-click with the mouse on the right pane, to open up the context menu, and untick Copy Color Tags. At the top of the window, the following display options are available: Display option Function Output dropdown Use the dropdown to select how to output the information in the Burst Inspector window Plain Without Debug Information Displays the raw output. Plain With Debug Information Displays the raw output with debug information. Enhanced with Minimal Debug Information (Only available in Assembly view) Displays the line information interweaved with the assembly to guide you to what line in your code matches what assembly output. If you've enabled Show Branch Flow, the branch flow indicates where jump instruction might branch off to. Enhanced With Full Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Minimal Debug Information but with debug information included. Coloured With Minimal Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Minimal Debug Information, but displays the output in color. Coloured With Full Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Full Debug Information, but displays the output in color. Safety Checks Enable this option to generate code that includes container access safety checks, for example, to check if a job is attempting to write to a read-only native container. Font Size Select the size of the text in the output pane. Architecture dropdown Select the target architecture for your build. Focus on Code (Only available in Enhanced or Coloured output) Collapses the least important blocks of the disassembly. When you select this, Unity hides most of the assembly language directives and non code segments, allowing you to focus on the code itself. Expand all (Only available in Enhanced or Coloured output) Expands all collapsed blocks of disassembly and displays all the hidden assembly language directives and data elements. Show Branch Flow (Only available in Enhanced or Coloured output) Enable this option to display arrows that show branch flow in the code. When enabled, the code moves to the right, to make space to display the arrows. Highlight SIMD Scalar vs Packed (Only available in Enhanced or Coloured output) Enable this option to display SIMD instruction differently depending on their nature (Whether they work on packed or scalar inputs). This can be used to quickly assess the quality of the generated vectorized code (see SIMD smell test by Andreas Fredriksson). Assembly Displays the final optimized native code that Burst generated. .NET IL Displays the original .NET IL extracted from the job method. LLVM IR (Unoptimized) Displays the internal LLVM IR before optimizations. LLVM IR (Optimized) Displays the internal LLVM IR after optimizations. LLVM IR Optimization Diagnostics Displays LLVM diagnostics of the optimizations, such as if they succeeded or failed. Additional resources Burst menu Job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-burst-menu.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-burst-menu.html",
    "title": "Burst menu reference | Inventory System",
    "summary": "Burst menu reference Use the settings in the Burst menu to control how Burst works in the Unity Editor. These settings control Burst complilation in the Editor only. To configure Burst compilation for Player builds, refer to Burst AOT Settings reference. To access the Burst menu, go to Jobs > Burst. The following settings are available: Setting Function Enable Compilation Enable this setting to activate Burst compilation. When you enable this setting, Burst compiles jobs and Burst custom delegates that you tag with the attribute [BurstCompile]. Enable Safety Checks Choose what safety checks Burst should use. For more information, refer to Enable Safety Checks setting. Off Disable safety checks across all Burst jobs and function-pointers. Only use this setting if you want more realistic profiling results from in-Editor captures. When you reload the Editor, this setting always resets to On. On Enable safety checks on code that uses collection containers (e.g NativeArray<T>). Checks include job data dependency and container indexes out of bounds. This is the default setting. Force On Force safety checks on even for jobs and function-pointers that have DisableSafetyChecks = true. Use this setting to rule out any problems that safety checks might have caught. Synchronous Compilation Enable this setting to compile Burst synchronously. For more information, refer to Synchronous compilation. Native Debug Mode Compilation Enable this setting to deactivate optimizations on all code that Burst compiles. This makes it easier to debug via a native debugger. For more information, refer to Native Debugging tools. Show Timings Enable this setting to log the time it takes to JIT compile a job in the Editor and display it in the Console. For more information, refer to Show Timings setting. Open Inspector Opens the Burst Inspector window. Enable Safety Checks setting To disable Burst's safety check code, use DisableSafetyChecks. This results in faster code generation, however make sure that you use containers in a safe fashion. To disable safety checks on a job or function-pointer set DisableSafetyChecks to true: [BurstCompile(DisableSafetyChecks = true)] public struct MyJob : IJob { // ... } Burst ignores code marked explicitly with DisableSafetyChecks = true when it safety checks your code if you set Enable Safety Checks to On in the Editor. Select Force On to make Burst to safety check all code, including code marked with DisableSafetyChecks = true. Show Timings setting When you enable the Show Timings setting, Unity logs an output in the Console window for each library of entry points that Burst compiles. Burst batches the compilation into units of methods-per-assembly, and groups multiple entry-points together in a single compilation task. This output is useful if you want to report outliers in compilation to the Burst compiler team (via the Burst forum). Unity splits Burst's output into the following major sections: Method discovery (where Burst works out what it needs to compile) Front end (where Burst turns C# IL into an LLVM IR module) Middle end (where Burst specializes, optimizes, and cleans up the module) Back end (where Burst turns the LLVM IR module into a native DLL) The compile time in the front end and optimizer is linear to the number of operations that it needs to compile. More functions and more instructions means a longer compile time. The more generic functions you have, the higher the front end performance timings, because generic resolutions have non-zero costs. The compile time in the back end scales with the number of entry-points in the module. This is because each entry point is in its own native object file. If the optimizer takes a significant amount of time, use [BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] which reduces the optimizations that Burst does, but compiles things much faster. Profile the job before and after to make sure that this tradeoff is right for that entry-point. Additional resources Burst Inspector window reference Job system"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-reference-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/editor-reference-overview.html",
    "title": "Editor reference | Inventory System",
    "summary": "Editor reference Explore the specific Burst Editor features. Topic Description Burst menu Use the Burst menu to control the Burst settings in your project. Burst Inspector Use the Burst Inspector to see the jobs and Burst compiled targets in your project. Additional resources Building your project"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/getting-started.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/getting-started.html",
    "title": "Get started | Inventory System",
    "summary": "Get started You can use Burst to compile jobs or static methods in non-job C# types. To start using the Burst compiler in your code, decorate a job or static method with the [BurstCompile] attribute. For more information on where and when to apply the [BurstCompile] attribute, refer to Marking code for Burst compilation. Compiling jobs with Burst For jobs, you only need to apply the [BurstCompile] attribute to the job declaration and Burst compiles everything inside the job automatically. The following example demonstrates this: using Unity.Burst; using Unity.Collections; using Unity.Jobs; using UnityEngine; public class MyBurst2Behavior : MonoBehaviour { void Start() { var input = new NativeArray<float>(10, Allocator.Persistent); var output = new NativeArray<float>(1, Allocator.Persistent); for (int i = 0; i < input.Length; i++) input[i] = 1.0f * i; var job = new MyJob { Input = input, Output = output }; job.Schedule().Complete(); Debug.Log(\"The result of the sum is: \" + output[0]); input.Dispose(); output.Dispose(); } // Using BurstCompile to compile a Job with Burst [BurstCompile] private struct MyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public void Execute() { float result = 0.0f; for (int i = 0; i < Input.Length; i++) { result += Input[i]; } Output[0] = result; } } } Compiling static methods with Burst For static methods, you must apply the [BurstCompile] attribute to both the individual methods you want Burst to compile and to the declaration of the parent type. The following example demonstrates this: using Unity.Burst; using Unity.Collections; using Unity.Jobs; using UnityEngine; [BurstCompile] public static class MyBurstUtilityClass { [BurstCompile] public static void BurstCompiled_MultiplyAdd(in float4 mula, in float4 mulb, in float4 add, out float4 result) { result = mula * mulb + add; } } For more information on how you can call this Burst-compiled utility class and its member method from your C# code, refer to Calling Burst-compiled code. Limitations Burst supports most C# expressions and statements, with a few exceptions. For more information, refer to C# language support. Compilation Burst compiles your code just-in-time (JIT) while in Play mode in the Editor, and ahead-of-time (AOT) when your application runs in a Player. For more information on compilation, refer to Burst compilation Command line options You can pass the following options to the Unity Editor on the command line to control Burst: --burst-disable-compilation disables Burst. --burst-force-sync-compilation force Burst to compile synchronously. For more information, refer to Burst compilation. Additional resources Burst compilation [BurstCompile] attribute"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/index.html",
    "title": "Burst compiler | Inventory System",
    "summary": "Burst compiler Compile compatible sections of your C# code into highly-optimized native CPU code. Burst is a compiler that works on a subset of C# referred to in the Unity context as High-Performance C# (HPC#). Burst uses LLVM to translate .NET Intermediate Language (IL) to code that's optimized for performance on the target CPU architecture. Burst was originally designed for use with Unity's job system. Jobs are structs that implement the IJob interface and represent small units of work that can run in parallel to make best use of all available CPU cores. Designing or refactoring your project to split work into Burst-compiled jobs can significantly improve the performance of CPU-bound code. Aside from jobs, Burst can also compile static methods, as long as the code inside them belongs to the supported subset of C#. Mark code for Burst compilation by applying the [BurstCompile] attribute to jobs or to static methods and their parent type. Topic Description Get started Get started with Burst by creating your first simple Burst-compiled example code. C# language support Check which elements of the C# language belong to the high-performance subset of C# that Burst can compile. Burst compilation Understand how Burst compiles code in different contexts, mark your code for Burst compilation, and configure aspects of the compilation process. Burst intrinsics Use low-level intrinsics to get extra performance from Burst if you're writing single instruction, multiple data (SIMD) assembly code. Editor reference Use the Burst menu and Burst Inspector window in the Unity Editor to configure Burst options and inspect the Burst-compilable jobs in your project. Building your project Build your project with the appropriate toolchains and Burst Ahead-of-Time (AOT) compilation settings for your target platform and architecture. Optimization Debug and profile to identify bugs or bottlenecks in Burst-compiled code and configure a range of options to optimize performance. Modding support Include Burst-compiled code as additional libraries in your mods. Installation To install the Burst package, follow the instructions in the Add and remove UPM packages or feature sets documentation. If you change the Burst package version (for example, via Update), you need to close and restart the Editor. Additional resources Videos Conference presentations given by the Burst team: Getting started with Burst - Unite Copenhagen 2019 Supercharging mobile performance with ARM Neon and Unity Burst Compiler Using Burst Compiler to optimize for Android - Unite Now 2020 Intrinsics: Low-level engine development with Burst - Unite Copenhagen 2019 (slides) Behind the Burst compiler: Converting .NET IL to highly optimized native code - DotNext 2018 Deep dive into the Burst compiler - Unite LA 2018 C# to machine code: GDC 2018 Using the native debugger for Burst compiled code Blogs Blog posts written by members of the Burst team : Raising your game with Burst 1.7 Enhancing mobile performance with the Burst compiler Enhanced aliasing with Burst In parameters in Burst"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/modding-support.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/modding-support.html",
    "title": "Modding support | Inventory System",
    "summary": "Modding support From Unity 2021.1, you can load additional Burst compiled libraries, which provide a way to create modifications that use Burst compiled code. Burst only provides a method to load additional libraries, and doesn't provide any tooling to create mods. You need a copy of the Unity Editor to compile the additional libraries. This section gives an example approach to modding with Burst and is a proof of concept. Supported uses You can use this function in Play mode (or Standalone Players) only. Make sure you load the libraries as soon as possible, and before the first Burst-compiled use of a C# method. Unity unloads any Burst libraries that BurstRuntime.LoadAdditionalLibraries loads when you exit Play mode in the Editor or quit a Standalone Player. Example modding system Note This example is limited in scope. You should have knowledge of assemblies and asmdefs to follow this example. This example declares an interface that the mods abide by: using UnityEngine; public interface PluginModule { void Startup(GameObject gameObject); void Update(GameObject gameObject); } You can use this interface to create new classes which follow these specifications and ship it separate to your application. Passing a single GameObject along limits the state that the plug-ins can affect. Modding manager The following is an example of a modding manager: using System; using System.Collections.Generic; using System.IO; using System.Reflection; using UnityEngine; using Unity.Burst; public class PluginManager : MonoBehaviour { public bool modsEnabled; public GameObject objectForPlugins; List<PluginModule> plugins; void Start() { plugins = new List<PluginModule>(); // If mods are disabled, early out - this allows us to disable mods, enter Play Mode, exit Play Mode //and be sure that the managed assemblies have been unloaded (assuming DomainReload occurs) if (!modsEnabled) return; var folder = Path.GetFullPath(Path.Combine(Application.dataPath, \"..\", \"Mods\")); if (Directory.Exists(folder)) { var mods = Directory.GetDirectories(folder); foreach (var mod in mods) { var modName = Path.GetFileName(mod); var monoAssembly = Path.Combine(mod, $\"{modName}_managed.dll\"); if (File.Exists(monoAssembly)) { var managedPlugin = Assembly.LoadFile(monoAssembly); var pluginModule = managedPlugin.GetType(\"MyPluginModule\"); var plugin = Activator.CreateInstance(pluginModule) as PluginModule; plugins.Add(plugin); } var burstedAssembly = Path.Combine(mod, $\"{modName}_win_x86_64.dll\"); // Burst dll (assuming windows 64bit) if (File.Exists(burstedAssembly)) { BurstRuntime.LoadAdditionalLibrary(burstedAssembly); } } } foreach (var plugin in plugins) { plugin.Startup(objectForPlugins); } } // Update is called once per frame void Update() { foreach (var plugin in plugins) { plugin.Update(objectForPlugins); } } } This code scans the Mods folder, and for each folder it finds within, it attempts to load both a managed dll and a Burst-compiled dll. It does this by adding them to an internal list that it can then iterate on and call the respective interface functions. The names of the files are arbitrary: refer to Simple Create Mod Menu Button, which is the code that generated those files. Because this code loads the managed assemblies into the current domain, you need a domain reload to unload those before you can overwrite them. Unity automatically unloads the Burst dll files automatically unloaded when you exit Play mode. This is why a Boolean to disable the modding system is included, for testing in the Editor. A mod that uses Burst Create a separate Unity project for this to use the project to produce the mod. The following script attaches to a UI Canvas that contains a text component called Main UI Label and changes the text when the mod is used. The text is either Plugin Updated : Bursted or Plugin Updated : Not Bursted. You will see the Plugin Updated : Bursted by default, but if you comment out the lines that load the Burst library in the PluginManager above, then the Burst compiled code doesn't load and the message changes appropriately. using Unity.Burst; using Unity.Collections; using Unity.Jobs; using UnityEngine; using UnityEngine.UI; public class MyPluginModule : PluginModule { Text textComponent; public void Startup(GameObject gameObject) { var childTextComponents = gameObject.GetComponentsInChildren<Text>(); textComponent = null; foreach (var child in childTextComponents) { if (child.name == \"Main UI Label\") { textComponent = child; } } if (textComponent==null) { Debug.LogError(\"something went wrong and i couldn't find the UI component i wanted to modify\"); } } public void Update(GameObject gameObject) { if (textComponent != null) { var t = new CheckBurstedJob { flag = new NativeArray<int>(1, Allocator.TempJob, NativeArrayOptions.UninitializedMemory) }; t.Run(); if (t.flag[0] == 0) textComponent.text = \"Plugin Updated : Not Bursted\"; else textComponent.text = \"Plugin Updated : Bursted\"; t.flag.Dispose(); } } [BurstCompile] struct CheckBurstedJob : IJob { public NativeArray<int> flag; [BurstDiscard] void CheckBurst() { flag[0] = 0; } public void Execute() { flag[0] = 1; CheckBurst(); } } } Put the above script in a folder along with an assembly definition file with an assembly name of TestMod_Managed so the next script can locate the managed part. Simple Create Mod Menu button The following script adds a menu button. When you use the menu button, it builds a Standalone Player, then copies the C# managed dll and the lib_burst_generated.dll into a chosen Mod folder. This example assumes you are using Windows. using UnityEditor; using System.IO; using UnityEngine; public class ScriptBatch { [MenuItem(\"Modding/Build X64 Mod (Example)\")] public static void BuildGame() { string modName = \"TestMod\"; string projectFolder = Path.Combine(Application.dataPath, \"..\"); string buildFolder = Path.Combine(projectFolder, \"PluginTemp\"); // Get filename. string path = EditorUtility.SaveFolderPanel(\"Choose Final Mod Location\", \"\", \"\"); FileUtil.DeleteFileOrDirectory(buildFolder); Directory.CreateDirectory(buildFolder); // Build player. var report = BuildPipeline.BuildPlayer(new[] { \"Assets/Scenes/SampleScene.unity\" }, Path.Combine(buildFolder, $\"{modName}.exe\"), BuildTarget.StandaloneWindows64, BuildOptions.Development); if (report.summary.result == UnityEditor.Build.Reporting.BuildResult.Succeeded) { // Copy Managed library var managedDest = Path.Combine(path, $\"{modName}_Managed.dll\"); var managedSrc = Path.Combine(buildFolder, $\"{modName}_Data/Managed/{modName}_Managed.dll\"); FileUtil.DeleteFileOrDirectory(managedDest); if (!File.Exists(managedDest)) // Managed side not unloaded FileUtil.CopyFileOrDirectory(managedSrc, managedDest); else Debug.LogWarning($\"Couldn't update managed dll, {managedDest} is it currently in use?\"); // Copy Burst library var burstedDest = Path.Combine(path, $\"{modName}_win_x86_64.dll\"); var burstedSrc = Path.Combine(buildFolder, $\"{modName}_Data/Plugins/x86_64/lib_burst_generated.dll\"); FileUtil.DeleteFileOrDirectory(burstedDest); if (!File.Exists(burstedDest)) FileUtil.CopyFileOrDirectory(burstedSrc, burstedDest); else Debug.LogWarning($\"Couldn't update bursted dll, {burstedDest} is it currently in use?\"); } } } Additional resources Import and configure plug-ins"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-assumerange.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-assumerange.html",
    "title": "AssumeRange attribute | Inventory System",
    "summary": "AssumeRange attribute Use the AssumeRange attribute to tell Burst that a given scalar-integer lies within a certain constrained range. If Burst has this information, it can improve the performance of your application. The following code is an example of this: [return:AssumeRange(0u, 13u)] static uint WithConstrainedRange([AssumeRange(0, 26)] int x) { return (uint)x / 2u; } This example tells Burst the following: The variable x is in the closed-interval range [0..26], or more plainly that x >= 0 && x <= 26. The return value from WithConstrainedRange is in the closed-interval range [0..13], or more plainly that x >= 0 && x <= 13. Burst uses these assumptions to create better code generation. However, there are some restrictions: You can only place these on scalar-integer (signed or unsigned) types. The type of the range arguments must match the type being attributed. Burst has deductions for the .Length property of NativeArray and NativeSlice which indicates that these always return non-negative integers: static bool IsLengthNegative(NativeArray<float> na) { // Burst always replaces this with the constant false return na.Length < 0; } For example, if you have a container like the following: struct MyContainer { public int Length; // Some other data... } The following example shows how to tell Burst that Length is always a positive integer: struct MyContainer { private int _length; [return: AssumeRange(0, int.MaxValue)] private int LengthGetter() { return _length; } public int Length { get => LengthGetter(); set => _length = value; } // Some other data... } Additional resources [AssumeRange] attribute API reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-constant.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-constant.html",
    "title": "Constant intrinsic | Inventory System",
    "summary": "Constant intrinsic Use the IsConstantExpression intrinsic to check if a given expression is constant at compile-time: using static Unity.Burst.CompilerServices.Constant; var somethingWhichWillBeConstantFolded = math.pow(42.0f, 42.0f); if (IsConstantExpression(somethingWhichWillBeConstantFolded)) { // Burst knows that somethingWhichWillBeConstantFolded is a compile-time constant } This is useful to check if a complex expression is always constant folded. You can use it for optimizations for a known constant value. For example, if you want to implement a pow-like function for integer powers: using static Unity.Burst.CompilerServices.Constant; public static float MyAwesomePow(float f, int i) { if (IsConstantExpression(i) && (2 == i)) { return f * f; } else { return math.pow(f, (float)i); } } The IsConstantExpression check means that Burst always removes the branch if i isn't constant, because the if condition is false. This means that if i is constant and is equal to 2, you can use a more efficient simple multiply instead. The result of IsConstantExpression intentionally depends on the result of the optimizations being run. Therefore the result can change based on whether a function gets inlined or not. For example, in the previous case: IsConstantExpression(i) is false on its own, because i is a function argument which is not constant. However, if MyAwesomePow gets inlined with a constant value for i, then it evaluates true. If MyAwesomePow ends up not being inlined, then IsConstantExpression(i) remains false. Note Constant folding only takes place during optimizations. If you've disabled optimizations, the intrinsic returns false. Additional resources [IsConstantExpression] API reference Burst intrinsics overview"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-hint.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-hint.html",
    "title": "Hint intrinsics | Inventory System",
    "summary": "Hint intrinsics Use the Hint intrinsics to add information to your code which helps with Burst optimization. It has the following methods: Unity.Burst.CompilerServices.Hint.Likely: Tells Burst that a Boolean condition is likely to be true. Unity.Burst.CompilerServices.Hint.Unlikely: Tells Burst that a Boolean condition is unlikely to be true. Unity.Burst.CompilerServices.Hint.Assume: Tells Burst that it can assume a Boolean condition is true. Likely intrinsic The Likely intrinsic is most useful to tell Burst which branch condition has a high probability of being true. This means that Burst can focus on the branch in question for optimization purposes: if (Unity.Burst.CompilerServices.Hint.Likely(b)) { // Any code in here will be optimized by Burst with the assumption that we'll probably get here! } else { // Whereas the code in here will be kept out of the way of the optimizer. } Unlikely intrinsic The Unlikely intrinsic tells Burst the opposite of the Likely intrinsic: the condition is unlikely to be true, and it should optimize against it: if (Unity.Burst.CompilerServices.Hint.Unlikely(b)) { // Whereas the code in here will be kept out of the way of the optimizer. } else { // Any code in here will be optimized by Burst with the assumption that we'll probably get here! } The Likely and Unlikely intrinsics make sure that Burst places the code most likely to be hit after the branching condition in the binary. This means that the code has a high probability of being in the instruction cache. Burst can also hoist the code out of the likely branch and spend extra time optimizing it, and not spend as much time looking at the unlikely code. An example of an unlikely branch is to check if the result of an allocation is valid. The allocation is valid most of the time, so you want the code to be fast with that assumption, but you want an error case to fall back to. Assume intrinsic The Assume intrinsic is powerful. Use it with caution because it tells Burst that a condition is always true. Warning When you use Assume, Burst assumes the value is true without checking whether it's true. Unity.Burst.CompilerServices.Hint.Assume(b); if (b) { // Burst has been told that b is always true, so this branch will always be taken. } else { // Any code in here will be removed from the program because b is always true! } Use the Assume intrinsic to arbitrarily tell Burst that something is true. For example, you can use Assume to tell Burst to assume that a loop end is always a multiple of 16, which means that it can provide perfect vectorization without any scalar spilling for that loop. You could also use it to tell Burst that a value isn't NaN, or it's negative. Additional resources [Hint] API reference Burst intrinsics overview"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-loop-vectorization.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-loop-vectorization.html",
    "title": "Loop vectorization | Inventory System",
    "summary": "Loop vectorization Burst uses loop vectorization to improve the performance of your code. It uses this technique to loop over multiple values at the same time, rather than looping over single values at a time, which speeds up the performance of your code. For example: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { a[i] += b[i]; } } public static unsafe void Foo(int count) { var a = stackalloc int[count]; var b = stackalloc int[count]; Bar(a, b, count); } Burst converts the scalar loop in Bar into a vectorized loop. Then, instead of looping over a single value at a time, it generates code that loops over multiple values at the same time, which produces faster code. This is the x64 assembly Burst generates for AVX2 for the loop in Bar above: .LBB1_4: vmovdqu ymm0, ymmword ptr [rdx + 4*rax] vmovdqu ymm1, ymmword ptr [rdx + 4*rax + 32] vmovdqu ymm2, ymmword ptr [rdx + 4*rax + 64] vmovdqu ymm3, ymmword ptr [rdx + 4*rax + 96] vpaddd ymm0, ymm0, ymmword ptr [rcx + 4*rax] vpaddd ymm1, ymm1, ymmword ptr [rcx + 4*rax + 32] vpaddd ymm2, ymm2, ymmword ptr [rcx + 4*rax + 64] vpaddd ymm3, ymm3, ymmword ptr [rcx + 4*rax + 96] vmovdqu ymmword ptr [rcx + 4*rax], ymm0 vmovdqu ymmword ptr [rcx + 4*rax + 32], ymm1 vmovdqu ymmword ptr [rcx + 4*rax + 64], ymm2 vmovdqu ymmword ptr [rcx + 4*rax + 96], ymm3 add rax, 32 cmp r8, rax jne .LBB1_4 Burst has unrolled and vectorized the loop into four vpaddd instructions, which calculate eight integer additions each, for a total of 32 integer additions per loop iteration. Loop vectorization intrinsics Burst includes experimental intrinsics to express loop vectorization assumptions: Loop.ExpectVectorized and Loop.ExpectNotVectorized. Burst then validates the loop vectorization at compile-time. This is useful in a situation where you might break the auto vectorization. For example, if you introduce a branch to the code: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { if (a[i] > b[i]) { break; } a[i] += b[i]; } } This changes the assembly to the following: .LBB1_3: mov r9d, dword ptr [rcx + 4*r10] mov eax, dword ptr [rdx + 4*r10] cmp r9d, eax jg .LBB1_4 add eax, r9d mov dword ptr [rcx + 4*r10], eax inc r10 cmp r8, r10 jne .LBB1_3 This isn't ideal because the loop is scalar and only has 1 integer addition per loop iteration. It can be difficult to spot this happening in your code, so use the experimental intrinsics Loop.ExpectVectorized and Loop.ExpectNotVectorized to express loop vectorization assumptions. Burst then validates the loop vectorization at compile-time. Because the intrinsics are experimental, you need to use the UNITY_BURST_EXPERIMENTAL_LOOP_INTRINSICS preprocessor define to enable them. The following example shows the original Bar example with the Loop.ExpectVectorized intrinsic: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { Unity.Burst.CompilerServices.Loop.ExpectVectorized(); a[i] += b[i]; } } Burst then validates at compile-time whether the loop is vectorized. If the loop isn't vectorized, Burst emits a compiler error. The following example produces an error: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { Unity.Burst.CompilerServices.Loop.ExpectVectorized(); if (a[i] > b[i]) { break; } a[i] += b[i]; } } Burst emits the following error at compile-time: LoopIntrinsics.cs(6,9): Burst error BC1321: The loop is not vectorized where it was expected that it is vectorized. Important These intrinsics don't work inside if statements. Burst doesn't prevent this from happening, so you won't see a compile-time error for this. Additional resources Burst intrinsics"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-overview.html",
    "title": "Optimization | Inventory System",
    "summary": "Optimization Debug and profile to identify problems in Burst-compiled code and configure a range of options to optimize performance. Topic Description Debugging and profiling tools Debug and profile your Burst-compiled code in the Editor and in player builds. Loop vectorization optimization Understand how Burst uses loop vectorization to optimize your code. Memory aliasing Use memory aliasing to tell Burst how your code uses data. AssumeRange attribute Use AssumeRange to tell Burst a given scalar-integer lies within a certain constrained range. Hint intrinsic Use the Hint intrinsic to give Burst more information about your data. Constant intrinsic Use IsConstantExpression top check if an expression is constant at run time. SkipLocalsInit attribute Use SkipLocalsInitAttribute to tell Burst that any stack allocations within a method don't have to be initialized to zero. Additional resources Burst intrinsics"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-skiplocalsinit.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Documentation~/optimization-skiplocalsinit.html",
    "title": "SkipLocalsInit attribute | Inventory System",
    "summary": "SkipLocalsInit attribute Use SkipLocalsInitAttribute to tell Burst that any stack allocations within a method don't have to be initialized to zero. In C# all local variables are initialized to zero by default, which prevents a class of bugs related to undefined data. But this can impact runtime performance because initializing this data to zero takes work: static unsafe int DoSomethingWithLUT(int* data); static unsafe int DoSomething(int size) { int* data = stackalloc int[size]; // Initialize every field of data to be an incrementing set of values. for (int i = 0; i < size; i++) { data[i] = i; } // Use the data elsewhere. return DoSomethingWithLUT(data); } The X86 assembly for this is: push rbp .seh_pushreg rbp push rsi .seh_pushreg rsi push rdi .seh_pushreg rdi mov rbp, rsp .seh_setframe rbp, 0 .seh_endprologue mov edi, ecx lea r8d, [4*rdi] lea rax, [r8 + 15] and rax, -16 movabs r11, offset __chkstk call r11 sub rsp, rax mov rsi, rsp sub rsp, 32 movabs rax, offset burst.memset.inline.X64_SSE4.i32@@32 mov rcx, rsi xor edx, edx xor r9d, r9d call rax add rsp, 32 test edi, edi jle .LBB0_7 mov eax, edi cmp edi, 8 jae .LBB0_3 xor ecx, ecx jmp .LBB0_6 .LBB0_3: mov ecx, eax and ecx, -8 movabs rdx, offset __xmm@00000003000000020000000100000000 movdqa xmm0, xmmword ptr [rdx] mov rdx, rsi add rdx, 16 movabs rdi, offset __xmm@00000004000000040000000400000004 movdqa xmm1, xmmword ptr [rdi] movabs rdi, offset __xmm@00000008000000080000000800000008 movdqa xmm2, xmmword ptr [rdi] mov rdi, rcx .p2align 4, 0x90 .LBB0_4: movdqa xmm3, xmm0 paddd xmm3, xmm1 movdqu xmmword ptr [rdx - 16], xmm0 movdqu xmmword ptr [rdx], xmm3 paddd xmm0, xmm2 add rdx, 32 add rdi, -8 jne .LBB0_4 cmp rcx, rax je .LBB0_7 .p2align 4, 0x90 .LBB0_6: mov dword ptr [rsi + 4*rcx], ecx inc rcx cmp rax, rcx jne .LBB0_6 .LBB0_7: sub rsp, 32 movabs rax, offset \"DoSomethingWithLUT\" mov rcx, rsi call rax nop mov rsp, rbp pop rdi pop rsi pop rbp ret In this example, the movabs rax, offset burst.memset.inline.X64_SSE4.i32@@32 line means that you've had to inject a memset to zero out the data. In the above example, you know that the array is entirely initialized in the following loop, but Burst doesn't know that. To fix this problem, use Unity.Burst.CompilerServices.SkipLocalsInitAttribute, which tells Burst that any stack allocations within a method don't have to be initialized to zero. Note Only use this attribute if you're certain that you won't run into undefined behavior bugs. For example: using Unity.Burst.CompilerServices; static unsafe int DoSomethingWithLUT(int* data); [SkipLocalsInit] static unsafe int DoSomething(int size) { int* data = stackalloc int[size]; // Initialize every field of data to be an incrementing set of values. for (int i = 0; i < size; i++) { data[i] = i; } // Use the data elsewhere. return DoSomethingWithLUT(data); } The assembly after adding the [SkipLocalsInit] on the method is: push rbp .seh_pushreg rbp mov rbp, rsp .seh_setframe rbp, 0 .seh_endprologue mov edx, ecx lea eax, [4*rdx] add rax, 15 and rax, -16 movabs r11, offset __chkstk call r11 sub rsp, rax mov rcx, rsp test edx, edx jle .LBB0_7 mov r8d, edx cmp edx, 8 jae .LBB0_3 xor r10d, r10d jmp .LBB0_6 .LBB0_3: mov r10d, r8d and r10d, -8 movabs rax, offset __xmm@00000003000000020000000100000000 movdqa xmm0, xmmword ptr [rax] mov rax, rcx add rax, 16 movabs rdx, offset __xmm@00000004000000040000000400000004 movdqa xmm1, xmmword ptr [rdx] movabs rdx, offset __xmm@00000008000000080000000800000008 movdqa xmm2, xmmword ptr [rdx] mov r9, r10 .p2align 4, 0x90 .LBB0_4: movdqa xmm3, xmm0 paddd xmm3, xmm1 movdqu xmmword ptr [rax - 16], xmm0 movdqu xmmword ptr [rax], xmm3 paddd xmm0, xmm2 add rax, 32 add r9, -8 jne .LBB0_4 cmp r10, r8 je .LBB0_7 .p2align 4, 0x90 .LBB0_6: mov dword ptr [rcx + 4*r10], r10d inc r10 cmp r8, r10 jne .LBB0_6 .LBB0_7: sub rsp, 32 movabs rax, offset \"DoSomethingWithLUT\" call rax nop mov rsp, rbp pop rbp ret The call to memset is now gone, because you've told Burst that any stack allocations within a method don't have to be initialized to zero. Additional resources [SkipLocalsInitAttribute] API reference"
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Burst copyright © 2022 Unity Technologies Source code of the package is licensed under the Unity Companion License (see https://unity3d.com/legal/licenses/unity_companion_license); otherwise licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.burst@59eb6f11d242/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.burst@59eb6f11d242/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: LLVM License Type: Apache 2.0 with LLVM Exceptions Copyright: The LLVM project does not collect copyright assignments, which means that the copyright for the code in the project is held by the respective contributors. Because you (or your company) retain ownership of the code you contribute, you know it may only be used under the terms of the open source license you contributed it under: the license for your contributions cannot be changed in the future without your approval. https://github.com/llvm/llvm-project/tree/main/llvm Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. --- LLVM Exceptions to the Apache 2.0 License --- As an exception, if, as a result of your compiling your source code, portions of this Software are embedded into an Object form of such source code, you may redistribute such embedded portions in such Object form without complying with the conditions of Sections 4(a), 4(b) and 4(d) of the License. In addition, if you combine or link compiled forms of this Software with software that is licensed under the GPLv2 (\"Combined Software\") and if a court of competent jurisdiction determines that the patent provision (Section 3), the indemnity provision (Section 9) or other Section of the License conflicts with the conditions of the GPLv2, you may retroactively and prospectively choose to deem waived or otherwise exclude such Section(s) of the License, but only in their entirety and only with respect to the Combined Software. Component Name: Legacy LLVM License License Type: The University of Illinois/NCSA Open Source License (NCSA) Copyright (c) 2007-2019 University of Illinois at Urbana-Champaign. All rights reserved. https://llvm.org/docs/DeveloperPolicy.html#legacy Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution. LLVM Team, University of Illinois at Urbana-Champaign, nor the names of its contributors may be used to endorse or promote products derived from this Software without specific prior written permission. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE. Component Name: Mono.Cecil License Type: MIT Copyright (c) 2008 - 2015 Jb Evain All rights reserved. Copyright (c) 2008 - 2011 Novell, Inc. All rights reserved. https://github.com/jbevain/cecil Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Smash License Type: BSD 2-Clause Copyright (c) 2021, Alexandre Mutel All rights reserved. https://github.com/xoofx/smash Redistribution and use in source and binary forms, with or without modification , are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: xxHash Library License Type: BSD 2-Clause Copyright (c) 2012-2021, Yann Collet All rights reserved. https://github.com/Cyan4973/xxHash Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: musl musl as a whole is licensed under the following standard MIT license: Copyright © 2005-2019 Rich Felker, et al. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Authors/contributors include: A. Wilcox Alex Dowad Alex Suykov Alexander Monakov Andre McCurdy Andrew Kelley Anthony G. Basile Aric Belsito Arvid Picciani Bartosz Brachaczek Benjamin Peterson Bobby Bingham Boris Brezillon Brent Cook Chris Spiegel Clément Vasseur Daniel Micay Daniel Sabogal Daurnimator David Carlier David Edelsohn Denys Vlasenko Dmitry Ivanov Dmitry V. Levin Drew DeVault Emil Renner Berthing Fangrui Song Felix Fietkau Felix Janda Gianluca Anzolin Hauke Mehrtens He X Hiltjo Posthuma Isaac Dunham Jaydeep Patil Jens Gustedt Jeremy Huntwork Jo-Philipp Wich Joakim Sindholt John Spencer Josiah Worcester Julien Ramseier Justin Cormack Kaarle Ritvanen Khem Raj Kylie McClain Leah Neukirchen Luca Barbato Luka Perkov M Farkas-Dyck (Strake) Mahesh Bodapati Markus Wichmann Masanori Ogino Michael Clark Michael Forney Mikhail Kremnyov Natanael Copa Nicholas J. Kain orc Pascal Cuoq Patrick Oppenlander Petr Hosek Petr Skocik Pierre Carrier Reini Urban Rich Felker Richard Pennington Ryan Fairfax Samuel Holland Segev Finer Shiz sin Solar Designer Stefan Kristiansson Stefan O'Rear Szabolcs Nagy Timo Teräs Trutz Behn Valentin Ochs Will Dietz William Haddon William Pitcock Portions of this software are derived from third-party works licensed under terms compatible with the above MIT license: The TRE regular expression implementation (src/regex/reg* and src/regex/tre*) is Copyright © 2001-2008 Ville Laurikari and licensed under a 2-clause BSD license (license text in the source files). The included version has been heavily modified by Rich Felker in 2012, in the interests of size, simplicity, and namespace cleanliness. Much of the math library code (src/math/* and src/complex/*) is Copyright © 1993,2004 Sun Microsystems or Copyright © 2003-2011 David Schultz or Copyright © 2003-2009 Steven G. Kargl or Copyright © 2003-2009 Bruce D. Evans or Copyright © 2008 Stephen L. Moshier and labelled as such in comments in the individual source files. All have been licensed under extremely permissive terms. The ARM memcpy code (src/string/arm/memcpy_el.S) is Copyright © 2008 The Android Open Source Project and is licensed under a two-clause BSD license. It was taken from Bionic libc, used on Android. The implementation of DES for crypt (src/crypt/crypt_des.c) is Copyright © 1994 David Burren. It is licensed under a BSD license. The implementation of blowfish crypt (src/crypt/crypt_blowfish.c) was originally written by Solar Designer and placed into the public domain. The code also comes with a fallback permissive license for use in jurisdictions that may not recognize the public domain. The smoothsort implementation (src/stdlib/qsort.c) is Copyright © 2011 Valentin Ochs and is licensed under an MIT-style license. The x86_64 port was written by Nicholas J. Kain and is licensed under the standard MIT terms. The mips and microblaze ports were originally written by Richard Pennington for use in the ellcc project. The original code was adapted by Rich Felker for build system and code conventions during upstream integration. It is licensed under the standard MIT terms. The mips64 port was contributed by Imagination Technologies and is licensed under the standard MIT terms. The powerpc port was also originally written by Richard Pennington, and later supplemented and integrated by John Spencer. It is licensed under the standard MIT terms. All other files which have no copyright comments are original works produced specifically for use as part of this library, written either by Rich Felker, the main author of the library, or by one or more contibutors listed above. Details on authorship of individual files can be found in the git version control history of the project. The omission of copyright and license comments in each file is in the interest of source tree size. In addition, permission is hereby granted for all public header files (include/* and arch//bits/) and crt files intended to be linked into applications (crt/, ldso/dlstart.c, and arch//crt_arch.h) to omit the copyright notice and permission notice otherwise required by the license, and to use these files without any requirement of attribution. These files include substantial contributions from: Bobby Bingham John Spencer Nicholas J. Kain Rich Felker Richard Pennington Stefan Kristiansson Szabolcs Nagy all of whom have explicitly granted such permission. This file previously contained text expressing a belief that most of the files covered by the above exception were sufficiently trivial not to be subject to copyright, resulting in confusion over whether it negated the permissions granted in the license. In the spirit of permissive licensing, and of not having licensing issues being an obstacle to adoption, that text has been removed. Component Name: SLEEF Boost Software License - Version 1.0 - August 17th, 2003 Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and accompanying documentation covered by this license (the \"Software\") to use, reproduce, display, distribute, execute, and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the Software is furnished to do so, all subject to the following: The copyright notices in the Software and this entire statement, including the above license grant, this restriction and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all derivative works of the Software, unless such copies or derivative works are solely in the form of machine-executable object code generated by a source language processor. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: gRPC for .NET Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Component Name: Google.Protobuf Copyright 2008 Google Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Code generated by the Protocol Buffer compiler is owned by the owner of the input file used when generating it. This code is not standalone and requires a support library to be linked with it. This support library is itself covered by the above license. Component Name: mimalloc MIT License Copyright (c) 2018-2021 Microsoft Corporation, Daan Leijen Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. [2.8.2] - 2025-05-06 Fixed false positive error showing in console if creating a workspace from the Hub with a version of the Unity Editor shipping with a default Version Control package older than version 2.7.1. [2.8.1] - 2025-04-29 Added Added to the list of branches a context action to hide branches. You can use the filter to list the hidden branches and unhide them from the context menu. Added to the list of branches a context action to diff the branch. Added to the list of changesets a context action to create a new branch from a specific changeset. Added to the check-in and shelve notification a link to go to the list of changesets/shelves. The user can also copy the direct diff link. Added to the merge operation a notification with a link to go to the pending changes. Added to the undo and update workspace operations an ephemeral notification. Added to the status bar an action to copy to the clipboard the name of the current branch. Added to most dialogs an \"Enter\" keyboard shortcut to confirm the operation like the corresponding button. Added to the history of a folder a context action to revert changes. Added to the history a context action to diff changes for files that were moved/renamed. Added to the pending changes view the user avatar if available from Gravatar. Added to the merge view the avatars for authors of changes. Fixed Fixed the UI that could start refreshing forever, never completing the ongoing operations. Fixed the auto checkout for assets to only apply for file containing actual changes. Fixed project download from the Hub that was silently skipped when trying to download inside another workspace. It's now logging an explicit error in the console. Fixed a null exception that could occur when switching to the changesets tab very quickly after checkin. Fixed bulk editing meta files that was only performing a single checkout for the last element. Fixed a null exception that could occur on Revert to this revision if the selected change triggered a domain reload. Fixed the scroll that was not at the top when opening the branches or the shelves view. Fixed an error that was showing when deleting a shelveset that wasn't the one selected in the list. Fixed merge success notification that was showing in the view potentially colliding with contents. Implemented a mechanism to fix the path to UnityYAMLMerge.exe in the client.conf so it always points to an existing Unity installation. Fixed the apply shelve operation so that it checks for dirty changes and warn the user before applying the shelve. Fixed Undo changes of a Moved asset using the Asset Context Menu from the Project View that was leaving an inconsistent .meta file. Added the option to add a folder by path to the ignore or hidden changes list, instead of the incorrect option \"Using the item extension\". Fixed incorrect branch name in the history of a file for a revision where it was moved, displaying details of the move instead of the name of the branch. Fixed the Unity Editor crashing on macOS when opening the Unity Version Control window with the PiXYZ Plugin installed. Fixed a null exception that occured when using the diff search filter without any shelve in the repository. [2.7.1] - 2025-02-13 Added Added a button to shelve selected pending changes. You can inspect the shelves content, and apply them to your workspace. Added the option to shelve pending changes when switching to another branch (or changeset). You can decide to apply them automatically after the switch. Added a context menu entry to create a code review from the list of branches (or changesets). You can decide to open the Desktop App or the Unity Cloud website. Changed Serialized the Checkin comment and tick selection so they are kept on any domain reload and play mode. Optimized incoming changes & merge to only reload the Package Manager when needed. Added dedicated toolbar buttons to open the list of branches and the Branch Explorer of the Desktop App. Reworded the changeset context menu \"Undo this change\" to \"Revert this file to the previous revision\" so it’s more explicit. Moved the 'Unity Version Control' menu item under 'Window'/'Version Control' submenu starting from Unity 6.1. Improve the Create workspace window to suggest the matching Unity Cloud project if it exists. Fixed Ensured ignore.conf is not being reformatted when adding or removing an ignore rule, so it keeps empty lines and comments. Fixed missing checked-out for renamed assets. Fixed rename asset leaves 'Added' + 'Remove locally' status instead of 'Moved'. Fixed console error GUI Error: Invalid GUILayout state in PlasticWindow view which is caused under some circumstances. Fixed null exception on entering in Play Mode before creating the workspace. Fixed lock statuses to correctly refresh in Project View and Inspector after merging. Fixed a performance issue by preventing the ConfigureLogging call on every domain reload when Unity Version Control is not used, reducing the load time by ~200ms. . Fixed the create branch operation to work in Gluon mode which uses partial workspaces. [2.6.0] - 2024-11-28 Added Added the ability to merge a branch or a changeset, using a new context menu actions Added file conflict & dir conflict context menu actions to the merge view Added diff and merge settings in Project Settings -> Version Control -> Unity Version Control Settings Added merge options dialog to the merge view Added copy path & history context menu actions in all menus where they apply Added an menu entry to 'Open in Unity Cloud' showing the repository in the Unity Dashboard Changed Updated the minimum supported version to Unity 2021.3.0f1 Removed support for migrating old Collaborate workspaces to Unity Version Control Hide from the public documentation all internal APIs that were previously visible by mistake Optimized switching operations to only triggers the Package Manager to reinstall packages when needed Optimized incoming changes to only reload the Package Manager when needed (Gluon/partial workspace only for now) Automatically add UnityDirMonSyncFile rule for existing ignore.conf to avoid triggering unnecessary finding changes operation Improved the “search” edit box so it can resize when there is not enough space in the toolbar Replaced the \"D\" DevOps icon by the branching icon used in the Hub Replaced the logo of Unity in the Sign in to Unity VCS window Fixed Fixed files getting checked out even though they are in hidden_changes.conf Fixed manual login to Cloud that didn't work with an Enterprise installation Fixed resolve conflicts not informing about lack of UVCS installation Fixed the Invite users to cloud organization when using an Enterprise installation Fixed new child branch not created from HEAD after update Fixed the learn more (here) link that showed the hex color value in Unity 6 Fixed link to invite members in Unity Cloud. Fixed a crash in the create workspace window when unable to resolve a @unity organization Fixed incoming changes view that was not kept as selected after resolving some conflicts Fixed workspace name that was not refreshed after repository manual creation or selection Added a warning message to inform users about mismatching cloud project. Removed from the Create Workspace window the Local server that was present with no installation of UVCS Replaced hardcoded urls pointing to plasticscm.com [2.5.2] - 2024-09-25 Fixed Fixed token renewal issue: Can't obtain a new token (Message: Invalid Refresh Token., Code: 132.104) Reworded labels in the Create Repository window and added a link to Create a new organization project. [2.5.1] - 2024-09-04 Added Added support for the new @unity organizations Allow deletion of non-empty branches that have not been merged anywhere New setting to control if new files must be automatically added to source control Changed Improve the dialog to install Unity Version Control from the Editor Fixed Fixed 'an existing xxx operation has locked the workspace' error on finding changes operation Fixed a case of a hang happening on Editor quit Fixed the login that could fail for Enterprise installation Fixed undo operation that didn't capture changes in packages Fixed history that was not shown when there was no desktop client installed Fixed unity 6 Editor going into the background after a dialog was closed Fixed wrong font size when changing to changesets view Fixed the \"Upgrade plan\" button in Unity plugin that used a obsolete redirection link Fixed Logs that were configured too late in the initialization Fixed the minimum supported version (2020.3.48f1 LTS) in the README [2.4.4] - 2024-07-19 Fixed Fixed the Unity Editor stuck on \"Creating workspace\" when \"Use Unity Version Control\" was selected from the Hub [2.4.3] - 2024-06-20 Added Changed the default ignore.conf to not ignore itself Added \"Undo unchanged\" and \"Undo checkouts keeping changes\" options to pending changes view Removed focus redirection after Check-in Fixed Moving folders in the Editor now correctly use the UVCS \"Move\" operation Fixed hang on domain reload Fixed \"item with the same key has already been added\" error Fixed failure to delete a .meta file when deleting a private folder from the pending changes Supported workspace name with non-latin characters in Pending Changes Fixed text cut-off in filter rules dialog Fixed unexpected error while switching between branches Fixed error after renaming a parent branch of the working branch Fixed variables's value becoming clear after resolving conflict in inspector Removed misleading indication about shelves Fixed column sorting in pending changes view Fixed missing incoming changes after removing a branch Fixed \"Collection was modified\" error when doing multiple renames in a row Fixed undo & check-in operations not working when the current scene was never saved Fixed check in error if nothing is selected in the pending changes tree [2.3.1] - 2024-02-27 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added New view to list and manage locks. Fixed Fixed DropdownField not working properly on a ModalUtility window on MacOS. Fixed issue with existing checkout operations locking the workspace. Reviewed initialization and application lifecycle. Fixed layout error when switching checkout status in the inspector. Fixed Diff option unavailable for .prefab. Fixed UI error when opening and closing multiple closable tabs. Ensured branch creations start from the latest changeset. Unable to expand added item list after collapsing. Pending Changes context menu had the view file history greyed out for asset+meta. Preconfigured date format was not recognized as a valid DateTime. Fixed finding changes operation being firing constantly. Removed obsolete content in package documentation. Fixed typo in locks tooltip. Replaced the text \"plasticscm.com\" by a https://unity.com/solutions/version-control in the package.json [2.2.0] - 2023-10-06 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added button for organization owner/admins to upgrade to DevOps subscription. Included new decorators for retained & locked files. Changed Updated description in the package.json, including an updated link to get started. Fixed Fixed failed operations when the workspace is already locked. [2.1.0] - 2023-09-01 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added command to support Hub creating a new project, and connecting a project to Unity Version Control. Show a message with a link to invite users to the organization after the first checkin. Changed Moved the button to invite users to the organization from the submenu to the toolbar. Removed Don't write cloudProjectId in ProjectSettings.asset anymore since it should only be managed by Services. Fixed Fixed Add to ignored/hidden changes list from the Project window creating a negative rule. Fixed Switch to changeset not working on Gluon partial workspace. [2.0.7] - 2023-07-25 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed the Unity Version Control icon disappearing from the Editor Toolbar on domain reload. Fixed the popup stating \"An existing checkout operation has locked the workspace\" when trying to check in a scene with unsaved changes. [2.0.5] - 2023-05-31 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed remaining references to 'Plastic SCM' in localized labels. [2.0.4] - 2023-04-14 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed 'Texture2D' does not contain a definition for 'ignoreMipmapLimit' error when installing Unity Version Control on previous Unity Editor Versions Fixed broken sign in dialog style when waiting for user to complete sign in Fixed NullReferenceException when opening a new project and the user doesn't have a Unity Version Control organization linked to a Unity ID [2.0.3] - 2023-03-29 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Changed the icons for Unity Version Control rebranding Changed onboarding workflow Fixed Fixed blurry icons in the Unity Version Control window and toolbar button Fixed Pending Changes tab not always opening its selected item's location in Project window Fixed \"Checked-out (changed)\" status icon not showing up on Pending Changes tab Fixed issue that prevented new packages from being installed unless user enters play mode [2.0.1] - 2023-02-17 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Updated branding from \"Plastic SCM\" to \"Unity Version Control\" Improved offline experience by disabling the plugin when there is no internet connection [2.0.0] - 2023-01-11 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Removed Collab from the package [1.17.7] - 2022-10-28 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added offline mode toggle for smoother offline experience Fixed Fixed performance issue with FindWorkspaceForPath method called multiple times every frame Fixed performance issue with UI.CooldownWindowDelayer.OnUpdate running on project without Plastic SCM workspace [1.17.6] - 2022-10-06 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Changed the \"Go back to changeset\" option in Changesets tab to \"Revert to changeset\" Improved notification banner appearance Fixed Fixed editor refresh triggering when a workspace update is in progress Fixed pending changes show global ignored as private Removed encryption checkbox from create organization dialog [1.17.2] - 2022-07-06 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added notification banner on the status bar for live updates Changed Renamed \"Invite members to workspace\" option to \"Invite members to organization\" Fixed Fixed not being able to view changesets in a Gluon workspace Fixed not being able to insert carriage return in checkin dialog [1.17.1] - 2022-06-21 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed missing references in synced prefabs [1.17.0] - 2022-06-13 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to enable changelists and display them in pending changes tab Added changelist related options to pending changes context menu Fixed Fixed editor hangs when there is no network available Fixed existing checkout has locked the workspace error Fixed checkin fails over unstable connection [1.15.18] - 2022-05-18 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed editor hang when entering Play Mode [1.15.17] - 2022-04-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added checkin comment column to Incoming Changes view Changed Updated Go Back confirmation message to be consistent with feature Updated Create Child Branch dialog to focus on branch name field when opened Improved messaging of Subtractive Merge after using Go Back feature Fixed Fixed assets not added correctly when Plastic SCM window is not open Fixed wrong position of overlay icons on Pending Changes view Disallowed Go Back feature to a changeset from another branch [1.15.16] - 2022-03-28 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added \"Switch to changeset\" menu option in changesets view Added \"Go back to changeset\" menu option in changesets view Changed Removed category icons from views Removed \"com.unity.services.core\" package dependency Fixed Fixed light theme icons used in dark theme after pulling incoming changes Fixed \"Input string was not in a correct format\" error [1.15.15] - 2022-03-09 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added checkout option in scene prefab view Changed Updated file overlay icon size to adapt to project window zoom level Updated the styling of number of items in a category in Gluon incoming changes view Fixed Fixed Plastic X not opening from plugin menu Fixed error when trying to invite members to proect Fixed editor unhandled errors being hijacked by the plugin Fixed toolbar icon not displaying incoming changes notification when Plastic window is closed Fixed VCCache::instance != NULL error when opening a project with Plastic window opened [1.15.13] - 2022-02-14 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added branch name column in changeset view Changed Updated checkin comment box to keep the last comment after checkin error Fixed Fixed performance regression in large projects due to FindObjectsOfTypeAll calls [1.15.12] - 2022-01-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to \"Save Revision as\" to the context menu in the changesets view Added incoming changes overview bar for Gluon workspace Changed Updated the styling for number of items in category for pending changes view Updated the styling for number of items in category for changesets view Updated the styling for tabs close button Updated the color in different sections of the plugin Reduced dialog padding for the \"Create Branch\" dialog Updated the display overlay icons to show even if PlasticSCM window is closed Updated styling of number of items in incoming changes category Improved plugin initialization process and let the plugin functions without needing the Plastic window opened Disabled the invite button when user does not have invite permission or not on a cloud repo Fixed Fixed size info in incoming changes view does not match actual changes size Fixed checkin and checkout options not respecting inspector locked status Fixed buttons in inspector view displayed even when Plastic window is closed Fixed icon incorrect sizes Fixed errors on create branch dialog Fixed Newtonsoft.Json.dll conflicts with other external packages Fixed editor objects count increasing when hovering over Plastic window or toolbar button Fixed ArgumentOutOfRange exception when creating a branch Fixed scene reloading not happening after creating a new branch [1.15.7] - 2021-12-02 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to \"Save Revision as\" to the context menu in the changesets view Added incoming changes overview bar for Gluon workspace Changed Moved Plastic Package settings to the Unity Project Settings window Refined styling for Updating Workplace success state Updated texts for empty state and overview bar Removed Incoming Changes notification from empty state Updated the text for Forced Checkout option Refined the status overlay icons Updated the refresh icon on the toolbar Updated the texts for empty checkin message dialog Fixed Fixed capitalization of Pending Changes and File History tab names Fixed the amount of spacing after the Item column title in the Pending Changes tab Removed pin striping from line items in File History tab Fixed project view context menu and icons missing after Collaborate project migration Fixed migrated projects not downloading correctly from Unity Hub [1.15.4] - 2021-11-10 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Add option to \"Add to ignore file\" in context menu in the project view Added empty state message for Pending Changes tab Added success state message for Pending Changes tab Added metrics for Branches tab functionalities Changed Removed pinstriping in the Gluon Incoming Changes window Removed the “Nothing to download” bar from the Incoming Changes window when there are no items to download Changed the default metadata columns shown in the Incoming Changes screen Updated the alignment of sorting arrows to the right of the column Fixed Fixed UI overlays in Project view missing on changed assets when force checkout is disabled Fixed console error when selecting object in Scene view hierarchy or creating a new asset Fixed NullReferenceException after closing the Plastic SCM window [1.15.1] - 2021-10-21 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added visual overview bar to the incoming changes tab Added progress dialog for the migration process Added Branches tab that shows a list of all branches in the repository Added option and dialog to create a child branch from selected branch. Added option to switch to another branch Added option and dialog to rename a branch Added option to delete a branch Added a preference to save if the window should open the Branches tab by default Added metrics for Plastic SCM installation window usage Changed Updated texts for workspace modes selection and checkin comment box Updated status bar notification icons Fixed Fixed inverted text for the force checkout option Fixed typing capital O in checkin comment would open the selected item Fixed loading indicator not centered on Plastic SCM installation window Fixed installing Plastic SCM would sign out user from the plugin Removed extra refresh button on Gluon's Incoming Changes tab Fixed loading indicator not centered on Plastic SCM installation window Fixed missing Plastic SCM window option when user is not signed in on Unity Hub Removed meta file warning message for the deleted Beta folder Fixed Plastic SCM menu missing from Project view context menu [1.13.5] - 2021-09-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added workspace migration from Collab to Plastic which can be done with or without Plastic installed Added notification status icons Added light and dark mode versions of avatar icon Changed Updated texts for migration Improved usage analytics around Editor and Plugin version Workspace Migration Adjustments Fixed Renamed the CoreServices namespace so it doesn't conflict with other packages Devex integration to properly depend on Core Fixed some situations where the history window would be blank Fixed missing Enterprise login link Fixed low resolution icons in light theme [1.11.2] - 2021-08-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added horizontal scroll bar to Changesets list for easier viewing Added auto-login for SSO credentials handler Added metrics for changeset tab usage Added metrics for checkin actions Added new Undo icon Added missing API documentation Added ability to modify assets without checkout Added ability to allow empty checkin messages Added empty checking message localization Added Plastic toolbar button to Unity editor Added notification icon for incoming changes to Plastic toolbar button Changed Removed the unneeded refresh button from History Tab Moved search bar to the top right global icon section in all tabs Updated capitalization of options in the Settings context menu Updated tab button styling to be consistent with Unity Editor conventions Status bar visible across all tabs Moved refresh button to the toolbar at the top right corner of the window Moved changesets time period selector to the right corner of the window Removed \"Changes of changeset\" header on the Changesets tab Moved number of selected items next to \"Item\" metadata title on the Pending Changes tab Improved refresh icon resolution Changed changesets detail to appear in vertical column Reduced default number of columns in changesets tab The number of changesets is no longer displayed in changesets tab Changed Launch branch explorer into an icon with tooltip Removed the hide changes button in changesets tab Moved incoming change prompt and button into a status bar Changed \"Launch Plastic\" to \"Launch Plastic SCM\" in options menu Wording change for plastic installation Updated file status icons Fixed Fixed a bug where the Texture2D error would pop up after downloading a project Fixed a bug when context menu would sometimes disappear Fixed small textbox on checkin dialog when launched from context menu Fixed a workspace NullReferenceException bug Fixed notification icon not showing on Plastic window Fixed auto login errors not showing up for users Fixed unexpected error message after user switched workspace to a label [1.9.0] - 2021-07-13 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added Checkin and Update confirmation notification Added auto sign in when logged into Unity account Changed Simplified UI: decluttered UI Improved load time performance Fixed Fixed view not switching to workspace after creating an Enterprise Gluon workspace Fixed contextual menu not showing up in project view Fixed SSO renew token after password change Fixed some namespace collisions with Antlr3 [1.7.1] - 2021-06-25 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added support for inviting other members. This option is available from the gear / settings icon. Added support for signing in with Cloud Edition. This is available during the onboarding screen if you have never signed in. Added support for turning off Plastic in their project. This option removes the Plastic metadata from your directory. This option is available under Assets > Plastic SCM > Turn off Plastic SCM Added notification on the Plastic SCM tab title to indicate incoming changes. Users will no longer need to have the Plastic SCM window visible to know there are incoming changes. Auto configuration of SSO Added date column in incoming changes Changed Updating license to better conform with expected customer usage. Updated documentation file to meet standards. Updated third-party usage. No longer requires downloading of the full Plastic client. Basic features will work without additional installation. Features that require the full Plastic client will allow download and install as needed. Usability improvements around checking in code Improved update workspace tab UX Plastic SCM context menu is now available even if the Plastic SCM window is closed Fixed Stability and performance improvements [1.5.7] - 2021-04-07 Unreleased The Version Control package will be expanding to include both Collaborate and Plastic SCM version control interfaces. This release is preparing for that move and contains no new functionality or bug fixes for Collaborate. Changed Collaborate Package renamed to Version Control with changes to package display name and description. Fixed Fixed NPE when updating the version of the Collab package. [1.3.9] - 2020-07-13 Fixed Unnecessary use of texture compression in icons that slowed down platform switching Update publish button state when selected changes update Use colorized icons when changes are available. [1.3.8] - 2020-06-08 Fixed Fix incorrect priority of error messages Fix Collab button being stuck in inprogress state Fix error when partially publishing without the window open [1.3.7] - 2020-01-30 Changed Bulk revert is now supported. Collab is blocked in play mode. Fixed Fixed services window's links to open Collab. [1.3.6] - 2020-01-21 Fixed Fixed compile errors when removing the NUnit package by removing unnecessary references. [1.3.5] - 2020-01-08 Fixed Fix \"accept mine\" / \"accept remote\" icon swap in conflicts view. [1.3.4] - 2019-12-16 Changed Window state is no longer restored after the window is closed and opened. Fixed History tab failing to load on startup if it is left open in the previous session. Progress bar percentage not matching the bar. History list correctly updates after a new revision is published. UI instabilities when restoring or going back to a revision with a different package manifest. Improve handling of changes to the project id. [1.3.3] - 2019-12-10 Changed Disable UI test cases that can be unstable. [1.3.2] - 2019-12-05 Changed Update UX to UIElements. Increased minimum supported version to 2020.1. Update Documentation to required standards. [1.2.16] - 2019-02-11 Fixed Update stylesheet to pass USS validation [1.2.15] - 2018-11-16 Changed Added support for non-experimental UIElements. [1.2.11] - 2018-09-04 Fixed Made some performance improvements to reduce impact on ReloadAssemblies. [1.2.9] - 2018-08-13 Fixed Test issues for the Collab History Window are now fixed. [1.2.7] - 2018-08-07 Fixed Toolbar drop-down will no longer show up when package is uninstalled. [1.2.6] - 2018-06-15 Fixed Fixed an issue where Collab's History window wouldn't load properly. [1.2.5] - 2018-05-21 This is the first release of Unity Package CollabProxy. Added Collab history and toolbar windows Collab view and presenter classes Collab Editor tests for view and presenter"
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/AccessRemoteProjects.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/AccessRemoteProjects.html",
    "title": "Access remote projects | Inventory System",
    "summary": "Access remote projects In the Unity Hub v3, click Open > Open Remote Project to see the list of your version control repositories that contain a Unity project. Select the project and click Next. Select the Editor version and platform and click the change version button. Your local version control workspace will be created for you. The latest version of the project will be downloaded and the Editor will open with the latest version of your Unity project."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/AddMembers.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/AddMembers.html",
    "title": "Add team members | Inventory System",
    "summary": "Add team members To invite team members to contribute to your project: From the toolbar, click Invite Members to Workspace. In your DevOps version control dashboard, click Add new user. You can also send invitations and add different permission types for each user."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/CreateProjects.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/CreateProjects.html",
    "title": "Create projects | Inventory System",
    "summary": "Create projects To create projects: In the Unity Editor, open the Unity Version Control window and click on Create Workspace. It will suggest names for your repository (shared files and history on the server) and workspace (your local copy on your computer). If you wish to use an existing version control repository, click the three dots next to the repository name, and select a repository from the list. Select the type of workspace that fits your needs. Developer workspace With this workspace, you can work with branching and merging. Gluon workspace This workspace tailored for artists allows you to pick the files you want to work on and check them back in without updating your whole workspace. Add asset files associated with your project. version control will display the project files from the asset folder in the Pending changes tab. You can choose specific files to include or add all to the repository by selecting the files and clicking Checkin changes. version control will automatically perform a check in for appropriate folders and files – such as package files and project settings – when it’s set up from the Unity Editor. You can view these in the Changesets tab. Once your initial asset check in is complete, you’re set up with version control for Unity and ready to create. See also See also the get started detailed guides: Get started with a new repository. Get started with an existing repository."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStarted.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStarted.html",
    "title": "Get started with Unity Version Control | Inventory System",
    "summary": "Get started with Unity Version Control The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. Unity Version Control enables you to work collaboratively by providing advanced features such as branching, locking, merging, and a standalone Desktop GUI. Learn more about Unity Version Control. To start with a new version control repository for your project, see Get started with a new repository. To start from an existing Unity Version Control repository, see Get started with an existing repository. For more information on how to get started, refer to the Unity Version Control documentation."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStartedExistingRepository.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStartedExistingRepository.html",
    "title": "Get started with an existing Unity Version Control repository | Inventory System",
    "summary": "Get started with an existing Unity Version Control repository Suppose you want to start working on a Unity project in an existing Unity Version Control repository and already have a Unity Version Control account linked to your Unity ID. In that case, you will be able to open the project straight from the Unity Hub. A workspace will automatically be created for your project on your machine. In the Unity Hub v3 Beta, click Open > Open remote project to see the list of your Unity Version Control repositories that contain a Unity project. Click the project and click Next. Click the Editor version and platform and click the change version button. In the Editor pop-up, click the Migrate button to migrate your local workspace to a Unity Version Control workspace Once the migration is completed, click the Open Unity Version Control button. Accessing the Unity Version Control Window You can access the Unity Version Control window in the Unity Editor by clicking Window > Unity Version Control."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStartedNewRepository.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GetStartedNewRepository.html",
    "title": "Get started with a new version control repository | Inventory System",
    "summary": "Get started with a new version control repository Note: To start from an existing version control repository, see Get started with an existing version control repository. You can walk through a straightforward onboarding wizard when creating a repository for your Unity project. This new wizard will help you: Set up your account and configure your repository for your Unity project, enabling you to sync to a version control Cloud Edition repository. Generate a standard ignore file that prevents unnecessary components of your Unity project from being checked in. Automatically do the first check-in so that your repository is in sync with your local changes. Open your Unity project. To access the version control window in the Unity Editor, click Window > version control: In the version control onboarding window, complete the steps to continue: Unity connects your project to your version control Cloud repository; version control automatically creates an ignore file in the workspace for Unity projects so it doesn't track files that shouldn't be part of the repository. It also creates a standard automatic checkin during the initial setup. So now you're all set to start using version control! Note: Basic version control actions, such as viewing pending changes, checking in changes, and viewing changesets, don’t require a version control Client install. However, if you want to use more advanced features, such as branching and diffing changeset, you will be prompted to download the version control client (if you have not already done so):"
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GitUsers.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/GitUsers.html",
    "title": "Unity version control for Git users | Inventory System",
    "summary": "Unity version control for Git users GIT Unity VCS Explanation To Commit To Check in To Check in is to submit changes to the repo. Commit Changeset Each new change on the history of the repo, grouping several individual file and directory changes. Master Main When you create a repo in Unity VCS, there's always an \"empty\" branch. Unity VCS calls it Main. To checkout To update Downloading content to the workspace (working copy). This is called \"update\" because in Unity VCS, \"checkout\" has a different meaning. Checkout When you checkout a file in Unity VCS, you're saying you are going to modify the file. Exclusive checkout or lock This is locking a file so nobody can touch it. It’s only useful for non-mergeable files, like binaries, images, or art in a video game. Rebase Unity VCS handles branching differently than Git. In Unity VCS, a rebase is just a merge operation. Repository Repository Where the entire history of the project is stored. Working copy Workspace In Git, you have the working copy and the repository in the exact location. You have a working copy and a .git hidden dir with the repository. In Unity VCS, this is slightly different since repositories and workspaces are separated. You can have several workspaces working with the same local repository."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/Glossary.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/Glossary.html",
    "title": "Glossary | Inventory System",
    "summary": "Glossary General terms Project In Unity, you use a project to design and develop a game. A project stores all of the files related to a game, such as the asset and Scene files. See 2D or 3D projects. Version Control A system for managing changes to a set of files. You can use Unity in conjunction with most version control tools, including Unity Version Control and Perforce. See Version Control. Ignore file A special file used in many Version Control Systems which specifies files to be excluded from version control. In Unity projects, several folders should be excluded from version control. Repository A shared history of changes made to the project's files, saved on a server. Workspace Your local copy of the repository, interacting with the version control system. It's where you download the project's files, make the required changes and perform checkins. Check-in Check-in is the act of submitting changes from your workspace to the shared repository. You can enter a comment before checking in your changes. Unity Version Control terms Developer Workflow Developers have access to the branch explorer directly from inside Unity and easily switch branches. Gluon Workflow Artists can take advantage of the Gluon visualized interface and workflow from inside Unity. Organization The organization handles different sets of repositories in the Cloud. Inside the organization, you can create as many repositories as you need."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/MainFeatures.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/MainFeatures.html",
    "title": "Overview of features | Inventory System",
    "summary": "Overview of features Pending Changes The Pending Changes tab allows you to view all pending changes in your workspace. These changes are not checked into the repository. In this tab, you can select which files you want to check in, add a comment, and check in the changes. Note : You can check in a specific file using the version control contextual menu in the project view or the Checkin button in the Inspector window. In the example below, the user adds a GameScene. They can check in the scene using the Pending Changes tab or the Checkin option in the contextual menu. Incoming Changes The Incoming Changes tab allows you to view all incoming changes and conflicts and update your local project. Any changes made to your project prompts an \"Incoming changes\" notification at the top right of the version control window. Tip : Check the Incoming Changes tab frequently to avoid facing future change conflicts in your team. Project History Use the Changesets tab to view all changes made to your project as they occur chronologically, along with who made the changes and when. You can sort by columns and alter the chronological view of the story. Double-click any file in a changeset to go to the File History tab, and display every changeset. In the File History view, right-click on a change and click Save the revision as… to restore the file's former state. This is useful if you had previously deleted some logic that you now need. You can also view the changes made to a specific file in the Project view through a contextual menu, then revert to an earlier revision of the file. Locks The File locks tab allows you to list and filter all locks in your repository, and gives you the ability to release or remove them selectively. To open the view, you can use the \"Show Locks\" button available in the toolbar."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/MoreHelp.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/MoreHelp.html",
    "title": "More help | Inventory System",
    "summary": "More help To find more information on working with the Unity version control plug-in, see Getting started with Unity Version control. You can also post and find questions related to Unity version control in the Unity forum."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/QuickStartGuide.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/QuickStartGuide.html",
    "title": "Quick start guide | Inventory System",
    "summary": "Quick start guide The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. Get started with Unity Version Control"
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/ReconnectCB.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/ReconnectCB.html",
    "title": "Connect Unity Cloud Build | Inventory System",
    "summary": "Connect Unity Cloud Build Unity Cloud Build is a continuous integration that automatically creates multiplatform builds in the Cloud in minutes. You can point Cloud Build toward your version control system to: Automate new builds Build faster Catch problems earlier Iterate on your builds more efficiently with agility. To get started, see Pay as you go with Cloud Build."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "About the Version Control package Quick start guide Create projects Access remote projects Add team members Connect Cloud Build Get started with Unity Version Control Get started with a new version control repository Get started with an existing version control repository Main features Pending Changes Incoming Changes Project History Locks Unity Version Control for Git users Glossary General terms Unity Version Control terms More help"
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Documentation~/index.html",
    "title": "About the Version Control package | Inventory System",
    "summary": "About the Version Control package The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. It is installed by default with the Editor, and follows the Unity support schedule. The minimum supported version of the Unity Editor is 2021.3.0f1 LTS. Quick start guide Get started with Unity Version Control"
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Editor/_Deprecated/README.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Editor/_Deprecated/README.html",
    "title": "| Inventory System",
    "summary": "Deprecated public classes that we need to keep until we change the major version of the package to 3.x. Removing any public API in a minor version is forbidden. The issue is that updating the major version of a default package is forbidden in a stable Unity Editor version, so we cannot do it during the lifetime of Unity 6.x."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Version Control copyright © 2025 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity.com/legal/licenses/unity-package-distribution-license). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/README.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/README.html",
    "title": "Unity Version Control Package | Inventory System",
    "summary": "Unity Version Control Package This package provides an in-editor interface for teams to work with Unity Version Control (Unity VCS), our leading version control solution, directly in Unity. Note that this project is the natural evolution of the old Collaborate package, hence its technical name \"collab-proxy\". Documentation - Changelog Compatibility The minimum supported version of the Unity Editor is 2021.3.0f1 LTS. Windows and macOS are officially supported, not Linux. The solution is exclusively targeting .NetStandard 2.0, and will not work with the legacy Mono runtime."
  },
  "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@c854d1f7d97f/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: File System Watcher https://docs.microsoft.com/en-us/dotnet/api/system.io.filesystemwatcher?view=net-5.0 License Type: MIT Copyright (c) Microsoft Corporation Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Zlib64 https://zlib.net/ License Type: zlib/libpng License (Zlib) version 1.2.11, January 15th, 2017 Copyright (C) 1995-2017 Jean-loup Gailly and Mark Adler This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This notice may not be removed or altered from any source distribution. Jean-loup Gailly Mark Adler jloup@gzip.org madler@alumni.caltech.edu Component Name: LZ4 Library/LZ4x64 https://github.com/lz4 License Type: BSD [The BSD License] Copyright (c) 2011-2020, Yann Collet All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: Antlr3/Antlr https://www.antlr3.org/ License Type: BSD [The BSD License] Copyright (c) 2010 Terence Parr All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the author nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: Log4Net https://logging.apache.org/log4net/ License Type: Apache 2.0 Copyright (c) 2004-2017 The Apache Software Foundation Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [2.5.1] - 2024-09-06 Changed Updated Burst dependency to version 1.8.17 Updated Unity Test Framework dependency to version 1.4.5 Updated entities packages dependencies Fixed Certain cases would cause an ILPostProcessor to fail, blocking compilation, but no more. [2.5.0-pre.2] - 2024-07-17 Changed Updated Burst dependency to version 1.8.16 [2.5.0-exp.1] - 2024-06-11 Added SortJobDefer type for scheduling sorting on NativeList when content of the list is not known ahead of time, and depends on dependent jobs. Changed Update entities package dependencies Fixed Clarified usage of \"front\" and \"end\" in API docs for NativeQueue and UnsafeQueue Default constructed container can call IsCreated and IsEmpty properties. [2.4.3] - 2024-08-14 Changed Update entities package dependencies [2.4.2] - 2024-05-30 Changed Update entities package dependencies [2.4.1] - 2024-04-26 Changed Release preparation Updated Burst dependency to version 1.8.13 [2.4.0] - 2024-03-22 Changed *Release Preparation [2.4.0-pre.5] - 2024-02-13 Changed Updated Burst dependency to version 1.8.12 Fixed Memory leaks in unit tests. Memory leak when using NativeBitArrayUnsafeUtility.ConvertExistingDataToNativeBitArray. Brace parsing in FixedString AppendFormat handles incorrect formatting now Updated Upgraded Test Framework version to 1.4.3 [2.4.0-pre.2] - 2023-11-28 Changed Updated Burst dependency to 1.8.10 Add lightweight spinlock to secure multithread write access to the ChildSafetyHandles in custom allocator framework. [2.4.0-exp.2] - 2023-11-09 Added DataStreamReader.ReadBytes and DataStreamWriter.WriteBytes now have a variant that takes a Span<byte> as a parameter, making it easier to use these APIs with regular byte[] arrays. Changed The minimum supported editor version is now 2022.3.11f1 Deprecated Removed Fixed Security [2.3.0-pre.3] - 2023-10-17 Changed Updated version for release preparation. [2.3.0-exp.1] - 2023-09-18 Added Added a new GetUnsafeReadOnlyPtr method to DataStreamReader. This can be used as an escape hatch if access to the underlying buffer of the stream reader is required. Fixed A previous release did not allow unsafeList.RemoveRange(unsafeList.Length, 0) anymore, which could cause failures in many common algorithms. This has been fixed. Made SortJob.SegmentSort, and SortJob.SegmentSortMerge public to allow generic job type registration. UnsafeList.RemoveAtSwapBack could read invalid memory when the last element of the list is removed Data elements in FixedList<T, U> now respect natural alignment for the type T [2.2.1] - 2023-09-11 Changed Updated Burst dependency to version 1.8.8 Fixed Previously the Sort extension for NativeContainers could access memory out of bounds of the container when an invalid IComparer<T> was implemented for T: Comparers must return three states (<0, 0, >0). Sort will now no longer access invalid memory and when running with collection checks enabled (e.g. always on in Editor) or using UNITY_DOTS_DEBUG in player builds, an additional check at the beginning of the sort will validate the comparer is implemented correctly and inform users otherwise. Added Added a dependency on the com.unity.test-framework.performance package [2.2.0] - 2023-06-20 Changed Made SegmentSort and SegmentSortMerge public to allow generic job type registration. Fixed Previously it was possible to change the length of a NativeList via the Length property setter while the NativeList is being used inside of a job without an InvalidOperationExcpetion being thrown for the unsafe access. [2.1.4] - 2023-04-25 Removed Dependency on com.unity.test-framework.performance Dependency on com.unity.test-framework [2.1.1] - 2023-04-12 Added IJobParallelBatch provides .Schedule, .ScheduleByRef, .ScheduleParallel, .ScheduleParallelByRef, .Run and .RunByRef forms. .ScheduleParallel is equivalent to calling .ScheduleBatch. Added Trim, TrimStart, TrimEnd, ToLowerAscii, ToUpperAscii methods to strings. NativeQueue.ReadOnly. UnsafeParallelHashMap.ReadOnly. UnsafeQueue container type Unsafe/NativeParallelMultiHashMap.ReadOnly view into container. UnsafeList.ReadOnly enumerator. Changed Added additional UNITY_DOTS_DEBUG checks to collection types to help with standalone player debugging (since ENABLE_UNITY_COLLECTION_CHECKS safety checks are unavailable in standalone player builds) Updated Burst version to 1.8.4 Reduced the amount of memory allocated by allocating based on the maximum number of worker threads the running platform requires rather than defaulting to using a theoretical upper-bound of 128 worker threads. Fixed Calling Dispose on uninitialized container will not throw. Properly tracks allocations made from the collections package such that when Unity.Collections.NativeLeakDetectionMode is NativeLeakDetectionMode.Enabled or NativeLeakDetectionMode.EnabledWithStackTrace, native memory leaks will be reported upon domain reload. UnsafeParallelHashSet.ReadOnly was not usable in jobs due to extraneous [NativeContainer] attribute NativeRingQueue.Dispose(JobHandle) allowed scheduling as a race condition Dispose(JobHandle) for many native containers adhere to proper safety system expectations Lowered benchmark memory usage in non-desktop player builds to avoid out-of-memory failures Fixed container types could provide unaligned access to T elements which could violate platform alignment requirements resulting in native exceptions / crashes in player builds. All fixed types like FixedList<T> now provide 8 byte alignment for the FixedList<T> type itself, whereas the elements T remain naturally aligned in the contiguous storage buffer inside FixedList<T> [2.1.0-pre.18] - 2023-03-21 Added UnsafeParallelHashMap.ParallelWriter.ThreadIndex is a public read-only property to mirror functionality in NativeParallelHashMap NativeParallelHashMap.ParallelWriter.TryAdd that takes a thread index argument for advanced usage UnsafeParallelHashMap.ParallelWriter.TryAdd that takes a thread index argument for advanced usage Starts/EndsWith to Native/UnsafeText and FixedStringN. Changed NativeReference/NativeList.GetUnsafePtr returns typed pointer T* instead of typeless void*. Updated Burst version in use to 1.8.3 Updated auto-generated allocator performance comparison documentation NativeParallelHashMap.ParallelWriter.m_ThreadIndex public property renamed to ThreadIndex Allocator benchmark documentation updated to reflect corrected performance measurements NativeParallelHashMap.ParallelWriter.TryAdd that takes a thread index argument is internal now UnsafeParallelHashMap.ParallelWriter.TryAdd that takes a thread index argument is internal now Significant performance improvements, especially when not burst compiled, across the board in all containers Implementation for NativeRingQueue simplified and performance increased greatly Removed GenPerformanceComparisonMd InternalsVisibleTo reference to Tiny Fixed All HashMap and HashSet types are now consistently initialized with a capacity no less than the minGrowth specified Incorrect markdown syntax for header anchors UnsafeAppendBuffer now safely reads and writes type T. Previously, it was possible to make unaligned reads and writes of type T which could violate platform architecture alignment requirements. [2.1.0-pre.11] - 2023-02-13 Added Ability to resize Unsafe/NativeBitArray with Resize, SetCapacity, TrimExcess methods. .Substring method to FixedStringN, and NativeText. NativeRingQueue. CollectionHelper.Dispose to dispose a NativeArray without Allocator input parameter. Changed Reviewed all safety checks and made many of them supported with UNITY_DOTS_DEBUG in addition to ENABLE_UNITY_COLLECTIONS_CHECKS Optimize RewindableAllocator. Underlying algorithm for *HashMap/Set containters to improve performance. Fixed Code generation responsible for early initialization of JobReflectionData could previously emit enormous amounts of code that could dramatically increase IL2CPP build times. We now produce the minimal amount of code necessary and no longer impact IL2CPP compilation times. Removed unnecessary test and documentation samples assemblies from always being loaded in projects. NativeHashSet.ToNativeArray(allocator) now works with custom allocators AllocatorManager.Block.AllocatedBytes and AllocatorManager.Block.Bytes properties could overflow returning incorrect negative values. [2.1.0-pre.6] - 2022-11-23 Fixed FixedListNBytes.Buffer and FixedString.GetUnsafePtr() could return an invalid pointer in some cases, if the target object was readonly. [2.1.0-pre.2] - 2022-10-11 Added BinarySearch for NativeArray<T>.ReadOnly NativeArray<T>.CopyFrom containers: NativeList<T>, NativeHashSet<T>, UnsafeHashSet<T>. NativeArray<T>.ArrayEquals containers: NativeList<T>. NativeList<T>.CopyFrom containers: NativeArray<T>, NativeList<T>, UnsafeList<T>. NativeList<T>.ArrayEquals containers: NativeArray<T>, NativeList<T>, UnsafeList<T>. Docs how to create/use/dispose a rewindable allocator. Document how how to define a custom allocator from scratch. CollectionHelper.DisposeNativeArray to dispose native array created from a custom allocator. WriteDouble, WritePackedDouble, WritePackedDoubleDelta to DataStreamWriter ReadDouble, ReadPackedDouble, ReadPackedDoubleDelta to DataStreamReader Changed Change the default NativeArrayOptions in CollectionHelper.CreateNativeArray to UninitializedMemory. Removed Move doc allocator.md into allocator folder in Documentation~. Fixed Don't cache DataStreamWriter.IsLittleEndian, as the cache could not be properly populated if its shared static was not 0-initialized. BinarySearch is using read-only access. Memory leak in Native/UnsafeStream due to orphaned block. Debug visualizers display content even when safety handle is in write-only mode. [2.1.0-exp.4] - 2022-08-05 Added Native/Unsafe/FixedList.InsertRange with index/count arguments. StreamCompressionModel moved from com.unity.transport DataStreamReader moved from com.unity.transport DataStreamWriter moved from com.unity.transport Job types depending on collections have been moved here Burst compiled delegates for allocators are now cached, which avoids a costly re-compilation DataStreamReader can now be passed to a job DataStreamReader can now be passed to a job. IJobParallelForBatch from com.unity.jobs Unsafe/NativeHashMap/Set suitable for single-threaded use cases. Native/UnsafeHashSet.ReadOnly and Native/UnsafeParallelHashSet.ReadOnly. ConvertExistingDataToNativeArray in CollectionHelper for custom allocators. Native/UnsafeBitArray.ReadOnly. CopyFromTruncated for one FixedStringXXXBytes to another FixedStringYYYBytes New method AddReplicate to NativeList, UnsafeList and all FixedList, which will add a value count times to the list. CollectionHelper.CreateSafetyHandle and CollectionHelper.DisposeSafetyHandle are public APIs now. Changed Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 T constraint on all containers from struct to unmanaged Add the missing string interpolation operator in two memory exception messages and make the message clearer. Awareness of newly supported nested containers Renamed UnsafeHashSet to UnsafeParallelHashSet. Renamed NativeHashSet to NativeParallelHashSet. Renamed UnsafeHashMap to UnsafeParallelHashMap. Renamed NativeHashMap to NativeParallelHashMap. Renamed UnsafeMultiHashMap to UnsafeParallelMultiHashMap. Renamed NativeMultiHashMap to NativeParallelMultiHashMap. Faster FixedString comparison Reset m_best in RewindableAllocator rewind. IJobParallelForFilter renamed to IJobFilter to better reflect functionality Ensure lazy initialization of IJob types Change Bool type, m_enableBlockFree in RewindableAllocator to Byte type. Change the growth rate of memory block size in RewindableAllocator. FixedList methods AddRange and AddRangeNoResize will no longer append elements if they would exceed capacity. Fixed Added an assembly definition file for sample code in the package to avoid spurious warnings when adding the package Some AssumePositive assumptions that should have been after some safety checks but weren't. Native/UnsafeList.InsertRangeWithBeginEnd to allow end argument to resize list. Fixed a race condition in the parallel hashmap when using ParallelWriter with hashmaps that operate close to their capacity Update documentation on existing DataStream structs and helper methods. Removed DisposeSentinel usage in containers. deprecated code untyped UnsafeList, and WordStorage. All deprecated code. Temporary NativeArray placeholder Deprecated NetworkCompressionModel. New type StreamCompressionModel is no longer IDisposable and all usage of this should use the SharedStatic reference instead. Packed read and write methods that take NetworkCompressionModel as a parameter. New versions taking StreamCompressionModel as an argument should be used instead. UnsafeList.ParallelReader replaced by UnsafeList.ReadOnly. NativeList.AsParallelReader() replaced by NativeList.AsReadOnly(). Implicit cast operator from NativeList<T> to NativeArray<T>. Explicit cast method NativeList<T>.AsArray() should be used instead. [1.4.0] - 2022-07-12 Changed The com.unity.jobs package has been merged into com.unity.collections to resolve circular dependency issues that can occur when using Unity 2022.2+ [1.3.2] - 2022-06-27 updated minimum compatible version of Unity to 2020.3.30f1 [1.3.1] - 2022-06-13 Minor Fixes to changelog [1.3.0] - 2022-05-16 Changed Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 Fixed Added an assembly definition file for sample code in the package to avoid spurious warnings when adding the package [1.2.3] - 2022-03-18 Changed Minor fixes to changelog [1.2.3-pre.1] - 2022-03-04 Changed Updated package dependencies [1.2.2] - 2022-03-03 Changed Updated package com.unity.test-framework to version 1.1.31. Updated package com.unity.burst to version 1.6.4. [1.2.1] - 2022-02-17 Fixed Shutdown the WordStorage with application exit to ensure memory is freed. NativeList.AsDeferredJobArray allocator label is changed to Allocator.Invalid to infer that the array is in list mode. Added Added FixedStringMethods.CopyFromTruncated to copy a string to a FixedString explicitly allowing truncation Added NativeText.ReadOnly type which provides a readonly, lightweight copy of a NativeText or UnsafeText type. New public API AllocatorHandle.UnmanagedUnregister, which unregisters an allocator without using managed code. Changed Native/UnsafeMultiHashMap.GetUniqueKeyArrayNBC extension methods from Unity.Collections.NotBurstCompatible are not necessary anymore. Burst supports tuple. Original methods Native/UnsafeMultiHashMap.GetUniqueKeyArray are now available again. Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 Static safety ID created for all types containing a uniquely represented AtomicSafetyHandle [1.2.0] - 2022-01-18 Fixed Shutdown the WordStorage with application exit to ensure memory is freed. NativeList.AsDeferredJobArray allocator label is changed to Allocator.Invalid to infer that the array is in list mode. Added Added FixedStringMethods.CopyFromTruncated to copy a string to a FixedString explicitly allowing truncation Added NativeText.ReadOnly type which provides a readonly, lightweight copy of a NativeText or UnsafeText type. New public API AllocatorHandle.UnmanagedUnregister, which unregisters an allocator without using managed code. Changed Native/UnsafeMultiHashMap.GetUniqueKeyArrayNBC extension methods from Unity.Collections.NotBurstCompatible are not necessary anymore. Burst supports tuple. Original methods Native/UnsafeMultiHashMap.GetUniqueKeyArray are now available again. Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 Static safety ID created for all types containing a uniquely represented AtomicSafetyHandle [1.1.0] - 2021-10-27 Added REMOVE_DISPOSE_SENTINEL ifdefs in all containers for future removal of DisposeSentinel. Bounds check to Fixed/Native/UnsafeList. SetCapacity and TrimExcess to NativeList. A custom allocator wrapper AllocatorHelper to facilitate custom allocator creation and destruction. NativeList<>.ArraysEqual & UnsafeList<>.ArraysEqual UnsafeList.CopyFrom Changed Only lower 15 bits of an allocator handle version are valid. Fixed Error in leak detection for NativeList created by RewindableAllocator. Removed pointer caching from Native/UnsafeList.ParallelWriter. AtomicSafetyHandle issue preventing use of foreach iterator in jobs for NativeHashSet, NativeHashMap, and NativeMultiHashMap containers. [1.0.0-pre.6] - 2021-08-31 Removed VirtualMemoryUtility BaselibErrorState BaselibSourceLocation VMRange DisposeSentinel (managed object) from all Native* containers. Changed Native container memory allocations align to multiple cacheline size. UnsafeText is marshalable now (doesn't contain generic field UnsafeList ). Fixed AllocatorManager.AllocateBlock no longer ignores alignment when allocating. Redundant and wrong computation of memory allocation alignment. [1.0.0-pre.5] - 2021-08-20 Changed Renamed FixedListN to FixedListNBytes, for all N, and same for FixedString Fixed NativeBitArray, NativeQueue, NativeStream, and NativeText will no longer throw an exception when using a custom allocator inside of a job. [1.0.0-pre.4] - 2021-08-11 Added FixedList* overflow checks when UNITY_DOTS_DEBUG is enabled. Disposed NativeArray related tests and updated some invalidated native array from native list tests to confirm that exceptions are thrown when accessing an object's Length and indexer following its disposal Changed Updated internal dependencies InvalidArrayAccessFromListJob check in the InvalidatedArrayAccessFromListThrowsInsideJob unit test to expect an ObjectDisposedException due to a change in the type thrown for AtomicSafetyHandle.CheckAndThrow Fixed Setting UnsafeList.Length will now resize the storage properly. [1.0.0-pre.3] - 2021-06-29 Added Native/UnsafeList*.RemoveRange* with index/count arguments. Upgraded to burst 1.5.2 UnsafeText added. Changed Burst compatibility tests now treat any explicit uses of [BurstCompatible] on private methods as an error (as opposed to silently ignoring) to avoid giving the impression that private methods are being tested. NativeList<T> generic constraint T is changed from struct to unmanaged to match UnsafeList<T>. User code can be simply fixed by changing struct to unmanaged when using NativeList<T> inside generic container. NativeHashMap.GetBucketData renamed to NativeHashMap.GetUnsafeBucketData Update the package to 1.0.0 HeapString renamed to NativeText. NativeText is based on UnsafeText. Deprecated Generated FixedList[Byte/Int/Float][32/64/128/256/512] are deprecated, and replaced with generics FixedList[32/64/128/256/512]<T>. UnsafeMultiHashMap<TKey, TValue>.GetUniqueKeyArray replaced with extension method UnsafeMultiHashMap<TKey, TValue>.GetUniqueKeyValueNBC from Unity.Collections.NotBurstCompatible namespace. NativeMultiHashMap<TKey, TValue>.GetUniqueKeyArray replaced with extension method NativeMultiHashMap<TKey, TValue>.GetUniqueKeyValueNBC from Unity.Collections.NotBurstCompatible namespace. NativeList<T>.ToArray replaced with extension method NativeList<T>.ToArrayNBC from Unity.Collections.NotBurstCompatible NativeList<T>.CopyFrom replaced with extension method NativeList<T>.CopyFromNBC from Unity.Collections.NotBurstCompatible namespace. UnsafeAppendBuffer.Add replaced with extension methodUnsafeAppendBuffer.AddNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. UnsafeAppendBuffer.ToBytes replaced with extension method UnsafeAppendBuffer.ToBytesNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. UnsafeAppendBuffer.Reader.ReadNext replaced with extension method UnsafeAppendBuffer.Reader.ReadNextNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. Native/UnsafeList*.RemoveRange*WithBeginEnd methods with begin/end arguments in favor of Native/UnsafeList*.RemoveRange* with index/count arguments. UnsafeList and replaced it with UnsafeList<T>. VirtualMemoryUtility. Removed NativeQueue.PersistentMemoryBlockCount and NativeQueue.MemoryBlockSize are now internal APIs. Fixed Burst compatibility tests will now ignore any method containing a '$' in the name, which can be generated by the Burst direct call IL post processor. xxHash3 is initialized after assembly load to avoid an exception that could be thrown if xxHash3 is accessed for the first time on a thread other than the main thread. Security [0.17.0] - 2021-03-15 Added [NotBurstCompatible] attribute to FixedStringN constructors that use a String argument. [NotBurstCompatible] attribute to NativeQueue constructor. UnsafeList<T>.Create and UnsafeList<T>.Destroy API. BurstCompatibilityTests now has a constructor that accepts multiple assembly names to verify Burst compatibility. This allows one test to verify multiple assemblies and can dramatically reduce CI times by avoiding costly setup overhead. UnsafePtrList<T> to replace deprecated untyped UnsafePtrList. Burst compatibility tests now also write the generated code to the Temp directory in order to make it easier to inspect. FixedList*.RemoveRange* with index/count arguments. FixedString parsing to type uint Deprecated untyped UnsafePtrList, and added UnsafePtrList<T> as replacement. FixedList*.RemoveRange*WithBeginEnd methods with begin/end arguments in favor of FixedList*.RemoveRange* with index/count arguments. Removed Removed single arg FixedString*.Format extension methods, use Clear() followed by Append(). CollectionsBurstTests has been removed and placed into the Entities test project. com.unity.test-framework.performance preview package dependency, and moved performance unit tests depending on it into different location. Fixed *BitArray.Clear when clearing with very short bit arrays. NativeQueue.AsParallelWriter doesn't need to be cached when chaining jobs. Removed unnecessary safety handle that was preventing calling NativeQueue.AsParallelWriter() multiple times when scheduling jobs. [0.16.0] - 2021-01-26 Deprecated Sort methods that return a JobHandle deprecated in favor of new SortJob methods that return a job struct. Less conveniently, the user is responsible for calling Schedule on the struct, but this pattern better accommodates scheduling generic jobs from Bursted code (See https://docs.unity3d.com/Packages/com.unity.entities@latest/index.html?subfolder=/manual/ecs_generic_jobs.html). Removed Removed deprecated FixedListN.IndexOf and SortJob variants Fixed An ENABLE_UNITY_COLLECTIONS_CHECKS define was misspelled. Now Memory is checked for reasonable byte length when enabled. Many methods that use IJob were marked as [NotBurstCompatible] to reflect their true Burst compatibility. Changed Updated com.unity.burst to 1.4.4 [0.15.0] - 2020-11-13 Added NativeReference constructor to initialize it with existing value. T[] *HashSet.ToArray() returns an array of all elements in the set. xxHash3 now also has a utility method to hash a struct directly (Previously it was only pointer + size) [BurstCompatible] attribute to FixedList and extensions. [BurstCompatible] attribute to CollectionHelper. [BurstCompatible] attribute to FixedBytesN. [BurstCompatible] attribute to HeapString. [BurstCompatible] attribute to NativeArrayExtensions. [BurstCompatible] attribute to NativeBitArray. [BurstCompatible] attribute to NativeBitArrayUnsafeUtility. [BurstCompatible] attribute to NativeHashMap. [BurstCompatible] attribute to NativeHashMapExtensions. [BurstCompatible] attribute to NativeHashSet. [BurstCompatible] attribute to NativeList. [BurstCompatible] attribute to NativeListUnsafeUtility. [BurstCompatible] attribute to NativeMultiHashMap. [BurstCompatible] attribute to NativeQueue. [BurstCompatible] attribute to NativeReference. [BurstCompatible] attribute to NativeStream. [BurstCompatible] attribute to NativeString. [BurstCompatible] attribute to UTF8ArrayUnsafeUtility. [BurstCompatible] attribute to Unicode and Rune. [BurstCompatible] attribute to NativeStringView. [BurstCompatible] attribute to UnsafeAppendBuffer. [BurstCompatible] attribute to UnsafeAtomicCounter32 and UnsafeAtomicCounter64. [BurstCompatible] attribute to UnsafeHashMap. [BurstCompatible] attribute to UnsafeHashSet. [BurstCompatible] attribute to UnsafeList, UnsafeListExtensions, UnsafePtrList, UnsafePtrListExtensions. [BurstCompatible] attribute to UnsafeRingQueue. [BurstCompatible] attribute to UnsafeScratchAllocator. [BurstCompatible] attribute to UnsafeUtilityExtensions. [BurstCompatible] attribute to VMRange, Baselib_ErrorState, and VirtualMemoryUtility. [BurstCompatible] attribute to xxHash3. Changed Update burst to 1.4.1. *BitArray Length would previously report backing capacity which is always 64-bit aligned, changed it to report number of bits user requested on allocation. For example, allocating 3 bits will now report Length 3 instead capacity which is always aligned to 64-bits. Update minimum editor version to 2020.1.2f1 Fixed Code generation for indexers in structs with [BurstCompatible] attribute. *BitArray search for empty bits when number of bits is less than 7 and backing storage is fragmented with 0x81 bit pattern. Namespace for *HashSet.ExceptWith/IntersectWith/UnionWith extension methods, so that use of Unity.Collections.LowLevel.Unsafe namespace is not necessary. using FixedList.ToNativeArray with collection checks enabled used to throw a null reference exception. [0.14.0] - 2020-09-24 Added *UnsafeBitArray.Find with pos/count search range arguments. Changed UnsafeStream block allocation performance has been improved by ~16% by appending to the start of the per-thread block lists rather than the end. Removed FixedList*.InsertRange, FixedList*.RemoveRangeSwapBack, FixedList*.RemoveRange, NativeString*, NativeList.RemoveRangeSwapBack, NativeList.RemoveRange, UnsafeList.RemoveRangeSwapBack, UnsafeList.RemoveRange, FixedString*.Format, FixedString*.AppendFrom, NativeHashSet.TryAdd, UnsafeHashSet.TryAdd. [NativeContainerSupportsDeallocateOnJobCompletion] attribute from NativeReference container. It didn't work properly. Users can use Dispose(JobHandle) method instead. Fixed FixedList<T> Remove and RemoveSwapBack extension methods were modifying copy, fixed by passing this by reference to modify actual container. [0.13.0] - 2020-08-26 Added Added *BitArray.Find linear search for 0-bit range. Added SortJob extension methods for NativeList, UnsafeList, UnsafeList<T>, and NativeSlice. Added Sort method that accepts custom comparator, and job dependency, to all supported containers. Added BinarySearch extension methods for NativeArray, NativeList, UnsafeList, UnsafeList<T>, and NativeSlice. Added foreach support to UnsafeList<T>. Changed Sort functions that take an IComparer no longer require the sorted elements to be IComparable Bumped Burst to 1.3.5. Deprecated Deprecated SortJob with default job dependency argument. Use Sort that require an explicit JobHandle argument. If no dependency is needed, pass a default valued JobHandle. Removed Removed: UnsafeUtilityEx, Unity.Collections.Experimental*,FixedString*.UTF8LengthInBytes, and *Stream.ComputeItemCount() Fixed Fixed performance regression of *HashMap.Count() introduced in Collections 0.10.0. [0.12.0] - 2020-08-04 Added Added Sort method with custom comparer to FixedList* and UnsafeList<T>. Added IsEmpty property and Clear method to INativeList intefrace. Added INativeDisposable interface which provides a mechanism for scheduling release of unmanaged resources. Added InsertRangeWithBeginEnd to NativeList, UnsafeList, UnsafeList<T>, and UnsafePtrList. Added AddRange and AddRangeNoResize to FixedList*. Added properties to BaselibErrorState to check if an operation resulted in success, out of memory, or accessing an invalid address range. Added HeapString type, for arbitrary-length (up to 2GB) heap-allocated strings compatible with the FixedString* methods. Allocating a HeapString requires specifying an allocator and disposing appropriately. Deprecated Deprecated FixedList* method IndexOf with index and index/count arguments. Removed Removed: IJobNativeMultiHashMapMergedSharedKeyIndices JobNativeMultiHashMapUniqueHashExtensions IJobNativeMultiHashMapVisitKeyValue JobNativeMultiHashMapVisitKeyValue IJobNativeMultiHashMapVisitKeyMutableValue JobNativeMultiHashMapVisitKeyMutableValue IJobUnsafeMultiHashMapMergedSharedKeyIndices JobUnsafeMultiHashMapUniqueHashExtensions IJobUnsafeMultiHashMapVisitKeyValue JobUnsafeMultiHashMapVisitKeyValue IJobUnsafeMultiHashMapVisitKeyMutableValue JobUnsafeMultiHashMapVisitKeyMutableValue Fixed Fixed *HashMap.IsEmpty when items are added and removed from *HashMap. IsEmpty previously used allocated count only to report emptiness, but returning not-empty didn't actually meant that *HashMap is not empty. Fixed bug where *HashSet.Enumerator.Current would always return the default value instead of the actual value from the set. Fixed bug with *HashMap/Set.Enumerator returning wrong index and dereferencing out of bounds memory. [0.11.0] - 2020-07-10 Added Added VirtualMemoryUtility providing low-level virtual memory utility functions backed by baselib. *HashMap and *HashSet now implement IEnumerable<>. ReadArrayElementBoundsChecked and WriteArrayElementBoundsChecked for ease of debugging ReadArrayElement and WriteArrayElement without sacrificing performance by adding bounds checking directly to those functions. Added InsertRangeWithBeginEnd, RemoveRangeSwapBackWithBeginEnd, and RemoveRangeWithBeginEnd to list containers. *WithBeginEnd in name signifies that arguments are begin/end instead of more standard index/count. Once InsertRange, RemoveRangeSwapBack, and RemoveRange are completely deprecated and removed, those methods will be added with correct index/count arguments. Added xxHash3 type to expose 64/128bits hashing API using xxHash3 algorithm (corresponding to the C++ version https://github.com/Cyan4973/xxHash/releases/tag/v0.8.0) Changed Updated minimum Unity Editor version to 2020.1.0b15 (40d9420e7de8) Bumped burst to 1.3.2 version. Changed *HashSet.Add API to return bool when adding element to set. UnsafeUtilityExtensions is now public. NativeReference methods Equals and GetHashCode will now operate on the value instead of the data pointer. FixedString{32,64,128,512,4096} have been reworked. Functionality is shared via generics as much as possible. The API attempts to follow StringBuilder semantics. Append methods now consistently append. Append variant to append a char was added (appends the char, does not resolve to int overload). Format methods that replaced the contents of the target have been deprecated. Use Clear() followed by Append(). Because FixedStrings start out cleared, in most cases just an Append is sufficient. Format that takes a format string has been renamed to AppendFormat. The static FixedString.Format methods still exist for convenience, and return a FixedString128. It is possible for users to extend the Append family of methods to support appending their own types. See FixedStringAppendMethods.cs for examples of how to declare your own extension methods. Deprecated Deprecated *HashSet.TryAdd. *HashSet.Add is equivalent. Deprecated NativeString*. The functionality is replaced by FixedString*. Deprecated InsertRange, RemoveRangeSwap, and RemoveRange from list containers, and added InsertRangeWithBeginEnd, RemoveRangeSwapBackWithBeginEnd, and RemoveRangeWithBeginEnd. *WithBeginEnd in name signifies that arguments are begin/end instead of more standard index/count. Once InsertRange, RemoveRangeSwapBack, and RemoveRange are completely deprecated and removed, those methods will be added with correct index/count arguments. Removed Removed System.Runtime.CompilerServices.Unsafe.dll from package. Known Issues This version is not compatible with 2020.2.0a17. Please update to the forthcoming alpha. All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance. This is problematic when using NativeHashMap, NativeMultiHashMap, NativeHashSet and NativeList together in situations where their secondary safety handle is used. This means that operations that invalidate an enumerator for either of these collections (or the NativeArray returned by NativeList.AsArray) will also invalidate all other previously acquired enumerators. For example, this will throw when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0]; This defect will be addressed in a future release. [0.10.0] - 2020-05-27 Added Added Native/UnsafeHashSet containers. Added IsEmpty method to *Queue, *HashMap, *MultiHashMap, *List, FixedString. This method should be prefered to Count() > 0 due to simpler checks for empty container. Added a new container NativeReference to hold unmanaged allocation. Added CollectionsTestFixture to enable jobs debugger and verify safety checks are enabled. Added NativeList.CopyFrom(NativeArray<> array) Changed Updated minimum Unity Editor version to 2020.1.0b9 (9c0aec301c8d) Updated package com.unity.burst to version 1.3.0-preview.12. Made several tests inherit CollectionsTestFixture to prevent crashing when running tests without jobs debugger or safety checks enabled. Added NativeBitArray.AsNativeArray<T> method to reinterpret NativeBitArray as NativeArray of desired type. Deprecated Deprecated NativeArrayChunked8 and NativeArrayFullSOA from Unity.Collections.Experimental. Deprecated UnsafeUtilityEx.As/AsRef/ArrayElementAsRef. The functionality is available in UnsafeUtility. Fixed FixedString and FixedList types now display their contents in the Entity Inspector. Fixed NativeHashMap.ParallelWriter.TryAdd race condition. [0.9.0] - 2020-05-04 Added Added RemoveAt and RemoveRange to List containers in collections. These methods remove elements in list container while preserving order of the list. These methods are slower than Remove*SwapBack methods and users should prefer Remove*SwapBack if they don't care about preserving order inside *List container. Added *BitArray.Copy between two different bit arrays. Added NativeBitArrayUnsafeUtility.ConvertExistingDataToNativeBitArray for assigning view into data as bit array. Changed Updated package com.unity.burst to version 1.3.0-preview.11 Fixed Moved NativeMultiHashMap.Remove<TValueEQ>(TKey key, TValueEq value) into an extension method and made it Burst compatible Fixed bug in *HashMap.Remove to not throw when removing from empty hash map. [0.8.0] - 2020-04-24 Added Added Native/UnsafeBitArray.Copy for copying or shifting bits inside array. Added UnsafeAtomicCounter32/64 providing helper interface for atomic counter functionality. Added NativeBitArray providing arbitrary sized bit array functionality with safety mechanism. Changed Bumped Burst version to improve compile time and fix multiple bugs. Deprecated Deprecated IJobNativeMultiHashMapMergedSharedKeyIndices, JobNativeMultiHashMapUniqueHashExtensions, IJobNativeMultiHashMapVisitKeyValue, JobNativeMultiHashMapVisitKeyValue, IJobNativeMultiHashMapVisitKeyMutableValue, JobNativeMultiHashMapVisitKeyMutableValue, and introduced NativeHashMap.GetUnsafeBucketData and NativeMultiHashMap.GetUnsafeBucketData to obtain internals to implement deprecated functionality inside user code. If this functionality is used, the best is to copy deprecated code into user code. Removed Removed expired API class TerminatesProgramAttribute [0.7.1] - 2020-04-08 Deprecated Deprecated Length property from NativeHashMap, UnsafeHashMap, NativeMultiHashMap, UnsafeMultiHashMap, NativeQueue, and replaced it with Count() to reflect that there is computation being done. Fixed Fixed an issue where FixedListDebugView<T> only existed for IComparable types, which lead to a crash while debugging other types. Removed code that made NativeStream incompatible with Burst. [0.7.0] - 2020-03-13 Added Added ability to dispose NativeKeyValueArrays from job (DisposeJob). Added NativeQueue<T>.ToArray to copy a native queue to an array efficiently Changed Upgraded Burst to fix multiple issues and introduced a native debugging feature. Deprecated Deprecated Length property from NativeHashMap, UnsafeHashMap, NativeMultiHashMap, UnsafeMultiHashMap, NativeQueue, and replaced it with Count() to reflect that there is computation being done. Removed Removed expired API CollectionHelper.CeilPow2() Removed expired API CollectionHelper.lzcnt() Removed expired API struct ResizableArray64Byte<T> Fixed Removed code that made NativeStream incompatible with Burst. [0.6.0] - 2020-03-03 Added Added ability to dispose UnsafeAppendBuffer from a DisposeJob. Added NativeHashSetExtensions and UnsafeHashSetExtensions for HashSetExtensions in different namespaces. Changed UnsafeAppendBuffer field Size renamed to Length. Removed [BurstDiscard] from all validation check functions. Validation is present in code compiled with Burst. Removed Removed expired overloads for NativeStream.ScheduleConstruct without explicit allocators. Removed HashSetExtensions, replaced with NativeHashSetExtensions and UnsafeHashSetExtensions. Fixed Fixed UnsafeBitArray out-of-bounds access. [0.5.2] - 2020-02-17 Changed Changed NativeList<T> parallel reader/writer to match functionality of UnsafeList parallel reader/writer. Updated dependencies of this package. Removed Removed expired API UnsafeUtilityEx.RestrictNoAlias Fixed Fixed bug in NativeList.CopyFrom. [0.5.1] - 2020-01-28 Changed Updated dependencies of this package. [0.5.0] - 2020-01-16 Added Added UnsafeRingQueue<T> providing fixed-size circular buffer functionality. Added missing IDisposable constraint to UnsafeList and UnsafeBitArray. Added ReadNextArray<T> to access a raw array (pointer and length) from an UnsafeAppendBuffer.Reader. Added FixedString types, guaranteed binary-layout identical to NativeString types, which they are intended to replace. Added FixedList<T> generic self-contained List struct Added BitArray.SetBits with arbitrary ulong value. Added BitArray.GetBits to retrieve bits as ulong value. Changed Changed UnsafeBitArray memory initialization option default to NativeArrayOptions.ClearMemory. Changed FixedList structs to pad to natural alignment of item held in list Deprecated BlobAssetComputationContext.AssociateBlobAssetWithGameObject(int, GameObject) replaced by its UnityEngine.Object counterpart BlobAssetComputationContext.AssociateBlobAssetWithUnityObject(int, UnityEngine.Object) to allow association of BlobAsset with any kind of UnityEngine.Object derived types. Adding removal dates to the API that have been deprecated but did not have the date set. Removed Removed IEquatable constraint from UnsafeList<T>. Fixed Fixed BitArray.SetBits. [0.4.0] - 2019-12-16 This version requires Unity 2019.3.0f1+ New Features Adding FixedListTN as a non-generic replacement for ResizableArrayN<T>. Added UnsafeBitArray providing arbitrary sized bit array functionality. Fixes Updated performance package dependency to 1.3.2 which fixes an obsoletion warning Adding [NativeDisableUnsafePtrRestriction] to UnsafeList to allow burst compilation. [0.3.0] - 2019-12-03 New Features Added fixed-size BitField32 and BitField64 bit array. Changes Removed the following deprecated API as announced in/before 0.1.1-preview: Removed struct Concurrent and ToConcurrent() for NativeHashMap, NativeMultiHashMap and NativeQueue (replaced by the ParallelWriter API). From NativeStream.cs: struct NativeStreamReader and struct NativeStreamWriter, replaced by struct NativeStream.Reader and struct NativeStream.Writer. From NativeList.cs: ToDeferredJobArray() (replaced by AsDeferredJobArray() API). [0.2.0] - 2019-11-22 This version requires Unity 2019.3 0b11+ New Features Added fixed-size UTF-8 NativeString in sizes of 32, 64, 128, 512, and 4096 bytes. Added HPC# functions for float-to-string and string-to-float. Added HPC# functions for int-to-string and string-to-int. Added HPC# functions for UTF16-to-UTF8 and UTF8-to-UTF16. New Native(Multi)HashMap.GetKeyValueArrays that will query keys and values at the same time into parallel arrays. Added UnsafeStream, UnsafeHashMap, and UnsafeMultiHashMap, providing functionality of NativeStream container but without any safety mechanism (intended for advanced users only). Added AddNoResize methods to NativeList. When it's known ahead of time that list won't grow, these methods won't try to resize. Rather exception will be thrown if capacity is insufficient. Added ParallelWriter support for UnsafeList. Added UnsafeList.TrimExcess to set capacity to actual number of elements in the container. Added convenience blittable UnsafeList<T> managed container with unmanaged T constraint. Changes UnsafeList.Resize now doesn't resize to lower capacity. User must call UnsafeList.SetCapacity to lower capacity of the list. This applies to all other containers based on UnsafeList. Updated dependencies for this package. Fixes Fixed NativeQueue pool leak. [0.1.1] - 2019-08-06 Fixes NativeHashMap.Remove(TKey key, TValueEQ value) is now supported in bursted code. Adding deprecated NativeList.ToDeferredJobArray() back in - Use AsDeferredJobArray() instead. The deprecated function will be removed in 3 months. This can not be auto-upgraded prior to Unity 2019.3. Fixing bug where TryDequeue on an empty NativeQueue that previously had enqueued elements could leave it in an invalid state where Enqueue would fail silently afterwards. Changes Updated dependencies for this package. [0.1.0] - 2019-07-30 New Features NativeMultiHashMap.Remove(key, value) has been addded. It lets you remove all key & value pairs from the hashmap. Added ability to dispose containers from job (DisposeJob). Added UnsafeList.AddNoResize, and UnsafeList.AddRangeNoResize. BlobString for storing string data in a blob Upgrade guide Native*.Concurrent is renamed to Native*.ParallelWriter. Native*.ToConcurrent() function is renamed to Native*.AsParallelWriter(). NativeStreamReader/Writer structs are subclassed and renamed to NativeStream.Reader/Writer (note: changelot entry added retroactively). Changes Deprecated ToConcurrent, added AsParallelWriter instead. Allocator is not an optional argument anymore, user must always specify the allocator. Added Allocator to Unsafe*List container, and removed per method allocator argument. Introduced memory intialization (NativeArrayOptions) argument to Unsafe*List constructor and Resize. Fixes Fixed UnsafeList.RemoveRangeSwapBack when removing elements near the end of UnsafeList. Fixed safety handle use in NativeList.AddRange. [0.0.9-preview.20] - 2019-05-24 Changes Updated dependencies for Unity.Collections.Tests [0.0.9-preview.19] - 2019-05-16 New Features JobHandle NativeList.Dispose(JobHandle dependency) allows Disposing the container from a job. Exposed unsafe NativeSortExtension.Sort(T* array, int length) method for simpler sorting of unsafe arrays Imporoved documentation for NativeList Added CollectionHelper.WriteLayout debug utility Fixes Fixes a NativeQueue alignment issue. [0.0.9-preview.18] - 2019-05-01 Change tracking started with this version."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Collections package Known issues Collections overview Collection types Parallel readers and writers Use allocators to control unmanaged memory Allocator overview Aliasing allocators Rewindable allocator overview Custom allocator overview Use a custom allocator Performance comparisons Allocator benchmarks Allocator performance comparison Container performance comparison"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocation.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocation.html",
    "title": "Use allocators to control unmanaged memory | Inventory System",
    "summary": "Use allocators to control unmanaged memory The Collections package allocates Native- and Unsafe- collections from unmanaged memory, which means that their existence is unknown to the garbage collector. You are responsible for deallocating any unmanaged memory that you don't need. If you fail to deallocate large or multiple allocations, it can lead to wasting a lot of memory, which might slow down or crash your program. Topic Description Allocator overview Understand how to use an allocator to manage unmanaged memory. Aliasing allocators Create aliases, which share memory allocations with another collection. Rewindable allocator overview Understand rewindable allocators, which can pre-allocate memory. Custom allocator Understand custom allocators, which you can create for specific memory allocation needs. Allocator benchmarks Compare the various allocators and inspect their performance benchmarks."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-aliasing.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-aliasing.html",
    "title": "Aliasing allocators | Inventory System",
    "summary": "Aliasing allocators An alias is a collection which doesn't have its own allocation but instead shares the allocation of another collection, in whole or in part. For example, you can create an UnsafeList that doesn't allocate its own memory but instead uses a NativeList's allocation. Writing to this shared memory via the UnsafeList affects the content of the NativeList, and vice versa. You don't need to dispose aliases, and calling Dispose on an alias does nothing. Once an original is disposed, you can no longer use the aliases of the original: NativeList<int> nums = new NativeList<int>(10, Allocator.TempJob); nums.Length = 5; // Create an array of 5 ints that aliases the content of the list. NativeArray<int> aliasedNums = nums.AsArray(); // Modify the first element of both the array and the list. aliasedNums[0] = 99; // Only the original need be disposed. nums.Dispose(); // Throws an ObjectDisposedException because disposing // the original deallocates the aliased memory. aliasedNums[0] = 99; Aliasing is useful for the following situations: Getting a collection's data in the form of another collection type without copying the data. For example, you can create an UnsafeList that aliases a NativeArray. Getting a subrange of a collection's data without copying the data. For example, you can create an UnsafeList that aliases a subrange of another list or array. Array reinterpretation. An Unsafe- collection can alias a Native- collection even though such cases undermine the safety checks. For example, if an UnsafeList aliases a NativeList, it's not safe to schedule a job that accesses one while also another job is scheduled that accesses the other, but the safety checks don't catch these cases. Array reinterpretation A reinterpretation of an array is an alias of the array that reads and writes the content as a different element type. For example, a NativeArray<int> which reinterprets a NativeArray<ushort> shares the same bytes, but it reads and writes the bytes as an int instead of a ushort. This is because each int is 4 bytes while each ushort is 2 bytes. Each int corresponds to two ushorts, and the reinterpretation has half the length of the original. NativeArray<int> ints = new NativeArray<int>(10, Allocator.Temp); // Length of the reinterpreted array is 20 // (because it has two shorts per one int of the original). NativeArray<short> shorts = ints.Reinterpret<int, short>(); // Modifies the first 4 bytes of the array. shorts[0] = 1; shorts[1] = 1; int val = ints[0]; // val is 65537 (2^16 + 2^0) // Like with other aliased collections, only the original // needs to be disposed. ints.Dispose(); // Throws an ObjectDisposedException because disposing // the original deallocates the aliased memory. shorts[0] = 1; Further information Define a custom allocator Rewindable allocators"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-benchmarks.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-benchmarks.html",
    "title": "Allocator benchmarks | Inventory System",
    "summary": "Allocator benchmarks The Collections package has different allocators that you can use to manage memory allocations. The different allocators organize and track their memory in different ways. These are the allocators available: Allocator.Temp: A fast allocator for short-lived allocations, which is created on every thread. Allocator.TempJob: A short-lived allocator, which must be deallocated within 4 frames of their creation. Allocator.Persistent: The slowest allocator for indefinite lifetime allocations. Rewindable allocator: A custom allocator that's fast and thread safe, and can rewind and free all your allocations at one point. The Entities package has its own set of custom prebuilt allocators: World update allocator: A double rewindable allocator that a world owns, which is fast and thread safe. Entity command buffer allocator: A rewindable allocator that an entity command buffer system owns and uses to create entity command buffers. System group allocator: An optional double rewindable allocator that a component system group creates when setting its rate manager. It's for allocations in a system of fixed or variable rate system group that ticks at different rate from the world update. For more information, see the Entities documentation on Custom prebuilt allocators. Allocator feature comparison The different allocators have the following different features: Allocator type Custom Allocator Need to create before use Lifetime Automatically freed allocations Can pass to jobs Min Allocation Alignment (bytes) Allocator.Temp No No A frame or a job Yes No 64 Allocator.TempJob No No Within 4 frames of creation No Yes 16 Allocator.Persistent No No Indefinite No Yes 16 Rewindable allocator Yes Yes Indefinite No Yes 64 Performance test results The following performance tests compare Temp, TempJob, Persistent and rewindable allocators. Because the world update allocator, entity command buffer allocator, and system group allocator are rewindable allocators, their performance is reflected in the rewindable allocator test results. The allocators are tested in single thread cases and in multithread cases by scheduling allocations in jobs across all the cores. For results, refer to the Performance comparison of allocators documentation."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-custom-define.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-custom-define.html",
    "title": "Custom allocator overview | Inventory System",
    "summary": "Custom allocator overview You can use a custom allocator for specific memory allocation needs. To create a custom allocator, it must contain an allocator handle of type AllocatorManager.AllocatorHandle and implement the interface, AllocatorManager.IAllocator. After you create a custom allocator, you need to register it in a global allocator table in AllocatorManager. Add the AllocatorManager.AllocatorHandle type to the custom allocator A custom allocator must contain an allocator handle of type AllocatorManager.AllocatorHandle. An allocator handle includes the following: Version: A 2 byte unsigned version number. Only the lower 15 bits are valid. Index: A 2 byte unsigned index of the global allocator table obtained during registration. Method to add a safety handle to the list of child safety handles of the allocator handle. Method to add a child allocator to the list of child allocators of the allocator handle. A rewind method to invalidate and unregister all the child allocators, invalidate all the child safety handles of the allocator handle, and increment the allocator handle' Version and OfficialVersion. Implement AllocatorManager.IAllocator interface To define a custom allocator, you must implement the interface AllocatorManager.IAllocator which includes: Function: A property that gets the allocator function of delegate TryFunction. The allocator function can allocate, deallocate, and reallocate memory. Try: A method that the allocator function invokes to allocate, deallocate, or reallocate memory. Handle: A property that gets and sets the allocator handle which is of type AllocatorManager.AllocatorHandle. ToAllocator: A property that casts the allocator handle index to the enum Allocator. IsCustomAllocator: A property that checks whether the allocator is a custom allocator. An allocator is a custom allocator if its handle Index is larger or equal to AllocatorManager.FirstUserIndex. IsAutoDispose: A property that checks whether the allocator is able to dispose individual allocations. True if disposing an individual allocation is a no-op. Because AllocatorManager.IAllocator implements IDisposable, your custom allocator must implement the Dispose method. The following is an example of how to set up the IAllocator interface and its required properties except the Try and AllocatorFunction method: // A custom allocator must implement AllocatorManager.IAllocator interface [BurstCompile(CompileSynchronously = true)] internal struct ExampleCustomAllocator : AllocatorManager.IAllocator { // A custom allocator must contain AllocatorManager.AllocatorHandle AllocatorManager.AllocatorHandle m_handle; // Implement the Function property required by IAllocator interface public AllocatorManager.TryFunction Function => AllocatorFunction; // Implement the Handle property required by IAllocator interface public AllocatorManager.AllocatorHandle Handle { get { return m_handle; } set { m_handle = value; } } // Implement the ToAllocator property required by IAllocator interface public Allocator ToAllocator { get { return m_handle.ToAllocator; } } // Implement the IsCustomAllocator property required by IAllocator interface public bool IsCustomAllocator { get { return m_handle.IsCustomAllocator; } } // Implement the IsAutoDispose property required by IAllocator interface // Allocations made by this example allocator are not automatically disposed. // This implementation can be skipped because the default implementation of // this property is false. public bool IsAutoDispose { get { return false; } } // Implement the Dispose method required by IDisposable interface because // AllocatorManager.IAllocator implements IDisposable public void Dispose() { // Make sure no memory leaks Assert.AreEqual(0, m_allocationCount); m_handle.Dispose(); } } The Try method tells a custom allocator how to allocate or deallocate memory. The following is an example of theTry method where a custom allocator allocates memory from Allocator.Persistant, initializes the allocated memory with a user configured value, and increments an allocation count. The custom allocator also decrements the allocation count when deallocating the allocated memory. // Value to initialize the allocated memory byte m_initialValue; // Allocation count int m_allocationCount; // Implement the Try method required by IAllocator interface public unsafe int Try(ref AllocatorManager.Block block) { // Error status int error = 0; // Allocate if (block.Range.Pointer == IntPtr.Zero) { // Allocate memory from Allocator.Persistant and restore the original allocator AllocatorManager.AllocatorHandle tempAllocator = block.Range.Allocator; block.Range.Allocator = Allocator.Persistent; error = AllocatorManager.Try(ref block); block.Range.Allocator = tempAllocator; // return if error occurs if (error != 0) return error; // if allocation succeeds, intialize the memory with the initial value and increment the allocation count if (block.Range.Pointer != IntPtr.Zero) { UnsafeUtility.MemSet((void*)block.Range.Pointer, m_initialValue, block.Bytes); Interlocked.Increment(ref m_allocationCount); } return 0; } // Deallocate else { // Deallocate memory from Allocator.Persistant and restore the original allocator AllocatorManager.AllocatorHandle tempAllocator = block.Range.Allocator; block.Range.Allocator = Allocator.Persistent; error = AllocatorManager.Try(ref block); block.Range.Allocator = tempAllocator; // return if error occurs if (error != 0) return error; // if deallocation succeeds, decrement the allocation count if (block.Range.Pointer == IntPtr.Zero) { Interlocked.Decrement(ref m_allocationCount); } return 0; } } Example method AllocatorFunction below shows an allocator function of the custom allocator. // Implement the allocator function of delegate AllocatorManager.TryFunction that is // required when register the allocator on the global allocator table [BurstCompile(CompileSynchronously = true)] [MonoPInvokeCallback(typeof(AllocatorManager.TryFunction))] public static unsafe int AllocatorFunction(IntPtr customAllocatorPtr, ref AllocatorManager.Block block) { return ((ExampleCustomAllocator*)customAllocatorPtr)->Try(ref block); } Global allocator table The global allocator table in AllocatorManager stores all the necessary information for custom allocators to work. When you instantiate a custom allocator, you must register the allocator in the global allocator table. The table stores the following information: A pointer to the custom allocator instance A pointer to the allocator function of the custom allocator instance The current official version of the custom allocator instance, lower 15 bits of a 2 byte unsigned integer value A list of child safety handles of native containers that are created using the custom allocator instance A list of child allocators that are allocated using the custom allocator instance A bit flag indicating whether the custom allocator is able to dispose individual allocations Custom allocator example The following is an example of a custom allocator that has an AllocatorManager.AllocatorHandle and initializes the allocated memory with a user configured value and increments the allocation count. It also uses AllocatorManager.TryFunction to register the allocator on the global allocator table: using System; using AOT; using System.Collections.Generic; using System.Threading.Tasks; using NUnit.Framework; using Unity.Collections; using Unity.Collections.LowLevel.Unsafe; using Unity.Burst; using System.Threading; // This is the example code used in // Packages/com.unity.collections/Documentation~/allocator/allocator-custom.md // Example custom allocator. The allocator is able to allocate memory from Allocator.Persistant, // if successful, initialize the allocated memory with a user configured value and increment an // allocation count. The allocator is able to deallocate the memory, if successful, decrement // the allocation count. // A custom allocator must implement AllocatorManager.IAllocator interface [BurstCompile(CompileSynchronously = true)] internal struct ExampleCustomAllocator : AllocatorManager.IAllocator { // A custom allocator must contain AllocatorManager.AllocatorHandle AllocatorManager.AllocatorHandle m_handle; // Implement the Function property required by IAllocator interface public AllocatorManager.TryFunction Function => AllocatorFunction; // Implement the Handle property required by IAllocator interface public AllocatorManager.AllocatorHandle Handle { get { return m_handle; } set { m_handle = value; } } // Implement the ToAllocator property required by IAllocator interface public Allocator ToAllocator { get { return m_handle.ToAllocator; } } // Implement the IsCustomAllocator property required by IAllocator interface public bool IsCustomAllocator { get { return m_handle.IsCustomAllocator; } } // Implement the IsAutoDispose property required by IAllocator interface // Allocations made by this example allocator are not automatically disposed. // This implementation can be skipped because the default implementation of // this property is false. public bool IsAutoDispose { get { return false; } } // Implement the Dispose method required by IDisposable interface because // AllocatorManager.IAllocator implements IDisposable public void Dispose() { // Make sure no memory leaks Assert.AreEqual(0, m_allocationCount); m_handle.Dispose(); } // Value to initialize the allocated memory byte m_initialValue; // Allocation count int m_allocationCount; // Implement the Try method required by IAllocator interface public unsafe int Try(ref AllocatorManager.Block block) { // Error status int error = 0; // Allocate if (block.Range.Pointer == IntPtr.Zero) { // Allocate memory from Allocator.Persistant and restore the original allocator AllocatorManager.AllocatorHandle tempAllocator = block.Range.Allocator; block.Range.Allocator = Allocator.Persistent; error = AllocatorManager.Try(ref block); block.Range.Allocator = tempAllocator; // return if error occurs if (error != 0) return error; // if allocation succeeds, intialize the memory with the initial value and increment the allocation count if (block.Range.Pointer != IntPtr.Zero) { UnsafeUtility.MemSet((void*)block.Range.Pointer, m_initialValue, block.Bytes); Interlocked.Increment(ref m_allocationCount); } return 0; } // Deallocate else { // Deallocate memory from Allocator.Persistant and restore the original allocator AllocatorManager.AllocatorHandle tempAllocator = block.Range.Allocator; block.Range.Allocator = Allocator.Persistent; error = AllocatorManager.Try(ref block); block.Range.Allocator = tempAllocator; // return if error occurs if (error != 0) return error; // if deallocation succeeds, decrement the allocation count if (block.Range.Pointer == IntPtr.Zero) { Interlocked.Decrement(ref m_allocationCount); } return 0; } } // Implement the allocator function of delegate AllocatorManager.TryFunction that is // required when register the allocator on the global allocator table [BurstCompile(CompileSynchronously = true)] [MonoPInvokeCallback(typeof(AllocatorManager.TryFunction))] public static unsafe int AllocatorFunction(IntPtr customAllocatorPtr, ref AllocatorManager.Block block) { return ((ExampleCustomAllocator*)customAllocatorPtr)->Try(ref block); } // Property to get the initial value public byte InitialValue => m_initialValue; // Property to get the allocation count public int AllocationCount => m_allocationCount; // Initialize the allocator public void Initialize(byte initialValue) { m_initialValue = initialValue; m_allocationCount = 0; } } Further information Use a custom allocator"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-custom-use.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-custom-use.html",
    "title": "Use a custom allocator | Inventory System",
    "summary": "Use a custom allocator Once you've defined a custom allocator, you can add it to your structure or class. Declare and create a custom allocator The first step is to declare and create the custom allocator. You must do the following: Allocate memory to hold the custom allocator Register the allocator by adding an entry in a global allocator table Initialize the allocator if necessary. The wrapper AllocatorHelper helps the process in creating a custom allocator. Examples are given below as how to declare and create a custom allocator defined in the Example custom allocator. // Example user structure that contains the custom allocator internal struct ExampleCustomAllocatorStruct { // Use AllocatorHelper to help creating the example custom alloctor AllocatorHelper<ExampleCustomAllocator> customAllocatorHelper; // Custom allocator property for accessibility public ref ExampleCustomAllocator customAllocator => ref customAllocatorHelper.Allocator; // Create the example custom allocator void CreateCustomAllocator(AllocatorManager.AllocatorHandle backgroundAllocator, byte initialValue) { // Allocate the custom allocator from backgroundAllocator and register the allocator customAllocatorHelper = new AllocatorHelper<ExampleCustomAllocator>(backgroundAllocator); // Set the initial value to initialize the memory customAllocator.Initialize(initialValue); } } Use a custom allocator to allocate memory For Native- collection types, allocation from a custom allocator is similar to a classic allocator, except you must use CollectionHelper.CreateNativeArray to create a NativeArray from a custom allocator and CollectionHelper.Dispose to deallocate a NativeArray from a custom allocator. For Unsafe- collection types, you must use AllocatorManager.Allocate to allocate memory from a custom allocator and AllocatorManager.Free to deallocate the memory. When you use a custom allocator to create a Native- collection type, its safety handle is added to the list of child safety handles of the custom allocator. When you rewind the allocator handle of a custom allocator, it invalidates and unregisters all its child allocators, and invalidates all its child safety handles. For Native- collection types, the disposal safety checks throw an exception if the allocator handle has rewound. The following example method UseCustomAllocator shows how to use a custom allocator to create and allocate native containers: // Sample code to use the custom allocator to allocate containers public void UseCustomAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList) { // Use custom allocator to allocate a native array and check initial value. nativeArray = CollectionHelper.CreateNativeArray<int, ExampleCustomAllocator>(100, ref customAllocator, NativeArrayOptions.UninitializedMemory); Assert.AreEqual(customAllocator.InitialValue, (byte)nativeArray[0] & 0xFF); nativeArray[0] = 0xFE; // Use custom allocator to allocate a native list and check initial value. nativeList = new NativeList<int>(customAllocator.Handle); for (int i = 0; i < 50; i++) { nativeList.Add(i); } unsafe { // Use custom allocator to allocate a byte buffer. byte* bytePtr = (byte*)AllocatorManager.Allocate(ref customAllocator, sizeof(byte), sizeof(byte), 10); Assert.AreEqual(customAllocator.InitialValue, bytePtr[0]); // Free the byte buffer. AllocatorManager.Free(customAllocator.ToAllocator, bytePtr, 10); } } Dispose a custom allocator To dispose a custom allocator, the following must happen: The custom allocator must rewind its allocator handle which invalidates and unregisters all the allocator handle's child allocators, and invalidates all its child safety handles. You must unregister the allocator You must dispose the memory used to store the allocator. Example method DisposeCustomAllocator in the user structure shows how to dispose a custom allocator. // Dispose the custom allocator void DisposeCustomAllocator() { // Dispose the custom allocator customAllocator.Dispose(); // Unregister the custom allocator and dispose it customAllocatorHelper.Dispose(); } Full example of a custom allocator The following is a full example of how to use a custom allocator: // Example user structure that contains the custom allocator internal struct ExampleCustomAllocatorStruct { // Use AllocatorHelper to help creating the example custom alloctor AllocatorHelper<ExampleCustomAllocator> customAllocatorHelper; // Custom allocator property for accessibility public ref ExampleCustomAllocator customAllocator => ref customAllocatorHelper.Allocator; // Create the example custom allocator void CreateCustomAllocator(AllocatorManager.AllocatorHandle backgroundAllocator, byte initialValue) { // Allocate the custom allocator from backgroundAllocator and register the allocator customAllocatorHelper = new AllocatorHelper<ExampleCustomAllocator>(backgroundAllocator); // Set the initial value to initialize the memory customAllocator.Initialize(initialValue); } // Dispose the custom allocator void DisposeCustomAllocator() { // Dispose the custom allocator customAllocator.Dispose(); // Unregister the custom allocator and dispose it customAllocatorHelper.Dispose(); } // Constructor of user structure public ExampleCustomAllocatorStruct(byte initialValue) { this = default; CreateCustomAllocator(Allocator.Persistent, initialValue); } // Dispose the user structure public void Dispose() { DisposeCustomAllocator(); } // Sample code to use the custom allocator to allocate containers public void UseCustomAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList) { // Use custom allocator to allocate a native array and check initial value. nativeArray = CollectionHelper.CreateNativeArray<int, ExampleCustomAllocator>(100, ref customAllocator, NativeArrayOptions.UninitializedMemory); Assert.AreEqual(customAllocator.InitialValue, (byte)nativeArray[0] & 0xFF); nativeArray[0] = 0xFE; // Use custom allocator to allocate a native list and check initial value. nativeList = new NativeList<int>(customAllocator.Handle); for (int i = 0; i < 50; i++) { nativeList.Add(i); } unsafe { // Use custom allocator to allocate a byte buffer. byte* bytePtr = (byte*)AllocatorManager.Allocate(ref customAllocator, sizeof(byte), sizeof(byte), 10); Assert.AreEqual(customAllocator.InitialValue, bytePtr[0]); // Free the byte buffer. AllocatorManager.Free(customAllocator.ToAllocator, bytePtr, 10); } } // Get allocation count from the custom allocator public int AllocationCount => customAllocator.AllocationCount; public void UseCustomAllocatorHandle(out NativeArray<int> nativeArray, out NativeList<int> nativeList) { // Use custom allocator to allocate a native array and check initial value. nativeArray = CollectionHelper.CreateNativeArray<int>(100, customAllocator.ToAllocator, NativeArrayOptions.UninitializedMemory); Assert.AreEqual(customAllocator.InitialValue, (byte)nativeArray[0] & 0xFF); nativeArray[0] = 0xFE; // Use custom allocator to allocate a native list and check initial value. nativeList = new NativeList<int>(customAllocator.Handle); for (int i = 0; i < 50; i++) { nativeList.Add(i); } unsafe { // Use custom allocator to allocate a byte buffer. byte* bytePtr = (byte*)AllocatorManager.Allocate(ref customAllocator, sizeof(byte), sizeof(byte), 10); Assert.AreEqual(customAllocator.InitialValue, bytePtr[0]); // Free the byte buffer. AllocatorManager.Free(customAllocator.ToAllocator, bytePtr, 10); } } } internal class ExampleCustomAllocatorStructUsage { // Initial value for the custom allocator. const int IntialValue = 0xAB; // Test code. [Test] public void UseCustomAllocator_Works() { ExampleCustomAllocatorStruct exampleStruct = new ExampleCustomAllocatorStruct(IntialValue); // Allocate native array and native list from the custom allocator exampleStruct.UseCustomAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList); // Able to access the native array and native list Assert.AreEqual(nativeArray[0], 0xFE); Assert.AreEqual(nativeList[10], 10); // Need to use CollectionHelper.DisposeNativeArray to dispose the native array from a custom allocator CollectionHelper.Dispose(nativeArray) ; // Dispose the native list nativeList.Dispose(); #if ENABLE_UNITY_COLLECTIONS_CHECKS // Object disposed exception throws because nativeArray is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeArray[0] = 0xEF; }); // Object disposed exception throws because nativeList is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeList[10] = 0x10; }); #endif // Check allocation count after dispose the native array and native list Assert.AreEqual(0, exampleStruct.AllocationCount); // Dispose the user structure exampleStruct.Dispose(); } [Test] public void UseCustomAllocatorHandle_Works() { ExampleCustomAllocatorStruct exampleStruct = new ExampleCustomAllocatorStruct(IntialValue); // Allocate native array and native list from the custom allocator handle exampleStruct.UseCustomAllocatorHandle(out NativeArray<int> nativeArray, out NativeList<int> nativeList); // Able to access the native array and native list Assert.AreEqual(nativeArray[0], 0xFE); Assert.AreEqual(nativeList[10], 10); // Need to use CollectionHelper.DisposeNativeArray to dispose the native array from a custom allocator CollectionHelper.Dispose(nativeArray); // Dispose the native list nativeList.Dispose(); #if ENABLE_UNITY_COLLECTIONS_CHECKS // Object disposed exception throws because nativeArray is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeArray[0] = 0xEF; }); // Object disposed exception throws because nativeList is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeList[10] = 0x10; }); #endif // Check allocation count after dispose the native array and native list Assert.AreEqual(0, exampleStruct.AllocationCount); // Dispose the user structure exampleStruct.Dispose(); } [Test] public void CustomAllocatorHandle_MultiThreadWorks() { ExampleCustomAllocatorStruct exampleStruct = new ExampleCustomAllocatorStruct(IntialValue); var taskList = new List<Task>(); // create 128 native array with another threads for (var i = 0; i < 128; i++) { var task = Task.Run(() => { var nativeArray = CollectionHelper.CreateNativeArray<int, ExampleCustomAllocator>(100, ref exampleStruct.customAllocator, NativeArrayOptions.UninitializedMemory); CollectionHelper.Dispose(nativeArray); }); taskList.Add(task); } Task.WaitAll(taskList.ToArray()); exampleStruct.Dispose(); } }"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-overview.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-overview.html",
    "title": "Allocator overview | Inventory System",
    "summary": "Allocator overview An allocator governs unmanaged memory from which you can make allocations. Different allocators organize and track their memory in different ways. The Collections package includes the following allocators: Allocator.Temp: The fastest allocator, for short-lived allocations. You can't pass this allocator to a job. Allocator.TempJob: A short-lived allocator that you can pass into jobs. Allocator.Persistent: The slowest allocator for indefinite lifetime allocations. You can pass this allocator to a job. Allocator.Temp Each frame, the main thread creates a Temp allocator which it deallocates in its entirety at the end of the frame. Each job also creates one Temp allocator per thread, and deallocates them in their entirety at the end of the job. Because a Temp allocator gets discarded as a whole, you don't need to manually deallocate Temp allocations, and doing so does nothing. The minimum alignment of Temp allocations is 64 bytes. Temp allocations are only safe to use in the thread and the scope where they were allocated. While you can make Temp allocations within a job, you can't pass main thread Temp allocations into a job. For example, you can't pass a native array that's Temp allocated in the main thread into a job. Allocator.TempJob You must deallocate TempJob allocations within 4 frames of their creation. 4 frames is the limit so that you can have an allocation that lasts a couple of frames with some extra margin for error. The minimum alignment of TempJob allocations is 16 bytes. For Native- collection types, the disposal safety checks throw an exception if a TempJob allocation lasts longer than 4 frames. For Unsafe- collection types, you must deallocate them within 4 frames, but Unity doesn't perform any safety checks to make sure that you do so. Allocator.Persistent Because Persistent allocations can remain indefinitely, safety checks can't detect if a Persistent allocation has outlived its intended lifetime. As such, you must deallocate a Persistent allocation when you no longer need it. The minimum alignment of Persistent allocations is 16 bytes. Deallocating an allocator Each collection retains a reference to the allocator that allocated its memory. This is because you must specify the allocator to deallocate its memory. An Unsafe- collection's Dispose method deallocates its memory. A Native- collection's Dispose method deallocates its memory and frees the handles needed for safety checks. An enumerator's Dispose method does nothing. The method exists only to fulfill the IEnumerator<T> interface. To dispose a collection after the jobs which need it have run, you can use the Dispose(JobHandle) method. This creates and schedules a job which disposes of the collection, and this new job takes the input handle as its dependency. Effectively, the method defers disposal until after the dependency runs: NativeArray<int> nums = new NativeArray<int>(10, Allocator.TempJob); // Create and schedule a job that uses the array. ExampleJob job = new ExampleJob { Nums = nums }; JobHandle handle = job.Schedule(); // Create and schedule a job that will dispose the array after the ExampleJob has run. // Returns the handle of the new job. handle = nums.Dispose(handle); IsCreated property The IsCreated property of a collection is false only in the following cases: Immediately after creating a collection with its default constructor. After Dispose has been called on the collection. Note You don't need to use a collection's default constructor. The constructor is only available because C# requires all structs have a public default constructor. Calling Dispose on a collection sets IsCreated to false only for that struct, and not in any copies of the struct. IsCreated might still be true even after the collection's underlying memory is deallocated in the following situations: Dispose was called on a different copy of the struct. The underlying memory was deallocated via an alias. Additional resources Aliasing allocators Rewindable allocators Define a custom allocator"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-rewindable.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/allocator-rewindable.html",
    "title": "Rewindable allocator overview | Inventory System",
    "summary": "Rewindable allocator overview A rewindable allocator is a custom allocator that works in a similar way to a linear allocator. It's fast and thread safe. A rewindable allocator pre-allocates blocks of memory in advance. When you request memory from a rewindable allocator, it selects a range of memory from its pre-allocated block and assigns it to use. The minimum alignment of rewindable allocations is 64 bytes. After it uses all the existing blocks of memory, the rewindable allocator allocates another block of memory. It doubles the size of the new block until it reaches a maximum block size. When it reaches this point, the rewindable allocator adds the maximum block size to its previous block size to increase its block size linearly. One advantage of rewindable allocator is that you don't need to free individual allocations. As its name implies, a rewindable allocator can rewind and free all your allocations at one point. When you rewind an allocator, the allocator keeps the memory blocks that it used before to improve performance and disposes the rest of the blocks. When you request to free or dispose a memory allocation from a rewindable allocator, it's a no-op unless you set the enable block free flag of the rewindable allocator. When you set the flag to enable block free, the rewindable allocator rewinds a memory block when it frees the last allocation from the block. Declare and create a rewindable allocator To create a rewindable allocator, you must do the following: Allocate memory to hold the rewindable allocator Add an entry in the global allocator table to register the allocator Pre-allocate the allocator's first memory block to initialize it. You can use the wrapper AllocatorHelper to create a rewindable allocator. The following example declares and creates a rewindable allocator: // Example user structure internal struct ExampleStruct { // Use AllocatorHelper to help creating a rewindable alloctor AllocatorHelper<RewindableAllocator> rwdAllocatorHelper; // Rewindable allocator property for accessibility public ref RewindableAllocator RwdAllocator => ref rwdAllocatorHelper.Allocator; // Create the rewindable allocator void CreateRewindableAllocator(AllocatorManager.AllocatorHandle backgroundAllocator, int initialBlockSize, bool enableBlockFree = false) { // Allocate the rewindable allocator from backgroundAllocator and register the allocator rwdAllocatorHelper = new AllocatorHelper<RewindableAllocator>(backgroundAllocator); // Allocate the first memory block with initialBlockSize in bytes, and indicate whether // to enable the rewindable allocator with individual block free through enableBlockFree RwdAllocator.Initialize(initialBlockSize, enableBlockFree); } } Use a rewindable allocator to allocate memory For Native- collection types, allocation from a rewindable allocator is similar to a classic allocator, except you must use CollectionHelper.CreateNativeArray to create a NativeArray from a rewindable allocator. When you use a rewindable allocator to create a Native- collection type, its safety handle is added to the list of child safety handles of the rewindable allocator. For Unsafe- collection types, you must use AllocatorManager.Allocate to allocate memory from a rewindable allocator. You don't need to dispose individual allocations. When all allocations aren't needed anymore, call the Rewind method of a rewindable allocator to free all its allocations. When you rewind the rewindable allocator, it invalidates and unregisters its child allocators, and invalidates all its child safety handles. For Native- collection types, the disposal safety checks throw an exception if the rewindable allocator has rewound. This example method UseRewindableAllocator shows how to use a rewindable allocator to create and allocate native containers: // Sample code to use rewindable allocator to allocate containers public unsafe void UseRewindableAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList, out byte* bytePtr) { // Use rewindable allocator to allocate a native array, no need to dispose the array manually // CollectionHelper is required to create/allocate native array from a custom allocator. nativeArray = CollectionHelper.CreateNativeArray<int, RewindableAllocator>(100, ref RwdAllocator); nativeArray[0] = 0xFE; // Use rewindable allocator to allocate a native list, do not need to dispose the list manually nativeList = new NativeList<int>(RwdAllocator.Handle); for (int i = 0; i < 50; i++) { nativeList.Add(i); } // Use custom allocator to allocate a byte buffer. bytePtr = (byte*)AllocatorManager.Allocate(ref RwdAllocator, sizeof(byte), sizeof(byte), 10); bytePtr[0] = 0xAB; } Free all allocated memory of a rewindable allocator When you Rewind the rewindable allocator, it performs the following operations: Invalidates and unregisters all the allocator handle's child allocators Invalidates all its child safety handles The example method FreeRewindableAllocator shows how to Free all allocations from the rewindable allocator, with Rewind. // Free all allocations from the rewindable allocator public void FreeRewindableAllocator() { RwdAllocator.Rewind(); } Dispose a rewindable allocator To dispose a rewindable allocator, you must do the following: Dispose all the memory blocks of the rewindable allocator from Allocator.Persistant. Unregister the allocator Dispose the memory used to store the allocator The following example adds a method DisposeRewindableAllocatorthat disposes a rewindable allocator using Dispose: // Dispose the rewindable allocator void DisposeRewindableAllocator() { // Dispose all the memory blocks in the rewindable allocator RwdAllocator.Dispose(); // Unregister the rewindable allocator and dispose it rwdAllocatorHelper.Dispose(); } Full example of a rewindable allocator The following is a full example of how to use a rewindable allocator: using System; using NUnit.Framework; using Unity.Collections; // This is the example code used in // Packages/com.unity.collections/Documentation~/allocator/allocator-rewindable.md // Example user structure internal struct ExampleStruct { // Use AllocatorHelper to help creating a rewindable alloctor AllocatorHelper<RewindableAllocator> rwdAllocatorHelper; // Rewindable allocator property for accessibility public ref RewindableAllocator RwdAllocator => ref rwdAllocatorHelper.Allocator; // Create the rewindable allocator void CreateRewindableAllocator(AllocatorManager.AllocatorHandle backgroundAllocator, int initialBlockSize, bool enableBlockFree = false) { // Allocate the rewindable allocator from backgroundAllocator and register the allocator rwdAllocatorHelper = new AllocatorHelper<RewindableAllocator>(backgroundAllocator); // Allocate the first memory block with initialBlockSize in bytes, and indicate whether // to enable the rewindable allocator with individual block free through enableBlockFree RwdAllocator.Initialize(initialBlockSize, enableBlockFree); } // Constructor of user structure public ExampleStruct(int initialBlockSize) { this = default; CreateRewindableAllocator(Allocator.Persistent, initialBlockSize, false); } // Dispose the user structure public void Dispose() { DisposeRewindableAllocator(); } // Sample code to use rewindable allocator to allocate containers public unsafe void UseRewindableAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList, out byte* bytePtr) { // Use rewindable allocator to allocate a native array, no need to dispose the array manually // CollectionHelper is required to create/allocate native array from a custom allocator. nativeArray = CollectionHelper.CreateNativeArray<int, RewindableAllocator>(100, ref RwdAllocator); nativeArray[0] = 0xFE; // Use rewindable allocator to allocate a native list, do not need to dispose the list manually nativeList = new NativeList<int>(RwdAllocator.Handle); for (int i = 0; i < 50; i++) { nativeList.Add(i); } // Use custom allocator to allocate a byte buffer. bytePtr = (byte*)AllocatorManager.Allocate(ref RwdAllocator, sizeof(byte), sizeof(byte), 10); bytePtr[0] = 0xAB; } // Free all allocations from the rewindable allocator public void FreeRewindableAllocator() { RwdAllocator.Rewind(); } // Dispose the rewindable allocator void DisposeRewindableAllocator() { // Dispose all the memory blocks in the rewindable allocator RwdAllocator.Dispose(); // Unregister the rewindable allocator and dispose it rwdAllocatorHelper.Dispose(); } } internal class ExampleStructSampleUsage { // Initial block size of the rewindable allocator. const int IntialBlockSize = 128 * 1024; [Test] public unsafe void UseRewindableAllocator_Works() { ExampleStruct exampleStruct = new ExampleStruct(IntialBlockSize); // Allocate native array and native list from rewindable allocator exampleStruct.UseRewindableAllocator(out NativeArray<int> nativeArray, out NativeList<int> nativeList, out byte* bytePtr); // Still able to access the native array, native list and byte buffer Assert.AreEqual(nativeArray[0], 0xFE); Assert.AreEqual(nativeList[10], 10); Assert.AreEqual(bytePtr[0], 0xAB); // Free all memories allocated from the rewindable allocator // No need to dispose the native array and native list exampleStruct.FreeRewindableAllocator(); #if ENABLE_UNITY_COLLECTIONS_CHECKS // Object disposed exception throws because nativeArray is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeArray[0] = 0xEF; }); // Object disposed exception throws because nativeList is already disposed Assert.Throws<ObjectDisposedException>(() => { nativeList[10] = 0x10; }); #endif // Dispose the user structure exampleStruct.Dispose(); } }"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/collection-types.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/collection-types.html",
    "title": "Collection types | Inventory System",
    "summary": "Collection types The collection types in this package extend and compliment the collections available in the Unity engine. This section outlines some key collection types you might want to use in your jobs and Burst compiled code. Array-like types The array-like types in this package extend the key array types in the UnityEngine.CoreModule namespace, which include Unity.Collections.NativeArray<T> and Unity.Collections.NativeSlice<T>. This package has the following array-like types: Data structure Description NativeList<T> A resizable list. Has thread and disposal safety checks. UnsafeList<T> A resizable list. UnsafePtrList<T> A resizable list of pointers. NativeStream A set of append-only, untyped buffers. Has thread and disposal safety checks. UnsafeStream A set of append-only, untyped buffers. UnsafeAppendBuffer An append-only untyped buffer. NativeQueue<T> A resizable queue. Has thread and disposal safety checks. NativeRingQueue<T> A fixed-size circular buffer. Has disposal safety checks. UnsafeRingQueue<T> A fixed-size circular buffer. FixedList32Bytes<T> A 32-byte list, which includes 2 bytes of overhead, so 30 bytes are available for storage. Max capacity depends upon T. FixedList32Bytes<T> has variants of larger sizes: - FixedList64Bytes<T> - FixedList128Bytes<T> - FixedList512Bytes<T> - FixedList4096Bytes<T> There aren't any multi-dimensional array types, but you can pack all the data into a single dimension. For example, for an int[4][5] array, use an int[20] array instead (because 4 * 5 is 20). Additionally, there are various extension methods in NativeArrayExtensions, ListExtensions, and NativeSortExtension. Map and set types Use these collection types in single threads when there is a low memory overhead: Data structure Description NativeHashMap<TKey, TValue> An unordered associative array of key-value pairs. Has thread and disposal safety checks. UnsafeHashMap<TKey, TValue> An unordered associative array of key-value pairs. NativeHashSet<T> A set of unique values. Has thread and disposal safety checks. UnsafeHashSet<T> A set of unique values. Use these collection types in multithreaded situations, when there is a high memory overhead. Data structure Description NativeParallelHashMap<TKey, TValue> An unordered associative array of key-value pairs. Has thread and disposal safety checks. UnsafeParallelHashMap<TKey, TValue> An unordered associative array of key value pairs. NativeParallelHashSet<T> A set of unique values. Has thread and disposal safety checks. UnsafeParallelHashSet<T> A set of unique values. NativeParallelMultiHashMap<TKey, TValue> An unordered associative array of key value pairs. The keys don't have to be unique. For example, two pairs can have equal keys. Has thread and disposal safety checks. UnsafeParallelMultiHashMap<TKey, TValue> An unordered associative array of key value pairs. The keys don't have to be unique. For example, two pairs can have equal keys. Additionally, there are various extension methods in NotBurstCompatible.Extensions and Unsafe.NotBurstCompatible.Extensions. Bit arrays and bit fields The following are arrays of bits: Data structure Description BitField32 A fixed-size array of 32 bits. BitField64 A fixed-size array of 64 bits. NativeBitArray An arbitrary sized array of bits. Has thread and disposal safety checks. UnsafeBitArray An arbitrary-sized array of bits. String types The following are string types: Data structure Description NativeText A UTF-8 encoded string. Mutable and resizable. Has thread and disposal safety checks. UnsafeText A UTF-8 encoded string. Mutable and resizable. FixedString32Bytes A 32-byte UTF-8 encoded string, including 3 bytes of overhead, so 29 bytes available for storage. FixedString64Bytes A 64-byte UTF-8 encoded string, including 3 bytes of overhead, so 61 bytes available for storage. FixedString128Bytes A 128-byte UTF-8 encoded string, including 3 bytes of overhead, so 125 bytes available for storage. FixedString512Bytes A 512-byte UTF-8 encoded string, including 3 bytes of overhead, so 509 bytes available for storage. FixedString4096Bytes A 4096-byte UTF-8 encoded string, including 3 bytes of overhead, so 4093 bytes available for storage. There are further extension methods in FixedStringMethods. Other types Data structure Description NativeReference<T> A reference to a single value. Functionally equivalent to an array of length 1. Has thread and disposal safety checks. UnsafeAtomicCounter32 A 32-bit atomic counter. UnsafeAtomicCounter64 A 64-bit atomic counter. Enumerators Most of the collections have a GetEnumerator method, which returns an implementation of IEnumerator<T>. The enumerator's MoveNext method advances its Current property to the next element: NativeList<int> nums = new NativeList<int>(10, Allocator.Temp); // Calculate the sum of all elements in the list. int sum = 0; var enumerator = nums.GetEnumerator(); // The first MoveNext call advances the enumerator to the first element. // MoveNext returns false when the enumerator has advanced past the last element. while (enumerator.MoveNext()) { sum += enumerator.Current; } // The enumerator is no longer valid to use after the array is disposed. nums.Dispose();"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/collections-overview.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/collections-overview.html",
    "title": "Collections overview | Inventory System",
    "summary": "Collections overview The Collections package extends the concepts and collections in the core Unity engine, including adding more native container objects and job types. The collections in this package fall into the following categories: Collection types which have safety checks that make sure that Unity properly disposes of the type, and you use them in a thread-safe way. These types are in the Unity.Collections namespace and their names start with Native. Collection types which don't have safety checks. These types are in the Unity.Collections.LowLevel.Unsafe namespace and their names start with Unsafe. The remaining collection types which don't fit into these categories aren't allocated and don't contain any pointers. These types only contain small amounts of data, and their disposal and thread safety aren't a concern. Native and unsafe comparison Native collection types perform safety checks to make sure that indices passed to their methods are in bounds, but the other types don't have these kind of checks. Several Native types have Unsafe equivalents, for example, NativeList has UnsafeList, and NativeHashMap has UnsafeHashMap. It's best practice to use Native collections over the Unsafe equivalents. However, it's sometimes necessary to use the Unsafe equivalents because Native collection types can't contain other Native collections. This is because of how Unity implements the Native safety checks. For example, if you want to get a list of lists, you can use either NativeList<UnsafeList<T>> or UnsafeList<UnsafeList<T>>, but you can't use NativeList<NativeList<T>>. If you've disabled safety checks, then there isn't a significant performance difference between a Native type and its Unsafe equivalent. In fact, most Native collections are implemented as wrappers of their Unsafe counterparts. For example, NativeList is made up of an UnsafeList plus some handles that the safety checks use. Additional resources Collection types overview Parallel readers and writers"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/index.html",
    "title": "Collections package | Inventory System",
    "summary": "Collections package The Collections package provides unmanaged data structures that you can use in jobs and Burst-compiled code. Topic Description Collections overview Understand the collection types contained in this package. Use allocators to control unmanaged memory Understand how to use allocators to control unmanaged memory. Additional resources Job system documentation Burst documentation"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/issues.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/issues.html",
    "title": "Known issues | Inventory System",
    "summary": "Known issues All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance rather than each having their own. Most of the time, this isn't an issue because you can't pass Temp allocated collections into a job. However, when you use Native*HashMap, NativeParallelMultiHashMap, Native*HashSet, and NativeList together with their secondary safety handle, this shared AtomicSafetyHandle instance is a problem. A secondary safety handle ensures that a NativeArray which aliases a NativeList is invalidated when the NativeList is reallocated due to resizing. Operations that invalidate an enumerator for these collection types, or invalidate the NativeArray that NativeList.AsArray returns also invalidates all other previously acquired enumerators. For example, the following throws an error when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0];"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/parallel-readers.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/parallel-readers.html",
    "title": "Parallel readers and writers | Inventory System",
    "summary": "Parallel readers and writers Several of the collection types have nested types to read and write from parallel jobs. For example, to write safely to a NativeList<T> from a parallel job, you need to use NativeList<T>.ParallelWriter: NativeList<int> nums = new NativeList<int>(1000, Allocator.TempJob); // The parallel writer shares the original list's AtomicSafetyHandle. var job = new MyParallelJob {NumsWriter = nums.AsParallelWriter()}; public struct MyParallelJob : IJobParallelFor { public NativeList<int>.ParallelWriter NumsWriter; public void Execute(int i) { // A NativeList<T>.ParallelWriter can append values // but not grow the capacity of the list. NumsWriter.AddNoResize(i); } } Note that these parallel readers and writers don't support the full functionality of the collection. For example, a NativeList can't grow its capacity in a parallel job because there's no way to safely allow this without incurring a synchronization overhead. Deterministic reading and writing Although a ParallelWriter ensures the safety of concurrent writes, the order of the concurrent writes is indeterminstic because it depends on thread scheduling. The operating system and other factors outside of your program's control determine thread scheduling. Likewise, although a ParallelReader ensures the safety of concurrent reads, the order of the concurrent reads is indeterminstic, you can't know which threads read which values. To get around this, you can use either NativeStream or UnsafeStream, which splits reads and writes into a separate buffer for each thread and avoids indeterminism. Alternatively, you can effectively get a deterministic order of parallel reads if you deterministically divide the reads into separate ranges and process each range in its own thread. You can also get a deterministic order if you deterministically sort the data after it has been written to the list."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparison-allocators.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparison-allocators.html",
    "title": "Performance Comparison: Allocators | Inventory System",
    "summary": "Performance Comparison: Allocators This file is auto-generated All measurments were taken on 12th Gen Intel(R) Core(TM) i9-12900K with 24 logical cores. Unity Editor version: 2022.2.8f1 To regenerate this file locally use: DOTS -> Unity.Collections -> Generate *** menu. Table of Contents Benchmark Results RewindableAllocator Benchmark Results The following benchmarks make 150 consecutive allocations per sample set. Multithreaded benchmarks make the full 150 consecutive allocations per worker thread per sample set. The Min of 50 sample sets is compared against the baseline on the far right side of the table. 5 extra sample sets are run as warmup. Legend (S) = Safety Enabled (B) = Burst Compiled with Safety Disabled (S+B) = Burst Compiled with Safety Enabled (E) = Engine Provided italic results are for benchmarking comparison only; these are not included in standard Performance Framework tests RewindableAllocator Functionality RewindableAllocator (S) RewindableAllocator (S+B) RewindableAllocator (B) TempJob (E) Temp (E) Persistent (E) FixedSize(1, 1024)³ 11.4µs (2.2x) 4.0µs (6.3x) 3.8µs (6.6x) \uD83D\uDFE2 17.0µs (1.5x) 10.1µs (2.5x) 25.1µs (1.0x) \uD83D\uDFE0 FixedSize(2, 1024)²˒³ 23.0µs (2.1x) 23.1µs (2.0x) 9.0µs (5.2x) \uD83D\uDFE2 20.2µs (2.3x) 11.2µs (4.2x) 47.2µs (1.0x) \uD83D\uDFE0 FixedSize(4, 1024)²˒³ 66.4µs (1.9x) 71.9µs (1.7x) 80.8µs (1.5x) 23.5µs (5.3x) 11.5µs (10.7x) \uD83D\uDFE2 123.5µs (1.0x) \uD83D\uDFE0 FixedSize(8, 1024)²˒³ 167.1µs (2.2x) 169.2µs (2.2x) 167.3µs (2.2x) 45.6µs (8.0x) 12.8µs (28.6x) \uD83D\uDFE2 366.4µs (1.0x) \uD83D\uDFE0 FixedSize(1, 1048576)³ 11.9µs (16.3x) 4.7µs (41.3x) 4.4µs (44.1x) \uD83D\uDFE2 17.1µs (11.4x) 10.9µs (17.8x) 194.1µs (1.0x) \uD83D\uDFE0 FixedSize(2, 1048576)²˒³ 26.0µs (10.0x) 17.0µs (15.2x) 14.1µs (18.4x) 32.0µs (8.1x) 11.7µs (22.1x) \uD83D\uDFE2 258.9µs (1.0x) \uD83D\uDFE0 FixedSize(4, 1048576)²˒³ 70.1µs (11.6x) 71.3µs (11.4x) 75.3µs (10.8x) 208.5µs (3.9x) 12.5µs (65.0x) \uD83D\uDFE2 812.2µs (1.0x) \uD83D\uDFE0 FixedSize(8, 1048576)²˒³ 139.7µs (14.6x) 161.0µs (12.7x) 179.8µs (11.3x) 1317.1µs (1.5x) 19.5µs (104.6x) \uD83D\uDFE2 2039.9µs (1.0x) \uD83D\uDFE0 IncSize(1, 4096)⁴ 11.9µs (4.0x) 4.6µs (10.3x) 4.3µs (11.0x) \uD83D\uDFE2 17.9µs (2.6x) 10.3µs (4.6x) 47.2µs (1.0x) \uD83D\uDFE0 IncSize(2, 4096)²˒⁴ 26.8µs (4.8x) 10.9µs (11.7x) 10.5µs (12.2x) \uD83D\uDFE2 31.7µs (4.0x) 10.9µs (11.7x) 127.6µs (1.0x) \uD83D\uDFE0 IncSize(4, 4096)²˒⁴ 58.9µs (7.6x) 67.6µs (6.6x) 64.5µs (6.9x) 71.9µs (6.2x) 11.2µs (39.7x) \uD83D\uDFE2 444.7µs (1.0x) \uD83D\uDFE0 IncSize(8, 4096)²˒⁴ 169.3µs (7.8x) 159.0µs (8.3x) 185.7µs (7.1x) 350.8µs (3.8x) 11.5µs (114.7x) \uD83D\uDFE2 1319.0µs (1.0x) \uD83D\uDFE0 IncSize(1, 65536)⁴ 12.7µs (49.2x) 5.0µs (125.1x) 4.7µs (133.1x) \uD83D\uDFE2 19.0µs (32.9x) 11.0µs (56.9x) 625.4µs (1.0x) \uD83D\uDFE0 IncSize(2, 65536)²˒⁴ 25.0µs (46.3x) 15.8µs (73.3x) 13.0µs (89.1x) 578.1µs (2.0x) 11.3µs (102.5x) \uD83D\uDFE2 1157.7µs (1.0x) \uD83D\uDFE0 IncSize(4, 65536)²˒⁴ 73.3µs (34.7x) 73.0µs (34.8x) 70.5µs (36.1x) 2098.0µs (1.2x) 11.9µs (213.6x) \uD83D\uDFE2 2542.2µs (1.0x) \uD83D\uDFE0 IncSize(8, 65536)²˒⁴ 141.3µs (40.5x) 168.1µs (34.1x) 162.6µs (35.2x) 6036.0µs (0.9x) \uD83D\uDFE0 12.7µs (450.8x) \uD83D\uDFE2 5724.9µs (1.0x) DecSize(1, 4096)⁵ 12.2µs (6.1x) 4.6µs (16.1x) 4.3µs (17.2x) \uD83D\uDFE2 16.9µs (4.4x) 9.8µs (7.5x) 73.9µs (1.0x) \uD83D\uDFE0 DecSize(2, 4096)²˒⁵ 27.6µs (3.4x) 12.5µs (7.6x) 11.9µs (8.0x) 37.3µs (2.5x) 11.4µs (8.3x) \uD83D\uDFE2 94.9µs (1.0x) \uD83D\uDFE0 DecSize(4, 4096)²˒⁵ 68.5µs (7.5x) 74.7µs (6.8x) 69.4µs (7.4x) 79.3µs (6.5x) 11.0µs (46.5x) \uD83D\uDFE2 511.6µs (1.0x) \uD83D\uDFE0 DecSize(8, 4096)²˒⁵ 173.5µs (7.4x) 173.4µs (7.4x) 168.3µs (7.6x) 313.4µs (4.1x) 17.1µs (75.1x) \uD83D\uDFE2 1284.6µs (1.0x) \uD83D\uDFE0 DecSize(1, 65536)⁵ 12.1µs (47.9x) 4.6µs (126.0x) 4.3µs (134.8x) \uD83D\uDFE2 20.8µs (27.9x) 11.7µs (49.6x) 579.8µs (1.0x) \uD83D\uDFE0 DecSize(2, 65536)²˒⁵ 28.6µs (37.1x) 17.7µs (60.0x) 11.5µs (92.3x) \uD83D\uDFE2 658.8µs (1.6x) 12.5µs (84.9x) 1061.4µs (1.0x) \uD83D\uDFE0 DecSize(4, 65536)²˒⁵ 67.3µs (38.8x) 69.4µs (37.6x) 73.1µs (35.7x) 2386.4µs (1.1x) 14.2µs (183.8x) \uD83D\uDFE2 2609.3µs (1.0x) \uD83D\uDFE0 DecSize(8, 65536)²˒⁵ 154.4µs (37.8x) 166.6µs (35.0x) 155.9µs (37.4x) 5938.8µs (1.0x) \uD83D\uDFE0 28.6µs (203.9x) \uD83D\uDFE2 5830.8µs (1.0x) ² Benchmark run on parallel job workers - results may vary ³ FixedSize(workerThreads, allocSize) ⁴ IncSize(workerThreads, allocSize) -- Makes linearly increasing allocations [1⋅allocSize, 2⋅allocSize ... N⋅allocSize] ⁵ DecSize(workerThreads, allocSize) -- Makes linearly decreasing allocations [N⋅allocSize ... 2⋅allocSize, 1⋅allocSize]"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparison-containers.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparison-containers.html",
    "title": "Performance Comparison: Containers | Inventory System",
    "summary": "Performance Comparison: Containers This file is auto-generated All measurments were taken on Intel(R) Core(TM) i9-9900KS CPU @ 4.00GHz with 16 logical cores. Unity Editor version: 2022.3.6f1 To regenerate this file locally use: DOTS -> Unity.Collections -> Generate *** menu. Table of Contents Benchmark Results HashMap HashSet List ParallelHashMap ParallelHashSet QueueParallelWriter Queue RingQueue Benchmark Results The Median of 10 sample sets is compared against the baseline on the far right side of the table. Multithreaded benchmarks divide the processing amongst the specified number of workers. 5 extra sample sets are run as warmup. Legend (S) = Safety Enabled (B) = Burst Compiled with Safety Disabled (S+B) = Burst Compiled with Safety Enabled (BCL) = Base Class Library implementation (such as provided by Mono or .NET) italic results are for benchmarking comparison only; these are not included in standard Performance Framework tests HashMap Functionality NativeHashMap (S) NativeHashMap (S+B) NativeHashMap (B) UnsafeHashMap (S) UnsafeHashMap (S+B) UnsafeHashMap (B) Dictionary (BCL) IsEmpty_x_100k(0)¹ 0.342ms (0.4x) \uD83D\uDFE0 0.111ms (1.1x) 0.133ms (0.9x) 0.221ms (0.5x) 0.105ms (1.1x) \uD83D\uDFE2 0.106ms (1.1x) 0.120ms (1.0x) IsEmpty_x_100k(100)¹ 0.342ms (0.4x) \uD83D\uDFE0 0.112ms (1.1x) 0.133ms (0.9x) 0.221ms (0.5x) 0.106ms (1.1x) 0.106ms (1.1x) \uD83D\uDFE2 0.120ms (1.0x) Count_x_100k(0)¹ 0.261ms (0.5x) \uD83D\uDFE0 0.142ms (0.8x) 0.108ms (1.1x) \uD83D\uDFE2 0.120ms (1.0x) 0.111ms (1.1x) 0.111ms (1.1x) 0.120ms (1.0x) Count_x_100k(100)¹ 0.261ms (0.5x) \uD83D\uDFE0 0.142ms (0.8x) 0.111ms (1.1x) \uD83D\uDFE2 0.120ms (1.0x) 0.111ms (1.1x) 0.111ms (1.1x) 0.120ms (1.0x) ToNativeArrayKeys(10000) 0.151ms (0.1x) 0.126ms (0.1x) 0.092ms (0.2x) 0.159ms (0.1x) \uD83D\uDFE0 0.125ms (0.1x) 0.083ms (0.2x) 0.018ms (1.0x) \uD83D\uDFE2 ToNativeArrayKeys(100000) 1.659ms (0.1x) \uD83D\uDFE0 1.214ms (0.1x) 0.918ms (0.2x) 1.610ms (0.1x) 1.205ms (0.1x) 0.908ms (0.2x) 0.174ms (1.0x) \uD83D\uDFE2 ToNativeArrayKeys(1000000) 21.689ms (0.1x) \uD83D\uDFE0 13.624ms (0.2x) 10.721ms (0.2x) 19.842ms (0.1x) 13.505ms (0.2x) 10.569ms (0.2x) 2.059ms (1.0x) \uD83D\uDFE2 ToNativeArrayValues(10000) 0.160ms (0.1x) 0.118ms (0.2x) 0.086ms (0.2x) 0.161ms (0.1x) \uD83D\uDFE0 0.125ms (0.1x) 0.084ms (0.2x) 0.018ms (1.0x) \uD83D\uDFE2 ToNativeArrayValues(100000) 1.702ms (0.1x) 1.192ms (0.1x) 0.935ms (0.2x) 1.721ms (0.1x) \uD83D\uDFE0 1.196ms (0.1x) 0.919ms (0.2x) 0.173ms (1.0x) \uD83D\uDFE2 ToNativeArrayValues(1000000) 20.402ms (0.1x) 13.609ms (0.1x) 11.017ms (0.2x) 20.556ms (0.1x) \uD83D\uDFE0 13.773ms (0.1x) 10.869ms (0.2x) 2.018ms (1.0x) \uD83D\uDFE2 Insert(10000) 0.135ms (1.3x) 0.070ms (2.5x) 0.061ms (2.9x) 0.120ms (1.5x) 0.060ms (2.9x) \uD83D\uDFE2 0.061ms (2.9x) 0.175ms (1.0x) \uD83D\uDFE0 Insert(100000) 1.723ms (1.3x) 0.996ms (2.2x) 0.914ms (2.4x) 1.565ms (1.4x) 0.909ms (2.4x) 0.889ms (2.5x) \uD83D\uDFE2 2.209ms (1.0x) \uD83D\uDFE0 Insert(1000000) 33.017ms (0.9x) 21.056ms (1.4x) 19.847ms (1.5x) 50.228ms (0.6x) \uD83D\uDFE0 19.654ms (1.5x) 19.613ms (1.5x) \uD83D\uDFE2 29.738ms (1.0x) AddGrow(4, 1048576)³ 137.459ms (0.4x) \uD83D\uDFE0 81.364ms (0.6x) 77.039ms (0.6x) 133.603ms (0.4x) 78.458ms (0.6x) 76.533ms (0.6x) 49.222ms (1.0x) \uD83D\uDFE2 AddGrow(65536, 1048576)³ 140.883ms (0.4x) \uD83D\uDFE0 82.611ms (0.6x) 77.670ms (0.6x) 134.717ms (0.4x) 79.913ms (0.6x) 77.316ms (0.6x) 50.215ms (1.0x) \uD83D\uDFE2 Contains(10000) 0.089ms (2.1x) 0.036ms (5.1x) 0.027ms (6.8x) 0.101ms (1.9x) 0.029ms (6.4x) 0.025ms (7.4x) \uD83D\uDFE2 0.188ms (1.0x) \uD83D\uDFE0 Contains(100000) 1.696ms (1.7x) 0.694ms (4.1x) 0.508ms (5.6x) 1.945ms (1.5x) 0.538ms (5.3x) 0.482ms (5.9x) \uD83D\uDFE2 2.843ms (1.0x) \uD83D\uDFE0 Contains(1000000) 42.805ms (1.5x) 17.135ms (3.6x) 12.633ms (4.9x) 43.284ms (1.4x) 12.700ms (4.9x) 11.703ms (5.3x) \uD83D\uDFE2 62.072ms (1.0x) \uD83D\uDFE0 IndexedRead(10000) 0.109ms (1.7x) 0.028ms (6.7x) 0.032ms (5.9x) 0.122ms (1.6x) 0.027ms (7.1x) 0.026ms (7.1x) \uD83D\uDFE2 0.189ms (1.0x) \uD83D\uDFE0 IndexedRead(100000) 1.983ms (1.4x) 0.592ms (4.7x) 0.614ms (4.5x) 2.125ms (1.3x) 0.543ms (5.1x) \uD83D\uDFE2 0.545ms (5.1x) 2.791ms (1.0x) \uD83D\uDFE0 IndexedRead(1000000) 57.739ms (1.1x) 16.881ms (3.7x) 16.937ms (3.7x) 57.860ms (1.1x) 14.918ms (4.1x) \uD83D\uDFE2 15.113ms (4.1x) 61.850ms (1.0x) \uD83D\uDFE0 IndexedWrite(10000) 0.103ms (2.0x) 0.080ms (2.6x) 0.040ms (5.2x) 0.084ms (2.5x) 0.039ms (5.3x) 0.036ms (5.8x) \uD83D\uDFE2 0.209ms (1.0x) \uD83D\uDFE0 IndexedWrite(100000) 1.890ms (1.6x) 1.269ms (2.4x) 0.755ms (4.1x) 1.473ms (2.1x) 0.759ms (4.1x) 0.707ms (4.3x) \uD83D\uDFE2 3.074ms (1.0x) \uD83D\uDFE0 IndexedWrite(1000000) 73.370ms (1.0x) 69.054ms (1.1x) 65.695ms (1.1x) \uD83D\uDFE2 73.500ms (1.0x) 65.870ms (1.1x) 66.574ms (1.1x) 73.729ms (1.0x) \uD83D\uDFE0 TryGetValue(10000) 0.105ms (1.8x) 0.033ms (5.7x) 0.032ms (5.9x) 0.120ms (1.6x) 0.029ms (6.6x) \uD83D\uDFE2 0.029ms (6.6x) \uD83D\uDFE2 0.191ms (1.0x) \uD83D\uDFE0 TryGetValue(100000) 1.943ms (1.4x) 0.645ms (4.4x) 0.637ms (4.4x) 2.102ms (1.3x) 0.574ms (4.9x) 0.557ms (5.1x) \uD83D\uDFE2 2.816ms (1.0x) \uD83D\uDFE0 TryGetValue(1000000) 55.056ms (1.1x) 18.084ms (3.4x) 17.878ms (3.5x) 59.138ms (1.0x) 15.889ms (3.9x) 15.692ms (4.0x) \uD83D\uDFE2 62.067ms (1.0x) \uD83D\uDFE0 Remove(10000) 0.110ms (1.4x) 0.044ms (3.6x) 0.035ms (4.5x) 0.094ms (1.7x) 0.029ms (5.4x) 0.028ms (5.6x) \uD83D\uDFE2 0.158ms (1.0x) \uD83D\uDFE0 Remove(100000) 1.889ms (1.3x) 0.844ms (2.8x) 0.661ms (3.6x) 3.654ms (0.7x) \uD83D\uDFE0 0.566ms (4.2x) 0.547ms (4.4x) \uD83D\uDFE2 2.395ms (1.0x) Remove(1000000) 62.623ms (1.0x) 56.372ms (1.1x) 53.877ms (1.2x) \uD83D\uDFE2 61.104ms (1.0x) 54.841ms (1.1x) 55.805ms (1.1x) 62.915ms (1.0x) \uD83D\uDFE0 Foreach(10000) 0.150ms (0.3x) \uD83D\uDFE0 0.083ms (0.5x) 0.077ms (0.5x) 0.141ms (0.3x) 0.077ms (0.5x) 0.079ms (0.5x) 0.041ms (1.0x) \uD83D\uDFE2 Foreach(100000) 1.984ms (0.2x) \uD83D\uDFE0 0.924ms (0.4x) 0.866ms (0.5x) 1.869ms (0.2x) 0.865ms (0.5x) 0.885ms (0.5x) 0.412ms (1.0x) \uD83D\uDFE2 Foreach(1000000) 27.605ms (0.2x) \uD83D\uDFE0 10.947ms (0.4x) 10.421ms (0.4x) 26.351ms (0.2x) 10.457ms (0.4x) 10.619ms (0.4x) 4.359ms (1.0x) \uD83D\uDFE2 ¹ Optimizations were disabled to perform this benchmark ³ AddGrow(capacity, growTo) -- Incrementally grows from capacity until reaching size of growTo HashSet Functionality NativeHashSet (S) NativeHashSet (S+B) NativeHashSet (B) UnsafeHashSet (S) UnsafeHashSet (S+B) UnsafeHashSet (B) HashSet (BCL) IsEmpty_x_100k(0)¹ 0.342ms (0.4x) \uD83D\uDFE0 0.112ms (1.3x) 0.133ms (1.1x) 0.221ms (0.6x) 0.106ms (1.3x) \uD83D\uDFE2 0.106ms (1.3x) 0.140ms (1.0x) IsEmpty_x_100k(100)¹ 0.342ms (0.4x) \uD83D\uDFE0 0.112ms (1.3x) 0.133ms (1.1x) 0.221ms (0.6x) 0.106ms (1.3x) 0.106ms (1.3x) \uD83D\uDFE2 0.140ms (1.0x) Count_x_100k(0)¹ 0.261ms (0.5x) \uD83D\uDFE0 0.143ms (1.0x) 0.111ms (1.3x) 0.100ms (1.4x) \uD83D\uDFE2 0.111ms (1.3x) 0.108ms (1.3x) 0.140ms (1.0x) Count_x_100k(100)¹ 0.261ms (0.5x) \uD83D\uDFE0 0.142ms (1.0x) 0.111ms (1.3x) 0.100ms (1.4x) \uD83D\uDFE2 0.111ms (1.3x) 0.111ms (1.3x) 0.140ms (1.0x) ToNativeArray(10000) 0.043ms (0.4x) \uD83D\uDFE0 0.015ms (1.2x) 0.009ms (1.9x) 0.043ms (0.4x) 0.015ms (1.2x) 0.009ms (1.9x) \uD83D\uDFE2 0.018ms (1.0x) ToNativeArray(100000) 0.475ms (0.4x) 0.144ms (1.2x) 0.085ms (2.1x) \uD83D\uDFE2 0.485ms (0.4x) \uD83D\uDFE0 0.144ms (1.2x) 0.085ms (2.1x) \uD83D\uDFE2 0.176ms (1.0x) ToNativeArray(1000000) 4.935ms (0.4x) 1.591ms (1.2x) 0.989ms (1.9x) \uD83D\uDFE2 5.378ms (0.4x) \uD83D\uDFE0 1.586ms (1.2x) 0.997ms (1.9x) 1.927ms (1.0x) Insert(10000) 0.093ms (1.1x) 0.044ms (2.3x) 0.040ms (2.6x) 0.078ms (1.3x) 0.039ms (2.6x) 0.035ms (2.9x) \uD83D\uDFE2 0.103ms (1.0x) \uD83D\uDFE0 Insert(100000) 0.937ms (1.1x) 0.441ms (2.3x) 0.403ms (2.6x) 0.785ms (1.3x) 0.390ms (2.6x) 0.351ms (2.9x) \uD83D\uDFE2 1.029ms (1.0x) \uD83D\uDFE0 Insert(1000000) 12.275ms (0.8x) \uD83D\uDFE0 7.030ms (1.5x) 6.650ms (1.6x) \uD83D\uDFE2 10.495ms (1.0x) 6.902ms (1.5x) 6.747ms (1.5x) 10.384ms (1.0x) AddGrow(4, 1048576)³ 76.515ms (0.3x) \uD83D\uDFE0 35.430ms (0.6x) 33.171ms (0.6x) 75.704ms (0.3x) 32.776ms (0.6x) 30.928ms (0.7x) 20.387ms (1.0x) \uD83D\uDFE2 AddGrow(65536, 1048576)³ 75.192ms (0.3x) \uD83D\uDFE0 34.149ms (0.6x) 32.652ms (0.6x) 74.248ms (0.3x) 34.092ms (0.6x) 32.440ms (0.6x) 19.978ms (1.0x) \uD83D\uDFE2 Contains(10000) 0.061ms (1.8x) 0.017ms (6.7x) 0.010ms (11.5x) 0.072ms (1.6x) 0.013ms (8.9x) 0.009ms (12.5x) \uD83D\uDFE2 0.113ms (1.0x) \uD83D\uDFE0 Contains(100000) 0.949ms (1.7x) 0.311ms (5.2x) 0.199ms (8.1x) 1.104ms (1.5x) 0.207ms (7.8x) 0.180ms (8.9x) \uD83D\uDFE2 1.610ms (1.0x) \uD83D\uDFE0 Contains(1000000) 11.436ms (1.7x) 3.877ms (4.9x) 2.576ms (7.4x) 13.252ms (1.4x) 2.653ms (7.2x) 2.373ms (8.0x) \uD83D\uDFE2 19.089ms (1.0x) \uD83D\uDFE0 Remove(10000) 0.111ms (1.7x) 0.054ms (3.4x) 0.044ms (4.3x) 0.101ms (1.8x) 0.036ms (5.2x) \uD83D\uDFE2 0.040ms (4.6x) 0.186ms (1.0x) \uD83D\uDFE0 Remove(100000) 1.327ms (1.6x) 0.645ms (3.2x) 0.531ms (3.9x) 1.218ms (1.7x) 0.438ms (4.7x) \uD83D\uDFE2 0.477ms (4.4x) 2.076ms (1.0x) \uD83D\uDFE0 Remove(1000000) 15.132ms (1.5x) 7.264ms (3.2x) 5.953ms (3.9x) 26.197ms (0.9x) \uD83D\uDFE0 4.917ms (4.7x) \uD83D\uDFE2 5.268ms (4.4x) 23.150ms (1.0x) Foreach(10000) 0.081ms (0.4x) \uD83D\uDFE0 0.029ms (1.2x) 0.016ms (2.3x) \uD83D\uDFE2 0.054ms (0.7x) 0.017ms (2.2x) 0.017ms (2.2x) 0.036ms (1.0x) Foreach(100000) 0.766ms (0.5x) \uD83D\uDFE0 0.241ms (1.5x) 0.135ms (2.6x) \uD83D\uDFE2 0.505ms (0.7x) 0.145ms (2.5x) 0.145ms (2.5x) 0.356ms (1.0x) Foreach(1000000) 7.540ms (0.5x) \uD83D\uDFE0 2.280ms (1.6x) 1.431ms (2.5x) \uD83D\uDFE2 4.906ms (0.7x) 1.524ms (2.4x) 1.516ms (2.4x) 3.638ms (1.0x) UnionWith(10000) 0.226ms (1.1x) 0.144ms (1.8x) 0.128ms (2.0x) 0.191ms (1.3x) 0.119ms (2.1x) 0.116ms (2.2x) \uD83D\uDFE2 0.254ms (1.0x) \uD83D\uDFE0 UnionWith(100000) 2.545ms (1.4x) 1.664ms (2.1x) 1.486ms (2.3x) 2.140ms (1.6x) 1.370ms (2.5x) 1.349ms (2.6x) \uD83D\uDFE2 3.441ms (1.0x) \uD83D\uDFE0 UnionWith(1000000) 80.802ms (0.7x) \uD83D\uDFE0 43.823ms (1.4x) 39.187ms (1.5x) \uD83D\uDFE2 74.811ms (0.8x) 45.527ms (1.3x) 40.115ms (1.5x) 59.785ms (1.0x) IntersectWith(10000) 0.246ms (1.1x) 0.142ms (1.9x) 0.123ms (2.2x) 0.201ms (1.3x) 0.107ms (2.5x) 0.105ms (2.6x) \uD83D\uDFE2 0.270ms (1.0x) \uD83D\uDFE0 IntersectWith(100000) 2.705ms (1.3x) 1.546ms (2.2x) 1.405ms (2.4x) 2.218ms (1.5x) 1.189ms (2.9x) \uD83D\uDFE2 1.231ms (2.8x) 3.436ms (1.0x) \uD83D\uDFE0 IntersectWith(1000000) 33.228ms (2.0x) 19.026ms (3.4x) 17.066ms (3.8x) 27.030ms (2.4x) 14.937ms (4.4x) \uD83D\uDFE2 15.096ms (4.3x) 65.055ms (1.0x) \uD83D\uDFE0 ExceptWith(10000) 0.212ms (1.0x) 0.125ms (1.7x) 0.107ms (2.0x) 0.175ms (1.3x) 0.094ms (2.3x) 0.093ms (2.4x) \uD83D\uDFE2 0.218ms (1.0x) \uD83D\uDFE0 ExceptWith(100000) 2.374ms (1.2x) 1.419ms (2.0x) 1.257ms (2.2x) 1.992ms (1.4x) 1.109ms (2.5x) \uD83D\uDFE2 1.110ms (2.5x) 2.799ms (1.0x) \uD83D\uDFE0 ExceptWith(1000000) 35.627ms (1.1x) 19.482ms (2.0x) 17.001ms (2.3x) 29.688ms (1.3x) 15.493ms (2.6x) \uD83D\uDFE2 15.620ms (2.5x) 39.627ms (1.0x) \uD83D\uDFE0 ¹ Optimizations were disabled to perform this benchmark ³ AddGrow(capacity, growTo) -- Incrementally grows from capacity until reaching size of growTo List Functionality NativeList (S) NativeList (S+B) NativeList (B) UnsafeList (S) UnsafeList (S+B) UnsafeList (B) List (BCL) IsEmpty_x_100k(0)¹ 0.154ms (0.9x) 0.121ms (1.2x) 0.111ms (1.3x) 0.161ms (0.9x) \uD83D\uDFE0 0.106ms (1.3x) \uD83D\uDFE2 0.106ms (1.3x) \uD83D\uDFE2 0.140ms (1.0x) IsEmpty_x_100k(100)¹ 0.154ms (0.9x) 0.121ms (1.2x) 0.111ms (1.3x) 0.161ms (0.9x) \uD83D\uDFE0 0.106ms (1.3x) 0.106ms (1.3x) \uD83D\uDFE2 0.140ms (1.0x) Count_x_100k(0)¹ 0.120ms (1.0x) \uD83D\uDFE0 0.111ms (1.1x) 0.111ms (1.1x) 0.020ms (6.0x) \uD83D\uDFE2 0.081ms (1.5x) 0.108ms (1.1x) 0.120ms (1.0x) Count_x_100k(100)¹ 0.120ms (1.0x) \uD83D\uDFE0 0.111ms (1.1x) 0.111ms (1.1x) 0.020ms (6.0x) \uD83D\uDFE2 0.081ms (1.5x) 0.108ms (1.1x) 0.120ms (1.0x) \uD83D\uDFE0 ToNativeArray(10000) 0.002ms (1.4x) 0.002ms (1.8x) 0.002ms (1.9x) \uD83D\uDFE2 --- --- --- 0.003ms (1.0x) \uD83D\uDFE0 ToNativeArray(100000) 0.088ms (0.3x) \uD83D\uDFE0 0.015ms (1.9x) 0.015ms (2.0x) \uD83D\uDFE2 --- --- --- 0.029ms (1.0x) ToNativeArray(1000000) 0.906ms (0.3x) \uD83D\uDFE0 0.143ms (2.1x) \uD83D\uDFE2 0.148ms (2.1x) --- --- --- 0.306ms (1.0x) Add(10000) 0.040ms (0.4x) \uD83D\uDFE0 0.014ms (1.0x) 0.016ms (0.9x) 0.017ms (0.9x) 0.007ms (2.2x) \uD83D\uDFE2 0.007ms (2.2x) 0.014ms (1.0x) Add(100000) 0.400ms (0.4x) \uD83D\uDFE0 0.140ms (1.0x) 0.155ms (0.9x) 0.166ms (0.9x) 0.061ms (2.3x) \uD83D\uDFE2 0.061ms (2.3x) \uD83D\uDFE2 0.144ms (1.0x) Add(1000000) 4.000ms (0.4x) \uD83D\uDFE0 1.399ms (1.0x) 1.548ms (0.9x) 1.654ms (0.9x) 0.605ms (2.4x) \uD83D\uDFE2 0.608ms (2.4x) 1.436ms (1.0x) AddGrow(4, 1048576)³ 4.647ms (0.5x) \uD83D\uDFE0 1.886ms (1.3x) 1.759ms (1.4x) 2.141ms (1.1x) 1.026ms (2.3x) \uD83D\uDFE2 1.033ms (2.3x) 2.402ms (1.0x) AddGrow(65536, 1048576)³ 4.604ms (0.5x) \uD83D\uDFE0 1.865ms (1.3x) 1.773ms (1.3x) 2.122ms (1.1x) 1.083ms (2.2x) 1.010ms (2.4x) \uD83D\uDFE2 2.381ms (1.0x) Contains(1000) 0.371ms (1.1x) 0.086ms (4.6x) 0.084ms (4.7x) 0.370ms (1.1x) 0.148ms (2.7x) 0.084ms (4.7x) \uD83D\uDFE2 0.394ms (1.0x) \uD83D\uDFE0 Contains(10000) 37.241ms (1.2x) 7.565ms (6.0x) 7.548ms (6.0x) 37.203ms (1.2x) 7.541ms (6.0x) \uD83D\uDFE2 7.544ms (6.0x) 45.509ms (1.0x) \uD83D\uDFE0 IndexedRead(10000) 0.037ms (0.6x) \uD83D\uDFE0 0.009ms (2.7x) 0.005ms (4.8x) 0.022ms (1.0x) 0.005ms (5.0x) \uD83D\uDFE2 0.005ms (4.9x) 0.023ms (1.0x) IndexedRead(100000) 0.474ms (0.7x) \uD83D\uDFE0 0.090ms (3.6x) 0.068ms (4.8x) 0.268ms (1.2x) 0.077ms (4.2x) 0.068ms (4.8x) \uD83D\uDFE2 0.328ms (1.0x) IndexedRead(1000000) 5.416ms (0.7x) \uD83D\uDFE0 1.487ms (2.6x) 1.341ms (2.9x) \uD83D\uDFE2 3.197ms (1.2x) 1.395ms (2.8x) 1.357ms (2.9x) 3.897ms (1.0x) IndexedWrite(10000) 0.028ms (1.0x) 0.011ms (2.6x) 0.007ms (4.4x) 0.018ms (1.6x) 0.006ms (4.6x) \uD83D\uDFE2 0.010ms (3.0x) 0.029ms (1.0x) \uD83D\uDFE0 IndexedWrite(100000) 0.311ms (1.1x) 0.125ms (2.7x) \uD83D\uDFE2 0.135ms (2.5x) 0.220ms (1.5x) 0.136ms (2.4x) 0.132ms (2.5x) 0.331ms (1.0x) \uD83D\uDFE0 IndexedWrite(1000000) 3.656ms (1.1x) 1.892ms (2.1x) 1.868ms (2.1x) 2.775ms (1.4x) 1.796ms (2.2x) 1.744ms (2.3x) \uD83D\uDFE2 3.956ms (1.0x) \uD83D\uDFE0 Remove(1000) 0.087ms (0.3x) \uD83D\uDFE0 0.011ms (1.9x) 0.011ms (2.1x) 0.085ms (0.3x) 0.011ms (2.0x) 0.010ms (2.2x) \uD83D\uDFE2 0.022ms (1.0x) Remove(10000) 7.626ms (0.1x) \uD83D\uDFE0 0.732ms (1.2x) 0.717ms (1.2x) 7.616ms (0.1x) 0.716ms (1.2x) 0.704ms (1.2x) \uD83D\uDFE2 0.853ms (1.0x) Foreach(10000) 0.038ms (0.6x) \uD83D\uDFE0 0.004ms (5.8x) 0.003ms (8.8x) 0.016ms (1.5x) 0.003ms (9.0x) \uD83D\uDFE2 0.003ms (9.0x) \uD83D\uDFE2 0.024ms (1.0x) Foreach(100000) 0.381ms (0.6x) \uD83D\uDFE0 0.037ms (6.5x) 0.024ms (10.0x) 0.160ms (1.5x) 0.024ms (10.0x) \uD83D\uDFE2 0.024ms (10.0x) \uD83D\uDFE2 0.242ms (1.0x) Foreach(1000000) 3.815ms (0.6x) \uD83D\uDFE0 0.360ms (6.7x) 0.229ms (10.6x) 1.621ms (1.5x) 0.226ms (10.7x) \uD83D\uDFE2 0.226ms (10.7x) 2.419ms (1.0x) ¹ Optimizations were disabled to perform this benchmark ³ AddGrow(capacity, growTo) -- Incrementally grows from capacity until reaching size of growTo ParallelHashMap Functionality NativeParallelHashMap (S) NativeParallelHashMap (S+B) NativeParallelHashMap (B) UnsafeParallelHashMap (S) UnsafeParallelHashMap (S+B) UnsafeParallelHashMap (B) ConcurrentDictionary (BCL) IsEmpty_x_100k(1, 0)¹ 0.462ms (176.1x) 0.141ms (577.9x) 0.109ms (748.4x) \uD83D\uDFE2 0.261ms (312.0x) 0.162ms (501.5x) 0.174ms (469.0x) 81.423ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(2, 0)¹˒² 0.234ms (551.2x) 0.072ms (1782.5x) \uD83D\uDFE2 0.090ms (1427.8x) 0.134ms (965.2x) 0.096ms (1338.9x) 0.091ms (1412.9x) 129.140ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(4, 0)¹˒² 0.267ms (644.7x) 0.042ms (4088.3x) \uD83D\uDFE2 0.050ms (3473.0x) 0.078ms (2214.0x) 0.048ms (3604.1x) 0.047ms (3626.9x) 171.914ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(1, 100)¹ 0.682ms (114.0x) 0.238ms (326.4x) 0.242ms (322.0x) 0.582ms (133.7x) 0.181ms (429.8x) 0.181ms (429.9x) \uD83D\uDFE2 77.786ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(2, 100)¹˒² 0.380ms (341.5x) 0.124ms (1046.8x) 0.142ms (911.2x) 0.295ms (440.2x) 0.093ms (1399.5x) \uD83D\uDFE2 0.095ms (1370.0x) 129.804ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(4, 100)¹˒² 0.354ms (490.4x) 0.114ms (1518.7x) 0.125ms (1385.9x) 0.217ms (799.6x) 0.109ms (1596.9x) 0.062ms (2818.0x) \uD83D\uDFE2 173.587ms (1.0x) \uD83D\uDFE0 Count_x_100k(1, 0)¹ 0.535ms (150.8x) 0.201ms (401.0x) 0.155ms (521.9x) \uD83D\uDFE2 0.287ms (280.9x) 0.181ms (445.7x) 0.161ms (501.3x) 80.634ms (1.0x) \uD83D\uDFE0 Count_x_100k(2, 0)¹˒² 0.271ms (455.4x) 0.103ms (1195.2x) 0.080ms (1532.7x) \uD83D\uDFE2 0.148ms (831.5x) 0.093ms (1326.5x) 0.083ms (1491.0x) 123.229ms (1.0x) \uD83D\uDFE0 Count_x_100k(4, 0)¹˒² 0.144ms (1320.5x) 0.061ms (3106.4x) 0.046ms (4132.8x) \uD83D\uDFE2 0.083ms (2294.1x) 0.103ms (1846.0x) 0.051ms (3730.1x) 189.491ms (1.0x) \uD83D\uDFE0 Count_x_100k(1, 100)¹ 3.685ms (25.7x) 1.444ms (65.7x) \uD83D\uDFE2 1.693ms (56.0x) 3.191ms (29.7x) 1.544ms (61.4x) 1.614ms (58.8x) 94.884ms (1.0x) \uD83D\uDFE0 Count_x_100k(2, 100)¹˒² 1.845ms (73.9x) 0.736ms (185.3x) \uD83D\uDFE2 0.887ms (153.8x) 1.595ms (85.5x) 0.773ms (176.6x) 0.825ms (165.4x) 136.423ms (1.0x) \uD83D\uDFE0 Count_x_100k(4, 100)¹˒² 1.613ms (113.9x) 0.708ms (259.3x) 0.707ms (259.9x) 1.460ms (125.8x) 0.746ms (246.2x) 0.689ms (266.5x) \uD83D\uDFE2 183.655ms (1.0x) \uD83D\uDFE0 ToNativeArrayKeys(1, 10000) 0.150ms (1.2x) 0.121ms (1.5x) 0.081ms (2.2x) \uD83D\uDFE2 0.201ms (0.9x) \uD83D\uDFE0 0.129ms (1.4x) 0.111ms (1.6x) 0.180ms (1.0x) ToNativeArrayKeys(1, 100000) 1.652ms (1.4x) 1.243ms (1.9x) 1.052ms (2.2x) \uD83D\uDFE2 1.796ms (1.3x) 1.402ms (1.7x) 1.053ms (2.2x) 2.336ms (1.0x) \uD83D\uDFE0 ToNativeArrayKeys(1, 1000000) 36.653ms (0.7x) \uD83D\uDFE0 17.665ms (1.4x) 12.848ms (2.0x) 36.236ms (0.7x) 18.985ms (1.3x) 10.798ms (2.3x) \uD83D\uDFE2 25.361ms (1.0x) ToNativeArrayValues(1, 10000) 0.150ms (0.9x) 0.121ms (1.2x) 0.080ms (1.8x) 0.151ms (0.9x) \uD83D\uDFE0 0.122ms (1.2x) 0.079ms (1.8x) \uD83D\uDFE2 0.141ms (1.0x) ToNativeArrayValues(1, 100000) 1.626ms (1.1x) 1.235ms (1.4x) 0.862ms (2.1x) \uD83D\uDFE2 1.629ms (1.1x) 1.229ms (1.4x) 0.872ms (2.0x) 1.773ms (1.0x) \uD83D\uDFE0 ToNativeArrayValues(1, 1000000) 20.867ms (1.1x) 15.371ms (1.5x) 11.046ms (2.1x) 24.782ms (1.0x) \uD83D\uDFE0 17.345ms (1.4x) 10.785ms (2.2x) \uD83D\uDFE2 23.593ms (1.0x) Insert(1, 10000) 0.353ms (5.6x) 0.209ms (9.5x) 0.212ms (9.3x) 0.320ms (6.2x) 0.205ms (9.6x) \uD83D\uDFE2 0.211ms (9.4x) 1.979ms (1.0x) \uD83D\uDFE0 Insert(2, 10000)² 0.543ms (4.3x) 0.514ms (4.5x) 0.329ms (7.1x) 0.400ms (5.8x) 0.266ms (8.8x) \uD83D\uDFE2 0.379ms (6.1x) 2.330ms (1.0x) \uD83D\uDFE0 Insert(4, 10000)² 0.449ms (5.2x) 0.290ms (8.0x) 0.217ms (10.6x) \uD83D\uDFE2 0.285ms (8.1x) 0.249ms (9.3x) 0.270ms (8.6x) 2.314ms (1.0x) \uD83D\uDFE0 Insert(1, 100000) 3.818ms (5.8x) 2.325ms (9.5x) 2.281ms (9.6x) 3.442ms (6.4x) 2.218ms (9.9x) \uD83D\uDFE2 2.285ms (9.6x) 21.983ms (1.0x) \uD83D\uDFE0 Insert(2, 100000)² 5.611ms (4.1x) 4.873ms (4.8x) 3.254ms (7.1x) 4.090ms (5.7x) 2.645ms (8.8x) \uD83D\uDFE2 3.080ms (7.5x) 23.181ms (1.0x) \uD83D\uDFE0 Insert(4, 100000)² 4.523ms (5.3x) 2.897ms (8.3x) 2.156ms (11.2x) 3.541ms (6.8x) 2.201ms (11.0x) 2.096ms (11.5x) \uD83D\uDFE2 24.121ms (1.0x) \uD83D\uDFE0 Insert(1, 1000000) 60.383ms (7.0x) 36.007ms (11.8x) \uD83D\uDFE2 36.109ms (11.8x) 53.923ms (7.9x) 36.016ms (11.8x) 36.542ms (11.6x) 425.024ms (1.0x) \uD83D\uDFE0 Insert(2, 1000000)² 62.895ms (7.1x) 50.118ms (8.9x) 40.151ms (11.1x) 50.271ms (8.8x) 39.964ms (11.1x) 38.384ms (11.6x) \uD83D\uDFE2 443.920ms (1.0x) \uD83D\uDFE0 Insert(4, 1000000)² 42.694ms (7.6x) 36.240ms (9.0x) 24.896ms (13.1x) 30.771ms (10.6x) 24.408ms (13.3x) \uD83D\uDFE2 25.097ms (13.0x) 325.595ms (1.0x) \uD83D\uDFE0 AddGrow(1, 4, 1048576)³ 72.547ms (5.9x) 39.816ms (10.7x) 39.313ms (10.8x) 71.458ms (6.0x) 39.813ms (10.7x) 39.265ms (10.8x) \uD83D\uDFE2 425.495ms (1.0x) \uD83D\uDFE0 AddGrow(1, 65536, 1048576)³ 68.046ms (10.0x) 39.004ms (17.5x) 38.764ms (17.6x) 67.198ms (10.2x) 38.417ms (17.8x) \uD83D\uDFE2 38.540ms (17.7x) 683.780ms (1.0x) \uD83D\uDFE0 Contains(1, 10000) 0.145ms (1.6x) 0.033ms (6.9x) 0.028ms (8.0x) \uD83D\uDFE2 0.118ms (1.9x) 0.036ms (6.3x) 0.029ms (7.9x) 0.228ms (1.0x) \uD83D\uDFE0 Contains(2, 10000)² 0.127ms (1.5x) 0.042ms (4.6x) 0.036ms (5.4x) \uD83D\uDFE2 0.111ms (1.8x) 0.038ms (5.2x) 0.036ms (5.3x) 0.194ms (1.0x) \uD83D\uDFE0 Contains(4, 10000)² 0.167ms (1.3x) 0.052ms (4.1x) 0.055ms (3.9x) 0.100ms (2.1x) 0.068ms (3.1x) 0.039ms (5.5x) \uD83D\uDFE2 0.213ms (1.0x) \uD83D\uDFE0 Contains(1, 100000) 2.247ms (1.5x) 0.650ms (5.0x) 0.498ms (6.6x) \uD83D\uDFE2 1.849ms (1.8x) 0.650ms (5.0x) 0.500ms (6.6x) 3.277ms (1.0x) \uD83D\uDFE0 Contains(2, 100000)² 1.226ms (1.4x) 0.403ms (4.4x) 0.328ms (5.4x) \uD83D\uDFE2 1.077ms (1.6x) 0.408ms (4.3x) 0.330ms (5.3x) 1.761ms (1.0x) \uD83D\uDFE0 Contains(4, 100000)² 1.065ms (2.2x) 0.334ms (7.0x) 0.268ms (8.7x) \uD83D\uDFE2 0.883ms (2.6x) 0.319ms (7.3x) 0.540ms (4.3x) 2.332ms (1.0x) \uD83D\uDFE0 Contains(1, 1000000) 66.122ms (1.5x) 16.585ms (5.9x) 12.089ms (8.0x) \uD83D\uDFE2 59.523ms (1.6x) 17.021ms (5.7x) 12.118ms (8.0x) 97.095ms (1.0x) \uD83D\uDFE0 Contains(2, 1000000)² 31.624ms (1.6x) 8.707ms (5.8x) 6.498ms (7.8x) \uD83D\uDFE2 29.568ms (1.7x) 8.714ms (5.8x) 6.511ms (7.8x) 50.806ms (1.0x) \uD83D\uDFE0 Contains(4, 1000000)² 25.406ms (1.7x) 6.925ms (6.3x) 5.677ms (7.7x) 22.636ms (1.9x) 6.716ms (6.5x) 5.494ms (7.9x) \uD83D\uDFE2 43.614ms (1.0x) \uD83D\uDFE0 IndexedRead(1, 10000) 0.145ms (1.6x) 0.029ms (8.1x) \uD83D\uDFE2 0.032ms (7.3x) 0.137ms (1.7x) 0.031ms (7.5x) 0.031ms (7.7x) 0.235ms (1.0x) \uD83D\uDFE0 IndexedRead(2, 10000)² 0.202ms (1.4x) 0.059ms (4.9x) 0.062ms (4.7x) 0.191ms (1.5x) 0.041ms (7.0x) \uD83D\uDFE2 0.066ms (4.4x) 0.288ms (1.0x) \uD83D\uDFE0 IndexedRead(4, 10000)² 0.581ms (0.9x) \uD83D\uDFE0 0.129ms (3.9x) 0.098ms (5.1x) 0.264ms (1.9x) 0.071ms (7.1x) \uD83D\uDFE2 0.097ms (5.2x) 0.501ms (1.0x) IndexedRead(1, 100000) 2.216ms (1.5x) 0.592ms (5.6x) \uD83D\uDFE2 0.604ms (5.5x) 2.140ms (1.5x) 0.600ms (5.5x) 0.607ms (5.4x) 3.291ms (1.0x) \uD83D\uDFE0 IndexedRead(2, 100000)² 2.416ms (1.5x) 0.698ms (5.0x) 0.692ms (5.1x) \uD83D\uDFE2 2.270ms (1.5x) 0.707ms (5.0x) 0.743ms (4.7x) 3.506ms (1.0x) \uD83D\uDFE0 IndexedRead(4, 100000)² 4.094ms (1.4x) 1.071ms (5.4x) 1.053ms (5.5x) \uD83D\uDFE2 7.214ms (0.8x) \uD83D\uDFE0 1.058ms (5.5x) 1.794ms (3.2x) 5.780ms (1.0x) IndexedRead(1, 1000000) 64.603ms (1.5x) 17.636ms (5.5x) 17.726ms (5.5x) 62.234ms (1.6x) 17.652ms (5.5x) 17.411ms (5.6x) \uD83D\uDFE2 96.983ms (1.0x) \uD83D\uDFE0 IndexedRead(2, 1000000)² 63.460ms (1.6x) 17.217ms (5.8x) 17.124ms (5.8x) 61.578ms (1.6x) 17.127ms (5.8x) 16.957ms (5.8x) \uD83D\uDFE2 99.146ms (1.0x) \uD83D\uDFE0 IndexedRead(4, 1000000)² 68.243ms (1.4x) 28.318ms (3.4x) 27.812ms (3.5x) 69.192ms (1.4x) 26.990ms (3.6x) \uD83D\uDFE2 27.918ms (3.5x) 97.383ms (1.0x) \uD83D\uDFE0 IndexedWrite(1, 10000) 0.164ms (2.8x) 0.051ms (9.0x) 0.041ms (11.0x) 0.131ms (3.5x) 0.040ms (11.4x) 0.038ms (12.0x) \uD83D\uDFE2 0.456ms (1.0x) \uD83D\uDFE0 IndexedWrite(1, 100000) 2.333ms (2.6x) 0.901ms (6.7x) 0.731ms (8.3x) 2.077ms (2.9x) 0.781ms (7.8x) 0.710ms (8.5x) \uD83D\uDFE2 6.067ms (1.0x) \uD83D\uDFE0 IndexedWrite(1, 1000000) 76.627ms (2.5x) 67.296ms (2.8x) \uD83D\uDFE2 68.052ms (2.8x) 85.977ms (2.2x) 68.516ms (2.8x) 69.221ms (2.8x) 191.108ms (1.0x) \uD83D\uDFE0 TryGetValue(1, 10000) 0.154ms (1.3x) 0.043ms (4.8x) 0.032ms (6.4x) 0.117ms (1.8x) 0.043ms (4.8x) 0.031ms (6.6x) \uD83D\uDFE2 0.206ms (1.0x) \uD83D\uDFE0 TryGetValue(2, 10000)² 0.125ms (1.4x) 0.045ms (3.8x) 0.036ms (4.8x) \uD83D\uDFE2 0.110ms (1.6x) 0.046ms (3.7x) 0.036ms (4.8x) 0.172ms (1.0x) \uD83D\uDFE0 TryGetValue(4, 10000)² 0.170ms (0.7x) \uD83D\uDFE0 0.051ms (2.4x) 0.038ms (3.3x) \uD83D\uDFE2 0.103ms (1.2x) 0.078ms (1.6x) 0.039ms (3.2x) 0.125ms (1.0x) TryGetValue(1, 100000) 2.187ms (1.5x) 0.839ms (4.0x) 0.616ms (5.4x) \uD83D\uDFE2 1.925ms (1.7x) 0.815ms (4.1x) 0.628ms (5.3x) 3.336ms (1.0x) \uD83D\uDFE0 TryGetValue(2, 100000)² 1.216ms (1.5x) 0.478ms (3.7x) 0.342ms (5.2x) \uD83D\uDFE2 1.072ms (1.7x) 0.489ms (3.6x) 0.391ms (4.5x) 1.769ms (1.0x) \uD83D\uDFE0 TryGetValue(4, 100000)² 1.042ms (1.7x) 0.408ms (4.3x) \uD83D\uDFE2 0.617ms (2.8x) 0.899ms (1.9x) 0.915ms (1.9x) 0.636ms (2.7x) 1.736ms (1.0x) \uD83D\uDFE0 TryGetValue(1, 1000000) 65.145ms (1.5x) 25.321ms (3.8x) 19.163ms (5.0x) 59.895ms (1.6x) 23.602ms (4.1x) 18.464ms (5.2x) \uD83D\uDFE2 96.395ms (1.0x) \uD83D\uDFE0 TryGetValue(2, 1000000)² 31.724ms (1.5x) 12.422ms (4.0x) 9.631ms (5.1x) 30.638ms (1.6x) 12.432ms (4.0x) 9.589ms (5.1x) \uD83D\uDFE2 49.107ms (1.0x) \uD83D\uDFE0 TryGetValue(4, 1000000)² 25.831ms (1.6x) 10.070ms (4.1x) 7.992ms (5.2x) \uD83D\uDFE2 23.710ms (1.8x) 10.235ms (4.1x) 8.062ms (5.2x) 41.691ms (1.0x) \uD83D\uDFE0 Remove(1, 10000) 0.120ms (4.5x) 0.214ms (2.5x) 0.050ms (11.0x) 0.095ms (5.7x) 0.050ms (10.9x) 0.049ms (11.1x) \uD83D\uDFE2 0.545ms (1.0x) \uD83D\uDFE0 Remove(1, 100000) 1.928ms (3.4x) 0.929ms (7.0x) 0.805ms (8.1x) 1.682ms (3.9x) 0.867ms (7.5x) 0.793ms (8.2x) \uD83D\uDFE2 6.512ms (1.0x) \uD83D\uDFE0 Remove(1, 1000000) 64.353ms (3.1x) 56.893ms (3.5x) \uD83D\uDFE2 57.422ms (3.4x) 62.480ms (3.1x) 57.884ms (3.4x) 57.271ms (3.4x) 196.582ms (1.0x) \uD83D\uDFE0 Foreach(1, 10000) 0.156ms (2.5x) 0.086ms (4.6x) 0.073ms (5.4x) \uD83D\uDFE2 0.143ms (2.7x) 0.080ms (4.9x) 0.080ms (4.9x) 0.393ms (1.0x) \uD83D\uDFE0 Foreach(1, 100000) 2.094ms (2.3x) 0.931ms (5.2x) 0.839ms (5.8x) \uD83D\uDFE2 1.862ms (2.6x) 0.885ms (5.5x) 0.884ms (5.5x) 4.876ms (1.0x) \uD83D\uDFE0 Foreach(1, 1000000) 28.544ms (2.0x) 11.060ms (5.1x) 10.143ms (5.6x) \uD83D\uDFE2 27.167ms (2.1x) 10.318ms (5.5x) 10.364ms (5.5x) 56.852ms (1.0x) \uD83D\uDFE0 ¹ Optimizations were disabled to perform this benchmark ² Benchmark run on parallel job workers - results may vary ³ AddGrow(workers, capacity, growTo) -- Incrementally grows from capacity until reaching size of growTo ParallelHashSet Functionality NativeParallelHashSet (S) NativeParallelHashSet (S+B) NativeParallelHashSet (B) UnsafeParallelHashSet (S) UnsafeParallelHashSet (S+B) UnsafeParallelHashSet (B) HashSet w/lock (BCL) IsEmpty_x_100k(1, 0)¹ 0.482ms (9.2x) 0.115ms (38.5x) \uD83D\uDFE2 0.176ms (25.1x) 0.301ms (14.7x) 0.183ms (24.2x) 0.171ms (25.8x) 4.422ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(2, 0)¹˒² 0.244ms (61.6x) 0.060ms (250.7x) \uD83D\uDFE2 0.092ms (164.2x) 0.154ms (98.0x) 0.091ms (166.2x) 0.086ms (175.3x) 15.041ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(4, 0)¹˒² 0.274ms (114.9x) 0.037ms (849.5x) \uD83D\uDFE2 0.048ms (659.1x) 0.153ms (206.3x) 0.049ms (640.4x) 0.047ms (667.5x) 31.474ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(1, 100)¹ 0.567ms (7.8x) 0.128ms (34.7x) 0.201ms (22.0x) 0.401ms (11.0x) 0.142ms (31.2x) 0.108ms (40.9x) \uD83D\uDFE2 4.424ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(2, 100)¹˒² 0.288ms (52.5x) 0.068ms (221.0x) 0.105ms (143.5x) 0.217ms (69.9x) 0.074ms (205.5x) 0.057ms (264.5x) \uD83D\uDFE2 15.128ms (1.0x) \uD83D\uDFE0 IsEmpty_x_100k(4, 100)¹˒² 0.315ms (99.6x) 0.072ms (437.6x) 0.058ms (538.5x) 0.185ms (169.8x) 0.046ms (686.0x) 0.037ms (842.3x) \uD83D\uDFE2 31.420ms (1.0x) \uD83D\uDFE0 Count_x_100k(1, 0)¹ 0.535ms (8.3x) 0.201ms (22.1x) 0.161ms (27.6x) 0.456ms (9.7x) 0.181ms (24.5x) 0.161ms (27.6x) \uD83D\uDFE2 4.435ms (1.0x) \uD83D\uDFE0 Count_x_100k(2, 0)¹˒² 0.271ms (59.0x) 0.103ms (155.8x) 0.082ms (193.8x) \uD83D\uDFE2 0.231ms (69.1x) 0.093ms (171.9x) 0.083ms (192.9x) 15.965ms (1.0x) \uD83D\uDFE0 Count_x_100k(4, 0)¹˒² 0.224ms (173.7x) 0.115ms (337.8x) 0.049ms (789.8x) \uD83D\uDFE2 0.164ms (237.0x) 0.054ms (724.3x) 0.073ms (529.1x) 38.861ms (1.0x) \uD83D\uDFE0 Count_x_100k(1, 100)¹ 4.426ms (1.0x) 1.620ms (2.7x) 1.517ms (2.9x) \uD83D\uDFE2 3.323ms (1.3x) 1.538ms (2.9x) 2.268ms (2.0x) 4.438ms (1.0x) \uD83D\uDFE0 Count_x_100k(2, 100)¹˒² 2.462ms (6.2x) 1.020ms (14.9x) 0.763ms (19.9x) \uD83D\uDFE2 1.683ms (9.0x) 0.783ms (19.4x) 0.824ms (18.4x) 15.206ms (1.0x) \uD83D\uDFE0 Count_x_100k(4, 100)¹˒² 1.778ms (18.1x) 0.848ms (37.9x) 0.723ms (44.5x) 1.556ms (20.7x) 0.744ms (43.2x) 0.665ms (48.4x) \uD83D\uDFE2 32.165ms (1.0x) \uD83D\uDFE0 ToNativeArray(1, 10000) 0.039ms (0.5x) \uD83D\uDFE0 0.021ms (0.8x) 0.009ms (1.9x) 0.038ms (0.5x) 0.021ms (0.8x) 0.009ms (1.9x) \uD83D\uDFE2 0.018ms (1.0x) ToNativeArray(1, 100000) 0.428ms (0.4x) 0.202ms (0.9x) 0.084ms (2.1x) \uD83D\uDFE2 0.437ms (0.4x) \uD83D\uDFE0 0.202ms (0.9x) 0.084ms (2.1x) \uD83D\uDFE2 0.175ms (1.0x) ToNativeArray(1, 1000000) 4.489ms (0.4x) 2.192ms (0.9x) 1.051ms (1.9x) \uD83D\uDFE2 4.690ms (0.4x) \uD83D\uDFE0 2.187ms (0.9x) 1.053ms (1.9x) 1.964ms (1.0x) Insert(1, 10000) 0.330ms (11.3x) 0.188ms (19.7x) 0.196ms (19.0x) 0.301ms (12.4x) 0.186ms (20.0x) \uD83D\uDFE2 0.202ms (18.4x) 3.715ms (1.0x) \uD83D\uDFE0 Insert(2, 10000)² 0.468ms (33.2x) 0.487ms (31.9x) 0.264ms (58.9x) 0.317ms (49.0x) 0.260ms (59.8x) \uD83D\uDFE2 0.331ms (47.0x) 15.537ms (1.0x) \uD83D\uDFE0 Insert(4, 10000)² 0.285ms (168.3x) 0.319ms (150.7x) 0.169ms (283.9x) \uD83D\uDFE2 0.244ms (196.6x) 0.207ms (231.4x) 0.225ms (212.9x) 48.000ms (1.0x) \uD83D\uDFE0 Insert(1, 100000) 3.300ms (1.8x) 1.880ms (3.1x) 1.957ms (3.0x) 3.014ms (1.9x) 1.857ms (3.2x) \uD83D\uDFE2 2.079ms (2.8x) 5.872ms (1.0x) \uD83D\uDFE0 Insert(2, 100000)² 4.849ms (3.2x) 4.541ms (3.4x) 2.555ms (6.1x) \uD83D\uDFE2 3.014ms (5.1x) 3.288ms (4.7x) 3.275ms (4.7x) 15.510ms (1.0x) \uD83D\uDFE0 Insert(4, 100000)² 2.759ms (16.9x) 2.462ms (19.0x) 1.494ms (31.3x) \uD83D\uDFE2 2.236ms (20.9x) 2.221ms (21.0x) 1.804ms (25.9x) 46.684ms (1.0x) \uD83D\uDFE0 Insert(1, 1000000) 33.989ms (1.8x) 19.882ms (3.1x) 20.803ms (3.0x) 31.233ms (2.0x) 19.637ms (3.1x) \uD83D\uDFE2 20.789ms (3.0x) 61.451ms (1.0x) \uD83D\uDFE0 Insert(2, 1000000)² 48.854ms (1.4x) 46.969ms (1.5x) 27.594ms (2.5x) \uD83D\uDFE2 31.891ms (2.2x) 33.639ms (2.1x) 35.067ms (2.0x) 70.068ms (1.0x) \uD83D\uDFE0 Insert(4, 1000000)² 32.946ms (2.8x) 28.736ms (3.2x) 18.753ms (4.9x) \uD83D\uDFE2 21.186ms (4.3x) 24.702ms (3.7x) 21.382ms (4.3x) 91.349ms (1.0x) \uD83D\uDFE0 AddGrow(1, 4, 1048576)³ 36.009ms (1.8x) 12.228ms (5.4x) 11.699ms (5.6x) \uD83D\uDFE2 34.592ms (1.9x) 11.898ms (5.5x) 11.875ms (5.6x) 65.912ms (1.0x) \uD83D\uDFE0 AddGrow(1, 65536, 1048576)³ 33.973ms (1.7x) 11.863ms (4.9x) 11.247ms (5.2x) 32.550ms (1.8x) 11.464ms (5.1x) 11.203ms (5.2x) \uD83D\uDFE2 58.064ms (1.0x) \uD83D\uDFE0 Contains(1, 10000) 0.109ms (5.6x) 0.019ms (32.3x) 0.013ms (47.2x) 0.095ms (6.4x) 0.017ms (35.8x) 0.010ms (60.2x) \uD83D\uDFE2 0.611ms (1.0x) \uD83D\uDFE0 Contains(2, 10000)² 0.101ms (141.6x) 0.019ms (749.5x) \uD83D\uDFE2 0.021ms (683.2x) 0.060ms (239.8x) 0.019ms (747.6x) 0.021ms (683.2x) 14.279ms (1.0x) \uD83D\uDFE0 Contains(4, 10000)² 0.098ms (128.3x) 0.031ms (402.6x) 0.023ms (559.2x) 0.057ms (219.8x) 0.021ms (607.8x) \uD83D\uDFE2 0.022ms (561.7x) 12.582ms (1.0x) \uD83D\uDFE0 Contains(1, 100000) 1.531ms (4.6x) 0.284ms (24.8x) 0.191ms (36.8x) 1.345ms (5.2x) 0.300ms (23.5x) 0.191ms (36.9x) \uD83D\uDFE2 7.043ms (1.0x) \uD83D\uDFE0 Contains(2, 100000)² 0.925ms (23.2x) 0.225ms (95.8x) 0.165ms (130.4x) \uD83D\uDFE2 0.827ms (26.0x) 0.227ms (94.7x) 0.166ms (129.7x) 21.506ms (1.0x) \uD83D\uDFE0 Contains(4, 100000)² 0.717ms (46.9x) 0.204ms (164.7x) 0.120ms (279.4x) \uD83D\uDFE2 0.689ms (48.8x) 0.389ms (86.5x) 0.275ms (122.2x) 33.617ms (1.0x) \uD83D\uDFE0 Contains(1, 1000000) 18.170ms (4.5x) 3.754ms (21.7x) 2.522ms (32.4x) 16.496ms (4.9x) 3.749ms (21.8x) 2.491ms (32.8x) \uD83D\uDFE2 81.628ms (1.0x) \uD83D\uDFE0 Contains(2, 1000000)² 11.131ms (7.8x) 2.652ms (32.7x) 2.045ms (42.5x) \uD83D\uDFE2 9.589ms (9.1x) 2.733ms (31.8x) 2.076ms (41.8x) 86.828ms (1.0x) \uD83D\uDFE0 Contains(4, 1000000)² 8.584ms (12.8x) 3.407ms (32.3x) 2.220ms (49.5x) 8.219ms (13.4x) 2.053ms (53.5x) \uD83D\uDFE2 2.324ms (47.3x) 109.936ms (1.0x) \uD83D\uDFE0 Remove(1, 10000) 0.139ms (4.4x) 0.065ms (9.3x) 0.059ms (10.3x) \uD83D\uDFE2 0.110ms (5.6x) 0.061ms (10.0x) 0.060ms (10.2x) 0.611ms (1.0x) \uD83D\uDFE0 Remove(1, 100000) 1.694ms (3.9x) 0.798ms (8.4x) 0.689ms (9.7x) \uD83D\uDFE2 1.314ms (5.1x) 0.707ms (9.5x) 0.695ms (9.6x) 6.684ms (1.0x) \uD83D\uDFE0 Remove(1, 1000000) 20.302ms (3.7x) 9.389ms (8.0x) 7.772ms (9.7x) \uD83D\uDFE2 15.004ms (5.0x) 8.087ms (9.3x) 7.788ms (9.6x) 75.082ms (1.0x) \uD83D\uDFE0 Foreach(1, 10000) 0.097ms (0.4x) \uD83D\uDFE0 0.024ms (1.4x) 0.018ms (1.9x) 0.068ms (0.5x) 0.018ms (2.0x) \uD83D\uDFE2 0.018ms (2.0x) 0.035ms (1.0x) Foreach(1, 100000) 0.929ms (0.4x) \uD83D\uDFE0 0.208ms (1.7x) 0.145ms (2.4x) 0.605ms (0.6x) 0.144ms (2.4x) \uD83D\uDFE2 0.144ms (2.4x) 0.344ms (1.0x) Foreach(1, 1000000) 9.214ms (0.4x) \uD83D\uDFE0 2.094ms (1.7x) 1.470ms (2.5x) 5.994ms (0.6x) 1.462ms (2.5x) \uD83D\uDFE2 1.491ms (2.4x) 3.611ms (1.0x) UnionWith(1, 10000) 0.539ms (0.4x) \uD83D\uDFE0 0.227ms (1.1x) 0.216ms (1.1x) 0.490ms (0.5x) 0.214ms (1.1x) \uD83D\uDFE2 0.214ms (1.1x) 0.242ms (1.0x) UnionWith(1, 100000) 5.532ms (0.5x) \uD83D\uDFE0 2.397ms (1.1x) 2.465ms (1.1x) 4.955ms (0.5x) 2.263ms (1.2x) 2.242ms (1.2x) \uD83D\uDFE2 2.687ms (1.0x) UnionWith(1, 1000000) 79.156ms (0.6x) \uD83D\uDFE0 41.627ms (1.2x) 36.230ms (1.4x) 72.721ms (0.7x) 36.150ms (1.4x) \uD83D\uDFE2 36.708ms (1.3x) 48.928ms (1.0x) IntersectWith(1, 10000) 0.318ms (0.9x) \uD83D\uDFE0 0.135ms (2.1x) 0.118ms (2.4x) 0.264ms (1.1x) 0.110ms (2.6x) \uD83D\uDFE2 0.112ms (2.5x) 0.286ms (1.0x) IntersectWith(1, 100000) 3.460ms (0.9x) \uD83D\uDFE0 1.490ms (2.0x) 1.322ms (2.2x) 2.881ms (1.0x) 1.259ms (2.4x) \uD83D\uDFE2 1.280ms (2.3x) 2.963ms (1.0x) IntersectWith(1, 1000000) 50.949ms (1.3x) 18.330ms (3.6x) 16.081ms (4.1x) 41.292ms (1.6x) 15.816ms (4.1x) \uD83D\uDFE2 15.828ms (4.1x) 65.453ms (1.0x) \uD83D\uDFE0 ExceptWith(1, 10000) 0.269ms (0.9x) \uD83D\uDFE0 0.213ms (1.1x) 0.118ms (2.0x) 0.197ms (1.2x) 0.115ms (2.0x) 0.112ms (2.1x) \uD83D\uDFE2 0.230ms (1.0x) ExceptWith(1, 100000) 2.960ms (0.8x) \uD83D\uDFE0 1.408ms (1.8x) 1.335ms (1.8x) 2.181ms (1.1x) 1.320ms (1.9x) 1.280ms (1.9x) \uD83D\uDFE2 2.467ms (1.0x) ExceptWith(1, 1000000) 40.054ms (1.0x) 20.188ms (2.0x) 18.223ms (2.2x) 30.004ms (1.4x) 18.972ms (2.2x) 17.592ms (2.3x) \uD83D\uDFE2 40.898ms (1.0x) \uD83D\uDFE0 ¹ Optimizations were disabled to perform this benchmark ² Benchmark run on parallel job workers - results may vary ³ AddGrow(workers, capacity, growTo) -- Incrementally grows from capacity until reaching size of growTo QueueParallelWriter Functionality NativeQueueParallelWriter (S) NativeQueueParallelWriter (S+B) NativeQueueParallelWriter (B) UnsafeQueueParallelWriter (S) UnsafeQueueParallelWriter (S+B) UnsafeQueueParallelWriter (B) ConcurrentQueue (BCL) EnqueueGrow(1, 10000)³ 0.063ms (1.8x) 0.037ms (3.1x) 0.027ms (4.2x) \uD83D\uDFE2 --- --- --- 0.112ms (1.0x) \uD83D\uDFE0 EnqueueGrow(2, 10000)²˒³ 0.036ms (3.8x) 0.032ms (4.3x) 0.022ms (6.3x) \uD83D\uDFE2 --- --- --- 0.136ms (1.0x) \uD83D\uDFE0 EnqueueGrow(4, 10000)²˒³ 0.041ms (5.0x) 0.023ms (9.1x) \uD83D\uDFE2 0.028ms (7.4x) --- --- --- 0.205ms (1.0x) \uD83D\uDFE0 EnqueueGrow(1, 100000)³ 1.111ms (1.0x) \uD83D\uDFE0 0.196ms (5.5x) \uD83D\uDFE2 0.249ms (4.3x) --- --- --- 1.069ms (1.0x) EnqueueGrow(2, 100000)²˒³ 0.353ms (43.1x) 0.129ms (118.3x) \uD83D\uDFE2 0.141ms (107.9x) --- --- --- 15.233ms (1.0x) \uD83D\uDFE0 EnqueueGrow(4, 100000)²˒³ 0.359ms (128.0x) 0.119ms (384.9x) 0.101ms (455.1x) \uD83D\uDFE2 --- --- --- 45.962ms (1.0x) \uD83D\uDFE0 EnqueueGrow(1, 1000000)³ 6.964ms (1.5x) 1.971ms (5.3x) \uD83D\uDFE2 2.470ms (4.2x) --- --- --- 10.493ms (1.0x) \uD83D\uDFE0 EnqueueGrow(2, 1000000)²˒³ 3.587ms (4.2x) 1.264ms (12.0x) \uD83D\uDFE2 1.353ms (11.2x) --- --- --- 15.213ms (1.0x) \uD83D\uDFE0 EnqueueGrow(4, 1000000)²˒³ 3.119ms (14.9x) 1.036ms (44.8x) 0.915ms (50.7x) \uD83D\uDFE2 --- --- --- 46.400ms (1.0x) \uD83D\uDFE0 Enqueue(1, 10000)⁴ 0.063ms (1.8x) 0.014ms (8.0x) \uD83D\uDFE2 0.019ms (5.9x) --- --- --- 0.112ms (1.0x) \uD83D\uDFE0 Enqueue(2, 10000)²˒⁴ 0.043ms (3.1x) 0.015ms (8.7x) 0.013ms (10.1x) \uD83D\uDFE2 --- --- --- 0.132ms (1.0x) \uD83D\uDFE0 Enqueue(4, 10000)²˒⁴ 0.036ms (5.7x) 0.017ms (11.8x) 0.016ms (13.0x) \uD83D\uDFE2 --- --- --- 0.203ms (1.0x) \uD83D\uDFE0 Enqueue(1, 100000)⁴ 0.628ms (1.7x) 0.244ms (4.4x) 0.187ms (5.7x) \uD83D\uDFE2 --- --- --- 1.068ms (1.0x) \uD83D\uDFE0 Enqueue(2, 100000)²˒⁴ 0.329ms (46.3x) 0.142ms (107.6x) 0.107ms (142.5x) \uD83D\uDFE2 --- --- --- 15.253ms (1.0x) \uD83D\uDFE0 Enqueue(4, 100000)²˒⁴ 0.305ms (154.5x) 0.077ms (611.1x) 0.061ms (767.5x) \uD83D\uDFE2 --- --- --- 47.086ms (1.0x) \uD83D\uDFE0 Enqueue(1, 1000000)⁴ 6.283ms (1.7x) 1.374ms (7.6x) \uD83D\uDFE2 1.869ms (5.6x) --- --- --- 10.486ms (1.0x) \uD83D\uDFE0 Enqueue(2, 1000000)²˒⁴ 3.268ms (4.7x) 0.896ms (17.0x) \uD83D\uDFE2 1.029ms (14.8x) --- --- --- 15.201ms (1.0x) \uD83D\uDFE0 Enqueue(4, 1000000)²˒⁴ 2.931ms (15.8x) 0.638ms (72.4x) \uD83D\uDFE2 0.697ms (66.3x) --- --- --- 46.225ms (1.0x) \uD83D\uDFE0 ² Benchmark run on parallel job workers - results may vary ³ EnqueueGrow(workers, insertions) ⁴ Enqueue(workers, insertions) Queue Functionality NativeQueue (S) NativeQueue (S+B) NativeQueue (B) UnsafeQueue (S) UnsafeQueue (S+B) UnsafeQueue (B) Queue (BCL) IsEmpty_x_100k(0)¹ 0.482ms (0.2x) \uD83D\uDFE0 0.181ms (0.6x) 0.161ms (0.6x) 0.232ms (0.4x) 0.000ms (334.3x) \uD83D\uDFE2 0.000ms (334.3x) \uD83D\uDFE2 0.100ms (1.0x) IsEmpty_x_100k(100)¹ 0.503ms (0.2x) \uD83D\uDFE0 0.188ms (0.5x) 0.141ms (0.7x) 0.241ms (0.4x) 0.000ms (334.3x) \uD83D\uDFE2 0.000ms (334.3x) \uD83D\uDFE2 0.100ms (1.0x) Count_x_100k(0)¹ 0.313ms (0.4x) \uD83D\uDFE0 0.193ms (0.6x) 0.161ms (0.7x) 0.189ms (0.6x) 0.000ms (401.2x) \uD83D\uDFE2 0.000ms (401.2x) \uD83D\uDFE2 0.120ms (1.0x) Count_x_100k(100)¹ 0.351ms (0.3x) \uD83D\uDFE0 0.181ms (0.7x) 0.141ms (0.9x) 0.231ms (0.5x) 0.000ms (401.2x) \uD83D\uDFE2 0.000ms (343.9x) 0.120ms (1.0x) ToNativeArray(10000) 0.003ms (1.2x) 0.002ms (1.7x) 0.002ms (1.7x) 0.002ms (1.8x) \uD83D\uDFE2 0.002ms (1.8x) 0.002ms (1.8x) \uD83D\uDFE2 0.003ms (1.0x) \uD83D\uDFE0 ToNativeArray(100000) 0.096ms (0.3x) \uD83D\uDFE0 0.016ms (1.9x) 0.015ms (1.9x) 0.089ms (0.3x) 0.015ms (1.9x) \uD83D\uDFE2 0.015ms (1.9x) 0.029ms (1.0x) ToNativeArray(1000000) 0.991ms (0.8x) \uD83D\uDFE0 0.197ms (4.1x) 0.163ms (5.0x) 0.897ms (0.9x) 0.156ms (5.2x) \uD83D\uDFE2 0.161ms (5.0x) 0.814ms (1.0x) EnqueueGrow(10000)³ 0.060ms (23.4x) 0.025ms (57.2x) 0.024ms (59.1x) \uD83D\uDFE2 0.045ms (31.3x) 0.025ms (56.4x) 0.026ms (55.1x) 1.414ms (1.0x) \uD83D\uDFE0 EnqueueGrow(100000)³ 0.657ms (0.6x) \uD83D\uDFE0 0.249ms (1.6x) 0.231ms (1.8x) \uD83D\uDFE2 0.445ms (0.9x) 0.241ms (1.7x) 0.248ms (1.6x) 0.407ms (1.0x) EnqueueGrow(1000000)³ 6.580ms (0.6x) \uD83D\uDFE0 2.452ms (1.6x) 2.340ms (1.7x) \uD83D\uDFE2 4.509ms (0.9x) 2.473ms (1.6x) 2.509ms (1.6x) 3.931ms (1.0x) Enqueue(10000)⁴ 0.060ms (0.8x) \uD83D\uDFE0 0.019ms (2.4x) 0.018ms (2.5x) \uD83D\uDFE2 0.039ms (1.2x) 0.020ms (2.3x) 0.020ms (2.2x) 0.046ms (1.0x) Enqueue(100000)⁴ 0.599ms (0.7x) \uD83D\uDFE0 0.193ms (2.1x) 0.180ms (2.3x) \uD83D\uDFE2 0.392ms (1.0x) 0.198ms (2.1x) 0.196ms (2.1x) 0.407ms (1.0x) Enqueue(1000000)⁴ 5.989ms (0.7x) \uD83D\uDFE0 2.048ms (1.9x) 1.801ms (2.2x) \uD83D\uDFE2 3.933ms (1.0x) 2.010ms (2.0x) 2.011ms (2.0x) 3.933ms (1.0x) Dequeue(10000) 0.066ms (0.6x) \uD83D\uDFE0 0.025ms (1.4x) 0.016ms (2.4x) \uD83D\uDFE2 0.045ms (0.8x) 0.017ms (2.2x) 0.017ms (2.2x) 0.037ms (1.0x) Dequeue(100000) 0.664ms (0.6x) \uD83D\uDFE0 0.248ms (1.5x) 0.151ms (2.4x) \uD83D\uDFE2 0.455ms (0.8x) 0.158ms (2.3x) 0.159ms (2.3x) 0.369ms (1.0x) Dequeue(1000000) 6.640ms (0.6x) \uD83D\uDFE0 2.479ms (1.5x) 1.503ms (2.5x) \uD83D\uDFE2 4.551ms (0.8x) 1.578ms (2.3x) 1.589ms (2.3x) 3.690ms (1.0x) Peek(10000)¹ 0.030ms (0.6x) \uD83D\uDFE0 0.023ms (0.8x) 0.014ms (1.3x) 0.012ms (1.5x) 0.000ms (45.4x) \uD83D\uDFE2 0.000ms (45.4x) \uD83D\uDFE2 0.018ms (1.0x) Peek(100000)¹ 0.302ms (0.6x) \uD83D\uDFE0 0.222ms (0.8x) 0.134ms (1.4x) 0.121ms (1.5x) 0.001ms (278.8x) \uD83D\uDFE2 0.001ms (258.9x) 0.181ms (1.0x) Peek(1000000)¹ 3.016ms (0.6x) \uD83D\uDFE0 2.213ms (0.8x) 1.369ms (1.3x) 1.205ms (1.5x) 0.001ms (2127.8x) 0.001ms (2260.8x) \uD83D\uDFE2 1.809ms (1.0x) Foreach(10000) 0.028ms (1.5x) 0.009ms (4.9x) 0.007ms (6.4x) 0.018ms (2.3x) 0.003ms (13.9x) 0.003ms (14.1x) \uD83D\uDFE2 0.042ms (1.0x) \uD83D\uDFE0 Foreach(100000) 0.283ms (1.5x) 0.082ms (5.2x) 0.062ms (6.9x) 0.182ms (2.3x) 0.027ms (15.5x) \uD83D\uDFE2 0.027ms (15.5x) \uD83D\uDFE2 0.425ms (1.0x) \uD83D\uDFE0 Foreach(1000000) 2.833ms (1.5x) 0.812ms (5.2x) 0.612ms (6.9x) 1.819ms (2.3x) 0.267ms (15.9x) 0.267ms (15.9x) \uD83D\uDFE2 4.250ms (1.0x) \uD83D\uDFE0 ¹ Optimizations were disabled to perform this benchmark ³ EnqueueGrow(insertions) ⁴ Enqueue(insertions) RingQueue Functionality NativeRingQueue (S) NativeRingQueue (S+B) NativeRingQueue (B) UnsafeRingQueue (S) UnsafeRingQueue (S+B) UnsafeRingQueue (B) Queue (BCL) IsEmpty_x_100k(0)¹ 0.174ms (0.7x) \uD83D\uDFE0 0.108ms (1.1x) \uD83D\uDFE2 0.108ms (1.1x) \uD83D\uDFE2 0.121ms (1.0x) 0.111ms (1.1x) 0.110ms (1.1x) 0.121ms (1.0x) IsEmpty_x_100k(100)¹ 0.161ms (0.8x) \uD83D\uDFE0 0.108ms (1.1x) 0.108ms (1.1x) \uD83D\uDFE2 0.120ms (1.0x) 0.111ms (1.1x) 0.110ms (1.1x) 0.120ms (1.0x) Count_x_100k(0)¹ 0.192ms (0.5x) \uD83D\uDFE0 0.142ms (0.7x) 0.108ms (0.9x) 0.120ms (0.8x) 0.111ms (0.9x) 0.111ms (0.9x) 0.101ms (1.0x) \uD83D\uDFE2 Count_x_100k(100)¹ 0.188ms (0.5x) \uD83D\uDFE0 0.143ms (0.7x) 0.110ms (0.9x) 0.120ms (0.8x) 0.111ms (0.9x) 0.111ms (0.9x) 0.100ms (1.0x) \uD83D\uDFE2 Enqueue(10000) 0.033ms (1.1x) 0.019ms (1.9x) 0.018ms (2.0x) 0.019ms (1.9x) 0.017ms (2.0x) \uD83D\uDFE2 0.018ms (2.0x) 0.035ms (1.0x) \uD83D\uDFE0 Enqueue(100000) 0.331ms (1.1x) 0.183ms (1.9x) 0.173ms (2.0x) 0.182ms (1.9x) 0.172ms (2.0x) \uD83D\uDFE2 0.173ms (2.0x) 0.349ms (1.0x) \uD83D\uDFE0 Enqueue(1000000) 3.311ms (1.1x) 1.815ms (1.9x) 1.725ms (2.0x) 1.823ms (1.9x) 1.722ms (2.0x) \uD83D\uDFE2 1.732ms (2.0x) 3.477ms (1.0x) \uD83D\uDFE0 Dequeue(10000) 0.032ms (1.1x) 0.017ms (2.1x) 0.008ms (4.6x) \uD83D\uDFE2 0.017ms (2.1x) 0.017ms (2.1x) 0.011ms (3.3x) 0.035ms (1.0x) \uD83D\uDFE0 Dequeue(100000) 0.326ms (1.1x) 0.163ms (2.2x) 0.072ms (4.9x) \uD83D\uDFE2 0.167ms (2.1x) 0.162ms (2.2x) 0.102ms (3.5x) 0.352ms (1.0x) \uD83D\uDFE0 Dequeue(1000000) 3.257ms (1.1x) 1.624ms (2.2x) 0.708ms (5.0x) \uD83D\uDFE2 1.666ms (2.1x) 1.612ms (2.2x) 1.008ms (3.5x) 3.516ms (1.0x) \uD83D\uDFE0 ¹ Optimizations were disabled to perform this benchmark"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparisons.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Documentation~/performance-comparisons.html",
    "title": "Performance comparisons | Inventory System",
    "summary": "Performance comparisons This section contains data around allocator and container performance benchmarks Topic Description Allocator benchmarks Benchmark information for allocators. Container performance comparison Performance comparison for containers. Additional resources Allocator overview"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.collections copyright © 2024 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/README.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/README.html",
    "title": "Unity.Collections | Inventory System",
    "summary": "Unity.Collections A C# collections library providing data structures that can be used in jobs, and optimized by Burst compiler. Package CI Summary Documentation https://docs.unity3d.com/Packages/com.unity.collections@0.14/manual/index.html Data structures The Unity.Collections package includes the following data structures: Data structure | Description | Documentation ---------------------------- | ----------- | ------------- BitField32 | Fixed size 32-bit array of bits. | Documentation BitField64 | Fixed size 64-bit array of bits. | Documentation NativeBitArray | Arbitrary sized array of bits. | Documentation UnsafeBitArray | Arbitrary sized array of bits, without any thread safety check features. | Documentation NativeList | An unmanaged, resizable list. | Documentation UnsafeList | An unmanaged, resizable list, without any thread safety check features. | Documentation NativeHashMap | Unordered associative array, a collection of keys and values. | Documentation UnsafeHashMap | Unordered associative array, a collection of keys and values, without any thread safety check features. | Documentation NativeHashSet | Set of values. | Documentation UnsafeHashSet | Set of values, without any thread safety check features. | Documentation NativeParallelHashMap | Unordered associative array, a collection of keys and values. | Documentation UnsafeParallelHashMap | Unordered associative array, a collection of keys and values, without any thread safety check features. | Documentation NativeParallelHashSet | Set of values. | Documentation UnsafeParallelHashSet | Set of values, without any thread safety check features. | Documentation NativeParallelMultiHashMap | Unordered associative array, a collection of keys and values. This container can store multiple values for every key. | Documentation UnsafeParallelMultiHashMap | Unordered associative array, a collection of keys and values, without any thread safety check features. This container can store multiple values for every key. | Documentation NativeStream | A deterministic data streaming supporting parallel reading and parallel writing. Allows you to write different types or arrays into a single stream. | Documentation UnsafeStream | A deterministic data streaming supporting parallel reading and parallel writings, without any thread safety check features. Allows you to write different types or arrays into a single stream. | Documentation NativeReference | An unmanaged, reference container. | Documentation UnsafeAppendBuffer | An unmanaged, untyped, buffer, without any thread safety check features. | Documentation UnsafeRingQueue | Fixed-size circular buffer, without any thread safety check features. | Documentation UnsafeAtomicCounter32 | 32-bit atomic counter. | Documentation UnsafeAtomicCounter64 | 64-bit atomic counter. | Documentation ... The items in this package build upon the NativeArray , NativeSlice , and other members of the Unity.Collections namespace, which Unity includes in the core module. Notation Native* container prefix signifies that containers have debug safety mechanisms which will warn users when a container is used incorrectly in regard with thread-safety, or memory management. Unsafe* containers do not provide those safety warnings, and the user is fully responsible to guarantee that code will execute correctly. Almost all Native* containers are implemented by using Unsafe* container of the same kind internally. In the release build, since debug safety mechanism is disabled, there should not be any significant performance difference between Unsafe* and Native* containers. Unsafe* containers are in Unity.Collections.LowLevel.Unsafe namespace, while Native* containers are in Unity.Collections namespace. Determinism Populating containers from parallel jobs is never deterministic, except when using NativeStream or UnsafeStream. If determinism is required, consider sorting the container as a separate step or post-process it on a single thread. Known Issues All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance. This is problematic when using NativeParallelHashMap, NativeParallelMultiHashMap, NativeParallelHashSet and NativeList together in situations where their secondary safety handle is used. This means that operations that invalidate an enumerator for either of these collections (or the NativeArray returned by NativeList.AsArray) will also invalidate all other previously acquired enumerators. For example, this will throw when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeParallelHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0]; This defect will be addressed in a future release. Licensing Unity Companion License (“License”) Software Copyright © 2017-2020 Unity Technologies ApS For licensing details see LICENSE.md"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Unity.Collections.PerformanceTests/README.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Unity.Collections.PerformanceTests/README.html",
    "title": "Collections Benchmarking and Performance Tests | Inventory System",
    "summary": "Collections Benchmarking and Performance Tests Table of Contents Overview Containers Allocators Container Benchmarking and Performance Tests Example Code - List.Add Results - List.Add Allocator Benchmarking and Performance Tests Example Code - RewindableAllocator.FixedSize Results - RewindableAllocator.FixedSize Overview com.unity.collections provides pre-defined intermediate 'glue' layers on top of the Benchmark Framework to enable relatively simple creation of performance and benchmark testing for a wide variety of code paths which may be taken when using the collections package. Containers Examples of provided benchmarking and performance testing include: NativeContainer code Burst compiled NativeContainer code with safety enabled Burst compiled NativeContainer code with safety disabled UnsafeContainer code Burst compiled UnsafeContainer code with safety enabled Burst compiled UnsafeContainer code with safety disabled Combine those with: Container.ParallelWriter code going wide in any of the above mentioned situations Container.ReadOnly code going wide and it is easy to visualize the vast number of possibilities which we want to monitor and generate concrete performance data and comparisons on. Regarding comparisons, we also want to ensure that these burst compatible containers are competitive or better with a similar container in .NET/IL2CPP/Mono's base class library, and have a way to validate and track improvements there as well, such as those found in: System.Collections.Generic System.Collections.Concurrent Allocators Naturally, there is a similar story with the custom allocator types provided by the collections package. In this case we want to be able to compare: A provided IAllocator implementation in a managed code path The same in a Burst compiled code path with safety enabled Again the same in a Burst compiled code path with safety disabled against: The UnityEngine built-in Allocator.Temp The UnityEngine built-in Allocator.TempJob The UnityEngine built-in Allocator.Persistent Container Benchmarking and Performance Tests Container performance testing and benchmarks are built around a small handful of types. |Type|Description| |---|---| |BenchmarkContainerType|This enum defines variations for Native and Unsafe containers with and without burst compilation - with and without safety enabled. See the inline documentation for full details.| |IBenchmarkContainer|Tests are written as implementations of this interface. It provides means for generic int parameters, allocation and disposal of Native, Unsafe, and C# Base Class Library containers, and measurement of the same. |BenchmarkContainerRunner|Easy-to-use API for running measurements in a single call. See inline documentation for full details, and see below for example usage.| |IBenchmarkContainerParallel|Similar to IBenchmarkContainer, but designed to support tightly designed measurement code with Unity Job system workers in mind| |BenchmarkContainerRunnerParallel|Similar to BenchmarkContainerRunner, but designed to parameterize worker thread counts for performance testing and benchmarking parallel container implementations| Example Code - List.Add Here is a real-world basic example of implementing a performance and test and benchmark comparison for lists. This measures the cost of simply adding elements to a list with the expected capacity pre-allocated. struct ListAdd : IBenchmarkContainer { int capacity; NativeList<int> nativeContainer; UnsafeList<int> unsafeContainer; void IBenchmarkContainer.SetParams(int capacity, params int[] args) => this.capacity = capacity; public void AllocNativeContainer(int capacity) => ListUtil.AllocInt(ref nativeContainer, capacity, false); public void AllocUnsafeContainer(int capacity) => ListUtil.AllocInt(ref unsafeContainer, capacity, false); public object AllocBclContainer(int capacity) => ListUtil.AllocBclContainer(capacity, false); public void MeasureNativeContainer() { for (int i = 0; i < capacity; i++) nativeContainer.Add(i); } public void MeasureUnsafeContainer() { for (int i = 0; i < capacity; i++) unsafeContainer.Add(i); } public void MeasureBclContainer(object container) { var bclContainer = (System.Collections.Generic.List<int>)container; for (int i = 0; i < capacity; i++) bclContainer.Add(i); } } To run these measurements, the calling code is quite simple, and generates a multitude of Performance Test Framework tests which can be run from the Unity Test Runner as well as through CI regression checks, and it also supports the necessary code paths for Benchmarking to make performance comparisons on all the variations including the BCL variation. Note the BCL variation of System.Collections.Generic.List will not appear as a Performance Test Framework test - it is considered for benchmarking only. [Benchmark(typeof(BenchmarkContainerType))] class List { ... [Test, Performance] [Category(\"Performance\")] public unsafe void Add( [Values(10000, 100000, 1000000)] int insertions, [Values] BenchmarkContainerType type) { BenchmarkContainerRunner<ListAdd>.Run(insertions, type); } ... } Results - List.Add This above two code snippets generate something like the following (notice the BCL tests aren't generated): Running the DOTS/Unity.Collections/Generate Container Benchmarks menu item will generate a markdown report, again running the same single code path per type. Here is a snippet of the full results showing only the output for List.Add: List Functionality NativeList (S) NativeList (S+B) NativeList (B) UnsafeList (S) UnsafeList (S+B) UnsafeList (B) List (BCL) Add(10000) 0.178ms (0.1x) \uD83D\uDFE0 0.057ms (0.3x) 0.018ms (0.8x) 0.041ms (0.4x) 0.006ms (2.3x) \uD83D\uDFE2 0.014ms (1.1x) 0.015ms (1.0x) Add(100000) 1.827ms (0.1x) \uD83D\uDFE0 0.622ms (0.2x) 0.180ms (0.8x) 0.432ms (0.3x) 0.061ms (2.4x) \uD83D\uDFE2 0.139ms (1.1x) 0.146ms (1.0x) Add(1000000) 18.910ms (0.1x) \uD83D\uDFE0 6.443ms (0.2x) 1.814ms (0.8x) 4.136ms (0.4x) 0.586ms (2.5x) \uD83D\uDFE2 1.482ms (1.0x) 1.468ms (1.0x) Allocator Benchmarking and Performance Tests Allocator performance testing and benchmarks are built around a small handful of types. |Type|Description| |---|---| |BenchmarkAllocatorType|This enum defines variations for allocators with and without burst compilation - with and without safety enabled. See the inline documentation for full details.| |IBenchmarkAllocator|Tests are written as implementations of this interface. It provides means for generic int parameters, creation and destruction of allocators, allocation and freeing of memory using these allocators as well as using Unity Engine's built-in allocators Temp, TempJob, and Persistent, and measurement of the same. |BenchmarkAllocatorRunner|Easy-to-use API for running measurements in a single call. See inline documentation for full details, and see below for example usage.| |BenchmarkAllocatorUtil|Generalized API for simplifying common Setup and Teardown implementations of IBenchmarkAllocator derived test types| Example Code - RewindableAllocator.FixedSize The following example will omit another utility type designed for RewindableAllocator. The type is designed to simplify setup, teardown, and Rewind functionality necessary on a per-test-run basis. See RewindableAllocatorPerformanceTests.cs for reference. struct Rewindable_FixedSize : IBenchmarkAllocator { RewindableAllocationInfo allocInfo; public void CreateAllocator(Allocator builtinOverride) => allocInfo.CreateAllocator(builtinOverride); public void DestroyAllocator() => allocInfo.DestroyAllocator(); public void Setup(int workers, int size, int allocations) => allocInfo.Setup(workers, size, 0, allocations); public void Teardown() => allocInfo.Teardown(); public void Measure(int workerI) => allocInfo.Allocate(workerI); } To run these measurements, the calling code is quite simple, and generates a multitude of Performance Test Framework tests which can be run from the Unity Test Runner as well as through CI regression checks, and it also supports the necessary code paths for Benchmarking to make performance comparisons on all the variations including the Temp, TempJob, and Persistent variations. Note these Unity Engine built-in allocator variations will not appear as a Performance Test Framework test - it is considered for benchmarking only. [Benchmark(typeof(BenchmarkAllocatorType))] [BenchmarkNameOverride(\"RewindableAllocator\")] class RewindableAllocatorBenchmark { ... [Test, Performance] [Category(\"Performance\")] [BenchmarkTestFootnote] public void FixedSize( [Values(1, 2, 4, 8)] int workerThreads, [Values(1024, 1024 * 1024)] int allocSize, [Values] BenchmarkAllocatorType type) { BenchmarkAllocatorRunner<Rewindable_FixedSize>.Run(type, allocSize, workerThreads); } ... } Results - RewindableAllocator.FixedSize This above two code snippets generate something like the following (notice the BCL tests aren't generated): Running the DOTS/Unity.Collections/Generate Allocator Benchmarks menu item will generate a markdown report, again running the same single code path per type. Here is a snippet of the full results showing only the output for RewindableAllocator.FixedSize: RewindableAllocator Functionality RewindableAllocator (S) RewindableAllocator (S+B) RewindableAllocator (B) TempJob (E) Temp (E) Persistent (E) FixedSize(1, 1024)³ 11.4µs (2.5x) 3.9µs (7.3x) 3.6µs (7.9x) \uD83D\uDFE2 13.6µs (2.1x) 10.2µs (2.8x) 28.6µs (1.0x) \uD83D\uDFE0 FixedSize(2, 1024)²˒³ 27.8µs (2.5x) 17.7µs (3.9x) 8.8µs (7.9x) \uD83D\uDFE2 19.3µs (3.6x) 10.6µs (6.5x) 69.1µs (1.0x) \uD83D\uDFE0 FixedSize(4, 1024)²˒³ 65.3µs (1.9x) 73.1µs (1.7x) 66.8µs (1.8x) 28.2µs (4.3x) 11.8µs (10.3x) \uD83D\uDFE2 121.8µs (1.0x) \uD83D\uDFE0 FixedSize(8, 1024)²˒³ 141.5µs (2.1x) 133.3µs (2.3x) 158.5µs (1.9x) 46.0µs (6.6x) 11.6µs (26.2x) \uD83D\uDFE2 303.9µs (1.0x) \uD83D\uDFE0 FixedSize(1, 1048576)³ 12.3µs (16.5x) 4.6µs (44.2x) 4.2µs (48.4x) \uD83D\uDFE2 17.3µs (11.8x) 10.5µs (19.4x) 203.3µs (1.0x) \uD83D\uDFE0 FixedSize(2, 1048576)²˒³ 24.7µs (12.1x) 14.9µs (20.0x) 10.4µs (28.7x) \uD83D\uDFE2 27.7µs (10.8x) 11.3µs (26.4x) 298.4µs (1.0x) \uD83D\uDFE0 FixedSize(4, 1048576)²˒³ 70.8µs (12.4x) 77.5µs (11.3x) 72.5µs (12.1x) 199.5µs (4.4x) 12.5µs (70.2x) \uD83D\uDFE2 877.7µs (1.0x) \uD83D\uDFE0 FixedSize(8, 1048576)²˒³ 152.0µs (14.5x) 155.2µs (14.2x) 160.9µs (13.7x) 1010.8µs (2.2x) 12.4µs (177.2x) \uD83D\uDFE2 2197.7µs (1.0x) \uD83D\uDFE0 ² Benchmark run on parallel job workers - results may vary ³ FixedSize(workerThreads, allocSize)"
  },
  "Library/PackageCache/com.unity.collections@56bff8827a7e/Unity.Collections.PerformanceTests/Unity.PerformanceTesting.Benchmark/README.html": {
    "href": "Library/PackageCache/com.unity.collections@56bff8827a7e/Unity.Collections.PerformanceTests/Unity.PerformanceTesting.Benchmark/README.html",
    "title": "Benchmark Framework | Inventory System",
    "summary": "Benchmark Framework Table of Contents Overview and Features Using the Framework Attribute Summary Example Glue Layer - Native Containers Performance and Benchmark Tests - Native Containers Results Overview and Features The Benchmark Framework is a complimentary framework to the Performance Test Framework. It provides a means to write a code for performance tests one time for a given type while providing the following benefits: Both benchmarks comparisons and performance/regression testing from a single implementation A managed execution path (JIT) from the same single implementation A Burst compiled with safety path from the same single implementation A Burst compiled without safety path from the same single implementation Automatically generate markdown formatted documentation for the Benchmark results Provide a simple means for running benchmarks through custom menu items with easily trackable progress and ability to cancel at any time For the Benchmark Framework itself, tests can be designed to easily group together multiple variations for comparison. For example, the list above may apply to: An implementation for Native containers Another implementation for Unsafe containers And yet another implementation for the container types included in .NET/Mono/IL2CPP Base Class Libraries Finally, test implementations may be classified such as: Only test for benchmarking, but not for performance/regression testing (such as managed BCL containers) Consider an implementation variation as the baseline, and compare all other implementation variations against it Include only a subset of implementation in case there is a gap in functionality (intentional or not) at this time Using the Framework To take advantage of the features above and write tests for the Benchmark Framework, three components are required: The Benchmark Framework itself which works alongside the Performance Test Framework An intermediate 'glue' layer for a given benchmark comparison type i.e. BenchmarkContainer, BenchmarkAllocator The Performance Tests themselves, using the intermediate layer from #2 above Because #1 is provided by the Framework here, the rest of this documentation will give an example of using it to create a 'glue' layer and then a performance test which makes use of this example 'glue' layer. Attribute Summary Most (but not quite all) interaction with the Benchmark Framework will occur through its attributes. These are all defined in the Unity.PerformanceTesting.Benchmark namespace. A summary will be given here, but further details can be found in the inline code documentation. As mentioned, a small example demonstrating their use will follow. Attribute Description [Benchmark] This marks a class containing performance tests to be used in Benchmark Comparison report generation. [BenchmarkComparison] This marks an enum as defining the variants that will be generated and simultaneously covers both the Performance Test Framework tests as well as Benchmark Framework tests. Optionally, this can define the Benchmark baseline if it is also a Performance Test Framework measurement. [BenchmarkComparisonExternal] Used on the same enum definition, this associates non-enum values with the enum for Benchmark Framework tests which are not to be included in Performance Test Framework tests. Optionally, this can define the Benchmark baseline if it is not a Performance Test Framework measurement. [BenchmarkComparisonDisplay] Also used on the same enum definition, this overrides the default measurement sample unit (millisecond, microsecond, etc.), the decimal places for Benchmark report generation, and the ranking statistic for Benchmark report generation (median, minimum, etc.). [BenchmarkName] Required with each enum value, this describes a formatting string for naming Benchmark result variations when a report is generated, such as [BenchmarkName(\"Native{0}\")], which when used with a [Benchmark] attributed class such as HashSet, would generate a the name \"NativeHashSet\" [BenchmarkNameOverride] Override the formatted name in case the class doesn't precisely represent the name that should appear in reports. [BenchmarkTestFootnote] Generate a footnote in the Benchmark Comparison report for a given Performance Test method. When used, the footnote will always include a description of the method and its parameters. Optionally, user-defined footnote text may be specified as well. Generally, [Benchmark], [BenchmarkNameOverride], and [BenchmarkTestFootnote] will be used while writing tests. The rest are used solely in the 'glue' layer, so if you are writing tests on top of a pre-existing 'glue' layer, you will be unlikely to need or use them. Example Glue Layer - Native Containers This will illustrate a simplified version of the com.unity.collections BenchmarkContainer implementation as an example of creating an intermediate 'glue' layer between the Benchmark Framework and user-defined performance tests. The first requirement is an enum type which defines the test variations that will be benchmarked. Values defined in the enum will also generate Performance Test Framework tests used in regression testing and performance analysis. Values defined through the [BenchmarkComparison] attribute will only appear in Benchmark reports. You'll notice two attributes used. [BenchmarkComparison] denotes this enum will be used for benchmarking as well as indicates an externally defined comparison type (BCL) as the baseline to benchmark against, and [BenchmarkComparisonDisplay] overrides the default format for report generation and the statistic used for comparison. It's worth pointing out that the {0} in the name strings will be replaced with the name of the test group, such as HashSet or List. This also references a MyExampleConfig for convenience and consistency which will be defined next. [BenchmarkComparison(MyExampleConfig.BCL, \"{0} (BCL)\")] [BenchmarkComparisonDisplay(SampleUnit.Millisecond, 3, BenchmarkRankingStatistic.Median)] public enum MyExampleType : int { [BenchmarkName(\"Native{0}\")] Managed, [BenchmarkName(\"Native{0} (B)\")] BurstCompiled, } The configuration class is not a requirement, but rather it is a recommended pattern for storing common data for all tests as well as the interface (in this case a menu item) for running benchmarks and generating the resulting markdown file. The main takeaway here is the call to GenerateMarkdown which also runs the benchmark tests. Specifically, the argument typeof(MyExampleType) refers to the above defined comparison enum, and this call will find all the types with a [Benchmark(typeof(MyExampleType))] attribute and their methods with the combined [Test] and [Performance] attributes discover and run benchmark tests. More on this later with the example performance tests which will be benchmarked. public static class MyExampleConfig { public const int BCL = -1; internal const int kCountWarmup = 5; internal const int kCountMeasure = 10; #if UNITY_EDITOR [UnityEditor.MenuItem(\"Benchmark Example/Generate My Benchmarks\")] #endif static void RunBenchmarks() => BenchmarkGenerator.GenerateMarkdown( \"Containers Example\", typeof(MyExampleType), \"Temp/performance-comparison-example.md\", $\"Example benchmark - {kCountMeasure} runs after {kCountWarmup} warmup runs\", \"Legend\", new string[] { \"`(B)` = Burst Compiled\", \"`(BCL)` = Base Class Library implementation (such as provided by Mono or .NET)\", }); } A glue layer should define an interface which specifies any test setup, teardown, and measurement for each unique type that will be measured. For the sake of this example, a NativeContainer will be measured, and a managed C# base class library container will be used as a baseline. Notice there is not a separate interface definition for the NativeContainer's managed code path versus Burst compiled code path. This can be handled automatically by the final piece of the 'glue' layer, defined next. public interface IMyExampleBenchmark { public void SetupTeardown(int capacity); public object SetupTeardownBCL(int capacity); public void Measure(); public void MeasureBCL(object container); } Finally, this brings all the individual 'glue' pieces together. Calling this method from a performance framework test implementation (with [Test] and [Performance] attributes) will ensure the proper code path is executed and measured. Some details worth noting: BenchmarkMeasure.Measure handles selecting the code path for either the Performance Test Framework (run through the Test Runner in Unity) or the Benchmark Framework (run through the above defined menu option, for instance). Setup and Teardown calls are not timed and measured. Burst compiled (and any other) variants of a single test implementation isn't entirely automatic - rather it is defined by the 'glue' layer and specified through the comparison enum value. External comparison values such as MyExampleConfig.BCL will never be called by the Performance Test Framework. Only the Benchmark Framework will automatically generation measurement invocations with this value. [BurstCompile(CompileSynchronously = true)] public static class MyExampleRunner<T> where T : unmanaged, IMyExampleBenchmark { [BurstCompile(CompileSynchronously = true)] unsafe struct BurstCompiledJob : IJob { [NativeDisableUnsafePtrRestriction] public T* methods; public void Execute() => methods->Measure(); } public static unsafe void Run(int capacity, MyExampleType type) { var methods = new T(); switch (type) { case (MyExampleType)(MyExampleConfig.BCL): object container = null; BenchmarkMeasure.Measure( typeof(T), MyExampleConfig.kCountWarmup, MyExampleConfig.kCountMeasure, () => methods.MeasureBCL(container), () => container = methods.SetupTeardownBCL(capacity), () => container = methods.SetupTeardownBCL(-1)); break; case MyExampleType.Managed: BenchmarkMeasure.Measure( typeof(T), MyExampleConfig.kCountWarmup, MyExampleConfig.kCountMeasure, () => methods.Measure(), () => methods.SetupTeardown(capacity), () => methods.SetupTeardown(-1)); break; case MyExampleType.BurstCompiled: BenchmarkMeasure.Measure( typeof(T), MyExampleConfig.kCountWarmup, MyExampleConfig.kCountMeasure, () => new BurstCompiledJob { methods = (T*)UnsafeUtility.AddressOf(ref methods) }.Run(), () => methods.SetupTeardown(capacity), () => methods.SetupTeardown(-1)); break; } } } With these 4 ingredients to the 'glue' layer, writing flexible multipurpose performance and benchmark tests which cover any number of combinations through the minimum amount of code possible - meaning little to no code duplication - is quite easy to do. There will still be some boiler-plate involved, as we do need to adhere to the contract set by the IMyExampleBenchmark interface, but the amount of code required to do this for 10s or 100s of performance tests is reduced by about an order of a magnitude compared to doing this manually, and that is without consideration even for generating benchmark comparisons and reports. Example Performance and Benchmark Tests - Native Containers Now that we have a 'glue' layer, it should be straightforward to define as many performance and benchmark tests for the comparison types provided by that layer as we can imagine. First let's define a simple utility class to reduce boiler plate in each test. This simply commonizes the setup and teardown, as we can not use inheritance due to needing the implementations to be unmanaged structs to satisfy the generic constraint of our MyExampleRunner in the 'glue' layer. static class ListUtil { static public void SetupTeardown(ref NativeList<int> container, int capacity, bool addValues) { if (capacity >= 0) { container = new NativeList<int>(capacity, Allocator.Persistent); if (addValues) { for (int i = 0; i < capacity; i++) container.Add(i); } } else container.Dispose(); } static public object SetupTeardownBCL(int capacity, bool addValues) { if (capacity < 0) return null; var list = new System.Collections.Generic.List<int>(capacity); if (addValues) { for (int i = 0; i < capacity; i++) list.Add(i); } return list; } } Now we'll create an implementation of IMyExampleBenchmark provided by the 'glue' layer to grow a list. The code should be straightforward, and each type of container has its code implemented only once. Additionally, the measurement code really is just \"the thing we want to measure\". struct ListAddGrow : IMyExampleBenchmark { int toAdd; NativeList<int> nativeContainer; public void SetupTeardown(int capacity) { toAdd = capacity; ListUtil.SetupTeardown(ref nativeContainer, 0, false); } public object SetupTeardownBCL(int capacity) { toAdd = capacity; return ListUtil.SetupTeardownBCL(0, false); } public void Measure() { for (int i = 0; i < toAdd; i++) nativeContainer.Add(i); } public void MeasureBCL(object container) { var list = (System.Collections.Generic.List<int>)container; for (int i = 0; i < toAdd; i++) list.Add(i); } } Let's make another implementation of IMyExampleBenchmark, this time testing the performance of a foreach over the list container types. Take special note of the Volatile.Write used to ensure optimizations don't throw away the value, thus rendering the loop unnecessary and optimizing it out altogether. struct ListForEach : IMyExampleBenchmark { NativeList<int> nativeContainer; public void SetupTeardown(int capacity) => ListUtil.SetupTeardown(ref nativeContainer, capacity, true); public object SetupTeardownBCL(int capacity) => ListUtil.SetupTeardownBCL(capacity, true); public void Measure() { int value = 0; foreach (var element in nativeContainer) Volatile.Write(ref value, element); } public void MeasureBCL(object container) { int value = 0; var list = (System.Collections.Generic.List<int>)container; foreach (var element in list) Volatile.Write(ref value, element); } } As a final example, we'll implement a performance test for checking if a list container is empty. This time, neither Volatile.Read nor Volatile.Write would help much because optimization passes can determine the result of checking for empty is constant through each loop iteration, i.e. there is no dependency within the loop itself when making this calculation. Due to this, we must turn off optimizations altogether with [MethodImpl(MethodImplOptions.NoOptimization)]. The best that could happen otherwise would be with a Volatile.Write. Then, the optimizer would extract the IsEmpty or Count to outside the loop, calling these only once, and then assign this pre-calculated value to the output of Volatile.Write kIterations times within a loop. Naturally, this doesn't tell us much about the code we want to measure. struct ListIsEmpty100k : IMyExampleBenchmark { const int kIterations = 100_000; NativeList<int> nativeContainer; public void SetupTeardown(int capacity) => ListUtil.SetupTeardown(ref nativeContainer, capacity, true); public object SetupTeardownBCL(int capacity) => ListUtil.SetupTeardownBCL(capacity, true); [MethodImpl(MethodImplOptions.NoOptimization)] public void Measure() { for (int i = 0; i < kIterations; i++) _ = nativeContainer.IsEmpty; } [MethodImpl(MethodImplOptions.NoOptimization)] public void MeasureBCL(object container) { var list = (System.Collections.Generic.List<int>)container; for (int i = 0; i < kIterations; i++) _ = list.Count == 0; } } Now, take our measurement code, and simply pass the IMyExampleBenchmark implementations into the MyExampleRunner<T> runner provided by the 'glue' layer. See the next section for the results of this work. Note [BenchmarkNameOverride] is used so that name formatting will look like \"NativeList\" rather than \"NativeMyListMeasurements\" in benchmark reports. That may have seemed like a lot of code to get to this point, but keep in mind in that once a 'glue' layer exists, it can be used for as many cases as fit. com.unity.collections has many, many performance and benchmarks tests built around a single (albeit more involved) intermediate 'glue' layer. [Benchmark(typeof(MyExampleType))] [BenchmarkNameOverride(\"List\")] class MyListMeasurements { [Test, Performance] [Category(\"Performance\")] public unsafe void IsEmpty_x_100k( [Values(0, 100)] int capacity, [Values] MyExampleType type) { MyExampleRunner<ListIsEmpty100k>.Run(capacity, type); } [Test, Performance] [Category(\"Performance\")] [BenchmarkTestFootnote(\"Incrementally reaching size of `growTo`\")] public unsafe void AddGrow( [Values(65536, 1024 * 1024)] int growTo, [Values] MyExampleType type) { MyExampleRunner<ListAddGrow>.Run(growTo, type); } [Test, Performance] [Category(\"Performance\")] public unsafe void Foreach( [Values(10000, 100000, 1000000)] int insertions, [Values] MyExampleType type) { MyExampleRunner<ListForEach>.Run(insertions, type); } } Example Results There are two clear results of the List performance tests implemented above The Test Runner in the Unity Editor will display the following Performance Test Framework tests. Note that with one implementation per type, there is both a burst compiled path and non-burst compiled path being measured. One could easily add others (such as burst compiled while safety on or off, or an UnsafeContainer variation of the same tests, though this would require a bit more 'glue' to integrate). Here is an example of the output: Running the Benchmark Example/Generate My Benchmarks menu item implemented above will generate a markdown report, again running the same single code path per type. Here is the output: Performance Comparison: Containers Example This file is auto-generated All measurments were taken on 12th Gen Intel(R) Core(TM) i9-12900K with 24 logical cores. To regenerate this file locally use: DOTS -> Unity.Collections -> Generate *** menu. Table of Contents Benchmark Results List Benchmark Results Example benchmark - 10 runs after 5 warmup runs Legend (B) = Burst Compiled (BCL) = Base Class Library implementation (such as provided by Mono or .NET) List Functionality NativeList NativeList (B) List (BCL) IsEmpty_x_100k(0)¹ 0.373ms (0.3x) \uD83D\uDFE0 0.089ms (1.1x) \uD83D\uDFE2 0.098ms (1.0x) IsEmpty_x_100k(100)¹ 0.334ms (0.3x) \uD83D\uDFE0 0.089ms (1.1x) \uD83D\uDFE2 0.098ms (1.0x) AddGrow(65536)³ 1.281ms (0.1x) \uD83D\uDFE0 0.427ms (0.3x) 0.144ms (1.0x) \uD83D\uDFE2 AddGrow(1048576)³ 21.435ms (0.1x) \uD83D\uDFE0 7.471ms (0.3x) 2.274ms (1.0x) \uD83D\uDFE2 Foreach(10000) 0.042ms (0.4x) \uD83D\uDFE0 0.003ms (6.6x) \uD83D\uDFE2 0.018ms (1.0x) Foreach(100000) 0.452ms (0.4x) \uD83D\uDFE0 0.025ms (7.4x) \uD83D\uDFE2 0.184ms (1.0x) Foreach(1000000) 4.500ms (0.4x) \uD83D\uDFE0 0.250ms (7.5x) \uD83D\uDFE2 1.877ms (1.0x) ¹ Optimizations were disabled to perform this benchmark ³ AddGrow(growTo) -- Incrementally reaching size of growTo Happy Benchmarking!"
  },
  "Library/PackageCache/com.unity.ext.nunit@031a54704bff/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@031a54704bff/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [2.0.5] - 2023-06-28 Fixing bug for InstanceID as struct changes [2.0.4] - 2023-06-21 Added support for InstanceID as struct changes [2.0.3] - 2022-05-31 Added unique test ID for repeated tests Added ContainKey and ContainValue constaints for dictionaries Fixed unexpected null exception when using EmptyConstraint with a null object [2.0.2] - 2021-10-19 STAR reviews updates. [2.0.1] - 2021-09-23 Minumum unity version lowered to 2019.4 [2.0.0] - 2021-06-23 Upgrade to dotnet 4.0 [1.0.6] - 2020-11-30 isExplicitlyReferenced set to 0 (case 1296162) [1.0.5] - 2020-11-04 Removed pdb files [1.0.4] - 2020-11-03 Added the portable-pdb (DSTR-37) [1.0.3] - 2020-10-30 Fixed being able to load mdb or portable-pdb symbolsbug (DSTR-37) Minimum unity version updated (case 1279253) [1.0.2] - 2019-12-04 Added missed metafiles [0.0.1] - 2019-02-21 This is the first release of Unity Package com.unity.ext.nunit. Migrated the custom version of nunit from inside of unity."
  },
  "Library/PackageCache/com.unity.ext.nunit@031a54704bff/Documentation~/ext.nunit.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@031a54704bff/Documentation~/ext.nunit.html",
    "title": "Custom Nunit manual | Inventory System",
    "summary": "Custom Nunit manual Package Summary A custom version of NUnit used by Unity Test Framework. Based on NUnit version 3.5 and works with all platforms, il2cpp and Mono AOT. See the NUnit documentation for more information."
  },
  "Library/PackageCache/com.unity.ext.nunit@031a54704bff/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@031a54704bff/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Custom Nunit copyright © 2019 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.ext.nunit@031a54704bff/README.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@031a54704bff/README.html",
    "title": "Custom Nunit build to work with Unity | Inventory System",
    "summary": "Custom Nunit build to work with Unity This version of nunit works with all platforms, il2cpp and Mono AOT. For Nunit Documentation: https://github.com/nunit/docs/wiki/NUnit-Documentation This source code for this packages lives at https://github.com/Unity-Technologies/nunit This custom Nunit is based on Nunit version 3.5, and it is precompiled for .NET 4.0. The uncompiled public version lives here https://github.com/Unity-Technologies/nunit."
  },
  "Library/PackageCache/com.unity.ext.nunit@031a54704bff/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@031a54704bff/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Nunit 3.5 License Type: \"MIT\" Copyright © 2018 Charlie Poole, Rob Prouse https://nunit.org/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/CHANGELOG.html",
    "title": "Code Editor Package for Rider | Inventory System",
    "summary": "Code Editor Package for Rider [3.0.36] - 2025-04-08 fix RIDER-124592 Avoid affecting \"Strip Engine Code\" while IL2CPP debug enabled [3.0.35] - 2025-03-05 fix RIDER-120306 RootNamespace is not generated for a csproj without cs files fix RIDER-121881 GetAllRiderPaths failed fix RIDER-122372 RiderPathLocator issue (found Rider installations duplicates on Linux) fix RIDER-122527 Open log in the Rider tab in Unity Editor doesn't work [3.0.34] - 2024-10-16 Bump Unity minimum supported version [3.0.33] - 2024-08-30 Improve UI performance [3.0.32] - 2024-08-30 Improved IL2CPP debugging by generating a custom link.xml during debug builds. RIDER-114406 Added support for debug_link.xml files, a debug-only version of link.xml. RIDER-114973 [3.0.28] - 2024-02-20 fix RIDER-103933 \"PlayerSettings.suppressCommonWarnings\" is not supported in Unity 2019.4.40f fix https://github.com/JetBrains/resharper-unity/issues/2431 and RIDER-104221 [3.0.27] - 2023-11-30 Restore the ability to select Rider installation from the custom location Fix possible extra project regeneration on moving focus from Rider to Unity Improve performance of code generation for very large projects [3.0.26] - 2023-10-04 https://github.com/JetBrains/resharper-unity/issues/2421 https://github.com/JetBrains/resharper-unity/issues/2422 [3.0.25] - 2023-08-18 unification of functionality to search JetBrains installations and open solution and file in Rider [3.0.22] - 2023-05-02 RIDER-82999 Unity's plugin SyncAll does not regenerate project files, and instead does basically nothing. #2401 Compilation issue with Unity 2021.3.0f1 [3.0.21] - 2023-04-18 RIDER-92424 JetBrains Rider Editor 3.0.20 package Update for Unity, Cause's Rider to Slows to a Crawl after updating RIDER-92419 JetBrains Rider Editor 3.0.20 for Unity has duplicate assemblies loaded into runtime [3.0.20] - 2023-04-05 fix loading Rider integration EditorPlugin on first switch of External Editor to Rider, see RIDER-91185 Keep the the PackageManager in sync with the Rider changes made to the manifest.json, it should help with RIDER-77343 Support CompilerOptions.RoslynAdditionalFilePaths and CompilerOptions.AnalyzerConfigPath [3.0.18] - 2023-01-09 RIDER-74818 Unity doesn't get to play mode if Editor is not running and user starts debug or profiling Improve performance of project generation - avoid using Directory.Exists avoid doing ProjectGeneration twice on the first start-up [3.0.17] - 2022-12-01 Avoid adding asset project parts to both editor and player projects, fixes the following issues: RIDER-75500 Local package references completions shows duplicate entries if player projects are generated RIDER-73795 Conversion to guid is not offered for assemblies with generated player projects RIDER-71238 No usages can be found for the assembly if player projects are generated [3.0.16] - 2022-09-09 Update the changelog Add folders to the generated csproj files Avoid extra RequestScriptReload call on the first start Fix shader support for folders in packages, but outside asmdef [3.0.15] - 2022-05-24 Cleanup cache after project generation to reduce memory consumption Performance optimization RIDER-76126 Rider package should generate an empty csproj for empty Unity project RIDER-77206 Unity 2020.1.3 'PlayerSettings' does not contain a definition for 'suppressCommonWarnings [3.0.14] - 2022-04-21 Move Rider package persisted state to Library, to avoid vcs collisions or adding it specifically to gitignore [3.0.13] - 2022-03-24 fix RIDER-69927 \"Test not run\" status is shown for the test suite when running unit tests for Unity project fix RIDER-74676 Unity plugin \"JetBrainseRider Editor\" completely breaks <= 2019.1.9 fix RIDER-71503 Unity Hang on \"Domain Unload\", caused by dispose of FileSystemWatcher [3.0.12] - 2022-01-28 Fix bug, which was introduced in 3.0.10: New script was not added to the csproj, because cached list of assemblies was used. [3.0.10] - 2021-12-09 Fix presentation of the TargetFramework in the csproj Fix: Auto-generated solution doesn't compile when code overrides virtual functions in other assemblies Fix RIDER-72234 Avoid full project generation, when only content of assembly was changed Fix RIDER-71985 Building large Unity projects randomly fails Fix RIDER-72174 Looking for Rider installed by dotUltimate installer [3.0.9] - 2021-11-09 Fix path for Roslyn analyser supplied with a package Minimal requirement for roslyn analyzer scope is Unity 2020.3.6f1 and above [3.0.8] - 2021-11-08 Technical release [3.0.7] - 2021-05-07 RIDER-60815 Simplify extensions lists for Rider package Fix csc.rsp -nullable+ / -nullable- parsing https://github.com/van800/com.unity.ide.rider/issues/7 Support -warnaserror/-warnaserror-:/-warnaserror+: in csc.rsp [3.0.6] - 2021-04-06 Fix bug: For Unity 2021.1+ Switching external editor from VS => Rider won't create the connection between Unity and Rider. When PlayerSettings.suppressCommonWarnings is true, it is reflected in the generated csproj with NoWarn \"0169\", \"0649\" By default include T4 templates in the generated solution (RIDER-37159) RIDER-60554 Unity crash in case of project without Unity Test Framework Package. RIDER-60445 Fix presentation of Rider external editor, when it is installed in a custom location. Improve project files generation performance RIDER-60508 Project Generation for projects without any cs files - add reference to UnityEditor/UnityEngine, so that Rider would detect Unity path and version and provide rich features for shader file. [3.0.5] - 2021-02-25 More stable in case of possible Rider product code change, improve test. Allows using \"Rider for Unreal\" with Unity projects (https://youtrack.jetbrains.com/issue/RIDER-51203) Remove implicit dependency to Test-Framework package Fix \"Unreachable code detected\" warning (https://youtrack.jetbrains.com/issue/RIDER-57930) [3.0.4] - 2021-01-26 Use LangVersion provided by Unity for generated csproj Improve documentation Support nullable provided in csc,rsp Avoid doing work in Unity secondary processes in UNITY_2021_1_OR_NEWER with UnityEditor.MPE.ProcessLevel.Secondary [3.0.3] - 2020-11-18 Update License Avoid connecting Rider from secondary UnityEditor instances Fix RIDER-53082 - Generate csproj without cs files, when there are any assets inside [3.0.2] - 2020-10-27 Speedup ProjectGeneration Fix RIDER-51958. Callbacks OnGeneratedCSProjectFiles would not work, but show a Warning instead. Remove release configuration Call RequestScriptReload, when External Editor is changed in Unity. [3.0.1] - 2020-10-02 RIDER-46658 Rider does not run PlayMode tests when ValueSource is combined with parameterized TestFixture RIDER-49947 Invoking PlayerSettings.SetScriptingDefineSymbolsForGroup() does not update definitions in Rider. Add static entrypoint Packages.Rider.Editor.RiderScriptEditor.SyncSolution to allow generating solution from commandline. [2.0.7] - 2020-08-18 Improve performance Add support for asmdef Root Namespace in .csproj generation ProjectGeneration for custom roslyn analysers https://docs.unity3d.com/2020.2/Documentation/Manual/roslyn-analyzers.html Switch target platform in Unity would regenerate csproj files (https://github.com/JetBrains/resharper-unity/issues/1740) [2.0.6] - 2020-08-10 Improve performance Add support for asmdef Root Namespace in .csproj generation ProjectGeneration for custom roslyn analysers https://docs.unity3d.com/2020.2/Documentation/Manual/roslyn-analyzers.html Switch target platform in Unity would regenerate csproj files (https://github.com/JetBrains/resharper-unity/issues/1740) [2.0.5] - 2020-05-27 Fix Regression in 2.0.3: In Unity 2019.2.9 on Mac, changing csproj and calling AssetDatabase.Refresh is not regenerating csproj. Regenerate projects on changes in manifest.json and Project Settings (EditorOnlyScriptingUserSettings.json) (#51) Fix: Assembly references to package assemblies break IDE projects. Fix: Reporting test duration. [2.0.2] - 2020-03-18 fix bug in searching Rider path on MacOS [2.0.1] - 2020-03-05 Speed improvements, ProjectTypeGuids for unity-generated project Improve UI for Project Generation settings Changes in csc.rsp would cause project-generation Remove NoWarn 0169 from generated csproj Support custom JetBrains Toolbox installation location [1.2.1] - 2019-12-09 Load optimised EditorPlugin version compiled to net 461, with fallback to previous version. On ExternalEditor settings page: reorder Generate all ... after Extensions handled Better presentation for Rider of some version in ExternalEditors list Initial support for Code Coverage with dotCover plugin in Rider Added support for Player Project generation [1.1.4] - 2019-11-21 Fix warning - unreachable code [1.1.3] - 2019-10-17 Update External Editor, when new toolbox build was installed Add xaml to default list of extensions to include in csproj Avoid initializing Rider package in secondary Unity process, which does Asset processing Reflect multiple csc.rsp arguments to generated csproj files: https://github.com/JetBrains/resharper-unity/issues/1337 Setting, which allowed to override LangVersion removed in favor of langversion in csc.rsp Environment.NewLine is used in generated project files instead of Windows line separator. [1.1.2] - 2019-09-18 performance optimizations: avoid multiple evaluations avoid reflection in DisableSyncSolutionOnceCallBack project generation optimization fixes: avoid compilation error with incompatible Test Framework package [1.1.1] - 2019-08-26 parse nowarn in csc.rsp warning, when Unity was started from Rider, but external editor was different improved unit test support workaround to avoid Unity internal project-generation (fix #28) [1.1.0] - 2019-07-02 new setting to manage list of extensions to be opened with Rider avoid breaking everything on any unhandled exception in RiderScriptEditor cctor hide Rider settings, when different Editor is selected dynamically load only newer rider plugins path detection (work on unix symlinks) speed up for project generation lots of bug fixing [1.0.8] - 2019-05-20 Fix NullReferenceException when External editor was pointing to non-existing Rider everything was broken by null-ref. [1.0.7] - 2019-05-16 Initial migration steps from rider plugin to package. Fix OSX check and opening of files. [1.0.6] - 2019-04-30 Ensure asset database is refreshed when generating csproj and solution files. [1.0.5] - 2019-04-27 Add support for generating all csproj files. [1.0.4] - 2019-04-18 Fix relative package paths. Fix opening editor on mac. [1.0.3] - 2019-04-12 Fixing null reference issue for callbacks to Asset pipeline. [1.0.2] - 2019-01-01 This is the first release of Unity Package rider_editor. Using the newly created api to integrate Rider with Unity."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/CONTRIBUTING.html",
    "title": "Contributing | Inventory System",
    "summary": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions. Once you have a change ready following these ground rules. Simply make a pull request How to contribute The main working branch is next/master-3.0. All pull requests should target this branch when trying to land. Once all changes needed for a version release lands in next/master-3.0, a release branch can be made. The version release branch should be named release/3.0.x, where x is a version bump from previous version. This branch must target release/3.0. Also, it needs to contain the version bump in necessary files and updated changelog. Once the version release branch lands in release/3.0, the new package version is ready to release."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/README.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/README.html",
    "title": "Code Editor Package for Rider | Inventory System",
    "summary": "Code Editor Package for Rider This package is not intended to be modified by users. Nor does it provide any api intended to be included in user projects."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "About JetBrains Rider Editor Using the JetBrains Rider Editor package"
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/index.html",
    "title": "About JetBrains Rider Editor | Inventory System",
    "summary": "About JetBrains Rider Editor The JetBrains Rider editor package integrates support for the JetBrains Rider .NET Integrated Development Environment (IDE), into the Unity Editor. This package provides an end-point for Rider to call different Unity APIs and to generate .csproj and .sln files, which Rider uses to implement support for Unity in its plug-in. This package ensures that IDE features like autocomplete suggestions and flagging dependency conflicts work in Rider. It uses .cproj and .sln files which store information about your project such as: Versioning information Build files Platform requirements Web server or database settings Not all code in Unity is directly visible to code editors, particularly when using packages. This is because packages don’t provide their own .csproj files, and Unity doesn’t create them for installed packages by default. This means that IDE features like autocomplete suggestions and flagging dependency conflicts do not work with code in these packages. The purpose of this package is to produce the .csproj files that make these features possible by default when you use Rider. Installation As of Unity version 2019.2, this package comes as a part of the default Unity installation. If you are updating your project from an older version of Unity, you might need to install this package via the Package Manager. Requirements This version of the JetBrains Rider editor package is compatible with the following versions of the Unity Editor: 2019.2.6 or later To use this package, you must have the following third-party products installed: JetBrains Rider version 2019.3 or newer For more information about the Rider IDE, see the JetBrains Rider documentation. Submitting issues This package is maintained by JetBrains and Unity. Submit issues to the JetBrains/resharper-unity/issues GitHub page. Unity intends for this package to become accessible to the public on GitHub in the future."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/using-the-jetbrains-rider-editor-package.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/Documentation~/using-the-jetbrains-rider-editor-package.html",
    "title": "Using the JetBrains Rider Editor package | Inventory System",
    "summary": "Using the JetBrains Rider Editor package To use the package, go to Edit > Preferences > External Tools, click on the External Script Editor dropdown menu and select your version of Rider. When you select this option, the window reloads. After the window reloads, new settings that control production of .csproj files become available. External Tools tab in the Preferences window Commandline endpoints Q: Generate sln/csproj files for CI? A: Unity -batchmode -quit -projectPath ProjectPath -executeMethod Packages.Rider.Editor.RiderScriptEditor.SyncSolution Q: Generate sln/csproj and open External Editor? A: Unity -batchmode -quit -projectPath ProjectPath -executeMethod Packages.Rider.Editor.RiderScriptEditor.SyncSolutionAndOpenExternalEditor Package preferences Property: Description: Extensions handled This field lists the file extensions that open in JetBrains Rider. This field contains a variety of extensions by default. Generate .csproj files for: Each setting in this list enables or disables production of .csproj files for a different type of package. The Regenerate project files button updates existing .csproj files and creates the necessary new ones based on the settings you choose. These settings control whether to generate .csproj files for any installed packages. For more information on how to install packages, see the Adding and removing packages documentation. __ Embedded packages__ Any package that appears under your project’s Packages folder is an embedded package. An embedded package is not necessarily built-in; you can create your own packages and embed them inside your project. This setting is enabled by default. For more information on embedded packages, see the Embedded dependencies documentation. __ Local packages__ Any package that you install from a local repository stored on your machine, but from outside of your Unity project. This setting is enabled by default. __ Registry packages__ Any package that you install from either the official Unity registry or a custom registry. Packages in the Unity registry are available to install directly from the Package Manager. For more information about the Unity package registry, see the Package Registry section of the Unity Package Manager documentation. For information on creating and using custom registries in addition to the Unity registry, see the Scoped package registries documentation. __ Git packages__ Any package you install directly from a Git repository using a URL. __ Built-in packages__ Any package that is already installed as part of the default Unity installation. __ Tarball packages__ Any package you install from a GZip tarball archive on the local machine, outside of your Unity project. __ Unknown packages__ Any package which Unity cannot determine an origin for. This could be because the package doesn’t list its origin, or that Unity doesn’t recognize the origin listed. Player projects For each player project, generate an additional .csproj file named 'originalProjectName.Player.csproj'. This allows different project types to have their code included in Rider’s systems, such as assembly definitions or testing suites. This package also adds a second tab under Preferences named Rider, pictured below. Rider tab in the Preferences window Note The Logging Level menu does not control the level of Unity's logging, only the level of log messages that Rider package logs in its own log file. For more information on controlling Unity's logging level, see the Stack Trace Logging section of the Console Window documentation. Property: Description: Pass Console to Rider If Pass Console to Rider is enabled, Rider can access data that Unity sends to the Unity Console and display it within its own environment instead. Log file The Log file field contains an Open log button. Select this button to open the log file inside the Rider IDE. This button is unavailable when Logging Level is set to OFF. Logging Level The Logging Level menu controls how detailed are the Rider package logs. Those logs may be used for troubleshooting communication between Rider and Unity. Rider package logs all messages of the type you select as well as any messages of a more severe type. For example, if you choose WARN, then Rider logs all ERROR and FATAL messages as well as WARN messages. The message types are listed below in order of severity, with FATAL as the most severe type of message and TRACE as the least severe. OFF Rider does not produce any logs. **FATAL Logs information relating to serious problems that cause the application to crash. This setting produces the smallest logs. ERROR Logs information about errors that prevent some functionality from working, but don’t cause the application to fail (for example, a failed database connection). WARN Logs information about possible problems, or any unusual behaviour. Warnings don’t indicate that something has gone wrong, but that Unity detects something that might potentially cause an issue if not investigated. INFO Logs information about normal operation of the application, such as a successful database connection attempt. VERBOSE Logs detailed but not exhaustive information about your code. This setting is helpful for checking how your code executes or providing diagnostic information for other developers. TRACE Logs as much information about the application as possible. This can create a very large and detailed log, so it’s good practice to only use it when attempting to find the cause of a specific issue with your code."
  },
  "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@4d374c7eb6db/LICENSE.html",
    "title": "| Inventory System",
    "summary": "JetBrains Rider Editor copyright © 2025 Unity Technologies MIT License Copyright (c) 2019 Unity Technologies Copyright (c) 2019 JetBrains s.r.o. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/CHANGELOG.html",
    "title": "Code Editor Package for Visual Studio | Inventory System",
    "summary": "Code Editor Package for Visual Studio [2.0.23] - 2025-02-03 Integration: Monitor additionalfile extension by default. Try opening a Visual Studio Code workspace if there's one (.code-workspace file in the Unity project). Project generation: Identify asset, meta, prefab and unity files as yaml (Visual Studio Code). Add sln/csproj file nesting (Visual Studio Code). Improve SDK style project generation. [2.0.22] - 2023-10-03 Integration: Add support for XDG_DATA_DIRS and .desktop files on Linux for VS Code discovery. Use compile-time platform-specifics instead of using runtime conditions. Project generation: Suppress USG0001 warnings. Mark referenced assemblies as private (to not copy extra files to output directory when building). Add Unity capability to SDK-Style projects. Prevent circular dependency errors with SDK-Style projects. [2.0.21] - 2023-09-05 Integration: Only disable the legacy com.unity.ide.vscode package going forward. Fix json parsing issues with specific non-UTF code pages. Project generation: Target netstandard2.1 instead of netstandard2.0. Set defaultSolution in settings.json. Remove files.exclude entries for root csproj and sln files in settings.json when needed. Add vstuc launch configuration to launch.json when needed. Add visualstudiotoolsforunity.vstuc entry to extensions.json when needed. You can prevent the package from patching those configuration files by creating a .vscode/.vstupatchdisable file. [2.0.20] - 2023-06-27 Integration: Internal API refactoring. Add support for Visual Studio Code. Project generation: Add support for Sdk Style project generation. Fix an issue related to missing properties with 2021.3. [2.0.18] - 2023-03-17 Integration: Performance improvements with EditorApplication.update callbacks. Project generation: Add extra compiler options for analyzers and source generators. [2.0.17] - 2022-12-06 Integration: Fix rare deadlocks while discovering or launching Visual Studio on Windows. Improve launching Visual Studio on macOs. Project generation: Include analyzers from response files. Update supported C# versions. Performance improvements. [2.0.16] - 2022-06-08 Integration: Prevent ADB Refresh while being in safe-mode with a URP project Fixed an issue keeping the progress bar visible even after opening a script with Visual Studio. [2.0.15] - 2022-03-21 Integration: Improved project generation performance. Added support for keeping file/folder structure when working with external packages. Fixed project generation not being refreshed when selecting Visual Studio as the preferred external editor. [2.0.14] - 2022-01-14 Integration: Remove package version checking. [2.0.13] - 2022-01-12 Integration: Fixed wrong path to analyzers in generated projects when using external packages. Fixed selective project generation not creating Analyzer/LangVersion nodes. Fixed asmdef references with Player projects. Documentation: Added new documentation including ToC, overview, how to use and images. [2.0.12] - 2021-10-20 Integration: Do not block asset opening when only a VS instance without a loaded solution is found. Only check package version once per Unity session. Improved support for Visual Studio For Mac 2022. [2.0.11] - 2021-07-01 Integration: Added support for Visual Studio and Visual Studio For Mac 2022. Fixed an issue when the package was enabled for background processes. Project generation: Use absolute paths for Analyzers and rulesets. [2.0.10] - 2021-06-10 Project generation: Improved project generation performance when a file is moved, deleted or modified. Integration: Improved Inner-loop performance by avoiding to call the package manager when looking up vswhere utility. Fixed a network issue preventing the communication between Visual Studio and Unity on Windows. [2.0.9] - 2021-05-04 Project generation: Added support for CLI. Integration: Improved performance when discovering Visual Studio installations. Warn when legacy assemblies are present in the project. Warn when the package version is not up-to-date. [2.0.8] - 2021-04-09 Project generation: Improved generation performance (especially with DOTS enabled projects). Improved stability. Updated Analyzers lookup strategy. Fixed .vsconfig file not generated when using \"regenerate all\". Integration: Improved automation plugins. Documentation: Open sourced automation plugins. [2.0.7] - 2021-02-02 Integration: Remove com.unity.nuget.newtonsoft-json dependency in favor of the built-in JsonUtility for the VS Test Runner. [2.0.6] - 2021-01-20 Project generation: Improved language version detection. Integration: Added support for the VS Test Runner. Added initial support for displaying asset usage. Fixed remaining issues with special characters in file/path. [2.0.5] - 2020-10-30 Integration: Disable legacy pdb symbol checking for Unity packages. [2.0.4] - 2020-10-15 Project generation: Added support for embedded Roslyn analyzer DLLs and ruleset files. Warn the user when the opened script is not part of the generation scope. Warn the user when the selected Visual Studio installation is not found. Generate a .vsconfig file to ensure Visual Studio installation is compatible. Integration: Fix automation issues on MacOS, where a new Visual Studio instance is opened every time. [2.0.3] - 2020-09-09 Project generation: Added C#8 language support. Added UnityProjectGeneratorVersion property. Local and Embedded packages are now selected by default for generation. Added support for asmdef root namespace. Integration: When the user disabled auto-refresh in Unity, do not try to force refresh the Asset database. Fix Visual Studio detection issues with languages using special characters. [2.0.2] - 2020-05-27 Added support for solution folders. Only bind the messenger when the VS editor is selected. Warn when unable to create the messenger. Fixed an initialization issue triggering legacy code generation. Allow package source in assembly to be generated when referenced from asmref. [2.0.1] - 2020-03-19 When Visual Studio installation is compatible with C# 8.0, setup the language version to not prompt the user with unsupported constructs. (So far Unity only supports C# 7.3). Use Unity's TypeCache to improve project generation speed. Properly check for a managed assembly before displaying a warning regarding legacy PDB usage. Add support for selective project generation (embedded, local, registry, git, builtin, player). [2.0.0] - 2019-11-06 Improved Visual Studio and Visual Studio for Mac automatic discovery. Added support for the VSTU messaging system (start/stop features from Visual Studio). Added support for solution roundtrip (preserves references to external projects and solution properties). Added support for VSTU Analyzers (requires Visual Studio 2019 16.3, Visual Studio for Mac 8.3). Added a warning when using legacy pdb symbol files. Fixed issues while Opening Visual Studio on Windows. Fixed issues while Opening Visual Studio on Mac. [1.1.1] - 2019-05-29 Fix Bridge assembly loading with non VS2017 editors. [1.1.0] - 2019-05-27 Move internal extension handling to package. [1.0.11] - 2019-05-21 Fix detection of visual studio for mac installation. [1.0.10] - 2019-05-04 Fix ignored comintegration executable. [1.0.9] - 2019-03-05 Updated MonoDevelop support, to pass correct arguments, and not import VSTU plugin. Use release build of COMIntegration for Visual Studio. [1.0.7] - 2019-04-30 Ensure asset database is refreshed when generating csproj and solution files. [1.0.6] - 2019-04-27 Add support for generating all csproj files. [1.0.5] - 2019-04-18 Fix relative package paths. Fix opening editor on mac. [1.0.4] - 2019-04-12 Fixing null reference issue for callbacks to AssetPostProcessor. Ensure Path.GetFullPath does not get an empty string. [1.0.3] - 2019-01-01 This is the first release of Unity Package visualstudio_editor. Using the newly created api to integrate Visual Studio with Unity."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/CONTRIBUTING.html",
    "title": "Contributing | Inventory System",
    "summary": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) and Microsoft Contributor License Agreement (CLA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA and CLA, including that your contributions are your original creation and that you have complete right and authority to make your contributions. Once you have a change ready following these ground rules. Simply make a pull request"
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/README.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/README.html",
    "title": "Code Editor Package for Visual Studio | Inventory System",
    "summary": "Code Editor Package for Visual Studio This package is not intended to be modified by users. Nor does it provide any api intended to be included in user projects."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "About Visual Studio Editor Using the Visual Studio Editor package"
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/index.html",
    "title": "Code Editor Package for Visual Studio | Inventory System",
    "summary": "Code Editor Package for Visual Studio About Visual Studio Editor The Visual Studio Editor package provides the Unity Editor with support for Unity-specific features from the Visual Studio Tools for Unity extension in Visual Studio and the Unity for Visual Studio Code extension in Visual Studio Code. These include IntelliSense auto-complete suggestions, C# editing, and debugging. Installation This package is a built-in package and installed by default. Note: If you’re using a version of the Unity Editor before 2019.4, you’ll need to install this package through the package manager. Requirements This version of the Visual Studio Editor package is compatible with the following versions of the Unity Editor: 2019.4 and later To use this package, you must have the following third-party products installed: On Windows: Visual Studio 2019 version 16.9 or newer with Visual Studio Tools for Unity 4.0.9 or newer. On macOS: Visual Studio Code with Unity for Visual Studio Code 0.9.0 or newer. For more information on using Visual Studio with Unity, refer to Microsoft's Visual Studio Tools for Unity documentation. For more information on using VS Code with Unity, refer to the Visual Studio Code Unity development with VS code documentation. Submitting issues This package is maintained by Microsoft and Unity. Submit issues directly from the Help menu in Visual Studio (Help > Submit Feedback > Report a Problem) or Visual Studio Code (Help > Report an Issue). Unity will make this package accessible to the public on GitHub in the future."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/using-visual-studio-editor.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/Documentation~/using-visual-studio-editor.html",
    "title": "Using the Visual Studio Editor package | Inventory System",
    "summary": "Using the Visual Studio Editor package To use the package, go to Edit > Preferences > External Tools > External Script Editor and select the version of Visual Studio you have installed. When you select this option, the window reloads and displays settings that control production of .csproj files. Generate .csproj files Each setting in the table below enables or disables the production of .csproj files for a different type of package.When you click Regenerate project files, Unity updates the existing .csproj files and creates the necessary new ones based on the settings you choose. These settings control whether to generate .csproj files for any installed packages. For more information on how to install packages, see Adding and removing packages. Property Description Embedded packages Any package that appears under your project’s Packages folder is an embedded package. An embedded package is not necessarily built-in; you can create your own packages and embed them inside your project. This setting is enabled by default. For more information on embedded packages, see Embedded dependencies. Local packages Any package that you install from a local repository stored on your machine, but from outside of your Unity project. This setting is enabled by default. Registry packages Any package that you install from either the official Unity registry or a custom registry. Packages in the Unity registry are available to install directly from the Package Manager. For more information about the Unity package registry, see The Package Registry section of the Unity Package Manager documentation. For information on how to create and use custom registries in addition to the Unity registry, see Scoped package registries. Git packages Any package you install directly from a Git repository using a URL. Built-in packages Any package that is already installed as part of the default Unity installation. Tarball packages Any package you install from a GZip tarball archive on the local machine, outside of your Unity project. Unknown packages Any package which Unity cannot determine an origin for. This could be because the package doesn’t list its origin, or that Unity doesn’t recognize the origin listed. Player projects For each player project, generate an additional .csproj file named ‘originalProjectName.Player.csproj’. This allows different project types to have their code included in Visual Studio’s systems, such as assembly definitions or testing suites."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/LICENSE.html",
    "title": "| Inventory System",
    "summary": "MIT License Copyright (c) 2019 Unity Technologies Copyright (c) 2019 Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/ThirdPartyNotices.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@198cdf337d13/ThirdPartyNotices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: VSWhere License Type: \"MIT\" The MIT License (MIT) Copyright (C) Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: benbuck/EnvDTE License Type: Zero-Clause BSD Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to the input system package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. Due to package verification, the latest version below is the unpublished version and the date is meaningless. however, it has to be formatted properly to pass verification tests. [1.14.0] - 2025-03-20 Fixed Fixed an issue where all action maps were enabled initially for project wide actions, which overrode the PlayerInput action map configuration. ISXB-920 Fixed an issue where ButtonStates are not fully updated when switching SingleUnifiedPointer. ISXB-1356 Fixed errors when pasting composite parts into non-composites. ISXB-757 Changed Changed enum value Key.IMESelected to obsolete which was not a real key. Please use the ButtonControl imeSelected. Added Added support of F13-F24 keys. UUM-44328 [1.13.1] - 2025-02-18 Fixed Fixed a problem with the logic to get the active player settings object that cause an infinit reimport loop. ISXB-1430 Fixed an issue where removing a newly created action in the Asset Editor would cause an exception. UUM-95693 Fixed arrow key navigation of Input Actions after Action rename. ISXB-1024 Fixed gamepad navigation in UI Toolkit TextField when using InputSystemUIInputModule. UUM-77364 Fixed issue where asset editor window splitter positions were not persisted [ISXB-1316] Fixed an issue where updating the InputSystem outside of the dynamic Update would lead to UI input and navigation events get lost. ISXB-1313 Fixed a bug that would cause TrackedPoseDriver to update position and rotation when no HMD device is connected ISXB-699 instead of keeping it unchanged. Changed Changed default input action asset name from New Controls to New Actions. Added disabling of action maps in rebinding UI sample. Added An alternative way to access if an action state reached a certain phase during this rendering frame (Update()). This can be utilized even if the InputSystem update mode is set to manual or FixedUpdate. It can be used to access the action phase during rendering, eg for perform updates to the UI. Added Added achievable average frequency diagnostic to Input Debugger device window (along with sensor frequency and global polling frequency information). Added processing delay input system latency (average, minimum, maximum) diagnostics to Input Bugger device window. [1.13.0] - 2025-02-05 Fixed Fixed an issue where the prompt to enable the InputSystem backends would interrupt the import of large assets. Fixed Cut Mode for Action Maps and Actions to make renaming disabled. ISXB-1155 Fixed GamepadButton.LeftTrigger and GamepadButton.RightTrigger enum values not matching displayed dropdown values in editor when using GamepadButtonPropertyDrawer ISXB-1270. Fixed an issue causing InvalidOperationException when entering playmode with domain reload disabled. ISXB-1208. Fixed an issue where compiling Addressables with Input System package present would result in failed compilation due to IInputAnalytic.TryGatherData not being defined ISXB-1203. Pinned Touch Samples sample package dependencies to avoid errors with Cinemachine 3.x and Probuilder 6.x. ISXB-1245 Fixed issue where a binding path is sometimes not saved when chosen from the binding path picker. ISXB-1221 Fixed an issue where dropdown menu for Path in Input Actions Editor could not be selected from any button position. ISXB-1309 Fixed an issue where changing Input System default parameter settings with the editor open would result in changes in the editor. ISXB-1351 [1.12.0] - 2025-01-15 Fixed Fixed an issue causing the Action context menu to not show on right click when right clicking an action in the Input Action Editor ISXB-1134. Reverted changes from 0ddd534d8 (ISXB-746) which introduced a regression ISXB-1127. Fixed ArgumentNullException: Value cannot be null. during the migration of Project-wide Input Actions from InputManager.asset to InputSystem_Actions.inputactions asset which lead do the lost of the configuration ISXB-1105. Fixed pointerId staying the same when simultaneously releasing and then pressing in the same frame on mobile using touch. ISXB-1006. Fixed ISubmitHandler.OnSubmit event processing when operating in Manual Update mode (ISXB-1141). Fixed Rename mode is not entered and name is autocompleted to default when creating a new Action Map on 2022.3. ISXB-1151. Fixed unexpected control scheme switch when using OnScreenControl and pointer based schemes which registed \"Cancel\" event on every frame.ISXB-656. Fixed an issue with The \"Add Control Scheme...\" popup window so that it now persists until any changes are explicitly Saved or Cancelled case ISXB-1131. Fixed missing documentation for source generated Input Action Assets. This is now generated as part of the source code generation step when \"Generate C# Class\" is checked in the importer inspector settings. Fixed pasting into an empty map list raising an exception. ISXB-1150 Fixed pasting bindings into empty Input Action asset. ISXB-1180 Fixed missing '&' symbol in Control Scheme dropdown on Windows platform. ISXB-1109 Fixed icon scaling in Input Actions window. Fixed an issue where removing the InputSystem package could lead to invalid input handling settings. Fixed ArgumentOutOfRangeException when adding a new Control Scheme with any Device selected. ISXB-1129 Fixed a CS0105 compiler warning due to duplicate using statement in test source code (ISXB-1247). Fixed tooltip support in the UI Toolkit version of the Input Actions Asset editor. Fixed documentation to clarify bindings with modifiers overrideModifiersNeedToBePressedFirst configuration ISXB-806. Fixed an issue in Samples/Visualizers/GamepadVisualizer.unity sample where the visualization wouldn't handle device disconnects or current device changes properly (ISXB-1243). Fixed an issue when displaying Serialized InputAction's Processor properties inside the Inspector window. ISXB-1269 Fixed an issue with default device selection when adding new Control Scheme. Fixed an issue where action map delegates were not updated when the asset already assigned to the PlayerInput component were changed ISXB-711. Fixed Action properties edition in the UI Toolkit version of the Input Actions Asset editor. ISXB-1277 Fixed an editor crash caused by input debugger device state window reusing cached state when reconnecting Stadia controller. ISXB-658 Fixed an issue where batch jobs would fail with \"Error: Error building Player because scripts are compiling\" if a source generated .inputactions asset is out of sync with its generated source code (ISXB-1300). Fixed multiple OnScreenStick Components that does not work together when using them simultaneously in isolation mode. ISXB-813 Fixed an issue in input actions editor window that caused certain fields in custom input composite bindings to require multiple clicks to action / focus. ISXB-1171 Fixed an editor/player hang in InputSystemUIInputModule due to an infinite loop. This was caused by the assumption that RemovePointerAtIndex would always successfully remove the pointer, which is not the case with touch based pointers. ISXB-1258 Fixed wrong Xbox Series S|X and Xbox One wireless controllers \"View\" button mapping on macOS by expanding device PID and VID matching. ISXB-1264 Changed Changed location of the link xml file (code stripping rules), from a temporary directory to the project Library folder (ISX-2140). Added back the InputManager to InputSystem project-wide asset migration code with performance improvement (ISX-2086). Changed OnScreenControl to automaticaly switch, in Single Player with autoswitch enabled, to the target device control scheme when the first component is enabled to prevent bad interactions when it start. Changed paremeter overrideModifiersNeedToBePressedFirst to obsolete for ButtonWithOneModifier, ButtonWithTwoModifiers, OneModifierComposite and TwoModifiersComposite in favour the new modifiersOrder parameter which is more explicit. Changed Samples/Visualizers/GamepadVisualizer.unity to visualize the control values of the current device instead of the first device. Added Added new API InputSystem.settings.useIMGUIEditorForAssets that should be used in custom InputParameterEditor that use both IMGUI and UI Toolkit. Added ProfilerMakers to InputAction.Enable() and InputActionMap.ResolveBindings() to enable gathering of profiling data. Added throwing an error message when trying to use the Input System package on console without the extension package installed. [1.11.2] - 2024-10-16 Fixed Fixed touch pointers being released twice causing an index out of bounds error. ISXB-687 Fixed NullReferenceException from disconnecting and reconnecting a GXDKGamepad. Fixed wrong mapping of Xbox Series S|X and Xbox One wireless controllers \"View\" button on macOS.ISXB-385 Fixed \"AnalyticsResult\" errors on consoles [ISXB-1107] Fixed wrong Display Index value for touchscreen events.ISXB-1101 Fixed event handling when using Fixed Update processing where WasPressedThisFrame could appear to true for consecutive frames ISXB-1006 Removed a redundant warning when using fallback code to parse a HID descriptor. (UUM-71260) Added Added the display of the device flag CanRunInBackground in device debug view. Added analytics for programmatic InputAction setup via InputActionSetupExtensions when exiting play-mode. Changed Removed the InputManager to InputSystem project-wide asset migration code for performance improvement (ISX-2086) [1.11.1] - 2024-09-26 Fixed Fixed Multiple interactions could breaks on Composite Binding. ISXB-619 Fixed memory leak when the OnScreenStick component was destroyed ISXB-1070. Contribution by LukeUnityDev. Fixed Action Maps contextual menu in Action Editor UI that occasionally displays unrelated items. Fixed \"MissingReferenceException\" errors when closing an in-game dropdown field ISXB-1081. Fixed potential crash on Mac when using stale references to deleted InputDevice objects ISXB-606. Fixed conditional compilation for non-editor analytics on platforms not enabling analytics. Fixed simulated touch input not working with PlayerInput component ISXB-483. Fixed unused PenState information to determine the displayIndex on platforms providing it. (PLAT-10123) Changed Renamed editor Resources directories to PackageResources to fix package validation warnings. Changed representation of GamepadButton enum values in Inspector to display aliased enum values as a single item to avoid confusion around selection and aliased value display when multiple enum items map to the same numerical value. ISXB-543 PlayerInput component now warns if the system cannot find matching control scheme, which can occur if all control schemes already paired (e.g. to other game objects with PlayerInput components) ISXB-1020 [1.11.0] - 2024-09-10 Fixed Fixed memory allocation on every frame when using UIDocument without EventSystem. ISXB-953 Fixed Action Maps name edition which could be inconsistent in Input Action Editor UI. Fixed InputDeviceTester sample only visualizing a given touch contact once. ISXB-1017 Fixed an update loop in the asset editor that occurs when selecting an Action Map that has no Actions. Fixed Package compilation when Unity Analytics module is not enabled on 2022.3. ISXB-996 Fixed 'OnDrop' event not called when 'IPointerDownHandler' is also listened. ISXB-1014 Fixed InputSystemUIInputModule calling pointer events on parent objects even when the \"Send Pointer Hover To Parent\" is off. ISXB-586 Improved performance of disconnected device activation (ISX-1450) Fixed DualSense controllers being recognized as DualShock4 (ISX-1411) Changed Use ProfilerMarker instead of Profiler.BeginSample and Profiler.EndSample when appropriate to enable recording of profiling data. Added Added Hinge Angle sensor support for foldable devices. Added InputDeviceMatcher.WithManufacturerContains(string noRegexMatch) API to improve DualShockSupport.Initialize performance (ISX-1411) Added tests for Input Action Editor UI for managing action maps (List, create, rename, delete) (ISX-2087) Added automatic loading of custom extensions of InputProcessor, InputInteraction and InputBindingComposite [ISXB-856]](https://issuetracker.unity3d.com/product/unity/issues/guid/ISXB-856). Added an IME Input sample scene. [1.10.0] - 2024-07-24 Fixed Fixed default scroll speed in uGUI being slower than before. ISXB-766 Fixed selection state preserving after a save operation. ISXB-966 Fixed an issue when multiple interactions drive an action and perform during the cancelation of the current active interaction ISXB-310. Fixed an issue when generating C# class of Input Actions that contain an action map named Debug ISXB-851. Fixed ArgumentNullException thrown when accessing Action's bindings after changing Composite part. ISXB-494. Added Added InputSystemUIInputModule.scrollDeltaPerTick property, a customizable multiplicative factor applied to the scroll wheel speed before it is sent to UI components. Note that this has no effect on UI Toolkit content, only uGUI. [1.9.0] - 2024-07-15 Changed Added warning messages to both OnScreenStick and OnScreenButton Inspector editors that would display a warning message in case on-screen control components are added to a GameObject not part of a valid UI hierarchy. Changed behavior for internal feature flag relating to Windows Gaming Input to be ignored on non-supported platforms. Changed DualSenseHIDInputReport from internal to public visibility Added Input Setting option allowing to keep platform-specific scroll wheel input values instead of automatically converting them to a normalized range. Fixed Avoid potential crashes from NullReferenceException in FireStateChangeNotifications. Fixed cases where wasPressedThisFrame would not return true if a press and release happened within the same frame before being queried (and vice versa for wasReleasedThisFrame). Fixed an issue where a composite binding would not be consecutively triggered after ResetDevice() has been called from the associated action handler ISXB-746. Fixed resource designation for \"d_InputControl\" icon to address CI failure. Fixed an issue where a composite binding would not be consecutively triggered after disabling actions while there are action modifiers in progress ISXB-505. Fixed prefabs and missing default control scheme used by PlayerInput component are now correctly shown in the inspector ISXB-818. Fixed error thrown when Cancelling Control Scheme creation in Input Actions Editor. Fixed Scheme Name in Control Scheme editor menu that gets reset when editing devices ISXB-763. Fixed an issue where InputActionAsset.FindAction(string, bool) would throw System.NullReferenceException instead of returning null if searching for a non-existent action with an explicit action path and using throwIfNotFound: false, e.g. searching for \"Map/Action\" when InputActionMap \"Map\" exists but no InputAction named \"Action\" exists within that map ISXB-895. Fixed scroll speed being slower when using InputSystemUIInputModule instead of StandaloneInputModule. (https://jira.unity3d.com/browse/ISXB-771) Fixed an issue where adding a OnScreenButton or OnScreenStick to a regular GameObject would lead to exception in editor. Fixed an issue where adding a OnScreenStick to a regular GameObject and entering play-mode would lead to exceptions being generated. Fixed InputActionReference issues when domain reloads are disabled ISXB-601, ISXB-718, ISXB-900 Fixed a performance issue with many objects using multiple action maps ISXB-573. Fixed an variable scope shadowing issue causing compilation to fail on Unity 2019 LTS. Fixed an issue where changing InputSettings instance would not affect associated feature flags. Submit and Cancel UI actions will now respect configured interactions. ISXB-841. Fixed the UI generation of enum fields when editing interactions of action properties. The new selected value was lost when saving. Fixed the UI generation of custom interactions of action properties when it rely on OnGUI callback. ISXB-886. Fixed deletion of last composite part raising an exception. ISXB-804 Fixed an issue related to Visualizers sample where exceptions would be thrown by InputActionVisualizer and InputControlVisualizer when entering play-mode if added as components to a new GameObject. Fixed an issue with InputAction Asset editor where invalid ControlScheme names with only spaces could be entered. ISXB-547. Fixed deletion of last composite part raising an exception. ISXB-804 Added Added additional device information when logging the error due to exceeding the maximum number of events processed set by InputSystem.settings.maxEventsBytesPerUpdate. This additional information is available in development builds only. Expanded editor and build insight analytics to cover ``.inputactionsasset editor usage,InputSettings` and common component configurations. Added Input Setting option allowing to keep platform-specific scroll wheel input values instead of automatically converting them to a normalized range. [1.8.2] - 2024-04-29 Added Documentation to clarify effects of ordering of interactions when a single action has multiple interactions ISXB-221. Additional tests for UI Input default actions (Navigate, Submit, Scroll etc.) Documented behaviour of InputSystemUIInputModule automatically enabling the UI action map. ISXB-621 Fixed Fixed an issue where UI interactions would not function without setting up a project-wide actions asset in Project Settings. Default UI actions are now created on the fly, if no asset for project-wide actions has been set. ISXB-811. Physical keyboards used on Android/ChromeOS could have keys \"stuck\" reporting as pressed after a long press and release ISXB-475. NullReferenceException thrown when right-clicking an empty Action Map list in Input Actions Editor windows ISXB-833. Fixed an issue where System.ObjectDisposedException would be thrown when deleting the last ActionMap item in the Input Actions Asset editor. Fixed DualSense Edge's vibration and light bar not working on Windows Fixed Project-wide Actions asset failing to reload properly after deleting project's Library folder. Fixed an issue where System.InvalidOperationException is thrown when entering PlayMode after deleting an ActionMap from Project-wide actions and later resetting it. Fixed OnPointerClick events not propagating to child objects unless the child also handled OnPointerDown events ISXB-857. Fixed Input Actions Editor window resource leak that could result in unexpected exceptions ISXB-865. Fixed an issue where UI integration would throw exceptions when Project-wide Input Actions asset did not contain the implicitly required UI action map or was missing any of the required actions. Additionally this fix now also generates warnings in the console for any divergence from expected action configuration or lack of bindings in edit-mode. Fixed a minor issue when importing InputAction assets that could result in unexpected logging during internal package validation checks. Changed For Unity 6.0 and above, when an EventSystem GameObject is created in the Editor it will have the InputSystemUIInputModule by default if the Input System package is installed and enabled. [1.8.1] - 2024-03-14 Fixed NullReferenceException thrown when editing a binding path in InputActionAsset windows. [1.8.0] - 2024-03-12 Changed From 2023.2 forward: UI toolkit now uses the \"UI\" action map of project-wide actions as their default input actions. Previously, the actions were hardcoded and were based on DefaultInputActions asset which didn't allow user changes. Also, removing bindings or renaming the 'UI' action map of project wide actions will break UI input for UI toolkit. Changed the 'Max player count reached' error to a warning instead. Removed \"Input Actions\" title from UI-Toolkit Input Action Editor when used in a window and not embedded in Project Settings. Moved project wide input action storage over to an Asset to avoid issues with multiple assets in a single project settings file. Migrate any project-wide input actions found in the InputManager.asset file to a new InputSystem_Actions.inputactions asset file. InputSystem.actions may now only be assigned in edit-mode. Any attempt to assign InputSystem.actions during play-mode will generate an exception. InputSystem.actions may now only be assigned a persisted InputActionAsset instance since in-memory objects can anyway not be included in a player build. This now generates an ArgumentException when attempting to assign a non-persisted object. Project Settings embedded Input Action Editor will now disallow selecting the Project-wide Actions asset during play-mode. The option is only available in edit-mode. The \"Assign as the Project-wide Input Actions\" option visible in the Inspector when selecting an .inputactions asset that is not the current Project-wide Input Actions Asset is now disabled in play-mode. Added Added new methods and properties to InputAction: InputAction.activeValueType returns the Type expected by ReadValue<TValue> based on the currently active control that is driving the action. InputAction.GetControlMagnitude returns the current amount of actuation of the control that is driving the action. InputAction.WasCompletedThisFrame returns true on the frame that the action stopped being in the performed phase. This allows for similar functionality to WasPressedThisFrame/WasReleasedThisFrame when paired with WasPerformedThisFrame except it is directly based on the interactions driving the action. For example, you can use it to distinguish between the button being released or whether it was released after being held for long enough to perform when using the Hold interaction. Added Copy, Paste and Cut support for Action Maps, Actions and Bindings via context menu and key command shortcuts. Added Dual Sense Edge controller to be mapped to the same layout as the Dual Sense controller Added drag and drop support in the Input Action Asset Editor for Action Maps, Actions and Bindings. UI Toolkit input action editor now supports showing the derived bindings. Device filtering support for control schemes in the UI-Toolkit Input Asset Editor. Added right-click (context) menu support for empty areas below the Action Maps/Actions lists in the Project Settings Input Action Editor and Asset Input Action Editor. Added text to show which action map asset was used to create each action in the Input Debug window. Fixed Fixed syntax of code examples in API documentation for AxisComposite. Fixed missing confirmation popup when deleting a control scheme. Fixed support for menu bar/customisable keyboard shortcuts used when interacting with Actions and Action Maps. Fixed add bindings button to support left button click. Fixed icon for adding bindings and composites button. Fixed Documentation~/filter.yml GlobalNamespace rule removing all API documentation. Fixed Destroy may not be called from edit mode error ISXB-695 Fixed possible exceptions thrown when deleting and adding Action Maps. Fixed selection not changing when right-clicking an Action Map or Action in the Project Settings Input Actions Editor. Fixed right-click context menus throwing errors when dealing with multiple Input Actions Editor windows. Fixed potential race condition on access to GCHandle in DefferedResolutionOfBindings and halved number of calls to GCHandle resolution ISXB-726 Fixed issue where composite part dropdown manipulates binding path and leaves composite part field unchanged. Fixed lingering highlight effect on Save Asset button after clicking. Fixed missing name in window title for Input Action assets. Fixed showing action properties view when there were no actions. Fixed \"Listen\" functionality for selecting an input sometimes expecting the wrong input type. Fixed console errors that can be produced when opening input package settings from the Inspector. Fixed InputManager.asset file growing in size on each Reset call. Fixed Opening InputDebugger throws 'Action map must have state at this point' error. Fixed Cut/Paste behaviour to match Editor - Cut items will now be cleared from clipboard after pasting. Improved window layout to avoid elements being hidden (both the Input Actions in Project Settings, and standalone Input Actions Editor windows). Fixed InputAction asset appearing dirty after rename ISXB-749. Fixed Error logged when InputActionsEditor window opened without a valid asset. Fixed ArgumentNullExceptions thrown when deleting items quickly in the UITK Editor. Fixed Project Settings header title styling for Input Actions editor. Fixed Input Actions Editor losing reference to current ControlScheme upon entering Play Mode ISXB-770. Fixed Save shortcut (ctrl/cmd + S by default) not saving changes in Input Actions Editor windows. ISXB-659. Fixed headers in InputActionsEditor windows becoming squashed when there is a large number of Action Maps/Actions. Fixed duplication of project wide input actions when loading/unloading scenes. Fixed an issue where UI Toolkit based editor would not close itself if the associated asset would be deleted (To mimic IMGUI Input Action Editor behavior). Fixed a regression in IMGUI Input Action Editor where editor would auto-save on focus lost even when the auto-save toggle was disabled. Fixed an issue where UI Toolkit based editor would not properly track tentative changes associated with a moved asset file. Fixed an issue where selection state of UI Toolkit editor state would not be preserved when associated with a new serialized copy of the asset. Fixed an issue where any exceptions throw from within UI Toolkit event queue would only log the error message and not the full exception stack trace, making debugging more difficult. Fixed an issue where UI Toolkit Input Actions Editor wouldn't provide a correct modification state when coming back from domain reload. Fixed an issue in the Input Actions Editor window where entries being cut would be deleted instantly and not after being pasted. Fixed an issue where preloaded InputActionAsset objects added by a Unity developer could accidentally be selected as the project-wide actions asset instead of the configured asset in built players. Fixed a compile-time warning: warning CS0109: The member 'UnityRemoteTestScript.camera' does not hide an accessible member. The new keyword is not required. showing up in the Console window when building a player including the Input System Unity Remote sample. Fixed an issue where the InputActionAsset editor window would remove the unsaved changes asterisk when cancelling the window. ISXB-797. Fixed an issue in the Input Actions Editor window where deleting items unfolded other actions or the selection switched unintended. Fixed Composite types missing in context menu when \"Any\" ControlType selected. ISXB-769. Fixed 3D Vector and 1D Axis binding dropdown usage in Input Actions Editor throwing NotImplementedExceptions. Fixed several missing tooltips from the Action/Binding Properties pane in Input Actions Editor. Fixed an issue in the InputActionAsset Editor where ControlType wasn't updated when ActionType changed. Fixed an issue in the InputActionAsset Editor where Canceling ControlScheme changes didn't reset the values in the UI. Fixed an issue where newly created action map names were not editable. Fixed an issue where having unsaved changes in InputActionsEditorWindow would be discarded when entering play-mode (or triggering domain reload in general). Fixed an issue where a InputActionsEditorWindow would not find an existing open editor window if the editor was open during a domain reload and then the asset was opened from the Project Explorer. Fixed a visual glitch in the InputActionAsset Editor when scrolling the Actions list with a rename in progress. ISXB-748 Fixed ProjectWideActions template so Previous/Next Actions are Button instead of Axis. Fixed an issue in the Input Action Editor window where entries being cut would be deleted instantly and not after being pasted. Fixed an issue in the Input Action Editor window where deleting items unfolded other actions or the selection switched unintended. Fixed an issue where InputActionAsset validation where not triggered for Project-wide input actions when the project-wide asset was edited in a regular windowed Input Action Asset editor window. Fixed incorrect documentation in InputSystem.actions and InputSystem.onActionsChanged property API contract. Fixed an issue where InputSystem.actions could be incorrectly evaluated if the associated asset was deleted. [1.8.0-pre.2] - 2023-11-09 Changed Removed icons from action map list as these were always the same and the icon was placeholder Input asset editor now switched to use UI Toolkit which matches the project wide input actions editor interface. Changed InputActionProperty property drawer to be more compact. Use the More menu (⋮) button to open a dropdown menu and select between Use Reference and Use Action. Static analysis warnings regarding flag enums have been suppressed in order to avoid compile-time warnings or errors. Action Map and Action Tree views of the UI Toolkit based Input Action Editor now prevents deselection in both views when Escape key is pressed. Input Action Asset editors Auto-save feature has been modified to trigger on focus-lost when activated instead of triggering on every modification to the asset in order to reduce impact of processing required to handle modified assets. Project-wide input actions template extension changed from .inputactions to .json. This avoids showing template actions in the action's selector UI that are not intended to be used. Re-enabled some UI tests that were disabled on iOS. Reorganized package Project Settings so that \"Input System Package\" setting node contains \"Input Actions\" and \"Settings\" becomes a child node when Project-wide Actions are available. For Unity versions where Project-wide Actions are not available, the settings structure remains unchanged. Make Project-wide Actions the default actions for Player Input. Added Support for Game rotation vector sensor on Android. Duplicate Input Action Items in the new Input Action Asset Editor with Ctrl+D (Windows) or Cmd+D (Mac). Selection of InputActionReferences from project-wide actions on fields that are of type InputActionReference. Uses a new advanced object picker that allows better searching and filtering of actions. Reset project wide Input Settings to default via a new Kebab-menu in Input System Project Settings. Fixed Partially fixed case ISX-1357 (Investigate performance regressing over time). A sample showed that leaving an InputActionMap enabled could lead to an internal list of listeners growing. This leads to slow-down, so we now warn if we think this is happening. UI fix for input fields in interactions: they are wider now and the width is fixed. Fixed exiting empty input fields for actions, action maps and composites in the input action asset editor. Fixed an issue where selecting an Action in the Input Action Asset Editor tree-view and then pressing ESC to unselect would throw an InvalidOperationException. Fixed an issue where selecting an Action Map in the Input Action Asset Editor list and then pressing ESC to unselect would print an NullReferenceException to the Debug console. Fixed case ISXB-251 (Action only calls started & performed callbacks when control type is set to Vector3Composite). EvaluateMagnitude wasn't overridden for Vector3Composite, also made some minor changes to Vector3Composite and Vector2Composite for consistency. Fixed case ISXB-580 (UI Submit / Cancel not working with Switch Pro controller) by adding \"Submit\" & \"Cancel\" usages to the Switch Pro controller input controls. Fixed an issue where undoing deletion of Action Maps did not restore Actions correctly. Fixed case ISXB-628 (OnIMECompositionChange does not return an empty string on accept when using Microsoft IME) by clarifying expectations and intended usage for the IME composition change event. Fixed issue where the expanded/collapsed state of items in the input action editor was not properly saved between rebuilds of the UI. Fixed issue where The Profiler shows incorrect data and spams the console with \"Missing Profiler.EndSample\" errors when there is an Input System Component in Scene). Fixed an issue where undoing duplications of action maps caused console errors. Fix for BindingSyntax WithInteraction() which was incorrectly using processors. Fix for UITK Input Action Editor binding 'Listen' button which wasn't working in the case for Control Type 'Any'. Fixed issue of visual elements being null during editing project-wide actions in project settings which prompted console errors. Fixed case ISX-1436 (UI TK Input Action Asset Editor - Error deleting Bindings with DeleteKey on Windows). Fixed issue with UI Toolkit based Input Action Editor not restoring it's selected items after Domain Reload. Fixed the GetHapticCapabilitiesCommand always failing to execute due to a mismatch in the size in bytes of the payload and the size expected by XR devices. Changed HapticCapabilities to include all properties returned by the XR input subsystem. This makes Input System match the functionality provided by the XR module's InputDevice.TryGetHapticCapabilities and HapticCapabilities. Fixed issue where deleting a binding in the Input Action Editor would usually result in an unexpected item being selected next. [1.8.0-pre.1] - 2023-09-04 Added Initial version of Project Wide Actions for pre-release (InputSystem.actions). This feature is available only on Unity Editor versions 2022.3 and above and can be modified in the Project Settings. Fixed Fixed device selection menu not responding to mouse clicks when trying to add a device in a Control Scheme (case ISXB-622). [1.7.0] - 2023-08-14 Added Preliminary support for visionOS. Show a list of Derived Bindings underneath the Binding Path editor to show all controls that matched. Changed Changed the InputAction constructors so it generates an ID for the action and the optional binding parameter. This is intended to improve the serialization of input actions on behaviors when created through API when the property drawer in the Inspector window does not have a chance to generate an ID. Fixed Fixed missing prefab errors in InputDeviceTester project (case ISXB-420). Fixed serialization migration in the Tracked Pose Driver component causing bindings to clear when prefabs are used in some cases (case ISXB-512, case ISXB-521). Fixed Tracked Pose Driver to use Transform.SetLocalPositionAndRotation when available to improve performance. Based on the user contribution from DevDunk in a forum post. Fixed the Clone methods of InputAction and InputActionMap so it copies the Initial State Check flag (InputAction.wantsInitialStateCheck) of input actions. Fixed the \"Release tests throws exception in InputSystem\" bug (case ISXB-581). Fixed issues with generating Precompiled Layouts for devices which are not defined in a namespace Fixed an issue where some controls like QuaternionControl could not be included in a Precompiled Layout because the generated code could not access a setter on child control properties. [1.6.3] - 2023-07-11 Fixed Fixed warning in USS file [1.6.2] - 2023-07-10 Added Enabled displayIndex support for Unity 2022.3. Fixed Fixed UI clicks not registering when OS provides multiple input sources for the same event, e.g. on Samsung Dex (case ISX-1416, ISXB-342). Fixed unstable integration test Integration_CanSendAndReceiveEvents by ignoring application focus on integration tests. (case ISX-1381) Fixed broken \"Listen\" button in Input actions editor window with Unity dark skin (case ISXB-536). [1.6.1] - 2023-05-26 Fixed Fixed issue with compiling in Unity 2022.1 and with XR Toolkit by guarding the experimental UITK Asset Editor code completely. [1.6.0] - 2023-05-25 Added Added internal InputSystemProvider class for the new InputForUI internal module. InputForUI allows the UIToolkit to have a single dependency for input events, regardless of using the new input system or the legacy input system. Added InputSystem.customBindingPathValidators interface to allow showing warnings in the InputAsset Editor for specific InputBindings and draw custom UI in the properties panel. Added InputSystem.runInBackground to be used internally by specific platforms packages. Allows telling the input system that a specific platform runs in background. It allows fixing of case UUM-6744. Added new UIToolkit version of the InputActionsAsset editor. Currently this is incomplete (view-only) and the existing editor is still used by default. Added displayIndex field to the Touch struct to expose the index of the display that was touched. Changed Changed XR Layout build behavior to create Axis2D control devices with StickControl type instead of Vector2Control. Fixed Fixed BindingPath String-Comparison to be culture and case insensitive (case ISXB-449). Fixed custom processor display in the input action asset UI after entering/exiting play mode (previously they got hidden) (case ISXB-445). [1.5.1] - 2023-03-15 Fixed Fixed unclosed profiler marker in InvokeCallbacksSafe_AnyCallbackReturnsTrue which would lead to eventually broken profiler traces in some cases like using PlayerInput (case ISXB-393). Fixed InputAction.bindings.count not getting correctly updated after removing bindings with Erase(). Fixed an issue where connecting a gamepad in the editor with certain settings will cause memory and performance to degrade (case UUM-19480). Fixed issue leading to a stack overflow crash during device initialization in InsertControlBitRangeNode (case ISXB-405). Fixed the issue where saving and loading override bindings to JSON would set unassigned overrides (that were null) to assigned overrides (as an empty string \"\"). [1.5.0] - 2023-01-24 Added Added support for reading Tracking State in TrackedPoseDriver to constrain whether the input pose is applied to the Transform. This should be used when the device supports valid flags for the position and rotation values, which is the case for XR poses. Added InputSettings.shortcutKeysConsumeInput. This allows programmatic access to opt-in to the enhanced shortcut key behaviour (case ISXB-254)). Significantly optimized cost of ReadValue/ReadUnprocessedValueFromState/WriteValueIntoState for some control types. Optimization is opt-in for now, please call InputSystem.settings.SetInternalFeatureFlag(\"USE_OPTIMIZED_CONTROLS\", true); in your project to enable it. You can observe which controls are optimized by looking at new optimized column in device debugger. You will need to call a new InputControl.ApplyParameterChanges() method if the code is changing AxisControl fields after initial setup is done. Added the ability to change the origin positioning and movement behaviour of the OnScreenStick (OnScreenStick.cs) via the new behaviour property. This currently supports three modes of operation, two of which are new in addition to the previous behaviour. Based on the user contribution from eblabs in #658. Significantly optimized cost of InputAction.ReadValue and InputControl.ReadValue calls by introducing caching behaviour to input controls. Input controls now keep track of whether their underlying state has been changed and only read the value from the underlying state and apply processors when absolutely necessary. Optimization is opt-in for now, please call InputSystem.settings.SetInternalFeatureFlag(\"USE_READ_VALUE_CACHING\", true); in your project to enable it. If there are issues try enabling InputSystem.settings.SetInternalFeatureFlag(\"PARANOID_READ_VALUE_CACHING_CHECKS\", true); and check in the console if there are any errors regarding caching. Added a note in the supported devices page about DualSense support for Android devices. Exposed displayIndex property for Pointer, Touchscreen, TouchControl, TouchState, Mouse, MouseState which enables look up of the logical screen associated with a pointer event via (display documentation)[https://docs.unity3d.com/ScriptReference/Display.html] Fixed Fixed composite bindings incorrectly getting a control scheme assigned when pasting into input asset editor with a control scheme selected. Fixed an issue on PS5 where device disconnected events that happen while the app is in the background are missed causing orphaned devices to hang around forever and exceptions when the same device is added again (case UUM-7842). Fixed Switch Pro, DualShock 4, DualSense gamepads becoming current on PC/macOS when no controls are changing (case ISXB-223)). Fixed an issue that made OnScreenStick unusable when used in conjunction with PlayerInput in Auto-Switch devices mode, or with any code that changes user/device pairing on unsued device activity being detected (case ISXB-48). Fixed issue where input events were being suppressed during interactive action rebinding even when when their controls were excluded (case ISXB-367). Removed unneeded check that could trigger a NotImplementedException when binding to a Usage (e.g. Submit) (case ISXB-373). Display a warning instead of throwing a NotImplementedException when loading binding overrides from json when some of the entries have become outdated (case ISXB-375). Actions Extended input action code generator (InputActionCodeGenerator.cs) to support optional registration and unregistration of callbacks for multiple callback instances via AddCallbacks(...) and RemoveCallbacks(...) part of the generated code. Contribution by Ramobo in #889. Changed Changed define requirements of Unity.InputSystem.TestFramework, so that it can be used by other packages without setting the com.unity.inputsystem package to be testable in the project manifest. [1.4.4] - 2022-11-01 Fixed Fixed ArgumentNullException when opening the Prefab Overrides window and selecting a component with an InputAction. Fixed {fileID: 0} getting appended to ProjectSettings.asset file when building a project (case ISXB-296). Fixed Type of instance in array does not match expected type assertion when using PlayerInput in combination with Control Schemes and Interactions (case ISXB-282). The InputActions consume their inputs behaviour for shortcut support introduced in v1.4 is opt-in now and can be enabled via the project settings (case ISXB-254)). Fixed Memory alignment issue with deserialized InputEventTraces that could cause infinite loops when playing back replays (case ISXB-317). Fixed an InvalidOperationException when using Hold interaction, and by extension any interaction that changes to performed state after a timeout (case ISXB-332). Fixed Given object is neither an InputAction nor an InputActionMap when using InputActionTrace on input action from an input action asset (case ISXB-29). Fixing devices not being removed if unplugged during domain reload (entering or exiting play mode) (case ISXB-232). [1.4.3] - 2022-09-23 Fixed Added missing script and gizmo icon for TrackedPoseDriver.cs component (case ISXB-262). Fix for mitigating symptoms reported in (case UUM-10774 effectively avoiding reenabling mouse, pen or touch devices in InputSystemPlugin.OnDestroy() if currently quitting the editor. The fix avoids editor crashing if closed when Simulator Window is open. Note that the actual issue needs a separate fix in Unity and this package fix is only to avoid running into the issue. Fixed an issue where Input Action name would not display correctly in Inspector if serialized as [SerializedProperty] within a class not derived from MonoBehavior (case ISXB-124. Fix an issue where users could end up with the wrong device assignments when using the InputUser API directly and removing a user (case ISXB-274). Fixed an issue where PlayerInput behavior description was not updated when changing action assset (case ISXB-286). Changed Readded OnDisable() member to MultiplayerEventSystem which was previously removed from the API Improved performance of HID descriptor parsing by moving json parsing to a simple custom predicitve parser instead of relying on Unity's json parsing. This should improve domain reload times when there are many HID devices connected to a machine. Changed Documentation improvements: New workflows and concepts pages. Reorganised table of contents. Improved some code samples. Updated screenshots. [1.4.2] - 2022-08-12 Changed Hide XR legacy HMD and controllers layouts from Editor UI dropdown. Fixed Fix UI sometimes ignoring the first mouse click event after losing and regaining focus (case ISXB-127. Fixed issue when using MultiplayerEventSystems where the visual state of UI controls would change due to constant toggling of CanvasGroup.interactable on and off (case ISXB-112). Fixed minor issue when renaming input actions where unique renaming would incorrectly consider the input action being renamed as a different action and not allow renaming of 'A' to 'a' without appending a unique integer for example (case ISXB-25). Fixed an issue where the Input Action asset icon would not be visible during asset creation (case ISXB-6). Fixed DualSense low frequency motor speed being always set to min value. Fixed an issue where ReadUnprocessedValueFromState in PoseControl always returning default values. Fix Player 1's UI controls stop working after second player joins (case ISXB-125)) [1.4.1] - 2022-05-30 Fixed Fixed composite touchscreen controls were not firing an action if screen was touched before enabling the action (case ISXB-98). [1.4.0] - 2022-04-10 Changed Button type InputActions now go to started when a button goes from a press to below the release threshold but not yet to 0. // Before: Set(Gamepad.current.rightTrigger, 0.7f); // Performed (pressed) Set(Gamepad.current.rightTrigger, 0.2f); // Canceled (released) Set(Gamepad.current.rightTrigger, 0.1f); // Started!! Set(Gamepad.current.rightTrigger, 0f); // Canceled // Now: Set(Gamepad.current.rightTrigger, 0.7f); // Performed (pressed) Set(Gamepad.current.rightTrigger, 0.2f); // Started (released but not fully) Set(Gamepad.current.rightTrigger, 0.1f); // <Nothing> Set(Gamepad.current.rightTrigger, 0f); // Canceled This also applies to PressInteraction when set to Press behavior. In effect, it means that a button will be in started or performed phase for as long as its value is not 0 and will only go to canceled once dropping to 0. Processors are now always applied when reading action values through InputAction.ReadValue<> or CallbackContext.ReadValue<>. Previously, if no bound control was actuated, ReadValue calls would return the default value for the action type but not run the value through the processors.(case 1293728). Made the following internal types public. These types can be useful when deconstructing raw events captured via InputEventTrace. UnityEngine.InputSystem.Android.LowLevel.AndroidAxis UnityEngine.InputSystem.Android.LowLevel.AndroidGameControllerState UnityEngine.InputSystem.Android.LowLevel.AndroidKeyCode Adding or removing a device no longer leads to affected actions being temporarily disabled (case 1379932). If, for example, an action was bound to <Gamepad>/buttonSouth and was enabled, adding a second Gamepad would lead to the action being temporarily disabled, then updated, and finally re-enabled. This was especially noticeable if the action was currently in progress as it would get cancelled and then subsequently resumed. Now, an in-progress action will get cancelled if the device of its active control is removed. If its active control is not affected, however, the action will keep going regardless of whether controls are added or removed from its InputAction.controls list. Installing the package for the first time will now set \"Active Input Handling\" to \"Both\" rather than \"Input System Package\". This means, that by default, both the old and the new input system will run side by side where supported. This can be manually switched by going to Edit >> Project Settings >> Player >> Active Input Handling. Fixed Fixed an issue where a layout-override registered via InputSystem.RegisterLayoutOverride(...) would cause the editor to malfunction or crash if the layout override had a name already used by an existing layout (case 1377685). Fixed an issue where attempting to replace an existing layout-override by using an existing layout-override name didn't work as expected and would instead aggregate overrides instead of replacing them when an override with the given name already exists. Fixed Switch Pro controller not working correctly in different scenarios (case 1369091, case 1190216, case 1314869). Fixed DualShock 4 controller not allowing input from other devices due to noisy input from its unmapped sensors (case 1365891). Fixed InputSystem.onAnyButtonPress so that it doesn't throw exceptions when trying to process non state or delta events (case 1376034). Fixed InputControlPath.Matches incorrectly reporting matches when only a prefix was matching. This would, for example, cause Keyboard.eKey to be matched by <Keyboard>/escape. Fix contributed by Fredrik Ludvigsen in #1485. Fixed OnScreenButton triggering NullReferenceException in combination with custom devices (case 1380790 ). Fixed no devices being available in Start and Awake methods if, in the player, any InputSystem API was accessed during the SubsystemRegistration phase (case 1392358). Fixed dropdown for \"Supported Devices\" in settings not showing all device layouts. Fixed \"STAT event with state format TOUC cannot be used with device 'Touchscreen:/Touchscreen'\" when more than max supported amount of fingers, currently 10, are present on the screen at a same time (case 1395648). Fixed mouse events not being timesliced when input system is switched to process input in fixed updates (case 1386738). Fixed missing tooltips in PlayerInputManagerEditor for the Player Limit and Fixed Splitscreen sizes labels (case 1396945). Fixed DualShock 4 controllers not working in some scenarios by adding support for extended mode HID reports (case 1281633, case 1409867). Fixed BackgroundBehavior.IgnoreFocus having no effect when Application.runInBackground was false (case 1400456). Fixed an issue where a device was left disabled when it was disconnected while an application was out-of-focus and then re-connected when in-focus (case 1404320). Actions Fixed InvalidCastException: Specified cast is not valid. being thrown when clicking on menu separators in the control picker (case 1388049). Fixed accessing InputActions directly during RuntimeInitializeOnLoad not initializing the input system as a whole and leading to exceptions (case 1378614). Fixed InputAction.GetTimeoutCompletionPercentage jumping to 100% completion early (case 1377009). Fixed d-pad inputs sometimes being ignored on actions that were binding to multiple controls (case 1389858). Fixed IndexOutOfRangeException when having multiple interactions on an action and/or binding in an action map other than the first of an asset (case 1392559). Fix contributed by Russell Quinn in #1483. Fixed AxisComposite not respecting processors applied to positive and negative bindings (case 1398942). This was a regression introduced in 1.0.0-pre.6. Fixed calling action.AddCompositeBinding(...).With(...) while action is enabled not correctly updating controls for part bindings of the composite. Fixed TwoModifiersComposite inadvertently not allowing controls other than ButtonControls being bound to its binding part. Added support for keyboard shortcuts and mutually exclusive use of modifiers. In short, this means that a \"Shift+B\" binding can now prevent a \"B\" binding from triggering. OneModifierComposite, TwoModifiersComposite, as well as the legacy ButtonWithOneModifierComposite and ButtonWithTwoModifiersComposite now require their modifiers to be pressed before (or at least simultaneously with) pressing the target button. This check is performed only if the target is a button. For a binding such as \"CTRL+MouseDelta\" the check is bypassed. It can also be manually bypassed via the overrideModifiersNeedToBePressedFirst. State change monitors on a device (IInputStateChangeMonitor) are now sorted by their monitorIndex and will trigger in that order. Actions are now automatically arranging their bindings to trigger in the order of decreasing \"complexity\". This metric is derived automatically. The more complex a composite a binding is part of, the higher its complexity. So, \"Shift+B\" has a higher \"complexity\" than just \"B\". If an binding of higher complexity \"consumes\" a given input, all bindings waiting to consume the same input will automatically get skipped. So, if a \"Shift+B\" binding composite consumes a \"B\" key press, a binding to \"B\" that is waiting in line will get skipped and not see the key press. If your project is broken by these changes, you can disable the new behaviors via a feature toggle in code: InputSystem.settings.SetInternalFeatureFlag(\"DISABLE_SHORTCUT_SUPPORT\", true); Added new APIs for getting and setting parameter values on interactions, processors, and composites. // Get parameter. action.GetParameterValue(\"duration\"); // Any \"duration\" value on any binding. action.GetParameterValue(\"tap:duration\"); // \"duration\" on \"tap\" interaction on any binding. action.GetParameterValue(\"tap:duration\", // \"duration\" on \"tap\" on binding in \"Gamepad\" group. InputBinding.MaskByGroup(\"Gamepad\")); // Set parameter. action.ApplyParameterOverride(\"duration\", 0.4f); action.ApplyParameterOverride(\"tap:duration\", 0.4f); action.ApplyParameterOverride(\"tap:duration\", 0.4f, InputBinding.MaskByGroup(\"Gamepad\")); // Can also apply parameter overrides at the level of // InputActionMaps and InputActionAssets with an effect // on all the bindings contained therein. asset.ApplyParameterOverride(\"scaleVector2:x\", 0.25f, new InputBinding(\"<Mouse>/delta\")); Added Added support for \"Hori Co HORIPAD for Nintendo Switch\", \"HORI Pokken Tournament DX Pro Pad\", \"HORI Wireless Switch Pad\", \"HORI Real Arcade Pro V Hayabusa in Switch Mode\", \"PowerA NSW Fusion Wired FightPad\", \"PowerA NSW Fusion Pro Controller (USB only)\", \"PDP Wired Fight Pad Pro: Mario\", \"PDP Faceoff Wired Pro Controller for Nintendo Switch\", \"PDP Faceoff Wired Pro Controller for Nintendo Switch\", \"PDP Afterglow Wireless Switch Controller\", \"PDP Rockcandy Wired Controller\". Added support for SteelSeries Nimbus+ gamepad on Mac (addition contributed by Mollyjameson). Added support for Game Core platforms to XR layouts, devices, and input controls. These classes were previously only enabled on platforms where ENABLE_VR is defined. Added a new DeltaControl control type that is now used for delta-style controls such as Mouse.delta and Mouse.scroll. Like StickControl, this control has individual up, down, left, and right controls (as well as x and y that it inherits from Vector2Control). This means it is now possible to directly bind to individual scroll directions (such as <Mouse>/scroll/up). Added the 'Cursor Lock Behavior' setting to InputSystemUIInputModule to control the origin point of UI raycasts when the cursor is locked. This enables the use of PhysicsRaycaster when the cursor is locked to the center of the screen (case 1395281). Added support for using the Unity Remote app with the Input System. Requires Unity 2021.2.18 or later. [1.3.0] - 2021-12-10 Changed The artificial ctrl, shift, and alt controls (which combine the left and right controls into one) on the keyboard can now be written to and no longer throw NotSupportedException when trying to do so (case 1340793). All devices are now re-synced/reset in next update after entering play mode, this is needed to read current state of devices before any intentional input is provided (case 1231907). Replaced UnityLinkerBuildPipelineData.inputDirectory with hardcoded Temp folder because inputDirectory is deprecated. Deprecated InputSettings.filterNoiseOnCurrent. Now noise filtering is always enabled. Device only will become .current if any non-noise control have changed state. A device reset (such as when focus is lost) on Touchscreen will now result in all ongoing touches getting cancelled instead of all touches being simply reset to default state. Calling InputTestFixture.Press, InputTestFixture.Set, etc. from within a [UnityTest] will no longer immediately process input. Instead, input will be processed like it normally would as part of the Unity player loop. Fixed Fixed writing values into the half-axis controls of sticks (such as Gamepad.leftStick.left) producing incorrect values on the stick (case 1336240). Fixed setting size of event trace in input debugger always growing back to largest size set before. Fixed successive clicks not getting triggered with TouchSimulation on when not moving the mouse in-between clicks (case 1330014). Fixed InputSystemUIInputModule stopping to listen for input when swapping InputActionAsset instances while input was disabled (case 1371332). Fixed InputSystemUIInputModule showing incorrect bindings after pressing the 'Fix UI Input Module' button in PlayerInput component(case 1319968). Fixed an issue where UI button clicks could be ignored by InputSystemUIInputModule if modifying on-screen devices from Update() callbacks (case 1365070). Fixed an issue with InputSystemUIInputModule that would cause UI to stop responding during play mode after changing a script file while Recompile and Continue mode is active, or by forcing a script recompile using RequestScriptCompilation(case 1324215). Fixed InputSystemUIInputModule inspector showing all action bindings as \"None\" when assigned a runtime created actions asset (case 1304943). Fixed a problem with UI Toolkit buttons remaining active when multiple fingers are used on a touchscreen, using InputSystemUIInputModule with pointerBehavior set to UIPointerBehavior.SingleUnifiedPointer. UI Toolkit will now always receive the same pointerId when that option is in use, regardless of the hardware component that produced the pointer event. (case 1369081). Fixed a problem with InputUser where devices would be removed and not added again after layout overrides preventing certain devices, e.g. gamepads to not work correctly when associated with action map bindings tied to PlayerInput (case 1347320). Fixed DualSense on iOS not inheriting from DualShockGamepad (case 1378308). Fixed a device becoming .current (e.g. Gamepad.current, etc) when sending a new state event that contains no control changes (case 1377952). Fixed calling IsPressed on an entire device returning true (case 1374024). Fixed HIDs having blackslashes in their vendor or product names leading to binding paths generated by interactive rebinding that failed to resolve to controls and thus lead to no input being received (case 1335465). Fixed InputSystem.RegisterLayoutOverride resulting in the layout that overrides are being applied to losing the connection to its base layout (case 1377719). Fixed Touch.activeTouches still registering touches after the app loses focus (case 1364017). Fixed MultiplayerEventSystem not preventing keyboard and gamepad/joystick navigation from one player's UI moving to another player's UI (case 1306361). This fix relies on a CanvasGroup being injected into each playerRoot and the interactable property of the group being toggled back and forth depending on which part of the UI is being updated. Fixed InputTestFixture incorrectly running input updates out of sync with the player loop (case 1341740). This had effects such as InputAction.WasPressedThisFrame() returning false expectedly. Fixed broken code example for state structs in Devices.md documentation (fix contributed by jeffreylanters). Fixed TrackedDeviceRaycaster not picking closest hit in scene (fix originally contributed by alexboost222). Actions Fixed opening a new project (or one that needs a full reimport) leading to several exceptions in the console if the most recently opened project was closed with a .inputactions editor open (case 1313185). Fixed incorrect indentation of input actions in the inspector (case 1285546). Fixed an issue where serialized InputAction properties would have display name \"Input Action\" in the Inspector window instead of their given name. (case 1367240). Fixed an issue where InputAction.Enable would not reuse memory allocated prior and thus lead to memory leaks (case 1367442). Fixed interactions such as Press not getting processed correctly when having multiple of them on different bindings of the same action and receiving simultaneous input on all of them (case 1364667). If, for example, you bind the A and S key on the same action, put a Press interaction on both, and then press both keys, interactions would get missed or got stuck. Fixed InputAction.IsPressed/WasPressed/WasReleased returning incorrect results when binding multiple buttons on the same action and pressing/releasing them simultaneously. Improved performance of looking up actions by name. Fixed InputAction.controls exhibiting bad performance when there were no controls bound to an action (case 1347829). Fixed interactions involving timeouts (such as HoldInteraction) performing erroneous delayed triggers on actions when input is composed of multiple controls (1251231). For example, if you bind Shift+B using a OneModifierComposite and put a HoldInteraction on the binding, then depending on the order in which the keys are pressed, you would sometimes see the action spuriously getting triggered when in fact no input was received. Fixed control schemes of bindings not getting updates when being pasted from one .inputactions asset into another (case 1276106). For example, if you copied a binding from an asset that had a \"Gamepad\" control scheme into an asset that had none, the resulting binding would be unusable. All associations with control schemes that do not exist in the target asset are now removed from bindings upon pasting. Fixed InputActionSetupExtensions.AddCompositeBinding not setting name of composite. [1.2.0] - 2021-10-22 Changed When exceptions occur in user code inside of Input System callbacks, the exception message is now printed first and details about the callback second. Previously a message similar to \"Exception ... while executing '...' callbacks\" was printed first and then followed by exception log. This was hiding the actual exception and created confusion. Fixed Fixed a performance issue on entering/exiting playmode where HID device capabilities JSON could be parsed multiple times for a single device(case 1362733). Fixed a problem where explicitly switching to the already active control scheme and device set for PlayerInput would cancel event callbacks for no reason when the control scheme switch would have no practical effect. This fix detects and skips device unpairing and re-pairing if the switch is detected to not be a change to scheme or devices. (case 1342297) Any unhandled exception in InputManager.OnUpdate failing latter updates with InvalidOperationException: Already have an event buffer set! Was OnUpdate() called recursively?. Instead the system will try to handle the exception and recover into a working state. Fixed an issue that broke the VirtualMouseInput component in the editor (case 1367553). Fixed a problem where only using runtimes that are not XR supported causes a compile error. This fix adds back in ENABLE_VR checks to prevent this case (case 1368300) Fixed input action for Android gamepad's right stick will be correctly invoked when only y axis is changing (case 1308637). Generic gamepad short display button names were incorrectly mapped on Switch (A instead of B, etc). Fixed an issue where resetting an action via InputAction.Reset() while being in disabled state would prevent the action from being enabled again. (case 1370732). Fixed \"Default constructor not found for type UnityEngine.InputSystem.iOS.LowLevel.iOSStepCounter\" any other potential exceptions due to classes, methods, fields and properties being stripped when managed stripping setting set to medium or high (case 1368761). Fixed an issue where InvalidOperationExceptions are thrown if an input for an action with multiple interactions is held while disconnecting the device(case 1354098). Fixed action.ReadValue and others returning invalid data when used from FixedUpdate or early update when running in play mode in the editor (case 1368559 case 1367556 case 1372830). Fixed current being null for sensors (Accelerometer.current, others) (case 1371204). Added Added support for PS5 DualSense controllers on Mac and Windows. Improved the user experience when creating single vs multi-touch touchscreen bindings in the Input Action Asset editor by making both options visible in the input action dropdown menu. Now it's not neccessary to be aware of the touch*/press path binding syntax (case 1357664). Added support for the Unity Remote app. NOTE: This unfortunately requires a change in the Unity native runtime. We are in the process of rolling out the change to Unity versions. A public build that receives the change will automatically enable the functionality in the Input System package. [1.1.1] - 2021-09-03 Fixed Fixed InvalidCastException: Specified cast is not valid. and InvalidOperationException: Already have an event buffer set! Was OnUpdate() called recursively? when upgrading from 1.1.0-pre.5 or earlier. If you experience this issue you can also restart the editor to resolve it. Fixed InputDeviceChange.Destroyed not being available, now it's correctly marked as obsolete instead. Removed documentation around platform user account management of InputUser which was ahead of actual backend support for the feature. [1.1.0] - 2021-08-27 Changed Modified the fix that landed in 1.1-preview.3 for any given control being added to an action only once. This caused a regression with some setups that, for example, bound the same control multiple times in a composite using processors to alter the value of the control. Internally, a control is now again allowed to feed into the same action through more than one binding. However, externally the control will be mentioned on the action's InputAction.controls list only once. Adding InputSystemUIInputModule from code now installs DefaultInputActions. This is equivalent to the default setup when adding the component in the editor (case 1259306). var go = new GameObject(); go.AddComponent<EventSystem>(); var uiModule = go.AddComponent<InputSystemUIInputModule>(); // uiModule.actionsAsset now has a DefaultInputActions() asset assigned to it and the various // action references point to its actions. InputSystemUIInputModule.UnassignActions has been added to remove all actions from the module en bloc. uiModule.UnassignActions(); Fixed Fixed an issue where mixing test cases based on InputTestFixture (using mocked InputSystem) and regular test cases (using real InputSystem) would lead to static state leaking between test cases causing random failures and unexpected/undefined behavior (case 1329015). Fixed InputSystemUIInputModule.AssignDefaultActions not assigning trackedDeviceOrientation and trackedDevicePosition. Fixed regression introduced by previous change where InputSystemUIInputModule would not disable actions correctly. Fixed InputAction.canceled not getting triggered reliably for InputActionType.PassThrough actions when InputSystem.ResetDevice was called. Fixed device resets (e.g. happening as part of focus changes) leading to only some actions bound to these devices getting cancelled instead of all of them. [1.1.0-pre.6] - 2021-08-23 Fixed Fixed pairing devices to existing InputUsers potentially corrupting list of paired devices from other InputUsers (case 1327628). Fixed duplication of control paths when viewing collections of InputControls in the inspector. Fix contributed by NibbleByte in 1354. Fixed StackOverflowException caused by calling InputSystem.Update from inside an input action callback such as InputAction.performed (case 1316000). Fixed InputTestFixture leaving all .current getters uninitialized after a test run (case 1329015). Fixed broken script references in Touch Samples project (case 1190598). Fixed PointerInput composite in TouchSamples project being registered only after scenes already loaded (case 1215048). Fixed InputControlExtensions.EnumerateChangedControls skipping over left, right, and down controls on PS4 controller's dpad (case 1315107). Fixed undo not working in Input System Package project settings pane (case 1291709). Fixed incorrect indexing in InputUser.OnDeviceChanged that could result in incorrect pairing of devices or IndexOutOfRangeException being thrown when removing, adding or reconfiguring a device. Fix contribution by Mikael Klages in #1359. Fixed incorrect indexing when sorting magnitude based on score in InputActionRebindingExtensions.RebindingOperation which could result in incorrect magnitudes for candidates. Contribution by Fredrik Ludvigsen in #1348. Fixed inconsistent ordering and execution when adding to or removing from the various callbacks in the API (such as InputSystem.onDeviceChange but also InputAction.started etc.) during the execution of a callback (case 1322530. Fixed inconsistent behavior of WebGL gamepad left/right stick. Up/Down controls were reverse of X/Y controls. (case 1348959) Fixed PlayerInputManagers join action not triggering when using a referenced InputAction (case 1260625). Fixed UI issue where pressing the wrong button was possible while quickly moving through a UI because the submit action fired on action press instead of action release (1333563). Fixed InvalidOperationException when opening a preset created from a .inputactions asset (case 1199544). Fixed a problem arising when combining InputSystemUIInputModule and PlayInput with SendMessage or BroadcastMessage callback behavior on the same game object or hierarchy which is an ambiguous input setup. This fix eliminates callbacks into InputSystemUIInputModule. Related to (1343712). Fixed inconsistent usage of ENABLE_PROFILER define together with Profiler.BeginSample/Profiler.EndSample by removing ENABLE_PROFILER macro check because BeginSample/EndSample are already conditional with [Conditional(\"ENABLE_PROFILER\")] (case 1350139). Remediated majority of performance issues with high frequency mice (>=1kHz poll rates) in release mode by merging consecutive mouse move events together (case 1281266), see the events documentation for more information. Fixed InputEventTrace replays skipping over empty frames and thus causing playback to happen too fast. Fixed \"Pointer should have exited all objects before being removed\" error when changing screen orientation on mobile. Controls such as mouse positions are no longer reset when focus is lost. Pressing a uGUI Button and then alt-tabbing away, letting go of the button, and then going back to the application will no longer trigger a button click. Fixed Input.onUnpairedDeviceActivity triggering from editor input. Fixed 'up' and 'down' controls on WebGLGamepad left and right sticks not being clamped correctly. Actions Fixed right-clicking in empty action map or action list not popping up context menu (case 1336426). Fixed binding paths being misaligned in UI when switching to text mode editing (case 1200107). Fixed \"Exception: Style.Draw may not be called with GUIContent that is null.\" error from PlayerInput inspector when having an action map with no actions (case 1317735). Fixed calling GetBindingDisplayString() on an InputAction with a composite binding leading to doubled up output (case 1321175). Fixed MultiTapInteraction not respecting InputSettings.multiTapDelayTime (case 1292754). Fixed changing values in Input System Package project settings not affecting default values displayed in .inputactions editor window (case 1292754). Fixed rebinding a part of a composite with RebindingOperation.WithTargetBinding not also changing the type of control being looked for (case 1272563). Fixed AxisComposite not respecting minValue and maxValue properties (case 1335838). Fixed ArgumentOutOfRangeException caused by IsPointerOverGameObject (case 1337354). PlayerInput no longer logs an error message when it is set to Invoke UnityEvents and can't find an action in the given .inputactions asset (case 1259577). Fixed HoldInteraction getting stuck when hold and release happens in same event (case 1346786). Fixed adding an action in the .inputactions editor automatically duplicating interactions and processors from the first action in the map. Fixed InputActionSetupExtensions.ChangeBinding when modifying binding from a different action than specified. Contribution by Fredrik Ludvigsen in #1348. Added Added InputSystem.runUpdatesInEditMode to enable processing of non-editor updates without entering playmode (only available for XR). Added a new \"UI vs Game Input\" sample to the package. The sample can be installed from the Unity Package Manager UI in the editor. The sample demonstrates how to deal with inputs that may both lead to UI actions as well as in-game actions. Added method SetMotorSpeedsAndLightBarColor as a workaround for setting both the light bar and motor speeds simultaneously on a DualShock 4 controller (case 1271119). Added the concept of \"soft\" and \"hard\" device resets. In general, resetting a device will reset its state to default values. Individual controls can be marked as dontReset to exclude them from resets. This makes the reset \"soft\" (default). // Perform a \"soft\" reset of the mouse. The mouse position will not be affected // but controls such as buttons will be reset. InputSystem.ResetDevice(Mouse.current); A \"hard\" reset can be forced through the API. This also resets dontReset controls. // Perform a \"hard\" reset of the mouse. The mouse position will also be reset to (0,0). InputSystem.ResetDevice(Mouse.current, alsoResetDontResetControls: true); Resets will lead to InputActions that are enabled and in-progress from controls that being reset, to be canceled. This will not perform actions even if they trigger on, for example, button release. InputDevice.canRunInBackground can now be force-set through layouts. // Force XInputWindows gamepads to not run in the background. InputSystem.RegisterLayoutOverride(@\" { \"\"name\"\": \"\"XInputWindowsNoCanRunInBackground\"\", \"\"extend\"\": \"\"XInputWindows\"\", \"\"runInBackground\"\": \"\"off\"\" } \"); Improved performance of Touchscreen by merging consecutive touch move events together. See the events documentation for more information. Actions Added a new InputAction.wantsInitialStateCheck property that allows toggling on initial state checks for Button and Pass-Through actions (implicitly enabled for Value actions). This allows responding immediately to controls that are already actuated when the action is enabled. Added new API for more easily listening for event changes. InputSystem.onEvent .ForDevice<Gamepad>() .Where(e => e.HasButtonPress()) .CallOnce(e => Debug.Log(\"Button pressed!)); Added new API to easily listen for button presses on any device. InputSystem.onAnyButtonPress .CallOnce(ctrl => Debug.Log($\"Button '{ctrl}' pressed\")); This is a simple wrapper around the new API mentioned above. Changed Application focus handling behavior has been reworked. When runInBackground is off, no action will be taken on focus loss. When focus comes back, all devices will receive a sync request. Those that don't support it will see a \"soft\" reset. When runInBackground is on (which, when running in the editor, is considered to always be the case), a new setting InputSettings.backgroundBehavior dictates how input is to be handled while the application does not have focus. The default setting of ResetAndDisableNonBackgroundDevices will soft-reset and disable all devices for which InputDevice.canRunInBackground is false. While in the background, devices that are flagged as canRunInBackground will keep running as in the foreground. In the editor, devices other than Pointer and Keyboard devices (i.e. anything not used to operate the editor UI) are now by default routing their input to the Game View regardless of focus. This also fixes the problem of gamepad sticks resetting to (0,0) on focus loss (case 1222305). A new setting InputSettings.gameViewFocus has been introduced to determine how Game View focused is handled in the editor with respect to input. Editor: Removed 'Lock Input to Game View' setting in the Input Debugger. The setting has been replaced by the new 'Game View Focus' project setting. InputSystem.defaultButtonPressPoint is now clamped to a minimum value of 0.0001 (case 1349002). InputDevice.OnConfigurationChanged can now be overridden in derived classes. InputSystemUIInputModule now defers removing pointers for touches by one frame. This is to ensure that IsPointerOverGameObject can meaningfully be queried for touches that have happened within the frame – even if by the time the method is called, a touch has technically already ended (case 1347048). More precisely, this means that whereas before a PointerExit and PointerUp was received in the same frame, a touch will now see a PointerUp in the frame of release but only see a PointerExit in the subsequent frame. Calling EventSystem.IsPointerOverGameObject() from within InputAction callbacks (such as InputAction.performed) will now result in a warning. UI updates after input and consumes input through InputActions as they are processed. Thus, querying UI state from within InputAction callbacks will query outdated UI state. Changed TrackedPoseDriver to use properties of type InputActionProperty rather than InputAction to allow more flexibility. Changed quickstart documentation sample to use the Update method instead of FixedUpdate to show a more correct usage of the wasPressedThisFrame API. [1.1.0-pre.5] - 2021-05-11 Fixes a problem with the package's manifest missing a dependency on the UI Elements module. [1.1.0-pre.4] - 2021-05-04 Changed The VirtualMouseInput component is now part of the Input System assembly. It was previously packaged with the Gamepad Mouse Cursor sample. The component has a different GUID from before, so existing setups that use the component from the sample are not broken. To use the built-in component you must explicitly switch over. InputTestFixture no longer deletes the GameObjects in the current scene in its TearDown (case 1286987). This was added for the sake of the Input System's own tests but should not have been in the public fixture. Generic Gamepad now has platform independent long button names. Previously it used different names if editor targeted PS4/Switch consoles (case 1321676). When creating a new control scheme with a name All Control Schemes, All Control Schemes1 will be created to avoid confusion with implicit All Control Schemes scheme (case 1217379). Display names of keyboard buttons are now passed through ToLower and ToTitleCase to enforce consistent casing between different platforms and keyboard layouts (case 1254705). Editor: All remaining InputUser instances are now removed automatically when exiting play mode. This means that all devices are automatically unpaired. In essence, like InputAction, InputUser is now considered a player-only feature. Events queued during event processing (i.e. InputSystem.Update()) are now processed in the same frame. This eliminates the 1-frame lag previously incurred by simulated input. Note that this does not extend to input queued outside of event processing but in the same frame. For example, input queued by the UI (such as by OnScreenButton and OnScreenStick) will still see a 1-frame lag as UI event processing happens later in the frame and outside of input event processing. Actions When removing/unplugging a device, it will now also be removed from the device list of InputActionMap.devices and InputActionAsset.devices. var gamepad = InputSystem.AddDevice<Gamepad>(); var actions = new MyGeneratedActions(); actions.devices = new[] { gamepad }; InputSystem.RemoveDevice(gamepad); // `actions.devices` is now an empty array. Adding an action to a InputActionMap that is part of an InputActionAsset now requires all actions in the asset to be disabled (case 1288335). This used to trigger an Assert at runtime but now properly throws an InvalidOperationException. Fixed Fixed inputs in game view sometimes not working when running in the editor, as initial focus state could end up being incorrect. Fixed bad performance in Input Debugger with high-frequency devices (e.g. 1+ KHz gaming mice). Before, high event volumes led to excessive refreshes of debugger data. Fixed compile error on tvOS due to step counter support for iOS added in 1.1.0-preview.3. Fixed PS4- and PS3-specific rightTriggerButton and leftTriggerButton controls not being marked as synthetic and thus conflicting with rightTrigger and leftTrigger input (case 1293734). This manifested itself, for example, when using interactive rebinding and seeing rightTriggerButton getting picked instead of the expected rightTrigger control. Fixed changes to usages of devices in remote player not being reflected in Input Debugger. Fixed exceptions and incorrect values with HIDs using 32-bit fields (case 1189859). This happened, for example, with vJoy installed. Fixed InputUser no longer sending InputUserChange.ControlsChanged when adding a new user after previously, all users were removed. Fix contributed by Sven Herrmann in 1292. Fixed AxisDeadzoneProcessor min/max values not being settable to 0 in editor UI (case 1293744). Fixed blurry icons in input debugger, asset editor, input settings (case 1299595). Fixed clickCount not being incremented correctly by InputSystemUIInputModule for successive mouse clicks (case 1317239). Fixed UI not working after additively loading scenes with additional InputSystemUIInputModule modules (case 1251720). Fixed no OnPointerExit received when changing UI state without moving pointer (case 1232705). Fixed reference to .inputactions of Player Prefab referenced by PlayerInputManager being destroyed on going into play mode, if the player prefab was a nested prefab (case 1319756). Fixed \"Scheme Name\" label clipped in \"Add Control Schema\" popup window ([case 1199560]https://issuetracker.unity3d.com/issues/themes-input-system-scheme-name-is-clipped-in-add-control-schema-window-with-inter-default-font)). Fixed InputSystem.QueueEvent calls from within InputAction callbacks getting dropped entirely (case 1297339). Fixed InputSystemUIInputModule being in invalid state when added from Awake to a game object when entering playmode (case 1323566). Fixed Keyboard.current becoming null after OnScreenButton is disabled or destroyed (case 1305016). Actions Fixed rebinding not working for any discrete control that was held when the rebinding operation started (case 1317225). Fixed bindings being added to every InputAction in a collection when editing a collection of InputActions in the inspector. (case 1258578) Fixed Retrieving array element that was out of bounds and SerializedProperty ... has disappeared! errors when deleting multiple action bindings in the input asset editor (case 1300506). Fixed delete key not working in the input actions editor (case 1282090). Fixed actions embedded into MonoBehaviours not showing bindings added directly from within constructors (case 1291334). public class MyMB : MonoBehaviour { // This would end up not showing the binding in the inspector. public InputAction action = new InputAction(binding: \"<Gamepad>/leftStick\"); Fixed tooltips not appearing for elements of the Input Actions editor window (case 1311595). Fixed NullReferenceException when reading values through InputAction.CallbackContext on a OneModifierComposite or TwoModifierComposite binding. Fixed multi-taps not working when multiple controls were bound to an action (case 1267805). When there were multiple controls bound to an action, this bug would get triggered by any interaction that did not result in a phase change on the action. Fixed runtime rebinds added as new bindings from leaking into .inputactions assets when exiting play mode (case 1190502) Fixed IndexOutOfRangeException and null elements in InputUser.lostDevices when an InputUser loses a devices from a control scheme with only optional devices (case 1275148). Fixed binding path selection windows not remembering navigation state when going up through hierarchy (case 1254981). Added Support for Device Simulator touchscreen input. Enabled XR device support on Magic Leap (Lumin). Added ability to force XR Support in a project by defining UNITY_INPUT_FORCE_XR_PLUGIN. Added a warning message to PlayerInputManager editor when the attached input action asset won't work with Join Players When Button Is Pressed behaviour due to missing control scheme device requirements (case 1265853). Added support for UI Toolkit with Unity 2021.1+. UITK is now supported as a UI solution in players. Input support for both Unity UI and UI Toolkit is based on the same InputSystemUIInputModule code path. More details in the manual. InputSystemUIInputModule now has an xrTrackingOrigin property. When assigned, this will transform all tracked device positions and rotations from it's local space into Unity's world space (case 1308480). Added InputSystemUIInputModule.GetLastRaycastResult. This returns the most recent raycast result and can be used to draw ray visualizations or get information on the most recent UI object hit. Added InputStateBlock support for kFormatSBit when working with floats (case 1258003). Added an API to parse control paths. var parsed = InputControlPath.Parse(\"<XRController>{LeftHand}/trigger\").ToArray(); Debug.Log(parsed.Length); // Prints 2. Debug.Log(parsed[0].layout); // Prints \"XRController\". Debug.Log(parsed[0].name); // Prints an empty string. Debug.Log(parsed[0].usages.First()); // Prints \"LeftHand\". Debug.Log(parsed[1].layout); // Prints null. Debug.Log(parsed[1].name); // Prints \"trigger\". Can, for example, be used with InputBinding.path. Added a new API-only setting in the form of InputSystem.settings.maxEventBytesPerUpdate. Puts an upper limit on the number of event bytes processed in a single update. If exceeded, any additional event data will get thrown away and an error will be issued. Set to 5MB by default. Added a new API-only setting called InputSystem.settings.maxQueuedEventsPerUpdate. This limits the number of events that can be queued during event processing using the InputSystem.QueueEvent method. This guards against infinite loops in the case where an action callback queues an event that causes the same action callback to be called again. Added InputSystemUIInputModule.AssignDefaultActions to assign default actions when creating ui module in runtime. Added UNITY_INCLUDE_TESTS define constraints to our test assemblies, which is 2019.2+ equivalent to \"optionalUnityReferences\": [\"TestAssemblies\"]. [1.1.0-preview.3] - 2021-02-04 Changed An upper limit of 1024 controls per device and 1kb of memory state per device has been introduced. This allows for certain optimizations. Should the limits prove too tight, they can be raised in the future. The most complex device we have at the moment (Touchscreen) has 242 controls and 616 bytes of state. TouchSimulation now disables the Pointer devices it reads input from. This is to address the problem of mouse input leading to both mouse and touch input happening concurrently. Instead, enabling touch simulation will now effectively replace mouse and pen input with touch input. Devices such Mouse and Pen will remain in place but will not get updated. Events received for them will be consumed by TouchSimulation. Enabled XR device support on Switch. Fixed Fixed Right stick to use AXIS.Z and AXIS.RZ for Android gamepads. Fixed triggers to always use Axis.Gas and Axis.Brake for Android gamepads. Fixed precompiled layouts such as FastKeyboard leading to build time regressions with il2cpp (case 1283676). Fixed InputDevice.canRunInBackground not being correctly set for VR devices (thus not allowing them to receive input while the application is not focused). Fixed InputUser.OnEvent and RebindingOperation.OnEvent exhibiting bad performance profiles and leading to multi-millisecond input update times (case 1253371). In our own measurements, InputUser.OnEvent is >9 times faster than before and RebindingOperation.OnEvent is ~2.5 times faster. Fixed PS4 controller not recognized on Mac when connected over Bluetooth (case 1286449). Fixed EnhancedTouch leaking NativeArray memory on domain reloads (case 1190150). Fixed TouchSimulation leading to \"Pointer should have exited all objects before being removed\" errors (case 1190150). Fixed multi-touch not working with InputSystemUIInputModule (case 1271942). This also manifested itself when using On-Screen Controls and not being able to use multiple controls at the same time (for example, in the Warriors demo). Fixed restart prompt after package installation not appearing on Unity 2020.2+ (case 1292513). Fixed action with multiple bindings getting stuck in Performed state when two or more controls are pressed at the same time (case 1295535). Regression introduced in 1.1-preview.2. Fixed Touch.activeTouches having incorrect touch phases after calling EnhancedTouch.Disable() and then EnhancedTouch.Enable() (case 1286865). Fixed compile errors related to XR/AR on console platforms. Actions Fixed actions not triggering correctly when multiple bindings on the same action were referencing the same control (case 1293808). Bindings will now \"claim\" controls during resolution. If several bindings on the same action resolve to the same control, only the first such binding will successfully resolve to the control. Subsequent bindings will only resolve to controls not already referenced by other bindings on the action. var action = new InputAction(); action.AddBinding(\"<Gamepad>/buttonSouth\"); action.AddBinding(\"<Gamepad>/buttonSouth\"); // Will be ignored. action.AddBinding(\"<Gamepad>/button*\"); // Will only receive buttonWest, buttonEast, and buttonNorth. This also means that InputAction.controls will now only contain any control at most once. Fixed JSON serialization of action maps not preserving empty binding paths (case 1231968). Added Added DualShock4GamepadAndroid and XboxOneGamepadAndroid layout for Android Added a new high-performance way to iterate over changed controls in an event. // Can optionally specify a magnitude threshold that controls must cross. // NOTE: This will note allocate GC memory. foreach (var control in eventPtr.EnumerateChangedControls(magnitudeThreshold: 0.1f)) Debug.Log($\"Control {control} changed state\"); This can be used, for example, to implement much more performant \"any button pressed?\" queries. InputSystem.onEvent += (eventPtr, device) => { // Ignore anything that is not a state event. var eventType = eventPtr.type; if (eventType != StateEvent.Type && eventType != DeltaStateEvent.Type) return; // Find all changed controls actuated above the button press threshold. foreach (var control in eventPtr.EnumerateChangedControls (device: device, magnitudeThreshold: InputSystem.settings.defaultButtonPressThreshold)) // Check if it's a button. if (control is ButtonControl button) Debug.Log($\"Button {button} was pressed\"); } Added support for Step Counter sensors for iOS. You need to enable Motion Usage under Input System settings before using the sensor. You can also manually add Privacy - Motion Usage Description to your application's Info.plist file. [1.1.0-preview.2] - 2020-10-23 Changed The submit and the cancel actions of the UI input module now trigger on release instead of press. This makes the behavior consistent with clicks triggering UI response on release rather than press. Removed the old \"Tanks\" demo (previously available from the samples shipped with the package). Added a new and improved demo project, which you can download from the InputSystem_Warriors GitHub repository. Actions Actions of type InputActionType.Button now respect button press (and release) points. Previously, button-type actions, when used without explicit \"Press\" interactions, would perform immediately when a bound control was actuated. Now, a button-type action will behave the same as if a \"Press\" interaction is applied with \"Trigger Behavior\" set to \"Press Only\". This means that a button-type action will now perform (and perform once only) when a control crosses the button press threshold defined in the global settings or, if present, locally on a ButtonControl. It will then stay performed and finally cancel only when the control falls back to or below the release threshold. InputAction.ReadValue<T>() now always returns default<T> when the action is canceled. This is to make it consistent with InputAction.CallbackContext.ReadValue<T>() which already returned default<T> when the action was canceled. In general, all APIs that read values will return default values when an action is in a phase other than Started or Performed. If multiple actions in different action maps but in the same .inputactions asset have the same name, calling InputActionAsset.FindAction() with just an action name will now return the first enabled action. If none of the actions are enabled, it will return the first action with a matching name as before (case 1207550). var map1 = new InputActionMap(\"map1\"); var map2 = new InputActionMap(\"map2\"); map1.AddAction(\"actionWithSameName\"); map2.AddAction(\"actionWithSameName\"); var asset = ScriptableObject.CreateInstance<InputActionAsset>(); asset.AddActionMap(map1); asset.AddActionMap(map2); map2[\"actionWithSameName\"].Enable(); var action = asset[\"actionWithSameName\"]; // Before: \"map1/actionWithSameName\" // Now: \"map2/actionWithSameName\" Fixed Fixed player build causing ProjectSettings.asset to be checked out in Perforce (case 1254502). Fixed player build corrupting preloaded asset list in PlayerSettings if it was modified by another build processor. Fixed remoting in Input Debugger not working for devices in the player that are created from generated layouts (such as XR devices). Fixed potential NullReferenceException in InputActionProperty when the InputActionReference is null. Fixed \"On-Screen Controls\" sample still using StandaloneInputModule and thus throwing InvalidOperationException when used with \"Active Input Handling\" set to \"Input System Package (New)\" (case 1201866). Fixed OnScreenButton leaving button controls in pressed state when disabled in-between receiving OnPointerDown and OnPointerUp. Usually manifested itself by having to click the button twice next time it was enabled. Fixed exiting out of play mode in the Unity Editor while a test run is in progress leading to the Input System permanently losing all its state until the editor is restarted (case 1251724). Fixed max values for Axis and Double controls stored as multi-bit fields being off by one (case 1223436). Fix contributed by jamre in 962. Thank you! Fixed debug assert in InputDeviceTester sample when simultaneously pressing two buttons on gamepad (case 1244988). Fixed use of UI Slider causing drag thresholds to no longer work (case 1275834). Fixed layout lists in Input Debugger not updating when removing layouts. Fixed device connects leading to different but similar device being reported as reconnected. Actions Fixed Action with multiple bindings becoming unresponsive after a Hold interaction was performed (case 1239551). Fixed NullReferenceException when Player Input component Create Action is pressed and saved (case 1245921). Fixed InputActionTrace.ActionEventPtr.ReadValueAsObject leading to InvalidCastException when trying to read values that came from composite bindings. Fixed not being able to stack a MultiTap on top of a Tap (case 1261462). Fixed rebinds triggered by the Enter key causing stuck Enter key states (case 1271591). Fixed Map index on trigger and IndexOutOfRangeException errors when using multiple Interactions on the same Action. (case 1253034). Fixed context menu in action editor not filtering out composites the same way that the + icon menu does. This led to, for example, a \"2D Vector\" composite being shown as an option for a button type action. Fixed initial state checks for composite bindings failing if performed repeatedly. For example, doing a ReadValue<Vector2> for a WASD binding would return an incorrect value after disabling the map twice while no input from the keyboard was received (case 1274977). Fixed \"Add Interaction\" menu in action editor not filtering out interactions with incompatible value types (case 1272772). Fixed PlayerInput no longer auto-switching control schemes if neverAutoSwitchControlSchemes was toggled off and back on after the component was first enabled (case 1232039). Fixed action map name being the same as .inputactions asset name leading to compile errors when Generate C# Class is used; now leads to import error (case 1212052). Fixed bindings not getting updated when binding by display name and there is no control with the given display name initially. // If at the time this action is enabled, there's no ä key on the keyboard, // this did not update properly later when switched to a layout that does have the key. var action = new InputAction(binding: \"<Keyboard>/#(ä)\"); Added Added tvOS documentation entries in 'Supported Input Devices' page. Actions Added \"release thresholds\" for buttons. Release points are now separated from press points by a percentage threshold. The threshold is defined by InputSettings.buttonReleaseThreshold. Thresholds are defined as percentages of press points. A release is thus defined as a button, after having reached a value of at least InputSettings.defaultButtonPressPoint (or whatever local press is used), falling back to a value equal to or less than InputSettings.buttonReleaseThreshold percent of the press point. This is intended to solve the problem of buttons flickering around button press points. The default threshold is set at 75%, that is, buttons release at 3/4 of the press point. Added new methods to the InputAction class: InputAction.IsPressed(): Whether a bound control has crossed the press threshold and has not yet fallen back below the release threshold. InputAction.WasPressedThisFrame(): Whether a bound control has crossed the press threshold this frame. InputAction.WasReleasedThisFrame(): Whether a bound control has fallen back below the release threshold this frame. InputAction.WasPerformedThisFrame(): Whether the action was performed at any point during the current frame. Equivalent to InputAction.triggered, which will be deprecated in the future. InputAction.Reset(): Forcibly reset the action state. Cancels the action, if it is currently in progress. Added InputAction.GetTimeoutCompletionPercentage to query the amount left to complete a currently ongoing interaction. // Let's say there's a hold interaction on a \"warp\" action. The user presses a button bound // to the action and then holds it. While the user holds the button, we want to know how much // longer the user will have to hold it so that we can display feedback in the UI. var holdCompleted = playerInput.actions[\"warp\"].GetTimeoutCompletionPercentage(); Added three new binding composite types: OneModifierComposite: This is a generalization of ButtonWithOneModifier (which is still available but now hidden from the UI) which also represents bindings such as \"SHIFT+1\" but now can be used to target bindings other than buttons (e.g. \"SHIFT+delta\"). TwoModifiersComposite: This is a generalization of ButtonWithTwoModifiers (which is still available but now hidden from the UI) which also represents bindings such as \"SHIFT+CTRL+1\" but now can be used to target bindings other than buttons (e.g. \"SHIFT+CTRL+delta\"). Vector3Composite: Works the same way Vector2Composite does. Adds a forward and backward binding in addition to up, down, left, and right. [1.1.0-preview.1] - 2020-08-20 The minimum version requirement for the Input System package has been moved up to 2019.4 LTS. Changed Actions Auto-generated C# files now have <auto-generated> headers so they get ignored by Rider code analysis. Auto-generated C# classes are now partial so that they can be manually extended. Deleting a composite binding with action.ChangeBinding(0).Erase() now also erases all the bindings that are part of the composite. Trigger binding resolution from within action callbacks (e.g. InputAction.performed) will now defer resolution until after the callback has completed. This fixes crashes such as case 1242406 where disabling PlayerInput from within an action callback led to an action's state being released while the action was still in a callback. Fixed Fixed input history on Android mono build by alligning memory of history records Fixed no input being processed when running a [UnityTest] over several frames. Before, this required calling InputSystem.Update manually. Fixed clicking on help page button in Unity inspector for Input System components not going to relevant manual pages. Fixed a bug that prevented DualShock controllers from working on tvOS. (case 1221223). GravitySensor, LinearAccelerationSensor, and AttitudeSensor not being initialized on iOS (case 1251382). Fixed compilation issues with XR and VR references when building to platforms that do not have complete XR and VR implementations. Fixed possible NullReferenceExceptions on ARMs with controls that receive automatic memory offsets. Fixed TouchControl.tapCount resetting to 0 when \"Script Debugging\" is enabled (case 1194636). Fixed Touch.activeTouches not having a TouchPhase.Began entry for touches that moved in the same frame that they began in (case 1230656). Fixed sequential taps causing touches to get stuck in Touch.activeTouches. Improved performance of Touch.activeTouches (most notably, a lot of time was spent in endlessly repetitive safety checks). Fixed EnhancedTouch APIs not indicating that they need to be enabled with EnhancedTouchSupport.Enable(). The APIs now throw InvalidOperationException when used without being enabled. Fixed memory corruption in InputEventTrace.AllocateEvent (case 1262496) Manifested itself, for example, as crashes when using InputActionTrace.SubscribeToAll. AxisControls and Vector2Controls' X and Y subcontrols on XR devices now have a minimum range of -1 and a maximum range of 1. This means they can now properly respond to modifiers and interactions in the binding system. Actions Fixed drag&drop reordering actions while having one control scheme selected causing bindings from other control schemes to be lost (case 122800). Fixed stack overflow in PlayerInput.SwitchCurrentActionMap when called from action callback (case 1232893). Fixed control picker ending up empty when listing devices in \"Supported Devices\" (case 1254150). Added Device layouts can now be \"precompiled\" for speed. Keyboard, Mouse, and Touchscreen are now included as precompiled layouts greatly reducing instantiation time and GC heap cost for these devices. For Touchscreen, this results in a >20x speed-up for InputSystem.AddDevice<Touchscreen>(). Added Pose Control layout. The Pose Control is used on XR Devices and wraps tracking state, position, rotation, and velocity information. Actions Can now save binding overrides as JSON strings and restore them from such using the newly added SaveBindingOverridesAsJson and LoadBindingOverridesFromJson extension methods. void SaveUserRebinds(PlayerInput player) { var rebinds = player.actions.SaveBindingOverridesAsJson(); PlayerPrefs.SetString(\"rebinds\", rebinds); } void LoadUserRebinds(PlayerInput player) { var rebinds = PlayerPrefs.GetString(\"rebinds\"); player.actions.LoadBindingOverridesFromJson(rebinds); } [1.0.0] - 2020-04-23 Fixed Fixed compilation issues in TrackedDeviceRaycaster when disabling built-in XR module. [1.0.0-preview.7] - 2020-04-17 Fixed VirtualMouseInput not moving the software cursor when set to HardwareCursorIsAvailable but not having a hardware cursor () Can now override built-in Android gamepad layouts. Previously, the input system would always choose its default defaults even after registering more specific layouts using InputSystem.RegisterLayout. InputControlPath.TryGetControlLayout no longer throws NotImplementedException for <Mouse>/scroll/x and similar paths where the layout is modifying a control it inherited from its base layout (thread). Fixed compilation errors when disabling built-in VR and XR modules. (case 1214248). Fixed compilation errors when disabling built-in Physics and Physics2D modules. (case 1191392). No longer throws NotImplementedException when matching against a field of InputDeviceDescription.capabilities when the value of the field used scientific notation. No longer incorrectly matches fields of InputDeviceDescription.capabilities by prefix only (i.e. previously it would find the field \"foo\" when actually looking for \"foobar\"). Input device debugger window slowing editor to a crawl when opened on PS4 DualShock controller. InputUser.UnpairDevices() corrupting user device list. Actions Controls are now re-resolved after adding or removing bindings from actions (case 1218544). Can now have spaces and special characters in action names when using PlayerInput with the SendMessages or BroadcastMessages behavior. Previously, an incorrect method name was generated (fix contributed by BHSPitMonkey in #1022; case 1214519). Adding a new action now sets expectedControlType to Button as expected (case 1221015). Player joins with PlayerInputManager from button presses no longer fail if there are multiple devices of the same type present and the join was not on the first gamepad (case 226920). PlayerInputEditor no longer leads to the player's InputActionAsset mistakenly getting replaced with a clone when the inspector is open on a PlayerInput component (case 1228636). The control picker in the .inputactions editor will no longer incorrectly filter out layouts such as Xbox One Gamepad (on XB1) when using them in control schemes. Also, it will no longer filter out controls from base layouts (such as Gamepad) (case 1219415). RebindOperations will no longer pick controls right away that are already actuated above the magnitude threshold when the operation starts. Instead, these controls will have to change their actuation from their initial level such that they cross the magnitude threshold configured in the operation (case 1215784). Newly added actions and action maps are now scrolled to when there are more items than fit into view. Previously newly added item was appended but outside of the visible area. Actions and bindings in the .inputactions editor are no longer force-expanded on every domain reload and whenever a new action or binding is added. The importer for .inputactions assets will now check out from version control the generated .cs file when overwriting it – which only happens if the contents differ (case 1222972). The editor for .inputactions assets will now check out from version control the asset before saving it. Drag-reordering action maps no longer throws \"Should have drop target\" asserts in the console (case 1229146). Drag-reordering actions no longer changes action IDs of some of the existing actions (case 1231233). References to InputActionReference objects created by the importer for .inputactions files are no longer broken when the action referenced by the object is renamed (case 1229145). NOTE: This fix does not apply to existing InputActionReference instances. The problem was inherent in the internal file IDs generated for actions – which were affected by action and map names. Thus, changing the name of an action or map would change the resulting file ID of the InputActionReference. However, changing file IDs will break any existing reference to the object. Thus we had to preserve the existing InputActionReference objects under their original file ID. We hide them in the Project Browser, however. The ones that are visible now have the new, fixed file IDs. To switch existing InputActionReference properties to the new file IDs, simply replace them with the newly created InputActionReference. Changed InputDevice.all has been deprecated due to the confusion it creates with other getters like Gamepad.all. Use InputSystem.devices instead (case 1231216). In the same vein, we added a new Joystick.all getter that works the same as Gamepad.all. Changed UI Package to be optional dependency. Removing the package will now disable all UI relevant Input code. [1.0.0-preview.6] - 2020-03-06 Changed InputSystemUIInputModule.trackedDeviceSelect has been removed. Use InputSystemUIInputModule.leftClick instead. InputSystemUIInputModule.repeatDelay has been renamed to moveRepeatDelay and repeatRate has been renamed to moveRepeatRate. Fixed Fixed CS0109 warning being generated during player build due to use of new with the PlayerInput.camera property (case 1174688). Fixed a number of issues in InputSystemUIInputModule. Fixed GC heap garbage when click-dragging. Fixed number of pointer states growing indefinitely if OS did not reuse touch IDs. Fixed lastPress on PointerEventData getting lost. Fixed button press-and-release happening in same frame resulting in no UI input. Fixed clicks initiated from non-pointer devices resulting in pointer inputs with (0,0) positions. Fixed huge screen deltas on pointer events from tracked devices. Fixed touch input not sending pointer exit events (case 1213550). Fixed TrackedDeviceRaycaster not setting screenPosition in RaycastResult. Actions Mixing the enabling&disabling of single actions (as, for example, performed by InputSystemUIInputModule) with enabling&disabling of entire action maps (as, for example, performed by PlayerInput) no longer leaves to unresponsive input and \"should not reach here\" assertions (forum thread). Leaving play mode no longer leaves state change monitors lingering around from enabled actions. Enabling action maps with bindings that do not refer to an existing action in the map no longer leads to asserts and exceptions when input on the bindings is received (case 1213085). PressInteraction no longer misses the next button press if it gets reset from within the performed callback (case 1205285). InputBinding.DisplayStringOptions.DontIncludeInteractions is now properly respected. Reading the value of a composite binding no longer causes processors from the last active part binding to be applied rather than the processors of the composite itself, if any (case 1207082). Fixed InputSystem.onActionChange getting invoked too many times on binding changes. Added InputSystemUIInputModule now sends pointer events using a new ExtendedPointerEventData instead of using the base PointerEventData class. This surfaces additional input data in pointer events. Added InputSystemUIInputModule.pointerBehavior to allow dictating how the UI will resolve concurrent input from multiple pointers. Actions Added InputAction.CallbackContext.ReadValueAsButton. [1.0.0-preview.5] - 2020-02-14 Changed We've changed the rules that govern how action phases have to progress: This is a breaking change! The primary effect is additional callbacks getting triggered. Before: There were no enforced rules about how an action would go through InputAction.started, InputAction.performed, and InputAction.canceled. Which of the callbacks were triggered and in what order depended on a number of factors, the biggest influencer of which were the different interactions that could be applied to actions (like Press or Hold). This made for unpredictable and frequently surprising results. In addition, it led to bugs where, for example, adding a Press interaction to the Click action of InputSystemUIInputModule would cause the click state to get stuck because the click action would never cancel. Now: The system will now always trigger InputAction.started first. If this is not done explicitly, it happens implicitly. Likewise, the system will now always trigger InputAction.canceled before going back to waiting state. Like with InputAction.started, if this isn't done explicitly, it will happen implicitly. This implies that InputAction.canceled no longer signifies an action getting aborted because it stopped after it started but before it performed. It now simply means \"the action has ended\" whether it actually got performed or not. In-between InputAction.started and InputAction.canceled, InputAction.performed may be triggered arbitrary many times (including not at all). While late in the cycle for 1.0, we've opted to make this change now in order to fix a range of bugs and problems we've observed that people encountered because of the previous behavior of the system. Related to the change above, the behavior of PressInteraction has been tweaked and now is the following: Press Only: Starts and immediately performs when pressed, then stays performed and cancels when button is released. Release Only: Starts when button is pressed and then performs and immediately cancels when the button is released. Press And Release: Starts and immediately performs when button is pressed, then stays performed and performs again and immediately cancels when button is released. Vector2Composite now has a mode parameter which can be used to choose between DigitalNormalized (the default), Digital (same as DigitalNormalized but does not normalize the resulting vector), and Analog (uses float input values as is). Vector2Composite.normalize has been deprecated. Note that it will not work together with Analog. The parameter will be removed in the future. Fixed XR controllers and HMDs have proper display names in the UI again. This regressed in preview.4 such that all XR controllers were displayed as just \"XR Controller\" in the UI and all HMDs were displayed as \"XR HMD\". InputSystemUIInputModule no longer generates GC heap garbage every time mouse events are processed. Fixed a bug where an internal array helper method was corrupting array contents leading to bugs in both InputUser and Touch. Fixed exception when saving changes to an Input Action asset and the parent directory has been renamed. (case 1207527) Actions The regression in 1.0.0-preview.4 of PlayerInputManager not joining players correctly if a scheme has more than one device requirement has been fixed. This most notably manifested itself with keyboard+mouse control schemes. PlayerInputManager will no longer join players when control schemes are used and none of the schemes produces a successful match based on the devices available for the join. When no action map is selected in action editor, plus icon to add an action is now disabled; formerly threw an exception when clicked (case 1199562). Removing a callback from actions from the callback itself no longer throws ArgumentOutOfRangeException (case 1192972). \"Invalid user\" ArgumentException when turning the same PlayerInput on and off (case 1198889). The list of device requirements for a control scheme in the action editor no longer displays devices with their internal layout name rather than their external display name. StackOverflowException when Invoke Unity Events is selected in PlayerInput and it cannot find an action (#1033). HoldInteraction now stays performed after timer has expired and cancels only on release of the control (case 1195498). Foldouts in the various action UIs now properly toggle their expansion state when clicked in Unity 2019.3+ (case 1213781). Added We've added a new Simple Multiplayer sample which demonstrates a simple, bare-bones local multiplayer setup. We've also added a Gamepad Mouse Cursor sample that shows how to drive a UI mouse cursor using the gamepad. The sample contains a reusable VirtualMouseInput component that does most of the work. Added a Deselect On Background Click option to InputSystemUIInputModule. This allows toggling the behavior off where clicking the mouse and not hitting a GameObject will automatically clear the current selection -- which will break keyboard and gamepad navigation. [1.0.0-preview.4] - 2020-01-24 This release includes a number of Quality-of-Life improvements for a range of common problems that users have reported. Added To aid in debugging issues, we've extended the system's event tracing and replay functionality to allow persisting and replaying arbitrary input event streams. InputEventTrace now has APIs to persist the events to disk and to load them back in from previously persisted event streams. The same API can be used to persist in arbitrary C# Stream instances, not just in file streams. // Write. myTrace.WriteTo(\"file.inputtrace\"); // Read. InputEventTrace.LoadFrom(\"file.inputtrace\"); InputEventTrace now has built-in replay functionality. myTrace.Replay().PlayAllFramesOneByOne(); The event trace in device windows of the Input Debugger has been extended with controls to save and load traces. We've added a new InputRecording sample which has a reusable MonoBehaviour component that can be used to capture and replay device activity. Keyboard now has a FindKeyOnCurrentKeyboardLayout method to look up key controls by their display names. Keyboards now have synthetic controls that combine left and right variants of modifier keys. This means that you can bind to just \"shift\" now, for example, instead of having to bind to both \"left shift\" and \"right shift\". new InputAction(binding: \"<Keyboard>/shift\"); The controls are also available as properties on Keyboard. if (Keyboard.current.shiftKey.isPressed) /* ... */; // Is equivalent to: if (Keyboard.current.leftShiftKey.isPressed || Keyboard.current.rightShiftKey.isPressed) /* ... */; Actions PlayerInput now has a new Controls Changed event/message which is triggered when the control setup of the player changes (e.g. when switching control schemes). public void OnControlsChanged() { // Update UI display hints, for example... } We've added APIs to simplify turning bindings into strings suitable for display in UIs. // Takes things such as currently bound controls and active binding masks into account // and can handle composites. action.GetBindingDisplayString(); Related to this, custom binding composites can now be annotated with the new DisplayStringFormat attribute to control how composites as a whole are turned into display strings. [DisplayStringFormat(\"{button}+{stick}\")] public class MyComposite : InputBindingComposite<Vector2> { [InputControl(layout = \"Button\")] public int button; [InputControl(layout = \"Stick\")] public int stick; } InputActionRebindingExtension.RebindingOperation has a new configuration method WithMatchingEventsBeingSuppressed which allows suitable input events to automatically be swallowed while a rebind is ongoing. This greatly helps with not having something else respond to input while a rebind is in progress. We've added two new samples: Rebinding UI: Demonstrates how to create a rebinding screen using the Input System's APIs. The sample also includes a reusable prefab you can use directly in your projects to quickly put rebinding screens together. In-Game Hints: Demonstrates how to show context-sensitive help that respects the current control scheme. Changed The logic for resetting devices on focus loss has changed somewhat: When focus is lost, all devices are forcibly reset to their default state. As before, a RequestResetCommand for each device is also sent to the backend but regardless of whether the device responds or not, the input state for the device will be overwritten to default. Noisy controls are exempted from resets. The assumption here is that noisy controls most often represent sensor readings of some kind (e.g. tracking data) and snapping the values back to their default will usually If Application.runInBackground is true, all devices that return true from InputDevice.canRunInBackground are exempted from resets entirely. This, for example, allows XR devices to continue running regardless of focus change. This fixes problems such as keyboard keys getting stuck when alt-tabbing between applications (case 1206199). InputControlExtensions.GetStatePtrFromStateEvent no longer throws InvalidOperationException when the state format for the event does not match that of the device. It simply returns null instead (same as when control is found in the event's state). InputEventTrace instances are no longer disposed automatically from their finalizer but MUST be disposed of explicitly using Dispose(). This is to allow event traces to survive domain reloads. If they are disposed of automatically during finalizers, even if they survive the reload, the next GC will cause traces to be deallocated. Actions InputActionRebindingExtensions.PerformInteractiveRebinding has been greatly enhanced to apply a wide range of default configurations to the rebind. This greatly reduces the need to manually configure the resulting rebind. // Start a rebind with the default configuration. myAction.PerformInteractiveRebinding().Start(); Pointer position input will be ignored by default. If not a suitable binding target itself, <Keyboard>/escape will automatically be made to quit the rebind. Events with control input not explicitly matching exclusions will now get suppressed. This prevents input actions from getting triggered while a rebind is in progress. The expected control type is automatically adjusted if a part binding of a composite is targeted by the rebind (e.g. if the action expects a Vector2 but the part binding expects a Button, the rebind switches automatically to Button). If the targeted binding is part of a control scheme, controls will automatically be restricted to match the device requirements of the control scheme. For example, if the binding belongs to a \"Keyboard&Mouse\" scheme that has <Keyboard> and a <Mouse> requirement, the rebind will ignore input on gamepads. As before, you can always create a RebindingOperation from scratch yourself or wipe/alter the configuration returned by PerformInteractiveRebinding however you see fit. Control schemes can now handle ambiguity. This means that, for example, you can now have one control scheme for generic gamepads and another control scheme specifically for PS4 controllers and the system will reliably pick the PS4 scheme when a PS4 controller is used and fall back to the generic gamepad scheme otherwise. While this is exposed as a new score property on InputControlScheme.MatchResult, no code changes are necessary to take advantage of this feature. PlayerInput.active has been renamed to PlayerInput.inputIsActive to avoid ambiguities with GameObject activation. Fixed InputUser in combination with touchscreens no longer throws InvalidOperationException complaining about incorrect state format. In a related change, InputControlExtensions.GetStatePtrFromStateEvent now works with touch events, too. Stack overflow in InputTestFixture.currentTime getter. Input that occurs in-between pressing the play button and the game starting no longer leaks into the game (case 1191342). This usually manifested itself as large accumulated mouse deltas leading to such effects as the camera immediately jerking around on game start. Removing a device no longer has the potential of corrupting state change monitors (and thus actions getting triggered) from other devices. This bug led to input being missed on a device once another device had been removed. TrackedDevice layout is no longer incorrectly registered as Tracked Device. Event traces in the input debugger are no longer lost on domain reloads. IndexOutOfRangeException being thrown when looking up controls on XR devices. Actions Clicking the \"Replace with InputSystemUIInputModule\" button in the inspector when looking at StandaloneInputModule, the resulting operation is now undoable and will properly dirty the scene. [1.0.0-preview.3] - 2019-11-14 Fixed Fixed wrong event handlers getting removed when having three or more handlers on an event (case 1196143). This was an bug in an internal data structure that impacted a number of code paths that were using the data structure. Fixed LayoutNotFoundException being thrown when InputControlPath.ToHumanReadableString referenced a layout that could not be found. [1.0.0-preview.2] - 2019-11-04 Changed Automatic conversion of window coordinates in EditorWindow code is now performed regardless of focus or the setting of Lock Input to Game View in the input debugger. Fixed Fixed touch taps triggering when they shouldn't on Android. Fixed custom devices registered from [InitializeOnLoad] code being lost on domain reload (case 1192379). This happened when there were multiple pieces of [InitializeOnLoad] code that accessed the input system in the project and the RegisterLayout for the custom device happened to not be the first in sequence. OpenVR touchpad controls (touchpadClicked & touchpadPressed) now report accurate data. Actions Fixed missing keyboard bindings in DefaultInputActions.inputactions for navigation in UI. Fixed using C# reserved names in .inputactions assets leading to compile errors in generated C# classes (case 1189861). Assigning a new InputActionAsset to a InputSystemUIInputModule will no longer look up action names globally but rather only look for actions that are located in action maps with the same name. Previously, if you e.g. switched from one asset where the point action was bound to UI/Point to an asset that had no UI action map but did have an action called Point somewhere else, it would erroneously pick the most likely unrelated Point action for use by the UI. Fixed missing custom editors for AxisDeadzoneProcessor and StickDeadzoneProcessor that link min and max values to input settings. Fixed actions ending up being disabled if switching to a control scheme that has no binding for the action (case 1187377). Fixed part of composite not being bound leading to subsequent part bindings not being functional (case 1189867). Fixed PlayerInput not pairing devices added after it was enabled when not having control schemes. This problem would also show in the SimpleDemo sample when having the CustomDeviceUsages sample installed as well. Gamepads would not get picked up in that case. Fixed ArgumentNullException when adding a device and a binding in an action map had an empty path (case 1187163). Fixed bindings that are not associated with any control scheme not getting enabled with other control schemes as they should. Added Added a new EditorWindow Demo sample that illustrates how to use the input system in editor UI code. [1.0.0-preview.1] - 2019-10-11 Changed Generated action wrappers now won't Destroy the generated Asset in a finalizer, but instead implement IDisposable. Added back XR layouts (except for Magic Leap) that were removed for 1.0-preview. We removed these layouts under the assumption that they would almost concurrently become available in the respective device-specific XR packages. However, this did not work out as expected and the gap here turned out to be more than what we anticipated. To deal with this gap, we have moved the bulk of the XR layouts back and will transition things gradually as support in device-specific packages becomes publicly available. Fixed Fixed a bug where the Input Settings Window might throw exceptions after assembly reload. Correctly implemented IsPointerOverGameObject method for InputSystemUIInputModule. Several bugs with layout overrides registered with (InputSystem.RegisterLayoutOverrides). In 1.0-preview, layout overrides could lead to corruption of the layout state and would also not be handled correctly by the various editor UIs. Selecting a layout in the input debugger no longer selects its first child item, too. Fixed XR devices reporting noise as valid user input (should fix problem of control schemes involving VR devices always activating when using PlayerInput). Fixed tap/swipe gesture detection in touch samples. Actions Fixed a bug where multiple composite bindings for the same controls but on different action maps would throw exceptions. Fixed anyKey not appearing in control picker for Keyboard. The text on the \"Listen\" button is no longer clipped off on 2019.3. Controls bound to actions through composites no longer show up as duplicates in the input debugger. Fixed \"Create Actions...\" on PlayerInput creating an asset with an incorrect binding for taps on Touchscreens. NOTE: If you have already created an .inputactions asset with this mechanism, update \"tap [Touchscreen]\" to \"Primary Touch/Tap\" to fix the problem manually. Fixed Invoke CSharp Events when selected in PlayerInput not triggering PlayerInput.onActionTriggered. Fixed duplicating multiple items at the same time in the action editor duplicating them repeatedly. Added Will now recognize Xbox One and PS4 controllers connected to iOS devices correctly as Xbox One and PS4 controllers. Added a new sample called \"Custom Device Usages\" that shows how to use a layout override on Gamepad to allow distinguishing two gamepads in bindings based on which player the gamepad is assigned to. Added abstract TrackedDevice input device class as the basis for various kinds of tracked devices. [1.0.0-preview] - 2019-09-20 Fixed Will now close Input Action Asset Editor windows from previous sessions when the corresponding action was deleted. Fixed an issue where Stick Controls could not be created in Players built with medium or high code stripping level enabled. Fixed incorrect default state for axes on some controllers. Actions Fixed CallbackContext.ReadValue throwing when invoked during device removal Changed Added [0.9.6-preview] - 2019-09-06 Fixed Exceptions in scenes of Visualizers sample if respective device was not present on system (e.g. in PenVisualizer if no pen was present in system). Fixed exception in Input Action Asset Editor window when typing whitespace into the search field. Fixed control scheme popup window in input action asset editor window showing in the correct screen position on windows. Actions Setting timeouts from IInputInteraction.Process not working as expected when processing happened in response to previous timeout expiring (#714). Pending timeouts on a device not being removed when device was removed. Changed Replaced HIDSupport.shouldCreateHID event with a new HIDSupport.supportedHIDUsages property, which takes an array of supported usages. Added Actions Added PlayerInput.neverAutoSwitchControlSchemes to disable logic that automatically enables control scheme switching when there is only a single PlayerInput in the game. Added PlayerInput.SwitchControlScheme to switch schemes manually. [0.9.5-preview] - 2019-08-29 Fixed Don't pass events for null devices (for devices which have not been created) to InputSystem.onEvent callbacks. Will close debugger input state windows, when the state is no longer valid instead of throwing exceptions. Fixed pointer coordinates in editor windows for non-mouse pointing devices. Fixed using the input system in il2cpp when managed stripping level is set higher then \"Low\". Device debugger window will still show when reading from specific controls throws exceptions. Offsets and sizes for elements on Linux joysticks are now computed correctly. Joysticks now have a deadzone processor on the stick itself. Up/down/left/right on sticks are now deadzoned just like X and Y on sticks are. Removed toplevel X and Y controls on HIDs when there is a Stick/X and Stick/Y added for the device. HID fallback can now deal with sticks that have X and Y controls of different sizes and sitting in non-contiguous locations in the HID input report. Button 1 on HID joysticks will now correctly come out as the trigger control. Previously, the trigger control on the joystick was left pointing to random state. Actions Binding paths now show the same way in the action editor UI as they do in the control picker. For example, where before a binding to <XInputController>/buttonSouth was shown as rightShoulder [XInputController], the same binding will now show as A [Xbox Controller]. When deleting a control scheme, bindings are now updated. A dialog is presented that allows choosing between deleting the bindings or just unassigning them from the control scheme. When renaming a control scheme, bindings are now updated. Previously the old name was in place on bindings. Control scheme names can no longer be set to empty strings. PlayerInput.Instantiate now correctly sets up a given control scheme, if specified. When passing a controlScheme: argument, the result used to be a correctly assigned control scheme at the InputUser level but no restrictions being actually applied to the bindings, i.e. every single binding was active regardless of the specified control scheme. NullReferenceExceptions during event processing from RebindingOperation. Changed InputUser.onUnpairedDeviceUsed now receives a 2nd argument which is the event that triggered the callback. Also, the callback is now triggered BEFORE the given event is processed rather than after the event has already been written to the device. This allows updating the pairing state of the system before input is processed. In practice, this means that, for example, if the user switches from keyboard&mouse to gamepad, the initial input that triggered the switch will get picked up right away. InputControlPath.ToHumanReadableString now takes display names from registered InputControlLayout instances into account. This means that the method can now be used to generate strings to display in rebinding UIs. AxisControl.clamp is now an enum-valued property rather than a bool. Can now perform clamping before normalization. Actions When switching devices/controls on actions, the system will no longer subsequently force an initial state check on all actions. Instead, every time an action's bindings get re-resolved, the system will simply cancel all on-going actions and then re-enable them the same way it would happen by manually calling InputAction.Enable. Removed non-functional InputControlScheme.baseScheme API and basedOn serialized property. This was never fully implemented. Added Can right-click devices in Input Debugger (also those under \"Unsupported\") and select \"Copy Device Description\" to copy the internal InputDeviceDescription of the device in JSON format to the system clipboard. This information is helpful for us to debug problems related to specific devices. If a device description has been copied to the clipboard, a new menu \"Paste Device Description as Device\" entry in the \"Options\" menu of the input debugger appears. This instantiates the device from the description as if it was reported locally by the Unity runtime. [0.9.3-preview] - 2019-08-15 Fixed XInputController and XboxOneGamepad no longer have two extraneous, non-functional \"menu\" and \"view\" buttons. Fixed InputUser.onUnpairedDeviceUser ignoring input on controls that do not support EvaluateMagnitude. This led to situations, for example, where PlayerInput would not initialize a control scheme switch from a <Mouse>/delta binding as the delta X and Y axes do not have min&max limits and thus return -1 from EvaluateMagnitude. Fixed available processor list not updated right away when changing the action type in the Input Action editor window. Actions NullReferenceException when the input debugger is open with actions being enabled. When selecting a device to add to a control scheme, can now select devices with specific usages, too (e.g. \"LeftHand\" XRController). Changed Removed timesliceEvents setting - and made this tied to the update mode instead. We now always time slice when using fixed updates, and not when using dynamic updates. When adding a composite, only ones compatible with the value type of the current action are shown. This will, for example, no longer display a 2D Vector composite as an option on a floating-point button action. The InputState.onChange callback now receives a second argument which is the event (if any) that triggered the state change on the device. Added InputSystemUIInputModule can now track multiple pointing devices separately, to allow multi-touch input - required to allow control of multiple On-Scree controls at the same time with different fingers. Two new composite bindings have been added. ButtonWithOneModifier can be used to represent shortcut-like bindings such as \"CTRL+1\". ButtonWithTwoModifiers can be used to represent shortcut-like bindings such as \"CTRL+SHIFT+1\". [0.9.2-preview] - 2019-08-09 Fixed A RebindingOperation will now fall back to the default path generation behavior if the callback provided to OnGeneratePath returns null. Fixed the Input Action editor window throwing exceptions when trying to view action properties. Actions PlayerInput will now copy overrides when creating duplicate actions. It is now possible to use an empty binding path with a non empty override path. It is now possible to use set an empty override path to disable a binding. It is not possible to query the effectively used path of a binding using effectivePath. Actions embedded into MonoBehaviour components can now have their properties edited in the inspector. Previously there was no way to get to the properties in this workflow. There is a gear icon now on the action that will open the action properties. Changed Added Added a new sample to the package called SimpleDemo. You can install the sample from the package manager. See the README.md file for details about the sample. [0.9.1-preview] - 2019-08-08 Fixed Fixed GC heap garbage being caused by triggered by event processing. This meant that every processing of input would trigger garbage being allocated on the managed heap. The culprit was a peculiarity in the C# compiler which caused a struct in InputEventPtr.IsA to be allocated on the heap. The bindings selection popup window will now show child controls matching the current action type even if the parent control does not match. Fixed duration values reported for Hold and Press interactions. DualShock 3 on macOS: Fixed actions bound to the dpad control performing correctly. Fixed non-present touchpad button control being triggered incorrectly. Fixed compile issues with switch classes on standalone Linux. Leak of unmanaged memory in InputControlList. Actions Fixed actions not updating their set of controls when the usages of a device are changed. Composite bindings with the default interaction will now correctly cancel when the composite is released, even if there are multiple composite bindings on the action. Changed MouseState, KeyboardState, and GamepadState have been made public again. PlayerInput and PlayerInputManager have been moved from the UnityEngine.InputSystem.PlayerInput namespace to UnityEngine.InputSystem. The signature of InputSystem.onEvent has changed. The callback now takes a second argument which is the device the given event is sent to (null if there's no corresponding InputDevice). // Before: InputSystem.onEvent += eventPtr => { var device = InputSystem.GetDeviceById(eventPtr.deviceId); //... }; // Now: InputSystem.onEvent += (eventPtr, device) => { //... }; The signatures of InputSystem.onBeforeUpdate and InputSystem.onAfterUpdate have changed. The callbacks no longer receive an InputUpdateType argument. Use InputState.currentUpdateType in case you need to know the type of update being run. InputUpdateType has been moved to the UnityEngine.InputSystem.LowLevel namespace. InputSystem.Update(InputUpdateType) has been removed from the public API. The way input devices are built internally has been streamlined. InputDeviceBuilder is now internal. It is no longer necessary to access it to look up child controls. Simply use InputControl.GetChildControl instead. To build a device without adding it to the system, call the newly added InputDevice.Build method. InputDevice.Build<Mouse>(); InputSystem.SetLayoutVariant has been removed. Layout variants can no longer be set retroactively but must be decided on as part of device creation. InputSystem.RegisterControlProcessor has been renamed to just InputSystem.RegisterProcessor. Actions InputAction.ReadValue<TValue>() is longer correlated to InputAction.triggered. It simply returns the current value of a bound control or composite while the action is being interacted with. InputInteractionContext.PerformedAndGoBackToWaiting has been renamed to just InputInteractionContext.Performed. Actions Individual composite part bindings can now no longer have interactions assigned to them as that never made any sense. Added Devices can now have more than one usage. Call InputSystem.AddDeviceUsage(device,usage) to add additional usages to a device. Call InputSystem.RemoveDeviceUsage(device,usage) to remove existing usages from a device. InputSystem.SetDeviceUsage(device,usage) still exists. It will clear all existing usages from the given device. A new VisualizerSamples sample that can be installed through the package manager. Contains two components InputControlVisualizer and InputActionVisualizer that help visualizing/debugging control/device and action activity through in-game overlays. A few sample scenes illustrate how to use them. Actions Added InputAction.ReadValueAsObject API. Added InputAction.activeControl API. [0.9.0-preview] - 2019-07-18 Fixed Validate all parameters on public APIs. Fixed an internal bug in InlinedArray.RemoveAtByMovingTailWithCapacity, which could cause data corruption. Fixed Xbox controller support on macOS il2cpp. Fixed issue of Xbox gamepads on Windows desktop not being able to navigate left and down in a UI. Allow using InputSystem package if the XR, VR or Physics modules are disabled for smaller builds. Fixed documentation landing page and table of contents. Fixed tracked devices assigning pointer ids for UI pointer events correctly. Adjusted some UI Elements to fit the Unity 19.3 font. Fixed NullReferenceException being thrown when project changes. Fixed duplicate devices showing in the \"Supported Devices\" popup when using a search filter. Fixed an error when adding new bindings in the Input Actions editor window when a filter was applied. Fixed scroll wheel handling in InputSystemUIInputModule not being smooth. Fixed compile errors from Switch Pro controller code on Linux. Actions Fixed CallbackContext.control referencing the composite member control which was actually actuated for this trigger for composite bindings. Generated C# wrappers for .inputactions assets are no longer placed in Assets/Assets/ folder on Windows. Added Touch support has been reworked and extended. Touchscreen.touch[0..9] are now bindable from the control picker. Touchscreen.primaryTouch is now a separate control which tracks the primary touch on the screen. The controls Touchscreen inherits from Pointer (such as position, phase, and delta) are now tied to Touchscreen.primaryTouch and allow for Touchscreen to function as a generic Pointer (like Mouse and Pen). Touchscreen.press (renamed from Touchscreen.button) is now a working, synthetic button that is down whenever at least one finger is on the screen. Recording of start time and start position has been added to touches. TouchControl.startPosition gives the starting position of the touch. TouchControl.startTime gives the starting time of the touch. Tap detection has been added to Touchscreen. Tap time (i.e. time within which a press-and-release must be completed for a tap to register) corresponds to InputSettings.defaultTapTime. Tap release must happen within a certain radius of first contact. This is determined by a new setting InputSettings.tapRadius. TouchControl.tap is a new button control that triggers then the touch is tapped. Note that this happens instantly when a touch ends. The button will go to 1 and immediately go back to 0. This means that polling the button in Update, for example, will never trigger a tap. Either use actions to observe the button or use the Touch API from EnhancedTouch to poll taps. Touchscreen.activeTouches has been removed. Use Touch.activeTouches from the new enhanced touch API instead for more reliable touch tracking. Touchscreen.allTouchControls has been renamed to Touchscreen.touches. A new EnhancedTouch plugin has been added which offers an enhanced Touch and Finger API to reliably track touches and fingers across updates. This obsoletes the need to manually track touch IDs and phases and gives access to individual touch history. Touch can be simulated from mouse or pen input now. To enable simulation, call TouchSimulation.Enable() or put the TouchSimulation MonoBehaviour in your scene. Also, in the input debugger, you can now enable touch simulation from the \"Options\" dropdown. Changing state has been decoupled from events. While input events are the primary means by which to trigger state changes, anyone can perform state changes manually now from anywhere. InputState.Change(gamepad.leftStick, new Vector2(123, 234)); This change makes it possible to update state from state and thus synthesize input data from other input coming in. A new API for recording state changes over time has been added. var history = new InputStateHistory(\"<Gamepad>/leftStick\"); history.StartRecording(); //... foreach (var record in history) Debug.Log(record); Added support for generic joysticks on WebGL (which don't use the standard gamepad mapping). Added support for DualShock 3 gamepads on desktops. Added support for Nintendo Switch Pro Controllers on desktops. Actions Actions now also have a polling API! InputAction.triggered is true if the action was performed in the current frame. InputAction.ReadValue<TValue>() yields the last value that started, performed, or cancelled (whichever came last) was called with. If the action is disabled, returns default(TValue). For InputActionType.Button type actions, returns 1.0f if triggered==true and 0.0f otherwise. Generated C# wrappers for .inputactions can now placed relative to the .inputactions file by specifying a path starting with './' (e.g. ./foo/bar.cs). Changed The system no longer supports processing input in BOTH fixed and dynamic updates. Instead, a choice has to be made whether to process input before each FixedUpdate() or before each Update(). Rationale: the existing code that supported having both updates receive input independently still had several holes and became increasingly complex and brittle. Our solution was based on not actually processing input twice but on channeling input concurrently into both the state of both updates. Together with the fact that specific inputs have to reset (and possibly accumulate) correctly with respect to their update time slices, this became increasingly hard to do right. This, together with the fact that we've come to increasingly question the value of this feature, led us to removing the capability while preserving the ability to determine where input is processed. NOTE: Timeslicing is NOT affected by this. You can still switch to ProcessEventInFixedUpdates and get events timesliced to individual FixedUpdate periods according to their timestamps. InputSettings.UpdateMode.ProcessEventsInBothFixedAndDynamicUpdate has been removed. InputSettings.UpdateMode.ProcessEventsInDynamicUpdateOnly has been renamed to InputSettings.UpdateMode.ProcessEventsInDynamicUpdate and is now the default. InputSettings.UpdateMode.ProcessEventsInFixedUpdateOnly has been renamed to InputSettings.UpdateMode.ProcessEventsInFixedUpdate. Added icons for PlayerInput, PlayerInputManager, InputSystemUIInputModule and MultiplayerEventSystem components. Changed Keyboard IME properties (imeEnabled, imeCursorPosition) to methods (SetIMEEnabled, SetIMECursorPosition). Added getters to all IInputRuntime properties. Replace some GetXxx methods in our API with xxx properties. Pointer.phase has been removed and PointerPhase has been renamed to TouchPhase. Phases are now specific to touch. PointerPhaseControl has been renamed to TouchPhaseControl. Pointer.button has been renamed to Pointer.press and now is a control that indicates whether the pointer is in \"press down\" state. For mouse, corresponds to left button press. For pen, corresponds to tip contact. For touch, corresponds to primary touch contact (i.e. whether any finger is down). The state change monitor APIs (IInputStateChangeMonitor and friends) have been moved out of InputSystem into a new static class InputState in UnityEngine.Experimental.Input.LowLevel. Rationale: These APIs are fairly low-level and not of general interest so having them out of InputSystem reduces the API surface visible to most users. InputDeviceChange.StateChanged has been removed and is now a separate callback InputState.onChange. Rationale: The other InputDeviceChange notifications are low-frequency whereas StateChanged is high-frequency. Putting them all on the same callback made adding a callback to InputSystem.onDeviceChange unnecessarily expensive. IInputStateCallbackReceiver has been rewritten from scratch. Now has two simple methods OnNextUpdate and OnEvent. If implemented by a device, the device now has completely control over changing its own state. Use the InputState.Change methods to affect state changes while trigger state change monitors (e.g. for actions) correctly. Simplified handling of XR input in InputSystemUIInputModule by having only one set of actions for all XR devices. We now use the same hierarchical device picker in the \"Add Control Scheme\" popup, which is already used in the \"Input Settings\" window. Made all IInputStateTypeInfo implementations internal, as these did not offer value to the user. Made all IInputDeviceCommandInfo implementations internal, as these did not offer value to the user. Removed ReadWriteArray, which was only used for making RebindingOperation.scores editable, which did not add any value. Removed PrimitiveValueOrArray, as non of it's functionality over PrimitiveValue was implemented. Made all InputProcessor implementation internal, as access to these types is exposed only through text mode representations. Removed CurveProcessor as it was not implemented. Renamed XInputControllerOSX to a more descriptive XboxGamepadMacOS. Actions InputAction.continuous has been removed. Running logic every frame regardless of input can easily be achieved in game code. The way action behavior is configured has been simplified. The previous roster of toggles has been replaced with two settings: Action Type: Determines the behavior of the action. Choices are Value, Button, and PassThrough. Control Type: Determines the type of control (and implicitly the type of value) the action is looking for if the action is a Value or PassThrough action. The previous Initial State Check toggle is now implicit in the action type now. Value actions perform an initial state check (i.e. trigger if their control is already actuated when the action is enabled). Other types of actions don't. The previous Pass Through toggle is now rolled into the action type. [0.2.10-preview] - 2019-05-17 Added Added a MultiplayerEventSystem class, which allows you use multiple UI event systems to control different parts of the UI by different players. InputSystemUIInputModule now lets you specify an InputActionAsset in the actionsAsset property. If this is set, the inspector will populate all actions from this asset. If you have a PlayerInput component on the same game object, referencing the same InputActionAsset, the PlayerInput component will keep the actions on the InputSystemUIInputModule in synch, allowing easy setup of multiplayer UI systems. Changed StickControl.x and StickControl.y are now deadzoned, i.e. have AxisDeadzone processors on them. This affects all gamepads and joysticks. NOTE: The deadzoning is independent of the stick. Whereas the stack has a radial deadzones, x and y have linear deadzones. This means that leftStick.ReadValue().x is not necessary equal to leftStick.x.ReadValue(). This change also fixes the problem of noise from sticks not getting filtered out and causing devices such as the PS4 controller to constantly make itself Gamepad.current. Redesigned UIActionInputModule Added a button in the inspector to automatically assign actions from an input action asset based on commonly used action names. Will now populate actions with useful defaults. Removed clickSpeed property - will use native click counts from the OS where available instead. Removed sendEventsWhenInBackground property. Hiding Touches and TrackedDevices until we decide how to handle them. Remove moveDeadzone property as it is made redundant by the action's dead zone. Removed UIActionInputModuleEnabler component, UIActionInputModule will now enable itself. Changed default button press point to 0.5. Changed all constants in public API to match Unity naming conventions (\"Constant\" instead of \"kConstant\"). Changed namespace from UnityEngine.Experimental.Input to UnityEngine.InputSystem. Generated wrapper code now has nicer formatting. Renamed UIActionInputModule to InputSystemUIInputModule. Nicer icons for InputActionAssets and InputActions and for Button and generic controls. Change all public API using IntPtr to use unsafe pointer types instead. PlayerInput will no longer disable any actions not in the currently active action map when disabling input or switching action maps. Change some public fields into properties. Input System project settings are now called \"Input System Package\" in the project window instead of \"Input (NEW)\". Removed Plugins from all namespaces. Rename \"Cancelled\" -> \"Canceled\" (US spelling) in all APIs. Fixed Adding devices to \"Supported Devices\" in input preferences not allowing to select certain device types (like \"Gamepad\"). Fixed scrolling in UIActionInputModule. Fixed compiling the input system package in Unity 19.2 with ugui being moved to a package now. In the Input System project settings window, you can no longer add a supported device twice. Actions Custom inspector for PlayerInput no longer adds duplicates of action events if Invoke Unity Events notification behavior is selected. Fixed Hold interactions firing immediately before the duration has passed. Fixed editing bindings or processors for InputAction fields in the inspector (Changes wouldn't persist before). Fixed exception message when calling CallbackContext.ReadValue<TValue>() for an action with a composite binding with TValue not matching the composite's value type. Added Actions PlayerInput can now handle .inputactions assets that have no control schemes. Will pair all devices mentioned by any of the bindings except if already paired to another player. [0.2.8-preview] - 2019-04-23 Added Added a clickCount control to the Mouse class, which specifies the click count for the last mouse click (to allow distinguishing between single-, double- and multi-clicks). Support for Bluetooth Xbox One controllers on macOS. Actions New API for changing bindings on actions // Several variations exist that allow to look up bindings in various ways. myAction.ChangeBindingWithPath(\"<Gamepad>/buttonSouth\") .WithPath(\"<Keyboard>/space\"); // Can also replace the binding wholesale. myAction.ChangeBindingWithPath(\"<Keyboard>/space\") .To(new InputBinding { ... }); // Can also remove bindings programmatically now. myAction.ChangeBindingWithPath(\"<Keyboard>/space\").Erase(); Changed Joystick.axes and Joystick.buttons have been removed. Generated wrapper code for Input Action Assets are now self-contained, generating all the data from code and not needing a reference to the asset; InputActionAssetReference has been removed. The option to generate interfaces on wrappers has been removed, instead we always do this now. The option to generate events on wrappers has been removed, we felt that this no longer made sense. Will now show default values in Input Action inspector if no custom values for file path, class name or namespace have been provided. InputSettings.runInBackground has been removed. This should now be supported or not on a per-device level. Most devices never supported it in the first place, so a global setting did not seem to be useful. Several new Sensor-based classes have been added. Various existing Android sensor implementations are now based on them. InputControlLayoutAttribute is no longer inherited. Rationale: A class marked as a layout will usually be registered using RegisterLayout. A class derived from it will usually be registered the same way. Because of layout inheritance, properties applied to the base class through InputControlLayoutAttribute will affect the subclass as intended. Not inheriting the attribute itself, however, now allows having properties such as isGenericTypeOfDevice which should not be inherited. Removed acceleration, orientation, and angularVelocity controls from DualShockGamepad base class. They are still on DualShockGamepadPS4. The reason is that ATM we do not yet support these controls other than on the PS4. The previous setup pretended that these controls work when in fact they don't. Marking a control as noisy now also marks all child controls as noisy. The input system now defaults to ignoring any HID devices with usage types not known to map to game controllers. You can use HIDSupport.supportedUsages to enable specific usage types. In the Input Settings window, asset selection has now been moved to the \"gear\" popup menu. If no asset is created, we now automatically create one. In the inspector for Input Settings assets, we now show a button to go to the Input Settings window, and a button to make the asset active if it isn't. Tests are now no longer part of the com.unity.inputsystem package. The InputTestFixture class still is for when you want to write input-related tests for your project. You can reference the Unity.InputSystem.TestFixture assembly when you need to do that. Implemented adding usages to and removing them from devices. Actions A number of changes have been made to the control picker UI in the editor. The button to pick controls interactively (e.g. by pressing a button on a gamepad) has been moved inside the picker and renamed to \"Listen\". It now works as a toggle that puts the picker into a special kind of 'search' mode. While listening, suitable controls that are actuated will be listed in the picker and can then be picked from. Controls are now displayed with their nice names (e.g. \"Cross\" instead of \"buttonSouth\" in the case of the PS4 controller). Child controls are indented instead of listed in \"parent/child\" format. The hierarchy of devices has been rearranged for clarity. The toplevel groups of \"Specific Devices\" and \"Abstract Devices\" are now merged into one hierarchy that progressively groups devices into more specific groups. Controls now have icons displayed for them. There is new support for binding to keys on the keyboard by their generated character rather than by their location. At the toplevel of the Keyboard device, you now have the choice of either binding by keyboard location or binding by generated/mapped character. Binding by location shows differences between the local keyboard layout and the US reference layout. The control path language has been extended to allow referencing controls by display name. <Keyboard>/#(a) binds to the control on a Keyboard with the display name a. continuous flag is now ignored for Press and Release interactions, as it did not make sense. Reacting to controls that are already actuated when an action is enabled is now an optional behavior rather than the default behavior. This is a breaking change. Essentially, this change reverts back to the behavior before 0.2-preview. To reenable the behavior, toggle \"Initial State Check\" on in the UI or set the initialStateCheck property in code. The reason for the change is that having the behavior on by default made certain setups hard to achieve. For example, if <Keyboard>/escape is used in one action map to toggle into the main menu and in another action map to toggle out of it, then the previous behavior would immediately exit out of the menu if escape was still pressed from going into the menu. We have come to believe that wanting to react to the current state of a control right away is the less often desirable behavior and so have made it optional with a separate toggle. Processors and Interactions are now shown in a component-inspector-like fashion in the Input Action editor window, allowing you to see the properties of all items at once. The various InputAction.lastTriggerXXX APIs have been removed. Rationale: They have very limited usefulness and if you need the information, it's easy to set things up in order to keep track of it yourself. Also, we plan on having a polling API for actions in the future which is really what the lastActionXXX APIs were trying to (imperfectly) solve. Tap, SlowTap, and MultiTap interactions now respect button press points. Tap, SlowTap, and MultiTap interactions now have improved parameter editing UIs. Fixed Input Settings configured in the editor are now transferred to the built player correctly. Time slicing for fixed updates now works correctly, even when pausing or dropping frames. Make sure we Disable any InputActionAsset when it is being destroyed. Otherwise, callbacks which were not cleaned up would could cause exceptions. DualShock sensors on PS4 are now marked as noisy (#494). IL2CPP causing issues with XInput on windows and osx desktops. Devices not being available yet in MonoBehavior.Awake, MonoBehaviour.Start, and MonoBehaviour.OnEnable in player or when entering play mode in editor. Fixed a bug where the event buffer used by InputEventTrace could get corrupted. Actions Actions and bindings disappearing when control schemes have spaces in their names. InputActionRebindingExceptions.RebindOperation can now be reused as intended; used to stop working properly the first time a rebind completed or was cancelled. Actions bound to multiple controls now trigger correctly when using PressInteraction set to ReleaseOnly (#492). PlayerInput no longer fails to find actions when using UnityEvents (#500). The \"{...}\" format for referencing action maps and actions using GUIDs as strings has been obsoleted. It will still work but adding the extra braces is no longer necessary. Drag&dropping bindings between other bindings that came before them in the list no longer drops the items at a location one higher up in the list than intended. Editing name of control scheme in editor not taking effect except if hitting enter key. Saving no longer causes the selection of the current processor or interaction to be lost. This was especially annoying when having \"Auto-Save\" on as it made editing parameters on interactions and processors very tedious. In locales that use decimal separators other than '.', floating-point parameters on composites, interactions, and processors no longer lead to invalid serialized data being generated. Fix choosing \"Add Action\" in action map context menu throwing an exception. The input action asset editor window will no longer fail saving if the asset has been moved. The input action asset editor window will now show the name of the asset being edited when asking for saving changes. Clicking \"Cancel\" in the save changes dialog for the input action asset editor window will now cancel quitting the editor. Fixed pasting or dragging a composite binding from one action into another. In the action map editor window, switching from renaming an action to renaming an action map will no longer break the UI. Fixed calling Enable/Disable from within action callbacks sometimes leading to corruption of state which would then lead to actions not getting triggered (#472). Fixed setting of \"Auto-Save\" toggle in action editor getting lost on domain reload. Fixed blurry icons in editor for imported .inputactions assets and actions in them. Press and Release interactions will now work correctly if they have multiple bound controls. Release interactions will now invoke a Started callback when the control is pressed. Made Vector2 composite actions respect the press points of button controls used to compose the value. [0.2.6-preview] - 2019-03-20 NOTE: The UI code for editing actions has largely been rewritten. There may be regressions. NOTE: The minimum version requirement for the new input system has been bumped to 2019.1 Added Support gamepad vibration on Switch. Added support for Joysticks on Linux. Actions Added ability to change which part of a composite a binding that is part of the composite is assigned to. Part bindings can now be freely duplicated or copy-pasted. This allows having multiple bindings for \"up\", for example. Changing part assignments retroactively allows to freely edit the composite makeup. Can now drag&drop multiple items as well as drop items onto others (equivalent to cut&paste). Holding ALT copies data instead of moving it. Edits to control schemes are now undoable. Control schemes are now sorted alphabetically. Can now search by binding group (control scheme) or devices directly from search box. g:Gamepad filters bindings to those in the \"Gamepad\" group. d:Gamepad filters bindings to those from Gamepad-compatible devices. Changed The input debugger will no longer automatically show remote devices when the profiler is connected. Instead, use the new menu in debugger toolbar to connect to players or to enable/disable remote input debugging. \"Press and Release\" interactions will now invoke the performed callback on both press and release (instead of invoking performed and cancel, which was inconsistent with other behaviors). Actions Bindings have GUIDs now like actions and maps already did. This allows to persistently and uniquely identify individual bindings. Replaced UI overlay while rebinding interactively with cancellable progress bar. Interactive rebinding now cancels automatically after 4 seconds without suitable input. Bindings that are not assigned to any control scheme are now visible when a particular control scheme is selected. Bindings not assigned to any control scheme are active in ALL control schemes. The change makes this visible in the UI now. When a specific control scheme is selected, these bindings are affixed with {GLOBAL} for added visibility. When filtering by devices from a control scheme, the filtering now takes layout inheritance into account. So, a binding to a control on Pointer will now be shown when the filter is Mouse. The public control picker API has been revised. The simplest way to add control picker UI to a control path is to add an InputControlAttribute to the field. // In the inspector, shows full UI to select a control interactively // (including interactive picking through device input). [InputControl(layout = \"Button\")] private string buttonControlPath; Processors of incompatible types will now be ignored instead of throwing an exception. Fixed Remote connections in input debugger now remain connected across domain reloads. Don't incorrectly create non-functioning devices if a physical device implements multiple incompatible logical HID devices (such as the MacBook keyboard/touch pad and touch bar). Removed non-functioning sort triangles in event list in Input Debugger device windows. Sort events in input debugger window by id rather then by timestamp. Make parsing of float parameters support floats represented in \"e\"-notation and \"Infinity\". Input device icons in input debugger window now render in appropriate resolution on retina displays. Fixed Xbox Controller on macOS reporting negative values for the sticks when represented as dpad buttons. InputSettings.UpdateMode.ProcessEventsManually now correctly triggers updates when calling InputSystem.Update(InputUpdateType.Manual). Actions Pasting or duplicating an action in an action map asset will now assign a new and unique ID to the action. \"Add Action\" button being active and triggering exceptions when no action map had been added yet. Fixed assert when generating C# class and make sure it gets imported correctly. Generate directories as needed when generating C# class, and allow path names without \"Assets/\" path prefix. Allow binding dpad controls to actions of type \"Vector2\". Fixed old name of action appearing underneath rename overlay. Fixed inspector UIs for on-screen controls throwing exceptions and being non-functional. Fixed deleting multiple items at same time in action editor leading to wrong items being deleted. Fixed copy-pasting actions not preserving action properties other than name. Fixed memory corruptions coming from binding resolution of actions. InputActionAssetReferences in ScriptableObjects will continue to work after domain reloads in the editor. Fixed startTime and duration properties of action callbacks. [0.2.1-preview] - 2019-03-11 Changed NativeUpdateCallback API update to match Unity 2018.3.8f1 [0.2.0-preview] - 2019-02-12 This release contains a number of fairly significant changes. The focus has been on further improving the action system to make it easier to use as well as to make it work more reliably and predictably. NOTE: There are some breaking changes. Please see the \"Changed\" section below. Changed Removed Unity 2018.2 support code. Removed .NET 3.5 support code. Started using C# 7. IInputControlProcessor<TValue> has been replaced with InputProcessor and InputProcessor<TValue> base classes. IInputBindingComposite has been replaced with an InputBindingComposite base class and the IInputBindingComposite<TValue> interface has been merged with the InputBindingComposite<TValue> class which had already existed. InputUser.onUnpairedDeviceUser will now notify for each actuated control until the device is paired or there are no more actuated controls. SensitivityProcessor has been removed. The approach needs rethinking. What SensitivityProcessor did caused more problems than it solved. State monitors no longer have their timeouts removed automatically when they fire. This makes it possible to have a timeout that is removed only in response to a specific state change. Events for devices that implement IInputStateCallbacks (such as Touchscreen) are allowed to go back in time. Avoids the problem of having to order events between multiple fingers correctly or seeing events getting rejected. PenState.Button is now PenButton. Removed TouchPositionTransformProcessor, was used only by Android, the position transformation will occur in native backend in 2019.x Actions: Bindings that have no interactions on them will trigger differently now. This is a breaking change. Previously, these bindings would trigger performed on every value change including when going back to their default value. This is why you would see two calls of performed with a button; one when the button was pressed, another when it was depressed. Now, a binding without an interaction will trigger started and then performed when a bound control is actuated. Thereafter, the action will remain in Started phase. For as long as the control is actuated, every value change will trigger performed again. When the control stops being actuated, it will trigger cancelled and the action will remain in Waiting state. Control actuation is defined as a control having a magnitude (see InputControl.EvaluateMagnitude) greater than zero. If a control does not support magnitudes (returns -1 from EvaluateMagnitude), then the control is considered actuated when it changes state away from its default state. To restore the previous behavior, simply change code like myAction.performed += MyCallback; to myAction.performed += MyCallback; myAction.cancelled += MyCallback; Alternatively, enable passThrough mode on an action. This effectively restores the previous default behavior of actions. new InputAction(binding: \"<Gamepad>/leftTrigger\") { passThrough = true }; As part of the aforementioned change, the following interactions have been removed as they are no longer relevant: StickInteraction: Can simply be removed from bindings. The new default behavior obsoletes the need for what StickInteraction did. Use started to know then the stick starts being actuated, performed to be updated on movements, and cancelled to know when the stick goes back into rest position. PressAndReleaseInteraction: Can simply be removed from bindings. The default behavior with no interaction encompasses press and release detection. Use started to know then a button is pressed and cancelled to know when it is released. To set a custom button press point, simply put an AxisDeadzoneProcessor on the binding. PressInteraction has been completely rewritten. Trigger behavior can be set through behavior parameter and now provides options for observing just presses (PressOnly), just releases (ReleaseOnly), or both presses and releases (PressAndRelease). Also, the interaction now operates on control actuation rather than reading out float values directly. This means that any control that supports magnitudes can be used. Also supports continuous mode now. If bound controls are already actuated when an action is enabled, the action will now trigger in the next input update as if the control had just been moved from non-actuated to actuated state. In other words, if e.g. you have a binding to the A button of the gamepad and the A button is already pressed when the action is first enabled, then the action associated with the A button will trigger as if the button had just been pressed. Previously, it required releasing and re-pressing the button first -- which, together with certain interactions, could lead to actions ending up in a confused state. When an action is disabled, it will now cancel all ongoing interactions, if any (i.e. you will see InputAction.cancelled being called). Note that unlike the above-mentioned callbacks that happen when an action starts out with a control already actuated, the cancellation callbacks happen immediately rather than in the next input update. Actions that at runtime are bound to multiple controls will now perform conflict resolution, if necessary. This applies only if an action actually receives multiple concurrent actuations from controls. When ambiguity is detected, the greatest amount of actuation on any of the controls gets to drive the action. In practice, this means that as long as any of the controls bound to an action is actuated, the action will keep going. This resolves ambiguities when an action has primary and secondary bindings, for examples, or when an action is bound to multiple different devices at the same time. Composite bindings count as single actuations regardless of how many controls participate in the composite. This behavior can be bypassed by setting the action to be pass-through. Action editor now closes when asset is deleted. If there are unsaved changes, asks for confirmation first. Interactions and processors in the UI are now filtered based on the type of the action (if set) and sorted by name. Renamed \"Axis\" and \"Dpad\" composites to \"1D Axis\" and \"2D Vector\" composite. The old names can still be used and existing data will load as expected. DpadComposite got renamed to Vector2Composite; AxisComposite is unchanged. InputInteractionContext.controlHasDefaultValue has been replaced with InputInteractionContext.ControlIsActuated(). InputActionChange.BindingsHaveChangedWhileEnabled has been reworked and split in two: InputActionChange.BoundControlsAboutToChange: Bindings have been previously resolved but are about to be re-resolved. InputActionChange.BoundControlsChanged: Bindings have been resolved on one or more actions. Actions internally now allocate unmanaged memory. Disposing should be taken care of automatically (though you can manually Dispose as well). If you see errors in the console log about unmanaged memory being leaked, please report the bug. All execution state except for C# heap objects for processors, interactions, and composites has been collapsed into a single block of unmanaged memory. Actions should now be able to re-resolve efficiently without allocating additional GC memory. Added PlayerInput component which simplifies setting up individual player input actions and device pairings. PlayerInputManager component which simplifies player joining and split-screen setups. InputDevice.all (equivalent to InputSystem.devices) InputControl.IsActuated() can be used to determine whether control is currently actuated (defined as extension method in InputControlExtensions). Can now read control values from buffers as objects using InputControl.ReadValueFromBufferAsObject. This allows reading a value stored in memory without having to know the value type. New processors: ScaleProcessor ScaleVector2Processor ScaleVector3Processor InvertVector2Processor InvertVector3Processor NormalizeVector2Processor NormalizeVector3Processor Added MultiTapInteraction. Can be used to listen for double-taps and the like. Can get total and average event lag times through InputMetrics.totalEventLagTime and InputMetrics.averageEventLagTime. Mouse.forwardButton and Mouse.backButton. The input debugger now shows users along with their paired devices and actions. See the documentation Added third and fourth barrel buttons on Pen. Actions: Actions have a new continuous mode that will cause the action to trigger continuously even if there is no input. See the documentation for details. Actions have a new pass-through mode. In this mode an action will bypass any checks on control actuation and let any input activity on the action directly flow through. See the documentation for details. Can now add interactions and processors directly to actions. This is functionally equivalent to adding the respective processors and/or interactions to every binding on the action. Can now change the type of a composite retroactively. Values can now be read out as objects using InputAction.CallbackContext.ReadValueAsObject(). Allocates GC memory. Should not be used during normal gameplay but is very useful for testing and debugging. Added auto-save mode for .inputactions editor. Processors, interactions, and composites can now define their own parameter editor UIs by deriving from InputParameterEditor. This solves the problem of these elements not making it clear that the parameters usually have global defaults and do not need to be edited except if local overrides are necessary. Can now set custom min and max values for axis composites. var action = new InputAction(); action.AddCompositeBinding(\"Axis(minValue=0,maxValue=2)\") .With(\"Positive\", \"<Keyboard>/a\") .With(\"Negative\", \"<Keyboard>/d\"); \"C# Class File\" property on .inputactions importer settings now has a file picker next to it. InputActionTrace has seen various improvements. Recorded data will now stay valid even if actions are rebound to different controls. Can listen to all actions using InputActionTrace.SubscribeToAll. InputActionTrace now maintains a list of subscriptions. Add subscriptions with SubscribeTo and remove a subscription with UnsubscribeFrom. See the documentation for details. Fixes Fixed support for Unity 2019.1 where we landed a native API change. InputUser.UnpairDevicesAndRemoveUser() corrupting device pairings of other InputUsers Control picker in UI having no devices if list of supported devices is empty but not null IndexOutOfRangeException when having multiple action maps in an asset (#359 and #358). Interactions timing out even if there was a pending event that would complete the interaction in time. Action editor updates when asset is renamed or moved. Exceptions when removing action in last position of action map. Devices marked as unsupported in input settings getting added back on domain reload. Fixed Pen causing exceptions and asserts. Composites that assign multiple bindings to parts failing to set up properly when parts are assigned out of order (#410). Known Issues Input processing in edit mode on 2019.1 is sporadic rather than happening on every editor update. [0.1.2-preview] - 2018-12-19 NOTE: The minimum version requirement for the new input system has been bumped to 2018.3. The previous minum requirement of 2018.2 is no longer supported. Also, we have dropped support for the .NET 3.5 runtime. The new .NET 4 runtime is now required to use the new input system. We've started working on documentation. The current work-in-progress can be found on GitHub. Changed InputConfiguration has been replaced with a new InputSettings class. InputConfiguration.lockInputToGame has been moved to InputEditorUserSettings.lockInputToGameView. This setting is now persisted as a local user setting. InputSystem.updateMask has been replaced with InputSettings.updateMode. InputSystem.runInBackground has been moved to InputSettings.runInBackground. Icons have been updated for improved styling and now have separate dark and light skin versions. Lock Input To Game and Diagnostics Mode are now persisted as user settings Brought back .current getters and added InputSettings.filterNoiseOnCurrent to control whether noise filtering on the getters is performed or not. Removed old and outdated Doxygen-generated API docs. Added InputSystem.settings contains the current input system settings. A new UI has been added to \"Edit >> Project Settings...\" to edit input system settings. Settings are stored in a user-controlled asset in any location inside Assets/. Multiple assets can be used and switched between. Joystick HIDs are now supported on Windows, Mac, and UWP. Can now put system into manual update mode (InputSettings.updateMode). In this mode, events will not get automatically processed. To process events, call InputSystem.Update(). Added shortcuts to action editor window (requires 2019.1). Added icons for .inputactions assets. Fixed InputSystem.devices not yet being initialized in MonoBehaviour.Start when in editor. Known Issues Input settings are not yet included in player builds. This means that at the moment, player builds will always start out with default input settings. There have been reports of some stickiness to buttons on 2019.1 alpha builds. We are looking at this now. [0.0.14-preview] - 2018-12-11 Changed Pointer.delta no longer has SensitivityProcessor on it. The processor was causing many issues with mouse deltas. It is still available for adding it manually to action bindings but the processor likely needs additional work. Fixed Core: Invalid memory accesses when using .NET 4 runtime Mouse.button not being identical to Mouse.leftButton DualShock not being recognized when connected via Bluetooth Actions: Parameters disappearing on processors and interactions in UI when edited Parameters on processors and interactions having wrong value type in UI (e.g. int instead of float) RebindingOperation calling OnComplete() after being cancelled Misc: Documentation no longer picked up as assets in user project [0.0.13-preview] - 2018-12-05 First release from stable branch."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionAssets.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionAssets.html",
    "title": "Input Action Assets | Inventory System",
    "summary": "Input Action Assets Creating Input Action Assets Editing Input Action Assets Using Input Action Assets Type-safe C# API Generation An Input Action Asset is an Asset which contains a set of Input Actions definitions and their associated Bindings and Control Schemes. These Assets have the .inputactions file extension and are stored in a plain JSON format. The input system creates an Action Asset when you set up the default project-wide actions, but you can also create new Action Assets directly in the Project window. For most common scenarios, you do not need to use more than one Input Action Asset. It is usually simpler to configure your project-wide action definition in the Project Settings window. Creating Input Action Assets To create an Asset that contains Input Actions in Unity, right-click in the Project window or go to Assets > Create > Input Actions from Unity's main menu. Editing Input Action Assets To bring up the Action editor, double-click an .inputactions Asset in the Project Browser, or select the Edit Asset button in the Inspector for that Asset. You can have more than one editor window open at the same time, but not for the same Asset. The Actions Editor which opens is identical to the Actions Editor in the Project Settings window. Using Input Action Assets Type-safe C# API Generation Input Action Assets allow you to generate a C# class from your action definitions, which allow you to refer to your actions in a type-safe manner from code. This means you can avoid looking up your actions by string. Auto-generating script code for Actions One of the most convenient ways to work with .inputactions Assets in scripts is to automatically generate a C# wrapper class for them. This removes the need to manually look up Actions and Action Maps using their names, and also provides an easier way to set up callbacks. To enable this option, tick the Generate C# Class checkbox in the importer properties in the Inspector of the .inputactions Asset, then select Apply. You can optionally choose a path name, class name, and namespace for the generated script, or keep the default values. This generates a C# script that simplifies working with the Asset. using UnityEngine; using UnityEngine.InputSystem; // IGameplayActions is an interface generated from the \"gameplay\" action map // we added (note that if you called the action map differently, the name of // the interface will be different). This was triggered by the \"Generate Interfaces\" // checkbox. public class MyPlayerScript : MonoBehaviour, IGameplayActions { // MyPlayerControls is the C# class that Unity generated. // It encapsulates the data from the .inputactions asset we created // and automatically looks up all the maps and actions for us. MyPlayerControls controls; public void OnEnable() { if (controls == null) { controls = new MyPlayerControls(); // Tell the \"gameplay\" action map that we want to get told about // when actions get triggered. controls.gameplay.SetCallbacks(this); } controls.gameplay.Enable(); } public void OnDisable() { controls.gameplay.Disable(); } public void OnUse(InputAction.CallbackContext context) { // 'Use' code here. } public void OnMove(InputAction.CallbackContext context) { // 'Move' code here. } } Note: To regenerate the .cs file, right-click the .inputactions asset in the Project Browser and choose \"Reimport\". Using Action Assets with PlayerInput The Player Input component provides a convenient way to handle input for one or multiple players. You can assign your Action Asset to the Player Input component so that it can then automatically handle activating Action Maps and selecting Control Schemes for you. Modifying Input Action Assets at runtime There are several ways to modify an Input Action Asset at runtime. Any modifications that you make during Play mode to an Input Action Asset do not persist in the Input Action Asset after you exit Play mode. This means you can test your application in a realistic manner in the Editor without having to worry about inadvertently modifying the asset. For examples on how to modify an Input Action Asset, see the documentation on Creating Actions in code and Changing Bindings. The Default Actions Asset An asset called DefaultInputActions.inputactions containing a default setup of Actions comes with the Input System Package. You can reference this asset directly in your projects like any other Unity asset. However, the asset is also available in code form through the DefaultInputActions class. void Start() { // Create an instance of the default actions. var actions = new DefaultInputActions(); actions.Player.Look.performed += OnLook; actions.Player.Move.performed += OnMove; actions.Enable(); } Note: This default actions asset is older than, and entirely separate from the default project-wide actions. It is a legacy asset that remains included in the package for backward compatibility."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionBindings.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionBindings.html",
    "title": "Input Bindings | Inventory System",
    "summary": "Input Bindings Composite Bindings 1D Axis 2D Vector 3D Vector One Modifier Two Modifiers Writing custom Composites Working with Bindings Looking up Bindings Changing Bindings Applying overrides Erasing Bindings Adding Bindings Setting parameters Interactive rebinding Saving and loading rebinds Restoring original Bindings Displaying Bindings Control schemes Details Binding resolution Binding resolution while Actions are enabled Choosing which Devices to use Conflicting inputs Initial state check An InputBinding represents a connection between an Action and one or more Controls identified by a Control path. For example, the right trigger of a gamepad (a control) might be bound to an an action named \"accelerate\", so that pulling the right trigger causes a car to accelerate in your game. You can add multiple bindings to an action, which is generally useful for supporting multiple types of input device. For example, in the default set of actions, the \"Move\" action has a binding to the left gamepad stick and the WSAD keys, which means input through any of these bindings will perform the action. You can also bind multiple controls from the same device to an action. For example, both the left and right trigger of a gamepad could be mapped to the same action, so that pulling either trigger has the same result in your game. The default \"Move\" action in the Actions Editor window, displaying the multiple bindings associated with it. Each Binding has the following properties: Property Description path Control path that identifies the control(s) from which the Action should receive input. Example: \"<Gamepad>/leftStick\" overridePath Control path that overrides path. Unlike path, overridePath is not persistent, so you can use it to non-destructively override the path on a Binding. If it is set to something other than null, it takes effect and overrides path. To get the path which is currently in effect (that is, either path or overridePath), you can query the effectivePath property. action The name or ID of the Action that the Binding should trigger. Note that this can be null or empty (for instance, for composites). Not case-sensitive. Example: \"fire\" groups A semicolon-separated list of Binding groups that the Binding belongs to. Can be null or empty. Binding groups can be anything, but are mostly used for Control Schemes. Not case-sensitive. Example: \"Keyboard&Mouse;Gamepad\" interactions A semicolon-separated list of Interactions to apply to input on this Binding. Note that Unity appends Interactions applied to the Action itself (if any) to this list. Not case-sensitive. Example: \"slowTap;hold(duration=0.75)\" processors A semicolon-separated list of Processors to apply to input on this Binding. Note that Unity appends Processors applied to the Action itself (if any) to this list. Not case-sensitive. Processors on Bindings apply in addition to Processors on Controls that are providing values. For example, if you put a stickDeadzone Processor on a Binding and then bind it to <Gamepad>/leftStick, you get deadzones applied twice: once from the deadzone Processor sitting on the leftStick Control, and once from the Binding. Example: \"invert;axisDeadzone(min=0.1,max=0.95)\" id Unique ID of the Binding. You can use it to identify the Binding when storing Binding overrides in user settings, for example. name Optional name of the Binding. Identifies part names inside Composites. Example: \"Positive\" isComposite Whether the Binding acts as a Composite. isPartOfComposite Whether the Binding is part of a Composite. To query the Bindings to a particular Action, you can use InputAction.bindings. To query a flat list of Bindings for all Actions in an Action Map, you can use InputActionMap.bindings. Composite Bindings Sometimes, you might want to have several Controls act in unison to mimic a different type of Control. The most common example of this is using the W, A, S, and D keys on the keyboard to form a 2D vector Control equivalent to mouse deltas or gamepad sticks. Another example is to use two keys to form a 1D axis equivalent to a mouse scroll axis. This is difficult to implement with normal Bindings. You can bind a ButtonControl to an action expecting a Vector2, but doing so results in an exception at runtime when the Input System tries to read a Vector2 from a Control that can deliver only a float. Composite Bindings (that is, Bindings that are made up of other Bindings) solve this problem. Composites themselves don't bind directly to Controls; instead, they source values from other Bindings that do, and then synthesize input on the fly from those values. To see how to create Composites in the editor UI, see documentation on editing Composite Bindings. To create composites in code, you can use the AddCompositeBinding syntax. myAction.AddCompositeBinding(\"Axis\") .With(\"Positive\", \"<Gamepad>/rightTrigger\") .With(\"Negative\", \"<Gamepad>/leftTrigger\"); Each Composite consists of one Binding that has InputBinding.isComposite set to true, followed by one or more Bindings that have InputBinding.isPartOfComposiste set to true. In other words, several consecutive entries in InputActionMap.bindings or InputAction.bindings together form a Composite. Note that each composite part can be bound arbitrary many times. // Make both shoulders and triggers pull on the axis. myAction.AddCompositeBinding(\"Axis\") .With(\"Positive\", \"<Gamepad>/rightTrigger\") .With(\"Positive\", \"<Gamepad>/rightShoulder\") .With(\"Negative\", \"<Gamepad>/leftTrigger\"); .With(\"Negative\", \"<Gamepad>/leftShoulder\"); Composites can have parameters, just like Interactions and Processors. myAction.AddCompositeBinding(\"Axis(whichSideWins=1)\"); There are currently five Composite types that come with the system out of the box: 1D-Axis, 2D-Vector, 3D-Vector, One Modifier and Two Modifiers. Additionally, you can add your own types of Composites. 1D axis A Composite made of two buttons: one that pulls a 1D axis in its negative direction, and another that pulls it in its positive direction. Implemented in the AxisComposite class. The result is a float. myAction.AddCompositeBinding(\"1DAxis\") // Or just \"Axis\" .With(\"Positive\", \"<Gamepad>/rightTrigger\") .With(\"Negative\", \"<Gamepad>/leftTrigger\"); The axis Composite has two part bindings. Part Type Description positive Button Controls pulling in the positive direction (towards maxValue). negative Button Controls pulling in the negative direction, (towards minValue). You can set the following parameters on an axis Composite: Parameter Description whichSideWins What happens if both positive and negative are actuated. See table below. minValue The value returned if the negative side is actuated. Default is -1. maxValue The value returned if the positive side is actuated. Default is 1. If Controls from both the positive and the negative side are actuated, then the resulting value of the axis Composite depends on the whichSideWin parameter setting. WhichSideWins Description (0) Neither Neither side has precedence. The Composite returns the midpoint between minValue and maxValue as a result. At their default settings, this is 0. This is the default value for this setting. (1) Positive The positive side has precedence and the Composite returns maxValue. (2) Negative The negative side has precedence and the Composite returns minValue. Note: There is no support yet for interpolating between the positive and negative over time. 2D vector A Composite that represents a 4-way button setup like the D-pad on gamepads. Each button represents a cardinal direction. Implemented in the Vector2Composite class. The result is a Vector2. This Composite is most useful for representing up-down-left-right controls, such as WASD keyboard input. myAction.AddCompositeBinding(\"2DVector\") // Or \"Dpad\" .With(\"Up\", \"<Keyboard>/w\") .With(\"Down\", \"<Keyboard>/s\") .With(\"Left\", \"<Keyboard>/a\") .With(\"Right\", \"<Keyboard>/d\"); // To set mode (2=analog, 1=digital, 0=digitalNormalized): myAction.AddCompositeBinding(\"2DVector(mode=2)\") .With(\"Up\", \"<Gamepad>/leftStick/up\") .With(\"Down\", \"<Gamepad>/leftStick/down\") .With(\"Left\", \"<Gamepad>/leftStick/left\") .With(\"Right\", \"<Gamepad>/leftStick/right\"); The 2D vector Composite has four part Bindings. Part Type Description up Button Controls representing (0,1) (+Y). down Button Controls representing (0,-1) (-Y). left Button Controls representing (-1,0) (-X). right Button Controls representing (1,0) (+X). In addition, you can set the following parameters on a 2D vector Composite: Parameter Description mode Whether to treat the inputs as digital or as analog controls. If this is set to Mode.DigitalNormalized, inputs are treated as buttons (off if below defaultButtonPressPoint and on if equal to or greater). Each input is 0 or 1 depending on whether the button is pressed or not. The vector resulting from the up/down/left/right parts is normalized. The result is a diamond-shaped 2D input range. If this is set to Mode.Digital, the behavior is essentially the same as Mode.DigitalNormalized except that the resulting vector is not normalized. Finally, if this is set to Mode.Analog, inputs are treated as analog (i.e. full floating-point values) and, other than down and left being inverted, values will be passed through as is. The default is Mode.DigitalNormalized. Note: There is no support yet for interpolating between the up/down/left/right over time. 3D vector A Composite that represents a 6-way button where two combinations each control one axis of a 3D vector. Implemented in the Vector3Composite class. The result is a Vector3. myAction.AddCompositeBinding(\"3DVector\") .With(\"Up\", \"<Keyboard>/w\") .With(\"Down\", \"<Keyboard>/s\") .With(\"Left\", \"<Keyboard>/a\") .With(\"Right\", \"<Keyboard>/d\"); // To set mode (2=analog, 1=digital, 0=digitalNormalized): myAction.AddCompositeBinding(\"3DVector(mode=2)\") .With(\"Up\", \"<Gamepad>/leftStick/up\") .With(\"Down\", \"<Gamepad>/leftStick/down\") .With(\"Left\", \"<Gamepad>/leftStick/left\") .With(\"Right\", \"<Gamepad>/leftStick/right\"); The 3D vector Composite has four part Bindings. Part Type Description up Button Controls representing (0,1,0) (+Y). down Button Controls representing (0,-1,0) (-Y). left Button Controls representing (-1,0,0) (-X). right Button Controls representing (1,0,0) (+X). forward Button Controls representing (0,0,1) (+Z). backward Button Controls representing (0,0,-1) (-Z). In addition, you can set the following parameters on a 3D vector Composite: Parameter Description mode Whether to treat the inputs as digital or as analog controls. If this is set to Mode.DigitalNormalized, inputs are treated as buttons (off if below defaultButtonPressPoint and on if equal to or greater). Each input is 0 or 1 depending on whether the button is pressed or not. The vector resulting from the up/down/left/right/forward/backward parts is normalized. If this is set to Mode.Digital, the behavior is essentially the same as Mode.DigitalNormalized except that the resulting vector is not normalized. Finally, if this is set to Mode.Analog, inputs are treated as analog (that is, full floating-point values) and, other than down, left, and backward being inverted, values will be passed through as they are. The default is Analog. One Modifier A Composite that requires the user to hold down a \"modifier\" button in addition to another control from which the actual value of the Binding is determined. This can be used, for example, for Bindings such as \"SHIFT+1\". Implemented in the OneModifierComposite class. The buttons can be on any Device, and can be toggle buttons or full-range buttons such as gamepad triggers. The result is a value of the same type as the controls bound to the binding part. // Add binding for \"CTRL+1\". myAction.AddCompositeBinding(\"OneModifier\") .With(\"Binding\", \"<Keyboard>/1\") .With(\"Modifier\", \"<Keyboard>/ctrl\") // Add binding to mouse delta such that it only takes effect // while the ALT key is down. myAction.AddCompositeBinding(\"OneModifier\") .With(\"Binding\", \"<Mouse>/delta\") .With(\"Modifier\", \"<Keyboard>/alt\"); The button with one modifier Composite has two part Bindings. Part Type Description modifier Button Modifier that has to be held for binding to come through. If the user holds any of the buttons bound to the modifier at the same time as the button that triggers the action, the Composite assumes the value of the modifier Binding. If the user does not press any button bound to the modifier, the Composite remains at default value. binding Any The control(s) whose value the Composite assumes while the user holds down the modifier button. This Composite has no parameters. Two Modifiers A Composite that requires the user to hold down two \"modifier\" buttons in addition to another control from which the actual value of the Binding is determined. This can be used, for example, for Bindings such as \"SHIFT+CTRL+1\". Implemented in the TwoModifiersComposite class. The buttons can be on any Device, and can be toggle buttons or full-range buttons such as gamepad triggers. The result is a value of the same type as the controls bound to the binding part. myAction.AddCompositeBinding(\"TwoModifiers\") .With(\"Button\", \"<Keyboard>/1\") .With(\"Modifier1\", \"<Keyboard>/leftCtrl\") .With(\"Modifier1\", \"<Keyboard>/rightCtrl\") .With(\"Modifier2\", \"<Keyboard>/leftShift\") .With(\"Modifier2\", \"<Keyboard>/rightShift\"); The button with two modifiers Composite has three part Bindings. Part Type Description modifier1 Button The first modifier the user must hold alongside modifier2, for binding to come through. If the user does not press any button bound to the modifier1, the Composite remains at default value. modifier2 Button The second modifier the user must hold alongside modifier1, for binding to come through. If the user does not press any button bound to the modifier2, the Composite remains at default value. binding Any The control(s) whose value the Composite assumes while the user presses both modifier1 and modifier2 at the same time. This Composite has no parameters. Writing custom Composites You can define new types of Composites, and register them with the API. Unity treats these the same as predefined types, which the Input System internally defines and registers in the same way. To define a new type of Composite, create a class based on InputBindingComposite<TValue>. IMPORTANT: Composites must be stateless. This means that you cannot store local state that changes depending on the input being processed. For stateful processing on Bindings, see interactions. // Use InputBindingComposite<TValue> as a base class for a composite that returns // values of type TValue. // NOTE: It is possible to define a composite that returns different kinds of values // but doing so requires deriving directly from InputBindingComposite. #if UNITY_EDITOR [InitializeOnLoad] // Automatically register in editor. #endif // Determine how GetBindingDisplayString() formats the composite by applying // the DisplayStringFormat attribute. [DisplayStringFormat(\"{firstPart}+{secondPart}\")] public class CustomComposite : InputBindingComposite<float> { // Each part binding is represented as a field of type int and annotated with // InputControlAttribute. Setting \"layout\" restricts the controls that // are made available for picking in the UI. // // On creation, the int value is set to an integer identifier for the binding // part. This identifier can read values from InputBindingCompositeContext. // See ReadValue() below. [InputControl(layout = \"Button\")] public int firstPart; [InputControl(layout = \"Button\")] public int secondPart; // Any public field that is not annotated with InputControlAttribute is considered // a parameter of the composite. This can be set graphically in the UI and also // in the data (e.g. \"custom(floatParameter=2.0)\"). public float floatParameter; public bool boolParameter; // This method computes the resulting input value of the composite based // on the input from its part bindings. public override float ReadValue(ref InputBindingCompositeContext context) { var firstPartValue = context.ReadValue<float>(firstPart); var secondPartValue = context.ReadValue<float>(secondPart); //... do some processing and return value } // This method computes the current actuation of the binding as a whole. public override float EvaluateMagnitude(ref InputBindingCompositeContext context) { // Compute normalized [0..1] magnitude value for current actuation level. } static CustomComposite() { // Can give custom name or use default (type name with \"Composite\" clipped off). // Same composite can be registered multiple times with different names to introduce // aliases. // // NOTE: Registering from the static constructor using InitializeOnLoad and // RuntimeInitializeOnLoadMethod is only one way. You can register the // composite from wherever it works best for you. Note, however, that // the registration has to take place before the composite is first used // in a binding. Also, for the composite to show in the editor, it has // to be registered from code that runs in edit mode. InputSystem.RegisterBindingComposite<CustomComposite>(); } [RuntimeInitializeOnLoadMethod(RuntimeInitializeLoadType.BeforeSceneLoad)] static void Init() {} // Trigger static constructor. } The Composite should now appear in the editor UI when you add a Binding, and you can now use it in scripts. myAction.AddCompositeBinding(\"custom(floatParameter=2.0)\") .With(\"firstpart\", \"<Gamepad>/buttonSouth\") .With(\"secondpart\", \"<Gamepad>/buttonNorth\"); To define a custom parameter editor for the Composite, you can derive from InputParameterEditor<TObject>. #if UNITY_EDITOR public class CustomParameterEditor : InputParameterEditor<CustomComposite> { public override void OnGUI() { EditorGUILayout.Label(\"Custom stuff\"); target.floatParameter = EditorGUILayout.FloatField(\"Some Parameter\", target.floatParameter); } } #endif Working with Bindings Looking up Bindings You can retrieve the bindings of an action using its InputAction.bindings property which returns a read-only array of InputBinding structs. // Get bindings of \"fire\" action. var fireBindings = playerInput.actions[\"fire\"].bindings; Also, all the bindings for all actions in an InputActionMap are made available through the InputActionMap.bindings property. The bindings are associated with actions through an action ID or action name stored in the InputBinding.action property. // Get all bindings in \"gameplay\" action map. var gameplayBindings = playerInput.actions.FindActionMap(\"gameplay\").bindings; You can also look up specific the indices of specific bindings in InputAction.bindings using the InputActionRebindingExtensions.GetBindingIndex method. // Find the binding in the \"Keyboard\" control scheme. playerInput.actions[\"fire\"].GetBindingIndex(group: \"Keyboard\"); // Find the first binding to the space key in the \"gameplay\" action map. playerInput.FindActionMap(\"gameplay\").GetBindingIndex( new InputBinding { path = \"<Keyboard>/space\" }); Finally, you can look up the binding that corresponds to a specific control through GetBindingIndexForControl. This way, you can, for example, map a control found in the controls array of an InputAction back to an InputBinding. // Find the binding that binds LMB to \"fire\". If there is no such binding, // bindingIndex will be -1. var fireAction = playerInput.actions[\"fire\"]; var bindingIndex = fireAction.GetBindingIndexForControl(Mouse.current.leftButton); if (binding == -1) Debug.Log(\"Fire is not bound to LMB of the current mouse.\"); Changing Bindings In general, you can change existing bindings via the InputActionSetupExtensions.ChangeBinding method. This returns an accessor that can be used to modify the properties of the targeted InputBinding. Note that most of the write operations of the accessor are destructive. For non-destructive changes to bindings, see Applying Overrides. // Get write access to the second binding of the 'fire' action. var accessor = playerInput.actions['fire'].ChangeBinding(1); // You can also gain access through the InputActionMap. Each // map contains an array of all its bindings (see InputActionMap.bindings). // Here we gain access to the third binding in the map. accessor = playerInput.actions.FindActionMap(\"gameplay\").ChangeBinding(2); You can use the resulting accessor to modify properties through methods such as WithPath or WithProcessors. playerInput.actions[\"fire\"].ChangeBinding(1) // Change path to space key. .WithPath(\"<Keyboard>/space\"); You can also use the accessor to iterate through bindings using PreviousBinding and NextBinding. // Move accessor to previous binding. accessor = accessor.PreviousBinding(); // Move accessor to next binding. accessor = accessor.NextBinding(); If the given binding is a composite, you can address it by its name rather than by index. // Change the 2DVector composite of the \"move\" action. playerInput.actions[\"move\"].ChangeCompositeBinding(\"2DVector\") // playerInput.actions[\"move\"].ChangeBinding(\"WASD\") Applying overrides You can override aspects of any Binding at run-time non-destructively. Specific properties of InputBinding have an override variant that, if set, will take precedent over the property that they shadow. All override properties are of type String. Property Override Description path overridePath Replaces the Control path that determines which Control(s) are referenced in the binding. If overridePath is set to an empty string, the binding is effectively disabled. Example: \"<Gamepad>/leftStick\" processors overrideProcessors Replaces the processors applied to the binding. Example: \"invert,normalize(min=0,max=10)\" interactions overrideInteractions Replaces the interactions applied to the binding. Example: \"tap(duration=0.5)\" NOTE: The override property values will not be saved along with the Actions (for example, when calling InputActionAsset.ToJson()). See Saving and loading rebinds for details about how to persist user rebinds. To set the various override properties, you can use the ApplyBindingOverride APIs. // Rebind the \"fire\" action to the left trigger on the gamepad. playerInput.actions[\"fire\"].ApplyBindingOverride(\"<Gamepad>/leftTrigger\"); In most cases, it is best to locate specific bindings using APIs such as GetBindingIndexForControl and to then apply the override to that specific binding. // Find the \"Jump\" binding for the space key. var jumpAction = playerInput.actions[\"Jump\"]; var bindingIndex = jumpAction.GetBindingIndexForControl(Keyboard.current.spaceKey); // And change it to the enter key. jumpAction.ApplyBindingOverride(bindingIndex, \"<Keyboard>/enter\"); Erasing Bindings You can erase a binding by calling Erase on the binding accessor. // Erase first binding on \"fire\" action. playerInput.actions[\"fire\"].ChangeBinding(0).Erase(); // Erase \"2DVector\" composite. This will also erase the part // bindings of the composite. playerInput.actions[\"move\"].ChangeCompositeBinding(\"2DVector\").Erase(); // Can also do this by using the name given to the composite binding. playerInput.actions[\"move\"].ChangeCompositeBinding(\"WASD\").Erase(); // Erase first binding in \"gameplay\" action map. playerInput.actions.FindActionMap(\"gameplay\").ChangeBinding(0).Erase(); Adding Bindings New bindings can be added to an Action using AddAction or AddCompositeBinding. // Add a binding for the left mouse button to the \"fire\" action. playerInput.actions[\"fire\"].AddBinding(\"<Mouse>/leftButton\"); // Add a WASD composite binding to the \"move\" action. playerInput.actions[\"move\"] .AddCompositeBinding(\"2DVector\") .With(\"Up\", \"<Keyboard>/w\") .With(\"Left\", \"<Keyboard>/a\") .With(\"Down\", \"<Keyboard>/s\") .With(\"Right\", \"<Keyboard>/d\"); Setting parameters A Binding may, either through itself or through its associated Action, lead to processor, interaction, and/or composite objects being created. These objects can have parameters you can configure through in the Binding properties view of the Action editor or through the API. This configuration will give parameters their default value. // Create an action with a \"Hold\" interaction on it. // Set the \"duration\" parameter to 4 seconds. var action = new InputAction(interactions: \"hold(duration=4)\"); You can query the current value of any such parameter using the GetParameterValue API. // This returns a PrimitiveValue?. It will be null if the // parameter is not found. Otherwise, it is a PrimitiveValue // which can be converted to a number or boolean. var p = action.GetParameterValue(\"duration\"); Debug.Log(\"'duration' is set to: \" + p.Value); The above looks for the parameter on any object found on any of the bindings on the action. You can restrict either or both to a more narrow set. // Retrieve the value of the \"duration\" parameter specifically of a // \"Hold\" interaction and only look on bindings in the \"Gamepad\" group. action.GetParameterValue(\"hold:duration\", InputBinding.MaskByGroup(\"Gamepad\")); Alternatively, you can use an expression parameter to encapsulate both the type and the name of the parameter you want to get the value of. This has the advantage of not needing a string parameter but rather references both the type and the name of the parameter in a typesafe way. // Retrieve the value of the \"duration\" parameter of TapInteraction. // This version returns a float? instead of a PrimitiveValue? as it // sees the type of \"duration\" at compile-time. action.GetParameterValue((TapInteraction x) => x.duration); To alter the current value of a parameter, you can use what is referred to as a \"parameter override\". You can apply these at the level of an individual InputAction, or at the level of an entire InputActionMap, or even at the level of an entire InputActionAsset. Such overrides are stored internally and applied automatically even on bindings added later. To add an override, use the ApplyParameterOverride API or any of its overloads. // Set the \"duration\" parameter on all bindings of the action to 4. action.ApplyParameterOverride(\"duration\", 4f); // Set the \"duration\" parameter specifically for \"tap\" interactions only. action.ApplyParameterOverride(\"tap:duration\", 0.5f); // Set the \"duration\" parameter on tap interactions but only for bindings // in the \"Gamepad\" group. action.ApplyParameterOverride(\"tap:duration\", 0.5f, InputBinding.MaskByGroup(\"Gamepad\"); // Set tap duration for all bindings in an action map. map.ApplyParameterOverride(\"tap:duration\", 0.5f); // Set tap duration for all bindings in an entire asset. asset.ApplyParameterOverride(\"tap:duration\", 0.5f); // Like for GetParameterValue, overloads are available that take // an expression instead. action.ApplyParameterOverride((TapInteraction x) => x.duration, 0.4f); map.ApplyParameterOverride((TapInteraction x) => x.duration, 0.4f); asset.ApplyParameterOverride((TapInteraction x) => x.duration, 0.4f); The new value will be applied immediately and affect all composites, processors, and interactions already in use and targeted by the override. Note that if multiple parameter overrides are applied – especially when applying some directly to actions and some to maps or assets –, there may be conflicts between which override to apply. In this case, an attempt is made to chose the \"most specific\" override to apply. // Let's say you have an InputAction `action` that is part of an InputActionAsset asset. var map = action.actionMap; var asset = map.asset; // And you apply a \"tap:duration\" override to the action. action.ApplyParameterOverride(\"tap:duration\", 0.6f); // But also apply a \"tap:duration\" override to the action specifically // for bindings in the \"Gamepad\" group. action.ApplyParameterOverride(\"tap:duration\", 1f, InputBinding.MaskByGroup(\"Gamepad\")); // And finally also apply a \"tap:duration\" override to the entire asset. asset.ApplyParameterOverride(\"tap:duration\", 0.3f); // Now, bindings on `action` in the \"Gamepad\" group will use a value of 1 for tap durations, // other bindings on `action` will use 0.6, and every other binding in the asset will use 0.3. You can use parameter overrides, for example, to scale mouse delta values on a \"Look\" action. // Set up an example \"Look\" action. var look = new InputAction(\"look\", type: InputActionType.Value); look.AddBinding(\"<Mouse>/delta\", groups: \"KeyboardMouse\", processors: \"scaleVector2\"); look.AddBinding(\"<Gamepad>/rightStick\", groups: \"Gamepad\", processors: \"scaleVector2\"); // Now you can adjust stick sensitivity separately from mouse sensitivity. look.ApplyParameterOverride(\"scaleVector2:x\", 0.5f, InputBinding.MaskByGroup(\"KeyboardMouse\")); look.ApplyParameterOverride(\"scaleVector2:y\", 0.5f, InputBinding.MaskByGroup(\"KeyboardMouse\")); look.ApplyParameterOverride(\"scaleVector2:x\", 2f, InputBinding.MaskByGroup(\"Gamepad\")); look.ApplyParameterOverride(\"scaleVector2:y\", 2f, InputBinding.MaskByGroup(\"Gamepad\")); // Alternative to using groups, you can also apply overrides directly to specific binding paths. look.ApplyParameterOverride(\"scaleVector2:x\", 0.5f, new InputBinding(\"<Mouse>/delta\")); look.ApplyParameterOverride(\"scaleVector2:y\", 0.5f, new InputBinding(\"<Mouse>/delta\")); NOTE: Parameter overrides are not persisted along with an asset. Interactive rebinding Note: To download a sample project which demonstrates how to set up a rebinding user interface with Input System APIs, open the Package Manager, select the Input System Package, and choose the sample project \"Rebinding UI\" to download. Runtime rebinding allows users of your application to set their own Bindings. To allow users to choose their own Bindings interactively, use the InputActionRebindingExtensions.RebindingOperation class. Call the PerformInteractiveRebinding() method on an Action to create a rebinding operation. This operation waits for the Input System to register any input from any Device which matches the Action's expected Control type, then uses InputBinding.overridePath to assign the Control path for that Control to the Action's Bindings. If the user actuates multiple Controls, the rebinding operation chooses the Control with the highest magnitude. IMPORTANT: You must dispose of InputActionRebindingExtensions.RebindingOperation instances via Dispose(), so that they don't leak memory on the unmanaged memory heap. void RemapButtonClicked(InputAction actionToRebind) { var rebindOperation = actionToRebind .PerformInteractiveRebinding().Start(); } The InputActionRebindingExtensions.RebindingOperation API is highly configurable to match your needs. For example, you can: Choose expected Control types (WithExpectedControlType()). Exclude certain Controls (WithControlsExcluding()). Set a Control to cancel the operation (WithCancelingThrough()). Choose which Bindings to apply the operation on if the Action has multiple Bindings (WithTargetBinding(), WithBindingGroup(), WithBindingMask()). Refer to the scripting API reference for InputActionRebindingExtensions.RebindingOperation for a full overview. Note that PerformInteractiveRebinding() automatically applies a set of default configurations based on the given action and targeted binding. Saving and loading rebinds You can serialize override properties of Bindings by serializing them as JSON strings and restoring them from these. Use SaveBindingOverridesAsJson to create these strings and LoadBindingOverridesFromJson to restore overrides from them. // Store player rebinds in PlayerPrefs. var rebinds = playerInput.actions.SaveBindingOverridesAsJson(); PlayerPrefs.SetString(\"rebinds\", rebinds); // Restore player rebinds from PlayerPrefs (removes all existing // overrides on the actions; pass `false` for second argument // in case you want to prevent that). var rebinds = PlayerPrefs.GetString(\"rebinds\"); playerInput.actions.LoadBindingOverridesFromJson(rebinds); Restoring original Bindings You can remove Binding overrides and thus restore defaults by using RemoveBindingOverride or RemoveAllBindingOverrides. // Remove binding overrides from the first binding of the \"fire\" action. playerInput.actions[\"fire\"].RemoveBindingOverride(0); // Remove all binding overrides from the \"fire\" action. playerInput.actions[\"fire\"].RemoveAllBindingOverrides(); // Remove all binding overrides from a player's actions. playerInput.actions.RemoveAllBindingOverrides(); Displaying Bindings It can be useful for the user to know what an Action is currently bound to (taking any potentially active rebindings into account) while rebinding UIs, and for on-screen hints while the app is running. You can use InputBinding.effectivePath to get the currently active path for a Binding (which returns overridePath if set, or otherwise returns path). The easiest way to retrieve a display string for an action is to call InputActionRebindingExtensions.GetBindingDisplayString which is an extension method for InputAction. // Get a binding string for the action as a whole. This takes into account which // bindings are currently active and the actual controls bound to the action. m_RebindButton.GetComponentInChildren<Text>().text = action.GetBindingDisplayString(); // Get a binding string for a specific binding on an action by index. m_RebindButton.GetComponentInChildren<Text>().text = action.GetBindingDisplayString(1); // Look up binding indices with GetBindingIndex. var bindingIndex = action.GetBindingIndex(InputBinding.MaskByGroup(\"Gamepad\")); m_RebindButton.GetComponentInChildren<Text>().text = action.GetBindingDisplayString(bindingIndex); You can also use this method to replace the text string with images. // Call GetBindingDisplayString() such that it also returns information about the // name of the device layout and path of the control on the device. This information // is useful for reliably associating imagery with individual controls. // NOTE: The first argument is the index of the binding within InputAction.bindings. var bindingString = action.GetBindingDisplayString(0, out deviceLayout, out controlPath); // If it's a gamepad, look up an icon for the control. Sprite icon = null; if (!string.IsNullOrEmpty(deviceLayout) && !string.IsNullOrEmpty(controlPath) && InputSystem.IsFirstLayoutBasedOnSecond(deviceLayout, \"Gamepad\")) { switch (controlPath) { case \"buttonSouth\": icon = aButtonIcon; break; case \"dpad/up\": icon = dpadUpIcon; break; //... } } // If you have an icon, display it instead of the text. var text = m_RebindButton.GetComponentInChildren<Text>(); var image = m_RebindButton.GetComponentInChildren<Image>(); if (icon != null) { // Display icon. text.gameObject.SetActive(false); image.gameObject.SetActive(true); image.sprite = icon; } else { // Display text. text.gameObject.SetActive(true); image.gameObject.SetActive(false); text.text = bindingString; } Additionally, each Binding has a ToDisplayString method, which you can use to turn individual Bindings into display strings. There is also a generic formatting method for Control paths, InputControlPath.ToHumanReadableString, which you can use with arbitrary Control path strings. Note that the Controls a Binding resolves to can change at any time, and the display strings for controls might change dynamically. For example, if the user switches the currently active keyboard layout, the display string for each individual key on the Keyboard might change. Control Schemes A Binding can belong to any number of Binding groups. Unity stores these on the InputBinding class as a semicolon-separated string in the InputBinding.groups property, and you can use them for any arbitrary grouping of bindings. To enable different sets of binding groups for an InputActionMap or InputActionAsset, you can use the InputActionMap.bindingMask/InputActionAsset.bindingMask property. The Input System uses this to implement the concept of grouping Bindings into different InputControlSchemes. Control Schemes use Binding groups to map Bindings in an InputActionMap or InputActionAsset to different types of Devices. The PlayerInput class uses these to enable a matching Control Scheme for a new user joining the game, based on the Device they are playing on. Details Binding resolution When the Input System accesses the Controls bound to an Action for the first time, the Action resolves its Bindings to match them to existing Controls on existing Devices. In this process, the Action calls InputSystem.FindControls<>() (filtering for devices assigned to the InputActionMap, if there are any) for the Binding path of each of the Action's bindings. This creates a list of resolved Controls that are now bound to the Action. Note that a single Binding path can match multiple Controls: A specific Device path such as <DualShockGamepad>/buttonEast matches the \"Circle\" button on a PlayStation controller. If you have multiple PlayStation controllers connected, it resolves to the \"Circle\" button on each of these controllers. An abstract Device path such as <Gamepad>/buttonEast matches the right action button on any connected gamepad. If you have a PlayStation controller and an Xbox controller connected, it resolves to the \"Circle\" button on the PlayStation controller, and to the \"B\" button on the Xbox controller. A Binding path can also contain wildcards, such as <Gamepad>/button*. This matches any Control on any gamepad with a name starting with \"button\", which matches all the four action buttons on any connected gamepad. A different example: */{Submit} matches any Control tagged with the \"Submit\" usage on any Device. If there are multiple Bindings on the same Action that all reference the same Control(s), the Control will effectively feed into the Action multiple times. This is to allow, for example, a single Control to produce different input on the same Action by virtue of being bound in a different fashion (composites, processors, interactions, etc). However, regardless of how many times a Control is bound on any given action, it will only be mentioned once in the Action's array of controls. To query the Controls that an Action resolves to, you can use InputAction.controls. You can also run this query if the Action is disabled. To be notified when binding resolution happens, you can listen to InputSystem.onActionChange which triggers InputActionChange.BoundControlsAboutToChange before modifying Control lists and triggers InputActionChange.BoundControlsChanged after having updated them. Binding resolution while Actions are enabled In certain situations, the Controls bound to an Action have to be updated more than once. For example, if a new Device becomes usable with an Action, the Action may now pick up input from additional controls. Also, if Bindings are added, removed, or modified, Control lists will need to be updated. This updating of Controls usually happens transparently in the background. However, when an Action is enabled and especially when it is in progress, there may be a noticeable effect on the Action. Adding or removing a device – either globally or to/from the device list of an Action – will remain transparent except if an Action is in progress and it is the device of its active Control that is being removed. In this case, the Action will automatically be cancelled. Modifying the binding mask or modifying any of the Bindings (such as through rebinding or by adding or removing bindings) will, however, lead to all enabled Actions being temporarily disabled and then re-enabled and resumed. Choosing which Devices to use Note: InputUser and PlayerInput make use of this facility automatically. They set InputActionMap.devices automatically based on the Devices that are paired to the user. By default, Actions resolve their Bindings against all Devices present in the Input System (that is, InputSystem.devices). For example, if there are two gamepads present in the system, a Binding to <Gamepad>/buttonSouth picks up both gamepads and allows the Action to be used from either. You can override this behavior by restricting InputActionAssets or individual InputActionMaps to a specific set of Devices. If you do this, Binding resolution only takes the Controls of the given Devices into account. var actionMap = new InputActionMap(); // Restrict the action map to just the first gamepad. actionMap.devices = new[] { Gamepad.all[0] }; Conflicting inputs There are two situations where a given input may lead to ambiguity: Several Controls are bound to the same Action and more than one is feeding input into the Action at the same time. Example: an Action that is bound to both the left and right trigger on a Gamepad and both triggers are pressed. The input is part of a sequence of inputs and there are several possible such sequences. Example: one Action is bound to the B key and another Action is bound to Shift-B. Multiple, concurrently used Controls Note: This section does not apply to PassThrough Actions as they are by design meant to allow multiple concurrent inputs. For a Button or Value Action, there can only be one Control at any time that is \"driving\" the Action. This Control is considered the activeControl. When an Action is bound to multiple Controls, the activeControl at any point is the one with the greatest level of \"actuation\", that is, the largest value returned from EvaluateMagnitude. If a Control exceeds the actuation level of the current activeControl, it will itself become the active Control. The following example demonstrates this mechanism with a Button Action and also demonstrates the difference to a PassThrough Action. // Create a button and a pass-through action and bind each of them // to both triggers on the gamepad. var buttonAction = new InputAction(type: InputActionType.Button, binding: \"<Gamepad>/*Trigger\"); var passThroughAction = new InputAction(type: InputActionType.PassThrough, binding: \"<Gamepad>/*Trigger\"); buttonAction.performed += c => Debug.Log(\"${c.control.name} pressed (Button)\"); passThroughAction.performed += c => Debug.Log(\"${c.control.name} changed (Pass-Through)\"); buttonAction.Enable(); passThroughAction.Enable(); // Press the left trigger all the way down. // This will trigger both buttonAction and passThroughAction. Both will // see leftTrigger becoming the activeControl. Set(gamepad.leftTrigger, 1f); // Will log // \"leftTrigger pressed (Button)\" and // \"leftTrigger changed (Pass-Through)\" // Press the right trigger halfway down. // This will *not* trigger or otherwise change buttonAction as the right trigger // is actuated *less* than the left one that is already driving action. // However, passThrough action is not performing such tracking and will thus respond // directly to the value change. It will perform and make rightTrigger its activeControl. Set(gamepad.rightTrigger, 0.5f); // Will log // \"rightTrigger changed (Pass-Through)\" // Release the left trigger. // For buttonAction, this will mean that now all controls feeding into the action have // been released and thus the button releases. activeControl will go back to null. // For passThrough action, this is just another value change. So, the action performs // and its active control changes to leftTrigger. Set(gamepad.leftTrigger, 0f); // Will log // \"leftTrigger changed (Pass-Through)\" For composite bindings, magnitudes of the composite as a whole rather than for individual Controls are tracked. However, activeControl will stick track individual Controls from the composite. Disabling Conflict Resolution Conflict resolution is always applied to Button and Value type Actions. However, it can be undesirable in situations when an Action is simply used to gather any and all inputs from bound Controls. For example, the following Action would monitor the A button of all available gamepads: var action = new InputAction(type: InputActionType.PassThrough, binding: \"<Gamepad>/buttonSouth\"); action.Enable(); By using the Pass-Through Action type, conflict resolution is bypassed and thus, pressing the A button on one gamepad will not result in a press on a different gamepad being ignored. Multiple input sequences (such as keyboard shortcuts) Note: The mechanism described here only applies to Actions that are part of the same InputActionMap or InputActionAsset. Inputs that are used in combinations with other inputs may also lead to ambiguities. If, for example, the b key on the Keyboard is bound both on its own as well as in combination with the shift key, then if you first press shift and then b, the latter key press would be a valid input for either of the Actions. The way this is handled is that Bindings will be processed in the order of decreasing \"complexity\". This metric is derived automatically from the Binding: A binding that is not part of a composite is assigned a complexity of 1. A binding that is part of a composite is assigned a complexity equal to the number of part bindings in the composite. In our example, this means that a OneModifier composite Binding to Shift+B has a higher \"complexity\" than a Binding to B and thus is processed first. Additionally, the first Binding that results in the Action changing phase will \"consume\" the input. This consuming will result in other Bindings to the same input not being processed. So in our example, when Shift+B \"consumes\" the B input, the Binding to B will be skipped. The following example illustrates how this works at the API level. // Create two actions in the same map. var map = new InputActionMap(); var bAction = map.AddAction(\"B\"); var shiftbAction = map.AddAction(\"ShiftB\"); // Bind one of the actions to 'B' and the other to 'SHIFT+B'. bAction.AddBinding(\"<Keyboard>/b\"); shiftbAction.AddCompositeBinding(\"OneModifier\") .With(\"Modifier\", \"<Keyboard>/shift\") .With(\"Binding\", \"<Keyboard>/b\"); // Print something to the console when the actions are triggered. bAction.performed += _ => Debug.Log(\"B action performed\"); shiftbAction.performed += _ => Debug.Log(\"SHIFT+B action performed\"); // Start listening to input. map.Enable(); // Now, let's assume the left shift key on the keyboard is pressed (here, we manually // press it with the InputTestFixture API). Press(Keyboard.current.leftShiftKey); // And then the B is pressed. This is a valid input for both // bAction as well as shiftbAction. // // What will happen now is that shiftbAction will do its processing first. In response, // it will *perform* the action (i.e. we see the `performed` callback being invoked) and // thus \"consume\" the input. bAction will stay silent as it will in turn be skipped over. Press(keyboard.bKey); Initial state check After an Action is enabled, it will start reacting to input as it comes in. However, at the time the Action is enabled, one or more of the Controls that are bound to an action may already have a non-default state at that point. x Using what is referred to as an \"initial state check\", an Action can be made to respond to such a non-default state as if the state change happened after the Action was enabled. The way this works is that in the first input update after the Action was enabled, all its bound controls are checked in turn. If any of them has a non-default state, the Action responds right away. This check is implicitly enabled for Value actions. If, for example, you have a Move Action bound to the left stick on the gamepad and the stick is already pushed in a direction when Move is enabled, the character will immediately start walking. By default, Button and Pass-Through type Actions, do not perform this check. A button that is pressed when its respective Action is enabled first needs to be released and then pressed again for it to trigger the Action. However, you can manually enable initial state checks on these types of Actions using the checkbox in the editor:"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Actions.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Actions.html",
    "title": "Actions | Inventory System",
    "summary": "Actions Actions are an important concept in the Input System. They allow you to separate the purpose of an input from the device controls which perform that input. Actions allow you to associate the purpose and device controls together in a flexible way. For example, the purpose of an input in a game might be to make the player's character move around. The device control associated with that action might be the motion of the left gamepad stick. The association between an Action and the device controls which perform that input is a binding, and you can set up bindings in the Input Actions editor. When you use Actions in your code, you do not need to refer to specific devices because the binding defines which device's controls are used to perform the action. To use actions in your code, you must use the Input Actions editor to establish the mapping between the Action and one or more device controls. For example in this screenshot, the \"Move\" action is displayed, showing its bindings the left gamepad stick, and the keyboard's arrow keys. The Actions panel of the Input Actions Editor in Project Settings You can then get a reference to this action in your code, and check its value, or attach a callback method to be notified when it is performed. See the Actions Workflow page for a simple example script demonstrating this. Actions also make it simpler to create a system that lets your players customize their bindings at runtime, which is a common requirement for games. Notes: Actions are a runtime only feature. You can't use them in Editor window code. You can read input without using Actions and Bindings by directly reading specific device controls. This is less flexible, but can be quicker to implement for certain situations. Read more about directly reading devices from script. Although you can reorder actions in this window, the ordering is for visual convenience only, and does not affect the order in which the actions are triggered in your code. If multiple actions are performed in the same frame, the order in which they are reported by the input system is undefined. To avoid problems, you should not write code that assumes they will be reported in a particular order. Overview When scripting with Actions in the Input System, there are number of important API you can use, which are described here: API name Description InputSystem.actions A reference to the set of actions assigned as the project-wide Actions. InputActionMap A named collection of Actions. The API equivalent to an entry in the \"Action Maps\" column of the Input Actions editor. InputAction A named Action that can return the current value of the controls that it is bound to, or can trigger callbacks in response to input. The API equivalent to an entry in the \"Actions\" column of the Input Actions editor. InputBinding The relationship between an Action and the specific device controls for which it receives input. For more information about Bindings and how to use them, see Action Bindings. Each Action has a name (InputAction.name), which must be unique within the Action Map that the Action belongs to, if any (see InputAction.actionMap). Each Action also has a unique ID (InputAction.id), which you can use to reference the Action. The ID remains the same even if you rename the Action. Each Action Map has a name (InputActionMap.name), which must also be unique with respect to the other Action Maps present, if any. Each Action Map also has a unique ID (InputActionMap.id), which you can use to reference the Action Map. The ID remains the same even if you rename the Action Map. Creating Actions The simplest way to create actions is to use the Input Actions editor in the Project Settings window. This is the primary recommended workflow and suitable for most scenarios. However, because the input system API is very open, there are many other ways to create actions which may suit less common scenarios. For example, by loading actions from JSON data, or creating actions entirely in code. Creating Actions using the Action editor For information on how to create and edit Input Actions in the editor, see the Input Actions editor. This is the recommended workflow if you want to organise all your input actions and bindings in one place, which applies across the whole of your project. This often the case for most types of game or app. The Input Actions Editor in the Project Settings window Other ways to create Actions The simplest way to create actions is to use the Input Actions editor to configure a set of actions in an asset, as described above. However, because the Input System package API is open and flexible, you can create actions using alternative techniques. These alternatives might be more suitable if you want to customize your project beyond the standard workflow. Creating Actions by declaring them in MonoBehaviours As an alternative workflow, you can declare individual Input Action and Input Action Maps as fields directly inside MonoBehaviour components. using UnityEngine; using UnityEngine.InputSystem; public class ExampleScript : MonoBehaviour { public InputAction move; public InputAction jump; } The result is similar to using an Actions defined in the Input Actions editor, except the Actions are defined in the GameObject's properties and saved as Scene or Prefab data, instead of in a dedicated Asset. When you embed actions like this, by defining serialized InputAction fields in a MonoBehaviour, the GameObject's Inspector window displays an interface similar to the Actions column of the Actions Editor, which allows you to set up the bindings for those actions. For example: To add or remove Actions or Bindings, click the Add (+) or Remove (-) icon in the header. To edit Bindings, double-click them. To edit Actions, double-click them in an Action Map, or click the gear icon on individual Action properties. You can also right-click entries to bring up a context menu, and you can drag them. Hold the Alt key and drag an entry to duplicate it. Unlike the project-wide actions in the Project Settings window, you must manually enable and disable Actions and Action Maps that are embedded in MonoBehaviour components. When you use this workflow, the serialised action configurations are stored with the parent GameObject as part of the scene, opposite to being serialised with an Action Asset. This can be useful if you want to bundle the control bindings and behaviour together in a single monobehaviour or prefab, so it can be distributed together. However, this can also make it harder to organize your full set of control bindings if they are distributed across multiple prefabs or scenes. Loading Actions from JSON You can load Actions as JSON in the form of a set of Action Maps or as a full InputActionAsset. This also works at runtime in the Player. // Load a set of action maps from JSON. var maps = InputActionMap.FromJson(json); // Load an entire InputActionAsset from JSON. var asset = InputActionAsset.FromJson(json); Creating Actions in code You can manually create and configure Actions entirely in code, including assigning the bindings. This also works at runtime in the Player. For example: // Create free-standing Actions. var lookAction = new InputAction(\"look\", binding: \"<Gamepad>/leftStick\"); var moveAction = new InputAction(\"move\", binding: \"<Gamepad>/rightStick\"); lookAction.AddBinding(\"<Mouse>/delta\"); moveAction.AddCompositeBinding(\"Dpad\") .With(\"Up\", \"<Keyboard>/w\") .With(\"Down\", \"<Keyboard>/s\") .With(\"Left\", \"<Keyboard>/a\") .With(\"Right\", \"<Keyboard>/d\"); // Create an Action Map with Actions. var map = new InputActionMap(\"Gameplay\"); var lookAction = map.AddAction(\"look\"); lookAction.AddBinding(\"<Gamepad>/leftStick\"); // Create an Action Asset. var asset = ScriptableObject.CreateInstance<InputActionAsset>(); var gameplayMap = new InputActionMap(\"gameplay\"); asset.AddActionMap(gameplayMap); var lookAction = gameplayMap.AddAction(\"look\", \"<Gamepad>/leftStick\"); Any action that you create in this way during Play mode do not persist in the Input Action Asset after you exit Play mode. This means you can test your application in a realistic manner in the Editor without having to worry about inadvertently modifying the asset. Enabling actions Actions have an enabled state, meaning you can enable or disable them to suit different situations. If you have an Action Asset assigned as project-wide, the actions it contains are enabled by default and ready to use. For actions defined elsewhere, such as in an Action Asset not assigned as project-wide, or defined your own code, they begin in a disabled state, and you must enable them before they will respond to input. You can enable actions individually, or as a group by enabling the Action Map which contains them. // Enable a single action. lookAction.Enable(); // Enable an en entire action map. gameplayActions.Enable(); When you enable an Action, the Input System resolves its bindings, unless it has done so already, or if the set of devices that the Action can use has not changed. For more details about this process, see the documentation on binding resolution. You can't change certain aspects of the configuration, such Action Bindings, while an Action is enabled. To stop Actions or Action Maps from responding to input, call Disable. While enabled, an Action actively monitors the Control(s) it's bound to. If a bound Control changes state, the Action processes the change. If the Control's change represents an Interaction change, the Action creates a response. All of this happens during the Input System update logic. Depending on the update mode selected in the input settings, this happens once every frame, once every fixed update, or manually if updates are set to manual."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionsEditor.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ActionsEditor.html",
    "title": "Configuring Input with the Actions Editor | Inventory System",
    "summary": "Configuring Input with the Actions Editor The Input Actions Editor allows you to edit Action Assets, which contain a saved configuration of Input Actions and their associated Bindings. It allows you to group collections of Actions into Action Maps, which represent different input scenarios in your project (such as UI navigation, gameplay, etc.) It also alows you to define Control Schemes which are a way to enable or disable a set of devices, or respond to which type of device is being used. This is often useful if you want to customise your UI based on whether your users are using mouse, keyboard, or gamepad as their chosen input. Action Assets and Project-Wide Actions The typical workflow for most projects is to have a single Action Asset, which is assigned as the project-wide actions. If you have not yet created and assigned an Actions Asset as the project-wide actions, the recommended workflow is to do this first. Read more about project-wide actions. Opening the Actions Editor The Input Actions Editor is an editor window displayed when you open an Action Asset by double-clicking it. It is also displayed in the Project Settings window under Edit > Project Settings > Input System Package if you have an Action Asset assigned as project-wide. The Input Actions editor, displaying the default actions The Actions Editor panels The Input Actions editor is divided into three panels (marked A, B & C above). Name Description (A) Action Maps Displays the list of currently defined Action Maps. Each Action Map is a collection of Actions that you can enable or disable together as a group. (B) Actions Displays all the actions defined in the currently selected Action Map, and the bindings associated with each Action. (C) Properties Displays the properties of the currently selected Action or Binding from the Actions panel. The title of this panel changes depending on whether you have an Action or a Binding selected in the Actions panel. Configure Action Maps To add a new Action Map, select the Add (+) icon in the header of the Action Map panel. To rename an existing Action Map, either long-click the name, or right-click the Action Map and select Rename from the context menu. Note that Action Map names can't contain slashes (/). To delete an existing Action Map, right-click it and select Delete from the context menu. To duplicate an existing Action Map, right-click it and select Duplicate from the context menu. Configure Actions To add a new Action, select the Add (+) icon in the header of the Action column. To rename an existing Action, either long-click the name, or right-click the Action Map and select Rename from the context menu. To delete an existing Action, either right-click it and select Delete from the context menu. To duplicate an existing Action, either right-click it and select Duplicate from the context menu. Action type and Control type If you select an Action, you can edit its properties in the right-hand pane of the window: Action Type The Action Type setting allows to to select between Button, Value or PassThrough. These options relate to whether this action should represent a discrete on/off button-style interaction or a value that can change over time while the control is being used. For device controls such as keyboard keys, mouse clicks, or gamepad buttons, select Button. For device controls such as mouse movement, a joystick or gamepad stick, or device orientation that provide continuously changing input over a period of time, select Value. The Button and Value types of action also provides data about the action such as whether it has started and stopped, and conflict resolution in situations where multiple bindings are mapped to the same action. The third option, PassThrough, is also a value type, and as such is suitable for the same types of device controls as value. The difference is that actions set to PassThrough only provide basic information about the values incoming from the device controls bound to it, and does not provide the extra data relating to the phase of the action, nor does it perform conflict resolution in the case of multiple controls mapped to the same action. For more detail about how these types work, see action types and default interactions. Control Type The Control Type setting allows you to select the type of control expected by the action. This limits the controls shown when setting up bindings in the UI and also limits which contols can be bound interactively to the action. For example, if you select 2D axis, only those controls that can supply a 2D vector as value are available as options for the binding control path. There are more specific control types available which futher filter the available bindings, such as \"Stick\", \"Dpad\" or \"Touch\". If you select one of these control types, the list of available controls is further limited to only those controls of those specific types when you select a binding for your action (see directly below). Bindings To add a new Binding, select the Add (+) icon on the action you want to add it to, and select the binding type from the menu that appears. To delete an existing Binding, either right-click it and select Delete from the context menu. To duplicate an existing Binding, either right-click it and select Duplicate from the context menu. You can add multiple bindings to an action, which is generally useful for supporting multiple types of input device. For example, in the default set of actions, the \"Move\" action has a binding to the left gamepad stick and the WSAD keys, which means input through any of these bindings will perform the action. The default \"Move\" action in the Actions Editor window, displaying the multiple bindings associated with it. If you select a Binding, you can edit its properties in the right-hand pane of the window: Picking Controls The most important property of any Binding is the control path it's bound to. To edit it, open the Path drop-down list. This displays a Control picker window. In the Control picker window, you can explore a tree of Input Devices and Controls that the Input System recognizes, and bind to these Controls. Unity filters this list by the Action's Control Type property. For example, if the Control type is Vector2, you can only select a Control that generates two-dimensional values, like a stick. The Device and Control tree is organized hierarchically from generic to specific. For example, the Gamepad Control path <Gamepad>/buttonSouth matches the lower action button on any gamepad. Alternatively, if you navigate to Gamepad > More Specific Gamepads and select PS4 Controller, and then choose the Control path <DualShockGamepad>/buttonSouth, this only matches the \"Cross\" button on PlayStation gamepads, and doesn't match any other gamepads. Instead of browsing the tree to find the Control you want, it's easier to let the Input System listen for input. To do that, select the Listen button. At first, the list of Controls is empty. Once you start pressing buttons or actuating Controls on the Devices you want to bind to, the Control picker window starts listing any Bindings that match the controls you pressed. Select any of these Bindings to view them. Finally, you can choose to manually edit the Binding path, instead of using the Control picker. To do that, select the T button next to the Control path popup. This changes the popup to a text field, where you can enter any Binding string. This also allows you to use wildcard (*) characters in your Bindings. For example, you can use a Binding path such as <Touchscreen>/touch*/press to bind to any finger being pressed on the touchscreen, instead of manually binding to <Touchscreen>/touch0/press, <Touchscreen>/touch1/press and so on. Editing Composite Bindings Composite Bindings are Bindings consisting of multiple parts, which form a Control together. For instance, a 2D Vector Composite uses four buttons (left, right, up, down) to simulate a 2D stick input. See the Composite Bindings documentation to learn more. To create a Composite Binding, in the Input Action Asset editor window, select the Add (+) icon on the Action you want to add it to, and select the Composite Binding type from the popup menu. This creates multiple Binding entries for the Action: one for the Composite as a whole, and then, one level below that, one for each Composite part. The Composite itself doesn't have a Binding path property, but its individual parts do, and you can edit these parts like any other Binding. Once you bind all the Composite's parts, the Composite can work together as if you bound a single control to the Action. Note: The set of Composites displayed in the menu is depends on the value type of the Action. This means that, for example, if the Action is set to type \"Button\", then only Composites able to return values of type float will be shown. To change the type of a Composite retroactively, select the Composite, then select the new type from the Composite Type drop-down in the Properties pane. To change the part of the Composite to which a particular Binding is assigned, use the Composite Part drop-down in the Binding's properties. You can assign multiple Bindings to the same part. You can also duplicate individual part Bindings: right-click the Binding, then select Duplicate to create new part Bindings for the Composite. This can be used, for example, to create a single Composite for both \"WASD\" style controls and arrow keys. Editing Control Schemes Input Action Assets can have multiple Control Schemes, which let you enable or disable different sets of Bindings for your Actions for different types of Devices. To see the Control Schemes in the Input Action Asset editor window, open the Control Scheme drop-down list in the top left of the window. This menu lets you add or remove Control Schemes to your Actions Asset. If the Actions Asset contains any Control Schemes, you can select a Control Scheme, and then the window only shows bindings that are associated with that Scheme. If you select a binding, you can now pick the Control Schemes for which this binding should be active in the Properties view to the left of the window. When you add a new Control Scheme, or select an existing Control Scheme, and then select Edit Control Scheme, you can edit the name of the Control Scheme and which devices the Scheme should be active for. When you add a new Control Scheme, the \"Device Type\" list is empty by default (as shown above). You must add at least one type of device to this list for the Control Scheme to be functional."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Architecture.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Architecture.html",
    "title": "Architecture | Inventory System",
    "summary": "Architecture The Input System has a layered architecture that consists of a low-level layer and a high-level layer. Native backend The foundation of the Input System is the native backend code. This is platform-specific code which collects information about available Devices and input data from Devices. This code is not part of the Input System package, but is included with Unity itself. It has implementations for each runtime platform supported by Unity. This is why some platform-specific input bugs can only be fixed by an update to Unity, rather than a new version of the Input System package. The Input System interfaces with the native backend using events that the native backend sends. These events notify the system of the creation and removal of Input Devices, as well as any updates to the Device states. For efficiency and to avoid creating any garbage, the native backend reports these events as a simple buffer of raw, unmanaged memory containing a stream of events. The Input System can also send data back to the native backend in the form of commands sent to Devices, which are also buffers of memory that the native backend interprets. These commands can have different meanings for different Device types and platforms. Input System (low-level) The low-level Input System code processes and interprets the memory from the event stream that the native backend provides, and dispatches individual events. The Input System creates Device representations for any newly discovered Device in the event stream. The low-level code sees a Device as a block of raw, unmanaged memory. If it receives a state event for a Device, it writes the data from the state event into the Device's state representation in memory, so that the state always contains an up-to-date representation of the Device and all its Controls. The low-level system code also contains structs which describe the data layout of commonly known Devices. Input System (high-level) The high-level Input System code interprets the data in a Device's state buffers by using layouts, which describe the data layout of a Device and its Controls in memory. The Input System creates layouts from either the pre-defined structs of commonly known Devices supplied by the low level system, or dynamically at runtime, as in the case of generic HIDs. Based on the information in the layouts, the Input System then creates Control representations for each of the Device's controls, which let you read the state of each individual Control in a Device. As part of the high-level system, you can also build another abstraction layer to map Input Controls to your application mechanics. Use Actions to bind one or more Controls to an input in your application. The Input System then monitors these Controls for state changes, and notifies your game logic using callbacks. You can also specify more complex behaviors for your Actions using Processors (which perform processing on the input data before sending it to you) and Interactions (which let you specify patterns of input on a Control to listen to, such as multi-taps)."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Concepts.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Concepts.html",
    "title": "Basic Concepts | Inventory System",
    "summary": "Basic Concepts This page introduces the basic concepts that relate to working with the Input System. They relate to the steps in the sequence of events that occur when a user sends input to your game or app. The Input System provides features which implement these steps, or you can choose to implement some of them yourself. Concept Description User The person playing your game or using your app, by holding or touching the input device and providing input. Input Device Often referred to just as a \"device\" within the context of input. A physical piece of hardware, such as a keyboard, gamepad, mouse, or touchscreen which allows the user to send input into Unity. Control The separate individual parts of an input device which each send input values into Unity. For example, a gamepad’s controls comprise multiple buttons, sticks and triggers, and a mouse’s controls include the two X and Y sensors on the underside, and the various buttons and scroll wheels on the top side. Action Actions are a high-level concept that describe individual things that a user might want to do in your game or app, such as \"Jump\" within a game, or \"Select\" in an on-screen UI. They are things a user can do in your game or app as a result of input, regardless of what device or control they use to perform it. Actions generally have conceptual names that you choose to suit your project, and should usually be verbs. For example \"Run\", \"Jump\" \"Crouch\", \"Use\", \"Start\", \"Quit\". Action Map Action Maps allow you to organise Actions into groups which represent specific situations where a set of actions make sense together. You can simultaneously enable or disable all Actions in an action map, so it is useful to group Actions in Action Maps by the context in which they are relevant. For example, you might have one action map for controlling a player, and another for interacting with your game's UI. Binding A connection defined between an Action and specific device controls. For example, your \"Move\" action might have bindings to the arrow keys and WSAD keys on the keyboard, and the left stick on a joypad, and the primary 2D axis on a VR controller. Multiple bindings like this means your game can accept cross-platform input. Your Action Code The part of your script which is executed based on the actions you have configured. In your code, you can use references to actions to either read the current value or state of the action (also known as \"polling\"), or set up a callback to call your own method when actions are performed. Action Asset An asset type which contains a saved configuration of Action Maps, Actions and Bindings. You can specify one Action Asset in your project as the project-wide actions, which allows you to easily reference those actions in code by using InputSystem.actions."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Contributing.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Contributing.html",
    "title": "Contributing | Inventory System",
    "summary": "Contributing The full source code for the Input System is available on GitHub. This is also where most of the Input System's development happens. Note: This includes the full source code for the managed/C# part of the system. At this point, the native, platform-specific C++ backends are still closed-source and require a source code license. Reporting bugs To report documentation problems, please use the feedback section at the bottom of the page containing the problem. To report bugs related to the Input System Please follow Unity's standard bug reporting guidelines. Don't forget to submit a Project that the developer who picks up your report can use to reproduce the issue. Be sure to mention that the bug is specific to the Input System package in the description, so it gets forwarded to the correct team at Unity. Discussion To ask questions or discuss the Input System, see the dedicated section on Unity's forum. This is also the best place to post feature requests."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Controls.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Controls.html",
    "title": "Controls | Inventory System",
    "summary": "Controls Hierarchies Types Usages Paths State Actuation Noisy Controls Synthetic Controls Performance Optimization An Input Control represents a source of values. These values can be of any structured or primitive type. The only requirement is that the type is blittable. Note: Controls are for input only. Output and configuration items on Input Devices are not represented as Controls. Each Control is identified by a name (InputControl.name) and can optionally have a display name (InputControl.displayName) that differs from the Control name. For example, the right-hand face button closest to the touchpad on a PlayStation DualShock 4 controller has the control name \"buttonWest\" and the display name \"Square\". Additionally, a Control might have one or more aliases which provide alternative names for the Control. You can access the aliases for a specific Control through its InputControl.aliases property. Finally, a Control might also have a short display name which can be accessed through the InputControl.shortDisplayName property. For example, the short display name for the left mouse button is \"LMB\". Control hierarchies Controls can form hierarchies. The root of a Control hierarchy is always a Device. The setup of hierarchies is exclusively controlled through layouts. You can access the parent of a Control using InputControl.parent, and its children using InputControl.children. To access the flattened hierarchy of all Controls on a Device, use InputDevice.allControls. Control types All controls are based on the InputControl base class. Most concrete implementations are based on InputControl<TValue>. The Input System provides the following types of controls out of the box: Control Type Description Example AxisControl A 1D floating-point axis. Gamepad.leftStick.x ButtonControl A button expressed as a floating-point value. Whether the button can have a value other than 0 or 1 depends on the underlying representation. For example, gamepad trigger buttons can have values other than 0 and 1, but gamepad face buttons generally can't. Mouse.leftButton KeyControl A specialized button that represents a key on a Keyboard. Keys have an associated keyCode and, unlike other types of Controls, change their display name in accordance to the currently active system-wide keyboard layout. See the Keyboard documentation for details. Keyboard.aKey Vector2Control A 2D floating-point vector. Pointer.position Vector3Control A 3D floating-point vector. Accelerometer.acceleration QuaternionControl A 3D rotation. AttitudeSensor.attitude IntegerControl An integer value. Touchscreen.primaryTouch.touchId StickControl A 2D stick control like the thumbsticks on gamepads or the stick control of a joystick. Gamepad.rightStick DpadControl A 4-way button control like the D-pad on gamepads or hatswitches on joysticks. Gamepad.dpad TouchControl A control that represents all the properties of a touch on a touch screen. Touchscreen.primaryTouch You can browse the set of all registered control layouts in the input debugger. Control usages A Control can have one or more associated usages. A usage is a string that denotes the Control's intended use. An example of a Control usage is Submit, which labels a Control that is commonly used to confirm a selection in the UI. On a gamepad, this usage is commonly found on the buttonSouth Control. You can access a Control's usages using the InputControl.usages property. Usages can be arbitrary strings. However, a certain set of usages is very commonly used and comes predefined in the API in the form of the CommonUsages static class. Check out the CommonUsages scripting API page for an overview. Control paths Example: <Gamepad>/leftStick/x means \"X Control on left stick of gamepad\". The Input System can look up Controls using textual paths. Bindings on Input Actions rely on this feature to identify the Control(s) they read input from. However, you can also use them for lookup directly on Controls and Devices, or to let the Input System search for Controls among all devices using InputSystem.FindControls. var gamepad = Gamepad.all[0]; var leftStickX = gamepad[\"leftStick/x\"]; var submitButton = gamepad[\"{Submit}\"]; var allSubmitButtons = InputSystem.FindControls(\"*/{Submit}\"); Control paths resemble file system paths. Each path consists of one or more components separated by a forward slash: component/component... Each component uses a similar syntax made up of multiple fields. Each field is optional, but at least one field must be present. All fields are case-insensitive. <layoutName>{usageName}controlName#(displayName) The following table explains the use of each field: Field Description Example <layoutName> Requires the Control at the current level to be based on the given layout. The actual layout of the Control may be the same or a layout based on the given layout. <Gamepad>/buttonSouth {usageName} Works differently for Controls and Devices. When used on a Device (the first component of a path), it requires the device to have the given usage. See Device usages for more details. For looking up a Control, the usage field is currently restricted to the path component immediately following the Device (the second component in the path). It finds the Control on the Device that has the given usage. The Control can be anywhere in the Control hierarchy of the Device. Device: <XRController>{LeftHand}/trigger Control: <Gamepad>/{Submit} controlName Requires the Control at the current level to have the given name. Takes both \"proper\" names (InputControl.name) and aliases (InputControl.aliases) into account. This field can also be a wildcard (*) to match any name. MyGamepad/buttonSouth */{PrimaryAction} (match PrimaryAction usage on Devices with any name) #(displayName) Requires the Control at the current level to have the given display name (i.e. InputControl.displayName). The display name may contain whitespace and symbols. <Keyboard>/#(a) (matches the key that generates the \"a\" character, if any, according to the current keyboard layout). <Gamepad>/#(Cross) You can access the literal path of a given control via its InputControl.path property. If needed, you can manually parse a control path into its components using the InputControlPath.Parse(path) API. var parsed = InputControlPath.Parse(\"<XRController>{LeftHand}/trigger\").ToArray(); Debug.Log(parsed.Length); // Prints 2. Debug.Log(parsed[0].layout); // Prints \"XRController\". Debug.Log(parsed[0].name); // Prints an empty string. Debug.Log(parsed[0].usages.First()); // Prints \"LeftHand\". Debug.Log(parsed[1].layout); // Prints null. Debug.Log(parsed[1].name); // Prints \"trigger\". Control state Each Control is connected to a block of memory that is considered the Control's \"state\". You can query the size, format, and location of this block of memory from a Control through the InputControl.stateBlock property. The state of Controls is stored in unmanaged memory that the Input System handles internally. All Devices added to the system share one block of unmanaged memory that contains the state of all the Controls on the Devices. A Control's state might not be stored in the natural format for that Control. For example, the system often represents buttons as bitfields, and axis controls as 8-bit or 16-bit integer values. This format is determined by the combination of platform, hardware, and drivers. Each Control knows the format of its storage and how to translate the values as needed. The Input System uses layouts to understand this representation. You can access the current state of a Control through its ReadValue method. Gamepad.current.leftStick.x.ReadValue(); Each type of Control has a specific type of values that it returns, regardless of how many different types of formats it supports for its state. You can access this value type through the InputControl.valueType property. Reading a value from a Control might apply one or more value Processors. See documentation on Processors for more information. Recording state history You might want to access the history of value changes on a Control (for example, in order to compute exit velocity on a touch release). To record state changes over time, you can use InputStateHistory or InputStateHistory<TValue>. The latter restricts Controls to those of a specific value type, which in turn simplifies some of the API. // Create history that records Vector2 control value changes. // NOTE: You can also pass controls directly or use paths that match multiple // controls (e.g. \"<Gamepad>/<Button>\"). // NOTE: The unconstrained InputStateHistory class can record changes on controls // of different value types. var history = new InputStateHistory<Vector2>(\"<Touchscreen>/primaryTouch/position\"); // To start recording state changes of the controls to which the history // is attached, call StartRecording. history.StartRecording(); // To stop recording state changes, call StopRecording. history.StopRecording(); // Recorded history can be accessed like an array. for (var i = 0; i < history.Count; ++i) { // Each recorded value provides information about which control changed // value (in cases state from multiple controls is recorded concurrently // by the same InputStateHistory) and when it did so. var time = history[i].time; var control = history[i].control; var value = history[i].ReadValue(); } // Recorded history can also be iterated over. foreach (var record in history) Debug.Log(record.ReadValue()); Debug.Log(string.Join(\",\\n\", history)); // You can also record state changes manually, which allows // storing arbitrary histories in InputStateHistory. // NOTE: This records a value change that didn't actually happen on the control. history.RecordStateChange(Touchscreen.current.primaryTouch.position, new Vector2(0.123f, 0.234f)); // State histories allocate unmanaged memory and need to be disposed. history.Dispose(); For example, if you want to have the last 100 samples of the left stick on the gamepad available, you can use this code: var history = new InputStateHistory<Vector2>(Gamepad.current.leftStick); history.historyDepth = 100; history.StartRecording(); Control actuation A Control is considered actuated when it has moved away from its default state in such a way that it affects the actual value of the Control. You can query whether a Control is currently actuated using IsActuated. // Check if leftStick is currently actuated. if (Gamepad.current.leftStick.IsActuated()) Debug.Log(\"Left Stick is actuated\"); It can be useful to determine not just whether a Control is actuated at all, but also the amount by which it is actuated (that is, its magnitude). For example, for a Vector2Control this would be the length of the vector, whereas for a button it is the raw, absolute floating-point value. In general, the current magnitude of a Control is always >= 0. However, a Control might not have a meaningful magnitude, in which case it returns -1. Any negative value should be considered an invalid magnitude. You can query the current amount of actuation using EvaluateMagnitude. // Check if left stick is actuated more than a quarter of its motion range. if (Gamepad.current.leftStick.EvaluateMagnitude() > 0.25f) Debug.Log(\"Left Stick actuated past 25%\"); There are two mechanisms that most notably make use of Control actuation: Interactive rebinding (InputActionRebindingExceptions.RebindOperation) uses it to select between multiple suitable Controls to find the one that is actuated the most. Conflict resolution between multiple Controls that are bound to the same action uses it to decide which Control gets to drive the action. Noisy Controls The Input System can label a Control as \"noisy\". You can query this using the InputControl.noisy property. Noisy Controls are those that can change value without any actual or intentional user interaction required. A good example of this is a gravity sensor in a cellphone. Even if the cellphone is perfectly still, there are usually fluctuations in gravity readings. Another example are orientation readings from an HMD. If a Control is marked as noisy, it means that: The Control is not considered for interactive rebinding. InputActionRebindingExceptions.RebindingOperation ignores the Control by default (you can bypass this using WithoutIgnoringNoisyControls). If enabled in the Project Settings, the system performs additional event filtering, then calls InputDevice.MakeCurrent. If an input event for a Device contains no state change on a Control that is not marked noisy, then the Device will not be made current based on the event. This avoids, for example, a plugged in PS4 controller constantly making itself the current gamepad (Gamepad.current) due to its sensors constantly feeding data into the system. When the application loses focus and Devices are reset as a result, the state of noisy Controls will be preserved as is. This ensures that sensor readinds will remain at their last value rather than being reset to default values. Note: If any Control on a Device is noisy, the Device itself is flagged as noisy. Parallel to the input state and the default state that the Input System keeps for all Devices currently present, it also maintains a noise mask in which only bits for state that is not noise are set. This can be used to very efficiently mask out noise in input. Synthetic Controls A synthetic Control is a Control that doesn't correspond to an actual physical control on a device (for example the left, right, up, and down child Controls on a StickControl). These Controls synthesize input from other, actual physical Controls and present it in a different way (in this example, they allow you to treat the individual directions of a stick as buttons). Whether a given Control is synthetic is indicated by its InputControl.synthetic property. The system considers synthetic Controls for interactive rebinding but always favors non-synthetic Controls. If both a synthetic and a non-synthetic Control that are a potential match exist, the non-synthetic Control wins by default. This makes it possible to interactively bind to <Gamepad>/leftStick/left, for example, but also makes it possible to bind to <Gamepad>/leftStickPress without getting interference from the synthetic buttons on the stick. Performance Optimization Avoiding defensive copies Use InputControl<T>.value instead of InputControl<T>.ReadValue to avoid creating a copy of the control state on every call, as the former returns the value as ref readonly while the latter always makes a copy. Note that this optimization only applies if the call site assigns the return value to a variable that has been declared 'ref readonly'. Otherwise a copy will be made as before. Additionally, be aware of defensive copies that can be allocated by the compiler when it is unable to determine that it can safely use the readonly reference i.e. if it can't determine that the reference won't be changed, it will create a defensive copy for you. For more details, see https://learn.microsoft.com/en-us/dotnet/csharp/write-safe-efficient-code#use-ref-readonly-return-statements. Control Value Caching When the 'USE_READ_VALUE_CACHING' internal feature flag is set, the Input System will switch to an optimized path for reading control values. This path efficiently marks controls as 'stale' when they have been actuated. Subsequent calls to InputControl<T>.ReadValue will only apply control processing when there have been changes to that control or in case of control processing. Control processing in this case can mean any hard-coded processing that might exist on the control, such as with AxisControl which has built-in inversion, normalisation, scaling etc, or any processors that have been applied to the controls' processor stack. Note: Performance improvements are currently not guaranteed for all use cases. Even though this performance path marks controls as \"stale\" in an efficient way, it still has an overhead which can degrade performance in some cases. A positive performance impact has been seen when: Reading from controls that do not change frequently. In case the controls change every frame, are being read and have actions bound to them as well, e.g. on a Gamepad, reading leftStick, leftStick.x and leftStick.left for example when there's a action with composite bindings setup. On the other hand, it is likely to have a negative performance impact when: No control reads are performed for a control, and there are a lot of changes for that particular control. Reading from controls that change frequently that have no actions bound to those controls. Moreover, this feature is not enabled by default as it can result in the following minor behavioural changes: Some control processors use global state. Without cached value optimizations, it is possible to read the control value, change the global state, read the control value again, and get a new value due to the fact that the control processor runs on every call. With cached value optimizations, reading the control value will only ever return a new value if the physical control has been actuated. Changing the global state of a control processor will have no effect otherwise. Writing to device state using low-level APIs like InputControl<T>.WriteValueIntoState does not set the stale flag and subsequent calls to InputControl<T>.value will not reflect those changes. After changing properties on AxisControl the ApplyParameterChanges has to be called to invalidate cached value. Processors that need to run on every read can set their respective caching policy to EvaluateOnEveryRead. That will disable caching on controls that are using such processor. If there are any non-obvious inconsistencies, 'PARANOID_READ_VALUE_CACHING_CHECKS' internal feature flag can be enabled to compare cached and uncached value on every read and log an error if they don't match. Optimized control read value When the 'USE_OPTIMIZED_CONTROLS' internal feature flag is set, the Input System will use faster way to use state memory for some controls instances. This is very specific optimization and should be used with caution. Please note: This optimization has a performance impact on PlayMode as we do extra checks to ensure that the controls have the correct memory representation during development. Don't be alarmed if you see a performance drop in PlayMode when using this optimization as it's expected at this stage. Most controls are flexible with regards to memory representation, like AxisControl can be one bit, multiple bits, a float, etc, or in Vector2Control where x and y can have different memory representation. Yet for most controls there are common memory representation patterns, for example AxisControl are floats or single bytes. Or some Vector2Control are two consequitive floats in memory. If a control matches a common representation we can bypass reading its children control and cast the memory directly to the common representation. For example if Vector2Control is two consecutive floats in memory we can bypass reading x and y separately and just cast the state memory to Vector2. Please note: This optimization only works if the controls don't need any processing applied to them, such as invert, clamp, normalize, scale or any other processor. If any of these are applied to the control, there won't be any optimization applied and the control will be read as usual. Also, InputControl.ApplyParameterChanges() must be explicitly called in specific changes to ensure InputControl.optimizedControlDataType is updated to the correct memory representation. Make sure to call it when: Configuration changes after InputControl.FinishSetup() is called. Changing parameters such AxisControl.invert, AxisControl.clamp, AxisControl.normalize, AxisControl.scale or changing processors. The memory representation needs to be recalculated after these changes so that we know that the control is not optimized anymore. Otherwise, the control will be read with wrong values. The optimized controls work as follows: A potential memory representation is set using InputControl.CalculateOptimizedControlDataType() Its memory representation is stored in InputControl.optimizedControlDataType Finally, ReadUnprocessedValueFromState uses the optimized memory representation to decide if it should cast to memory directly instead of reading every children control on it's own to reconstruct the controls state."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Debugging.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Debugging.html",
    "title": "Debugging | Inventory System",
    "summary": "Debugging Debugging Input Debugger Debugging Devices Debugging Actions Debugging users and PlayerInput Debugging layouts Debugging remotely Input visualizers InputControlVisualizer InputActionVisualizer Device Simulator Unity Remote (iOS, Android) Other tips: When something isn't working as expected, the quickest way to troubleshoot what's wrong is the Input Debugger in the Unity Editor. The Input Debugger provides access to the activity of the Input System in both the Editor and the connected Players. To open the Input Debugger, go to Window > Analysis > Input Debugger from Unity's main menu. Input Debugger The Input Debugger displays a tree breakdown of the state of the Input System. Item Description Devices A list of all Input Devices that are currently in the system, and a list of unsupported/unrecognized Devices. Layouts A list of all registered Control and Device layouts. This is the database of supported hardware, and information on how to represent a given piece of input hardware. Actions Only visible in Play mode, and only if at least one Action is enabled. A list of all currently enabled Actions, and the Controls they are bound to. See Debugging Actions. Users Only visible when one or more InputUser instances exist. See documentation on user management. A list of all currently active users, along with their active Control Schemes and Devices, all their associated Actions, and the Controls these Actions are bound to. Note that PlayerInput uses InputUser to run. When using PlayerInput components, each player has an entry in this list. See Debugging users and PlayerInput. Settings The currently active Input System settings. Metrics Statistics about Input System resource usage. Debugging Devices In the Input Debugger window, navigate to the Devices list and double-click any Input Device. This opens a window that displays information about the Device, including real-time state information for its Controls. The top of the Device window displays general information about the specific Device, such as name, manufacturer, associated layout, device flags, device ID and serial number. In addition, this section also display the current sample frequency and processing delay of the deivce. Sample frequency indicates the frequency in Hertz (Hz) at which the Input System is currently processing samples or events. For devices receiving events this reflects the current flow of events received by the system. For devices receiving periodic readings this reflects the achievable sample rate of the system. The latter may be compared to the globally configured target sampling frequency, while achievable event frequency is uncorrelated to the sample polling frequency setting. Processing delay indicates the average, minimum and maximum latency contribution from creating an input event or reading until the Input System has processed the same input event. Note that this excludes any additional input delay caused by OS, drivers or device communication. Also note that this excludes any additional output latency that may be caused by additional processing, rendering, GPU swap-chains or display refresh rate. The Controls section lists the Device's Controls and their individual states. This is useful when debugging input issues, because you can verify whether the data that the Input System receives from the Input Device is what you expect it to be. There are two buttons at the top of this panel: HID Descriptor: Only displayed for devices that use the HID protocol to connect. This opens a window that displays the detailed HID specifications for the Device and each of it's logical controls. State: Display the current state of the Device in a new window. This is identical to the information displayed in this view, but doesn't update in real time, so you can take a snapshot of input state data and take the time to inspect it as needed. The Events section lists all input events generated by the Device. You can double-click any event in the list to inspect the full Device state at the time the event occurred. To get a side-by-side difference between the state of the Device at different points in time, select multiple events, right-click them, and click Compare from the context menu. Debugging Actions The Input Debugger window lists all enabled Actions in the Actions list. This list only appears if at least one Action is active and the Editor is in Play mode. If an Action has actively bound Controls, you can click the arrow next to the Action to see a list of the Controls. This is useful to debug whether your Bindings correctly map to the Controls you want them to bind to. See documentation on Binding resolution for more information about how Unity maps Bindings to Controls. Note: Actions that belong to InputUsers don't appear here. They appear in the Users list instead. Debugging users and PlayerInput When there are InputUser instances (if you use PlayerInput, each PlayerInput instance implicitly creates one), the Input Debugger's Users list displays each instance along with its paired Devices and active Actions. The listed Devices and Actions work the same way as those displayed in the Devices and Actions lists in the debugging window. Debugging layouts The Layouts list in the Input Debugger window displays a breakdown of all registered Control and Device layouts. This is the database of supported hardware and the knowledge of how to represent a given piece of input hardware. It's useful when you want to create a new Device mapping and see how the Input System represents it. Debugging remotely You can connect the Input Debugger to a Player that runs on a remote computer or device. This makes it possible to observe input activity from the Player in the Editor. This connection uses the PlayerConnection mechanism, which is the same one the Unity profiler uses to connect to a Player. Note: At the moment, debugging input in Players is restricted to seeing Devices and events from connected Players. There is no support for seeing other input-related data such as Actions and input users from Players. To see remote Devices from built Players, open the Input Debugger window's Remote Devices drop-down list. This list displays the remote Player instance you can connect to (if there are any). The same list appears in the Profiler and Console windows, and any connections are shared between those windows. If any Player(s) are connected, you can enable Show remote devices in the same drop-down list. If Players are connected, and Show remote devices is enabled, the Devices list in the Input Debugger window splits into a Local section and a Remote section. The Remote section displays any Input Device from any connected Player, and lets you inspect Device state and events in real time, as if it were a local Device. Input visualizers The Input System package comes with a Visualizers sample, which provides various components which let you monitor the state of various Input System elements in real time using on-screen visualizers. To install the sample, navigate to the Input System package in the Package Manager window (see Installation), and next to the Visualizers sample, click Import in project. The sample provides two visualizer components: InputControlVisualizer Visualizes the current state of a single Control in real time. You can have multiple Control visualizers to visualize the state of multiple Controls. Check the GamepadVisualizer, MouseVisualizer, or PenVisualizer Scenes in the sample for examples. InputActionVisualizer Visualizes the current state of a single Action in real time. You can have multiple Action visualizers to visualize the state of multiple Actions. This can also display the current value of the Action and the Control currently driving the Action, and track the state of Interactions over time. Check the SimpleControlsVisualizer Scene in the sample for examples. Device Simulator When Device Simulator window is in use, mouse and pen inputs on the simulated device screen are turned into touchscreen inputs. Device Simulator uses its own touchscreen device, which it creates and destroys together with the Device Simulator window. To prevent conflicts between simulated touchscreen inputs and native mouse and pen inputs, Device Simulator disables all native mouse and pen devices. Unity Remote The Unity Remote is an app available for iOS and Android which allows using a mobile device for input while running in the Unity Editor. You can find details about the app and how to install it in the Unity manual. If you would like to try out the Unity Remote app, you can install the \"Unity Remote\" sample that is provided with the Input System package. Note: Joysticks/gamepads are not yet supported over the Unity Remote. No joystick/gamepad input from the mobile device will come through in the editor. Note: This requires Unity 2021.2.18 or later. When in play mode in the Editor and connected to the Unity Remote app, you will see a number of Devices have been added with the InputDevice.remote flag set to true: Touchscreen Accelerometer If a gyro is present on the mobile device: Gyroscope AttitudeSensor LinearAccelerationSensor GravitySensor These Devices can be used just like local Devices. They will receive input from the connected mobile device which in turn will receive the rendered output of the game running in the editor. The Accelerometer device will automatically be enabled and will not need you to call InputSystem.EnableDevice explicitly. Setting the sampling frequency on the accelerometer from the Unity Remote using Sensor.samplingFrequency has no effect. The remaining sensors listed above will need to be explicitly enabled via InputSystem.EnableDevice just like local sensors. Setting the sampling frequency on these sensors from the Unity Remote using Sensor.samplingFrequency will be relayed to the device but note that setting the frequency on one of them will set it for all of them. Touch coordinates from the device will be translated to the screen coordinates of the Game View inside the Editor. Other tips: To record events flowing through the system, use this code: // You can also provide a device ID to only // trace events for a specific device. var trace = new InputEventTrace(); trace.Enable(); var current = new InputEventPtr(); while (trace.GetNextEvent(ref current)) { Debug.Log(\"Got some event: \" + current); } // Also supports IEnumerable. foreach (var eventPtr in trace) Debug.Log(\"Got some event: \" + eventPtr); // Trace consumes unmanaged resources. Make sure you dispose it correctly to avoid memory leaks. trace.Dispose(); To see events as they're processed, use this code: InputSystem.onEvent += (eventPtr, device) => { // Can handle events yourself, for example, and then stop them // from further processing by marking them as handled. eventPtr.handled = true; };"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Devices.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Devices.html",
    "title": "Devices | Inventory System",
    "summary": "Devices Devices Device descriptions Capabilities Matching Hijacking the matching process Device lifecycle Device creation Device removal Device resets Device syncs Device enabling and disabling Background and focus change behavior Domain reloads in the Editor Native Devices Disconnected Devices Device IDs Device usages Device commands Sending commands to Devices Adding custom device Commands Device state State changes Monitoring state changes Synthesizing state Working with Devices Monitoring Devices Adding and removing Devices Creating custom Devices Step 1: The state struct Step 2: The Device class Step 3: The Update method Step 4: Device registration and creation Step 5: current and all (optional) Step 6: Device Commands (Optional) Physically, Input Devices represent devices attached to the computer, which a user can use to control the app. Logically, Input Devices are the top-level container for Controls. The InputDevice class is itself a specialization of InputControl. See supported Devices to see what kind of Devices the Input System currently supports. To query the set of all currently present Devices, you can use InputSystem.devices. Device descriptions An InputDeviceDescription describes a Device. The Input System uses this primarily during the Device discovery process. When a new Device is reported (by the runtime or by the user), the report contains a Device description. Based on the description, the system then attempts to find a Device layout that matches the description. This process is based on Device matchers. After a Device has been created, you can retrieve the description it was created from through the InputDevice.description property. Every description has a set of standard fields: Field Description interfaceName Identifier for the interface/API that is making the Device available. In many cases, this corresponds to the name of the platform, but there are several more specific interfaces that are commonly used: HID, RawInput, XInput. This field is required. deviceClass A broad categorization of the Device. For example, \"Gamepad\" or \"Keyboard\". product Name of the product as reported by the Device/driver itself. manufacturer Name of the manufacturer as reported by the Device/driver itself. version If available, provides the version of the driver or hardware for the Device. serial If available, provides the serial number for the Device. capabilities A string in JSON format that describes Device/interface-specific capabilities. See the section on capabilities. Capabilities Aside from a number of standardized fields, such as product and manufacturer, a Device description can contain a capabilities string in JSON format. This string describes characteristics which help the Input System to interpret the data from a Device, and map it to Control representations. Not all Device interfaces report Device capabilities. Examples of interface-specific Device capabilities are HID descriptors. WebGL, Android, and Linux use similar mechanisms to report available Controls on connected gamepads. Matching InputDeviceMatcher instances handle matching an InputDeviceDescription to a registered layout. Each matcher loosely functions as a kind of regular expression. Each field in the description can be independently matched with either a plain string or regular expression. Matching is not case-sensitive. For a matcher to apply, all of its individual expressions have to match. To matchers to any layout, call InputSystem.RegisterLayoutMatcher. You can also supply them when you register a layout. // Register a new layout and supply a matcher for it. InputSystem.RegisterLayoutMatcher<MyDevice>( matches: new InputDeviceMatcher() .WithInterface(\"HID\") .WithProduct(\"MyDevice.*\") .WithManufacturer(\"MyBrand\"); // Register an alternate matcher for an already registered layout. InputSystem.RegisterLayoutMatcher<MyDevice>( new InputDeviceMatcher() .WithInterface(\"HID\") If multiple matchers are matching the same InputDeviceDescription, the Input System chooses the matcher that has the larger number of properties to match against. Hijacking the matching process You can overrule the internal matching process from outside to select a different layout for a Device than the system would normally choose. This also makes it possible to quickly build new layouts. To do this, add a custom handler to the InputSystem.onFindControlLayoutForDevice event. If your handler returns a non-null layout string, then the Input System uses this layout. Device lifecycle Device creation Once the system has chosen a layout for a device, it instantiates an InputDevice and populates it with InputControls as the layout dictates. This process is internal and happens automatically. Note: You can't create valid InputDevices and InputControls by manually instantiating them with new. To guide the creation process, you must use layouts. After the Input System assembles the InputDevice, it calls FinishSetup on each control of the device and on the device itself. Use this to finalize the setup of the Controls. After an InputDevice is fully assembled, the Input System adds it to the system. As part of this process, the Input System calls MakeCurrent on the Device, and signals InputDeviceChange.Added on InputSystem.onDeviceChange. The Input System also calls InputDevice.OnAdded. Once added, the InputDevice.added flag is set to true. To add devices manually, you can call one of the InputSystem.AddDevice methods such as InputSystem.AddDevice(layout). // Add a gamepad. This bypasses the matching process and creates a device directly // with the Gamepad layout. InputSystem.AddDevice<Gamepad>(); // Add a device such that the matching process is employed: InputSystem.AddDevice(new InputDeviceDescription { interfaceName = \"XInput\", product = \"Xbox Controller\", }); When a device is added, the Input System automatically issues a sync request on the device. This instructs the device to send an event representing its current state. Whether this request succeeds depends on the whether the given device supports the sync command. Device removal When a Device is disconnected, it is removed from the system. A notification appears for InputDeviceChange.Removed (sent via InputSystem.onDeviceChange) and the Devices are removed from the devices list. The system also calls InputDevice.OnRemoved. The InputDevice.added flag is reset to false in the process. Note that Devices are not destroyed when removed. Device instances remain valid and you can still access them in code. However, trying to read values from the controls of these Devices leads to exceptions. Device resets Resetting a Device resets its Controls to their default state. You can do this manually using InputSystem.ResetDevice: InputSystem.ResetDevice(Gamepad.current); There are two types of resets as determined by the second parameter to InputSystem.ResetDevice: Type Description \"Soft\" Resets This is the default. With this type, only controls that are not marked as dontReset are reset to their default value. This excludes controls such as Pointer.position from resets and thus prevents mouse positions resetting to (0,0). \"Hard\" Resets In this type, all controls are reset to their default value regardless of whether they have dontReset set or not. Resetting Controls this way is visible on Actions. If you reset a Device that is currently driving one or more Action, the Actions are cancelled. This cancellation is different from sending an event with default state. Whereas the latter may inadvertently perform Actions (e.g. a button that was pressed would not appear to have been released), a reset will force clean cancellation. Resets may be triggered automatically by the Input System depending on application focus. Device syncs A Device may be requested to send an event with its current state through RequestSyncCommand. It depends on the platform and type of Device whether this is supported or not. A synchronization request can be explicitly sent using InputSystem.TrySyncDevice. If the device supports sync requests, the method returns true and an InputEvent will have been queued on the device for processing in the next update. Synchronization requests are also automatically sent by the Input System in certain situations. See Background and focus change behavior for more details. Device enabling and disabling When a Device is added, the Input System sends it an initial QueryEnabledStateCommand to find out whether the device is currently enabled or not. The result of this is reflected in the InputDevice.enabled property. When disabled, no events other than removal (DeviceRemoveEvent) and configuration change (DeviceConfigurationEvent) events are processed for a Device, even if they are sent. A Device can be manually disabled and re-enabled via InputSystem.DisableDevice and InputSystem.EnableDevice respectively. Note that sensors start in a disabled state by default, and you need to enable them in order for them to generate events. The Input System may automatically disable and re-enable Devices in certain situations, as detailed in the next section. Background and focus change behavior In general, input is tied to application focus. This means that Devices do not receive input while the application is not in the foreground and thus no Actions will receive input either. When the application comes back into focus, all devices will receive a sync request to have them send their current state (which may have changed while the application was in the background) to the application. Devices that do not support sync requests will see a soft reset that resets all Controls not marked as dontReset to their default state. On platforms such as iOS and Android, that do not support running Unity applications in the background, this is the only supported behavior. If the application is configured to run while in the background (that is, not having focus), input behavior can be selected from several options. This is supported in two scenarios: In Unity's Player Settings you can explicity enable Run In Background for specific players that support it (such as Windows or Mac standalone players). Note that in these players this setting is always enabled automatically in development players. In the editor, application focus is tied to focus on the Game View. If no Game View is focused, the application is considered to be running in the background. However, while in play mode, the editor will always keep running the player loop regardless of focus on the Game View window. This means that in the editor, Run In Background is considered to always be enabled. If the application is configured this way to keep running while in the background, the player loop and thus the Input System, too, will keep running even when the application does not have focus. What happens with respect to input then depends on two factors: On the ability of individual devices to receive input while the application is not running in the foreground. This is only supported by a small subset of devices and platforms. VR devices (TrackedDevice) such as HMDs and VR controllers generally support this. To find out whether a specific device supports this, you can query the InputDevice.canRunInBackground property. This property can also be forced to true or false via a Device's layout. On two settings you can find in the project-wide Input Settings. Specifically, InputSettings.backgroundBehavior and InputSettings.editorInputBehaviorInPlayMode. The table below shows a detailed breakdown of how input behaviors vary based on these two settings and in relation to the Run In Background player setting in Unity. Note: InputDevice.canRunInBackground is overridden by the editor in certain situations (see table below). In general, the value of the property does not have to be the same between the editor and the player and depends on the specific platform and device. The following table shows the full matrix of behaviors according to the Input Settings and whether the game is running in the editor or in the player. Domain reloads in the Editor The Editor reloads the C# application domain whenever it reloads and recompiles scripts, or when the Editor goes into Play mode. This requires the Input System to reinitialize itself after each domain reload. During this process, the Input System attempts to recreate devices that were instantiated before the domain reload. However, the state of each Device doesn't carry across, which means that Devices reset to their default state on domain reloads. Note that layout registrations do not persist across domain reloads. Instead, the Input System relies on all registrations to become available as part of the initialization process (for example, by using [InitializeOnLoad] to run registration as part of the domain startup code in the Editor). This allows you to change registrations and layouts in script, and the change to immediately take effect after a domain reload. Native Devices Devices that the native backend reports are considered native (as opposed to Devices created from script code). To identify these Devices, you can check the InputDevice.native property. The Input System remembers native Devices. For example, if the system has no matching layout when the Device is first reported, but a layout which matches the device is registered later, the system uses this layout to recreate the Device. You can force the Input System to use your own layout when the native backend discovers a specific Device, by describing the Device in the layout, like this: { \"name\" : \"MyGamepad\", \"extend\" : \"Gamepad\", \"device\" : { // All strings in here are regexs and case-insensitive. \"product\" : \"MyController\", \"manufacturer\" : \"MyCompany\" } } Note: You don't have to restart Unity in order for changes in your layout to take effect on native Devices. The Input System applies changes automatically on every domain reload, so you can just keep refining a layout and your Device is recreated with the most up-to-date version every time scripts are recompiled. Disconnected Devices If you want to get notified when Input Devices disconnect, subscribe to the InputSystem.onDeviceChange event, and look for events of type InputDeviceChange.Disconnected. The Input System keeps track of disconnected Devices in InputSystem.disconnectedDevices. If one of these Devices reconnects later, the Input System can detect that the Device was connected before, and reuses its InputDevice instance. This allows the PlayerInputManager to reassign the Device to the same user again. Device IDs Each Device that is created receives a unique numeric ID. You can access this ID through InputDevice.deviceId. All IDs are only used once per Unity session. Device usages Like any InputControl, a Device can have usages associated with it. You can query usages with the usages property, and useInputSystem.SetDeviceUsage() to set them. Usages can be arbitrary strings with arbitrary meanings. One common case where the Input System assigns Devices usages is the handedness of XR controllers, which are tagged with the \"LeftHand\" or \"RightHand\" usages. Device commands While input events deliver data from a Device, commands send data back to the Device. The Input System uses these to retrieve specific information from the Device, to trigger functions on the Device (such as rumble effects), and for a variety of other needs. Sending commands to Devices The Input System sends commands to the Device through InputDevice.ExecuteCommand<TCommand>. To monitor Device commands, use InputSystem.onDeviceCommand. Each Device command implements the IInputDeviceCommandInfo interface, which only requires the typeStatic property to identify the type of the command. The native implementation of the Device should then understand how to handle that command. One common case is the \"HIDO\" command type which is used to send HID output reports to HIDs. Adding custom device Commands To create custom Device commands (for example, to support some functionality for a specific HID), create a struct that contains all the data to be sent to the Device, and add a typeStatic property to make that struct implement the IInputDeviceCommandInfo interface. To send data to a HID, this property should return \"HIDO\". You can then create an instance of this struct and populate all its fields, then use InputDevice.ExecuteCommand<TCommand> to send it to the Device. The data layout of the struct must match the native representation of the data as the device interprets it. Device state Like any other type of Control, each Device has a block of memory allocated to it which stores the state of all the Controls associated with the Device. State changes State changes are usually initiated through state events from the native backend, but you can use InputControl<>.WriteValueIntoState() to manually overwrite the state of any Control. Monitoring state changes You can use InputState.AddChangeMonitor() to register a callback to be called whenever the state of a Control changes. The Input System uses the same mechanism to implement input Actions. Synthesizing state The Input System can synthesize a new state from an existing state. An example of such a synthesized state is the press button Control that Touchscreen inherits from Pointer. Unlike a mouse, which has a physical button, for Touchscreen this is a synthetic Control that doesn't correspond to actual data coming in from the Device backend. Instead, the Input System considers the button to be pressed if any touch is currently ongoing, and released otherwise. To do this, the Input System uses InputState.Change, which allows feeding arbitrary state changes into the system without having to run them through the input event queue. The Input System incorporates state changes directly and synchronously. State change monitors still trigger as expected. Working with Devices Monitoring Devices To be notified when new Devices are added or existing Devices are removed, use InputSystem.onDeviceChange. InputSystem.onDeviceChange += (device, change) => { switch (change) { case InputDeviceChange.Added: // New Device. break; case InputDeviceChange.Disconnected: // Device got unplugged. break; case InputDeviceChange.Connected: // Plugged back in. break; case InputDeviceChange.Removed: // Remove from Input System entirely; by default, Devices stay in the system once discovered. break; default: // See InputDeviceChange reference for other event types. break; } } InputSystem.onDeviceChange delivers notifications for other device-related changes as well. See the InputDeviceChange enum for more information. Adding and removing Devices To manually add and remove Devices through the API, use InputSystem.AddDevice() and InputSystem.RemoveDevice(). This allows you to create your own Devices, which can be useful for testing purposes, or for creating virtual Input Devices which synthesize input from other events. As an example, see the on-screen Controls that the Input System provides. The Input Devices used for on-screen Controls are created entirely in code and have no native representation. Creating custom Devices Note: This example deals only with Devices that have fixed layouts (that is, you know the specific model or models that you want to implement). This is different from an interface such as HID, where Devices can describe themselves through the interface and take on a wide variety of forms. A fixed Device layout can't cover self-describing Devices, so you need to use a layout builder to build Device layouts from information you obtain at runtime. There are two main situations in which you might need to create a custom Device: You have an existing API that generates input, and which you want to reflect into the Input System. You have an HID that the Input System ignores, or that the Input system auto-generates a layout for that doesn't work well enough for your needs. For the second scenario, see Overriding the HID Fallback. The steps below deal with the first scenario, where you want to create a new Input Device entirely from scratch and provide input to it from a third-party API. Step 1: The state struct The first step is to create a C# struct that represents the form in which the system receives and stores input, and also describes the InputControl instances that the Input System must create for the Device in order to retrieve its state. // A \"state struct\" describes the memory format that a Device uses. Each Device can // receive and store memory in its custom format. InputControls then connect to // the individual pieces of memory and read out values from them. // // If it's important for the memory format to match 1:1 at the binary level // to an external representation, it's generally advisable to use // LayoutLind.Explicit. [StructLayout(LayoutKind.Explicit, Size = 32)] public struct MyDeviceState : IInputStateTypeInfo { // You must tag every state with a FourCC code for type // checking. The characters can be anything. Choose something that allows // you to easily recognize memory that belongs to your own Device. public FourCC format => new FourCC('M', 'Y', 'D', 'V'); // InputControlAttributes on fields tell the Input System to create Controls // for the public fields found in the struct. // Assume a 16bit field of buttons. Create one button that is tied to // bit #3 (zero-based). Note that buttons don't need to be stored as bits. // They can also be stored as floats or shorts, for example. The // InputControlAttribute.format property determines which format the // data is stored in. If omitted, the system generally infers it from the value // type of the field. [InputControl(name = \"button\", layout = \"Button\", bit = 3)] public ushort buttons; // Create a floating-point axis. If a name is not supplied, it is taken // from the field. [InputControl(layout = \"Axis\")] public short axis; } The Input System's layout mechanism uses InputControlAttribute annotations to add Controls to the layout of your Device. For details, see the layout system documentation. With the state struct in place, you now have a way to send input data to the Input System and store it there. The next thing you need is an InputDevice that uses your custom state struct and represents your custom Device. Step 2: The Device class Next, you need a class derived from one of the InputDevice base classes. You can either base your Device directly on InputDevice, or you can pick a more specific Device type, like Gamepad. This example assumes that your Device doesn't fit into any of the existing Device classes, so it derives directly from InputDevice. // InputControlLayoutAttribute attribute is only necessary if you want // to override the default behavior that occurs when you register your Device // as a layout. // The most common use of InputControlLayoutAttribute is to direct the system // to a custom \"state struct\" through the `stateType` property. See below for details. [InputControlLayout(displayName = \"My Device\", stateType = typeof(MyDeviceState))] public class MyDevice : InputDevice { // In the state struct, you added two Controls that you now want to // surface on the Device, for convenience. The Controls // get added to the Device either way. When you expose them as properties, // it is easier to get to the Controls in code. public ButtonControl button { get; private set; } public AxisControl axis { get; private set; } // The Input System calls this method after it constructs the Device, // but before it adds the device to the system. Do any last-minute setup // here. protected override void FinishSetup() { base.FinishSetup(); // NOTE: The Input System creates the Controls automatically. // This is why don't do `new` here but rather just look // the Controls up. button = GetChildControl<ButtonControl>(\"button\"); axis = GetChildControl<AxisControl>(\"axis\"); } } Step 3: The Update method You now have a Device in place along with its associated state format. You can call the following method to create a fully set-up Device with your two Controls on it: InputSystem.AddDevice<MyDevice>(); However, this Device doesn't receive input yet, because you haven't added any code that generates input. To do that, you can use InputSystem.QueueStateEvent or InputSystem.QueueDeltaStateEvent from anywhere, including from a thread. The following example uses IInputUpdateCallbackReceiver, which, when implemented by any InputDevice, adds an OnUpdate() method that automatically gets called during InputSystem.onBeforeUpdate and provides input events to the current input update. Note: If you already have a place where input for your device becomes available, you can skip this step and queue input events from there instead of using IInputUpdateCallbackReceiver. public class MyDevice : InputDevice, IInputUpdateCallbackReceiver { //... public void OnUpdate() { // In practice, this would read out data from an external // API. This example uses some empty input. var state = new MyDeviceState(); InputSystem.QueueStateEvent(this, state); } } Step 4: Device registration and creation You now have a functioning device, but you haven't registered it (added it to the system) yet. This means you can't see the device when, for example, you create bindings in the Action editor. You can register your device type with the system from within the code that runs automatically as part of Unity's startup. To do so, modify the definition of MyDevice like so: // Add the InitializeOnLoad attribute to automatically run the static // constructor of the class after each C# domain load. #if UNITY_EDITOR [InitializeOnLoad] #endif public class MyDevice : InputDevice, IInputUpdateCallbackReceiver { //... static MyDevice() { // RegisterLayout() adds a \"Control layout\" to the system. // These can be layouts for individual Controls (like sticks) // or layouts for entire Devices (which are themselves // Controls) like in our case. InputSystem.RegisterLayout<MyDevice>(); } // You still need a way to trigger execution of the static constructor // in the Player. To do this, you can add the RuntimeInitializeOnLoadMethod // to an empty method. [RuntimeInitializeOnLoadMethod(RuntimeInitializeLoadType.BeforeSceneLoad)] private static void InitializeInPlayer() {} } This registers the Device type with the system and makes it available in the Control picker. However, you still need a way to add an instance of the Device when it is connected. In theory, you could call InputSystem.AddDevice<MyDevice>() somewhere, but in a real-world setup you likely have to correlate the Input Devices you create with their identities in the third-party API. It might be tempting to do something like this: public class MyDevice : InputDevice, IInputUpdateCallbackReceiver { //... // This does NOT work correctly. public ThirdPartyAPI.DeviceId externalId { get; set; } } and then set that on the Device after calling AddDevice<MyDevice>. However, this doesn't work as expected in the Editor, because the Input System requires Devices to be created solely from their InputDeviceDescription in combination with the chosen layout (and layout variant). In addition, the system supports a fixed set of mutable per-device properties such as device usages (that is, InputSystem.SetDeviceUsage() and related methods). This allows the system to easily recreate Devices after domain reloads in the Editor, as well as to create replicas of remote Devices when connecting to a Player. To comply with this requirement, you must cast that information provided by the third-party API into an InputDeviceDescription and then use an InputDeviceMatcher to match the description to our custom MyDevice layout. This example assumes that the third-party API has two callbacks, like this: public static ThirdPartyAPI { // This example assumes that the argument is a string that // contains the name of the Device, and that no two Devices // have the same name in the external API. public static Action<string> deviceAdded; public static Action<string> deviceRemoved; } You can hook into those callbacks and create and destroy devices in response. // This example uses a MonoBehaviour with [ExecuteInEditMode] // on it to run the setup code. You can do this many other ways. [ExecuteInEditMode] public class MyDeviceSupport : MonoBehaviour { protected void OnEnable() { ThirdPartyAPI.deviceAdded += OnDeviceAdded; ThirdPartyAPI.deviceRemoved += OnDeviceRemoved; } protected void OnDisable() { ThirdPartyAPI.deviceAdded -= OnDeviceAdded; ThirdPartyAPI.deviceRemoved -= OnDeviceRemoved; } private void OnDeviceAdded(string name) { // Feed a description of the Device into the system. In response, the // system matches it to the layouts it has and creates a Device. InputSystem.AddDevice( new InputDeviceDescription { interfaceName = \"ThirdPartyAPI\", product = name }); } private void OnDeviceRemoved(string name) { var device = InputSystem.devices.FirstOrDefault( x => x.description == new InputDeviceDescription { interfaceName = \"ThirdPartyAPI\", product = name, }); if (device != null) InputSystem.RemoveDevice(device); } // Move the registration of MyDevice from the // static constructor to here, and change the // registration to also supply a matcher. protected void Awake() { // Add a match that catches any Input Device that reports its // interface as \"ThirdPartyAPI\". InputSystem.RegisterLayout<MyDevice>( matches: new InputDeviceMatcher() .WithInterface(\"ThirdPartyAPI\")); } } Step 5: current and all (optional) For convenience, you can quickly access the last used device of a given type, or list all devices of a specific type. To do this, add support for a current and for an all getter to the API of MyDevice. public class MyDevice : InputDevice, IInputCallbackReceiver { //... public static MyDevice current { get; private set; } public static IReadOnlyList<MyDevice> all => s_AllMyDevices; private static List<MyDevice> s_AllMyDevices = new List<MyDevice>(); public override void MakeCurrent() { base.MakeCurrent(); current = this; } protected override void OnAdded() { base.OnAdded(); s_AllMyDevices.Add(this); } protected override void OnRemoved() { base.OnRemoved(); s_AllMyDevices.Remove(this); } } Step 6: Device Commands (Optional) A final, but optional, step is to add support for Device commands. A \"device command\" is that opposite of input. In other words, it consists of data traveling to the input device, which might also return data as part of the operation (much like a function call). You can use this to communicate with the backend of the device in order to query configuration, or to initiate effects such as haptics. At the moment there isn't a proper interface available for this, however there are still some scenarios that can be solved with the current interfaces. E.g. the following shows, when implementing a non-hardware-backed device (simulated device), how to simulate hardware reporting that the device can be run in the background and supports sync commands. This is useful to prevent the device from cancelling Actions when application focus is lost and restored. For more info see Device syncs public class MyDevice : InputDevice, IInputCallbackReceiver { //... protected override unsafe long ExecuteCommand(InputDeviceCommand* commandPtr) { var type = commandPtr->type; if (type == RequestSyncCommand.Type) { // Report that the device supports the sync command and has handled it. // This will prevent device reset during focus changes. result = InputDeviceCommand.GenericSuccess; return true; } if (type == QueryCanRunInBackground.Type) { // Notify that the device supports running in the background. ((QueryCanRunInBackground*)commandPtr)->canRunInBackground = true; result = InputDeviceCommand.GenericSuccess; return true; } result = default; return false; } }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/EditorFeatures.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/EditorFeatures.html",
    "title": "Input System Editor Features | Inventory System",
    "summary": "Input System Editor Features This section describes how the Input System integrates with the Unity Editor, which allows you to read input in edit mode, debug input values, and set up automated input tests. Using Input in the Editor Unlike Unity's old Input Manager, the Input System package allows you to read input from within Editor window code as well. (Read more) The Input Debugger When something isn't working as expected, the quickest way to troubleshoot what's wrong is the Input Debugger in the Unity Editor. The Input Debugger provides access to the activity of the Input System in both the Editor and the connected Players. (Read more) Automated Input Testing The Input System has built-in support for writing automated input tests. You can drive input entirely from code, without any dependencies on platform backends and physical hardware devices. The automated input tests you write consider the generated input to be the same as input generated at runtime by actual platform code. (Read more)"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Events.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Events.html",
    "title": "Input events | Inventory System",
    "summary": "Input events Types of events State events Device events Text events Working with events Listening to events Reading state events Creating events Capturing events Processing events Merging of events The Input System is event-driven. All input is delivered as events, and you can generate custom input by injecting events. You can also observe all source input by listening in on the events flowing through the system. Note: Events are an advanced, mostly internal feature of the Input System. Knowledge of the event system is mostly useful if you want to support custom Devices, or change the behavior of existing Devices. Input events are a low-level mechanism. Usually, you don't need to deal with events if all you want to do is receive input for your app. Events are stored in unmanaged memory buffers and not converted to C# heap objects. The Input System provides wrapper APIs, but unsafe code is required for more involved event manipulations. Note that there are no routing mechanism. The runtime delivers events straight to the Input System, which then incorporates them directly into the Device state. Input events are represented by the InputEvent struct. Each event has a set of common properties: Property Description type FourCC code that indicates what type of event it is. eventId Unique numeric ID of the event. time Timestamp of when the event was generated. This is on the same timeline as Time.realtimeSinceStartup. deviceId ID of the Device that the event targets. sizeInBytes Total size of the event in bytes. You can observe the events received for a specific input device in the input debugger. Types of events State events A state event contains the input state for a Device. The Input System uses these events to feed new input to Devices. There are two types of state events: StateEvent ('STAT') DeltaStateEvent ('DLTA') StateEvent contains a full snapshot of the entire state of a Device in the format specific to that Device. The stateFormat field identifies the type of the data in the event. You can access the raw data using the state pointer and stateSizeInBytes. A DeltaStateEvent is like a StateEvent, but only contains a partial snapshot of the state of a Device. The Input System usually sends this for Devices that require a large state record, to reduce the amount of memory it needs to update if only some of the Controls change their state. To access the raw data, you can use the deltaState pointer and deltaStateSizeInBytes. The Input System should apply the data to the Device's state at the offset defined by stateOffset. Device events Device events indicate a change that is relevant to a Device as a whole. If you're interested in these events, it is usually more convenient to subscribe to the higher-level InputSystem.onDeviceChange event rather then processing InputEvents yourself. There are three types of Device events: DeviceRemoveEvent ('DREM') DeviceConfigurationEvent ('DCFG') DeviceResetEvent ('DRST') DeviceRemovedEvent indicates that a Device has been removed or disconnected. To query the device that has been removed, you can use the common deviceId field. This event doesn't have any additional data. DeviceConfigurationEvent indicates that the configuration of a Device has changed. The meaning of this is Device-specific. This might signal, for example, that the layout used by the keyboard has changed or that, on a console, a gamepad has changed which player ID(s) it is assigned to. You can query the changed device from the common deviceId field. This event doesn't have any additional data. DeviceResetEvent indicates that a device should get reset. This will trigger InputSystem.ResetDevice to be called on the Device. Text events Keyboard devices send these events to handle text input. If you're interested in these events, it's usually more convenient to subscribe to the higher-level callbacks on the Keyboard class rather than processing InputEvents yourself. There are two types of text events: TextEvent ('TEXT') IMECompositionEvent ('IMES') Working with events Listening to events If you want to do any monitoring or processing on incoming events yourself, subscribe to the InputSystem.onEvent callback. InputSystem.onEvent += (eventPtr, device) => { Debug.Log($\"Received event for {device}\"); }; An IObservable interface is provided to more conveniently process events. // Wait for first button press on a gamepad. InputSystem.onEvent .ForDevice<Gamepad>() .Where(e => e.HasButtonPress()) .CallOnce(ctrl => Debug.Log($\"Button {ctrl} pressed\")); To enumerate the controls that have value changes in an event, you can use InputControlExtensions.EnumerateChangedControls. InputSystem.onEvent .Call(eventPtr => { foreach (var control in eventPtr.EnumerateChangedControls()) Debug.Log($\"Control {control} changed value to {control.ReadValueFromEventAsObject(eventPtr)}\"); }; This is significantly more efficient than manually iterating over InputDevice.allControls and reading out the value of each control from the event. Reading state events State events contain raw memory snapshots for Devices. As such, interpreting the data in the event requires knowledge about where and how individual state is stored for a given Device. The easiest way to access state contained in a state event is to rely on the Device that the state is meant for. You can ask any Control to read its value from a given event rather than from its own internally stored state. For example, the following code demonstrates how to read a value for Gamepad.leftStick from a state event targeted at a Gamepad. InputSystem.onEvent += (eventPtr, device) => { // Ignore anything that isn't a state event. if (!eventPtr.IsA<StateEvent>() && !eventPtr.IsA<DeltaStateEvent>()) return; var gamepad = device as Gamepad; if (gamepad == null) { // Event isn't for a gamepad or device ID is no longer valid. return; } var leftStickValue = gamepad.leftStick.ReadValueFromEvent(eventPtr); }; Creating events Anyone can create and queue new input events against any existing Device. Queueing an input event is thread-safe, which means that event generation can happen in background threads. Note: Unity allocates limited memory to events that come from background threads. If background threads produce too many events, queueing an event from a thread blocks the thread until the main thread flushes out the background event queue. Note that queuing an event doesn't immediately consume the event. Event processing happens on the next update (depending on InputSettings.updateMode, it is triggered either manually via InputSystem.Update, or automatically as part of the Player loop). Sending state events For Devices that have a corresponding \"state struct\" describing the state of the device, the easiest way of sending input to the Device is to simply queue instances of those structs: // Mouse. InputSystem.QueueStateEvent(Mouse.current, new MouseState { position = new Vector2(123, 234) }); // Keyboard. InputSystem.QueueStateEvent(Keyboard.current, new KeyboardState(Key.LeftCtrl, Key.A)); Touchscreen is somewhat special in that it expects its input to be in TouchState format. // Start touch. InputSystem.QueueStateEvent(Touchscreen.current, new TouchState { touchId = 1, phase = TouchPhase.Began, position = new Vector2(123, 234) }); // Move touch. InputSystem.QueueStateEvent(Touchscreen.current, new TouchState { touchId = 1, phase = TouchPhase.Moved, position = new Vector2(234, 345) }); // End touch. InputSystem.QueueStateEvent(Touchscreen.current, new TouchState { touchId = 1, phase = TouchPhase.Ended, position = new Vector2(123, 234) }); IMPORTANT: Touch IDs cannot be 0! A valid touch must have a non-zero touch ID. Concurrent touches must each have a unique ID. After a touch has ended, its ID can be reused – although it is recommended to not do so. If the exact format of the state used by a given Device is not known, the easiest way to send input to it is to simply create a StateEvent from the Device itself: // `StateEvent.From` creates a temporary buffer in unmanaged memory that holds // a state event large enough for the given device and contains a memory // copy of the device's current state. InputEventPtr eventPtr; using (StateEvent.From(myDevice, out eventPtr)) { ((AxisControl) myDevice[\"myControl\"]).WriteValueIntoEvent(0.5f, eventPtr); InputSystem.QueueEvent(eventPtr); } Alternatively, you can send events for individual Controls. // Send event to update leftStick on the gamepad. InputSystem.QueueDeltaStateEvent(Gamepad.current.leftStick, new Vector2(0.123f, 0.234f); Note that delta state events only work for Controls that are both byte-aligned and a multiple of 8 bits in size in memory. You can't send a delta state event for a button Control that is stored as a single bit, for example. Capturing Events NOTE: To download a sample project which contains a reusable MonoBehaviour called InputRecorder, which can capture and replay input from arbitrary devices, open the Package Manager, select the Input System Package, and choose the sample project \"Input Recorder\" to download. You can use the InputEventTrace class to record input events for later processing: var trace = new InputEventTrace(); // Can also give device ID to only // trace events for a specific device. trace.Enable(); //... run stuff var current = new InputEventPtr(); while (trace.GetNextEvent(ref current)) { Debug.Log(\"Got some event: \" + current); } // Also supports IEnumerable. foreach (var eventPtr in trace) Debug.Log(\"Got some event: \" + eventPtr); // Trace consumes unmanaged resources. Make sure to dispose. trace.Dispose(); Dispose event traces after use, so that they do not leak memory on the unmanaged (C++) memory heap. You can also write event traces out to files/streams, load them back in, and replay recorded streams. // Set up a trace with such that it automatically grows in size as needed. var trace = new InputEventTrace(growBuffer: true); trace.Enable(); // ... capture some input ... // Write trace to file. trace.WriteTo(\"mytrace.inputtrace.\"); // Load trace from same file. var loadedTrace = InputEventTrace.LoadFrom(\"mytrace.inputtrace\"); You can replay captured traces directly from InputEventTrace instances using the Replay method. // The Replay method returns a ReplayController that can be used to // configure and control playback. var controller = trace.Replay(); // For example, to not replay the events as is but rather create new devices and send // the events to them, call WithAllDevicesMappedToNewInstances. controller.WithAllDevicessMappedToNewInstances(); // Replay all frames one by one. controller.PlayAllFramesOnyByOne(); // Replay events in a way that tries to simulate original event timing. controller.PlayAllEventsAccordingToTimestamps(); Processing events Events are collected on a queue by the Unity runtime. This queue is regularly flushed out and the events on it processed. Events can be added to the queue manually by calling InputSystem.QueueEvent. Each time input is processed, InputSystem.Update is called implicitly by the Unity runtime. The interval at which this happens is determined by the \"Update Mode\" configured in the settings. By default, input is processed in each frame before MonoBehaviour.Update methods are called. If the setting is changed to process input in fixed updates, then this changes to input being processed each time before MonoBehaviour.FixedUpdate methods are called. Normally, when input is processed, all outstanding input events on the queue will be consumed. There are two exceptions to this, however. When using UpdateMode.ProcessEventsInFixedUpdate, the Input System attempts to associate events with the timeslice of the corresponding FixedUpdate . This is based on the timestamps of the events and a \"best effort\" at calculating the corresponding timeslice of the current FixedUpdated . The other exception are BeforeRender updates. These updates are run after fixed or dynamic updates but before rendering and used used exclusively to update devices such as VR headsets that need the most up-to-date tracking data. Other input is not consumed from such updates and these updates are only enabled if such devices are actually present. BeforeRender updates are not considered separate frames as far as input is concerned. Note: Manually calling InputSystem.Update is strongly advised against except within tests employing InputTestFixture or when explicitly setting the system to manual update mode. Methods such as InputAction.WasPerformedThisFrame and InputAction.WasPerformedThisFrame operate implicitly based on the [InputSystem.Update] cadence described above. Meaning, that they refer to the state as per the last fixed/dynamic/manual update happened. You can query the current/last update type and count from InputState. Merging of events Input system uses event mering to reduce amount of events required to be processed. This greatly improves performance when working with high refresh rate devices like 8000 Hz mice, touchscreens and others. For example let's take a stream of 7 mouse events coming in the same update: Mouse Mouse Mouse Mouse Mouse Mouse Mouse Event no1 Event no2 Event no3 Event no4 Event no5 Event no6 Event no7 Time 1 Time 2 Time 3 Time 4 Time 5 Time 6 Time 7 Pos(10,20) Pos(12,21) Pos(13,23) Pos(14,24) Pos(16,25) Pos(17,27) Pos(18,28) Delta(1,1) Delta(2,1) Delta(1,2) Delta(1,1) Delta(2,1) Delta(1,2) Delta(1,1) BtnLeft(0) BtnLeft(0) BtnLeft(0) BtnLeft(1) BtnLeft(1) BtnLeft(1) BtnLeft(1) To reduce workload we can skip events that are not encoding button state changes: Mouse Mouse Mouse Time 3 Time 4 Time 7 Event no3 Event no4 Event no7 Pos(13,23) Pos(14,24) Pos(18,28) Delta(3,3) Delta(1,1) Delta(4,4) BtnLeft(0) BtnLeft(1) BtnLeft(1) In that case we combine no1, no2, no3 together into no3 and accumulate the delta, then we keep no4 because it stores the transition from button unpressed to button pressed, and it's important to keep the exact timestamp of such transition. Later we combine no5, no6, no7 together into no7 because it is the last event in the update. Currently this approach is implemented for: FastMouse, combines events unless buttons or clickCount differ in MouseState. Touchscreen, combines events unless touchId, phaseId or flags differ in TouchState. You can disable merging of events by: InputSystem.settings.disableRedundantEventsMerging = true;"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Gamepad.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Gamepad.html",
    "title": "Gamepad Support | Inventory System",
    "summary": "Gamepad Support Controls Deadzones Polling Rumble Pausing, resuming, and stopping haptics PlayStation controllers Xbox controllers Switch controllers Cursor Control Discover all connected devices A Gamepad is narrowly defined as a Device with two thumbsticks, a D-pad, and four face buttons. Additionally, gamepads usually have two shoulder and two trigger buttons. Most gamepads also have two buttons in the middle. A gamepad can have additional Controls, such as a gyro, which the Device can expose. However, all gamepads are guaranteed to have at least the minimum set of Controls described above. Gamepad support guarantees the correct location and functioning of Controls across platforms and hardware. For example, a PS4 DualShock controller layout should look identical regardless of which platform it is supported on. A gamepad's south face button should always be the lowermost face button. NOTE: Generic HID gamepads will not be surfaced as Gamepad devices but rather be created as generic joysticks. This is because the Input System cannot guarantee correct mapping of buttons and axes on the controller (the information is simply not available at the HID level). Only HID gamepads that are explicitly supported by the Input System (like the PS4 controller) will come out as gamepads. Note that you can set up the same kind of support for specific HID gamepads yourself (see \"Overriding the HID Fallback\"). NOTE: In case you want to use the gamepad for driving mouse input, there is a sample called Gamepad Mouse Cursor you can install from the package manager UI when selecting the Input System package. The sample demonstrates how to set up gamepad input to drive a virtual mouse cursor. Controls Every gamepad has the following Controls: Control Type Description leftStick StickControl Thumbstick on the left side of the gamepad. Deadzoned. Provides a normalized 2D motion vector. X is [-1..1] from left to right, Y is [-1..1] from bottom to top. Has up/down/left/right buttons for use like a D-pad. rightStick StickControl Thumbstick on the right side of the gamepad. Deadzoned. Provides a normalized 2D motion vector. X is [-1..1] from left to right, Y is [-1..1] from bottom to top. Has up/down/left/right buttons for use like a D-pad. dpad DpadControl The D-pad on the gamepad. buttonNorth ButtonControl The upper button of the four action buttons, which are usually located on the right side of the gamepad. Labelled \"Y\" on Xbox controllers and \"Triangle\" on PlayStation controllers. buttonSouth ButtonControl The lower button of the four action buttons, which are usually located on the right side of the gamepad. Labelled \"A\" on Xbox controllers and \"Cross\" on PlayStation controllers. buttonWest ButtonControl The left button of the four action buttons, which are usually located on the right side of the gamepad. Labelled \"X\" on Xbox controllers and \"Square\" on PlayStation controllers. buttonEast ButtonControl The right button of the four action buttons, which are usually located on the right side of the gamepad. Labelled \"B\" on Xbox controllers and \"Circle\" on PlayStation controllers. leftShoulder ButtonControl The left shoulder button. rightShoulder ButtonControl The right shoulder button. leftTrigger ButtonControl The left trigger button. rightTrigger ButtonControl The right trigger button. startButton ButtonControl The start button. selectButton ButtonControl The select button. leftStickButton ButtonControl The button pressed when the user presses down the left stick. rightStickButton ButtonControl The button pressed when the user presses down the right stick. Note: Buttons are also full floating-point axes. For example, the left and right triggers can function as buttons as well as full floating-point axes. You can also access gamepad buttons using the indexer property on Gamepad and the GamepadButton enumeration: Gamepad.current[GamepadButton.LeftShoulder]; Gamepads have both both Xbox-style and PS4-style aliases on buttons. For example, the following four accessors all retrieve the same \"north\" face button: Gamepad.current[GamepadButton.Y] Gamepad.current[\"Y\"] Gamepad.current[GamepadButton.Triangle] Gamepad.current[\"Triangle\"] Deadzones Deadzones prevent accidental input due to slight variations in where gamepad sticks come to rest at their centre point. They allow a certain small inner area where the input is considered to be zero even if it is slightly off from the zero position. To add a deadzone to gamepad stick, put a stick deadzone Processor on the sticks, like this: { \"name\" : \"MyGamepad\", \"extend\" : \"Gamepad\", \"controls\" : [ { \"name\" : \"leftStick\", \"processors\" : \"stickDeadzone(min=0.125,max=0.925)\" }, { \"name\" : \"rightStick\", \"processors\" : \"stickDeadzone(min=0.125,max=0.925)\" } ] } You can do the same in your C# state structs. public struct MyDeviceState { [InputControl(processors = \"stickDeadzone(min=0.125,max=0.925)\"] public StickControl leftStick; [InputControl(processors = \"stickDeadzone(min=0.125,max=0.925)\"] public StickControl rightStick; } The gamepad layout already adds stick deadzone processors which take their min and max values from InputSettings.defaultDeadzoneMin and InputSettings.defaultDeadzoneMax. Polling On Windows (XInput controllers only), Universal Windows Platform (UWP), and Switch, Unity polls gamepads explicitly rather than deliver updates as events. You can control polling frequency manually. The default polling frequency is 60 Hz. Use InputSystem.pollingFrequency to get or set the frequency. // Poll gamepads at 120 Hz. InputSystem.pollingFrequency = 120; Increased frequency should lead to an increased number of events on the respective Devices. The timestamps provided on the events should roughly follow the spacing dictated by the polling frequency. Note, however, that the asynchronous background polling depends on OS thread scheduling and can vary. Rumble The Gamepad class implements the IDualMotorRumble interface that allows you to control the left and right motor speeds. In most common gamepads, the left motor emits a low-frequency rumble, and the right motor emits a high-frequency rumble. // Rumble the low-frequency (left) motor at 1/4 speed and the high-frequency // (right) motor at 3/4 speed. Gamepad.current.SetMotorSpeeds(0.25f, 0.75f); Note: Only the following combinations of Devices/OSes currently support rumble: PS4, Xbox, and Switch controllers, when connected to their respective consoles. Only supported if you install console-specific input packages in your Project. PS4 controllers, when connected to Mac or Windows/UWP computers. Xbox controllers on Windows. Pausing, resuming, and stopping haptics IDualMotorRumble is based on IHaptics, which is the base interface for any haptics support on any Device. You can pause, resume, and reset haptic feedback using the PauseHaptics, ResumeHaptics, and ResetHaptics methods respectively. In certain situations, you might want to globally pause or stop haptics for all Devices. For example, if the player enters an in-game menu, you can pause haptics while the player is in the menu, and then resume haptics once the player resumes the game. You can use the corresponding methods on InputSystem to achieve this result. These methods work the same way as Device-specific methods, but affect all Devices: // Pause haptics globally. InputSystem.PauseHaptics(); // Resume haptics globally. InputSystem.ResumeHaptics(); // Stop haptics globally. InputSystem.ResetHaptics(); The difference between PauseHaptics and ResetHaptics is that the latter resets haptics playback state on each Device to its initial state, whereas PauseHaptics preserves playback state in memory and only stops playback on the hardware. PlayStation controllers PlayStation controllers are well supported on different Devices. The Input System implements these as different derived types of the DualShockGamepad base class, which derives from Gamepad): DualShock3GamepadHID: A DualShock 3 controller connected to a desktop computer using the HID interface. Currently only supported on macOS. Doesn't support rumble. DualShock4GamepadHID: A DualShock 4 controller connected to a desktop computer using the HID interface. Supported on macOS, Windows, UWP, and Linux. DualSenseGamepadHID: A DualSense controller connected to a desktop computer using the HID interface. Supported on macOS, Windows. DualShock4GampadiOS: A DualShock 4 controller connected to an iOS Device via Bluetooth. Requires iOS 13 or higher. SetLightBarColor(Color): Used to set the color of the light bar on the controller. Note that, due to limitations in the USB driver and/or the hardware, only one IOCTL (input/output control) command can be serviced at a time. SetLightBarColor(Color) and SetMotorSpeeds(Single, Single) functionality on Dualshock 4 is implemented using IOCTL commands, and so if either method is called in quick succession, it is likely that only the first command will successfully complete. The other commands will be dropped. If there is a need to set both lightbar color and rumble motor speeds at the same time, use the SetMotorSpeedsAndLightBarColor(Single, Single, Color) method. Note: Unity supports PlayStation controllers on WebGL in some browser and OS configurations, but treats them as basic Gamepad or Joystick Devices, and doesn't support rumble or any other DualShock-specific functionality. Unity doesn't support connecting a PlayStation controller to a desktop machine using the DualShock 4 USB Wireless Adaptor. Use USB or Bluetooth to connect it. Xbox controllers Xbox controllers are well supported on different Devices. The Input System implements these using the XInputController class, which derives from Gamepad. On Windows and UWP, Unity uses the XInput API to connect to any type of supported XInput controller, including all Xbox One or Xbox 360-compatible controllers. These controllers are represented as an XInputController instance. You can query the XInputController.subType property to get information about the type of controller (for example, a wheel or a gamepad). On other platforms Unity, uses derived classes to represent Xbox controllers: XboxGamepadMacOS: Any Xbox or compatible gamepad connected to a Mac via USB using the Xbox Controller Driver for macOS. XboxOneGampadMacOSWireless: An Xbox One controller connected to a Mac via Bluetooth. Only the latest generation of Xbox One controllers supports Bluetooth. These controllers don't require any additional drivers in this scenario. XboxOneGampadiOS: An Xbox One controller connected to an iOS Device via Bluetooth. Requires iOS 13 or higher. Note: XInput controllers on Mac currently require the installation of the Xbox Controller Driver for macOS. This driver only supports USB connections, and doesn't support wireless dongles. However, the latest generation of Xbox One controllers natively support Bluetooth. Macs natively support these controllers as HIDs without any additional drivers when connected via Bluetooth. Unity supports Xbox controllers on WebGL in some browser and OS configurations, but treats them as basic Gamepad or Joystick Devices, and doesn't support rumble or any other Xbox-specific functionality. Switch controllers The Input System support Switch Pro controllers on desktop computers via the SwitchProControllerHID class, which implements basic gamepad functionality. Note: This support does not currently work for Switch Pro controllers connected via wired USB. Instead, the Switch Pro controller must be connected via Bluetooth. This is due to the controller using a prioprietary communication protocol on top of HID which does not allow treating the controller like any other HID. Note: Switch Joy-Cons are not currently supported on desktop. Cursor Control To give gamepads and joysticks control over a hardware or software cursor, you can use the VirtualMouseInput component. See VirtualMouseInput component in the UI section of the manual. Discover all connected devices There are various ways to discover the currently connected devices, as shown in the code samples below. To query a list of all connected devices (does not allocate; read-only access): InputSystem.devices To get notified when a device is added or removed: InputSystem.onDeviceChange += (device, change) => { if (change == InputDeviceChange.Added || change == InputDeviceChange.Removed) { Debug.Log($\"Device '{device}' was {change}\"); } } To find all gamepads and joysticks: var devices = InputSystem.devices; for (var i = 0; i < devices.Count; ++i) { var device = devices[i]; if (device is Joystick || device is Gamepad) { Debug.Log(\"Found \" + device); } }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/HID.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/HID.html",
    "title": "HID Support | Inventory System",
    "summary": "HID Support Human Interface Device (HID) is a specification to describe peripheral user input devices connected to computers via USB or Bluetooth. HID is commonly used to implement devices such as gamepads, joysticks, or racing wheels. The Input System directly supports HID (connected via both USB and Bluetooth) on Windows, MacOS, and the Universal Windows Platform (UWP). The system might support HID on other platforms, but not deliver input through HID-specific APIs. For example, on Linux, the system supports gamepad and joystick HIDs through SDL, but doesn't support other HIDs. Every HID comes with a device descriptor. To browse through the descriptor of an HID from the Input Debugger, click the HID Descriptor button in the device debugger window. To specify the type of the device, the HID descriptor reports entry numbers in the HID usage tables, and a list of all controls on the device, along with their data ranges and usages. The Input System handles HIDs in one of two ways: The system has a known layout for the specific HID. If the system does not have a known layout, it auto-generates one for the HID. Auto-generated layouts By default, the Input System creates layouts and Device representations for any HID which reports its usage as GenericDesktop/Joystick, GenericDesktop/Gamepad, or GenericDesktop/MultiAxisController (see the HID usage table specifications for more information). To change the list of supported usages, set HIDSupport.supportedHIDUsages. When the Input System automatically creates a layout for an HID, it always reports these Devices as Joysticks, represented by the Joystick device class. The first elements with a reported HID usage of GenericDesktop/X and GenericDesktop/Y together form the joystick's stick Control. The system then adds Controls for all further HID axis or button elements, using the Control names reported by the HID specification. The Input System assigns the first control with an HID usage of Button/Button 1 to the joystick's trigger Control. The auto-generated layouts represent a \"best effort\" on the part of the Input System. The way Human Interface Devices describe themselves in accordance with the HID standard is too ambiguous in practice, so generated layouts might lead to Controls that don't work as expected. For example, while the layout builder can identify hat switches and D-pads, it can often only make guesses as to which direction represents which. The same goes for individual buttons, which generally aren't assigned any meaning in HID. The best way to resolve the situation of HIDs not working as expected is to add a custom layout, which bypasses auto-generation altogether. See Creating a custom device layout for details. HID output HIDs can support output (for example, to toggle lights or force feedback motors on a gamepad). Unity controls output by sending HID Output Report commands to a Device. Output reports use Device-specific data formats. To use HID Output Reports, call InputDevice.ExecuteCommand to send a command struct with the typeStatic property set as \"HIDO\" to a Device. The command struct contains the Device-specific data sent out to the HID. Creating a custom device layout Often, when using the layouts auto-generated for HIDs, the result isn't ideal. Controls don't receive proper names specific to the Device, some Controls might not work as expected, and some Controls that use vendor-specific formats might not appear altogether. The best way to deal with this is to override the HID fallback and set up a custom Device layout specifically for your Device. This overrides the default auto-generation and gives you full control over how the Device is exposed. Below are three example workflows showing different ways to achieve this. Example 1 - Use an existing C# InputDevice Example 2 - Create your own InputDevice class Example 3 - A more complex example using the PS4 DualShock Controller Custom Device Workflow Example 1 - Use an existing C# InputDevice If you want to use one of the existing C# InputDevice classes in code to interface with your Device, you can build on an existing layout using JSON: { \"name\" : \"MyDevice\", \"extend\" : \"Gamepad\", // Or some other thing \"controls\" : [ { \"name\" : \"firstButton\", \"layout\" : \"Button\", \"offset\" : 0, \"bit\": 0, \"format\" : \"BIT\", }, { \"name\" : \"secondButton\", \"layout\" : \"Button\", \"offset\" : 0, \"bit\": 1, \"format\" : \"BIT\", }, { \"name\" : \"axis\", \"layout\" : \"Axis\", \"offset\" : 4, \"format\" : \"FLT\", \"parameters\" : \"clamp=true,clampMin=0,clampMax=1\" } ] } You then register your layout with the system and then instantiate it: InputSystem.RegisterControlLayout(myDeviceJson); var device = InputSystem.AddDevice(\"MyDevice\"); Custom Device Workflow Example 2 - Create your own InputDevice class Alternatively, you can create your own InputDevice class and state layouts in C#. public struct MyDeviceState : IInputStateTypeInfo { // FourCC type codes are used to identify the memory layouts of state blocks. public FourCC format => new FourCC('M', 'D', 'E', 'V'); [InputControl(name = \"firstButton\", layout = \"Button\", bit = 0)] [InputControl(name = \"secondButton\", layout = \"Button\", bit = 1)] public int buttons; [InputControl(layout = \"Analog\", parameters=\"clamp=true,clampMin=0,clampMax=1\")] public float axis; } [InputState(typeof(MyDeviceState)] public class MyDevice : InputDevice { public ButtonControl firstButton { get; private set; } public ButtonControl secondButton { get; private set; } public AxisControl axis { get; private set; } protected override void FinishSetup(InputControlSetup setup) { firstButton = setup.GetControl<ButtonControl>(this, \"firstButton\"); secondButton = setup.GetControl<ButtonControl>(this, \"secondButton\"); axis = setup.GetControl<AxisControl>(this, \"axis\"); base.FinishSetup(setup); } } To create an instance of your Device, register it as a layout and then instantiate it: InputSystem.RegisterControlLayout(\"MyDevice\", typeof(MyDevice)); InputSystem.AddDevice(\"MyDevice\"); Custom Device Workflow Example 3 - PS4 DualShock Controller This example workflow uses the same technique as the previous example, but provides more detail by using the PS4 DualShock controller as a more complex device to set up. The following example assumes that the Input System doesn't already have a custom layout for the PS4 DualShock controller, and that you want to add such a layout. In this example, you want to expose the controller as a Gamepad and you roughly know the HID data format used by the Device. Tip: If you don't know the format of a given HID you want to support, you can open the Input Debugger with the Device plugged in and pop up both the debugger view for the Device and the window showing the HID descriptor. Then, you can go through the Controls one by one, see what happens in the debug view, and correlate that to the Controls in the HID descriptor. You can also double-click individual events and compare the raw data coming in from the Device. If you select two events in the event trace, you can then right-click them and choose Compare to open a window that shows only the differences between the two events. Step 1: The state struct The first step is to describe in detail what format that input data for the Device comes in, as well as the InputControl instances that should read out individual pieces of information from that data. The HID input reports from the PS4 controller look approximately like this: struct PS4InputReport { byte reportId; // #0 byte leftStickX; // #1 byte leftStickY; // #2 byte rightStickX; // #3 byte rightStickY; // #4 byte dpad : 4; // #5 bit #0 (0=up, 2=right, 4=down, 6=left) byte squareButton : 1; // #5 bit #4 byte crossButton : 1; // #5 bit #5 byte circleButton : 1; // #5 bit #6 byte triangleButton : 1; // #5 bit #7 byte leftShoulder : 1; // #6 bit #0 byte rightShoulder : 1; // #6 bit #1 byte leftTriggerButton : 2;// #6 bit #2 byte rightTriggerButton : 2;// #6 bit #3 byte shareButton : 1; // #6 bit #4 byte optionsButton : 1; // #6 bit #5 byte leftStickPress : 1; // #6 bit #6 byte rightStickPress : 1; // #6 bit #7 byte psButton : 1; // #7 bit #0 byte touchpadPress : 1; // #7 bit #1 byte padding : 6; byte leftTrigger; // #8 byte rightTrigger; // #9 } You can translate this into a C# struct: // We receive data as raw HID input reports. This struct // describes the raw binary format of such a report. [StructLayout(LayoutKind.Explicit, Size = 32)] struct DualShock4HIDInputReport : IInputStateTypeInfo { // Because all HID input reports are tagged with the 'HID ' FourCC, // this is the format we need to use for this state struct. public FourCC format => new FourCC('H', 'I', 'D'); // HID input reports can start with an 8-bit report ID. It depends on the device // whether this is present or not. On the PS4 DualShock controller, it is // present. We don't really need to add the field, but let's do so for the sake of // completeness. This can also help with debugging. [FieldOffset(0)] public byte reportId; // The InputControl annotations here probably look a little scary, but what we do // here is relatively straightforward. The fields we add we annotate with // [FieldOffset] to force them to the right location, and then we add InputControl // to attach controls to the fields. Each InputControl attribute can only do one of // two things: either it adds a new control or it modifies an existing control. // Given that our layout is based on Gamepad, almost all the controls here are // inherited from Gamepad, and we just modify settings on them. [InputControl(name = \"leftStick\", layout = \"Stick\", format = \"VC2B\")] [InputControl(name = \"leftStick/x\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5\")] [InputControl(name = \"leftStick/left\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0,clampMax=0.5,invert\")] [InputControl(name = \"leftStick/right\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0.5,clampMax=1\")] [InputControl(name = \"leftStick/y\", offset = 1, format = \"BYTE\", parameters = \"invert,normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5\")] [InputControl(name = \"leftStick/up\", offset = 1, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0,clampMax=0.5,invert\")] [InputControl(name = \"leftStick/down\", offset = 1, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0.5,clampMax=1,invert=false\")] [FieldOffset(1)] public byte leftStickX; [FieldOffset(2)] public byte leftStickY; [InputControl(name = \"rightStick\", layout = \"Stick\", format = \"VC2B\")] [InputControl(name = \"rightStick/x\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5\")] [InputControl(name = \"rightStick/left\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0,clampMax=0.5,invert\")] [InputControl(name = \"rightStick/right\", offset = 0, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0.5,clampMax=1\")] [InputControl(name = \"rightStick/y\", offset = 1, format = \"BYTE\", parameters = \"invert,normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5\")] [InputControl(name = \"rightStick/up\", offset = 1, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0,clampMax=0.5,invert\")] [InputControl(name = \"rightStick/down\", offset = 1, format = \"BYTE\", parameters = \"normalize,normalizeMin=0,normalizeMax=1,normalizeZero=0.5,clamp,clampMin=0.5,clampMax=1,invert=false\")] [FieldOffset(3)] public byte rightStickX; [FieldOffset(4)] public byte rightStickY; [InputControl(name = \"dpad\", format = \"BIT\", layout = \"Dpad\", sizeInBits = 4, defaultState = 8)] [InputControl(name = \"dpad/up\", format = \"BIT\", layout = \"DiscreteButton\", parameters = \"minValue=7,maxValue=1,nullValue=8,wrapAtValue=7\", bit = 0, sizeInBits = 4)] [InputControl(name = \"dpad/right\", format = \"BIT\", layout = \"DiscreteButton\", parameters = \"minValue=1,maxValue=3\", bit = 0, sizeInBits = 4)] [InputControl(name = \"dpad/down\", format = \"BIT\", layout = \"DiscreteButton\", parameters = \"minValue=3,maxValue=5\", bit = 0, sizeInBits = 4)] [InputControl(name = \"dpad/left\", format = \"BIT\", layout = \"DiscreteButton\", parameters = \"minValue=5, maxValue=7\", bit = 0, sizeInBits = 4)] [InputControl(name = \"buttonWest\", displayName = \"Square\", bit = 4)] [InputControl(name = \"buttonSouth\", displayName = \"Cross\", bit = 5)] [InputControl(name = \"buttonEast\", displayName = \"Circle\", bit = 6)] [InputControl(name = \"buttonNorth\", displayName = \"Triangle\", bit = 7)] [FieldOffset(5)] public byte buttons1; [InputControl(name = \"leftShoulder\", bit = 0)] [InputControl(name = \"rightShoulder\", bit = 1)] [InputControl(name = \"leftTriggerButton\", layout = \"Button\", bit = 2)] [InputControl(name = \"rightTriggerButton\", layout = \"Button\", bit = 3)] [InputControl(name = \"select\", displayName = \"Share\", bit = 4)] [InputControl(name = \"start\", displayName = \"Options\", bit = 5)] [InputControl(name = \"leftStickPress\", bit = 6)] [InputControl(name = \"rightStickPress\", bit = 7)] [FieldOffset(6)] public byte buttons2; [InputControl(name = \"systemButton\", layout = \"Button\", displayName = \"System\", bit = 0)] [InputControl(name = \"touchpadButton\", layout = \"Button\", displayName = \"Touchpad Press\", bit = 1)] [FieldOffset(7)] public byte buttons3; [InputControl(name = \"leftTrigger\", format = \"BYTE\")] [FieldOffset(8)] public byte leftTrigger; [InputControl(name = \"rightTrigger\", format = \"BYTE\")] [FieldOffset(9)] public byte rightTrigger; [FieldOffset(30)] public byte batteryLevel; } Step 2: The InputDevice Next, you need an InputDevice to represent your device. Because you're dealing with a gamepad, you must create a new subclass of Gamepad. For simplicity, this example ignores the fact that there is a DualShockGamepad class that the actual DualShockGamepadHID is based on. // Using InputControlLayoutAttribute, we tell the system about the state // struct we created, which includes where to find all the InputControl // attributes that we placed on there. This is how the Input System knows // what controls to create and how to configure them. [InputControlLayout(stateType = typeof(DualShock4HIDInputReport)] public DualShock4GamepadHID : Gamepad { } Step 3: Registering the Device The last step is to register your new type of Device and set up the Input System so that when a PS4 controller is connected, the Input System generates your custom Device instead of using the default HID fallback. This only requires a call to InputSystem.RegisterLayout<T>, giving it an InputDeviceMatcher that matches the description for a PS4 DualShock HID. In theory, you can place this call anywhere, but the best point for registering layouts is generally during startup. Doing so ensures that your custom layout is visible to the Unity Editor and therefore exposed, for example, in the Input Control picker. You can insert your registration into the startup sequence by modifying the code for your DualShock4GamepadHID Device as follows: [InputControlLayout(stateType = typeof(DualShock4HIDInputReport)] #if UNITY_EDITOR [InitializeOnLoad] // Make sure static constructor is called during startup. #endif public DualShock4GamepadHID : Gamepad { static DualShock4GamepadHID() { // This is one way to match the Device. InputSystem.RegisterLayout<DualShock4GamepadHID>( new InputDeviceMatcher() .WithInterface(\"HID\") .WithManufacturer(\"Sony.+Entertainment\") .WithProduct(\"Wireless Controller\")); // Alternatively, you can also match by PID and VID, which is generally // more reliable for HIDs. InputSystem.RegisterLayout<DualShock4GamepadHID>( matches: new InputDeviceMatcher() .WithInterface(\"HID\") .WithCapability(\"vendorId\", 0x54C) // Sony Entertainment. .WithCapability(\"productId\", 0x9CC)); // Wireless controller. } // In the Player, to trigger the calling of the static constructor, // create an empty method annotated with RuntimeInitializeOnLoadMethod. [RuntimeInitializeOnLoadMethod(RuntimeInitializeLoadType.BeforeSceneLoad)] static void Init() {} } Your custom layout now picks up any Device that matches the manufacturer and product name strings, or the vendor and product IDs in its HID descriptor. The Input System now represents a DualShock4GamepadHID Device instance. For more information, you can also read the Device matching documentation."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/HowDoI.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/HowDoI.html",
    "title": "How do I…? | Inventory System",
    "summary": "How do I…? A collection of frequently asked questions, and where to find their answers in the documentation. Note: If you're new to the Input System and have landed on this page looking for documentation, it's best to read the QuickStart Guide, and the Concepts and Workflows pages, so that you can make sure you're choosing the best workflow for your project's input requirements. This is because there are a number of different ways to read input using the Input System, and many of the answers on this page give you the quickest but least flexible solution, and may not be suitable for a project with more complex requirements. How do I...? check if a specific key or button was pressed this frame? check if any key or button was pressed find all connected gamepads? find the gamepad that the player is currently using? know when a new device was plugged in? create my own custom devices? create a simple \"Fire\" type action? Use the same techniques shown for the \"Jump\" action in the Workflows section require a button to be held down for some duration before triggering an action? use a \"positive\" and a \"negative\" button to drive an axis? create a UI to rebind input in my game? set up an Action to specifically target the left-hand XR controller? make my left-hand XR controller my right-hand one? get all current touches from the touchscreen? deal with my gamepad data arriving in a format different from GamepadState? force the Input System to use my own layout when the native backend discovers a specific Device? add deadzoning to my gamepad sticks? give my head tracking an extra update before rendering? record events flowing through the system? see events as they're processed? see what Devices I have and what state they're in?"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Installation.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Installation.html",
    "title": "Installation guide | Inventory System",
    "summary": "Installation guide Installation guide Installing the package Enabling the new input backends Installing samples This guide describes how to install and activate the Input System package for your Unity Project. Note: The new Input System requires Unity 2019.4+ and the .NET 4 runtime. It doesn't work in projects using the old .NET 3.5 runtime. Installing the package To install the new Input System, open Unity's package manager (menu: Window > Package Manager). Select the Input System package from the list, then click Install. Enabling the new input backends By default, Unity's classic Input Manager (UnityEngine.Input) is active, and support for the new Input System is inactive. This allows existing Unity Projects to keep working as they are. When you install the Input System package, Unity will ask whether you want to enable the new backends. Click Yes to enable the new backends and disable the old backends. The Editor restarts during this process. You can find the corresponding setting in Edit > Project Settings > Player > Other Settings > Active Input Handling. If you change this setting you must restart the Editor for it to take effect. Note: You can enable both the old and the new system at the same time. To do so, set Active Input Handling to Both. When the new input backends are enabled, the ENABLE_INPUT_SYSTEM=1 C# #define is added to builds. Similarly, when the old input backends are enabled, the ENABLE_LEGACY_INPUT_MANAGER=1 C# #define is added. Because both can be enabled at the same time, it is possible for both defines to be 1 at the same time. Installing samples The Input System package comes with a number of samples. You can install these directly from the Package Manager window in Unity (Window > Package Manager). To see the list of samples, select the Input System package in the Package Manager window and click the Samples tab. Then click Import next to any sample name to import it into the current Project. For a more comprehensive demo project for the Input System, see the InputSystem_Warriors GitHub repository."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Interactions.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Interactions.html",
    "title": "Interactions | Inventory System",
    "summary": "Interactions Interactions Operation Multiple Controls on an Action Multiple Interactions on a Binding Timeouts Using Interactions Interactions applied to Bindings Interactions applied to Actions Predefined Interactions Default Interaction Press Hold Tap SlowTap MultiTap Writing custom Interactions An Interaction represents a specific input pattern. For example, a hold is an Interaction that requires a Control to be held for at least a minimum amount of time. Interactions drive responses on Actions. You can place them on individual Bindings or an Action as a whole, in which case they apply to every Binding on the Action. At runtime, when a particular interaction completes, this triggers the Action. Operation An Interaction has a set of distinct phases it can go through in response to receiving input. Phase Description Waiting The Interaction is waiting for input. Started The Interaction has been started (that is, it received some of its expected input), but is not complete yet. Performed The Interaction is complete. Canceled The Interaction was interrupted and aborted. For example, the user pressed and then released a button before the minimum time required for a hold Interaction to complete. Not every Interaction triggers every phase, and the pattern in which specific Interactions trigger phases depends on the Interaction type. While Performed is typically the phase that triggers the actual response to an Interaction, Started and Canceled can be useful for providing UI feedback while the Interaction is in progress. For example, when a hold is Started, the app can display a progress bar that fills up until the hold time has been reached. If, however, the hold is Canceled before it completes, the app can reset the progress bar to the beginning. The following example demonstrates this kind of setup with a fire Action that the user can tap to fire immediately, or hold to charge: var fireAction = new InputAction(\"fire\"); fireAction.AddBinding(\"<Gamepad>/buttonSouth\") // Tap fires, slow tap charges. Both act on release. .WithInteractions(\"tap,slowTap\"); fireAction.started += context => { if (context.interaction is SlowTapInteraction) ShowChargingUI(); }; fireAction.performed += context => { if (context.interaction is SlowTapInteraction) ChargedFire(); else Fire(); }; fireAction.canceled += _ => HideChargingUI(); fireAction.Enable(); Multiple Controls on an Action If you have multiple Controls bound to a Binding or an Action which has an Interaction, then the Input System first applies the Control conflict resolution logic to get a single value for the Action, which it then feeds to the Interaction logic. Any of the bound Controls can perform the Interaction. Multiple Interactions on a Binding If multiple Interactions are present on a single Binding or Action, then the Input System checks the Interactions in the order they are present on the Binding. The code example above illustrates this example. The Binding on the fireAction Action has two Interactions: WithInteractions(\"tap;slowTap\"). The tap Interaction gets a first chance at interpreting the input from the Action. If the button is pressed, the Action calls the Started callback on the tap Interaction. If the user keeps holding the button, the tap Interaction times out, and the Action calls the Canceled callback for the tap Interaction and starts processing the slow tap Interaction (which now receives a Started callback). At any one time, only one Interaction can be \"driving\" the action (that is, it gets to determine the action's current phase). If an Interaction higher up in the stack cancels, Interactions lower down in the stack can take over. Note that the order of interactions can affect which interaction is passed to your callback function. For example, an action with Tap, MultiTap and Hold interactions will have different behaviour when the interactions are in a different order, such as Hold, MultiTap and Tap. If you get unexpected behaviour, you may need to experiment with a different ordering. Timeouts Interactions might need to wait a certain time for a specific input to occur or to not occur. An example of this is the Hold interaction which, after a button is pressed, has to wait for a set duration until the \"hold\" is complete. To do this, an interaction installs a timeout using SetTimeout. It can be useful to know how much of a timeout is left for an interaction to complete. For example, you might want to display a bar in the UI that is charging up while the interaction is waiting to complete. To query the percentage to which a timeout has completed, use GetTimeoutCompletionPercentage. // Returns a value between 0 (inclusive) and 1 (inclusive). var warpActionCompletion = playerInput.actions[\"warp\"].GetTimeoutCompletionPercentage(); Note that each Interaction can have its own separate timeout (but only a single one at any one time). If multiple interactions are in effect, then GetTimeoutCompletionPercentage will only use the timeout of the one interaction that is currently driving the action. Some Interactions might involve multiple timeouts in succession. In this case, knowing only the completion of the currently running timeout (if any) is often not useful. An example is MultiTapInteraction, which involves a timeout on each individual tap, as well as a timeout in-between taps. The Interaction is complete only after a full tap sequence has been performed. An Interaction can use SetTotalTimeoutCompletionTime to inform the Input System of the total time it will run timeouts for. Using Interactions You can install Interactions on Bindings or Actions. Interactions applied to Bindings When you create Bindings for your Actions, you can choose to add Interactions to the Bindings. If you're using project-wide actions, or Input Action Assets, you can add any Interaction to your Bindings in the Input Action editor. Once you created some Bindings, select the Binding you want to add Interactions to, so that the right pane of the window shows the properties for that Binding. Next, click on the plus icon on the Interactions foldout to open a list of all available Interactions types. Choose an Interaction type to add an Interaction instance of that type. The Interaction now appears in the Interactions foldout. If the Interaction has any parameters, you can now edit them here as well: To remove an Interaction, click the minus button next to it. To change the order of Interactions, click the up and down arrows. If you create your Bindings in code, you can add Interactions like this: var Action = new InputAction(); action.AddBinding(\"<Gamepad>/leftStick\") .WithInteractions(\"tap(duration=0.8)\"); Interactions applied to Actions Applying Interactions directly to an Action is equivalent to applying them to all Bindings for the Action. It is thus more or less a shortcut that avoids manually adding the same Interaction(s) to each of the Bindings. If Interactions are applied both to an Action and to its Bindings, then the effect is the same as if the Action's Interactions are appended to the list of Interactions on each of the Bindings. This means that the Binding's Interactions are applied first, and then the Action's Interactions are applied after. You can add and edit Interactions on Actions in the Input Action Assets editor window the same way as you would do for Bindings: select an Action to Edit, then add the Interactions in the right window pane. If you create your Actions in code, you can add Interactions like this: var Action = new InputAction(Interactions: \"tap(duration=0.8)\"); Predefined Interactions The Input System package comes with a set of basic Interactions you can use. If an Action has no Interactions set, the system uses its default Interaction. Note: The built-in Interactions operate on Control actuation and don't use Control values directly. The Input System evaluates the pressPoint parameters against the magnitude of the Control actuation. This means you can use these Interactions on any Control which has a magnitude, such as sticks, and not just on buttons. The following diagram shows the behavior of the built-in Interactions for a simple button press. Default Interaction If you haven't specifically added an Interaction to a Binding or its Action, the default Interaction applies to the Binding. Value type Actions have the following behavior: As soon as a bound Control becomes actuated, the Action goes from Waiting to Started, and then immediately to Performed and back to Started. One callback occurs on InputAction.started, followed by one callback on InputAction.performed. For as long as the bound Control remains actuated, the Action stays in Started and triggers Performed whenever the value of the Control changes (that is, one call occurs to InputAction.performed). When the bound Control stops being actuated, the Action goes to Canceled and then back to Waiting. One call occurs to InputAction.canceled. Button type Actions have the following behavior: As soon as a bound Control becomes actuated, the Action goes from Waiting to Started. One callback occurs on InputAction.started. If a Control then reaches or exceeds the button press threshold, the Action goes from Started to Performed. One callback occurs on InputAction.performed. The default value of the button press threshold is defined in the input settings. However, an individual control can override this value. Once the Action has Performed, if all Controls then go back to a level of actuation at or below the release threshold, the Action goes from Performed to Canceled. One call occurs to InputAction.canceled. If the Action never went to Performed, it will go to Canceled as soon as all Controls are released. One call occurs to InputAction.canceled. PassThrough type Actions have a simpler behavior. The Input System doesn't try to track bound Controls as a single source of input. Instead, it triggers a Performed callback for each value change. Callback InputActionType.Value InputActionType.Button InputActionType.PassThrough started Control(s) changed value away from the default value. Button started being pressed but has not necessarily crossed the press threshold yet. not used performed Control(s) changed value. Button was pressed to at least the button press threshold. Control changed value. canceled Control(s) are no longer actuated. Button was released. If the button was pressed above the press threshold, the button has now fallen to or below the release threshold. If the button was never fully pressed, the button is now back to completely unpressed. Action is disabled. Press You can use a PressInteraction to explicitly force button-like interactions. Use the behavior parameter to select if the Interaction should trigger on button press, release, or both. Parameters Type Default value pressPoint float InputSettings.defaultButtonPressPoint behavior PressBehavior PressOnly Callbacks/behavior PressOnly ReleaseOnly PressAndRelease started Control magnitude crosses pressPoint Control magnitude crosses pressPoint Control magnitude crosses pressPoint performed Control magnitude crosses pressPoint Control magnitude goes back below pressPoint - Control magnitude crosses pressPoint or - Control magnitude goes back below pressPoint canceled not used not used not used Hold A HoldInteraction requires the user to hold a Control for duration seconds before the Input System triggers the Action. Parameters Type Default value duration float InputSettings.defaultHoldTime pressPoint float InputSettings.defaultButtonPressPoint To display UI feedback when a button starts being held, use the started callback. action.started += _ => ShowGunChargeUI(); action.performed += _ => FinishGunChargingAndHideChargeUI(); action.cancelled += _ => HideChargeUI(); Callbacks started Control magnitude crosses pressPoint. performed Control magnitude held above pressPoint for >= duration. canceled Control magnitude goes back below pressPoint before duration (that is, the button was not held long enough). Tap A TapInteraction requires the user to press and release a Control within duration seconds to trigger the Action. Parameters Type Default value duration float InputSettings.defaultTapTime pressPoint float InputSettings.defaultButtonPressPoint Callbacks started Control magnitude crosses pressPoint. performed Control magnitude goes back below pressPoint before duration. canceled Control magnitude held above pressPoint for >= duration (that is, the tap was too slow). SlowTap A SlowTapInteraction requires the user to press and hold a Control for a minimum duration of duration seconds, and then release it, to trigger the Action. Parameters Type Default value duration float InputSettings.defaultSlowTapTime pressPoint float InputSettings.defaultButtonPressPoint Callbacks started Control magnitude crosses pressPoint. performed Control magnitude goes back below pressPoint after duration. canceled Control magnitude goes back below pressPoint before duration (that is, the tap was too fast). MultiTap A MultiTapInteraction requires the user to press and release a Control within tapTime seconds tapCount times, with no more then tapDelay seconds passing between taps, for the Interaction to trigger. You can use this to detect double-click or multi-click gestures. Parameters Type Default value tapTime float InputSettings.defaultTapTime tapDelay float 2 * tapTime tapCount int 2 pressPoint float InputSettings.defaultButtonPressPoint Callbacks started Control magnitude crosses pressPoint. performed Control magnitude went back below pressPoint and back up above it repeatedly for tapCount times. canceled - After going back below pressPoint, Control magnitude did not go back above pressPoint within tapDelay time (that is, taps were spaced out too far apart). or - After going back above pressPoint, Control magnitude did not go back below pressPoint within tapTime time (that is, taps were too long). Writing custom Interactions You can also write a custom Interaction to use in your Project. You can use custom Interactions in the UI and code the same way you use built-in Interactions. Add a class implementing the IInputInteraction interface, like this: // Interaction which performs when you quickly move an // axis all the way from extreme to the other. public class MyWiggleInteraction : IInputInteraction { public float duration = 0.2; void Process(ref InputInteractionContext context) { if (context.timerHasExpired) { context.Canceled(); return; } switch (context.phase) { case InputActionPhase.Waiting: if (context.Control.ReadValue<float>() == 1) { context.Started(); context.SetTimeout(duration); } break; case InputActionPhase.Started: if (context.Control.ReadValue<float>() == -1) context.Performed(); break; } } // Unlike processors, Interactions can be stateful, meaning that you can keep a // local state that mutates over time as input is received. The system might // invoke the Reset() method to ask Interactions to reset to the local state // at certain points. void Reset() { } } Now, you need to tell the Input System about your Interaction. Call this method in your initialization code: InputSystem.RegisterInteraction<MyWiggleInteraction>(); Your new Interaction is now available in the Input Action Asset Editor window. You can also add it in code like this: var Action = new InputAction(Interactions: \"MyWiggle(duration=0.5)\");"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Joystick.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Joystick.html",
    "title": "Joystick support | Inventory System",
    "summary": "Joystick support The Input System currently has limited support for joysticks as generic HIDs only. The system attempts to identify Controls based on the information provided in the HID descriptor of the Device, but it might not always be accurate. These Devices often work best when you allow the user to manually remap the Controls. To better support specific joysticks Devices, you can also provide your own custom mappings for those Devices. Unity might extend the Input System to include some mappings for common devices in the future. See the manual page on HID for more information. Controls The Input System supports Generic HID Input Devices which are recognized as joysticks via the Joystick class. Joystick Devices can have any number of Controls as reported by the Device's HID descriptor, but the Input System always tries to at least match these common Controls: Control Type Description stick StickControl The main stick of the joystick. trigger ButtonControl The primary trigger of the joystick."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Keyboard.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Keyboard.html",
    "title": "Keyboard support | Inventory System",
    "summary": "Keyboard support The Keyboard class defines a Device with a set of key Controls defined by the Key enumeration. The location of individual keys is agnostic to keyboard layout. This means that, for example, the A key is always the key to the right of the Caps Lock key, regardless of where the currently active keyboard layout places the key that generates an a character, or whether or not the layout doesn't have a key assigned to that character. To query which (if any) character is generated by a given key, use the key Control's displayName property. The value of this property changes automatically when the OS changes the keyboard layout. You can look up keys based on the character they produce using Control paths. For example, you can query the key that produces the producing the a character from Keyboard using Keyboard.current[\"#(a)\"]. Note Keyboards usually have hardware limitations on both the number of simultaneous keypresses they report, and the combinations of keys they support. This means that certain simultaneous keypresses may not register correctly. For example, a given keyboard might report a simultaneous press of the \"QWERT\" keys correctly, but might not report \"QWERA\" correctly. At the moment, the new Input System doesn't support on-screen keyboards. For now, please Unity's existing API in UnityEngine.TouchScreenKeyboard. At the moment, Unity platform backends generally do not support distinguishing between multiple keyboards. While the Input System supports having many Keyboard devices at any point, platform backends generally only report a single keyboard and route input from all attached keyboards to the one keyboard device. Controls To retrieve a key from Keyboard, you can use one of these methods: Use the key's accessor property, such Keyboard.spaceKey. Use Keyboard's indexer and the Key enumeration (for example, keyboard[Key.Space]). The scripting API reference for the Keyboard class lists all the properties for the individual key Controls. Two special Controls, anyKey and imeSelected, don't directly map to individual keys. anyKey is a synthetic button Control which reports whether any key on the keyboard is pressed, and imeSelected reports whether or not IME text processing is enabled. In addition, Keyboard's indexer and the Key has three synthetic controls that represent combinations of modifier keys: Control Description shiftKey A button that is pressed if leftShiftKey and/or rightShiftKey is pressed. ctrlKey A button that is pressed if leftCtrlKey and/or rightCtrlKey is pressed. altKey A button that is pressed if leftAltKey and/or rightAltKey is pressed. Text input As a best practice, you shouldn't manually translate text input from key presses by trying to string together the characters corresponding to the keys. Instead, to listen to text input, hook into Keyboard.onTextInput. This delivers character-by-character input as reported by the platform, including input from on-screen keyboards. Note that the text input API doesn't allocate GC memory because it doesn't deliver fully composed strings. IME Some writing systems, such as some East-Asian scripts, are too complex to represent all characters as individual keys on a keyboard. For these layouts, operating systems implement IMEs (Input Method Editors) to allow composing input strings by other methods, for instance by typing several keys to produce a single character. Unity's UI frameworks for text input support IME without any additional configuration. If you want to build your own UI for text input, the Keyboard class allows you to work with input from IMEs using the following APIs: imeSelected is a virtual input Control that reports whether IME text processing is enabled. SetIMEEnabled() is a method which lets you turn IME processing on or off. Typically, IME processing is useful when the user wants to edit text, but not so much when the user is using the keyboard to control a game. SetIMECursorPosition(). IMEs might open system windows that let users interactively edit the text they want to input. Typically, these open next to the text editing UI. You can use the SetIMECursorPosition() method to tell the OS where that is. onIMECompositionChange is an event you can subscribe to in order to receive all updates to the IME composition string. The composition string is the text input the user is currently editing using an IME. Typically, any UI dealing with text input displays this text (with some visual indication of it being actively edited, usually an underline) at the current text input cursor position. Keyboard layouts You can query the name of the current keyboard layout using Keyboard.keyboardLayout. Layout names are platform-specific. There is no support for setting keyboard layouts from your application. To monitor keyboard layout changes, hook into InputSystem.onDeviceChange and check for InputDeviceChange.ConfigurationChanged on a Keyboard device. To find the key control that corresponds to a specific display character sequence, call Keyboard.FindKeyOnCurrentKeyboardLayout. // Find key that generates a 'q' character according to the current keyboard layout. Keyboard.current.FindKeyOnCurrentKeyboardLayout(\"q\");"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/KnownLimitations.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/KnownLimitations.html",
    "title": "Known Limitations | Inventory System",
    "summary": "Known Limitations The following is a list of known limitations that the Input System currently has. Compatibility with other Unity features Input processing in the background is tied to Application.runInBackground (i.e. the \"Run In Background\" setting in \"Player Preferences\") which, however, Unity always forces to true in development players. This means that in development players, input will always be processed, even if the app is in the background. Of course, this only pertains to platforms where the player can actually run in the background (iOS and Android are thus unaffected). PlayerInput split-screen support does not work with Cinemachine virtual cameras. The Input System cannot generate input for IMGUI. UI Toolkit can be used with InputSystemUIInputModule but only pointer (mouse, pen, touch) and gamepad input is supported at the moment. XR support is coming. Also, UI Toolkit support currently requires use of an EventSystem setup in order to interface the Input System with UITK. uGUI After enabling, the UI will not react to a pointer's position until the position is changed. The new input system cannot yet feed text input into uGUI and TextMesh Pro input field components. This means that text input ATM is still picked up directly and internally from the Unity native runtime. The UI will not consume input such that it will not also trigger in-game actions. Device support Currently, devices whose input sources depend on application focus (generally, keyboards and pointers but can be any device depending on platform) will not automatically sync their current state when the app loses and subsequently regains focus. This means that, for example, if the W key is held when application comes back into the foreground, the key needs to be depressed and pressed again for the input to come through. This is being worked on. (Desktop) We do not yet support distinguishing input from multiple pointers (mouse, pen, touch) or keyboards. There will be a single Mouse, Pen, Touch, and Keyboard device. (Windows) Pen input will not work with Wacom devices if \"Windows Ink\" support is turned off. (Windows) HID input is not currently supported in 32-bit players. This means that devices such as the PS4 controller will not work in 32-bit standalone players. Use the 64-bit standalone player instead. (Android) We only support a single Touchscreen at the moment. (Stadia) The Stadia controller is only supported in the Stadia player at the moment. In the editor, use the generic Gamepad for bindings and use any Xbox or PS4 controller for testing. Joy-Cons are only supported on Switch. Sensors in the PS4 controller are currently only supported on PS4. NOTE: Support for NDA platforms is distributed as separate packages due to licensing restrictions. The packages, at this point, are made available separately to licensees for download and installation. Features Supported by Old Input Manager MonoBehaviour mouse methods (OnMouseEnter, OnMouseDrag, etc) will not be called by the Input System. Unity Remote doesn't currently support the Input System. This is being worked on."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Layouts.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Layouts.html",
    "title": "Layouts | Inventory System",
    "summary": "Layouts Layout formats Layout from type Layout from JSON Generated layouts Layout inheritance Control items Layout overrides Precompiled layouts Creating a precompiled layout Layouts are the central mechanism by which the Input System learns about types of Input Devices and Input Controls. Each layout represents a specific composition of Input Controls. By matching the description of a Device to a layout, the Input System is able to create the correct type of Device and interpret the incoming input data correctly. Note: Layouts are an advanced, mostly internal feature of the Input System. Knowledge of the layout system is mostly useful if you want to support custom Devices or change the behavior of existing Devices. A layout describes a memory format for input, and the Input Controls to build in order to read and write data to or from that memory. The Input System ships with a large set of layouts for common Control types and common Devices. For other Device types, the system automatically generates layouts based on the Device description that the Device's interface reports. You can browse the set of currently understood layouts from the Input Debugger. A layout has two primary functions: Describe a certain memory layout containing input data. Assign names, structure, and meaning to the Controls operating on the data. A layout can either be for a Control on a Device (for example, Stick), or for a Device itself (that is, anything based on InputDevice). The Input System only loads layouts when they are needed (usually, when creating a new Device). To manually load a layout, you can use InputSystem.LoadLayout. This returns an InputControlLayout instance, which contains the final, fully merged (that is, containing any information inherited from base layouts and/or affected by layout overrides) structure of the layout. You can register new layouts through InputSystem.RegisterLayout. Layout formats You can add new layouts layouts in one of three ways. Represented by C# structs and classes. In JSON format. Built on the fly at runtime using layout builders. Layout from type In its most basic form, a layout can be expressed by a C# class derived from: InputControl for a Control layout. InputDevice for a Device layout. // The InputControlLayout attribute is not strictly necessary here. // However, you can use it to set additional properties (such as // a custom display name for the layout). [InputControlLayout] public class MyDevice : InputDevice { public AxisControl axis { get; private set; } public ButtonControl button { get; private set; } protected override void FinishSetup(InputDeviceBuilder builder) { base.FinishSetup(builder); axis = builder.GetControl<AxisControl>(\"axis\"); button = builder.GetControl<ButtonControl>(\"button\"); } } You can then register the layout with InputSystem.RegisterLayout. This works the same for Control and for Device layouts. // Note: This should generally be done from InitializeOnLoad/ // RuntimeInitializeOnLoad code. InputSystem.RegisterLayout<MyDevice>(); When the layout is instantiated, the system looks at every field and property defined directly in the type to potentially turn it into one or more Control items. If the field or property is annotated with InputControlAttribute, the system applies the attribute's properties to the Control item. Some special defaults apply in this case: If no offset is set, and the attribute is applied to a field, offset defaults to the offset of the field. If no name is set, it defaults to the name of the property/field. If no layout is set, the system infers it from the type of the field/property. If the field or property has a struct type which implements IInputStateTypeInfo, the field is considered to be an embedded state struct and the system recurses into the field or property to gather Controls from it. Otherwise, if the type of the field or property is based on InputControl, the system adds a Control item similar to case 1, where the member is annotated with InputControlAttribute. Using a state structure When you implement support for a new Input Device, there's usually an existing data format in which the Input System receives input for the Device. The easiest way to add support for the data format is to describe it with a C# struct annotated with InputControlAttribute. public struct MyDeviceState : IInputStateTypeInfo { public FourCC format => new FourCC('M', 'D', 'E', 'V'); [InputControl(name = \"button1\", layout = \"Button\", bit = 0)] [InputControl(name = \"button2\", layout = \"Button\", bit = 1)] [InputControl(name = \"dpad\", layout = \"Dpad\", bit = 2, sizeInBits = 4)] [InputControl(name = \"dpad/up\", bit = 2)] [InputControl(name = \"dpad/down\", bit = 3)] [InputControl(name = \"dpad/left\", bit = 4)] [InputControl(name = \"dpad/right\", bit = 5)] public int buttons; [InputControl(layout = \"Stick\")] public Vector2 stick; [InputControl(layout = \"Axis\")] // Automatically converts from byte to float. public byte trigger; } // The Device must be directed to the state struct we have created. [InputControlLayout(stateType = typeof(MyDeviceState)] public class MyDevice : InputDevice { } Layout from JSON You can also create a layout from a JSON string that contains the same information. This is mostly useful if you want to be able to store and transfer layout information separate from your code - for instance, if you want to be able to add support for new Devices dynamically without making a new build of your application. You can use InputControlLayout.ToJson() and InputControlLayout.FromJson() to convert layouts to and from the format. The same layout as above looks like this in JSON format: { \"name\": \"MyDevice\", \"format\": \"MDEV\", \"controls\": [ { \"name\": \"button1\", \"layout\": \"Button\", \"offset\": 0, \"bit\": 0, }, { \"name\": \"button2\", \"layout\": \"Button\", \"offset\": 0, \"bit\": 1, }, { \"name\": \"dpad\", \"layout\": \"Dpad\", \"offset\": 0, \"bit\": 2, \"sizeInBits\": 4, }, { \"name\": \"dpad/up\", \"offset\": -1, \"bit\": 2, }, { \"name\": \"dpad/down\", \"offset\": -1, \"bit\": 3, }, { \"name\": \"dpad/left\", \"offset\": -1, \"bit\": 4, }, { \"name\": \"dpad/right\", \"offset\": -1, \"bit\": 5, }, { \"name\": \"stick\", \"layout\": \"Stick\", \"offset\": 4, \"format\": \"VEC2\", }, { \"name\": \"trigger\", \"layout\": \"Axis\", \"offset\": 12, \"format\": \"BYTE\", } ] } Generated layouts Finally, the Input System can also build layouts on the fly in code. This is useful for Device interfaces such as HID that supply descriptive information for each Device. To build layouts dynamically in code, you can use the InputControlLayout.Builder API. Here's the same layout from the previous examples constructed programmatically: var builder = new InputControlLayout.Builder() .WithName(\"MyDevice\") .WithFormat(\"MDEV\"); builder.AddControl(\"button1\") .WithLayout(\"Button\") .WithByteOffset(0) .WithBitOffset(0); builder.AddControl(\"button2\") .WithLayout(\"Button\") .WithByteOffset(0) .WithBitOffset(1); builder.AddControl(\"dpad\") .WithLayout(\"Dpad\") .WithByteOffset(0) .WithBitOffset(2) .WithSizeInBits(4); builder.AddControl(\"dpad/up\") .WithByteOffset(-1) .WithBitOffset(2); builder.AddControl(\"dpad/down\") .WithByteOffset(-1) .WithBitOffset(3); builder.AddControl(\"dpad/left\") .WithByteOffset(-1) .WithBitOffset(4); builder.AddControl(\"dpad/right\") .WithByteOffset(-1) .WithBitOffset(5); builder.AddControl(\"stick\") .WithLayout(\"Stick\") .WithByteOffset(4) .WithFormat(\"VEC2\"); builder.AddControl(\"trigger\") .WithLayout(\"Axis\") .WithByteOffset(12) .WithFormat(\"BYTE\"); var layout = builder.Build(); Layout inheritance You can derive a layout from an existing layout. This process is based on merging the information from the derived layout on top of the information that the base layout contains. For layouts defined as types, the base layout is the layout of the base type (if any). For layouts defined in JSON, you can specify the base layout in the extends property of the root node. For layouts created in code using InputControlLayout.Builder, you can specify a base layout using InputControlLayout.Builder.Extend(). Control items Each layout is comprised of zero or more Control items. Each item either describes a new Control, or modifies the properties of an existing Control. The latter can also reach down into the hierarchy and modify properties of a Control added implicitly as a child by another item. // Add a dpad Control. [InputControl(layout = \"Dpad\")] // And now modify the properties of the \"up\" Control that was added by the // \"Dpad\" layout above. [InputControl(name = \"dpad/up\", displayName = \"DPADUP\")] public int buttons; The following table details the properties that a Control item can have. These can be set as properties on InputControlAttribute, as properties on the Control in JSON, or through methods on InputControlLayout.Builder.ControlBuilder. Property Description name Name of the Control. By default, this is the name of the field/property that InputControlAttribute is applied to. displayName Display name of the Control (for use in UI strings). shortDisplayName Short display name of the Control (for use in UI strings). layout Layout to use for the Control. variants Variants of the Control. aliases Aliases for the Control. These are alternative names the Control can be referred by. usages Usages of the Control. offset The byte offset at which the state for the Control is found. bit The bit offset at which the state of the Control is found within its byte. sizeInBits The total size of the Control's state, in bits. arraySize If this is set to a non-zero value, the system will create an array of Controls of this size. parameters Any parameters to be passed to the Control. The system will apply these to any fields the Control type might have, such as AxisControl.scaleFactor. processors Processors to apply to the Control. noisy Whether the Control is to be considered noisy. synthetic Whether the Control is to be considered synthetic. defaultState Default initial value of the state memory Control. useStateFrom For synthetic Controls, used to synthesize Control state. minValue The minimum value the Control can report. Used for evaluating Control magnitude. maxValue The maximum value the Control can report. Used for evaluating Control magnitude. dontReset When a device \"soft\" reset is performed, the state of this control will not be reset. This is useful for controls such as pointer positions which should not go to (0,0) on a reset. When a \"hard\" reset is performed, the control will still be reset to its default value. Layout overrides You can non-destructively change aspects of an existing layout using layout overrides. You can call InputSystem.RegisterLayoutOverride to register a layout as an override of its base layout. The system then adds any property present in the override to the base layout or to existing properties. // Add an extra Control to the \"Mouse\" layout const string json = @\" { \"\"name\"\" : \"\"Overrides\"\", \"\"extend\"\" : \"\"Mouse\"\", \"\"controls\"\" : [ { \"\"name\"\" : \"\"extraControl\"\", \"\"layout\"\" : \"\"Button\"\" } ] } \"; InputSystem.RegisterLayoutOverride(json); Precompiled layouts Building a device at runtime from an InputControlLayout is a slow process. The layout instance itself has to be built (which might involve reflection) and then interpreted in order to put the final InputDevice instance together. This process usually involves the loading of multiple InputControlLayout instances, each of which might be the result of merging multiple layouts together (if the layout involves inheritance or overrides). You can speed up this process up by \"baking\" the final form of a layout into a \"precompiled layout\". A precompiled layout is generated C# code that, when run, will build the corresponding device without relying on loading and interpreting an InputControlLayout. Aside from running faster, this will also create far less garbage and will not involve C# reflection (which generally causes runtime overhead by inflating the number of objects internally kept by the C# runtime). NOTE: Precompiled layouts must be device layouts. It is not possible to precompile the layout for an InputControl. Creating a precompiled layout The first step in setting up a precompiled layout is to generate it. To do so, open the Input Debugger, navigate to the layout you want to precompile within the Layouts branch, right-click it, and select Generate Precompiled Layout. Unity will ask you where to store the generated code. Pick a directory in your project, enter a file name, and click Save. Once generated, you can register the precompiled layout with the Input System using InputSystem.RegisterPrecompiledLayout. The method expects a string argument containing metadata for the precompiled layout. This string is automatically emitted as a const inside the generated class. InputSystem.RegisterPrecompiledLayout<MyPrecompiledDevice>(MyPrecompiledDevice.metadata); IMPORTANT: It is very important that this method is called with all relevant layout registrations being in the same state as at the time the layout was precompiled. There is no internal check whether the precompiled layout will still generate an identical result to the non-precompiled version. Once registered, a precompiled layout is automatically used whenever the layout that the precompiled layout is based on is instantiated. // Let's assume you have a custom device class. public class MyDevice : InputDevice { // Setters for your control getters need to have at least `protected` // or `internal` access so the precompiled version can use them. [InputControl] public ButtonControl button { get; protected set; } // This method will *NOT* be invoked by the precompiled version. Instead, all the lookups // performed here will get hardcoded into the generated C# code. protected override void FinishSetup() { base.FinishSetup(); button = GetChildControl<ButtonControl>(\"button1\"); } } // You register the device as a layout somewhere during startup. InputSystem.RegisterLayout<MyDevice>(); // And you register a precompiled version of it then as well. InputSystem.RegisterPrecompiledLayout<PrecompiledMyDevice>(PrecompiledMyDevice.metadata); // Then the following will implicitly use the precompiled version. InputSystem.AddDevice<MyDevice>(); A precompiled layout will automatically be unregistered in the following cases: A layout override is applied to one of the layouts used by the precompiled Device. This also extends to controls used by the Device. A layout with the same name as one of the layouts used by the precompiled Device is registered (which replaces the layout already registered under the name). A processor is registered that replaces a processor used by the precompiled Device. This causes the Input System to fall back to the non-precompiled version of the layout. Note also that a precompiled layout will not be used for layouts derived from the layout the precompiled version is based on. In the example above, if someone derives a new layout from MyDevice, the precompiled version is unaffected (it will not be unregistered) but is also not used for the newly created type of device. // Let's constinue from the example above and assume that sometime // later, someone replaces the built-in button with an extended version. InputSystem.RegisterLayout<ExtendedButtonControl>(\"Button\"); // PrecompiledMyDevice has implicitly been removed now, because the ButtonControl it uses // has now been replaced with ExtendedButtonControl. If needed, you can add #if checks to the generated code, if needed. The code generator will scan the start of an existing file for a line starting with #if and, if found, preserve it in newly generated code and generate a corresponding #endif at the end of the file. Similarly, you can change the generated class from public to internal and the modifier will be preserved when regenerating the class. Finally, you can also modify the namespace in the generated file with the change being preserved. The generated class is marked as partial, which means you can add additional overloads and other code by having a parallel, partial class definition. // The next line will be preserved when regenerating the precompiled layout. A // corresponding #endif will be emitted at the end of the file. #if UNITY_EDITOR || UNITY_STANDALONE // If you change the namespace to a different one, the name of the namespace will be // preserved when you regenerate the precompiled layout. namepace MyNamespace { // If you change `public` to `internal`, the change will be preserved // when regenerating the precompiled layout. public partial class PrecompiledMyDevice : MyDevice { //... The namespace of the generated layout will correspond to the"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Migration.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Migration.html",
    "title": "Migrating from the old Input Manager | Inventory System",
    "summary": "Migrating from the old Input Manager Read the introductory documentation first Which system is enabled? Comparison of API in the old Input Manager and the new Input System package Action-based input Directly reading Gamepad and Joystick controls Keyboard Mouse Touch and Pen Sensors This page is provided to help you match input-related API from Unity's old, built-in input (known as the Input Manager) to the corresponding API in the new Input System package. Read the introductory documentation first If you're new to the Input System package and have landed on this page looking for documentation, it's best to read the QuickStart Guide, and the Concepts and Workflows pages from the introduction section of the documentation, so that you can make sure you're choosing the best workflow for your project's input requirements. This is because there are a number of different ways to read input using the Input System, and some of the directly corresponding API methods on this page might give you the quickest - but least flexible - solution, and may not be suitable for a project with more complex requirements. Which system is enabled? When installing the new Input System, Unity prompts you to enable the new input system and disable the old one. You can change this setting at any time later, by going to Edit > Project Settings > Player > Other Settings > Active Input Handling, as described here. There are scripting symbols defined which allow you to use conditional compilation based on which system is enabled, as shown in the example below. #if ENABLE_INPUT_SYSTEM // New input system backends are enabled. #endif #if ENABLE_LEGACY_INPUT_MANAGER // Old input backends are enabled. #endif Note: It is possible to have both systems enabled at the same time, in which case both sets of code in the example above above will be active. Comparison of API in the old Input Manager and the new Input System package Below is a list comparing the API from the old Input Manager with the corresponding API for the new Input System package. All of the new Input System package APIs listed below are in the UnityEngine.InputSystem namespace. The namespace is omitted here for brevity. Action-based input Action-based input refers to reading pre-configured named axes, buttons, or other controls. (Read more about Action-based input) In the old Input Manager, these are defined in the Axes list, in the Input Manager section of the Project Settings window. (Below, left) In the new Input System, these are defined in the Actions Editor, which can be found in the Input System Package section of the Project Settings window, or by opening an Action Asset. (Below, right) On the left, the old Input Manager Axes Configuration window, in Project settings. On the right, the new Input System's Actions Editor. Note: In some cases for named axes and buttons, the new Input System requires slightly more code than the old Input Manager, but this results in better performance. This is because in the new Input System, the logic is separated into two parts: the first is to find and store a reference to the action (usually done once, for example in your Start method), and the second is to read the action (usually done every frame, for example in your Update method). In contrast, the old Input Manager used a string-based API to \"find\" and \"read\" the value at the same time, because it was not possible to store a reference to a button or axis. This results in worse performance, because the axis or button is looked up each time the value is read. To find and store references to actions, which can be axes or buttons use FindAction. For example: // A 2D axis action named \"Move\" InputAction moveAction = InputSystem.actions.FindAction(\"Move\"); // A button action named \"Jump\" InputAction jumpAction = InputSystem.actions.FindAction(\"Jump\"); Then, to read the action values, use the following: Input Manager (Old) Input System (New) Input.GetAxis In the old Input Manager System, all axes are 1D and return float values. For example, to read the horizontal and vertical axes: float h = Input.GetAxis(\"Horizontal\"); float v = Input.GetAxis(\"Vertical\"); Use ReadValue on the reference to the action to read the current value of the axis. In the new Input System, axes can be 1D, 2D or other value types. You must specify the correct value type that corresponds with how the action is set up. This example shows a 2D axis: Vector2 moveVector = moveAction.ReadValue<Vector2>();. Input.GetButton Example: bool jumpValue = Input.GetButton(\"Jump\"); Use IsPressed on the reference to the action to read the button value. Example: bool jumpValue = jumpAction.IsPressed();. Input.GetButtonDown Example: bool jump = Input.GetButtonDown(\"Jump\"); Use WasPressedThisFrame on the reference to the action to read if the button was pressed this frame. Example: bool jumpValue = jumpAction.WasPressedThisFrame();. Input.GetButtonUp Example: bool jump = Input.GetButtonUp(\"Jump\"); Use WasReleasedThisFrame on the reference to the action to read whether the button was released this frame. Example: bool jumpValue = jumpAction.WasReleasedThisFrame();. Input.GetAxisRaw For example, to read the raw values of the horizontal and vertical axes: float h = Input.GetAxisRaw(\"Horizontal\"); float v = Input.GetAxisRaw(\"Vertical\"); No direct equivalent, but if there are processors associated with the action, you can use InputControl<>.ReadUnprocessedValue() to read unprocessed values. Example: Vector2 moveVector = moveAction.ReadUnprocessedValue(); Note: This returns the same value as ReadValue when there are no processors on the action. Directly reading Gamepad and Joystick controls Directly reading hardware controls bypasses the new Input System's action-based workflow, which has some benefits and some drawbacks. (Read more about directly reading devices) Input Manager (Old) Input System (New) Input.GetKey Example: Input.GetKey(KeyCode.JoystickButton0) Use isPressed on the corresponding Gamepad button. Example: InputSystem.GamePad.current.buttonNorth.isPressed. Input.GetKeyDown Example: Input.GetKeyDown(KeyCode.JoystickButton0) Use wasPressedThisFrame on the corresponding Gamepad button. Example: InputSystem.GamePad.current.buttonNorth.WasPressedThisFrame. Input.GetKeyUp Example: Input.GetKeyUp(KeyCode.JoystickButton0) Use wasReleasedThisFrame on the corresponding Gamepad button. Example: InputSystem.GamePad.current.buttonNorth.wasReleasedThisFrame. Input.GetJoystickNames There is no API that corresponds to this exactly, but there are examples of how to read all connected devices here. Input.IsJoystickPreconfigured Not needed. Devices which derive from Gamepad always correctly implement the mapping of axes and buttons to the corresponding InputControl members of the Gamepad class. Input.ResetInputAxes Keyboard Input Manager (Old) Input System (New) Input.GetKey Example: Input.GetKey(KeyCode.Space) Use isPressed on the corresponding key. Example: InputSystem.Keyboard.current.spaceKey.isPressed Input.GetKeyDown Example: Input.GetKeyDown(KeyCode.Space) Use wasPressedThisFrame on the corresponding key. Example: InputSystem.Keyboard.current.spaceKey.wasPressedThisFrame Input.GetKeyUp Example: Input.GetKeyUp(KeyCode.Space) Use wasReleasedThisFrame on the corresponding key. Example: InputSystem.Keyboard.current.spaceKey.wasReleasedThisFrame Input.anyKey Use onAnyButtonPress. This also includes controller buttons as well as keyboard keys. Input.anyKeyDown Use Keyboard.current.anyKey.wasUpdatedThisFrame Input.compositionCursorPos Use Keyboard.current.SetIMECursorPosition(myPosition) Input.compositionString Subscribe to the Keyboard.onIMECompositionChange. Input.imeCompositionMode Use: Keyboard.current.SetIMEEnabled(true) Also see: Keyboard text input documentation. Input.imeIsSelected Use: Keyboard.current.imeSelected Input.inputString Subscribe to the Keyboard.onTextInput event: Keyboard.current.onTextInput += character => /* ... */; Mouse Input Manager (Old) Input System (New) Input.GetMouseButton Example: Input.GetMouseButton(0) Use isPressed on the corresponding mouse button. Example: InputSystem.Mouse.current.leftButton.isPressed Input.GetMouseButtonDown Example: Input.GetMouseButtonDown(0) Use wasPressedThisFrame on the corresponding mouse button. Example: InputSystem.Mouse.current.leftButton.wasPressedThisFrame Input.GetMouseButtonUp Example: Input.GetMouseButtonUp(0) Use wasReleasedThisFrame on the corresponding mouse button. Example: InputSystem.Mouse.current.leftButton.wasReleasedThisFrame Input.mousePosition Use Mouse.current.position.ReadValue() Example: Vector2 position = Mouse.current.position.ReadValue(); Note: Mouse simulation from touch isn't implemented yet. Input.mousePresent No corresponding API yet. Touch and Pen Input Manager (Old) Input System (New) Input.GetTouch For example: Touch touch = Input.GetTouch(0); Vector2 touchPos = touch.position; Use EnhancedTouch.Touch.activeTouches[i] Example: Vector2 touchPos = EnhancedTouch.Touch.activeTouches[0].position; Note: Enable enhanced touch support first by calling EnhancedTouch.Enable(). Input.multiTouchEnabled No corresponding API yet. Input.simulateMouseWithTouches No corresponding API yet. Input.stylusTouchSupported No corresponding API yet. Input.touchCount EnhancedTouch.Touch.activeTouches.Count Note: Enable enhanced touch support first by calling EnhancedTouchSupport.Enable() Input.touches EnhancedTouch.Touch.activeTouches Note: Enable enhanced touch support first by calling EnhancedTouch.Enable() Input.touchPressureSupported No corresponding API yet. Input.touchSupported Touchscreen.current != null Input.backButtonLeavesApp No corresponding API yet. GetPenEvent GetLastPenContactEvent ResetPenEvents ClearLastPenContactEvent Use: Pen.current See the Pen, tablet and stylus support docs for more information. Note: UnityEngine.TouchScreenKeyboard is not part of the old Input Manager API, so you can continue to use it when migrating to the new Input System package. Sensors Input Manager (Old) Input System (New) Input.acceleration Accelerometer.current.acceleration.ReadValue(). Input.accelerationEventCount Input.accelerationEvents Acceleration events aren't made available separately from other input events. See the accelerometer code sample on the Sensors page. Input.compass No corresponding API yet. Input.compensateSensors InputSettings.compensateForScreenOrientation. Input.deviceOrientation No corresponding API yet. Input.gyro The UnityEngine.Gyroscope class is replaced by multiple separate sensor Devices in the new Input System: Gyroscope to measure angular velocity. GravitySensor to measure the direction of gravity. AttitudeSensor to measure the orientation of the device. Accelerometer to measure the total acceleration applied to the device. LinearAccelerationSensor to measure acceleration applied to the device, compensating for gravity. Input.gyro.attitude AttitudeSensor.current.orientation.ReadValue(). Input.gyro.enabled Get: Gyroscope.current.enabled Set: EnableDevice(Gyroscope.current); DisableDevice(Gyroscope.current); Note: The new Input System replaces UnityEngine.Gyroscope with multiple separate sensor devices. Substitute Gyroscope with other sensors in the sample as needed. See the notes for Input.gyro above for details. Input.gyro.gravity GravitySensor.current.gravity.ReadValue() Input.gyro.rotationRate Gyroscope.current.angularVelocity.ReadValue(). Input.gyro.rotationRateUnbiased No corresponding API yet. Input.gyro.updateInterval Sensor.samplingFrequency Example: Gyroscope.current.samplingFrequency = 1.0f / updateInterval; Notes: samplingFrequency is in Hz, not in seconds as updateInterval, so you need to divide 1 by the value. The new Input System replaces UnityEngine.Gyroscope with multiple separate sensor devices. Substitute Gyroscope with other sensors in the sample as needed. See the notes for Input.gyro above for details. Input.gyro.userAcceleration LinearAccelerationSensor.current.acceleration.acceleration.ReadValue() Input.location No corresponding API yet. Input.GetAccelerationEvent See notes for Input.accelerationEvents above."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Mouse.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Mouse.html",
    "title": "Mouse support | Inventory System",
    "summary": "Mouse support The Input System represents mouse input with the Mouse Device layout that the Mouse class implements. Mice are based on the Pointer layout. To query the last used or last added mouse, use Mouse.current. var mouse = Mouse.current; Note: The Input System does not currently support: Input from multiple mice at the platform level. Identifying the current display a mouse is on. Controls In addition to the Controls inherited from Pointer, Mouse devices implement the following Controls: Control Type Description leftButton ButtonControl The left mouse button. Same as the inherited Pointer.press. rightButton ButtonControl The right mouse button. middleButton ButtonControl The middle mouse button. forwardButton ButtonControl Used for other mouse buttons where applicable. backButton ButtonControl Used for other mouse buttons where applicable. clickCount IntegerControl A Control which lets you read the number of consecutive clicks the last mouse click belonged to, as reported by the OS. Use this to distinguish double- or multi-clicks. scroll Vector2Control The input from the mouse scrolling control expressed as a delta in pixels since the last frame. Can come from a physical scroll wheel, or from touchpad gestures. Cursor warping On desktop platforms (Windows, Mac, Linux, and UWP), you can move the mouse cursor via code. Note that this moves the system's actual mouse cursor, not just Unity's internally-stored mouse position. This means that the user sees the cursor jumping to a different position, which is generally considered to be bad UX practice. It's advisable to only do this if the cursor is hidden (see the Cursor API documentation for more information). To move the cursor to a different position, use Mouse.WarpCursorPosition. The coordinates are expressed as Unity screen coordinates, just like Mouse.position. Mouse.current.WarpCursorPosition(new Vector2(123, 234)); Note: If the cursor is locked, warping the mouse position is only temporary and Unity resets the cursor to the center of the window every frame."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/OnScreen.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/OnScreen.html",
    "title": "On-screen Controls | Inventory System",
    "summary": "On-screen Controls You can use on-screen Controls to simulate Input Devices with UI widgets that the user interacts with on the screen. The most prominent example is the use of stick and button widgets on touchscreens to emulate a joystick or gamepad. There are currently two Control types implemented out of the box: buttons and sticks. You can implement custom Controls by extending the base OnScreenControl class (see documentation on writing custom on screen Controls to learn more). Note: On-screen Controls don't have a predefined visual representation. It's up to you to set up the visual aspect of a Control (for example, by adding a sprite or UI component to the GameObject). On-screen Controls take care of the interaction logic and of setting up and generating input from interactions. Each on-screen Control uses a Control path to reference the Control that it should report input as. For example, the following on-screen button reports input as the right shoulder button of a gamepad: The collection of on-screen Controls present in a Scene forms one or more Input Devices. The Input System creates one Input Device for each distinct type of Device the Controls reference. For example, if one on-screen button references <Gamepad>/buttonSouth and another on-screen button references <Keyboard>/a, the Input System creates both a Gamepad and a Keyboard. This happens automatically when the components are enabled. When disabled, the Input System automatically removes the Devices again. To query the Control (and, implicitly, the Device) that an on-screen Control feeds into, you can use the OnScreenControl.control property. Note: This design allows you to use on-screen Controls to create input for arbitrary Input Devices, in addition to joysticks and gamepads. On-screen buttons To create an on-screen button: Add a UI Button object. Add the OnScreenButton component to it. Set the Control Path to refer to a ButtonControl (for example, <Gamepad>/buttonSouth). The type of device referenced by the control path determines the type of virtual device created by the component. The OnScreenButton component requires the target Control to be a Button Control. OnScreenButton sets the target Control value to 1 when it receives a pointer-down (IPointerDownHandler.OnPointerDown) event, or 0 when it receives a pointer-up (IPointerUpHandler.OnPointerUp) event. On-screen sticks To create an on-screen stick: Create a UI Image object. Add the OnScreenStick component to it. Set the Control Path to refer to a Vector2Control (for example, <Gamepad>/leftStick). The type of device referenced by the control path determines the type of virtual device created by the component. The OnScreenStick component requires the target Control to be a Vector2 Control. OnScreenStick starts the movement of the stick Control when it receives a pointer-down (IPointerDownHandler.OnPointerDown) event, and stops it when it receives a pointer-up (IPointerUpHandler.OnPointerUp) event. In-between, the stick moves according to the pointer being dragged (IDragHandler.OnDrag) within a box centered on the pointer-down screen point, and with an edge length defined in the component's Movement Range property. A movement range of 50, for example, means that the stick's on-screen area is 25 pixels up, down, left, and right of the pointer-down point on screen. If you want to be notified when the user starts and/or stops touching the on-screen stick, implement IPointerDownHandler and/or IPointerUpHandler on a component and add it to the stick GameObject. Isolated mode The OnScreenStick simulates input events from the device specified in the OnScreenControl.control property. To the Input System itself, these are normal events and can cause the paired device to change in games and applications where dynamic device switching is used, for example when the PlayerInput component is used with the PlayerInput.neverAutoSwitchControlSchemes) propety set to false. As the stick is dragged around, the paired device will alternate between the device that owns the pointer (mouse, touch, pen etc) and the device from the control path, which can result in jittery movement of the on-screen stick. Use Isolated Input Actions to fix this. This mode uses a local set of Input Action instances to drive interaction with the stick, and not the actions defined in the UI. The downside of this mode is that pointer actions will be duplicated in both the on-screen stick component and any Input Action Assets being used to drive the UI. Note that if a set of bindings is not specified for the Pointer Down Action and Pointer Move Actions, the following defaults will be used: Pointer Down Action <Mouse>/leftButton <Pen>/tip <Touchscreen>/touch*/press <XRController>/trigger Pointer Move Action <Mouse>/position <Pen>/position <Touchscreen>/touch*/position Writing custom on-screen Controls You can add support for new types of Input Controls by extending OnScreenControl. An easy example to follow is OnScreenButton. [AddComponentMenu(\"Input/On-Screen Button\")] public class OnScreenButton : OnScreenControl, IPointerDownHandler, IPointerUpHandler { public void OnPointerUp(PointerEventData data) { SendValueToControl(0.0f); } public void OnPointerDown(PointerEventData data) { SendValueToControl(1.0f); } [InputControl(layout = \"Button\")] [SerializeField] private string m_ControlPath; protected override string controlPathInternal { get => m_ControlPath; set => m_ControlPath = value; } }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Pen.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Pen.html",
    "title": "Pen, tablet, and stylus support | Inventory System",
    "summary": "Pen, tablet, and stylus support Pen support comprises both tablets on desktops (such as the various tablets produced by Wacom), and styluses on mobile devices (such as the stylus on the Samsung Note, the Apple Pencil on iOS, or the Surface Pen on the Microsoft Surface line of notebooks). Pens generally offer pressure sensitivity, in-range detection (being able to control the cursor while not yet touching the tablet/screen surface), and often the ability to flip the pen for eraser-like behavior. Pens are represented by the Pen Device layout implemented by the Pen class. Pens are based on the Pointer layout. You can query the last used or last added pen with Pen.current. Note: Pen/tablet support is currently implemented on Windows, UWP, iOS, and Android. macOS is supported in Unity 2020.1+. Some devices support tracking multiple pens independently. Unity's Input System doesn't support this currently. iOS: The double-tap interaction on the side of the Apple Pencil is not surfaced as input at the moment. Also, no in-range detection is supported and inRange will remain at its default value. Controls In addition to the Controls inherited from Pointer, pen Devices implement the following Controls: Control Type Description tip ButtonControl Whether the tip of the pen touches the surface. Same as the inherited Pointer.press. eraser ButtonControl Whether the eraser/back end of the pen touches the surface. firstBarrelButton ButtonControl Whether the first button on the barrel of the pen is pressed. secondBarrelButton ButtonControl Whether the second button on the barrel of the pen is pressed. thirdBarrelButton ButtonControl Whether the third button on the barrel of the pen is pressed. fourthBarrelButton ButtonControl Whether the forth button on the barrel of the pen is pressed. inRange ButtonControl Whether the pen is currently in detection range of the tablet. If unsupported, this control will remain at a value of 1. tilt Vector2Control Tilt of the pen relative to the surface. twist AxisControl Rotation of the pen around its own axis. Only supported on a limited number of pens, such as the Wacom Art Pen. Pressure, tilt, and twist Pressure: You can access the pen's current pressure via Pen.pressure, where 0 means no pressure, and 1 means maximum pressure. However, pressure can go over 1 if the system applies a custom pressure curve where a pressure value of 1 doesn't require pressing the pen down all the way to the maximum force the hardware supports. If a pen doesn't support different pressure levels, the pressure Control always returns 1. Tilt: If supported, the Pen.tilt Control represents the angle at which the pen tilts towards the tablet or screen surface. The X and Y axes correspond to the respective screen axes. A value of 1 on either axis means that the pen is fully parallel to the tablet or screen surface on that axis. A value of 0 means that the pen is perpendicular to the tablet or screen surface on that axis. If a pen doesn't support tilt angles, Pen.tilt is always (0,0). Twist: Some pens also support twist detection (the pen rotating around its own axis). If supported, Pen.twist represents the current rotation, where 0 means that the pen is facing up towards the Y axis, and values close to 1 mean that the pen is fully rotated clockwise around its own axis. In-range detection A pen might not need to touch the tablet or screen surface in order to be able to control the cursor. You can use the inRange button Control to determine whether the pen is currently in detection range. If inRange reports as pressed, the pen registers with the tablet or screen. For Devices that don't support this feature, inRange always reports as pressed. Barrel buttons Pen Devices often have one or multiple buttons on the side of the pen. These are represented by the firstBarrelButton, secondBarrelButton, thirdBarrelButton, and fourthBarrelButton where applicable."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/PlayerInput.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/PlayerInput.html",
    "title": "The Player Input component | Inventory System",
    "summary": "The Player Input component The Player Input component provides two related but separate features which can be useful in common game scenarios. These are: Configuring how Actions map to methods or callbacks in the script that controls your player. Handling local multiplayer scenarios such as player lobbies, device filtering, and screen-splitting. The Player Input component Above, the Player Input component displayed in the inspector. Connecting actions to methods or callbacks The Player Input component represents a single player, and the connection between that player's associated device, Actions, and methods or callbacks. You can use a single instance of a Player Input component in a single-player game to set up a mapping between your Input Actions and methods or callbacks in the script that controls your player. For example, by using the Player Input component, you can set up a mapping between actions such as \"Jump\" to C# methods in your script such as public void OnJump(). There are a few options for doing exactly how the Player Input component does this, such as using SendMessage, or Unity Events, which is described in more detail below. Handling local multiplayer scenarios You can also have multiple Player Input components active at the same time (each on a separate instance of a prefab) along with the Player Input Manager component to implement local multiplayer features, such as device filtering, and screen-splitting. In these local multiplayer scenarios, the Player Input component should be on a prefab that represents a player in your game, which the Player Input Manager has a reference to. The Player Input Manager then instantiates players as they join the game and pairs each player instance to a unique device that the player uses exclusively (for example, one gamepad for each player). You can also manually pair devices in a way that enables two or more players to share a Device (for example, left/right keyboard splits or hot seat use). Each PlayerInput corresponds to one InputUser. You can use PlayerInput.user to query the InputUser from the component. Getting started To get started using the Player Input component, use the following steps: Add a Player Input component to a GameObject. This would usually be the GameObject that represents the player in your game. Assign your Action Asset to the Actions field. This is usually the default project-wide action asset named \"InputSystem_Actions\" Set up Action responses, by selecting a Behaviour type from the Behaviour menu. The Behaviour type you select affects how you should implement the methods that handle your Action responses. See the notification behaviors section further down for details. Configuring the Player Input component You can use the following properties to configure PlayerInput: Property Description Actions The set of Input Actions associated with the player. Typically you would set this to Project-Wide Actions, however you can assign an ActionAsset reference here). To receive input, each player must have an associated set of Actions. See documentation on Actions for details. Default Control Scheme Which Control Scheme (from what is defined in Actions) to enable by default. Default Action Map Which Action Map in Actions to enable by default. If set to None, then the player starts with no Actions being enabled. Camera The individual camera associated with the player. This is only required when employing split-screen setups and has no effect otherwise. Behavior How the PlayerInput component notifies game code about things that happen with the player. See documentation on notification behaviors. Actions To receive input, each player must have an associated set of Input Actions. Specifying the Actions to use The simplest workflow is to use the project-wide actions defined in the Input Actions editor. However, the Player Input component also allows you to use an Actions Asset to specify the actions that should be used by any instance of the component. If you set the Actions field to Actions Asset, the inspector displays a field into which you can assign an actions asset, and a Create Actions button which allows you to create a new actions asset. When you create these via the Player Input inspector's Create Actions button, the Input System creates a default set of Actions. However, the Player Input component places no restrictions on the arrangement of Actions. Enabling and disabling Actions The Player Input component automatically handles enabling and disabling Actions, and also handles installing callbacks on the Actions. When multiple Player Input components use the same Actions, the components automatically create private copies of the Actions. This is why, when writing input code that works with the PlayerInput component, you should not use InputSystem.actions because this references the \"singleton\" copy of the actions rather than the specific private copy associated with the PlayerInput instance you are coding for. When first enabled, the Player Input component enables all Actions from the the Default Action Map. If no default Action Map exists, the Player Input component does not enable any Actions. To manually enable Actions, you can call Enable and Disable on the Action Maps or Actions, like you would do without PlayerInput. To check which Action Map is currently enabled, or to switch to a different one, use the PlayerInput.currentActionMap property. To switch Action Maps with an Action Map name, you can also call PlayerInput.SwitchCurrentActionMap. To disable a player's input, call PlayerInput.DeactivateInput. To re-enable it, call PlayerInput.ActivateInput. The latter enables the default Action Map, if it exists. When PlayerInput is disabled, it automatically disables the currently active Action Map (PlayerInput.currentActionMap) and disassociate any Devices paired to the player. See the notification behaviors section below for how to be notified when player triggers an Action. When using Send Messages or Broadcast Messages When the notification behavior of PlayerInput is set to Send Messages or Broadcast Messages, you can set your app to respond to Actions by defining methods in components like so: public class MyPlayerScript : MonoBehaviour { // \"jump\" action becomes \"OnJump\" method. // If you're not interested in the value from the control that triggers the action, use a method without arguments. public void OnJump() { // your Jump code here } // If you are interested in the value from the control that triggers an action, you can declare a parameter of type InputValue. public void OnMove(InputValue value) { // Read value from control. The type depends on what type of controls. // the action is bound to. var v = value.Get<Vector2>(); // IMPORTANT: // The given InputValue is only valid for the duration of the callback. Storing the InputValue references somewhere and calling Get<T>() later does not work correctly. } } The component must be on the same GameObject if you are using Send Messages, or on the same or any child GameObject if you are using Broadcast Messages. When using Invoke Unity Events When the notification behavior of PlayerInput is set to Invoke Unity Events, each Action has to be routed to a target method. The methods have the same format as the started, performed, and canceled callbacks on InputAction. public class MyPlayerScript : MonoBehaviour { public void OnFire(InputAction.CallbackContext context) { } public void OnMove(InputAction.CallbackContext context) { var value = context.ReadValue<Vector2>(); } } Notification behaviors You can use the Behavior property in the Inspector to determine how a PlayerInput component notifies game code when something related to the player has occurred. The following options are available: Behavior Description Send Messages Uses GameObject.SendMessage on the GameObject that the PlayerInput component belongs to. Broadcast Messages Uses GameObject.BroadcastMessage on the GameObject that the PlayerInput component belongs to. This broadcasts the message down the GameObject hierarchy. Invoke Unity Events Uses a separate UnityEvent for each individual type of message. When this is selected, the events available on the PlayerInput are accessible from the Events foldout. The argument received by events triggered for Actions is the same as the one received by started, performed, and canceled callbacks. Invoke CSharp Events Similar to Invoke Unity Events, except that the events are plain C# events available on the PlayerInput API. You cannot configure these from the Inspector. Instead, you have to register callbacks for the events in your scripts. The following events are available: onActionTriggered (collective event for all actions on the player) onDeviceLost onDeviceRegained In addition to per-action notifications, PlayerInput sends the following general notifications: Notification Description DeviceLostMessage The player has lost one of the Devices assigned to it. This can happen, for example, if a wireless device runs out of battery. DeviceRegainedMessage Notification that triggers when the player recovers from Device loss and is good to go again. Device assignments If the PlayerInput component has any Devices assigned, it matches these to the Control Schemes in the associated Action Asset, and only enables Control Schemes which match its Input Devices. Each PlayerInput can have one or more Devices assigned to it. By default, no two PlayerInput components are assigned the same Devices, but you can force this; to do so, manually assign Devices to a player when calling PlayerInput.Instantiate, or call InputUser.PerformPairingWithDevice on the InputUser of a PlayerInput. Debug information When the Editor is in Play mode, each PlayerInput component instance displays a Debug section, as shown below. The Debug section shows the User number (which starts counting from zero), the control Scheme, and the devices assigned to the PlayerInput instance. UI input The PlayerInput component can work together with an InputSystemUIInputModule to drive the UI system. To set this up, assign a reference to a InputSystemUIInputModule component in the UI Input Module field of the PlayerInput component. The PlayerInput and InputSystemUIInputModule components should be configured to work with the same InputActionAsset for this to work. Once you've completed this setup, when the PlayerInput component configures the Actions for a specific player, it assigns the same Action configuration to the InputSystemUIInputModule. In other words, the same Action and Device configuration that controls the player now also controls the UI. If you use MultiplayerEventSystem components to dispatch UI events, you can also use this setup to simultaneously have multiple UI instances on the screen, each controlled by a separate player. Notes: As a general rule, if you are using the PlayerInput workflow, you should read input through callbacks as described above, however if you need to access the input actions asset directly while using the PlayerInput component, you should access the PlayerInput component's copy of the actions, not InputSystem.actions. This is because the PlayerInput component performs device filtering to automatically assign devices to multiple players, so each instance has its own copy of the actions filtered for each player. If you bypass this by reading InputSystem.actions directly, the automatic device assignment won't work. This component is built on top of the public Input System API. As such, they don't do anything that you can't program yourself. They are meant primarily as an easy, out-of-the-box setup that eliminates much of the need for custom scripting."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/PlayerInputManager.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/PlayerInputManager.html",
    "title": "The Player Input Manager component | Inventory System",
    "summary": "The Player Input Manager component NOTE: The Input System package comes with a sample called Simple Multiplayer which you can install from the package manager UI in the Unity editor. The sample demonstrates how to use PlayerInputManager to set up a simple local multiplayer scenario. The Player Input system facilitates setting up local multiplayer games, where multiple players share a single screen and multiple controllers. You can set this up using the PlayerInputManager component, which automatically manages the creation and lifetime of PlayerInput instances as players join and leave the game. Property Description Notification Behavior How the PlayerInputManager component notifies game code about changes to the connected players. This works the same way as for the PlayerInput component. Join Behavior Determines the mechanism by which players can join when joining is enabled. See documentation on join behaviors. Player Prefab A prefab that represents a player in the game. The PlayerInputManager component creates an instance of this prefab whenever a new player joins. This prefab must have one PlayerInput component in its hierarchy. Joining Enabled By Default While this is enabled, new players can join via the mechanism determined by Join Behavior. Limit Number of Players Enable this if you want to limit the number of players who can join the game. Max Player Count(Only shown when Limit number of Players is enabled.) The maximum number of players allowed to join the game. Enable Split-Screen If enabled, each player is automatically assigned a portion of the available screen area. See documentation on split-screen multiplayer. Join behaviors You can use the Join Behavior property in the Inspector to determine how a PlayerInputManager component decides when to add new players to the game. The following options are available to choose the specific mechanism that PlayerInputManager employs. Behavior Description Join Players When Button IsPressed Listen for button presses on Devices that are not paired to any player. If a player presses a button and joining is allowed, join the new player using the Device they pressed the button on. Join Players When Join Action Is Triggered Similar to Join Players When Button IsPressed, but this only joins a player if the control they triggered matches a specific action you define. For example, you can set up players to join when pressing a specific gamepad button. Join Players Manually Don't join players automatically. Call JoinPlayer explicitly to join new players. Alternatively, create GameObjects with PlayerInput components directly and the Input System will automatically join them. Split-screen If you enable the Split-Screen option, the PlayerInputManager automatically splits the available screen space between the active players. For this to work, you must set the Camera property on the PlayerInput prefab. The PlayerInputManager then automatically resizes and repositions each camera instance to let each player have their own part of the screen. If you enable the Split-Screen option, you can configure the following additional properties in the Inspector: Property Description Maintain Aspect Ratio A false value enables the game to produce screen areas that have an aspect ratio different from the screen resolution when subdividing the screen. Set Fixed Number If this value is greater than zero, the PlayerInputManager always splits the screen into a fixed number of rectangles, regardless of the actual number of players. Screen Rectangle The normalized screen rectangle available for allocating player split-screens into. By default, any player in the game can interact with any UI elements. However, in split-screen setups, your game can have screen-space UIs that are restricted to just one specific camera. See the UI Input section on the Player Input component page on how to set this up using the Player Input component, InputSystemUIInputModule and MultiplayerEventSystem components. PlayerInputManager notifications PlayerInputManager sends notifications when something notable happens with the current player setup. These notifications are delivered according to the Notification Behavior property, in the same way as for PlayerInput. Your game can listen to the following notifications: Notification Description PlayerJoinedMessage A new player joined the game. Passes the [PlayerInput](PlayerInput.mdPlayerInputManager sends a Player Joined notification for each of these. PlayerLeftMessage A player left the game. Passes the PlayerInput instance of the player who left."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Pointers.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Pointers.html",
    "title": "Pointers | Inventory System",
    "summary": "Pointers Pointer Devices are defined as InputDevices that track positions on a 2D surface. The Input System supports three types of pointers: Touch Mouse Pen Controls Each of these types implements a common set of Controls. For a more detailed descriptions of these Controls, refer to their scripting reference. Control Type Description position Vector2Control The current pointer coordinates in window space. delta Vector2Control Provides motion delta in pixels accumulated (summed) over the duration of the current frame/update. Resets to (0,0) each frame. Note that the resolution of deltas depends on the specific hardware and/or platform. press ButtonControl Whether the pointer or its primary button is pressed down. pressure AxisControl The pressure applied with the pointer while in contact with the pointer surface. This value is normalized. This is only relevant for pressure-sensitive devices, such as tablets and some touch screens. radius Vector2Control The size of the area where the finger touches the surface. This is only relevant for touch input. Window space The coordinates within Player code are in the coordinate space of the Player window. Within Editor code, the coordinates are in the coordinate space of the current EditorWindow. If you query Pointer.current.position in UnityEditor.EditorWindow.OnGUI, for example, the returned 2D vector will be in the coordinate space of your local GUI (same as UnityEngine.Event.mousePosition)."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Processors.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Processors.html",
    "title": "Processors | Inventory System",
    "summary": "Processors An Input Processor takes a value and returns a processed result for it. The received value and result value must be of the same type. For example, you can use a clamp Processor to clamp values from a control to a certain range. Note: To convert received input values into different types, see composite Bindings. Using Processors Processors on Bindings Processors on Actions Processors on Controls Predefined Processors Clamp Invert Invert Vector 2 Invert Vector 3 Normalize Normalize Vector 2 Normalize Vector 3 Scale Scale Vector 2 Scale Vector 3 Axis deadzone Stick deadzone Writing custom Processors Using Processors You can install Processors on bindings, actions or on controls. Each Processor is registered using a unique name. To replace an existing Processor, register your own Processor under an existing name. Processors can have parameters which can be booleans, integers, or floating-point numbers. When created in data such as bindings, processors are described as strings that look like function calls: // This references the processor registered as \"scale\" and sets its \"factor\" // parameter (a floating-point value) to a value of 2.5. \"scale(factor=2.5)\" // Multiple processors can be chained together. They are processed // from left to right. // // Example: First invert the value, then normalize [0..10] values to [0..1]. \"invert,normalize(min=0,max=10)\" Processors on Bindings When you create Bindings for your actions, you can choose to add Processors to the Bindings. These process the values from the controls they bind to, before the system applies them to the Action value. For instance, you might want to invert the Vector2 values from the controls along the Y axis before passing these values to the Action that drives the input logic for your application. To do this, you can add an Invert Vector2 Processor to your Binding. If you're using Actions defined in the Input Actions Editor, or in an Action Asset, you can add any Processor to your Bindings in the Input Action editor. Select the Binding you want to add Processors to so that the right pane of the window displays the properties for that Binding. Select the Add (+) icon on the Processors foldout to open a list of all available Processors that match your control type, then choose a Processor type to add a Processor instance of that type. The Processor now appears under the Processors foldout. If the Processor has any parameters, you can edit them in the Processors foldout. To remove a Processor, click the Remove (-) icon next to it. You can also use the up and down arrows to change the order of Processors. This affects the order in which the system processes values. If you create your Bindings in code, you can add Processors like this: var action = new InputAction(); action.AddBinding(\"<Gamepad>/leftStick\") .WithProcessor(\"invertVector2(invertX=false)\"); Processors on Actions Processors on Actions work in the same way as Processors on Bindings, but they affect all controls bound to an Action, rather than just the controls from a specific Binding. If there are Processors on both the Binding and the Action, the system processes the ones from the Binding first. You can add and edit Processors on Actions in the Input Actions Editor, or in an Action Asset the same way as you would for Bindings: select an Action to edit, then add one or more Processors in the right window pane. If you create your Actions in code, you can add Processors like this: var action = new InputAction(processors: \"invertVector2(invertX=false)\"); Processors on Controls You can have any number of Processors directly on an InputControl, which then process the values read from the Control. Whenever you call ReadValue on a Control, all Processors on that Control process the value before it gets returned to you. You can use ReadUnprocessedValue on a Control to bypass the Processors. The Input System adds Processors to a Control during device creation, if they're specified in the Control's layout. You can't add Processors to existing Controls after they've been created, so you can only add Processors to Controls when you're creating custom devices. The devices that the Input System supports out of the box already have some useful Processors added on their Controls. For instance, sticks on gamepads have a Stick Deadzone Processor. If you're using a layout generated by the Input System from a state struct using InputControlAttributes, you can specify the Processors you want to use via the processors property of the attribute, like this: public struct MyDeviceState : IInputStateTypeInfo { public FourCC format => return new FourCC('M', 'Y', 'D', 'V'); // Add an axis deadzone to the Control to ignore values // smaller then 0.2, as our Control does not have a stable // resting position. [InputControl(layout = \"Axis\", processors = \"AxisDeadzone(min=0.2)\")] public short axis; } If you create a layout from JSON, you can specify Processors on your Controls like this: { \"name\" : \"MyDevice\", \"extend\" : \"Gamepad\", // Or some other thing \"controls\" : [ { \"name\" : \"axis\", \"layout\" : \"Axis\", \"offset\" : 4, \"format\" : \"FLT\", \"processors\" : \"AxisDeadzone(min=0.2)\" } ] } Predefined Processors The Input System package comes with a set of useful Processors you can use. Clamp Name Clamp Operand Type float Parameters float min float max Clamps input values to the [min..max] range. Invert Name Invert Operand Type float Inverts the values from a Control (that is, multiplies the values by -1). Invert Vector 2 Name InvertVector2 Operand Type Vector2 Parameters bool invertX bool invertY Inverts the values from a Control (that is, multiplies the values by -1). Inverts the x axis of the vector if invertX is true, and the y axis if invertY is true. Invert Vector 3 Name Invert Vector 3 Operand Type Vector3 Parameters bool invertX bool invertY bool invertZ Inverts the values from a Control (that is, multiplies the values by -1). Inverts the x axis of the vector if invertX is true, the y axis if invertY is true, and the z axis if invertZ is true. Normalize Name Normalize Operand Type float Parameters float min float max float zero Normalizes input values in the range [min..max] to unsigned normalized form [0..1] if min is >= zero, and to signed normalized form [-1..1] if min < zero. Normalize Vector 2 Name NormalizeVector2 Operand Type Vector2 Normalizes input vectors to be of unit length (1). This is the same as calling Vector2.normalized. Normalize Vector 3 Name NormalizeVector3 Operand Type Vector3 Normalizes input vectors to be of unit length (1). This is the same as calling Vector3.normalized. Scale Name Scale Operand Type float Parameters float factor Multiplies all input values by factor. Scale Vector 2 Name ScaleVector2 Operand Type Vector2 Parameters float x float y Multiplies all input values by x along the X axis and by y along the Y axis. Scale Vector 3 Name ScaleVector3 Operand Type Vector3 Parameters float x float y float x Multiplies all input values by x along the X axis, by y along the Y axis, and by z along the Z axis. Axis deadzone Name AxisDeadzone Operand Type float Parameters float min float max An axis deadzone Processor scales the values of a Control so that any value with an absolute value smaller than min is 0, and any value with an absolute value larger than max is 1 or -1. Many Controls don't have a precise resting point (that is, they don't always report exactly 0 when the Control is in the center). Using the min value on a deadzone Processor avoids unintentional input from such Controls. Also, some Controls don't consistently report their maximum values when moving the axis all the way. Using the max value on a deadzone Processor ensures that you always get the maximum value in such cases. Stick deadzone Name StickDeadzone Operand Type Vector2 Parameters float min float max A stick deadzone Processor scales the values of a Vector2 Control, such as a stick, so that any input vector with a magnitude smaller than min results in (0,0), and any input vector with a magnitude greater than max is normalized to length 1. Many Controls don't have a precise resting point (that is, they don't always report exactly 0,0 when the Control is in the center). Using the min value on a deadzone Processor avoids unintentional input from such Controls. Also, some Controls don't consistently report their maximum values when moving the axis all the way. Using the max value on a deadzone Processor ensures that you always get the maximum value in such cases. Writing custom Processors You can also write custom Processors to use in your Project. Custom Processors are available in the UI and code in the same way as the built-in Processors. Add a class derived from InputProcessor<TValue>, and implement the Process method: IMPORTANT: Processors must be stateless. This means you cannot store local state in a processor that will change depending on the input being processed. The reason for this is because processors are not part of the input state that the Input System keeps. public class MyValueShiftProcessor : InputProcessor<float> { [Tooltip(\"Number to add to incoming values.\")] public float valueShift = 0; public override float Process(float value, InputControl control) { return value + valueShift; } } Now, you need to tell the Input System about your Processor. Call InputSystem.RegisterProcessor in your initialization code. You can do so locally within the Processor class like this: #if UNITY_EDITOR [InitializeOnLoad] #endif public class MyValueShiftProcessor : InputProcessor<float> { #if UNITY_EDITOR static MyValueShiftProcessor() { Initialize(); } #endif [RuntimeInitializeOnLoadMethod(RuntimeInitializeLoadType.BeforeSceneLoad)] static void Initialize() { InputSystem.RegisterProcessor<MyValueShiftProcessor>(); } //... } Your new Processor is now available in the in the Input Actions Editor and you can also add it in code like this: var action = new InputAction(processors: \"myvalueshift(valueShift=2.3)\"); If you want to customize the UI for editing your Processor, create a custom InputParameterEditor class for it: // No registration is necessary for an InputParameterEditor. // The system will automatically find subclasses based on the // <..> type parameter. #if UNITY_EDITOR public class MyValueShiftProcessorEditor : InputParameterEditor<MyValueShiftProcessor> { private GUIContent m_SliderLabel = new GUIContent(\"Shift By\"); public override void OnEnable() { // Put initialization code here. Use 'target' to refer // to the instance of MyValueShiftProcessor that is being // edited. } public override void OnGUI() { // Define your custom UI here using EditorGUILayout. target.valueShift = EditorGUILayout.Slider(m_SliderLabel, target.valueShift, 0, 10); } } #endif"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ProjectWideActions.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/ProjectWideActions.html",
    "title": "Project-Wide Actions | Inventory System",
    "summary": "Project-Wide Actions The Input System stores your configuration of Input Actions and their associated Bindings, Action Maps and Control Schemes in an Action Asset file. While it's possible to have more than one Action Asset in a project, most projects only ever need a single Action Asset. This is because an Action Asset can contain multiple Action Maps, which each containing a set of actions relevant to the various parts of your project (such as UI navigation, gameplay, etc). The Input System's project-wide actions feature allows you to choose an individual Action Asset as being available project-wide, which means the actions within that asset are available more conveniently through the Input System API without needing to set up a reference to the Actions Asset. The Action Asset assigned as project-wide is also a preloaded asset, loaded when your app starts up, and kept available until until it terminates. Unless you have specific project requirements that require more than one Action Asset, the recommended workflow is to use a single Action Asset assigned as the project-wide actions, as described below. Create and Assign a Project-Wide Actions Asset To create and assign the current project-wide actions, go to Edit > Project Settings > Input System Package. If you don't yet have an Action Asset assigned as project-wide in your project, the Input System Package settings window displays an empty field for you to assign your action asset, and a button allowing you to create and assign one. The Input System Package Project Settings with no project-wide actions assigned Note: If you already have an Action Asset assigned, this button is not displayed, and instead the Actions Editor is displayed, allowing you to edit the project-wide actions. To create an Action Asset with default actions pre-configured, click \"Create a new project-wide Action Asset\". The asset is created in your project, and automatically assigned as the project-wide actions. The Action Asset appears in your Project view, and is named \"InputSystem_Actions\". This is where your new configuration of actions is saved, including any changes you make to it. The new Actions Asset in your Project window Edit project-wide actions Once you have created and assigned project-wide actions, the Input System Package page in Project Settings displays the Actions Editor interface. Read more about how to use the Actions Editor to configure your actions. The Input System Package Project Settings after creating and assigning the default actions The default actions When you create and assign default project-wide actions using the method described above, the Action Asset comes pre-configured with some default Actions such as \"Move\", \"Jump\", and more, which suit many common app and game scenarios. They are configured to read input from the most common types of input controller such as Keyboard, Mouse, Gamepad, Touchscreen and XR. These default actions mean that in many cases, you can start scripting with the Input System without any configuration by referring to the names of the default actions that are already configured for you. You can also rename and reconfigure the default actions, or delete these default configurations to suit your needs. If you’d like to delete all the default actions so that you can start from an empty configuration, you don’t need to delete the individual actions one-by-one. You can delete the each Action Map, which deletes all the Actions contained in the maps in one go. You can also delete all action maps, or reset all the actions back to the default values from the more (⋮) menu at the top right of the Input Actions section of the settings window, below the Project Settings window search field. Note: this more (⋮) menu is not available when the Actions Editor is open in a separate window, it is only present in the Project Settings window. Using project-wide actions in code The benefit of assign an Action Asset as the project-wide actions is that you can access the actions directly through the InputSystem.actions property directly, rather than needing to set up a reference to your Action Asset first. For example, you can get a reference to an action named \"Move\" in your project-wide actions using a line of code like this: InputSystem.actions.FindAction(\"Move\"); Project-wide actions are also enabled by default."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/QuickStartGuide.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/QuickStartGuide.html",
    "title": "Quickstart Guide | Inventory System",
    "summary": "Quickstart Guide This page has a brief description of how to quickly start using the Input System. The Input System has multiple workflows which you might prefer that offer different benefits. This quickstart guide shows a workflow which suits most common scenarios. First, install the Input System package. For information on how to install the new Input System, see Installation. Create and assign the default project-wide actions The input system stores your input configuration in an Actions Asset. When you first install the input system package, you must create this Actions Asset. You can do this by going to by going to Edit > Project Settings > Input System Package > Input Actions, then click the button labelled Create and assign a default project-wide Action Asset. View and edit the default input settings Once you have created and assigned some project-wide actions, the Input Actions Settings window allows you to view and edit your input configuration. The input actions settings window displaying the default actions You can use this window to view the Actions to find out their names, value types, and what their corresponding bindings. You can also edit, delete, or add new Actions here. Read more about using the Input Action Settings Window. The default Action Maps and Actions Action Maps allow you to organise Actions into groups which represent specific situations where a set of actions make sense together. The Input System's default configuration comes with two Action Maps: \"Player\" and \"UI\". These each contain default actions that are typically useful for gameplay and user interface interactions respectively. The \"Player\" Action Map defines several game-related actions such as \"Move\", \"Look\", \"Jump\" and \"Attack\" actions. The \"UI\" action map defines several user-interface-related actions such as \"Navigate\", \"Submit\" and \"Cancel\". Each each default action has bindings to several different types of Control. For example: The \"Move\" action is bound to the \"WSAD\" keyboard keys and arrow keys, a gamepad stick, the primary 2D axis on an XR controller The \"Jump\" action is bound to the space key, the \"south\" button on a gamepad, and the secondary button on an XR controller. Read values from the default Actions The Input System comes pre-configured with some default Actions such as \"Move\", \"Jump\", and more, which suit many common app and game scenarios. They are configured to read input most types of input controller such as Keyboard, Mouse, Gamepad, Touchscreen and XR. This means, in many cases, you can start scripting with the Input System without any configuration. This workflow uses the following steps: Add the Input System \"using\" statement at the top of your script. Create variables to hold the Action references. In your Start method, find the and store the Action references. In your Update method, read the values from the Action references, and add your own code to respond accordingly. These steps are shown in the example script below: using UnityEngine; using UnityEngine.InputSystem; // 1. The Input System \"using\" statement public class Example : MonoBehaviour { // 2. These variables are to hold the Action references InputAction moveAction; InputAction jumpAction; private void Start() { // 3. Find the references to the \"Move\" and \"Jump\" actions moveAction = InputSystem.actions.FindAction(\"Move\"); jumpAction = InputSystem.actions.FindAction(\"Jump\"); } void Update() { // 4. Read the \"Move\" action value, which is a 2D vector // and the \"Jump\" action state, which is a boolean value Vector2 moveValue = moveAction.ReadValue<Vector2>(); // your movement code here if (jumpAction.IsPressed()) { // your jump code here } } } These actions named \"Move\" and \"Jump\" in this script work straight away with no configuration required because they match the names of some of the pre-configured defaults in the Input System package. Note: Different types of Action have different value types, and so have different methods to access their value, which is why you see .ReadValue<Vector2>() used to read a 2D axis, and .IsPressed() to read a button state, in the example above. Note: If you create more than one Action with same name in different Action Maps, you must specify the Action Map and the Action Name separated by a / character when using FindAction. For example: InputSystem.actions.FindAction(\"Player/Move\")"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/RespondingToActions.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/RespondingToActions.html",
    "title": "Responding to Actions | Inventory System",
    "summary": "Responding to Actions There are two main techniques you can use to respond to Actions in your project. These are to either use polling or an event-driven approach. The Polling approach refers to the technique of repeatedly checking the current state of the Actions you are interested in. Typically you would do this in the Update() method of a MonoBehaviour script. The Event-driven approach involves creating your own methods in code that are automatically called when an action is performed. For most common scenarios, especially action games where the user's input should have a continuous effect on an in-game character, Polling is usually simpler and easier to implement. For other situations where input is less frequent and directed to various different GameObjects in your scene, an event-driven approach might be more suitable. Polling Actions You can poll the current value of an Action using InputAction.ReadValue<>(): using UnityEngine; using UnityEngine.InputSystem; public class Example : MonoBehaviour { InputAction moveAction; private void Start() { moveAction = InputSystem.actions.FindAction(\"Move\"); } void Update() { Vector2 moveValue = moveAction.ReadValue<Vector2>(); // your code would then use moveValue to apply movement // to your GameObject } } Note that the value type has to correspond to the value type of the control that the value is being read from. There are two methods you can use to poll for performed action callbacks to determine whether an action was performed or stopped performing in the current frame. These methods differ from InputAction.WasPressedThisFrame() and InputAction.WasReleasedThisFrame() in that these depend directly on the Interactions driving the action (including the default Interaction if no specific interaction has been added to the action or binding). Method Description InputAction.WasPerformedThisFrame() True if the InputAction.phase of the action has, at any point during the current frame, changed to Performed. InputAction.WasCompletedThisFrame() True if the InputAction.phase of the action has, at any point during the current frame, changed away from Performed to any other phase. This can be useful for Button actions or Value actions with interactions like Press or Hold when you want to know the frame the interaction stops being performed. For actions with the default Interaction, this method will always return false for Value and Pass-Through actions (since the phase stays in Started for Value actions and stays in Performed for Pass-Through). This example uses the Interact action from the default actions, which has a Hold interaction to make it perform only after the bound control is held for a period of time (for example, 0.4 seconds): using UnityEngine; using UnityEngine.InputSystem; public class Example : MonoBehaviour { InputAction interactAction; private void Start() { interactAction = InputSystem.actions.FindAction(\"Interact\"); } void Update() { if (interactAction.WasPerformedThisFrame()) { // your code to respond to the first frame that the Interact action is held for enough time } if (interactAction.WasCompletedThisFrame()) { // your code to respond to the frame that the Interact action is released after being held for enough time } } } Finally, there are three methods you can use to poll for button presses and releases: Method Description InputAction.IsPressed() True if the level of actuation on the action has crossed the press point and did not yet fall to or below the release threshold. InputAction.WasPressedThisFrame() True if the level of actuation on the action has, at any point during the current frame, reached or gone above the press point. InputAction.WasReleasedThisFrame() True if the level of actuation on the action has, at any point during the current frame, gone from being at or above the press point to at or below the release threshold. This example uses three actions called Shield, Teleport and Submit (which are not included in the default actions): using UnityEngine; using UnityEngine.InputSystem; public class Example : MonoBehaviour { InputAction shieldAction; InputAction teleportAction; InputAction submitAction; private void Start() { shieldAction = InputSystem.actions.FindAction(\"Shield\"); teleportAction = InputSystem.actions.FindAction(\"Teleport\"); submitAction = InputSystem.actions.FindAction(\"Submit\"); } void Update() { if (shieldAction.IsPressed()) { // shield is active for every frame that the shield action is pressed } if (teleportAction.WasPressedThisFrame()) { // teleport occurs on the first frame that the action is pressed, and not again until the button is released } if (submit.WasReleasedThisFrame()) { // submit occurs on the frame that the action is released, a common technique for buttons relating to UI controls. } } } Responding to Actions using callbacks When you set up callbacks for your Action, the Action informs your code that a certain type of input has occurred, and your code can then respond accordingly. There are several ways to do this: You can use the PlayerInput component to set up callbacks in the inspector. Each Action has a started, performed, and canceled callback. Each Action Map has an actionTriggered callback. The Input System has a global InputSystem.onActionChange callback. InputActionTrace can record changes happening on Actions. The PlayerInput component The PlayerInput component is the simplest way to set up Action callbacks. It provides an interface in the inspector that allows you set up callbacks directly to your methods without requiring intermediate code. Read more about the PlayerInput component. Alternatively, you can implement callbacks entirely from your own code using the following workflow: Action callbacks Every Action has a set of distinct phases it can go through in response to receiving input. Phase Description Disabled The Action is disabled and can't receive input. Waiting The Action is enabled and is actively waiting for input. Started The Input System has received input that started an Interaction with the Action. Performed An Interaction with the Action has been completed. Canceled An Interaction with the Action has been canceled. You can read the current phase of an action using InputAction.phase. The Started, Performed, and Canceled phases each have a callback associated with them: var action = new InputAction(); action.started += context => /* Action was started */; action.performed += context => /* Action was performed */; action.canceled += context => /* Action was canceled */; Each callback receives an InputAction.CallbackContext structure, which holds context information that you can use to query the current state of the Action and to read out values from Controls that triggered the Action (InputAction.CallbackContext.ReadValue). Note: The contents of the structure are only valid for the duration of the callback. In particular, it isn't safe to store the received context and later access its properties from outside the callback. When and how the callbacks are triggered depends on the Interactions present on the respective Bindings. If the Bindings have no Interactions that apply to them, the default Interaction applies. InputActionMap.actionTriggered callback Instead of listening to individual actions, you can listen on an entire Action Map for state changes on any of the Actions in the Action Map. var actionMap = new InputActionMap(); actionMap.AddAction(\"action1\", \"<Gamepad>/buttonSouth\"); actionMap.AddAction(\"action2\", \"<Gamepad>/buttonNorth\"); actionMap.actionTriggered += context => { ... }; The argument received is the same InputAction.CallbackContext structure that you receive through the started, performed, and canceled callbacks. Note: The Input System calls InputActionMap.actionTriggered for all three of the individual callbacks on Actions. That is, you get started, performed, and canceled all on a single callback. InputSystem.onActionChange callback Similar to InputSystem.onDeviceChange, your app can listen for any action-related change globally. InputSystem.onActionChange += (obj, change) => { // obj can be either an InputAction or an InputActionMap // depending on the specific change. switch (change) { case InputActionChange.ActionStarted: case InputActionChange.ActionPerformed: case InputActionChange.ActionCanceled: Debug.Log($\"{((InputAction)obj).name} {change}\"); break; } } InputActionTrace You can trace Actions to generate a log of all activity that happened on a particular set of Actions. To do so, use InputActionTrace. This behaves in a similar way to InputEventTrace for events. Note: InputActionTrace allocates unmanaged memory and needs to be disposed of so that it doesn't create memory leaks. var trace = new InputActionTrace(); // Subscribe trace to single Action. // (Use UnsubscribeFrom to unsubscribe) trace.SubscribeTo(myAction); // Subscribe trace to entire Action Map. // (Use UnsubscribeFrom to unsubscribe) trace.SubscribeTo(myActionMap); // Subscribe trace to all Actions in the system. trace.SubscribeToAll(); // Record a single triggering of an Action. myAction.performed += ctx => { if (ctx.ReadValue<float>() > 0.5f) trace.RecordAction(ctx); }; // Output trace to console. Debug.Log(string.Join(\",\\n\", trace)); // Walk through all recorded Actions and then clear trace. foreach (var record in trace) { Debug.Log($\"{record.action} was {record.phase} by control {record.control}\"); // To read out the value, you either have to know the value type or read the // value out as a generic byte buffer. Here, we assume that the value type is // float. Debug.Log(\"Value: \" + record.ReadValue<float>()); // If it's okay to accept a GC hit, you can also read out values as objects. // In this case, you don't have to know the value type. Debug.Log(\"Value: \" + record.ReadValueAsObject()); } trace.Clear(); // Unsubscribe trace from everything. trace.UnsubscribeFromAll(); // Release memory held by trace. trace.Dispose(); Once recorded, a trace can be safely read from multiple threads as long as it is not concurrently being written to and as long as the Action setup (that is, the configuration data accessed by the trace) is not concurrently being changed on the main thread. Action types Each Action can be one of three different Action types. You can select the Action type in the Input Action editor window, or by specifying the type parameter when calling the InputAction() constructor. The Action type influences how the Input System processes state changes for the Action. The default Action type is Value. Value This is the default Action type. Use this for any inputs which should track continuous changes to the state of a Control. Value type actions continuously monitor all the Controls which are bound to the Action, and then choose the one which is the most actuated to be the Control driving the Action, and report the values from that Control in callbacks, triggered whenever the value changes. If a different bound Control actuated more, then that Control becomes the Control driving the Action, and the Action starts reporting values from that Control. This process is called conflict resolution. This is useful if you want to allow different Controls to control an Action in the game, but only take input from one Control at the same time. When the Action initially enables, it performs an initial state check of all bound Controls. If any of them is actuated, the Action then triggers a callback with the current value. Button This is very similar to Value, but Button type Actions can only be bound to ButtonControl Controls, and don't perform an initial state check like Value Actions do (see the Value section above). Use this for inputs that trigger an Action once every time they are pressed. The initial state check is usually not useful in such cases, because it can trigger actions if the button is still held down from a previous press when the Action was enabled. Pass-Through Pass-Through Actions bypass the conflict resolution process described above for Value Actions and don't use the concept of a specific Control driving the Action. Instead, any change to any bound Control triggers a callback with that Control's value. This is useful if you want to process all input from a set of Controls. Debugging Actions To see currently enabled Actions and their bound Controls, use the Input Debugger. You can also use the InputActionVisualizer component from the Visualizers sample to get an on-screen visualization of an Action's value and Interaction state in real-time. Using Actions with multiple players You can use the same Action definitions for multiple local players (for example, in a local co-op game). For more information, see documentation on the Player Input Manager component."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Sensors.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Sensors.html",
    "title": "Sensor support | Inventory System",
    "summary": "Sensor support Sampling frequency Accelerometer Gyroscope GravitySensor AttitudeSensor LinearAccelerationSensor MagneticFieldSensor LightSensor PressureSensor ProximitySensor HumiditySensor AmbientTemperatureSensor StepCounter HingeAngle Sensors are InputDevices that measure environmental characteristics of the device that the content is running on. Unity currently supports sensors on iOS and Android. Android supports a wider range of sensors than iOS. Note: To test your app on iOS or Android in the editor with sensor input from your mobile device, you can use the Unity Remote as described here. This currently supports Accelerometer, Gyroscope, GravitySensor, AttitudeSensor, and LinearAccelerationSensor. To determine whether a particular sensor is present, you can use its .current getter. // Determine if a Gyroscope sensor device is present. if (Gyroscope.current != null) Debug.Log(\"Gyroscope present\"); Unlike other devices, sensors are disabled by default. To enable a sensor, call InputSystem.EnableDevice()). InputSystem.EnableDevice(Gyroscope.current); To disable a sensor, call InputSystem.DisableDevice(). InputSystem.DisableDevice(Gyroscope.current); To check whether a sensor is currently enabled, use InputDevice.enabled. if (Gyroscope.current.enabled) Debug.Log(\"Gyroscope is enabled\"); Each sensor Device implements a single Control which represents the data read by the sensor. The following sensors are available: Device Android iOS WebGL Control Type Accelerometer Yes Yes Yes(1) acceleration Vector3Control Gyroscope Yes Yes Yes(1) angularVelocity Vector3Control GravitySensor Yes Yes Yes(1) gravity Vector3Control AttitudeSensor Yes Yes Yes(1) attitude QuaternionControl LinearAccelerationSensor Yes Yes Yes(1) acceleration Vector3Control MagneticFieldSensor Yes No No magneticField Vector3Control LightSensor Yes No No lightLevel AxisControl PressureSensor Yes No No atmosphericPressure AxisControl ProximitySensor Yes No No distance AxisControl HumiditySensor Yes No No relativeHumidity AxisControl AmbientTemperatureSensor Yes No No ambientTemperature AxisControl StepCounter Yes Yes No stepCounter IntegerControl HingeAngle Yes No No angle AxisControl Notes: Sensor support for WebGL on Android and iOS devices is available in Unity 2021.2 Sampling frequency Sensors sample continuously at a set interval. You can set or query the sampling frequency for each sensor using the samplingFrequency property. The frequency is expressed in Hertz (number of samples per second). // Get sampling frequency of gyro. var frequency = Gyroscope.current.samplingFrequency; // Set sampling frequency of gyro to sample 16 times per second. Gyroscope.current.samplingFrequency = 16; Accelerometer Use the accelerometer to measure the acceleration of a device. This is useful to control content by moving a device around. It reports the acceleration measured on a device both due to moving the device around, and due to gravity pulling the device down. You can use GravitySensor and LinearAccelerationSensor to get separate values for these. Values are affected by the Compensate Orientation setting. The following code traces all input events on the Accelerometer.current device. private InputEventTrace trace; void StartTrace() { InputSystem.EnableDevice(Accelerometer.current); trace = new InputEventTrace(Accelerometer.current); trace.Enable(); } void Update() { foreach (var e in trace) { //... } trace.Clear(); } Gyroscope Use the gyroscope to measure the angular velocity of a device. This is useful to control content by rotating a device. Values are affected by the Compensate Orientation setting. GravitySensor Use the gravity sensor to determine the direction of the gravity vector relative to a device. This is useful to control content by device orientation. This is usually derived from a hardware Accelerometer, by subtracting the effect of linear acceleration (see LinearAccelerationSensor). Values are affected by the Compensate Orientation setting. AttitudeSensor Use the attitude sensor to determine the orientation of a device. This is useful to control content by rotating a device. Values are affected by the Compensate Orientation setting. Note: On Android devices, there are two types of attitude sensors: RotationVector and GameRotationVector. Some Android devices have both types of sensor, while other devices may only have one or the other type available. These two types of attitude sensor behave slightly differently to each other. You can read about the differences between them here. Because of this variety in what type of rotation sensors are available across devices, when you require input from a rotation sensor on Android devices, you should include code that checks for your preferred type of rotation sensor with a fallback to the alternative type of rotation sensor if it is not present. For example: AttitudeSensor attitudeSensor = InputSystem.GetDevice<AndroidRotationVector>(); if (attitudeSensor == null) { attitudeSensor = InputSystem.GetDevice<AndroidGameRotationVector>(); if (attitudeSensor == null) Debug.LogError(\"AttitudeSensor is not available\"); } if (attitudeSensor != null) InputSystem.EnableDevice(attitudeSensor); LinearAccelerationSensor Use the accelerometer to measure the acceleration of a device. This is useful to control content by moving a device around. Linear acceleration is the acceleration of a device unaffected by gravity. This is usually derived from a hardware Accelerometer, by subtracting the effect of gravity (see GravitySensor). Values are affected by the Compensate Orientation setting. MagneticFieldSensor This Input Device represents the magnetic field that affects the device which is running the content. Values are in micro-Tesla (μT) and measure the ambient magnetic field in the X, Y, and Z axis. LightSensor This Input Device represents the ambient light measured by the device which is running the content. Value is in SI lux units. PressureSensor This Input Device represents the atmospheric pressure measured by the device which is running the content. Value is in in hPa (millibar). ProximitySensor This Input Device measures how close the device which is running the content is to the user. Phones typically use the proximity sensor to determine if the user is holding the phone to their ear or not. Values represent distance measured in centimeters. NOTE: The Samsung devices' proximity sensor is only enabled during calls and not when using speakerphone or Bluetooth earphones. This means the lock screen function won't work, allowing the user to use the display during the call. It is important to note that the proximity sensor only works during non-speakerphone or non-Bluetooth calls, as it is designed to prevent accidental touches during calls. However, the proximity sensor can work slightly differently on different Samsung phones. HumiditySensor This Input Device represents the ambient air humidity measured by the device which is running the content. Values represent the relative ambient air humidity in percent. AmbientTemperatureSensor This Input Device represents the ambient air temperature measured by the device which is running the content. Values represent temperature in Celsius degrees. StepCounter This Input Device represents the user's footstep count as measured by the device which is running the content. NOTE: To access the pedometer on iOS/tvOS devices, you need to enable the Motion Usage setting in the Input Settings. HingeAngle This Input Device represents hinge angle for foldable devices. For ex., Google Fold Android phone. [Serializable] class SensorCapabilities { public int sensorType; public float resolution; public int minDelay; } void Start() { if (HingeAngle.current != null) { InputSystem.EnableDevice(HingeAngle.current); var caps = JsonUtility.FromJson<SensorCapabilities>(HingeAngle.current.description.capabilities); Debug.Log($\"HingeAngle Capabilities: resolution = {caps.resolution}, minDelay = {caps.minDelay}\"); } } void Update() { if (HingeAngle.current != null) Debug.Log($\"HingeAngle={HingeAngle.current.angle.ReadValue()}\"); }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Settings.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Settings.html",
    "title": "Input settings | Inventory System",
    "summary": "Input settings Create Settings Asset Update Mode Background Behavior Filter Noise On Current Compensate Orientation Default value properties Supported Devices Platform-specific settings To configure the Input System individually for each project, go to Edit > Project Settings… > Input System Package from Unity's main menu. This page describes each input setting in detail. Create Settings Asset When you first view the input settings, they are not editable, and instead a button to Create settings asset is displayed at the top of the input settings window. If you want to customise the input settings, you must first click this button, which creates a settings asset in your Project. Once your project contains a settings asset, the Create settings asset is no longer displayed, and the settings fields become editable. Unity saves changes to your settings in the settings asset when you save the project. If your project contains multiple settings assets, you can use the gear menu in the top-right corner of the window to choose which asset to use. You can also use this menu to create additional settings assets. Update Mode This setting determines when the Input System processes input. The Input System can process input in one of three distinct ways: Type Description Process Events In Dynamic Update The Input System processes events at irregular intervals determined by the current framerate. Process Events In Fixed Update The Input System processes events at fixed-length intervals. This corresponds to how MonoBehaviour.FixedUpdate operates. The length of each interval is determined by Time.fixedDeltaTime. Process Events Manually The Input System does not process events automatically. Instead, it processes them whenever you call InputSystem.Update(). Note: The system performs two additional types of updates in the form of InputUpdateType.BeforeRender (late update for XR tracking Devices) and InputUpdateType.Editor (for EditorWindows). Neither of these update types change how the application consumes input. Background Behavior Background Behaviour determines what happens when application focus is lost or regained, and how input behaves while the application is not in the foreground. This setting is only relevant when \"Run In Background\" is enabled in the Player Settings for the project. This setting is only supported on some platforms. On platforms such as Android and iOS, your app will not run when it is not in the foreground. In the Editor, \"Run In Background\" is considered to always be enabled as the player loop is kept running regardless of whether a Game View is focused or not. Also, in development players on desktop platforms, the setting is force-enabled during the build process. Note: In the editor, Background Behavior is further influenced by Play Mode Input Behavior. See Background and Focus Change Behavior for a detailed breakdown. In particular, which devices are considered as canRunInBackground partly depends on the Play Mode Input Behavior setting. Setting Description Reset And Disable Non Background Devices When focus is lost, perform a soft reset on all Devices that are not marked as canRunInBackground and also subsequently disable them. Does not affect Devices marked as being able to run in the background. When focus is regained, re-enable any Device that has been disabled and also issue a sync request on these Devices in order to update their current state. If a Device is issued a sync request and does not respond to it, soft-reset the Device. This is the default setting. Reset And Disable All Devices When focus is lost, perform a soft reset on all Devices and also subsequently disable them. When focus is regained, re-enable all Devices and also issue a sync request on each Device in order to update it to its current state. If a device does not respond to the sync request, soft-reset it. Ignore Focus Do nothing when focus is lost. When focus is regained, issue a sync request on all Devices. Focus behavior has implications for how Actions behave on focus changes. When a Device is reset, Actions bound to Controls on the device will be cancelled. This ensures, for example, that a user-controlled character in your game doesn't continue to move when focus is lost while the user is pressing one of the W, A, S or D keys. The cancellation happens in such a way that Actions are guaranteed to not trigger. That is, even if an Action is set to trigger on button release, it will not get triggered when a button is down and gets reset by a Device reset. Filter Noise On Current This setting is disabled by default, and it's only relevant for apps that use the .current properties (such as Gamepad.current) in the API. If your app doesn't use these properties, leave this setting disabled. Otherwise, it adds needless overhead. Whenever there is input on a Device, the system make the respective Device .current. For example, if a Gamepad receives new input, Gamepad.current is assigned to that gamepad. Some Devices have noise in their input, and receive input even if nothing is interacting with them. For example, the PS4 DualShock controller generates a constant stream of input because of its built-in gyro. This means that if both an Xbox and a PS4 controller are connected, and the user is using the Xbox controller, the PS4 controller still pushes itself to the front continuously and makes itself current. To counteract this, enable noise filtering. When this setting is enabled and your application receives input, the system determines whether the input comes from a Device that has noisy Controls (InputControl.noisy). If it does, the system also determines whether the given input contains any state changes on a Control that isn't flagged as noisy. If so, that Device becomes current. Otherwise, your application still consumes the input, which is also visible on the Device, but the Device doesn't become current. Note: The system doesn't currently detect most forms of noise, but does detect those on gamepad sticks. This means that if the sticks wiggle a small amount but are still within deadzone limits, the Device still becomes current. This doesn't require actuating the sticks themselves. On most gamepads, there's a small tolerance within which the sticks move when the entire device moves. Compensate Orientation If this setting is enabled, rotation values reported by sensors are rotated around the Z axis as follows: Screen orientation Effect on rotation values ScreenOrientation.Portrait Values remain unchanged ScreenOrientation.PortraitUpsideDown Values rotate by 180 degrees. ScreenOrientation.LandscapeLeft Values rotate by 90 degrees. ScreenOrientation.LandscapeRight Values rotate by 270 degrees. This setting affects the following sensors: Gyroscope GravitySensor AttitudeSensor Accelerometer LinearAccelerationSensor Default value properties Property Description Default Deadzone Min The default minimum value for Stick Deadzone or Axis Deadzone processors when no min value is explicitly set on the processor. Default Deadzone Max The default maximum value for Stick Deadzone or Axis Deadzone processors when no max value is explicitly set on the processor. Default Button Press Point The default press point for Button Controls, and for various Interactions. For button Controls which have analog physics inputs (such as triggers on a gamepad), this configures how far they need to be held down for the system to consider them pressed. Default Tap Time Default duration for Tap and MultiTap Interactions. Also used by by touchscreen Devices to distinguish taps from to new touches. Default Slow Tap Time Default duration for SlowTap Interactions. Default Hold Time Default duration for Hold Interactions. Tap Radius Maximum distance between two finger taps on a touchscreen Device for the system to consider this a tap of the same touch (as opposed to a new touch). Multi Tap Delay Time Default delay between taps for MultiTap Interactions. Also used by touchscreen Devices to count multi-taps (See TouchControl.tapCount). Supported Devices A Project usually supports a known set of input methods. For example, a mobile app might support only touch, and a console application might support only gamepads. A cross-platform application might support gamepads, mouse, and keyboard, but might not require XR Device support. To narrow the options that the Editor UI presents to you, and to avoid creating input Devices and consuming input that your application won't use, you can restrict the set of supported Devices on a per-project basis. If Supported Devices is empty, no restrictions apply, which means that the Input System adds any Device that Unity recognizes and processes input for it. However, if Support Devices contains one or more entries, the Input System only adds Devices that are of one of the listed types. Note: When the Support Devices list changes, the system removes or re-adds Devices as needed. The system always keeps information about what Devices are available for potential, which means that no Device is permanently lost as long as it stays connected. To add Devices to the list, click the Add (+) icon and choose a Device from the menu that appears. Override in Editor In the Editor, you might want to use input Devices that the application doesn't support. For example, you might want to use a tablet in the Editor even if your application only supports gamepads. To force the Editor to add all locally available Devices, even if they're not in the list of Supported Devices, open the Input Debugger (menu: Window > Analysis > Input Debugger), and select Options > Add Devices Not Listed in 'Supported Devices'. Note: This setting is stored as a user setting, not a project setting. This means other users who open the project in their own Editor do not share the setting. Platform-specific settings iOS/tvOS Motion Usage Governs access to the pedometer on the device. If you enable this setting, the Description field becomes editable. The text you enter into the Description field is added to your application's Info.plist. Editor Play Mode Input Behavior Play Mode Input Behavior determines how input is handled in the Editor when in play mode. Unlike in built players, in the Unity Editor the input back-ends keep running for as long as the Editor is active, regardless of whether a Game View window is focused or not. This setting determines how input should behave when focus is not on any Game View – and thus Application.isFocused is false and the player considered to be running in the background. Setting Description Pointers And Keyboards Respect Game View Focus Only Pointer and Keyboard Devices require the Game View to be focused. Other Devices will route their input into the application regardless of Game View focus. This setting essentially routes any input into the game that is, by default, not used to operate the Editor UI. So, Devices such as gamepads will go to the application at all times when in play mode whereas keyboard input, for example, will require explicitly giving focus to a Game View window. This setting is the default. All Devices Respect Game View Focus Focus on a Game View is required for all Devices. When no Game View window is focused, all input goes to the editor and not to the application. This allows other EditorWindows to receive these inputs (from gamepads, for example). All Device Input Always Goes To Game View All editor input is disabled and input is considered to be exclusive to Game Views. Also, Background Behavior is to be taken literally and executed like in players. Meaning, if in a certain situation, a Device is disabled in the player, it will get disabled in the editor as well. This setting most closely aligns player behavior with editor behavior. Be aware, however, that no EditorWindows will be able to see input from Devices (this does not effect IMGUI and UITK input in the Editor in general as they do not consume input from the Input System). Input Action Property Drawer Mode Determines how the Inspector window displays InputActionProperty fields. This setting is not shown in the Edit > Project Settings window, it is instead only available in the Debug mode of the Inspector window of an Input Settings asset. See the Unity Manual page for working in the Inspector under section Toggle Debug Mode. Setting Description Compact Display the property in a compact format, using a minimal number of lines. Toggling between a reference to an input action in an asset and a directly serialized input action is done using a dropdown menu. Multiline Effective Display the effective action underlying the property, using multiple lines. Toggling between a reference to an input action in an asset and a directly serialized input action is done using a property that is always visible. This mode could be useful if you want to see or revert prefab overrides and hide the field that is ignored. Multiline Both Display both the input action and external reference underlying the property. Toggling between a reference to an input action in an asset and a directly serialized input action is done using a property that is always visible. This mode could be useful if you want to see both values of the property without needing to toggle Use Reference."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/SupportedDevices.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/SupportedDevices.html",
    "title": "Supported Input Devices | Inventory System",
    "summary": "Supported Input Devices This page lists Input Device types and products that the Input System package supports, and the platforms they're supported on. Generic Support for the following Devices doesn't require specialized support of particular products. Device Windows Mac Linux UWP Android iOS tvOS Xbox(3) PS4(3) Switch(3) WebGL Mouse Yes Yes Yes Yes Yes No No Yes Yes No Yes Keyboard Yes Yes Yes Yes Yes No No Yes Yes No Yes Pen Yes No (1) No Yes Yes Yes No No No No No Touchscreen Yes No No Yes Yes Yes Yes(4) No No No Yes Sensors No No No No Yes Yes No No No No Yes(5) Joystick (2) Yes Yes Yes Yes Yes No No No No No Yes Notes: Tablet support for macOS is coming in Unity 2020.1. Joysticks are supported as generic HIDs (See Other gamepads, joysticks, and racing wheels below). Consoles are supported using separate packages. You need to install these packages in your Project to enable console support. Indirect touches are received from Siri Remote. Sensor support for WebGL on Android and iOS devices is available in Unity 2021.2 Gamepads Device Windows Mac Linux UWP(13) Android iOS(6) tvOS(6) Xbox(7) PS4/PS5(7) Switch(7) WebGL Xbox 360 (4) Yes Yes (3) Yes Yes No No No Yes No No Sometimes (2) Xbox One Yes (1) Yes (3) Yes (1) Yes Yes (1) Yes (6) Yes (6) Yes No No Sometimes (2) PS3/PS4 Yes (5) Yes (5) Yes (5) Yes (5) Yes (5, 8) Yes (5, 6) Yes (5, 6) No Yes No Sometimes (2) PS5 Yes (11) Yes (11) No (11) Yes (11) Yes (9, 11) No (11) No (11) No Yes No Sometimes (2) Switch Yes (10) Yes (10) Yes Yes No No No No No Yes Sometimes (2) MFi (such as SteelSeries) No Sometimes (12) No No No Yes Yes No No No No Notes: The trigger motors on the Xbox One controller are only supported on UWP and Xbox. WebGL support varies between browsers, Devices, and operating systems. XInput controllers on Mac currently require the installation of the Xbox Controller Driver for macOS. This driver only supports only USB connections, and doesn't support wireless dongles. However, the latest generation of Xbox One controllers natively support Bluetooth, and are natively supported on Macs as HIDs without any additional drivers when connected via Bluetooth. This includes any XInput-compatible Device. Unity doesn't support motor rumble and lightbar color over Bluetooth. Unity doesn't support the gyro or accelerometer on PS4/PS5 controllers on platforms other than the PlayStation consoles. Unity also doesn't support the DualShock 4 USB Wireless Adaptor. On UWP only USB connection is supported, motor rumble and lightbar are not working correctly. Unity supports Made for iOS (Mfi) certified controllers on iOS. Xbox One and PS4 controllers are only supported on iOS 13 or higher. Consoles are supported using separate packages. You need to install these packages in your Project to enable console support. Unity supports PS4 controllers on Android devices running Android 10 or higher. Unity supports PS5 controllers on Android devices running Android 12 or higher. Switch Joy-Cons are not currently supported on Windows and Mac. Some of official accessories are supported on Windows and Mac: \"Hori Co HORIPAD for Nintendo Switch\", \"HORI Pokken Tournament DX Pro Pad\", \"HORI Wireless Switch Pad\", \"HORI Real Arcade Pro V Hayabusa in Switch Mode\", \"PowerA NSW Fusion Wired FightPad\", \"PowerA NSW Fusion Pro Controller (USB only)\", \"PDP Wired Fight Pad Pro: Mario\", \"PDP Faceoff Wired Pro Controller for Nintendo Switch\", \"PDP Faceoff Deluxe Wired Pro Controller for Nintendo Switch\", \"PDP Afterglow Wireless Switch Controller\", \"PDP Rockcandy Wired Controller\". PS5 DualSense is supported on Windows and macOS via USB HID, though setting motor rumble and lightbar color when connected over Bluetooth is currently not supported. SteelSeries Nimbus+ supported via HID on macOS. On UWP only USB connection is supported, motor rumble and lightbar are not working correctly. On Android it's expected to be working from Android 12. On iOS/tvOS it's currently recognized as a generic gamepad and most controls do work. To ensure all controller types are detected on UWP, enable the HumanInterfaceDevice setting in UWP Player Settings. WebGL The Input System supports the Standard Gamepad mapping as specified in the W3C Gamepad Specification. It also supports gamepads and joysticks that the browser surfaces without a mapping, but this support is generally limited to detecting the axes and buttons which are present, without any context as to what they mean. This means gamepads and joysticks are generally only useful when the user manually remaps them. The Input System reports these Devices as generic Joysticks. Support varies between browsers, Devices, and operating systems, and further differs for different browser versions, so it's not feasible to provide an up-to-date compatibility list. At the time of this publication (September 2019), Safari, Chrome, Edge, and Firefox all support the gamepad API, but only Chrome reliably maps common gamepads (Xbox and PlayStation controllers) to the W3C Standard Gamepad mapping, which allows the Input System to correctly identify and map controls. Note: WebGL currently doesn't support rumble. Other gamepads, joysticks, and racing wheels The Input System supports any Device which implements the USB HID specification. However, for Devices which don't have specific layouts implemented in the Input System, the system can only surface the information available from the HID descriptor of the Device, which limits how precisely it can describe a control. These Devices often work best when allowing the user to manually remap the controls. If you need to support a specific Device, you can also add your own mapping for it. See documentation on HID for more information."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Introduction Installation Quickstart Guide Concepts Workflows Workflow - Actions Workflow - Actions & PlayerInput Workflow - Direct Using the Input System Project-Wide Actions Configuring Input Actions Responding to Actions Input Action Assets Input Bindings Interactions Devices Controls Processors Player Input Component Player Input Manager Component Input settings Advanced Topics Events Layouts User Management Timing and latency Input events queue Select an input processing mode Optimize for dynamic update Optimize for fixed update Avoid missed or duplicate events Mixed timing scenarios Supported Input Devices Pointers Touch support Mouse support Pen, tablet, and stylus support Keyboard support Gamepad support Joystick support Sensor support HID support UI support On-screen Controls Editor Features Using Input in the Editor Debugging Input testing How do I...? Architecture Migrating from the old Input Manager Contributing Known Limitations"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Testing.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Testing.html",
    "title": "Input testing | Inventory System",
    "summary": "Input testing The Input System has built-in support for writing automated input tests. You can drive input entirely from code, without any dependencies on platform backends and physical hardware devices. The automated input tests you write consider the generated input to be the same as input generated at runtime by actual platform code. Setting up test assemblies To set up a test assembly that uses the Input System's automation framework, follow these steps: In the Packages/manifest.json file of your project, com.unity.inputsystem must be listed in testables. This is necessary for test code that comes with the package to be included with test builds of your project. You can, for example, add this after the dependencies property like so: }, \"testables\" : [ \"com.unity.inputsystem\" ] Create a new assembly definition (menu: Create > Assembly Definition) or go to an assembly definition for a test assembly that you have already created. Add references to nunit.framework.dll, UnityEngine.TestRunner, and UnityEditor.TestRunner (as described in How to create a new test assembly), as well as Unity.InputSystem and Unity.InputSystem.TestFramework for the Input System. Setting up test fixtures Use InputTestFixture to create an isolated version of the Input System for tests. The fixture sets up a blank, default-initialized version of the Input System for each test, and restores the Input System to its original state after the test completes. The default-initialized version has all built-in registrations (such as layout and processors), but doesn't have any pre-existing Input Devices. NOTE: InputTestFixture will not have custom registrations performed from Unity startup code such as [InitializeOnLoad] or [RuntimeInitializeOnLoadMethod]. Layouts needed during tests have to be manually registered as part of the test setup. You can use the fixture as a base class for your own fixture: class MyTests : InputTestFixture { [Test] public void CanPressButtonOnGamepad() { var gamepad = InputSystem.AddDevice<Gamepad>(); Press(gamepad.buttonSouth); } // If you need custom setup and tear-down logic, override the methods inherited // from InputTestFixture. // IMPORTANT: If you use NUnit's [Setup] and [TearDown] attributes on methods in your // test fixture, this will *override* the methods inherited from // InputTestFixture and thus cause them to not get executed. Either // override the methods as illustrated here or call the Setup() and // TearDown() methods of InputTestFixture explicitly. public override void Setup() { base.Setup(); // Add setup code here. } public override void TearDown() { // Add teardown code here. base.TearDown(); } } IMPORTANT: If you do this, do not add a [SetUp] or [TearDown] method. Doing so will cause the methods in InputTestFixture to not be called, thus leading to the test fixture not properly initializing or shutting down. Instead, override the Setup and/or TearDown method inherited from InputTestFixture. Alternatively, you can instantiate it in your fixture: [TestFixture] class MyTestFixture { private InputTestFixture input = new InputTestFixture(); // NOTE: You have to manually call Setup() and TearDown() in this scenario. [SetUp] void Setup() { input.Setup(); } [TearDown] void TearDown() { input.TearDown(); } } This is especially useful when creating a larger setup for game testing using PrebuiltSetup. [PrebuildSetup(\"GameTestPrebuildSetup\")] public class GameTestFixture { public Game game { get; set; } public InputTestFixture input { get; set; } public Mouse mouse { get; set; } public Keyboard keyboard { get; set; } public Touchscreen touchscreen { get; set; } public Gamepad gamepad { get; set; } //... } #if UNITY_EDITOR public class GameTestPrebuildSetup : IPrebuildSetup { public void Setup() { UnityEditor.EditorBuildSettings.scenes = new[] { new UnityEditor.EditorBuildSettingsScene(\"Assets/Scenes/Main.unity\", true) }; } } #endif Note that you do not generally need to clean up any input-related data you set up. This includes devices you add, layouts you registered, InputSettings you modify, and any other alteration to the state of InputSystem. InputTestFixture will automatically throw away the current state of the Input System and restore the state from before the test was started. Writing tests When writing a test, use InputSystem.AddDevice<T>() to add new Devices. [Test] public void PlayerInput_CanInstantiatePlayer_WithSpecificControlScheme() { InputSystem.AddDevice<Gamepad>(); var keyboard = InputSystem.AddDevice<Keyboard>(); var mouse = InputSystem.AddDevice<Mouse>(); var prefab = new GameObject(); prefab.SetActive(false); var prefabPlayerInput = prefab.AddComponent<PlayerInput>(); prefabPlayerInput.actions = InputActionAsset.FromJson(kActions); var player = PlayerInput.Instantiate(prefab, controlScheme: \"Keyboard&Mouse\"); Assert.That(player.devices, Is.EquivalentTo(new InputDevice[] { keyboard, mouse })); Assert.That(player.controlScheme, Is.EqualTo(\"Keyboard&Mouse\")); } To feed input, the easiest way is to use the Press(button), Release(button), PressAndRelease(button), Set(control,value), and Trigger(action) helper methods provided by InputTestFixture. [Test] public void Actions_WhenDisabled_CancelAllStartedInteractions() { var gamepad = InputSystem.AddDevice<Gamepad>(); var action1 = new InputAction(\"action1\", binding: \"<Gamepad>/buttonSouth\", interactions: \"Hold\"); var action2 = new InputAction(\"action2\", binding: \"<Gamepad>/leftStick\"); action1.Enable(); action2.Enable(); Press(gamepad.buttonSouth); Set(gamepad.leftStick, new Vector2(0.123f, 0.234f)); using (var trace = new InputActionTrace()) { trace.SubscribeTo(action1); trace.SubscribeTo(action2); runtime.currentTime = 0.234f; runtime.advanceTimeEachDynamicUpdate = 0; action1.Disable(); action2.Disable(); var actions = trace.ToArray(); Assert.That(actions.Length, Is.EqualTo(2)); //... } } Alternatively, you can use code to feed arbitrary input events into the system, and run arbitrary input updates: [Test] public void PlayerInput_JoiningPlayerThroughButtonPress_WillFailIfDeviceIsNotUsableWithPlayerActions() { var playerPrefab = new GameObject(); playerPrefab.SetActive(false); playerPrefab.AddComponent<PlayerInput>(); playerPrefab.GetComponent<PlayerInput>().actions = InputActionAsset.FromJson(kActions); var manager = new GameObject(); var listener = manager.AddComponent<MessageListener>(); var managerComponent = manager.AddComponent<PlayerInputManager>(); managerComponent.joinBehavior = PlayerJoinBehavior.JoinPlayersWhenButtonIsPressed; managerComponent.playerPrefab = playerPrefab; // Create a Device based on the HID layout with a single button control. const string kLayout = @\" { \"\"name\"\" : \"\"TestDevice\"\", \"\"extend\"\" : \"\"HID\"\", \"\"controls\"\" : [ { \"\"name\"\" : \"\"button\"\", \"\"layout\"\" : \"\"Button\"\" } ] } \"; InputSystem.RegisterLayout(kLayout); var device = InputSystem.AddDevice(\"TestDevice\"); using (StateEvent.From(device, out var eventPtr)) { ((ButtonControl)device[\"button\"]).WriteValueIntoEvent(1f, eventPtr); InputSystem.QueueEvent(eventPtr); InputSystem.Update(); } Assert.That(listener.messages, Is.Empty); Assert.That(PlayerInput.all, Is.Empty); } Note: For reference, you can find the tests for the Input System itself in its GitHub repository."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Touch.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Touch.html",
    "title": "Touch support | Inventory System",
    "summary": "Touch support Touch support Touchscreen Device Controls Using touch with Actions EnhancedTouch.Touch Class Touch Simulation Reading all touches Touch support is divided into: low-level support implemented in the Touchscreen class. high-level support implemented in the EnhancedTouch.Touch class. Note: You should not use Touchscreen for polling. If you want to read out touches similar to UnityEngine.Input.touches, see EnhancedTouch. If you read out touch state from Touchscreen directly inside of the Update or FixedUpdate methods, your app will miss changes in touch state. Touch input is supported on Android, iOS, Windows, and the Universal Windows Platform (UWP). Note: To test your app on iOS or Android in the editor with touch input from your mobile device, you can use the Unity Remote as described here. Touchscreen Device At the lowest level, a touch screen is represented by an InputSystem.Touchscreen Device which captures the touch screen's raw state. Touch screens are based on the Pointer layout. To query the touch screen that was last used or last added, use Touchscreen.current. Controls Additional to the Controls inherited from Pointer, touch screen Devices implement the following Controls: Control Type Description primaryTouch TouchControl A touch Control that represents the primary touch of the screen. The primary touch drives the Pointer representation on the Device. touches ReadOnlyArray<TouchControl> An array of touch Controls that represents all the touches on the Device. A touch screen Device consists of multiple TouchControls. Each of these represents a potential finger touching the Device. The primaryTouch Control represents the touch which is currently driving the Pointer representation, and which should be used to interact with the UI. This is usually the first finger that touches the screen. primaryTouch is always identical to one of the entries in the touches array. The touches array contains all the touches that the system can track. This array has a fixed size, regardless of how many touches are currently active. If you need an API that only represents active touches, see the higher-level EnhancedTouch.Touch class. Each TouchControl on the Device, including primaryTouch, is made up of the following child Controls: Control Type Description position Vector2Control Absolute position on the touch surface. delta Vector2Control The difference in position since the last frame. startPosition Vector2Control The position where the finger first touched the surface. startTime DoubleControl The time when the finger first touched the surface. press ButtonControl Whether the finger is pressed down. pressure AxisControl Normalized pressure with which the finger is currently pressed while in contact with the pointer surface. radius Vector2Control The size of the area where the finger touches the surface. touchId IntegerControl The ID of the touch. This allows you to distinguish individual touches. phase TouchPhaseControl A Control that reports the current TouchPhase of the touch. tap ButtonControl A button Control that reports whether the OS recognizes a tap gesture from this touch. tapCount IntegerControl Reports the number of consecutive tap reports from the OS. You can use this to detect double- and multi-tap gestures. Using touch with Actions You can use touch input with Actions, like any other Pointer Device. To do this, bind to the pointer Controls, like <Pointer>/press or <Pointer>/delta. This gets input from the primary touch, and any other non-touch pointer Devices. However, if you want to get input from multiple touches in your Action, you can bind to individual touches by using Bindings like <Touchscreen>/touch3/press. Alternatively, use a wildcard Binding to bind one Action to all touches: <Touchscreen>/touch*/press. If you bind a single Action to input from multiple touches, you should set the Action type to pass-through so the Action gets callbacks for each touch, instead of just one. EnhancedTouch.Touch Class The EnhancedTouch.Touch class provides a polling API for touches similar to UnityEngine.Input.touches. You can use it to query touches on a frame-by-frame basis. Because the API comes with a certain overhead due to having to record touches as they happen, you must explicitly enable it. To do this, call EnhancedTouchSupport.Enable(): using UnityEngine.InputSystem.EnhancedTouch; // ... // Can be called from MonoBehaviour.Awake(), for example. Also from any // RuntimeInitializeOnLoadMethod code. EnhancedTouchSupport.Enable(); Note: Touchscreen does not require EnhancedTouchSupport to be enabled. You only need to call EnhancedTouchSupport.Enable() if you want to use the EnhancedTouch.Touch API. The EnhancedTouch.Touch API is designed to provide access to touch information along two dimensions: By finger: Each finger is defined as the Nth contact source on a Touchscreen. You can use Touch.activeFingers to get an array of all currently active fingers. By touch: Each touch is a single finger contact with at least a beginning point (PointerPhase.Began) and an endpoint (PointerPhase.Ended or PointerPhase.Cancelled). Between those two points, an arbitrary number of PointerPhase.Moved and/or PointerPhase.Stationary records exist. All records in a touch have the same touchId. You can use Touch.activeTouches to get an array of all currently active touches. This lets you track how a specific touch moves over the screen, which is useful if you want to implement recognition of specific gestures. See EnhancedTouch.Touch API documentation for more details. Note: The Touch and Finger APIs don't generate GC garbage. The bulk of the data is stored in unmanaged memory that is indexed by wrapper structs. All arrays are pre-allocated. Touch Simulation Touch input can be simulated from input on other kinds of Pointer devices such as Mouse and Pen devices. To enable this, you can either add the TouchSimulation MonoBehaviour to a GameObject in your scene or simply call TouchSimulation.Enable somewhere in your startup code. void OnEnable() { TouchSimulation.Enable(); } In the editor, you can also enable touch simulation by toggling \"Simulate Touch Input From Mouse or Pen\" on in the \"Options\" dropdown of the Input Debugger. TouchSimulation will add a Touchscreen device and automatically mirror input on any Pointer device to the virtual touchscreen device. Reading all touches To get all current touches from the touchscreen, use EnhancedTouch.Touch.activeTouches, as in this example: using Touch = UnityEngine.InputSystem.EnhancedTouch.Touch; public void Update() { foreach (var touch in Touch.activeTouches) Debug.Log($\"{touch.touchId}: {touch.screenPosition},{touch.phase}\"); } Note: You must first enable enhanced touch support by calling InputSystem.EnhancedTouchSupport.Enable(). You can also use the lower-level Touchscreen.current.touches API."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UISupport.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UISupport.html",
    "title": "UI support | Inventory System",
    "summary": "UI support Overview and compatibility Setting up UI input Required Actions for UI The UI Input Module component Using the UI Input Module UI Input Module properties How the bindings work Other notes about the UI Input Module Multiplayer UIs Virtual mouse cursor control Using the Virtual Mouse component Distinguishing between UI and game input Handling ambiguities for pointer-type input Handling ambiguities for navigation-type input Immediate Mode GUI Overview and compatibility Unity has various UI solutions. The Input System package's compatibility and workflow with these solutions varies depending on which UI solution you are using, and which version of Unity you are using. In some cases you must use the UI Input Module (a component supplied in the Input System package) to define which actions are passed through from the Input System to the UI. The three main UI solutions are UI Toolkit, Unity UI, and IMGUI. The compatibility and workflow for each of these are as follows: For UI Toolkit, also known as \"UI Elements\" (an XML/CSS style UI solution): From Unity 2023.2 and onwards, the UI actions defined in the default project-wide actions directly map to UI Toolkit input. You do not need to use the UI Input Module component. In versions of Unity prior to 2023.2, you must use the UI Input Module component to define which actions are passed through from the Input System to the UI. Refer to UI Toolkit Runtime UI event system and input handling for more information on how to configure UI Toolkit input. For Unity UI, also known as \"uGUI\" (a GameObject and Component style UI solution): When using Unity UI (uGUI), you must always use the UI Input Module component to define which actions are passed through from the Input System to the UI. For IMGUI (a script-based \"Immediate Mode\" UI using the OnGUI method): The Input System package is not compatible with IMGUI, however you can still use the Input System for other parts of your project such as gameplay. See the Immediate Mode GUI section for more information. The compatibility above is summarized in the following table: UI Solution Compatible UI Input Module component UI Toolkit (2023.2+) Yes Not required UI Toolkit (pre 2023.2) Yes Required Unity UI (uGUI) Yes Required IMGUI No n/a Setting up UI input The default project-wide actions comes with a \"UI\" Action Map, that contains all the actions required for UI interaction (shown in the image below). You can configure the bindings for these actions in the Actions Editor. Go to Project Settings > Input System Package, then select \"UI\" in the Action Maps column. Required Actions for UI The default project-wide actions comes with all the required actions to be compatible with UI Toolkit and Unity UI. You can modify, add, or remove bindings to the named actions in the UI action map to suit your project, however in order to remain compatible with UI Toolkit, the name of the action map (\"UI\"), the names of the actions it contains, and their respective Action Types must remain the same. These specific actions and types, which are expected by the UI Input Module class, are as follows: Action Type Control Type Description Navigate PassThrough Vector2 A vector used to select the currently active UI selectable in gamepad or arrow-key navigation-type input. Submit Button Button Submits the currently selected UI selectable in navigation-type input Cancel Button Button Exits any interaction with the currently selected UI selectable in navigation-type input Point PassThrough Vector2 A 2D screen position. The cursor for pointer-type interaction. Click PassThrough Button The primary button for pointer-type interaction. RightClick PassThrough Button The secondary button for pointer-type interaction. MiddleClick PassThrough Button The middle button for pointer-type interaction. ScrollWheel PassThrough Vector2 The scrolling gesture for pointer-type interaction. Tracked Device Position PassThrough Vector3 A 3D position of one or multiple spatial tracking devices, such as XR hand controllers. In combination with Tracked Device Orientation, this allows XR-style UI interactions by pointing at UI selectables in space. See tracked-type input. Tracked Device Orientation PassThrough Quaternion a Quaternion representing the rotation of one or multiple spatial tracking devices, such as XR hand controllers. In combination with Tracked Device Position, this allows XR-style UI interactions by pointing at UI selectables in space. See tracked-type input. You can also reset the UI action map to its default bindings by selecting Reset from the More (⋮) menu, at the top right of the actions editor window. However, this will reset both the 'Player' and 'UI' action maps to their default bindings. The UI Input Module component When working with Unity UI (uGUI), or when using UI Toolkit in versions of Unity prior to Unity 2023.2, you must use the UI Input Module component which defines which actions are passed through to your UI, as well as some other UI-related input settings. Note: If you have an instance of the Input System UI Input Module component in your scene, the settings on that component takes priority and are used instead of the UI settings in your project-wide actions. Also, The UI action map will be enabled, along with the default action map specified on any UI Input Module component in the scene. The UI Input module is implemented in the class InputSystemUIInputModule. Using the UI Input Module The UI Input Module is a component which you must add to a GameObject in your scene in order for your UI to receive input from the Input System. To do this: Create a new empty GameObject Click Add Component in the inspector In the search field displayed, type \"Input System UI Input Module\" Select Input System UI Input Module to add it to the GameObject. UI Input Module properties You can use the following properties to configure InputSystemUIInputModule: Property Description Move Repeat Delay The initial delay (in seconds) between generating an initial IMoveHandler.OnMove navigation event and generating repeated navigation events when the Move Action stays actuated. Move Repeat Rate The interval (in seconds) between generating repeat navigation events when the Move Action stays actuated. Note that this is capped by the frame rate; there will not be more than one move repeat event each frame so if the frame rate dips below the repeat rate, the effective repeat rate will be lower than this setting. Actions Asset An Input Action Asset containing all the Actions to control the UI. You can choose which Actions in the Asset correspond to which UI inputs using the following properties. By default, this references a built-in Asset named DefaultInputActions, which contains common default Actions for driving UI. If you want to set up your own Actions, create a custom Input Action Asset and assign it here. When you assign a new Asset reference to this field in the Inspector, the Editor attempts to automatically map Actions to UI inputs based on common naming conventions. Deselect on Background Click By default, when the pointer is clicked and does not hit any GameObject, the current selection is cleared. This, however, can get in the way of keyboard and gamepad navigation which will want to work off the currently selected object. To prevent automatic deselection, set this property to false. Pointer Behavior How to deal with multiple pointers feeding input into the UI. See pointer-type input. Cursor Lock Behavior Controls the origin point of UI raycasts when the cursor is locked. How the bindings work The UI input module can deal with three different types of input: Pointer-type input Navigation-type input Tracked-type input For each of these types of input, input is sourced and combined from a specific set of Actions as detailed below. Pointer-type input To the UI, a pointer is a position from which clicks and scrolls can be triggered to interact with UI elements at the pointer's position. Pointer-type input is sourced from point, leftClick, rightClick, middleClick, and scrollWheel. The UI input module does not have an association between pointers and cursors. In general, the UI is oblivious to whether a cursor exists for a particular pointer. However, for mouse and pen input, the UI input module will respect Cusor.lockState and pin the pointer position at (-1,-1) whenever the cursor is locked. This behavior can be changed through the Cursor Lock Behavior property of the InputSystemUIInputModule. Multiple pointer Devices may feed input into a single UI input module. Also, in the case of Touchscreen, a single Device can have the ability to have multiple concurrent pointers (each finger contact is one pointer). Because multiple pointer Devices can feed into the same set of Actions, it is important to set the action type to PassThrough. This ensures that no filtering is applied to input on these actions and that instead every input is relayed as is. From the perspective of InputSystemUIInputModule, each InputDevice that has one or more controls bound to one of the pointer-type actions is considered a unique pointer. Also, for each Touchscreen devices, each separate TouchControl that has one or more of its controls bound to the those actions is considered its own unique pointer as well. Each pointer receives a unique pointerId which generally corresponds to the deviceId of the pointer. However, for touch, this will be a combination of deviceId and touchId. Use ExtendedPointerEventData.touchId to find the ID for a touch event. You can influence how the input module deals with concurrent input from multiple pointers using the Pointer Behavior setting. Pointer Behavior Description Single Mouse or Pen But Multi Touch And Track Behaves like Single Unified Pointer for all input that is not classified as touch or tracked input, and behaves like All Pointers As Is for tracked and touch input. If concurrent input is received on a Mouse and Pen, for example, the input of both is fed into the same UI pointer instance. The position input of one will overwrite the position of the other. Note that when input is received from touch or tracked devices, the single unified pointer for mice and pens is removed including IPointerExit events being sent in case the mouse/pen cursor is currently hovering over objects. This is the default behavior. Single Unified Pointer All pointer input is unified such that there is only ever a single pointer. This includes touch and tracked input. This means, for example, that regardless how many devices feed input into Point, only the last such input in a frame will take effect and become the current UI pointer's position. All Pointers As Is The UI input module will not unify any pointer input. Any device, including touch and tracked devices that feed input pointer-type actions, will be its own pointer (or multiple pointers for touch input). Note: This might mean that there will be an arbitrary number of pointers in the UI, and several objects might be pointed at concurrently. If you bind a device to a pointer-type action such as Left Click without also binding it to Point, the UI input module will recognize the device as not being able to point and try to route its input into that of another pointer. For example, if you bind Left Click to the Space key and Point to the position of the mouse, then pressing the space bar will result in a left click at the current position of the mouse. For pointer-type input (as well as for tracked-type input), InputSystemUIInputModule will send ExtendedPointerEventData instances which are an extended version of the base PointerEventData. These events contain additional data such as the device and pointer type which the event has been generated from. Navigation-type input Navigation-type input controls the current selection based on motion read from the move action. Additionally, input from submit will trigger ISubmitHandler on the currently selected object and cancel will trigger ICancelHandler on it. Unlike with pointer-type, where multiple pointer inputs may exist concurrently (think two touches or left- and right-hand tracked input), navigation-type input does not have multiple concurrent instances. In other words, only a single move vector and a single submit and cancel input will be processed by the UI module each frame. However, these inputs need not necessarily come from one single Device always. Arbitrary many inputs can be bound to the respective actions. While, move should be set to PassThrough Action type, it is important that submit and cancel be set to the Button Action type. Navigation input is non-positional, that is, unlike with pointer-type input, there is no screen position associcated with these actions. Rather, navigation actions always operate on the current selection. Tracked-type input Input from tracked devices such as XR controllers and HMDs essentially behaves like pointer-type input. The main difference is that the world-space device position and orientation sourced from trackedDevicePosition and trackedDeviceOrientation is translated into a screen-space position via raycasting. Important: Because multiple tracked Devices can feed into the same set of Actions, it is important to set the action type to PassThrough. This ensures that no filtering is applied to input on these actions and that instead every input is relayed as is. For this raycasting to work, you need to add TrackedDeviceRaycaster to the GameObject that has the UI's Canvas component. This GameObject will usually have a GraphicRaycaster component which, however, only works for 2D screen-space raycasting. You can put TrackedDeviceRaycaster alongside GraphicRaycaster and both can be enabled at the same time without advserse effect. Clicks on tracked devices do not differ from other pointer-type input. Therefore, actions such as Left Click work for tracked devices just like they work for other pointers. Other notes about the UI Input Module Upgrading from the Input Manager and the older Standalone Input Module The Unity UI (uGUI) package contains an older equivalent module called \"Standalone Input Module\" which performs the same kind of integration between the Unity UI and the legacy Input Manager system. If you have one of these older Standalone Input Module components on a GameObject in your project, and the Input System is installed, Unity displays a button in the Inspector offering to automatically replace it with the equivalent newer Input System UI Input Module for you. UI Input Module priority The UI Input Module component is not required with UI Toolkit in Unity 2023.2 and onwards. However, if you do use it, the settings on that component take priority over the UI settings in your project-wide actions. Technical details Input support for both Unity UI and UI Toolkit is based on the same EventSystem and BaseInputModule subsystem. In other words, the same input setup based on InputSystemUIInputModule supports input in either UI solution and nothing extra needs to be done. Internally, UI Toolkit installs an event listener in the form of the PanelEventHandler component which intercepts events that InputSystemUIInputModule sends and translates them into UI Toolkit-specific events that are then routed into the visual tree. If you employ EventSystem.SetUITookitEventSystemOverride, this default mechanism is bypassed. Note: XR (tracked-type input) is not yet supported in combination with UI Toolkit. This means that you cannot use devices such as VR controllers to operate interfaces created with UI Toolkit. There are some additional things worth noting: UI Toolkit handles raycasting internally. No separate raycaster component is needed like for uGUI. This means that TrackedDeviceRaycaster does not work together with UI Toolkit. A pointer click and a gamepad submit action are distinct at the event level in UI Toolkit. This means that if you, for example, do button.RegisterCallback<ClickEvent>(_ => ButtonWasClicked()); the handler is not invoked when the button is \"clicked\" with the gamepad (a NavigationSubmitEvent and not a ClickEvent). If, however, you do button.clicked += () => ButtonWasClicked(); the handle is invoked in both cases. Multiplayer UIs The Input System can also handle multiple separate UI instances on the screen controlled separately from different input Bindings. This is useful if you want to have multiple local players share a single screen with different controllers, so that every player can control their own UI instance. To allow this, you need to replace the Event System component from Unity with the Input System's Multiplayer Event System component. Unlike the Event System component, you can have multiple Multiplayer Event Systems active in the Scene at the same time. That way, you can have multiple players, each with their own UI Input Module and Multiplayer Event System components, and each player can have their own set of Actions driving their own UI instance. If you are using the Player Input component, you can also set it to automatically configure the player's UI Input Module to use the player's Actions. See the documentation on Player Input to learn how. The properties of the Multiplayer Event System component are identical to those from the Event System component. Additionally, the Multplayer Event System component adds a Player Root property, which you can set to a GameObject that contains all the UI selectables this event system should handle in its hierarchy. Mouse input that this event system processes then ignores any UI selectables which are not on any GameObject in the Hierarchy under Player Root. Virtual mouse cursor control If your application uses gamepads and joysticks as an input, you can use the navigation Actions to operate the UI. However, it usually involves extra work to make the UI work well with navigation. An alternative way to operate the UI is to allow gamepads and joysticks to drive the cursor from a \"virtual mouse cursor\". The Input System package provides a Virtual Mouse component for this purpose. Note: This component is only compatible with the Unity UI (uGUI) system, and not UI Toolkit. To see an example of the Virtual Mouse in a project, see the Gamepad Mouse Cursor sample included with the Input System package. Using the Virtual Mouse component To set up the Virtual Mouse component with the Unity UI system: Create a UI GameObject with an Image component. This GameObject is the mouse pointer. It can help to rename it \"Pointer\". Parent the pointer GameObject as a child of your Canvas GameObject that contains the UI which the cursor should operate on. Set the anchor position of the GameObject's RectTransform to the bottom left. Ensure your pointer GameObject is the last child of the Canvas so that the cursor draws on top of everything else. Add a Virtual Mouse component to the GameObject. Drag the Image component of the pointer GameObject into the Cursor Graphic field of the Virtual Mouse component. Drag the Rect Transform component of the pointer GameObject to the Cursor Transform field of the Virtual Mouse component. If you want the virtual mouse to control the system mouse cursor, set Cursor Mode to Hardware Cursor If Available. In this mode, the Cursor Graphic is hidden when a system mouse is present and you use Mouse.WarpCursorPosition to move the system mouse cursor instead of the software cursor. The transform linked through Cursor Transform is not updated in that case. To configure the input to drive the virtual mouse, either add bindings on the various actions (such as Stick Action), or enable Use Reference and link existing actions from an Input Actions asset. Important: Make sure the UI Input Module component on the UI's Event System does not receive navigation input from the same devices that feed into the Virtual Mouse component. If, for example, the Virtual Mouse component is set up to receive input from gamepads, and Move, Submit, and Cancel on the UI Input Module are also linked to the gamepad, then the UI receives input from the gamepad on two channels. At runtime, the component adds a virtual Mouse device which the InputSystemUIInputModule component picks up. The controls of the Mouse are fed input based on the actions configured on the VirtualMouseInput component. Note that the resulting Mouse input is visible in all code that picks up input from the mouse device. You can therefore use the component for mouse simulation elsewhere, not just with InputSystemUIInputModule. Note: Do not set up gamepads and joysticks for navigation input while using the Virtual Mouse component. If both the Virtual Mouse component and navigation are configured, input is triggered twice: once via the pointer input path, and once via the navigation input path. If you encounter problems such as where buttons are pressed twice, this is likely the problem. Distinguishing between UI and game input UI in Unity receives input through the same mechanisms as the input for the rest of your game or app. There is no automatic mechanism that implicitly ensures that if a certain input – such as a click – is consumed by the UI, it is not also received by your gameplay code. This can create ambiguities between, for example, code that responds to UI.Button.onClick and code that responds to InputAction.performed of an Action bound to <Mouse>/leftButton. Whether such ambiguities exist depends on how UIs are used. For example, you can avoid ambiguities by implementing your UI in one of the following ways: All interaction is performed through UI elements. A 2D/3D scene is rendered in the background but all interaction is performed through UI events (including those such as 'background' clicks on the Canvas). UI is overlaid over a 2D/3D scene but the UI elements cannot be interacted with directly. UI is overlaid over a 2D/3D scene but there is a clear \"mode\" switch that determines if interaction is picked up by UI or by the game. For example, a first-person game on desktop may employ a cursor lock and direct input to the game while it is engaged whereas it may leave all interaction to the UI while the lock is not engaged. When ambiguities arise, they do so differently for pointer-type and navigation-type. Note A sample called \"UI vs Game Input\" is provided with the package and can be installed from the Unity Package Manager UI in the editor. The sample demonstrates how to deal with a situation where ambiguities arise between inputs for UI and inputs for the game. Handling ambiguities for pointer-type input Input from pointers (mice, touchscreens, pens) can be ambiguous depending on whether or not the pointer is over a UI element when initiating an interaction. For example, if there is a button on screen, then clicking on the button may lead to a different outcome than clicking outside of the button and within the game scene. If all pointer input is handled via UI events, no ambiguities arise as the UI will implicitly route input to the respective receiver. If, however, input within the UI is handled via UI events and input in the game is handled via Actions, pointer input will by default lead to both being triggered. The easiest way to resolve such ambiguities is to respond to in-game actions by polling from inside MonoBehaviour.Update methods and using EventSystem.IsPointerOverGameObject to find out whether the pointer is over UI or not. Another way is to use EventSystem.RaycastAll to determine if the pointer is currently over UI. Note Calling EventSystem.IsPointerOverGameObject from within InputAction callbacks such as InputAction.performed will lead to a warning. The UI updates separately after input processing and UI state thus corresponds to that of the last frame/update while input is being processed. Handling ambiguities for navigation-type input Ambiguities for navigation-type Devices such as gamepads and joysticks (but also keyboards) cannot arise the same way that it does for pointers. Instead, your application has to decide explicitly whether to use input for the UI's Move, Submit, and Cancel inputs or for the game. This can be done by either splitting control on a Device or by having an explicit mode switch. Splitting input on a Device is done by simply using certain controls for operating the UI while using others to operate the game. For example, you could use the d-pad on gamepads to operate UI selection while using the sticks for in-game character control. This setup requires adjusting the bindings used by the UI Actions accordingly. An explicit mode switch is implemented by temporarily switching to UI control while suspending in-game Actions. For example, the left trigger on the gamepad could bring up an item selection wheel which then puts the game in a mode where the sticks are controlling UI selection, the A button confirms the selection, and the B button closes the item selection wheel. No ambiguities arise as in-game actions will not respond while the UI is in the \"foreground\". Immediate Mode GUI The Input System package does not support Immediate Mode GUI (IMGUI) methods at runtime. However, if you need to use IMGUI for your UI, it is possible to use legacy Input Manager input for your IMGUI user interface, while also using the Input System package for your in-game input. When the Editor's Active Input Handling setting is set to \"Input System Package\" (which is the default, when using the Input System package), the OnGUI methods in your player code won't receive any input events. To restore functionality to runtime OnGUI methods, you can change the Active Input Handling setting to \"Both\". Doing this means that Unity processes the input twice which could introduce a small performance impact. This only affects runtime (play mode) OnGUI methods. Editor GUI code is unaffected and will receive input events regardless."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UseInEditor.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UseInEditor.html",
    "title": "Using Input in the Editor | Inventory System",
    "summary": "Using Input in the Editor Unlike Unity's old Input Manager, you can use the new Input System from within EditorWindow code as well. For example, you can gain access to pen pressure information like this: class MyEditorWindow : EditorWindow { public void OnGUI() { var pen = Pen.current; if (pen != null) { var position = pen.position.ReadValue(); var pressure = pen.pressure.ReadValue(); //... } } } This encompasses all code called from OnGUI() methods, which means that you can also use the Input System in property drawers, Inspectors, and other similar places. Note: Unity doesn't support Actions in Edit mode. Coordinate System The coordinate system differs between EditorWindow code and UnityEngine.Screen. EditorWindow code has its origin in the upper-left corner, with Y down. UnityEngine.Screen has it in the bottom-left corner, with Y up. The Input System compensates for that by automatically converting coordinates depending on whether you call it from your application or from Editor code. In other words, calling Mouse.current.position.ReadValue() from inside EditorWindow code returns mouse coordinates in Editor UI coordinates (Y down), and reading the position elsewhere returns it in application screen coordinates (Y up). Internally, an editor-specific Processor called AutoWindowSpace handles this translation."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UserManagement.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/UserManagement.html",
    "title": "User Management | Inventory System",
    "summary": "User Management The Input System supports multi-user management through the InputUser class. This comprises both user account management features on platforms that have these capabilities built into them (such as Xbox and PS4), as well as features to manage Device allocations to one or more local users. Note: The user management API is quite low-level in nature. The stock functionality of Player Input Manager component (see Player Input Manager) provides an easier way to set up user management. The API described here is useful when you want more control over user management. In the Input System, each InputUser represents a human interacting with the application. For example, you can have multiple users playing a game together on a single computer or device (local multiplayer), where each user has one or more paired Input Devices. The PlayerInputManager class uses InputUser internally to handle users. Note: In the editor, all InputUser instances are automatically removed when exiting play mode thus also removing any device pairings. In essence, InputUser is considered a player-only API. Device pairing You can use the InputUser.PerformPairingWithDevice method to create a new InputUser instance and pair it with an InputDevice. You can also optionally pass in an existing InputUser instance to pair it with the Device, if you don't want to create a new user instance. To query the Devices paired to a specific InputUser, use InputUser.pairedDevices. To remove the pairing, use InputUser.UnpairDevice or InputUser.UnpairDevices. Initial engagement After you create a user, you can use InputUser.AssociateActionsWithUser to associate Input Actions to it, and use InputUser.ActivateControlScheme to associate and activate a Control Scheme. You can use InputControlScheme.FindControlSchemeForDevice to pick a control scheme that matches the selected Actions and Device: var scheme = InputControlScheme.FindControlSchemeForDevice(user.pairedDevices[0], user.actions.controlsSchemes); if (scheme != null) user.ActivateControlScheme(scheme); When you activate a Control Scheme, the Input System automatically switches the active Binding mask for the user's Actions to that Control Scheme. Loss of Device If paired Input Devices disconnect during the session, the system notifies the InputUser class. It still keeps track of the Device, and automatically re-pairs the Device if it becomes available again. To get notifications about these changes, subscribe to the InputUser.onChange event. Debugging Check the debugger documentation to learn how to debug active users."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-Actions.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-Actions.html",
    "title": "Workflow Overview - Actions | Inventory System",
    "summary": "Workflow Overview - Actions While the Input System has a variety of workflows to choose from, this is the primary recommended workflow, which suits most common scenarios for game and app input. In this workflow, you configure Actions in the Input Actions editor, then set up references to those actions and read their values in your code. Configure Actions in the Actions Editor Open the Input System settings by going to Edit > Project Settings > Input System Package > Input Actions. If you have not yet created and assigned the default project-wide actions, the Input System settings window displays a button to do this. Once you have created and assigned the default project-wide actions, the Actions Editor is displayed: The Input Actions editor in the Project Settings window The Input Actions editor provides a way to define and manage Actions which relate to what you want users to be able to do in your game or app. It also allows you to create bindings between your Actions and one or more types of control on various devices, such as a stick on a gamepad, a key on a keyboard, or a button on an XR controller. Actions and Bindings allows you to separate the conceptual actions that you want in your game or app from the the specific decvices and controls that a player has to use to perform the actions, which can make your code simpler and more flexible. This is in contrast to directly reading device states in your code, which can suit simple projects, but can become unwieldy and inflexible for more complex projects. The default Actions The Input System comes pre-configured with some default Actions such as \"Move\", \"Jump\", and more, which suit many common app and game scenarios. They are configured to read input most types of input controller such as Keyboard, Mouse, Gamepad, Touchscreen and XR. This means, in many cases, you can start scripting with the Input System without any configuration by referring to the names of the default actions that are already configured for you. Accessing your Actions from code There are various ways to access your actions from code. One of the simplest ways is to use the FindAction method. FindAction allows you to search for an action by name from within the set of configured acations, and returns a reference which you can then either read the value directly (also called \"polling\"), or you can attach callback methods that are called the action is performed. The workflow described on this page focuses only on reading the action values. You can read more about using callbacks here. Tip: Finding and storing a reference to an Action is similar to finding and storing a reference to a Component, so if you have done that elsewhere in Unity, this may be a familiar process. To use FindAction to get references to your Actions and read user input in your script, use the following steps: Create a new C# script in Unity. Add the Input System's \"using\" statement to the top of your script. This allows you to use the Input System API throughout the rest of your script: using UnityEngine.InputSystem Create some variables of type InputAction in your class body, one for each Action that you want to use in your script. These will store the references to each Action. A good naming convention is to add the word Action to the name of the action. For example: InputAction moveAction; InputAction jumpAction; In your Start() method, use FindAction to find the reference to each action and store it in its respective variable, for example: moveAction = InputSystem.actions.FindAction(\"Move\"); jumpAction = InputSystem.actions.FindAction(\"Jump\"); In your Update() method, read the value from your action variables. This allows you to write code that reads the latest values coming from your Actions each frame and respond accordingly. The way you read a value depends on the Action's value type. For example some actions may return a 1D or 2D axis value, and other actions may return a boolean true/false value. In this example, the \"Move\" action returns a 2D axis, and the \"Jump\" action returns a boolean. Vector2 moveValue = moveAction.ReadValue<Vector2>(); bool jumpValue = jumpAction.IsPressed(); The example script below shows all these steps combined together into a single script: using UnityEngine; using UnityEngine.InputSystem; public class Example : MonoBehaviour { // These variables are to hold the Action references InputAction moveAction; InputAction jumpAction; private void Start() { // Find the references to the \"Move\" and \"Jump\" actions moveAction = InputSystem.actions.FindAction(\"Move\"); jumpAction = InputSystem.actions.FindAction(\"Jump\"); } void Update() { // Read the \"Move\" action value, which is a 2D vector // and the \"Jump\" action state, which is a boolean value Vector2 moveValue = moveAction.ReadValue<Vector2>(); // your movement code here if (jumpAction.IsPressed()) { // your jump code here } } } Note: You should avoid using FindAction in your Update() loop, because it performs a string-based lookup which could impact performance. This is why the Action refeferences in the example above are found during the Start() function, and stored in variables after finding them. Note: The InputSystem.actions API refers specifically to the Action Asset assigned as the project-wide actions. Most projects only require one Action Asset, but if you are using more than one Action Asset, you must create a reference using the type InputActionAsset to the asset you wish to access. Pros and Cons This is the recommended workflow with the Input System Package, providing a flexible but simple solution suitable for most projects. You benefit from the Action-based features such as Action Maps, Bindings, and the ability to configure them in the Actions Editor. You can also implement user rebinding at run time. This workflow alone doesn't provide built-in support for local multiplayer scenarios with multiple devices, so if you are producing a local multiplayer game you might want to consider using the Actions & PlayerInput workflow."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-Direct.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-Direct.html",
    "title": "Workflow Overview - Directly Reading Device States | Inventory System",
    "summary": "Workflow Overview - Directly Reading Device States This is the simplest and most direct input workflow, but the least flexible. It bypasses the Input Actions editor, so you do not benefit from all the features come with Actions. It can be useful if you want a quick implementation with one specific type of device. It's generally not the best choice if you want to provide your users with multiple types of input or if you want to target multiple platforms. You can directly read the values from connected devices by referring to the device’s controls and reading the values they are currently generating, using code like this: using UnityEngine; using UnityEngine.InputSystem; public class MyPlayerScript : MonoBehaviour { void Update() { var gamepad = Gamepad.current; if (gamepad == null) { return; // No gamepad connected. } if (gamepad.rightTrigger.wasPressedThisFrame) { // 'Use' code here } Vector2 move = gamepad.leftStick.ReadValue(); { // 'Move' code here } } } The example above reads values directly from the right trigger, and the left stick, of the currently connected gamepad. It does not use the input system’s \"Action\" class, and instead the conceptual actions in your game or app, such as \"move\" and \"use\", are implicitly defined by what your code does in response to the input. You can use the same approach for other Device types such as the keyboard or mouse. Pros and Cons This can be the fastest way to set up some code which responds to input, but it is the least flexible because there is no abstraction between your code and the values generated by a specific device. If you choose to use this technique: You won’t benefit from Unity’s management of actions and interactions. It is harder to make your game or app work with multiple types of input device. Your input bindings are hard-coded in your script, so any changes to bindings require changes to the code. It is harder to allow the user to remap their own controls to different actions at run time. You can find an example of this workflow in the sample projects included with the input system package. To find it, in the Project window, look in Assets > Samples > SimpleDemo and open the scene: SimpleDemo_UsingState. See Supported Devices for more information about devices supported by the input system, and the API to read their states. For more a more flexible workflow, see the Actions Workflow."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-PlayerInput.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflow-PlayerInput.html",
    "title": "Workflow Overview - Actions and the PlayerInput Component | Inventory System",
    "summary": "Workflow Overview - Actions and the PlayerInput Component The highest level of abstraction provided by the Input System is when you use Actions and the Player Input component together. The Player Input provides a way to make connections between your configured Actions and the C# methods in your own MonoBehaviour scripts, so that your desired C# methods are called when the user performs an input action. It allows you to set up these connections using a UI in the inspector using an event-driven model, instead writing code to poll the values of your Actions as described in the previous workflow example). The PlayerInput component also helps with local multi-player scenarios. You can use the PlayerInput component along with the PlayerInputManager component to handle automatic instantiation of new players when input occurs on new devices. For example, if you were making a four-player local cooperative game, PlayerInput with PlayerInputManager can handle allowing new players to join when they press start on their respective controller. In the above example image, you can see the PlayerInput component set up to map the \"move\", \"jump\" actions to OnMove and OnJump methods in a script, via Unity Events. This is an example of the script which would provide an implementation of these methods using UnityEngine; using UnityEngine.InputSystem; // This script is designed to have the OnMove and // OnJump methods called by a PlayerInput component public class ExampleScript : MonoBehaviour { Vector2 moveAmount; public void OnMove(InputAction.CallbackContext context) { // read the value for the \"move\" action each event call moveAmount = context.ReadValue<Vector2>(); } public void OnJump(InputAction.CallbackContext context) { // your jump code goes here. } public void Update() { // to use the Vector2 value from the \"move\" action each // frame, use the \"moveAmount\" variable here. } } Note: As a general rule, if you are using the PlayerInput workflow, you should read input through callbacks as described above, however if you need to access the input actions asset directly while using the PlayerInput component, you should access the PlayerInput component's copy of the actions, not InputSystem.actions. This is because the PlayerInput component performs device filtering to automatically assign devices to multiple players, so each instance has its own copy of the actions filtered for each player. If you bypass this by reading InputSystem.actions directly, the automatic device assignment won't work. Pros and Cons This workflow has pros and cons when compared to using Actions without a PlayerInput component. Because it builds on the use of Actions, it comes with all the benefits provided by them, such as Action Maps, Bindings, and the ability to configure them in the Actions Editor. You can also implement user rebinding at run time. This workflow also allows you to set up callbacks in the Editor using an interface in the Inspector, which can sometimes reduce code complexity but can also make debugging more difficult, because the connections between your actions and code are not themselves defined in your code. It also provides ready-made handling of the assignment of devices and screen-splitting in local multiplayer scenarios. While these are things you can implement yourself, having a simple solution ready to go can be beneficial. However if you choose this option, the implementation is somewhat of a \"black box\", meaning you are less able to customise how it works. As with the other workflows described in this section, there is a trade-off between flexibility, simplicity, and speed of implementation. To get started using this workflow, see the documentation for the Player Input component."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflows.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/Workflows.html",
    "title": "Input System Workflows | Inventory System",
    "summary": "Input System Workflows There are multiple ways to use the Input System, however the primary and recommended workflow is to use the Input Actions panel in the Project Settings window to configure your project-wide Actions and Bindings, get references to those Actions in your code's Start method, then read the values for those actions in your Update method. There are other workflows which can suit more unusual situations, for example you can use the PlayerInput component together with Actions and Bindings which adds a further layer of abstraction, allowing you to connect actions to your event handlers without requiring any intermediate code, and easily handle multiplayer scenarios. You can choose to configure Actions and Bindings in the Editor UI, or you can set up everything through scripting. Or you can take a more direct approach by omitting the Actions and Bindings features altogether and instead use script to directly read the state of devices. The descriptions below describe these main workflows and link to more detailed description of them. Using Actions This is the recommended workflow for most situations. In this workflow, you use the Actions Editor window to configure sets of actions and bindings, then set up references and read the values for those actions in your code (read more). Using Actions and the PlayerInput Component This workflow provides extra features that allow you to connect up callbacks directly from Actions to your own callback handler methods, removing the need to deal with Action references in your code. It also provides features that are useful in local multiplayer scenarios such as device assignment and split-screen functionality. (read more). Directly read device states This workflow is a simplified, script-only approach which bypasses the Actions and Bindings features entirely. Instead your script explicitly references specific device controls (such as \"left gamepad stick\") and reads the values directly. This is suitable for fast prototyping, or single fixed platform scenarios. It is a less flexible workflow because it bypasses some of the main input system features (read more). Note: Because the Input System has multiple workflows, the code samples used throughout this documentation also vary, often demonstrating techniques using various workflows. For example, some code samples may use Action references, and some may use the workflow of reading input directly from devices."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/index.html",
    "title": "Input System | Inventory System",
    "summary": "Input System The Input System allows your users to control your game or app using a device, touch, or gestures. Introduction Unity supports input through two separate systems, one older, and one newer. The older system, which is built-in to the editor, is called the Input Manager. The Input Manager is part of the core Unity platform and is the default, if you do not install this Input System Package. This Input System package is a newer, more flexible system, which allows you to use any kind of Input Device to control your Unity content. It's intended to be a replacement for Unity's classic Input Manager. It is referred to as \"The Input System Package\", or just \"The Input System\". To use it, you must install it into your project using the Package Manager. During the installation process for the Input System package, the installer offers to automatically deactivate the older built-in system. (Read more) To get started, see the Installation and Workflows sections. For a demo project, see the Warriors demo on GitHub. The Input Actions Editor, displaying some of the default actions that come pre-configured with the Input System package."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-and-latency.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-and-latency.html",
    "title": "Timing and Latency | Inventory System",
    "summary": "Timing and Latency Input Timing refers to the topic of exactly when the Input System receives and processes input from devices. Latency is the amount of time between the user providing some input, and the user receiving a response to that input. For example, the time between a button press and your game’s character moving on-screen. In fast-paced input scenarios such as action games, even tiny delays between the user's input and your game responding can be noticeable and affect the feel of your gameplay. In addition to the effects of latency, timing can affect one-off discrete events such as when a button press starts or finishes. Checking for these at the wrong time can result in missed or duplicate events. To minimize input latency, and to avoid missed or duplicate events, it helps to understand how the Input System processes events in relation to Unity's frame updates, physics updates, and fixed updates. This will help you make decisions about how to read and respond to input in your game or app. Topic Description Input events queue Understand how and when the Input System receives and processes input from devices. Select an input processing mode How to select an appropriate Update Mode which controls when the Input System processes queued input events. Optimize for dynamic update How to optimize input for use in Update calls. Optimize for fixed update How to optimize input for use in FixedUpdate calls. Avoid missed or duplicate events How to avoid missing or duplicated discrete input events like when a button was pressed or released. Mixed timing scenarios How to optimize and avoid problems when using input in both Update and FixedUpdate calls."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-input-events-queue.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-input-events-queue.html",
    "title": "The input events queue | Inventory System",
    "summary": "The input events queue The Input System receives information from hardware input devices as a stream of events. These events represent either system events received from the input device, or snapshots in time based on frequent samples from the device. The incoming events are stored in a queue, and by default are processed each frame. Input controls which have discrete (on/off) states, such as a button on a gamepad or mouse, generate corresponding single discrete events when they change state. Input controls with a range of motion, for example a stick or trigger on a gamepad that can be gradually moved over a period of time, generate a stream of individual events in rapid succession that approximates the smooth change in value. A diagram showing an example of events coming from a smoothly changing analog input such as a gamepad stick over a period of four frames. In this example, the events are occurring faster than the game’s frame rate, which means multiple events are received each frame. Because a device can cause events at times when the input system can't process them (for example, during the rendering phase of the player loop), these events are placed in an incoming queue, and the input system processes them in batches at frequent intervals. Input Event Queue Processing Unity’s player loop repeats at frequent intervals depending on how fast your game or app is running. The player loop repeats once per frame, and performs the Update and FixedUpdate calls. However, the player loop in your game or app usually runs at a rate that's different to the rate of incoming events from input controls, which tend to have their own rate of operation. This means that each time an Update cycle occurs while a user is moving an input control, there's likely to be a queue of events representing the gradual change in values that occurred between the last frame and the current frame. This queue is processed at the beginning of the next Update or FixedUpdate, depending on which Input Update Mode you're using. Event grouping and processing To pass through these incoming input events to your code, the Input System groups and processes them at a specific time within the Player Loop. This is either just before the next Update if the Input Update Mode is set to Process Events In Dynamic Update, or just before the next FixedUpdate if the Input Mode is set to Process Events in Fixed Update. The following diagram shows how each batch of events (labeled with letters) is processed at the start of the subsequent frame, when the Input Update mode is set to Process Events in Dynamic Update. Events (a), (b) & (c) occurred during frame 1, and so are processed at the start of frame 2, before frame 2’s Update() call. Events (d), (e), (f) & (g) occurred during frame 2, and so are processed at the start of frame 3. Events (h) & (i) occur during frame 3, and so are processed at the start of frame 4. This means that the exact time that your code receives the events isn't the same as the time the event was received by the input system in Unity. For this reason, when you're using event callbacks (as opposed to polling), the Input System includes time stamps for each event so that you can know when each event was generated. For example, event (d) in the diagram is received from the device by the input system at time 0.012 s, but the time at which your code receives the event callback is at the start of the next frame, at about 0.03 s. It retains its timestamp of 0.012 s, but it, along with events (e), (f), and (g), are all processed by your code at almost exactly the same time, each marked with their own time stamps."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-missed-duplicate-events.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-missed-duplicate-events.html",
    "title": "Avoid missed or duplicate discrete events | Inventory System",
    "summary": "Avoid missed or duplicate discrete events Discrete events are simple on/off events that occur when a user presses or releases a control such as a gamepad button, key, mouse, or touch press. This is in contrast to continuously changing values like those from gamepad stick movement. You can poll for these types of discrete event by using WasPressedThisFrame or WasReleasedThisFrame. However, you can get incorrect results such as missing an event or appearing to receive multiple, if you check for them at the wrong time. If your Update Mode is set to Process in FixedUpdate, you must ensure that you only use WasPressedThisFrame or WasReleasedThisFrame in FixedUpdate calls. Using them in Update might either miss events, or returns true across multiple consecutive frames depending on whether the frame rate is running slower or faster than the fixed time step. Conversely, if your Update Mode is set to process in Dynamic Update, you must ensure that you only use WasPressedThisFrame or WasReleasedThisFrame in Update calls. Using them in FixedUpdate might either miss events, or return true across multiple consecutive frames depending on whether the fixed time step is running slower or faster than your game’s frame rate. If you find that you're missing events that should have been detected, or are receiving multiple events for what should have been a single press or release of a control, the reason is probably that you either have your Input Update Mode set to the wrong setting, or that you're reading the state of these events in the wrong Update or FixedUpdate call."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-mixed-scenarios.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-mixed-scenarios.html",
    "title": "Mixed timing scenarios with fixed and dynamic input | Inventory System",
    "summary": "Mixed timing scenarios with fixed and dynamic input There are some situations where you might set the Update Mode process in Dynamic Update even when using input code in FixedUpdate, to minimize input latency, as described in the previous section. In this situation, for discrete events you must ensure that you use WasPressedThisFrame or WasReleasedThisFrame in Update, and pass through a variable to your FixedUpdate code to indicate the event happened. There may still be some latency between the frame in which the event occurred, and the next FixedUpdate call. For example: using UnityEngine; using UnityEngine.InputSystem; public class ExampleScript : MonoBehaviour { InputAction jumpAction; bool jumpPressed; private void Start() { jumpAction = InputSystem.actions.FindAction(\"Jump\"); } private void Update() { // read discrete jump pressed event here: if (jumpAction.WasPressedThisFrame()) { // set this variable to true, for use in FixedUpdate jumpPressed = true; } } void FixedUpdate() { if (jumpPressed) { // apply jump physics here // set the variable to false so that the jump pressed physics are only applied once jumpPressed = false; } } } Minimum latency in mixed timing scenarios A technique to give the user the feel of absolute minimum latency while still using FixedUpdate is to respond as fast as possible in Update giving some visual feedback, but also respond to that same input in FixedUpdate for your physics system code. For example, you could display the start of a \"jump\" animation immediately in Update, while applying physics to correspond with the \"jump\" animation in the next available FixedUpdate which might come slightly later. In this scenario, set your Update Mode Process events in Dynamic Update which gives you the fastest response in your Update call. However for the reasons mentioned in the previous section, this might mean you miss discrete events if you use methods like WasPressedThisFrame in your FixedUpdate call. To avoid this problem, use a variable to pass through the pressed/released state of the discrete event from the event handler to your FixedUpdate call, and then clear it once your FixedUpdate code has acted on it. For example: using UnityEngine; using UnityEngine.InputSystem; public class ExampleScript : MonoBehaviour { InputAction jumpAction; bool jumpPressed; private void Start() { jumpAction = InputSystem.actions.FindAction(\"Jump\"); } private void Update() { // at high FPS, it’s fastest to read actions here: // read discrete jump pressed event here: if (jumpAction.WasPressedThisFrame()) { // start jump animation here // set this variable to true, for use in FixedUpdate jumpPressed = true; } } void FixedUpdate() { if (jumpPressed) { // apply jump physics here // set the variable to false so that the jump pressed physics are only applied once jumpPressed = false; } } }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-optimize-dynamic-update.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-optimize-dynamic-update.html",
    "title": "Optimize for dynamic update (non-physics) scenarios | Inventory System",
    "summary": "Optimize for dynamic update (non-physics) scenarios If you're not working with the physics system or using FixedUpdate, always set the input system to process input in sync with the frame rate and Update() calls. This is the default setting, but to check or set this, go to Project Settings > Input System Package > Input Settings, and set Update Mode to Process Events in Dynamic Update. You can use either a Polling or Event-driven approach to read and process input each frame. You can find out more about Polling or Event-driven approaches in Responding To Actions. Whether you choose polling or event-driven, as long as you have your Update Mode set to Process Events in Dynamic Update, you receive the latest events and values at the start of each frame. Polling technique Poll input in Update and use those values to control your game in Update. If there were multiple events after the last frame completed (for example, multiple changing position values of a continuously moving gamepad stick), polling gives you the most recently processed value which is often fine for most scenarios. This approach is often called sample-and-hold and is a form of down-sampling, because individual subframe information is discarded. For example, in the scenario shown in the diagram below, polling the input on frame 3 gives the value for event (g), while the values for events (d) (e) and (f) are discarded. Also use Update to poll for discrete on/off state changes using API such as WasPressedThisFrame and WasReleasedThisFrame. Note The input system doesn't detect multiple discrete on/off events that happen in a single frame when you use the poll driven approach. Multiple discrete on/off events might happen if your game is running at a low frame rate and a user repeatedly presses a button very rapidly, or if the user is using a type of game controller with a rapid \"auto fire\" mode. The polling technique also can't detect the order of multiple buttons were pressed on the same frame. Use event-driven input if you require this information. Event-driven technique All events that occurred since the last frame are immediately processed before the current frame's Update, in the order that they were received. For continuously changing values (for example, multiple changing position values of a continuously moving gamepad stick), you might receive multiple events per frame with backdated timestamps indicating when they occurred between the last frame and the start of the current frame. You can read and store input values from the input events in your event handler methods, and use those values to control your game in Update. For example, in the scenario shown in the previous diagram, at the start of frame 3, you receive events for (d), (e), (f), and (g) and can process all of them in your game code."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-optimize-fixed-update.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-optimize-fixed-update.html",
    "title": "Optimize for fixed-timestep or physics-based scenarios | Inventory System",
    "summary": "Optimize for fixed-timestep or physics-based scenarios If you are working with the physics system or using FixedUpdate to control your game in a scenario where a small amount of input latency is acceptable (for example, a few frames), the simplest approach is to set the input system update mode to Process Events in Fixed Update. This means your input code in FixedUpdate will operate as expected. To get the minimum possible latency from the Input System and minimize lag, set the input system update mode to Process Events in Dynamic Update. However in doing this, you must understand how to avoid the problems which can arise when using this strategy. Although it might seem incorrect if you have code in FixedUpdate, for most cases, this approach minimizes lag compared with processing events in Fixed Update. The reasons for this are explained in detail on this page. Having a good understanding of how input is processed in each mode allows you to make your own decision about how best to process input for your particular project. Input in Fixed Update mode When you set the input system update mode to Process Events in Fixed Update, input events are processed in groups according to whether their timestamp falls within the current fixed time step. There might be none, one, or multiple FixedUpdate calls processed per frame depending on how fast the game's frame rate is updating compared with the fixed update time step period. If your game’s frame rate is running faster than the fixed time step period, you will have either zero or one FixedUpdate call per frame, depending whether the previous fixed time step has completed or not. If your game’s frame rate is running slower than the fixed time step period, you will have one or more FixedUpdate calls per frame - as many as are required to catch up with the number of completed fixed time step periods that have elapsed. You can learn more about how the player loop processes fixed update time steps in Time and Framerate Management. It’s important to understand that Fixed Update provides a simulation of code running at fixed time deltas (the fixed time step), however it does not actually run at regular time intervals. Instead, at the start of each frame loop, Unity will run as many Fixed Update steps as is needed to catch-up to the current frame’s time. If a whole fixed time step hasn't completed yet, no Fixed Update steps occur. If more than one whole fixed time step has elapsed, more than one Fixed Update step occurs. This means that on each frame, the FixedUpdate method can be called a variable number of times (or even not at all) depending on how much time has elapsed since the last frame and the value set for the Fixed Update time step. When the frame rate runs faster than fixed time step duration This diagram shows the frame rate running faster than the fixed update time step rate. Time progresses to the right, each frame is numbered, and shows its Update call at the start of the frame in orange. The fixed time step here is 0.02 seconds (50 times per second), and the game is running faster, at about 80 frames per second. In this situation there are some frames with one fixed update call, and some frames with none, depending on whether a full fixed update time step has completed by the time the frame starts. The fixed time step periods are marked with letters A, B, C, D, E, and the frames in which their corresponding fixed update calls occur are marked in green. The fixed update call for time step A occurs at the start of frame 4, the FixedUpdate call for time step B occurs at the start of frame 7, and so on. When the frame rate runs slower than the fixed time step duration This diagram shows the opposite scenario, when the fixed update cycle is running faster than the frame rate. The fixed time step here is 0.01 seconds (100 times per second), and the game frame rate is running slower, at about 40 frames per second. In this situation most frames have multiple fixed update calls before each update call, the number depending on how many whole update time steps have elapsed since the previous frame. The fixed update time step periods are marked with letters A, B, C, and so on, and frames in which their corresponding fixed update calls occur are marked in green. The fixed update call for time step A and B occurs at the start of frame 2, the fixed update call for frames C, D & E occur at the start of frame 3, and so on. In both types of situation, whether the frame rate is running either faster or slower than the fixed time step, the start of the frame usually occurs somewhere part-way through a fixed time step interval. This means a portion of the most recent fixed time step period occurs before the frame, and some during the frame. Partially elapsed fixed time step periods like this aren't processed until the frame after they have fully elapsed. Implications for input lag in fixed time step mode Because input that occurs during partially elapsed time steps isn't processed until the frame after the time step has fully completed, this has implications for increased input lag in fixed time step mode. There's almost always some amount of unprocessed time left between the end of the last fixed time step, and the start of the next frame. This means it's possible for input events to occur within that unprocessed time. An example of an input event occurring during such unprocessed time is shown in this diagram: This diagram shows the frame rate running faster than the fixed update time step rate. Each frame is numbered (1 to 7), and shows its Update call at the start of the frame in orange. The fixed time step here is 0.02s (50 steps per second), and the game is running faster, at about 80 frames per second. In this situation there are some frames with one fixed update call, and some frames with none. The diagram shows an input event (shown as a blue dot) that occurs during some unprocessed time during frame 3. Although the event occurs during frame 3, it's not processed in the fixed update input processing step at the start of frame 4 because it didn't occur during fixed time step (A). Instead, it occurred during fixed time step (B), which is processed at the start of frame 7 - the first frame to occur after fixed time step (B) has completely elapsed. This has the counterintuitive effect that the processing of input on frame 4 actually ignores some input that has already occurred on frame 3, because it's only processing events that occurred in the last complete fixed time step: (A). Minimize latency when using fixed update code To minimize input latency in input code in FixedUpdate calls, set the input system update mode to Process Events in Dynamic Update, which eliminates the problem of unprocessed time described previously. You can then use an event-driven or polling technique to read your input without missing events that occurred after the last fixed timestep but before the current frame. However, the Process Events in Dynamic Update mode might introduce the problem of missed or duplicate discrete events, such as attempting to read whether a button was pressed in a given frame. If you use this strategy, you must understand how to avoid missed or duplicate events in mixed timing scenarios requiring fixed and dynamic input. Event-driven input with fixed update code For event-driven input, where the Player Input component calls events in your code, you should store the input values in variables which you can then read in your FixedUpdate call. For example: using UnityEngine; using UnityEngine.InputSystem; public class ExampleScript : MonoBehaviour { Vector2 moveInputValue; Rigidbody rigidBody; public float moveForce = 10; private void Start() { rigidBody = GetComponent<Rigidbody>(); } public void OnMove(InputAction.CallbackContext context) { // in the event callback, we store the input value moveInputValue = context.ReadValue<Vector2>(); } private void FixedUpdate() { // in fixed update, we use the stored value for // applying physics forces rigidBody.AddForce(moveInputValue * moveForce); } } Polling input with fixed update code For code where you're polling input action values, you can read the values directly from FixedUpdate: using UnityEngine; using UnityEngine.InputSystem; public class ExampleScript : MonoBehaviour { InputAction moveAction; Rigidbody rigidBody; public float moveForce = 10; private void Start() { moveAction = InputSystem.actions.FindAction(\"move\"); } private void FixedUpdate() { Vector2 moveInputValue = moveAction.ReadValue<Vector2>(); rigidBody.AddForce(moveInputValue * moveForce); } }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-select-mode.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Documentation~/timing-select-mode.html",
    "title": "Select an appropriate input processing mode | Inventory System",
    "summary": "Select an appropriate input processing mode The Input System Update Mode controls when the input system processes queued input events. You can find and change the Update Mode by going to Project Settings > Input System Package > Input Settings > Update Mode. The choice of Update Mode that best suits your project relates to whether you're using Update or FixedUpdate to respond to input events. You should choose this based on the specifics of the game you're making. You can read more about Update and FixedUpdate in Time and Framerate Management. When a small amount of latency is not an issue In cases where a small amount of input latency (a few frames) isn't an issue, set the update mode to match where you read your input. If your input code is in Update (usually non-physics-based scenarios), use Process Events in Dynamic Update. If your input code is in FixedUpdate (usually physics-based scenarios), use Process Events in Fixed Update. When minimum latency is a necessity In cases where minimum latency is a necessity, set the update mode to Process Events in Dynamic Update, even if you're using code in FixedUpdate to apply physics forces based on input. This strategy comes with some additional issues that you must be aware of. Refer to the section Optimizing for fixed-timestep scenarios for more information."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.inputsystem copyright © 2024 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/README.html",
    "title": "| Inventory System",
    "summary": "A new Input System for Unity. Check out the Input System documentation for more info."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomComposite/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomComposite/README.html",
    "title": "| Inventory System",
    "summary": "This sample shows how to implement and register a custom InputBindingComposite."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomDevice/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomDevice/README.html",
    "title": "| Inventory System",
    "summary": "This sample demonstrates how to add author a custom device that plugs into the input system."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomDeviceUsages/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/CustomDeviceUsages/README.html",
    "title": "| Inventory System",
    "summary": "This sample shows how to tag devices with custom \"usages\" and how to bind actions specifically to devices with only those usages. This is useful if you have the same type of device that appears in multiple different roles that you want to distinguish when binding to the device. For example, when a device may appear in both the left and the right hand or may appear held in different orientations (say, horizontal vs vertical)."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/GamepadMouseCursor/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/GamepadMouseCursor/README.html",
    "title": "Licenses | Inventory System",
    "summary": "Rather than adapting UIs for gamepad navigation/use, an oft-used alternative is to instead keep having UIs operated by pointer input but to drive the pointer from gamepad input. This sample demonstrates how to set this up with the input system. It uses a custom actions file for feeding input to the UI as the default actions are set up for gamepad navigation – something we don't want here as it would conflict with gamepad input being used for virtual cursor navigation. Note how InputSystemUIInputModule on the EventSystem GameObject is set up to reference actions from that file. The key component to take a look at is VirtualMouseInput on Canvas >> Cursor. The component is set up to receive input from the gamepad and translates it into motion on the RectTransform it is given. When going into play mode, you should also see a Virtual Mouse being added to the devices by the component. Note how the anchor position on the RectTransform is set to bottom left. This way the coordinate system responds to how mouse screen space operates. Note how Cursor is the last child of Canvas so that it draws on top of everything else. Note that Raycast Target on the Image component of the cursor is turned off to avoid raycasts from the mouse cursor hitting the cursor itself. Note that Cursor Mode on the VirtualMouseInput component is set to Hardware Cursor If Available. This will cause the component to look for a system mouse. If present, the system mouse is disabled and the system mouse cursor is warped to the virtual mouse position using Mouse.WarpCursorPosition. If no system mouse is present, Cursor Graphic will be used as a software mouse cursor. Licenses The cursor used in the example is from game-icons.net and made by Delapuite and released under the CC BY 3.0 license. It is used without modifications."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/InputRecorder/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/InputRecorder/README.html",
    "title": "| Inventory System",
    "summary": "This sample is both a demonstration for how to use InputEventTrace as well as a useful tool by itself in the form of the InputRecorder reusable MonoBehaviour component. One possible way in which you can use this facility, for example, is to record input, save it to disk, and then replay the same input in automation (e.g. in tests or when recording short video snippets of preset gameplay sequences for manual proofing)."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/RebindingUI/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/RebindingUI/README.html",
    "title": "| Inventory System",
    "summary": "This sample demonstrates how to use the Input System APIs to set up a rebinding UI. The main file is RebindActionUI which, aside from serving as an example, contains a reusable MonoBehaviour component for composing rebinding UIs. The RebindUIPrefab contains a ready-made prefab that can be used as a simple drop-in setup for rebinding an individual action. To demonstrate how to use images instead of textual display strings, take a look at GamepadIconsExample. Finally, the RebindSaveLoad script demonstrates how to persist user rebinds in PlayerPrefs and how to restore them from there. The icons used in the sample are taken from Free Prompts Pack v4.0 created by, and made available to public domain by Nicolae Berbece. Icons are licensed under Creative Commons CC0."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/SimpleDemo/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/SimpleDemo/README.html",
    "title": "SimpleDemo_UsingState | Inventory System",
    "summary": "This sample shows how to set up a simple character controller using the input system. As there is more than one way to do it, the sample illustrates several ways. Each demonstration is set up as a separate scene. The basic functionality in all the scenes is the same. You can move and look around and fire projectiles (colored cubes) into the scene. In some scenes, only gamepads are supported but the more involved demonstrations support several different inputs concurrently. SimpleDemo_UsingState Source This starts off at the lowest level by demonstrating how to wire up input by polling input state directly in a MonoBehaviour.Update function. For simplicity's sake it only deals with gamepads but the same mechanism works in equivalent ways for other types of input devices (e.g. using Mouse.current and Keyboard.current). The key APIs demonstrated here are Gamepad.current and InputControl.ReadValue. public class SimpleController_UsingState : MonoBehaviour { //... public void Update() { var gamepad = Gamepad.current; if (gamepad == null) return; var move = Gamepad.leftStick.ReadValue(); //... } } SimpleDemo_UsingActions Source This moves one level higher and moves input over to \"input actions\". These are input abstractions that allow you to bind to input sources indirectly. In this scene, the actions are embedded directly into the character controller component. This allows setting up the bindings for the actions directly in the inspector. To see the actions and their bindings, select the Player object in the hierarchy and look at the SimpleController_UsingActions component in the inspector. The key APIs demonstrated here are InputAction and its Enable/Disable methods and its ReadValue method. public class SimpleController_UsingActions : MonoBehaviour { public InputAction moveAction; //... public void OnEnable() { moveAction.Enable(); //... } public void OnDisable() { moveAction.Disable(); //... } public void Update() { var move = moveAction.ReadValue<Vector2>(); //... } } The sample also demonstrates how to use a Tap and a SlowTap interaction on the fire action to implement a charged shooting mechanism. Note that in this case, we run the firing logic right from within the action using the action's started, performed, and canceled callbacks. fireAction.performed += ctx => { if (ctx.interaction is SlowTapInteraction) { StartCoroutine(BurstFire((int)(ctx.duration * burstSpeed))); } else { Fire(); } m_Charging = false; }; fireAction.started += ctx => { if (ctx.interaction is SlowTapInteraction) m_Charging = true; }; fireAction.canceled += ctx => { m_Charging = false; }; SimpleDemo_UsingActionAsset Source As more and more actions are added, it can become quite tedious to manually set up and Enable and Disable all the actions. We could use an InputActionMap in the component like so public class SimpleController : MonoBehaviour { public InputActionMap actions; public void OnEnable() { actions.Enable(); } public void OnDisable() { actions.Disable(); } } but then we would have to look up all the actions manually in the action map. A simpler approach is to put all our actions in a separate asset and generate a C# wrapper class that automatically performs the lookup for us. To create such an .inputactions asset, right-click in the Project Browser and click Create >> Input Actions. To edit the actions, double-click the .inputactions asset and a separate window will come up. The asset we use in this example is SimpleControls.inputactions. When you select the asset, note that Generate C# Class is ticked in the import settings. This triggers the generation of SimpleControls.cs based on the .inputactions file. Regarding the SimpleController_UsingActionAsset script, there are some notable differences. public class SimpleController_UsingActionAsset { // This replaces the InputAction instances we had before with // the generated C# class. private SimpleControls m_Controls; //... public void Awake() { // To use the controls, we need to instantiate them. // This can be done arbitrary many times. E.g. there // can be multiple players each with its own SimpleControls // instance. m_Controls = new SimpleControls(); // The generated C# class exposes all the action map // and actions in the asset by name. Here, we reference // the `fire` action in the `gameplay` action map, for // example. m_Controls.gameplay.fire.performed += //... } //... public void Update() { // Same here, we can just look the actions up by name. var look = m_Controls.gameplay.look.ReadValue<Vector2>(); var move = m_Controls.gameplay.move.ReadValue<Vector2>(); //... } } Just for kicks, this sample also adds keyboard and mouse control to the game. SimpleDemo_UsingPlayerInput Source Finally, we reached the highest level of the input system. While scripting input like in the examples above can be quick and easy, it becomes hard to manage when there can be multiple devices and/or multiple players in the game. This is where PlayerInput comes in. PlayerInput automatically manages per-player device assignments and can also automatically handle control scheme switching in single player (e.g. when the player switches between a gamepad and mouse&keyboard). In our case, we're not getting too much out of it since we don't have control schemes or multiple players but still, let's have a look. The first thing you'll probably notice is that now there are two script components on the Player object, one being the usual SimpleController and the other being PlayerInput. The latter is what now refers to SimpleControls.inputactions. It also has gameplay set as the Default Action Map so that the gameplay actions will get enabled right away when PlayerInput itself is enabled. For getting callbacks, we have chosen Invoke Unity Events as the Behavior. If you expand the Events foldout in the inspector, you can see that OnFire, OnMove, and OnLook are added to the respective events. Each callback method here looks like the started, performed, and canceled callbacks we've already seen on fireAction before. public class SimpleController_UsingPlayerInput : MonoBehaviour { private Vector2 m_Move; //... public void OnMove(InputAction.CallbackContext context) { m_Move = context.ReadValue<Vector2>(); } //... }"
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/SimpleMultiplayer/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/SimpleMultiplayer/README.html",
    "title": "Simple Multiplayer Demo | Inventory System",
    "summary": "Simple Multiplayer Demo This demo shows a simple local multiplayer setup. Players can join by pressing buttons on the supported devices. As players join, the screen is subdivided in split-screen fashion. Joining is handled by the PlayerManager GameObject in the scene which has the PlayerInputManager component added to it. The component references Player.prefab which is instantiated for each player that joins the game. The prefab contains a GameObject that has a PlayerInput component added to it. The component references the actions available to each player which, by means of the control schemes defined in the asset, also determine the devices (and combinations of devices) supported by the game. The actions available to each player are intentionally kept simple for this demonstration in order to not add irrelevant details. The only action available to players is Teleport which players can trigger through a button on their device. When trigger, they will be teleported to a random position within the game area. This serves to demonstrate that player inputs are indeed separate. Note that each PlayerInput also references a Camera which is specific to each player. This is used by PlayerInputManager to configure the split-screen setup."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/UIvsGameInput/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/UIvsGameInput/README.html",
    "title": "UI vs Game Input | Inventory System",
    "summary": "UI vs Game Input NOTE: More information related to ambiguities between UI and game input may be found here in the documentation. When interactive UI elements are overlaid over a game view, ambiguity may arise for inputs. If, for example, there is a UI.Button on screen that can be clicked/tapped, while clicking/tapping on the scene itself also has associated functionality, clicking on the UI button should not also trigger the corresponding action on the scene. This sample demonstrates how to handle input in such a situation. The Sample Scene The sample scene has a UI button in each of the corners of the screen. The camera in the scene can be rotated and projectiles can be fired while at the same time the buttons in the UI can be clicked. There are two ways to control the game: \"Pointer\", i.e. mouse (optionally combined with keyboard) or touch input, and \"Navigation\", i.e. gamepad input. Mouse/Touch/Keyboard Input When clicking any of the buttons, the \"status bar\" text along the bottom edge of the screen changes. Left-click-dragging with the mouse or finger-dragging with touch rotates the camera (note: only when starting the drag on the background). Alternatively, when using mouse&keyboard, holding the the left control key will engage camera control. Right-clicking with the mouse or tapping the second finger while rotating the camera shoots a projectile. Double-clicking/tapping on the scene resets the camera orientation. Pressing Escape will bring up the game menu. With touch input, an extra button is shown in the game UI to do that. Gamepad Input The right stick rotates the camera and the right trigger fires a projectile. Double-pressing the A button will reset the camera to its initial orientation. Holding the left trigger switch to UI focus. UI selection is now active and can be changed with the d-pad or the sticks. The A button performs a button press. Pressing B while in game brings up the main menu. How It Works Pointer Input For the most part, input processing is done in Update() such that actions are processed on a per-frame basis. Responses to actions that may conflict with UI input use IsPointerOverGameObject to determine whether the pointer is currently over UI. Since this is called from Update() and thus outside of input processing (i.e. not from within an InputAction callback), the method can be safely called and will return an accurate result. There are two implementations of handling the Fire action. One uses the same approach just mentioned where the action's response is dealt with once per frame. The second one, however, immediately creates a projectile within the callback and thus operates at sub-frame accuracy. For a low-frequency input such as the Fire action here, this is not generally a useful thing to do but it is done here for the sake of demonstration. We cannot call IsPointerOverGameObject from the action callback and thus need to use the UI's public raycasting interface to determine \"over UI?\" state manually for the current pointer position. Navigation Input Navigation input employs an explicit mode switch to go from gameplay to UI input. This is handled by OnUIEngage."
  },
  "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/UnityRemote/README.html": {
    "href": "Library/PackageCache/com.unity.inputsystem@7fe8299111a7/Samples~/UnityRemote/README.html",
    "title": "Unity Remote Sample | Inventory System",
    "summary": "Unity Remote Sample This sample is just a simple scene that lets you see try out the Unity Remote app. The app is useful for quickly testing your project in the Unity Editor without having to build and deploy to the device. This is supported for iOS and Android. More detailed information about the Unity Remote can be found in the Unity manual. Instructions: Install the Unity Remote app on your Android or iOS device. Connect the device to your computer via USB. On Android, make sure you have the Android SDK installed and configured appropriately in Unity. Also, USB debugging needs to be enabled. In Unity, go to Edit > Project Settings > Editor and select the device in the Unity Remote section. Open the Unity Remote app on the device. Open the UnityRemoteTest.unity scene from this sample. Enter play mode. After a short delay, the Unity Remote app on your device should switch to display the scene and you should be able to interact with the scene in the editor using the device."
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [1.3.2] - 2024-01-11 Fixed Fixed math.hash crash when using IL2CPP builds on Arm 32 bit devices. Fixed obsolete method usage warnings for MatrixDrawer.CanCacheInspectorGUI and PrimitiveVectorDrawer.CanCacheInspectorGUI in UNITY_2023_2_OR_NEWER. Updated minimum editor version to 2021.3 [1.3.1] - 2023-07-12 Added Added math.square to compute the square (x * x). Added math.orthonormal_basis to compute an orthonormal basis from a single unit length vector. Added math.sign for int, int2, int3 and int4. Added math.chgsign for float, float2, float3, and float4. Added math.Euler to convert a quaternion to Euler angles. Added math.angle to compute the angle between two unit quaternions. Added math.rotation to extract a quaternion rotation from a float3x3 (that may have scale). Added math.mulScale to scale columns of a float3x3 with scaling coefficients in a float3. Added math.scaleMul to scale rows of a float3x3 with scaling coefficients in a float3. Added AffineTransform type. Added PI2, PIHALF, TAU, TODEGREES and TORADIANS constants. Changed asfloat(uint), asuint(float), asint(float) and other related methods are now faster in mono without Burst. Other methods which use these will see a performance improvement. Modified quaternion.nlerp to be branchless. More descriptive parameter names for many methods in math class. Made Il2CppEagerStaticClassConstructionAttribute internal to avoid conflicts with other definitions outside of the package. [1.2.6] - 2022-02-11 Changed Made Il2CppEagerStaticClassConstructionAttribute internal to avoid conflicts with other definitions outside of the package. [1.2.5] - 2021-11-01 Fixed Fixed property drawing when manually drawing a property that was hidden with [HideInInspector]. [1.2.4] - 2021-09-22 Added Added [Il2CppEagerStaticClassConstruction] to Unity.Mathematics types to run static constructors at startup. This improves IL2CPP performance slightly for types that have static constructors. Changed License file updated to satisfy Unity's package validation tests. Changed noise documentation in comments to xmldoc comments. Fixed Fixed Equals(object) override which did not check type before casting. This could cause exceptions to be thrown when the object did not match the expected type. Fixed incorrect math.tzcnt documentation which mentioned leading zero counts instead of trailing zero counts. Fixed float2x2.Rotate documentation to mention radians instead of degrees. Fixed documentation for methods and properties that were previously undocumented. [1.2.1] - 2020-08-06 Fixed Fixed warnings for meta files existing even though the files they represent did not exist. Internal (Not ready for production) [1.2.0] - 2020-08-03 Added Added [MethodImpl(MethodImplOptions.AggressiveInlining)] to many static functions to improve IL2CPP performance. Added compress() that accepts a float4 and uint4. Added math.project() and math.projectsafe() for vector projection. Added math.EPSILON, math.INFINITY, math.NAN and their double counterparts. Added [Serializable] to RigidTransform. Added math.ceillog2(). Added math.floorlog2(). Added math.down(), math.forward(), etc for Cartesian coordinate axes that match UnityEngine Vector3 equivalents. Added math.ispow2(). Added half.MinValueAsHalf and half.MaxValueAsHalf to avoid having to explicitly convert from float. Added a float3x3 constructor which takes a float4x4 as input. Added [Serializable] to half types. Added some performance tests which can be run from the Unity test project. Added Random.CreateFromIndex() to assist in creating Random instances from loop indices. Fixed Fixed documentation bug where quaternion.RotateX/Y/Z referred to a float4x4 instead of quaternion. Fixed code generation bugs which could cause Windows and Mac to generate different test code. Fixed some test asserts which used NaNs and signed zeros which failed in IL2CPP builds. Updated documentation for math.countbits() to include equivalent names on Intel and ARM architectures to aid in discoverability. Internal (Not ready for production) Added Unity.Mathematics.Geometry.Plane to represent planes in 3D space. Added more MinMaxAABB functionality from Unity.Physics.Aabb. Added Unity.Mathematics.Geometry.Math to hold static functions like AABB transformations. Added MinMaxAABB. [1.1.0] - 2019-07-08 Release stable version [1.1.0-preview.1] - 2019-06-27 Add new math.bitmask to return a bit mask from a bool4 [1.0.1] - 2019-04-15 Release stable version Modify all math constants (e.g math.PI) to provide float constant by default instead of double. Use for example math.PI_DBL to get the previous double constant. [1.0.0-preview.1] - 2019-02-28 Fixed bug where modifications on prefabs could not be reverted for vector properties when using context menu in Inspector. Fixed structure of the package for internal validation"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/4x4-matrices.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/4x4-matrices.html",
    "title": "4×4 matrices | Inventory System",
    "summary": "4×4 matrices To create a 4×4 transformation matrix, use the constructors in float4x4 to assign one value to all elements of the matrix, or individually set all 16 elements directly: // Unity Mathematics example void Build4x4UnityMathematics() { var c0 = new float4(1.0f, 0.0f, 0.0f, 0.0f); var c1 = new float4(0.0f, 1.0f, 0.0f, 0.0f); var c2 = new float4(0.0f, 0.0f, 1.0f, 0.0f); var c3 = new float4(0.0f, 0.0f, 0.0f, 1.0f); var m = new float4x4(c0, c1, c2, c3); } Multiplying a 4×4 matrix Unity Mathematics and UnityEngine define the * operator differently. The * operator for float4x4 implements componentwise multiplication. If you multiply a float4x4 of all 1s with 0.5 on the diagonal, you get back the half identity because the upper and lower triangles of the matrix are multiplied by the respective zero entries from f4x4_HalfIdentity: // Unity Mathematics example void OperatorMultiply4x4UnityMathematics() { float4x4 result = f4x4_Ones * f4x4_HalfIdentity; // result: // 0.5, 0.0, 0.0, 0.0, // 0.0, 0.5, 0.0, 0.0, // 0.0, 0.0, 0.5, 0.0, // 0.0, 0.0, 0.0, 0.5 } Multiplying a 4×4 matrix and a 4D vector Use the math.mul method to multiply a 4×4 matrix and a 4D vector. If you supply a float4x4 as the first parameter and a float4 as the second, it performs a 4×4 matrix multiplication with a 4×1 column vector, which returns a 4×1 column vector as a float4. math.mul can also multiply a 1×4 row vector by a 4×4 matrix to produce a 1×4 row vector by taking a float4 as the first parameter and a float4×4 as the second. Unity Mathematics stores the row vector in a float4 and it isn't treated as a separate type. // Unity Mathematics example void Multiply4x4AndVector4UnityMathematics() { float4 result1 = math.mul(f4x4, f4); // 4x4 * 4x1 = 4x1 float4 result2 = math.mul(f4, f4x4); // 1x4 * 4x4 = 1x4 }"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Unity Mathematics Compatibility with Mathf Getting started Common operations 4×4 matrices Vector multiplication Quaternion multiplication Random numbers"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/compatibility.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/compatibility.html",
    "title": "Compatibility with UnityEngine mathematics | Inventory System",
    "summary": "Compatibility with UnityEngine mathematics If you want to Burst-compile your project, it's best practice to use the Unity Mathematics package by default and only use Mathf when necessary. Unity Mathematics isn't implemented in the same way as the UnityEngine.Mathf struct in the core Unity engine. Because of this, if your application relies on the specific behaviors of Mathf, you'll have to reimplement them to get similar behavior in Unity Mathematics. Important For performance reasons, if your project uses the Mono compiler, you should continue to use the mathematical operations in Mathf, rather than Unity Mathematics. You can use both Mathf and Unity Mathematics methods in your project, but it might impact on the performance of your application because the conversions between the UnityEngine and Unity.Mathematics types such as Vector3 to float3 and vice-versa are performance-intensive. Porting UnityEngine code to Unity.Mathematics If you want to migrate code from UnityEngine to Unity.Mathematics, you need to make the following changes first: Update UnityEngine types to Unity.Mathematics types. For example, Vector4 to float4, and Quaternion to quaternion. These examples aren't exhaustive: see the Scripting API reference for the full list of Unity Mathematics types available. Update any operators involved in matrices or vectors. For example, the Matrix4x4 multiplication operator implements matrix multiplication, but the float4x4 multiplication operator implements componentwise multiplication. Degrees to radians How your code generates random numbers. Random in Unity.Mathematics works differently to Random in UnityEngine. You can completely control random number generation with Random in Unity.Mathematics, and it's instanced, rather than static. It's also exclusive with its upper bound, which is important to bear in mind if you want to convert UnityEngine code which is sensitive to the bounds. For more information, see the documentation on Random numbers."
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/getting-started.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/getting-started.html",
    "title": "Getting started | Inventory System",
    "summary": "Getting started To use Unity Mathematics, add using Unity.Mathematics to your code: using static Unity.Mathematics.math; namespace MyNamespace { using Unity.Mathematics; ... var v1 = float3(1,2,3); var v2 = float3(4,5,6); v1 = normalize(v1); v2 = normalize(v2); var v3 = dot(v1, v2); ... } Naming convention In C# int and float are built-in types. The Burst compiler extends this set of built-in types to also include vectors, matrices, and quaternions. These types are built-in because the Burst compiler already has implementations of these types, and so can use them to generate better code than for custom types. To signify that these types are built-in their type names are in all lower case. The operators on these built-in types in Unity.Mathematics.math are intrinsics and are always in lower case. There are no plans to extend the set of intrinsic types beyond the current set of vectors (typeN), matrices (typeNxN) and quaternions (quaternion). This convention has the added benefit of making the library highly compatible with shader code and makes porting or sharing code between the two almost frictionless."
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/index.html",
    "title": "Unity Mathematics | Inventory System",
    "summary": "Unity Mathematics Unity Mathematics is a C# math library that provides vector types and math functions that have a shader-like syntax, similar to SIMD or HLSL. The Burst compiler uses Unity Mathematics to compile C#/IL code into highly efficient native code. It implements the following vector and matrix types: floatN, quaternion float3×3, float4×4 Plus elementary functions: min, max, fabs, etc. sin, cos, sqrt, normalize, dot, cross, etc. Installation You can install the Mathematics package through Unity's Package Manager. For more information, see the Unity User Manual documentation on Adding and removing packages. Editor config Unity Mathematics uses editorconfig to keep files formatted for EOL and spaces. Your IDE should have support for editorconfig. If it doesn't, you can get the extension for it here: VS2015/VS2017 EditorConfig extension Visual Studio Code EditorConfig extension SublimeText EditorConfig extension"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/quaternion-multiplication.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/quaternion-multiplication.html",
    "title": "Quaternion multiplication | Inventory System",
    "summary": "Quaternion multiplication To rotate a quaternion, use the AxisAngle method. You need to specify the axis of rotation and the angle of rotation, in that order. All are in radians rather than degrees. math.mul multiplies the quaternion, just as with matrices and vectors. // Unity Mathematics example void QuaternionMultiplicationUnityMathematics() { var axis = new float3(0.0f, 1.0f, 0.0f); var q = quaternion.AxisAngle(axis,math.radians(45.0f)); var orientation = quaternion.Euler( math.radians(45.0f), math.radians(90.0f), math.radians(180.0f)); var result = math.mul(q, orientation); }"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/random-numbers.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/random-numbers.html",
    "title": "| Inventory System",
    "summary": "Random numbers To generate random numbers, you must create and manage the random number generator state yourself with the Random struct. You can control the random number generator state explicitly, which is useful if you're using parallel code, or if you want to make sure that one source of random numbers is seeded differently than another source. You can also have as many Random instances as you like. Once you set up the state, use NextFloat to get random floats. By default it returns random numbers between [0, 1), exclusive: // Unity Mathematics example void RandomNumberUnityMathematics() { // Choose some non-zero seed and set up the random number generator state. uint seed = 1; Unity.Mathematics.Random rng = new Unity.Mathematics.Random(seed); // [0, 1) exclusive float randomFloat1 = rng.NextFloat(); // [-5, 5) exclusive float randomFloat2 = rng.NextFloat(-5.0f, 5.0f); }"
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/vector-multiplication.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/Documentation~/vector-multiplication.html",
    "title": "Vector multiplication | Inventory System",
    "summary": "Vector multiplication To multiply vectors, use the *: // Unity Mathematics example void ComponentwiseVectorMultiplyUnityMathematics() { var v0 = new float4(2.0f, 4.0f, 6.0f, 8.0f); var v1 = new float4(1.0f, -1.0f, 1.0f, -1.0f); var result = v0 * v1; // result == new float4(2.0f, -4.0f, 6.0f, -8.0f). } This is a common way of writing SIMD code, which applies a single instruction to multiple data elements. Other operators such as addition, subtraction, and division work in the same way."
  },
  "Library/PackageCache/com.unity.mathematics@8017b507cc74/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.mathematics@8017b507cc74/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.mathematics copyright © 2023 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [1.0.0] - 2024-08-28 Changed Become a core package Fixed Scoring of distributed authority hosting model in the Recommendations tab Minor wording and style improvement Packages that are not fundamentally incompatible with game specs are marked again as \"Not Recommended\" instead of \"Incompatible\" [1.0.0-pre.3] - 2024-08-21 Fixed The Quickstart tab was not automatically shown after installing packages Made the UI look more responsive when reopening the window during package installation Added vertical Scrollbar to the Game specifications section Changed Always installing the latest Netcode for GameObjects 2.0.0-pre.x when it is selected as Netcode solution Made loading wheel more visible when installing packages (dark mode) Sort the game genre list alphabetically in the Recommendations tab [1.0.0-pre.2] - 2024-08-01 Changed Widgets are now recommended for Netcode for Entities. [1.0.0-pre.1] - 2024-07-29 Fixed Quickstart Tab: Show HelpBox if no quickstart package is installed but Quickstart Tab is visible. [0.4.0] - 2024-07-19 Added Added Recommendation for Distributed Authority hosting model with Netcode for GameObjects. Undo support for Recommendation tab. Added status Label at the bottom for package related information. Changed Refined the Netcode Recommendation. The Quickstart tab is deactivated if no multiplayer-related package is installed. [0.3.0] - 2024-06-06 Added Added analytics to the package Changed New user interface for the recommendations tab Multiplayer Center no longer upgrades packages that are embedded, linked locally, installed via Git or local Tarball Window can now be found under Window > Multiplayer > Multiplayer Center Updated the recommendation of the Widgets package (only compatible with Netcode for GameObjects at the moment) Updated the tooltips and various texts in the recommendations tab [0.2.1] - 2024-04-25 Non user-facing changes only [0.2.0] - 2024-04-24 Added Automatic installation of the Getting Started content. Changed API for the getting started content. [0.1.0] - 2024-04-22 This is the first release of com.unity.multiplayer.center. The package provides a new Window available at Window > Multiplayer Center that gives a starting point to create a multiplayer game. The window consists of two tabs: Recommendations and Getting Started. The Recommendations tab provides a customized list of packages and solutions to use based on the characteristics of your multiplayer game. The Getting Started tab provides a list of resources based on the packages that you have installed."
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/TableofContents.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/TableofContents.html",
    "title": "| Inventory System",
    "summary": "About the Multiplayer Center package System requirements Use the Multiplayer Center window"
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/index.html",
    "title": "Multiplayer Center package | Inventory System",
    "summary": "Multiplayer Center package The Multiplayer Center package generates a customized list of Unity packages and services for the type of multiplayer game you want to create and installs them. Install To install this package, refer to Install a package from a registry."
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/sys-req.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/sys-req.html",
    "title": "System requirements | Inventory System",
    "summary": "System requirements The Unity Multiplayer Center package is compatible with the following versions of the Unity Editor: Unity 6 beta and later"
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/use-multiplayer-center.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Documentation~/use-multiplayer-center.html",
    "title": "Use the Multiplayer Center window | Inventory System",
    "summary": "Use the Multiplayer Center window Open the Unity Multiplayer Center window by selecting Window > Multiplayer > Multiplayer Center. To use the Multiplayer Center, do the following: Select Game Specifications to generate recommended packages and solutions in the Recommendation tab Install the packages the Multiplayer Center recommends. Follow the examples and resources in the Quickstart tab to use the packages you installed. Generate a list of recommended packages for a multiplayer game To generate a list of packages that meet the needs of the multiplayer game you want to make, do the following: Select a value in each Game Specification field. Examine the packages that the Multiplayer Center suggests are the best solutions for your game. Hover over each package name in the Recommended Multiplayer Packages section to learn why each package is useful for the game specifications you selected. The recommendations that appear in the Recommendation tab change immediately when you change any of the Game Specifications properties. You can select which packages to install or ignore. However, you can't deselect packages that are essential for the netcode solution or hosting model you selected. Install recommended packages To install the packages the Multiplayer Center recommended, select Install Packages. Unity then installs these packages and their dependencies in your project and automatically opens the Quickstart tab. To remove a package from the install process, deselect the checkbox next to the package name before you select Install Packages. When a tick appears next to a package name, hover over it to learn which version of this package exists in your project. To install an individual package: Select the Open Package Manager icon next to the package you want to install. In the Package Manager window that appears, select Install. Important: If the Multiplayer Center detects that any other multiplayer package is already installed, a warning dialog appears to cancel the installation of those packages. To avoid breaking changes, backup your project before you continue. If you continue with the installation, Unity installs or upgrades the selected packages but doesn't remove existing packages. This can cause compatibility issues. To fix them, remove the conflicting packages from your project in the Package Manager window. Get started with the recommended packages The Quickstart tab includes guidance, examples, and links to resources about the packages that the Multiplayer Center installs. Follow this guidance to set up and use these packages. The Quickstart content sometimes changes based on the recommendations you selected in the Recommendation tab. The Quickstart tab organises this guidance into categories. Follow the instructions in each category from top to bottom to set up each package in your project. Some packages have the option to import example setups to help you get started with their functionality. To modify a script asset that the Multiplayer Center imports, copy the contents of the script to a new file and change the namespace."
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.multiplayer.center copyright © 2023 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions.”"
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/README.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/README.html",
    "title": "Multiplayer Center | Inventory System",
    "summary": "Multiplayer Center The Multiplayer Center provides a starting point to create multiplayer games of all types. It starts by asking you a range of questions to identify your needs. It will then recommend and install a range of packages to help get you started. The Multiplayer Center provides interactive guidance and a rich selection of resources to help you experiment with all the new tools that are now part of the Multiplayer end-to-end experience. The Unity Multiplayer Center is added as a default package for a short period until it becomes a core module. We are integrating the lightweight Multiplayer Center directly into the Unity Editor to enhance your game development experience. Open the Unity Multiplayer Center window by selecting Window > Multiplayer > Multiplayer Center. Original Repository: https://github.cds.internal.unity3d.com/unity/com.unity.multiplayer.center/ 1c1c6d10c13a0f8e5329e463d690e27442180f9a"
  },
  "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.multiplayer.center@f3fb577b3546/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package does not contains third-party software."
  },
  "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [1.11.4] - 2021-11-30 This is a verified release of the com.unity.nuget.mono-cecil with embedded dlls of mono-cecil Updated Mono to 0.11.4 [1.10.2] - 2021-10-04 This is a verified release of the com.unity.nuget.mono-cecil with embedded dlls of mono-cecil Updated with Signature for publishing Updated internal CI Fixtures [1.10.1] - 2020-11-14 This is a verified release of the com.unity.nuget.mono-cecil with embedded dlls of mono-cecil [1.10.1-preview.1] - 2020-11-14 Update README [1.10.0] - 2020-11-14 This is a verified release of the com.unity.nuget.mono-cecil with embedded dlls of mono-cecil [1.10.0-preview.1] - 2020-11-14 This is a preview of the verified release of the com.unity.nuget.mono-cecil with embedded dlls of mono-cecil [0.1.6-preview.3] - 2020-11-14 Doc and Meta File Updates [0.1.6-preview.1] - 2020-06-18 This is a SHIM Package to change the namespace of the mono-cecil package from nuget.mono-cecil to com.unity.nuget.mono-cecil [0.1.6-preview] - 2020-06-18 Updated to use the package publishing CI Updated documentation and other files to fit valid package structure"
  },
  "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/Documentation~/index.html",
    "title": "Mono.Cecil Unity Package | Inventory System",
    "summary": "Mono.Cecil Unity Package This is a package intended for internal Unity Development Projects and as such this package is not supported. Use at your own risk. This is a Unity package for Mono.Cecil and corresponds to Mono.Cecil version 0.11.4. Documentation for this Package is provided as links to the Mono.Cecil Documentation. Mono.Cecil is a library to generate and inspect programs and libraries in the ECMA CIL form. Documentation Mono Project Mono.Cecil Mono.Cecil Wiki Mono.Cecil Development Log Mono.Cecil Source Code This is a package intended for internal Unity Development Projects and as such this package is not supported. Use at your own risk."
  },
  "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.nuget.mono-cecil copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/README.html": {
    "href": "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/README.html",
    "title": "Mono Cecil | Inventory System",
    "summary": "This package wraps the Mono-Cecil DLLs. Mono Cecil Unity Package for [Mono.Cecil library] https://www.nuget.org/packages/Mono.Cecil/ This package includes the DLL version of Mono.Cecil Version: 0.11.4 This package is intended to be inherited as a dependency, and should not be directly installed, by end users."
  },
  "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.nuget.mono-cecil@d6f9955a5d5f/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Mono.Cecil License Type: MIT The MIT License (MIT) Copyright (c) 2008 - 2015 Jb Evain Copyright (c) 2008 - 2011 Novell, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [17.0.3] - 2025-02-13 This version is compatible with Unity 6000.0.39f1. Added helper functions to Render Graph. Changed Improved the Native Render Pass CPU performance by implementing a Render Pass pooling system (URP RG). Reworked the additional properties. Improved Render Graph warning message in URP when missing RecordRenderGraph implementation. Displayed subpass and attachment index on Render Graph Viewer. Added a new icon and tooltip if there are multiple usage details for a resource block on Render Graph Viewer. Fixed Render Graph Viewer being called before Render Graph execution and its resource deallocation. Added What's New in Unity 6 to SRP Core Package. Fixed Added messaging to the Rendering Debugger UI to make it clearer that GPU Resident Drawer settings do not work if GPU Resident Drawer is not enabled. GPU Resident Drawer: Changed BatchRendererGroup variants was not reinitializing the system. Improved the compiler logic that detects if the current render target is being used outside the current native render pass (e.g., when the pass is broken up by an unsafe pass), and determines the store action for this case. The fix now ensures that the StoreAndResolve action is used when the resource is read by an Unsafe Pass. Rendering Debugger - Keep the correct selected panel when entering and exiting from playmode. Removed \"depth only surface\" warning message appearing when using Game View Gizmos in URP RG. Render Graph Viewer: Fixed missing min height when resizing side panel vertical splitter. Render Graph Viewer: Fixed possible NullReferenceException when opening the project. Render Graph Viewer: Fixed side panel splitter state after returning from empty pass/resource filter. Render Graph Viewer: Fixed long resource name clipping issues in side panel. Render Graph Viewer: Fixed tooltip size bug and restructure tooltip messages. Fixed memory usage regression causing up to 150MB higher memory usage in URP player builds. Added missing user-facing text when inspecting volume profile when render pipeline has not been properly initialized yet. Game view background turn yellow after enable render graph. Fixed light.useViewFrustumForShadowCasterCull previously being ignored for shadow cascades. light.useViewFrustumForShadowCasterCull now works as expected. Fixed an exception thrown when Render Graph pass was missing its renderFunc but tried to compute its hash value. Fixed Render Graph Compiler logic bug where UnsafePass using MSAA texture could result in missing resolve surface errors. Fixed incorrect default source texture name for Render Graph blit util function. Fixed NullReferenceException when jumping to pass code from Render Graph Viewer. Fixed _FOVEATED_RENDERING_NON_UNIFORM_RASTER shader compilation errors. Fixed a null reference exception on the Graphics Settings stripper. Avoid that the same volume can be registered more than 1 time in the VolumeManager. Fixed crash caused by indirect argument buffer being one item too small. [GLES3] Fixed an issue where Blitter.GetBlitMaterial(TextureDimension.Tex2DArray) returns null. Fixed alignment of the columns on DebugUI.Foldouts. Fixed BlitTexture(RenderTargetIdentifier) to be affected by PostProcessing. Fixed errors that could happen when interacting with the Default Volume Profile context menu in Project Settings > Graphics. Fixed a numerical error of ComputeEdgeFactor(V1, V2) when two vectors are colinear. Fixed potential data corruption due to incorrect native render pass store action in NRP compiler. Added stencil flag to read-only depth logic in NRP compiler to avoid unintentional usage of depth read and stencil write states on some APIs. Added more error checking to RenderGraph.ImportTexture to prevent importing RenderTextures that have both color and depth. An exception will now be thrown in this case. Fixed an issue when using multiple AddBlitPass would binds the _BlitTexture wrongly. Modified TextureDesc so it can now use GraphicsFormat to set the depthStencil format (TextureDesc.format). The TextureDesc.depthBufferBits and TextureDesc.colorFormat fields are now properties that call GraphicsFormatUtilities functions for backwards compatibility. The descriptor now unambiguously describes a single resource, either color or depth. Therefore, TextureHandle clearly represents a single resource. Modified RTHandle allocators so they can now use GraphicsFormat to set the depthStencil format (TextureDesc.format). The allocators take a single format for either color or depth stencil to avoid incorrectly creating depth instead of color or vice versa. Fixed a crash on DX12 due to invalid subpass flags passed by native render pass compiler. Fixed an issue where Lens Flare was not rendering properly in OpenGLES3. Fixed render graph incorrectly handling rendering to array slices and mipmaps other than 0 in some cases. Render Graph Viewer - Improved UI lock when searching on side panels. Render Graph Viewer - Padding corrected on burger menu on the side panels. Fixed missing STP shaders & visual artifacts when targeting GLCore renderer Rendering Debugger - Silent crash when selecting a Volume component with public RTHandles. Fixed a crash on leaking streaming scratch buffer differently sized into the current pool. [17.0.2] - 2024-04-02 This version is compatible with Unity 6000.0.0b15. Changed Improved Render Graph Viewer UI to allow jumping to pass definitions in C# IDE. Replaced the overlays inside the RenderGraph Viewer with a fixed side panel. Small optimization, frame allocation checks of the Render Graph resource pool are now enabled through Validation checks. Improved and unified render graph profiling markers. Improved execution performance with Render Graph. Improved the resource pooling system in Render Graph. Improved BeginRenderPass CPU performance in the Native Render Pass Render Graph (URP). Made various improvements to Render Graph Viewer UX. Fixed Improve reliability of shader variance list regex parser. Current parser includes time stamps which cause duplicates to not be parsed correctly. Changes improve regex parsing and sanitize the liens from the log (which include time stamps). Fixed amemory leak from NativeList in RenderGraph. Fixed some leaks / missing calls to Dispose() in GI probe baking code. Fixed an issue where Screen Space UI Overlay would not rendered again without a camera in URP/HDRP. Fixed issue where using BiRP-only Camera APIs with active SRP didn't display a warning as expected. Fixed issue where errors could be thrown by debug action registration if deleting all axes in Input Manager. Tier0 rendering ignores the scene visibility toggle. Rendering Debugger - Fixed Render Graph Debug Display Reset behaviour. Added CreateSkyboxRendererList in Render Graph API. Fixed PackFloat2To8 in packing.hlsl. Fixed DebugUI.Button not working in Rendering Debugger runtime UI. Fix Render Graph Viewer generating warnings when RenderGraph.Begin/EndProfilingSampler functions are used Fixed Render Graph Viewer becoming empty on URP when selecting Project Settings > Graphics Fix Render Graph Viewer displaying incorrect store action reasoning for MSAA textures [17.0.1] - 2023-12-21 This version is compatible with Unity 2023.3.0b2. Added API to manage global textures New useDynamicScaleExplicit flag to render graph's TextureDesc which can be used to control the underlying RenderTexture's dynamic scaling behavior Added TEMPLATE_X_HALF shader macros that define functions using min16float only. Added TEMPLATE_X_FLT_HALF shader macros that defines functions with both min16float and float. Foveated rendering API to fix FSR rendering new API that allows users to execute Scalable Temporal Post-Processing (STP) upscaling in a render graph. Changed Replaced DynamicArray with NativeList in NativeRenderPassCompiler to improve performance Improved CPU performance of Native Render Pass Render Graph compiler by 15-40% (combined with NativeList PR and other optimization) depending on the complexity of the rendering and the runtime device Merged rendergraph native render passes that have different depths. Added GPU Resident Drawer debug panel to display culling stats when Instanced Drawing is enabled. Added icons and fixed bugs in Render Graph Viewer. Prevented the unnecessary store op of MSAA buffers in URP when using Native Render Pass Render Graph. RenderGraphObjectPool is now 3x faster with RasterRenderRenderGraphPass objects by using UnityEngine.Pool Reducing AddRaster/Compute/UnsafeRenderPass Render Graph API CPU cost by not clearing anymore internal arrays. Now relying on handle IsValid() API instead. Validation checks of Render Graph can be enabled/disabled from the Editor. Enabled by default, disabling them slightly improves Render Graph performance. Fixed Bump MaxReaders Fixed CurrentPipelineHelpURLAttribute.URL returning null when render no pipeline is active, causing errors. Fix volume profile reset action in graphics settings Fix Remove All context action for Volume Profile not working in VolumeEditor Add XR for Lens Flare Data Driven Fixed left eye's Lens Flare light in XR [17.0.0] - 2023-09-26 This version is compatible with Unity 2023.3.0a8. Changed Dumping in the temp folder the stripping of IRenderPipelineGraphicsSettings Fixed Fixed an issue in the Rendering Debugger where APV was not shown on editor when Strip runtime debug shaders was enabled in the global settings. Fixed Stripping.meta corrupted metal file. When changing the Global Settings asset, the UI was not being refreshed to and the old asset was being displayed. Allowing buffer read through NRP RenderGraph API. [16.0.3] - 2023-07-04 This version is compatible with Unity 2023.3.0a1. Added RenderPipelineGraphicsSettings container. That allows stripping of IRenderPipelineGraphicsSettings. Changed Improved VolumeEditor UI Fixed Fix console errors when debug actions are removed from Input Manager during play mode [16.0.2] - 2023-06-28 This version is compatible with Unity 2023.2.0a22. Fixed Fixed Rendering Debugger runtime UI getting occluded by user UI with sorting order larger than 0. Fixed potentially broken rendering and errors after renaming a VolumeProfile asset. Removed some unexpected SRP changed callback invocations. Fixed HDRP FrameSettings object changes getting lost during editing. [16.0.1] - 2023-05-23 This version is compatible with Unity 2023.2.0a17. Added ObjectID Render Request that provides a render texture with the ObjectId of each pixel. Exposed VolumeProfileEditor as public. Added RenderPipelineGlobalSettingsUI::DrawVolumeProfileAssetField. Added VolumeComponentListEditor::SetIsGlobalDefaultVolumeProfile. Changed Added optimizations to Static APV for Mobile Devices. Fixed Rendering Debugger - Foldouts - Right Click anywhere on the foldout opens the context menu. Rendering Debugger - Foldouts - Left click on context menu collapsed/expand the foldout. Rendering Debugger - HotKeys- Fixed regression to open the Rendering Debugger with Ctrl + Backspace on standalone/player modes. Fixed SerializedBitArray behavior when editing multiple objects or values. (e.g. HDRP Frame Settings toggles working inconsistently) Fixed a crash on keywords::LocalKeywordState::ResetWithSpace when shader contains Grab Pass. [16.0.0] - 2023-03-22 This version is compatible with Unity 2023.2.0a9. Added Common C# & Shader Code for Scalable Temporal Post-Processing Upscaler. Changed Unified the Create, Clone and Ensure workflows for RenderPipelineGlobalSettings. Fixed Updated the Render Graph documentation to reflect API changes. Fixed an IES Importer issue producing incorrect results. Fixed the Revert Property for animation curves on Volume Components so it now works correctly. Fixed Decal Projector Editor fields so they are now saved when editing a prefab. [15.0.3] - 2022-12-02 This version is compatible with Unity 2023.2.0a1. Added Added HDR output utilities to handle keywords and shader stripping. Changed Deprecated the VolumeComponentMenuForRenderPipeline. Fixed Fixed volume profile field state when asset is removed. Fixed ColorCurves volume leaking Texture2D objects under certain circumstances. Fixed virtual offset pushing probes outside of geometry. Added Local mode to fit Probe Volumes to scene. Fixed APV so it is now present in the light explorer. Fixed reset of APV debug. [15.0.2] - 2022-11-04 This version is compatible with Unity 2023.1.0a23. Added Extended RendererList to handle UI, WireFrame, CameraSetup and Gizmo draw. Added bigQuery Nested columns extensions. Changed Restructured the APV indirection buffer to decrease the amount of memory required when an high number of subdivision levels is used. Allow setting order for panels on the rendering debugger. Enabled VolumeComponent BoolParameter UI to display enabled/disabled dropdown instead of checkboxes. Fixed Fixed a FreeCamera printing an error when using old InputSystem. Fixed an issue where shaders from any SRP not are completely stripped when building for Built-in renderer. Fixed dropdowns for multiple editors. Fixed the behaviour preventing the bake to restart if probe volumes are changed while a bake has started. Fixed global probe volumes not fitting to all objects. Fixed shadow cascade editor so the snatches now appear and the gradient appearance is improved. Fixed missing subdivision label when looking at APV realtime subdivision preview. Updated the Volumes when the Volume Info is collapsed. Fixed changing current value by mouse click on DebugUI.ObjectFields on the runtime UI. Fixed missing documentation and documentation links on Rendering-Debugger and components used for the Runtime UI. Fixed popup showing multiple time when trying to remove additional data while in multi selection. Fixed VolumeComponent visibility without additional attributes. Fixed null exception while selecting a camera on the Rendering Debugger > Volumes > Camera. [15.0.1] - 2022-08-04 This version is compatible with Unity 2023.1.0a19. Added An extension method to fetch the Render Pipeline assets from a BuildTarget. Added new XRSystem API to allow SRPs override the XR built-in stereo matrices. Changed Tooltips improvement across SRPs. Fixed Fixed a Volume Component Editor issue where Foldouts states were stored by position instead of state. Fixed a SerializedObjectNotCreatableException on Volume Component Editors. Fixed a null reference exception when settings null Render Pipeline Global settings on the Settings provider. Fixed a swaping Volume Component issue in a Volume profile when there was mixed pipeline Volume Components did not override correctly. Fixed a serialization error when Recovering Default Volume Profile after it was deleted from the project folder. Fixed an editor drawer for Value tuples in the Rendering Debugger. Fixed an issue where Asset Icons and MonoBehaviour for SRP's where not unified. [15.0.0] - 2022-06-13 This version is compatible with Unity 2023.1.0a6. Added Extension method to fetch the Render Pipeline assets from a BuildTarget. New XRSystem API to allow SRPs override the XR built-in stereo matrices. Changed Improved performance of APV baking. Allow setting order for panels on the rendering debugger. Allow VolumeComponent BoolParameter UI to display enabled/disabled dropdown instead of checkboxes. Fixed Fixed the reset of APV volume placement when using multi selection. Fixed an issue so that APV dilated data not being written back to disk. Fixed realtime subdivision so it culls empty cells. Hid the warning on the reflection probe if you disable APV. Fixed so that data isn't cleared for probes to be dilated into, to avoid bright colored splotches. Fixed probes so that the max distance between then are respected. Fixed uninitialized memory for virtual offset. Fixed NaN when you bake high intensity lights. Fixed the APV touchup volume test so it uses OBB instead of AABB. Fixed null reference when you enable the Camera in a project with multiple SRPs installed. Volume Component Editor Foldouts states are now stored by type instead of by position. Fixed SerializedObjectNotCreatableException on Volume Component Editors. Fixed null reference exception when settings null Render Pipeline Global settings on the Settings provider. Fixed swapping Volume Component in a Volume profile with mixed pipeline Volume Components. Default Volume Profile can now be recovered when it is being deleted from the project folder. Fixed editor drawer for Value tuples in the Rendering Debugger. Fixed an issue where FreeCamera would print an error when using old InputSystem. Fixed missing subdivision label when looking at APV realtime subdivision preview. Fixed shadow cascade editor so the snatches now appear and the gradient appearance is improved. Fixed the behaviour preventing the bake to restart if probe volumes are changed while a bake has started. Fixed global probe volumes not fitting to all objects. Fixed dropdowns for multiple editors. Fixed Light Editor didn't apply changes to SerializedObject. [14.0.3] - 2021-05-09 Fixed Added Shader Stripping Watcher so you get notifications when a Shader Variant is stripped. [14.0.2] - 2021-02-04 Added Added new extension TryRemoveElementsInRange to remove a range of elements from a IList. Added error on ResourceReloader when attempting to use [ReloadGroup] on ScriptableObject. Added Screen Coordinates Override shader utilities. Added API to blend between baking states for Probe Volumes. Aded explicit control over scenario blending factor and a debug mode for visualization. Fixed Fixed texture gather macros for GLCore and moved them from target 4.6 to target 4.5. Fixed cubemap array macros for GLCore. Fixed regression on ResourceReloader due to change for supporting built-in resources. Fixed issue with debug markers in Unity Profiler in deep profiler mode [14.0.1] - 2021-12-07 Added Linear version of function that sets FSR RCAS shader constants DebugUI.ObjectPopupField to render a list of UnityEngine.Objects as a popup on the Rendering Debugger. Add probe volume influence weight parameter Added support for multiple Baking States to Prove Volumes. Hidding Volume Components not available for the current pipeline on the Volume Profile Inspector. Changed Volume Component editor are now specified by CustomEditorAttribute instead of VolumeComponentEditorAttribute. Fixed The Volume Panel on the Rendering Debugger was not corretly showing cameras when they were added or deleted. Fixed issue in DynamicResolutionHandler when camera request was turned off at runtime, the ScalableBufferManager would leak state and not unset DRS state (case 1383093). Fixed undo in for DebugUI.EnumFields on the rendering debugger. (case 1386964) Fixed DebugUI.Enum fields collapsing their parent DebugUI.Foldout Fixed IES profile importer handling of overflow (outside 0-1 range) of attenutation splines values. Fixed issue with Probe Volume Baking window incorrectly displaying the icon for probe volumes in scenes that don't contain probe volumes. Fixed unnecessary memory allocation inside FSR's RCAS shader constants helper function. Fixed the issue with the special Turkish i, when looking for the m_IsGlobal property in VolumeEditor. (case 1276892) [14.0.0] - 2021-11-17 Added Context menu on Volume Parameters to restore them to their default values. Fixed Fixed XR support in CoreUtils.DrawFullscreen function. Changed Removed FSR_ENABLE_16BIT option from FSRCommon.hlsl. The 16-bit FSR implementation is now automatically enabled when supported by the target platform. [13.1.2] - 2021-11-05 Added Added function to allocate RTHandles using RenderTextureDescriptor. Added vrUsage support for RTHandles allocation. Fixed Fixed issue when changing volume profiles at runtime with a script (case 1364256). Fixed XR support in CoreUtils.DrawFullscreen function. Fixed an issue causing Render Graph execution errors after a random amount of time. [13.1.1] - 2021-10-04 Added Added support for high performant unsafe (uint only) Radix, Merge and Insertion sort algorithms on CoreUnsafeUtils. Added DebugFrameTiming class that can be used by render pipelines to display CPU/GPU frame timings and bottlenecks in Rendering Debugger. Added new DebugUI widget types: ProgressBarValue and ValueTuple Added common support code for FSR. Added new RenderPipelineGlobalSettingsProvider to help adding a settings panel for editing global settings. Added blending for curves in post processing volumes. New extension for Render Pipeline Global Settings for shader variants settings -> IShaderVariantsSettings. [13.1.0] - 2021-09-24 Added Debug Panels Framework See IDebugDisplaySettingsQuery. Fixed Fixed keyword and float property upgrading in SpeedTree8MaterialUpgrader [13.0.0] - 2021-09-01 Version Updated The version number for this package has increased due to a version update of a related graphics package. Added New IVolumeDebugSettings interface and VolumeDebugSettings<T> class that stores the information for the Volumes Debug Panel. Added AMD FidelityFX shaders which were originally in HDRP Added support for high performant unsafe (uint only) Radix, Merge and Insertion sort algorithms on CoreUnsafeUtils. Fixed Fixed black pixel issue in AMD FidelityFX RCAS implementation Fixed a critical issue on android devices & lens flares. Accidentally creating a 16 bit texture was causing gpus not supporting them to fail. Fixed serialization of DebugStateFlags, the internal Enum was not being serialized. [12.0.0] - 2021-01-11 Added Support for the PlayStation 5 platform has been added. Support for additional properties for Volume Components without custom editor Added VolumeComponentMenuForRenderPipelineAttribute to specify a volume component only for certain RenderPipelines. Calculating correct rtHandleScale by considering the possible pixel rounding when DRS is on Support for the PlayStation 5 platform has been added. Support for the XboxSeries platform has been added. Added Editor window that allow showing an icon to browse the documentation New method DrawHeaders for VolumeComponentsEditors Unification of Material Editor Headers Scopes New API functions with no side effects in DynamicResolutionHandler, to retrieve resolved drs scale and to apply DRS on a size. Added helper for Volumes (Enable All Overrides, Disable All Overrides, Remove All Overrides). Added a blitter utility class. Moved from HDRP to RP core. Added a realtime 2D texture atlas utility classes. Moved from HDRP to RP core. New methods on CoreEditorDrawers, to allow adding a label on a group before rendering the internal drawers Method to generate a Texture2D of 1x1 with a plain color Red, Green, Blue Texture2D on CoreEditorStyles New API in DynamicResolutionHandler to handle multicamera rendering for hardware mode. Changing cameras and resetting scaling per camera should be safe. Added SpeedTree8MaterialUpgrader, which provides utilities for upgrading and importing SpeedTree 8 assets to scriptable render pipelines. Adding documentation links to Light Sections Support for Lens Flare Data Driven (from images and Procedural shapes), on HDRP New SRPLensFlareData Asset Adding documentation links to Light Sections. Added sampling noise to probe volume sampling position to hide seams between subdivision levels. Added DebugUI.Foldout.isHeader property to allow creating full-width header foldouts in Rendering Debugger. Added DebugUI.Flags.IsHidden to allow conditional display of widgets in Rendering Debugger. Added \"Expand/Collapse All\" buttons to Rendering Debugger window menu. Added mouse & touch input support for Rendering Debugger runtime UI, and fix problems when InputSystem package is used. Add automatic spaces to enum display names used in Rendering Debugger and add support for InspectorNameAttribute. Adding new API functions inside DynamicResolutionHandler to get mip bias. This allows dynamic resolution scaling applying a bias on the frame to improve on texture sampling detail. Added a reminder if the data of probe volume might be obsolete. Added new API function inside DynamicResolutionHandler and new settings in GlobalDynamicResolutionSettings to control low res transparency thresholds. This should help visuals when the screen percentage is too low. Added common include file for meta pass functionality (case 1211436) Added OverridablePropertyScope (for VolumeComponentEditor child class only) to handle the Additional Property, the override checkbox and disable display and decorator attributes in one scope. Added IndentLevelScope (for VolumeComponentEditor child class only) to handle indentation of the field and the checkbox. Added an option to change the visibilty of the Volumes Gizmos (Solid, Wireframe, Everything), available at Preferences > Core Render Pipeline Added class for drawing shadow cascades UnityEditor.Rendering.ShadowCascadeGUI.DrawShadowCascades. Added UNITY_PREV_MATRIX_M and UNITY_PREV_MATRIX_I_M shader macros to support instanced motion vector rendering Added new API to customize the rtHandleProperties of a particular RTHandle. This is a temporary work around to assist with viewport setup of Custom post process when dealing with DLSS or TAAU Added IAdditionalData interface to identify the additional datas on the core package. Added new API to draw color temperature for Lights. Fixed Help boxes with fix buttons do not crop the label. Fixed missing warning UI about Projector component being unsupported (case 1300327). Fixed the display name of a Volume Parameter when is defined the attribute InspectorName Calculating correct rtHandleScale by considering the possible pixel rounding when DRS is on Problem on domain reload of Volume Parameter Ranges and UI values Fixed Right Align of additional properties on Volume Components Editors Fixed normal bias field of reference volume being wrong until the profile UI was displayed. Fixed L2 for Probe Volumes. When adding Overrides to the Volume Profile, only show Volume Components from the current Pipeline. Fixed assertion on compression of L1 coefficients for Probe Volume. Explicit half precision not working even when Unified Shader Precision Model is enabled. Fixed ACES filter artefact due to half float error on some mobile platforms. Fixed issue displaying a warning of different probe reference volume profiles even when they are equivalent. Fixed missing increment/decrement controls from DebugUIIntField & DebugUIUIntField widget prefabs. Fixed IES Importer related to new API on core. Fixed a large, visible stretch ratio in a LensFlare Image thumbnail. Fixed Undo from script refreshing thumbnail. Fixed cropped thumbnail for Image with non-uniform scale and rotation Skip wind calculations for Speed Tree 8 when wind vector is zero (case 1343002) Fixed memory leak when changing SRP pipeline settings, and having the player in pause mode. Fixed alignment in Volume Components Virtual Texturing fallback texture sampling code correctly honors the enableGlobalMipBias when virtual texturing is disabled. Fixed LightAnchor too much error message, became a HelpBox on the Inspector. Fixed library function SurfaceGradientFromTriplanarProjection to match the mapping convention used in SampleUVMappingNormalInternal.hlsl and fix its description. Fixed Volume Gizmo size when rescaling parent GameObject Fixed rotation issue now all flare rotate on positive direction (1348570) Fixed error when change Lens Flare Element Count followed by undo (1346894) Fixed Lens Flare Thumbnails Fixed Lens Flare 'radialScreenAttenuationCurve invisible' Fixed Lens Flare rotation for Curve Distribution Fixed potentially conflicting runtime Rendering Debugger UI command by adding an option to disable runtime UI altogether (1345783). Fixed Lens Flare position for celestial at very far camera distances. It now locks correctly into the celestial position regardless of camera distance (1363291) Fixed issues caused by automatically added EventSystem component, required to support Rendering Debugger Runtime UI input. (1361901) Changed Improved the warning messages for Volumes and their Colliders. Changed Window/Render Pipeline/Render Pipeline Debug to Window/Analysis/Rendering Debugger Changed Window/Render Pipeline/Look Dev to Window/Analysis/Look Dev Changed Window/Render Pipeline/Render Graph Viewer to Window/Analysis/Render Graph Viewer Changed Window/Render Pipeline/Graphics Compositor to Window/Rendering/Graphics Compositor Volume Gizmo Color setting is now under Colors->Scene->Volume Gizmo Volume Gizmo alpha changed from 0.5 to 0.125 Moved Edit/Render Pipeline/Generate Shader Includes to Edit/Rendering/Generate Shader Includes Moved Assets/Create/LookDev/Environment Library to Assets/Create/Rendering/Environment Library (Look Dev) Changed Nintendo Switch specific half float fixes in color conversion routines to all platforms. Improved load asset time for probe volumes. ClearFlag.Depth does not implicitely clear stencil anymore. ClearFlag.Stencil added. The RTHandleSystem no longer requires a specific number of sample for MSAA textures. Number of samples can be chosen independently for all textures. Platform ShaderLibrary API headers now have a new macro layer for 2d texture sampling macros. This layer starts with PLATFORM_SAMPLE2D definition, and it gives the possibility of injecting sampling behavior on a render pipeline level. For example: being able to a global mip bias for temporal upscalers. Update icon for IES, LightAnchor and LensFlare LensFlare (SRP) can be now disabled per element LensFlare (SRP) tooltips now refer to meters. Serialize the Probe Volume asset as binary to improve footprint on disk and loading speed. LensFlare Element editor now have Thumbnail preview Improved IntegrateLDCharlie() to use uniform stratified sampling for faster convergence towards the ground truth DynamicResolutionHandler.GetScaledSize function now clamps, and never allows to return a size greater than its input. Removed DYNAMIC_RESOLUTION snippet on lens flare common shader. Its not necessary any more on HDRP, which simplifies the shader. Made occlusion Radius for lens flares in directional lights, be independant of the camera's far plane. [11.0.0] - 2020-10-21 Fixed Fixed the default background color for previews to use the original color. Fixed spacing between property fields on the Volume Component Editors. Fixed ALL/NONE to maintain the state on the Volume Component Editors. Fixed the selection of the Additional properties from ALL/NONE when the option \"Show additional properties\" is disabled Fixed ACES tonemaping for Nintendo Switch by forcing some shader color conversion functions to full float precision. Fixed a bug in FreeCamera which would only provide a speed boost for the first frame when pressing the Shfit key. Added New View Lighting Tool, a component which allow to setup light in the camera space New function in GeometryTools.hlsl to calculate triangle edge and full triangle culling. Several utils functions to access SphericalHarmonicsL2 in a more verbose and intuitive fashion. [10.2.0] - 2020-10-19 Version Updated The version number for this package has increased due to a version update of a related graphics package. [10.1.0] - 2020-10-12 Added Added context options \"Move to Top\", \"Move to Bottom\", \"Expand All\" and \"Collapse All\" for volume components. Added the support of input system V2 Fixed Fixed the scene view to scale correctly when hardware dynamic resolution is enabled (case 1158661) Fixed game view artifacts on resizing when hardware dynamic resolution was enabled Fixed issue that caused UNITY_REVERSED_Z and UNITY_UV_STARTS_AT_TOP being defined in platforms that don't support it. Changed LookDev menu item entry is now disabled if the current pipeline does not support it. [10.0.0] - 2019-06-10 Added Add rough version of ContextualMenuDispatcher to solve conflict amongst SRP. Add api documentation for TextureCombiner. Add tooltips in LookDev's toolbar. Add XRGraphicsAutomatedTests helper class. Fixed Fixed compile errors for platforms with no VR support Replaced reference to Lightweight Render Pipeline by Universal Render Pipeline in the package description Fixed LighProbes when using LookDev. Fix LookDev minimal window size. Fix object rotation at instentiation to keep the one in prefab or used in hierarchy. Fixed shader compile errors when trying to use tessellation shaders with PlayStation VR on PS4. Fixed shader compile errors about LODDitheringTransition not being supported in GLES2. Fix WaveIsFirstLane() to ignore helper lanes in fragment shaders on PS4. Fixed a bug where Unity would crash if you tried to remove a Camera component from a GameObject using the Inspector window, while other components dependended on the Camera component. Fixed errors due to the debug menu when enabling the new input system. Fix LookDev FPS manipulation in view Fix LookDev zoom being stuck when going near camera pivot position Fix LookDev manipulation in view non responsive if directly using an HDRI Fix LookDev behaviour when user delete the EnvironmentLibrary asset Fix LookDev SunPosition button position Fix LookDev EnvironmentLibrary tab when asset is deleted Fix LookDev used Cubemap when asset is deleted Fixed the definition of rcp() for GLES2. Fixed copy/pasting of Volume Components when loading a new scene Fix LookDev issue when adding a GameObject containing a Volume into the LookDev's view. Fixed duplicated entry for com.unity.modules.xr in the runtime asmdef file Fixed the texture curve being destroyed from another thread than main (case 1211754) Fixed unreachable code in TextureXR.useTexArray Fixed GC pressure caused by VolumeParameter<T>.GetHashCode() Fixed issue when LookDev window is opened and the CoreRP Package is updated to a newer version. Fix LookDev's camera button layout. Fix LookDev's layout vanishing on domain reload. Fixed issue with the shader TransformWorldToHClipDir function computing the wrong result. Fixed division by zero in V_SmithJointGGX function. Fixed null reference exception in LookDev when setting the SRP to one not implementing LookDev (case 1245086) Fix LookDev's undo/redo on EnvironmentLibrary (case 1234725) Fix a compil error on OpenGL ES2 in directional lightmap sampling shader code Fix hierarchicalbox gizmo outside facing check in symetry or homothety mode no longer move the center Fix artifacts on Adreno 630 GPUs when using ACES Tonemapping Fixed a null ref in the volume component list when there is no volume components in the project. Fixed issue with volume manager trying to access a null volume. HLSL codegen will work with C# file using both the GenerateHLSL and C# 7 features. Changed Restored usage of ENABLE_VR to fix compilation errors on some platforms. Only call SetDirty on an object when actually modifying it in SRP updater utility Set depthSlice to -1 by default on SetRenderTarget() to clear all slices of Texture2DArray by default. ResourceReloader will now add additional InvalidImport check while it cannot load due to AssetDatabase not available. Replaced calls to deprecated PlayerSettings.virtualRealitySupported property. Enable RWTexture2D, RWTexture2DArray, RWTexture3D in gles 3.1 Updated macros to be compatible with the new shader preprocessor. Updated shaders to be compatible with Microsoft's DXC. Changed CommandBufferPool.Get() to create an unnamed CommandBuffer. (No profiling markers) Deprecating VolumeComponentDeprecad, using HideInInspector or Obsolete instead [7.1.1] - 2019-09-05 Added Add separated debug mode in LookDev. Changed Replaced usage of ENABLE_VR in XRGraphics.cs by a version define (ENABLE_VR_MODULE) based on the presence of the built-in VR module ResourceReloader now works on non-public fields. Removed normalize from UnpackNormalRGB to match UnpackNormalAG. Fixed shadow routines compilation errors when \"real\" type is a typedef on \"half\". Removed debug menu in non development build. [7.0.1] - 2019-07-25 Fixed Fixed a precision issue with the ACES tonemapper on mobile platforms. [7.0.0] - 2019-07-17 Added First experimental version of the LookDev. Works with all SRP. Only branched on HDRP at the moment. LookDev out of experimental [6.7.0-preview] - 2019-05-16 [6.6.0] - 2019-04-01 Fixed Fixed compile errors in XRGraphics.cs when ENABLE_VR is not defined [6.5.0] - 2019-03-07 [6.4.0] - 2019-02-21 Added Enabled support for CBUFFER on OpenGL Core and OpenGL ES 3 backends. [6.3.0] - 2019-02-18 [6.2.0] - 2019-02-15 [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Fixed Fixed a typo in ERROR_ON_UNSUPPORTED_FUNCTION() that was causing the shader compiler to run out of memory in GLES2. [Case 1104271] (https://issuetracker.unity3d.com/issues/mobile-os-restarts-because-of-high-memory-usage-when-compiling-shaders-for-opengles2) [5.2.0] - 2018-11-27 [5.1.0] - 2018-11-19 Added Added a define for determining if any instancing path is taken. Changed The Core SRP package is no longer in preview. [5.0.0-preview] - 2018-10-18 Changed XRGraphicConfig has been changed from a read-write control of XRSettings to XRGraphics, a read-only accessor to XRSettings. This improves consistency of XR behavior between the legacy render pipeline and SRP. XRGraphics members have been renamed to match XRSettings, and XRGraphics has been modified to only contain accessors potentially useful to SRP You can now have up to 16 additional shadow-casting lights. Fixed LWRP no longer executes shadow passes when there are no visible shadow casters in a Scene. Previously, this made the Scene render as too dark, overall. [4.0.0-preview] - 2018-09-28 Added Space transform functions are now defined in ShaderLibrary/SpaceTransforms.hlsl. Changed Removed setting shader inclue path via old API, use package shader include paths [3.3.0] - 2018-01-01 [3.2.0] - 2018-01-01 [3.1.0] - 2018-01-01 Added Add PCSS shadow filter Added Core EditMode tests Added Core unsafe utilities Improvements Improved volume UI & styling Fixed CoreUtils.QuickSort infinite loop when two elements in the list are equals. Changed Moved root files into folders for easier maintenance"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Camera-Switcher.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Camera-Switcher.html",
    "title": "Camera Switcher | Inventory System",
    "summary": "Camera Switcher The CameraSwitcher component allows you to define a List of Cameras in the Scene and then use the Debug Window to switch between them in Play Mode. This is useful when you want a set of different fixed views for profiling purposes where you need to guarantee that the Camera view is in the same position between sessions. Properties Property Description Cameras Drag and drop GameObjects that have a Camera component attached to add them to this List of Cameras. The Debug Window can switch between the Cameras in this List."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/lens-flare-data-driven-asset.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/lens-flare-data-driven-asset.html",
    "title": "Lens Flare (SRP) Asset | Inventory System",
    "summary": "Lens Flare (SRP) Asset Unity’s Scriptable Render Pipeline (SRP) includes the Lens Flare Data asset. You can use this asset to control the appearance of Lens Flares in your scene. This is the SRP equivalent of the Built-in Render Pipeline's Flare asset, which is incompatible with SRPs. To create a Lens Flare Data asset, select Assets > Create > Lens Flare (SRP). To use this asset, assign it to the Lens Flare Data property of a Lens Flare (SRP) component. Properties The Lens Flare Element asset has the following properties: Type Image Circle Polygon Ring Lens Flare Data SRP Common Cutoff Transform AxisTransform Distortion Multiple Elements Uniform Curve Random Type Property Description Type Select the type of Lens Flare Element this asset creates: • Image • Circle • Polygon Image Property Description Flare Texture The Texture this lens flare element uses. Preserve Aspect Ratio Fixes the width and height (aspect ratio) of the Flare Texture. You can use Distortion to change this property. Circle Property Description Gradient Controls the offset of the circular flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the circular flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the circle. Inverse Enable this property to reverse the direction of the gradient. Polygon Property Description Gradient Controls the offset of the polygon flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the polygon flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the polygon. Side Count Determines how many sides the polygon flare has. Roundness Defines how smooth the edges of the polygon flare are. This value ranges from 0 to 1, where 0 is a sharp polygon and 1 is a circle. Inverse Enable this property to reverse the direction of the gradient Ring Property Description Gradient Controls the offset of the circular flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the circular flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the circle. Inverse Enable this property to reverse the direction of the gradient. Amplitude Amplitude of the sampling of the noise. Repeat Frequency of the sampling for the noise. Speed Scale the speed of the animation. Ring Thickness Ring Thickness. Lens Flare Data Driven SRP Property Description Asset Lens Flare Data SRP asset as an element. Unity support an Lens Flare Data SRP recursive, but with a hard cutoff after 16 recursions call. For instance asset A constains asset B which constains asset A (infinite recursion). That will trigger a warning and execution 16 recursions: \"LensFlareSRPAsset contains too deep recursive asset (> 16). Be careful to not have recursive aggregation, A contains B, B contains A, ... which will produce an infinite loop.\" Color Property Description Color Type Select the color type of Lens Flare Element this asset creates: • Constant • Radial • Angular Tint Changes the tint of the lens flare. If this asset is attached to the light, this property is based on the light tint. Modulate By Light Color Allows light color to affect this Lens Flare Element. This only applies when the asset is used in a SRP Lens Flare Override Component that is attached to a point, spot, or area light. Intensity Controls the intensity of this element. Blend Mode Select the blend mode of the Lens Flare Element this asset creates: • Additive • Screen • Premultiplied • Lerp Constant Color Property Description Tint Changes the tint of the lens flare. If this asset is attached to the light, this property is based on the light tint. Constant Color Property Description Tint Radial Specifies the radial gradient tint of the element. If the element type is set to Image, the Flare Texture is multiplied by this color. Constant Color Property Description Tint Angular Specifies the angular gradient tint of the element. If the element type is set to Image, the Flare Texture is multiplied by this color. Common Cutoff | Property | Description | | ----------------------- | ------------------------------------------------------------ | | Cutoff Speed | Sets the speed at which the radius occludes the element. A value of zero (with a large radius) does not occlude anything. The higher this value, the faster the element is occluded on the side of the screen. The effect of this value is more noticeable with multiple elements. . | | Cutoff Radius | Sets the normalized radius of the lens shape used to occlude the lens flare element. A radius of one is equivalent to the scale of the element.. | Transform Property Description Position Offset Defines the offset of the lens flare's position in screen space, relative to its source. Auto Rotate Enable this property to automatically rotate the Lens Flare Texture relative to its angle on the screen. Unity uses the Auto Rotate angle to override the Rotation parameter. To ensure the Lens Flare can rotate, assign a value greater than 0 to the Starting Position property. Rotation Rotates the lens flare. This value operates in degrees of rotation. Size Use this to adjust the scale of this lens flare element. This property is not available when the Type is set to Image and Preserve Aspect Ratio is enabled. Scale The size of this lens flare element in world space. Axis Transform Property Description Starting Position Defines the starting position of the lens flare relative to its source. This value operates in screen space. Angular Offset Controls the angular offset of the lens flare, relative to its current position. This value operates in degrees of rotation. Translation Scale Limits the size of the lens flare offset. For example, values of (1, 0) create a horizontal lens flare, and (0, 1) create a vertical lens flare. You can also use this property to control how quickly the lens flare appears to move. For example, values of (0.5, 0.5) make the lens flare element appear to move at half the speed. Distortion Property Description Enable Set this property to True to enable distortion. Radial Edge Size Controls the size of the distortion effect from the edge of the screen. Radial Edge Curve Blends the distortion effect along a curve from the center of the screen to the edges of the screen. Relative To Center Set this value to True to make distortion relative to the center of the screen. Otherwise, distortion is relative to the screen position of the lens flare. Multiple Elements Property Description Enable Enable this to allow multiple lens flare elements in your scene. Count Determines the number of identical lens flare elements Unity generates. A value of 1 appears the same as a single lens flare element. Distribution Select the method that Unity uses to generate multiple lens flare elements: •Uniform •Curve •Random Length Spread Controls how spread out multiple lens flare elements appear. Relative To Center If true the distortion is relative to center of the screen otherwise relative to lensFlare source screen position. Uniform Property Description Colors The range of colors that this asset applies to the lens flares. Rotation The angle of rotation (in degrees) applied to each element incrementally. Curve Property Description Colors The range of colors that this asset applies to the lens flares. You can use the Position Spacing curve to determine how this range affects each lens flare. Position Variation Adjust this curve to change the placement of the lens flare elements in the Lens Spread. Rotation The uniform angle of rotation (in degrees) applied to each element distributed along the curve. This value ranges from -180° to 180°. Scale Adjust this curve to control the size range of the lens flare elements. Random Property Description Seed The base value that this asset uses to generate randomness. Intensity Variation Controls the variation of brightness across the lens flare elements. A high value can make some elements might invisible. Colors The range of colors that this asset applies to the lens flares. This property is based on the Seed value. Position Variation Controls the position of the lens flares. The X value is spread along the same axis as Length Spread. A value of 0 means there is no change in the lens flare position. The Y value is spread along the vertical screen space axis based on the Seed value. Rotation Variation Controls the rotation variation of the lens flares, based on the Seed value. The Rotation and Auto Rotate parameters inherit from this property. Scale Variation Controls the scale of the lens flares based on the Seed value."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/lens-flare-data-driven-component.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/lens-flare-data-driven-component.html",
    "title": "Lens Flare (SRP) Component | Inventory System",
    "summary": "Lens Flare (SRP) Component Unity’s Scriptable Render Pipeline (SRP) includes the SRP Lens Flare Override component to control a Lens Flare (SRP) Data asset. You can attach an Lens Flare (SRP) Component to any GameObject. Some properties only appear when you attach this component to a light. Properties General Property Description Lens Flare Data Select the Lens Flare (SRP) Asset asset this component controls. Intensity Multiplies the intensity of the lens flare. Scale Multiplies the scale of the lens flare. Light Override Specifies the light component where the color and shape values are fetched from when using \"Modulate By Light Color\" or \"Attenuation By Light Shape\" properties on a Lens Flare Element. If nothing is specified, the light component from this gameobject is used. Attenuation by Light Shape Enable this property to automatically change the appearance of the lens flare based on the type of light you attached this component to. For example, if this component is attached to a spot light and the camera is looking at this light from behind, the lens flare will not be visible. This property is only available when this component is attached to a light. Attenuation Distance The distance between the start and the end of the Attenuation Distance Curve. This value operates between 0 and 1 in world space. Attenuation Distance Curve Fades out the appearance of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Scale Distance The distance between the start and the end of the Scale Distance Curve. This value operates between 0 and 1 in world space. Scale Distance Curve Changes the size of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Screen Attenuation Curve Reduces the effect of the lens flare based on its distance from the edge of the screen. You can use this to display a lens flare at the edge of your screen Occlusion Property Description Enable Enable this property to partially obscure the lens flare based on the depth buffer Occlusion Radius Defines how far from the light source Unity occludes the lens flare. This value is in world space. Sample Count The number of random samples the CPU uses to generate the Occlusion Radius. Occlusion Offset Offsets the plane that the occlusion operates on. A higher value moves this plane closer to Camera. This value is in world space. For example, if a lens flare is inside the light bulb, you can use this to sample occlusion outside the light bulb. Occlusion Remap Curve Specifies the curve used to remap the occlusion of the flare. By default, the occlusion is linear, between 0 and 1. This can be specifically useful to occlude flare more drastically when behind clouds. Allow Off Screen Enable this property to allow lens flares outside the Camera's view to affect the current field of view."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/light-anchor.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Common/light-anchor.html",
    "title": "Light Anchor | Inventory System",
    "summary": "Light Anchor You can use a Light Anchor to light a scene in Rendered Camera Space. To use a Light Anchor, you must connect it to a Light. Properties Property Description Orbit Use the left icon to control the Orbit of the light. This tool becomes green when you move the icon. Elevation Use the middle icon to control the Elevation of the light. This tool becomes blue when you move the icon. Roll Use the right icon to control the Rollof the light. This tool becomes gray when you move the icon. This is especially useful if the light has an IES or a Cookie. Distance Controls the distance between the light and its anchor in world space. Up Direction Defines the space of the up direction of the anchor. When this value is set to Local, the Up Direction is relative to the camera. Common Assigns a preset to the light component based on the behaviour of studio lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Free-Camera.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Free-Camera.html",
    "title": "Free Camera | Inventory System",
    "summary": "Free Camera The FreeCamera component provides you with an implementation for a simple free camera. When you add this component to a Camera, you can use the keyboard and mouse, or a controller, to control the Camera's position and rotation in Play Mode. Properties Property Description Look Speed Controller Set the look speed of the Camera when using a controller. Look Speed Mouse Set the look speed of the Camera when using a mouse. Move Speed Set the speed at which the Camera moves. Move Speed Increment Set the value of the increment that you can increase or decrease the Move Speed by. This is useful if you have a large Scene and the current Move Speed is not enough to easily traverse it. Turbo Set the value that this component multiplies the Move Speed by when you press the key or button assigned to \"Fire1\"."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Look-Dev-Environment-Library.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Look-Dev-Environment-Library.html",
    "title": "Environment Library | Inventory System",
    "summary": "Environment Library An Environment Library is an Asset that contains a list of environments that you can use in Look Dev to simulate different lighting conditions. Each environment uses an HDRI (High Dynamic Range Image) for its skybox and also includes properties that you can use to fine-tune the environment. Creating an Environment Library To create an Environment Library Asset, either: Select Assets > Create > Rendering Environment Library (Look Dev). Open Look Dev and click the New Library button. Creating and editing an environment After you create an Environment Library, you can add environments to it which you can then use in Look Dev. To create environments or edit their properties, use the Look Dev window itself. To create and edit environments, you need to open an Environment Library in Look Dev. To do this, either: Go to the Look Dev window (menu: Window > Rendering > Look Dev) and drag your Environment Library from your Project window into the sidebar. In your Project window, click on your Environment Library Asset. Then, in the Inspector, click the Open in LookDev window button. If you already have environments in the Environment Library, you can see a list of them in the sidebar. When you click on any of the HDRI previews for an environment, a box appears at the bottom of the Environment Library list. This contains the selected environment's properties for you to edit. To add, remove, or duplicate environments, use the toolbar at the bottom of the Environment Library list, which contains the following buttons. Button Function Description Add Click this button to add a new environment to the bottom of the list. Remove Click this button to remove the environment currently selected. Note that the environment that you have selected is the one with the blue frame. Duplicate Click this button to duplicate the currently selected environment and add it as a new environment to the bottom of the list. Properties Property Description Sky with Sun Set the HDRI Texture that Look Dev uses for the sky lighting when using this environment. For information on how to import an HDRI Texture, see Importing an HDRI Texture. Sky without Sun Set the HDRI Texture that Look Dev uses for compositing the shadows when simulating a sun in the view. If you do not assign this value, Look Dev uses a lower intensity version of the same HDRI Texture in Sky with Sun. For information on how to import an HDRI Texture, see Importing an HDRI Texture. Rotation Set the offset longitude that Look Dev applies for the whole sky and sun position. Exposure Set the exposure that Look Dev uses when it renders the environment. Sun Position Set the position of the sun when compositing the shadows. The Sun button at the end of the line automatically places the sun on the brightest spot of the Sky with Sun HDRI Texture. Shadow Tint Use the color picker to set the color of the tint that Look Dev uses to color shadows. Importing an HDRI Texture To import an HDRI Texture into the Unity Editor, load an .hdr or .exr file into your Unity Project like you would any other image. In the Texture Importer Inspector window, set Texture Type to Default, set Texture Shape to Cube, and set Convolution Type to None. When you want to test an HDRI Texture Asset or a skybox cube map Material, drag and drop it into the Look Dev view."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Look-Dev.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Look-Dev.html",
    "title": "Look Dev | Inventory System",
    "summary": "Look Dev Look Dev is an image-based lighting tool that contains a viewer for you to check and compare Assets to ensure they work well in various lighting conditions. Look Dev uses the Scriptable Render Pipeline, so it can display the Asset in the same way as it looks in your Scene. You can load Assets into Look Dev either as Prefabs or from the Hierarchy window. Look Dev is only available in Edit mode. The Look Dev window closes when you enter Play mode. Asset validation Asset validation confirms whether Assets are authored correctly and behave as expected in different lighting environments. You must use an HDRI (high dynamic range image) to validate your Assets in Look Dev. An HDRI contains real-world lighting with incredibly high detail. As such, it offers perfect lighting that is difficult to create by hand. By using such an accurate lighting environment to test an Asset, you can determine whether the Asset itself or your Project's lighting is reducing the visual quality of your Scene. You can load two different Assets into Look Dev at the same time and compare them in two viewports. For example, an Art Director can check that a new Asset matches the art direction guidelines of a reference Asset. Using Look Dev To open Look Dev in the Unity Editor, select Window > Rendering > Look Dev. The first time you use Look Dev, you must either create a new Environment Library or load one. For information on how to create an Environment Library, see the Environment Library documentation. Viewports By default, there is only one viewport in Look Dev, but you can choose from a selection of split-screen views (see the Multi-view section). Controls Navigation with the Look Dev Camera works in a similar way to the Scene view Camera: Rotate around pivot: Left click and drag (this is similar to the Scene view except that you need to press the Alt key for the Scene view Camera). Pan camera: Middle click and drag. Zoom: Alt + right click and drag. Forward/backward: Mouse wheel. First Person mode: Right click + W, A,S, and D. Loading Assets into Look Dev Look Dev lets you view: Prefabs - To load a Prefab into Look Dev, drag it from the Project window into the Look Dev viewport. GameObjects - To load a copy of a Hierarchy GameObject, drag the GameObject from the Hierarchy into the Look Dev viewport. Viewport modes Use the toolbar in the top-left of the window to change which viewing mode Look Dev uses. Single viewport By default, Look Dev displays a single viewport which contains the Prefab or GameObject you are working with. If you are in another viewing mode, you can click either the number 1 or number 2 button to go back to single view. Each button corresponds to a viewport in Look Dev. Select button 1 to use viewport 1, and button 2 to use viewport 2. Multi-viewport Use multiple viewports to compare different environments and settings for the same Asset. You can arrange viewports: Vertically side-by-side. Use this mode to compare two different lighting conditions on the same Asset to check that the Asset behaves correctly. Horizontally side-by-side. Use this mode to compare two different lighting conditions for horizontal objects, like an environment Asset, to check that the Asset behaves correctly. Split-screen. Use this mode investigate texture problems using a debug Shader mode (for example, use one screen to view Normal or Albedo shading, and the other for environment-lit mode). Side-by-side and split-screen: Use this mode to compare two different versions of the same Asset using the same lighting conditions to see which changes improve the Asset’s quality. All three of these modes are useful to compare two different versions of the same Asset using the same lighting conditions to see which changes improve the Asset’s quality. To load a different Prefab or Hierarchy GameObject into each split-screen view, drag and drop the Asset into the viewport that you want to view it in. When using multiple viewports, it only makes sense to compare different Prefabs or GameObjects when you want to look at two versions of the same Asset. Comparing completely different Assets doesn’t give you a good idea of the difference in lighting or visual effect. Vertical or horizontal side-by-side Vertical and horizontal side-by-side viewports show an identical view of your Asset. Split-screen In a split-screen view, there is a red/blue manipulation Gizmo that separates the two viewports. For information on how to use this Gizmo, see Using the manipulation Gizmo. Multi-viewport Camera By default, Look Dev synchronizes the camera movement for both views. To decouple the Cameras from one another, and manipulate them independently, click the Synchronized Cameras button in-between the two numbered Camera buttons. To align the cameras with each other, or reset them, click on the drop-down arrow next to the viewport 2 icon: Using the manipulation Gizmo The manipulation Gizmo represents the separation plane between the two viewports. It has different behavior in split-screen mode, but you use it in the same way for both side-by-side or split-screen modes. Moving the separator To move the separator, click and drag the straight line of the Gizmo to the location you want. Changing the orientation and length To change the orientation and length of the manipulator Gizmo, click and drag the circle at either end of the manipulator. Changing the length of the Gizmo lets you set the orientation and blending values more precisely. Changing the split in increments To change the split in increments, click and hold the circle on the end of the manipulation Gizmo, then hold Shift as you move the mouse. This snaps the manipulation Gizmo to set angles in increments of 22.5°, which is useful for a perfectly horizontal, vertical or diagonal angle. Blending The central white circle on the separator allows you to blend between the two views. Left click on it and drag along the red line to blend the left-hand view with the right-hand view. Drag along the blue line to blend the right-hand view with the left-hand view (as shown in the image below). The white circle automatically snaps back into the center when you drag it back. This helps you get back to the default blending value quickly. HDRI environments in Look Dev Lighting in Look Dev uses an HDRI. The Look Dev view allows you to manipulate and easily switch between HDRIs to simulate different environments for the Asset you are working on. Look Dev uses the Environment Library Asset to store a list of environments, which are HDRIs with extra properties that you can use to further refine the environment. For information on how to create, edit, and assign Environment Libraries, see the Environment Library documentation. Implementing Look Dev for your custom Scriptable Render Pipeline In order to use Look Dev in your custom Scriptable Render Pipeline, you must implement the UnityEngine.Rendering.LookDev.IDataProvider interface. Function Description void FirstInitScene(StageRuntimeInterface stage) Look Dev calls this function after it initializes the Scene with a Light and Camera. It uses this function to add and configure extra components according to the needs of your Scriptable Render Pipeline. void UpdateSky(Camera camera, Sky sky, StageRuntimeInterface stage) Look Dev uses this function to update the environment when you change something in Look Dev. You can handle the sky in various ways, so add code that corresponds to your Scriptable Render Pipeline. IEnumerable** ** supportedDebugModes { get; } Use this function to specify the list of supported debug modes. You do not need to add None because Look Dev handles that automatically. void UpdateDebugMode(int debugIndex) Use this function to update the debug mode based on what the user selects. The debugIndex matches the list in supportedDebugModes. If the user selects None, then the debugIndex is -1; void GetShadowMask(ref RenderTexture output, StageRuntimeInterface stage) This function computes a shadow map. The given StageRuntimeInterface contains access to the Camera and a Light simulating the sun."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Rendering-Debugger.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/Rendering-Debugger.html",
    "title": "Rendering Debugger | Inventory System",
    "summary": "Rendering Debugger The Rendering Debugger is a window you can customize with your own controls and scripts to visualize your project's lighting, rendering, or Material properties. If your project uses a custom Scriptable Render Pipeline (SRP), you can add controls to the default empty window. If your project uses the Universal Render Pipeline (URP) or the High-Definition Render Pipeline (HDRP), refer to the following pages: Add controls to the Rendering Debugger in URP Add controls to the Rendering Debugger in HDRP How to access the Rendering Debugger The Rendering Debugger window is available in the following modes: Mode Platform Availability How to Open the Rendering Debugger Editor All Yes (window in the Editor) Select Window > Analysis > Rendering Debugger Play mode All Yes (overlay in the Game view) On a desktop or laptop computer, press LeftCtrl+Backspace (LeftCtrl+Delete on macOS) On a console controller, press L3 and R3 (Left Stick and Right Stick) Runtime Desktop/Laptop Yes (only in Development builds) Press LeftCtrl+Backspace (LeftCtrl+Delete on macOS) Runtime Console Yes (only in Development builds) Press L3 and R3 (Left Stick and Right Stick) Runtime Mobile Yes (only in Development builds) Use a three-finger double tap To disable the runtime UI, use the enableRuntimeUI property. Navigation at runtime Keyboard Action Control Change the current active item Use the arrow keys Change the current tab Use the Page up and Page down keys (Fn + Up and Fn + Down keys respectively for MacOS) Display the current active item independently of the debug window Press the right Shift key Xbox Controller Action Control Change the current active item Use the Directional pad (D-Pad) Change the current tab Use the Left Bumper and Right Bumper Display the current active item independently of the debug window Press the X button PlayStation Controller Action Control Change the current active item Use the Directional buttons Change the current tab Use the L1 button and R1 button Display the current active item independently of the debug window Press the Square button Add a control The Rendering Debugger window can contain multiple tabs ('panels'). When you select a panel, the window displays one or more controls ('widgets'). To create a widget and add it to a new panel, do the following: Create a script that uses using UnityEngine.Rendering; to include the UnityEngine.Rendering namespace. Create a widget by creating an instance of a child class of DebugUI.Widget, for example DebugUI.Button. In the widget, implement the onValueChanged callback, which Unity calls when you change the value in the widget. Create a panel using DebugUI.instance.GetPanel. Add the widget to an array. Add the widget array to the list of children in the panel. If you add 2 or more widgets to the array, the panel displays the widgets in the same order as the array. The following code sample creates and adds a widget that enables or disables the main directional light: using UnityEngine; using UnityEngine.Rendering; using System.Collections.Generic; using System.Linq; [ExecuteInEditMode] public class CustomDebugPanel : MonoBehaviour { static bool lightEnabled = true; void OnEnable() { // Create a list of widgets var widgetList = new List<DebugUI.Widget>(); // Add a checkbox widget to the list of widgets widgetList.AddRange(new DebugUI.Widget[] { new DebugUI.BoolField { displayName = \"Enable main directional light\", tooltip = \"Enable or disable the main directional light\", getter = () => lightEnabled, // When the widget value is changed, change the value of lightEnabled setter = value => lightEnabled = value, // Run a custom function to enable or disable the main directional light based on the widget value onValueChanged = DisplaySunChanged }, }); // Create a new panel (tab) in the Rendering Debugger var panel = DebugManager.instance.GetPanel(\"My Custom Panel\", createIfNull: true); // Add the widgets to the panel panel.children.Add(widgetList.ToArray()); } // Remove the custom panel if the GameObject is disabled void OnDisable() { DebugManager.instance.RemovePanel(\"My Custom Panel\"); } // Enable or disable the main directional light based on the widget value void DisplaySunChanged(DebugUI.Field<bool> field, bool displaySun) { Light sun = FindObjectsOfType<Light>().Where(x => x.type == LightType.Directional).FirstOrDefault(); if (sun) sun.enabled = displaySun; } } Add the script to a GameObject. You should see a new My Custom Panel panel in the Rendering Debugger window. Add a control to an existing panel You can only add properties to existing panels if you're using a custom SRP. You shouldn't add widgets to URP or HDRP's built-in Rendering Debugger panels. To fetch an existing panel, use DebugManager.instance.GetPanel with the panel name. Set createIfNull to false, so you don't accidentally create a new panel if the name doesn't match an existing panel. The following code sample fetches the panel from the code sample above: var panel = DebugManager.instance.GetPanel(\"My Custom Panel\", createIfNull: false); Add a container You can use containers to display groups of widgets together. Create a container using one of the child classes of DebugUI.Container, for example DebugUI.Foldout. Add a widget array using the container's Add method. The following example creates a collapsible container that contains 2 checkboxes: using UnityEngine; using UnityEngine.Rendering; using System.Collections.Generic; [ExecuteInEditMode] public class CustomDebugPanelWithContainer : MonoBehaviour { void OnEnable() { // Create a list of widgets var widgetList = new List<DebugUI.Widget>(); // Add 2 checkbox widgets to the list of widgets widgetList.AddRange(new DebugUI.Widget[] { new DebugUI.BoolField { displayName = \"Visualisation 1\", }, new DebugUI.BoolField { displayName = \"Visualisation 2\", }, }); // Create a container var container = new DebugUI.Foldout { displayName = \"My Container\" }; // Add the widgets to the container container.children.Add(widgetList.ToArray()); // Create a new panel (tab) in the Rendering Debugger var panel = DebugManager.instance.GetPanel(\"My Custom Panel With Container\", createIfNull: true); // Add the container to the panel panel.children.Add(container); } } Control the Rendering Debugger overlay To change the value of the currently active widget: On a keyboard, press the Left and Right arrow keys. On a touch screen, tap the arrows next to the properties. On an Xbox controller, use the Directional pad (D-Pad). On a PlayStation controller, use the Directional buttons. To change the current panel: On a Windows keyboard, use the Page up and Page down keys (macOS: fn + Up arrow key, and fn + Down arrow key). On a touch screen, tap the arrows next to the tab title. On an Xbox controller, use the Left Bumper and Right Bumper. On a PlayStation controller, use L1 and R1. To display the currently active widget independently of the debug window: On a keyboard, press Right Shift. On an Xbox controller, press X. On a PlayStation controller, press Square. Disable the Rendering Debugger To disable the Rendering Debugger in your built application, set DebugManager.enableRuntimeUI to false."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "SRP Core What's new 12 13 17 Creating a custom render pipeline Create a custom Scriptable Render Pipeline Create a Render Pipeline Asset and Render Pipeline Instance in a custom render pipeline Create a simple render loop in a custom render pipeline Execute rendering commands in a custom render pipeline Scriptable Render Pipeline callbacks reference Camera components Free Camera Camera Switcher Render Requests Render Graph Benefits of the render graph system Render graph fundamentals Writing a Render Pipeline RTHandle system RTHandle fundamentals Using the RTHandle system Custom Material Inspector Custom graphics settings Adding properties in the menu Add a settings group Add a setting Customize the UI of a setting Get custom graphics settings Include or exclude a setting in your build Shaders Use shader methods from the SRP Core shader library Synchronizing shader code and C# Look Dev Environment Library Rendering Debugger Light Anchor"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/User-Render-Requests.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/User-Render-Requests.html",
    "title": "Render Requests | Inventory System",
    "summary": "Render Requests You can use a render request in a C# script to trigger a Camera to render to a render texture, outside the Unity rendering loop. The request is processed sequentially in your script, so there's no callback involved. Use RenderPipeline.StandardRequest RenderPipeline.StandardRequest renders the following: A full stack of cameras in the Universal Render Pipeline (URP). A single camera in the High Definition Render Pipeline (HDRP). The following code sample gets the output of the scriptable render pipeline when you select a GUI button. Attach the script to a camera and select Enter Play Mode. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering; [RequireComponent(typeof(Camera))] public class StandardRenderRequest : MonoBehaviour { [SerializeField] RenderTexture texture2D, texture2DArray, cubeMap, texture3D; // Render requests are sent when GUI button is selected private void OnGUI() { GUILayout.BeginVertical(); if (GUILayout.Button(\"Render Request\")) { SendRenderRequests(); } GUILayout.EndVertical(); } void SendRenderRequests() { Camera cam = GetComponent<Camera>(); // Create a standard request RenderPipeline.StandardRequest request = new RenderPipeline.StandardRequest(); // Check if the request is supported by the active render pipeline if (RenderPipeline.SupportsRenderRequest(cam, request)) { // Submit the render request to the active render pipeline with different destination textures // 2D Texture request.destination = texture2D; // Render camera and fill texture2D with its view RenderPipeline.SubmitRenderRequest(cam, request); // 2D Array Texture request.destination = texture2DArray; for (int i = 0; i < texture2DArray.volumeDepth; i++) { request.slice = i; // Render camera and fill slice i of texture2DArray with its view RenderPipeline.SubmitRenderRequest(cam, request); } // Cubemap var faces = new[] { CubemapFace.NegativeX, CubemapFace.PositiveX, CubemapFace.NegativeY, CubemapFace.PositiveY, CubemapFace.NegativeZ, CubemapFace.PositiveZ }; request.destination = cubeMap; foreach (var face in faces) { request.face = face; // Render camera and fill face of cubeMap with its view RenderPipeline.SubmitRenderRequest(cam, request); } // 3D Texture request.destination = texture3D; for (int i = 0; i < texture3D.volumeDepth; i++) { request.slice = i; // Render camera and fill slice i of texture3D with its view RenderPipeline.SubmitRenderRequest(cam, request); } } } } Other useful information On Universal Render Pipeline (URP)."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/View-Lighting-Tool.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/View-Lighting-Tool.html",
    "title": "| Inventory System",
    "summary": "Light Anchor The Light Anchor can help to place light sources around subjects, in relation to a Camera and an anchor point. It's particularly effective for cinematic lighting, which often requires multiple light sources orbiting a subject. Using the Light Anchor Component To add a Light Anchor component to a GameObject in your Scene: Select a Light GameObject in the hierarchy to open its Inspector window. Go to Add Component > Rendering > Light Anchor By default, the Anchor's position is the same as the position of the GameObject the Light Anchor Component is attached to. Note: To use the Light Anchor, you must set the Tag of at least one Camera to \"MainCamera\". Use the Orbit and Elevation to control the orientation of the light, in degrees, relative to the main Camera's and Anchor's positions. If the Light has a Cookie or an IES Profile, use the Roll to change their orientation. Use the Distance to control how far from the anchor, in meters, you want to place the Light. You can use the Anchor Position Override to provide a GameObject’s Transform as an anchor point for the Light. This is useful if you want the Light to follow a specific GameObject in the Scene. Note: The above example uses the Main Camera as the reference Camera that adjusts the light rotation. The Common presets might create a different result in the Scene View if your view isn't aligned with the Main Camera. You can set a Position Offset for this custom Anchor. This is useful if the Transform position of the custom Anchor isn't centered appropriately for the light to orbit correctly around the custom Anchor. The Light Anchor component also includes a list of Presets that you can use to set the Light's orientation relative to the main Camera. Properties Property Description Orbit Use the left icon to control the Orbit of the light. This tool becomes green when you move the icon. Elevation Use the middle icon to control the Elevation of the light. This tool becomes blue when you move the icon. Roll Use the right icon to control the Roll of the light. This tool becomes gray when you move the icon. This is useful if the light has an IES or a Cookie. Distance Controls the distance between the light and its anchor in world space. Up Direction Defines the space of the up direction of the anchor. When you set this value to Local, the Up Direction is relative to the Camera. Anchor Position Override Allows you to use a GameObject's Transform as anchor position instead of the LightAnchor's Transform. When the Transform of the GameObject you assigned to this property changes, the Light Anchor's Transform also changes. Common Assigns a preset to the light component based on the behavior of studio lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/add-custom-graphics-setting.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/add-custom-graphics-setting.html",
    "title": "Add a setting | Inventory System",
    "summary": "Add a setting Add a simple property or a reference property to a custom graphics settings group. You can change the values of the setting in the Unity Editor while you're editing your project. Unity serializes the graphics settings you add. For more information, refer to Script serialization. Note: The value of a custom setting is static in a built project. You can't change the setting at runtime. Add a simple property To add a simple property, add a field to your IRenderPipelineGraphicsSettings class using the [SerializeField] attribute. For example: using System; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; [Serializable] [SupportedOnRenderPipeline(typeof(UniversalRenderPipelineAsset))] // Create a new settings group by implementing the IRenderPipelineGraphicsSettings interface public class MySettings : IRenderPipelineGraphicsSettings { // Add a private field for the version property int internalVersion = 1; // Implement the public version property public int version => internalVersion; // Add a float setting [SerializeField] private float mySetting = 1.0f; // Add a Material reference property [SerializeField] public Material myMaterial; } The Edit > Project Settings > Graphics window with the new custom setting from the example script. Set the default asset for a reference property To set a default asset for a reference property, for example a material, add a [ResourcePath] attribute. For example: public class MySettings: IRenderPipelineGraphicsSettings { ... [SerializeField] [ResourcePath('path-to-default-file')] public Material myMaterial; } Additional resources SerializeField Reference properties"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/add-custom-graphics-settings.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/add-custom-graphics-settings.html",
    "title": "Add a settings group | Inventory System",
    "summary": "Add a settings group To add a custom graphics settings group to a Scriptable Render Pipeline, implement the IRenderPipelineGraphicsSettings interface. Follow these steps: Create a class that implements the IRenderPipelineGraphicsSettings interface, then add a [Serializable] attribute. To set which render pipeline the setting applies to, add a [SupportedOnRenderPipeline] attribute and pass in a RenderPipelineAsset type. Note: If you don't add a [SupportedOnRenderPipeline] attribute, the setting applies to any Scriptable Render Pipeline. However each Scriptable Render Pipeline stores its own value for the setting. Implement the version property. Unity doesn't currently use the version property, but you must implement it. Unity adds the new settings group to the Edit > Project Settings > Graphics window. For example, the following script adds a settings group called My Settings in the Graphics settings window of the Universal Render Pipeline (URP). using System; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; [Serializable] [SupportedOnRenderPipeline(typeof(UniversalRenderPipelineAsset))] // Create a new settings group by implementing the IRenderPipelineGraphicsSettings interface public class MySettings : IRenderPipelineGraphicsSettings { // Add a private field for the version property int internalVersion = 1; // Implement the public version property public int version => internalVersion; } The Edit > Project Settings > Graphics window with the new custom settings group from the example script. Change the display order of settings groups To change where a settings group appears, use the [UnityEngine.Categorization.CategoryInfo] attribute. For example, the following code gives the settings group the name My Settings and moves the group to the top of the graphics settings window. [UnityEngine.Categorization.CategoryInfo(Name = \"My Settings\", Order = 0)] public class MySettings : IRenderPipelineGraphicsSettings { ... } Additional resources Add a setting"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/adding-properties.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/adding-properties.html",
    "title": "Adding properties to the Core Render Pipeline settings section | Inventory System",
    "summary": "Adding properties to the Core Render Pipeline settings section To add properties in the Core Render Pipeline settings section (Edit > Preferences > Core Render Pipeline), create a class that implements the interface ICoreRenderPipelinePreferencesProvider. For example: class MyPreference : ICoreRenderPipelinePreferencesProvider { class Styles { public static readonly GUIContent myBoolLabel = EditorGUIUtility.TrTextContent(\"My check box\", \"The description of the property.\"); } public List<string> keywords => new List<string>() {Styles.myBoolLabel.text}; public GUIContent header => EditorGUIUtility.TrTextContent(\"My property section\", \"The description of my property section.\"); public static bool s_MyBoolPreference; public void PreferenceGUI() { EditorGUI.BeginChangeCheck(); var newValue = EditorGUILayout.Toggle(Styles.myBoolLabel, s_MyBoolPreference); if (EditorGUI.EndChangeCheck()) { s_MyBoolPreference = newValue; } } } Unity shows the new properties in the Core Render Pipeline settings section:"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/advanced-properties.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/advanced-properties.html",
    "title": "Advanced Properties | Inventory System",
    "summary": "Advanced Properties Unity Render Pipelines components expose standard properties by default that are suitable for most use-cases. However, there are components and Volume Overrides that include advanced properties which you can use to fine-tune the behavior of the component. There is a global state per user that stores if Unity displays advanced properties or not. Exposing advanced properties within the inspector Not every component or Volume Override includes advanced properties. If one does, it has a contextual menu to the right of each property section header that includes additional properties. To expose advanced properties for that section, open the contextual menu and click Advanced Properties. For an example, see the Water Surface component in High Definition Render Pipeline (HDRP). By default only standard properties are shown. When you select Advanced Properties: Advanced Properties become visible: For Volume Overrides, the already existing contextual menu has a Advanced Properties toggle as well. Exposing advanced properties on preferences You can also access to this global preference by: Open the Graphics tab in the Preferences window (menu: Edit > Preferences > Graphics). Under Properties. Set Advanced Properties to All Visible."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/api_index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/api_index.html",
    "title": "Scriptable Render Pipeline Core scripting API | Inventory System",
    "summary": "Scriptable Render Pipeline Core scripting API This is the documentation for the scripting APIs of the Scriptable Render Pipeline (SRP) Core package. Note: URP and HDRP are built on the Scriptable Render Pipeline (SRP) Core package, but have their own class types. For more information, refer to the following: Universal Render Pipeline (URP) Scripting API High Definition Render Pipeline (HDRP) Scripting API"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/built-in-shader-methods.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/built-in-shader-methods.html",
    "title": "Use shader methods from the SRP Core shader library | Inventory System",
    "summary": "Use shader methods from the SRP Core shader library SRP Core has a library of High-Level Shader Language (HLSL) shader files that contain helper methods. You can import these files into your custom shader files and use the helper methods. To use the following methods, add #include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/SpaceTransforms.hlsl\" inside the HLSLPROGRAM in your shader file. Get matrices Method Syntax Description CreateTangentToWorld real3x3 CreateTangentToWorld(real3 normal, real3 tangent, real flipSign) Returns the matrix that converts tangents to world space. GetObjectToWorldMatrix() float4x4 GetObjectToWorldMatrix() Returns the matrix that converts positions in object space to world space. GetViewToHClipMatrix() float4x4 GetViewToHClipMatrix() Returns the matrix that converts positions in view space to clip space. GetViewToWorldMatrix() float4x4 GetViewToWorldMatrix() Returns the matrix that converts positions in view space to world space. GetWorldToHClipMatrix() float4x4 GetWorldToHClipMatrix() Returns the matrix that converts positions in world space to clip space. GetWorldToObjectMatrix() float4x4 GetWorldToObjectMatrix() Returns the matrix that converts positions in world space to object space. GetWorldToViewMatrix() float4x4 GetWorldToViewMatrix() Returns the matrix that converts positions in world space to view space. Transform positions Method Syntax Description TransformObjectToHClip float4 TransformObjectToHClip(float3 positionInObjectSpace) Converts a position in object space to clip space. TransformObjectToWorld float3 TransformObjectToWorld(float3 positionInObjectSpace) Converts a position in object space to world space. TransformViewToWorld float3 TransformViewToWorld(float3 positionInViewSpace) Converts a position in view space to world space. TransformWorldToHClip float4 TransformWorldToHClip(float3 positionInWorldSpace) Converts a position in world space to clip space. TransformWorldToObject float3 TransformWorldToObject(float3 positionInWorldSpace) Converts a position in world space to object space. TransformWorldToView float3 TransformWorldToView(float3 positionInWorldSpace) Converts a position in world space to view space. TransformWViewToHClip float4 TransformWViewToHClip(float3 positionInViewSpace) Converts a position in view space to clip space. Transform directions Method Syntax Description TransformObjectToTangent real3 TransformObjectToTangent(real3 directionInObjectSpace, real3x3 tangentToWorldMatrix) Converts a direction in object space to tangent space, using a tangent-to-world matrix. TransformObjectToWorldDir float3 TransformObjectToWorldDir(float3 directionInObjectSpace, bool normalize = true) Converts a direction in object space to world space. TransformTangentToObject real3 TransformTangentToObject(real3 dirTS, real3x3 tangentToWorldMatrix) Converts a direction in tangent space to object space, using a tangent-to-world matrix. TransformTangentToWorldDir real3 TransformTangentToWorldDir(real3 directionInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a direction in tangent space to world space, using a tangent-to-world matrix. TransformViewToWorldDir real3 TransformViewToWorldDir(real3 directionInViewSpace, bool normalize = false) Converts a direction in view space to world space. TransformWorldToHClipDir real3 TransformWorldToHClipDir(real3 directionInWorldSpace, bool normalize = false) Converts a direction in world space to clip space. TransformWorldToObjectDir float3 TransformWorldToObjectDir(float3 directionInWorldSpace, bool normalize = true) Converts a direction in world space to object space. TransformWorldToTangentDir real3 TransformWorldToTangentDir(real3 directionInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a direction in world space to tangent space, using a tangent-to-world matrix. TransformWorldToViewDir real3 TransformWorldToViewDir(real3 directionInWorldSpace, bool normalize = false) Converts a direction in world space to view space. Transform surface normals Method Syntax Description TransformObjectToWorldNormal float3 TransformObjectToWorldNormal(float3 normalInObjctSpace, bool normalize = true) Converts a normal in object space to world space. TransformTangentToWorld float3 TransformTangentToWorld(float3 normalInTangentSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a normal in tangent space to world space, using a tangent-to-world matrix. TransformViewToWorldNormal real3 TransformViewToWorldNormal(real3 normalInViewSpace, bool normalize = false) Converts a normal in view space to world space. TransformWorldToObjectNormal float3 TransformWorldToObjectNormal(float3 normalInWorldSpace, bool normalize = true) Converts a normal in world space to object space. TransformWorldToTangent float3 TransformWorldToTangent(float3 normalInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = true) Converts a normal in world space to tangent space using a tangent-to-world matrix. TransformWorldToViewNormal real3 TransformWorldToViewNormal(real3 normalInWorldSpace, bool normalize = false) Converts a normal in world space to view space. Additional resources HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/choose-whether-unity-includes-a-graphics-setting-in-your-build.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/choose-whether-unity-includes-a-graphics-setting-in-your-build.html",
    "title": "Include or exclude a setting in your build | Inventory System",
    "summary": "Include or exclude a setting in your build By default, Unity doesn't include a setting (\"strips\" the setting) in your built project to optimize performance and reduce build size. For example, if you create a custom reference property that points to a shader asset, by default Unity doesn't include that property in your build. You can choose to include a setting in your build instead. The value of the property is read-only at runtime. Include a setting in your build To include a setting in your build by default, set the IsAvailableInPlayerBuild property of your settings group class to true. For example: public class MySettings: IRenderPipelineGraphicsSettingsStripper { ... // Make settings in this class available in your build public bool IsAvailableInPlayerBuild => true; } Create your own stripping code To conditionally control whether Unity includes or excludes a setting in your build, override the IsAvailableInPlayerBuild property by implementing the IRenderPipelineGraphicsSettingsStripper interface. Follow these steps: Create a class that implements the IRenderPipelineGraphicsSettingsStripper interface, and pass in your settings class. Implement the active property. If you set active to false, the code in the class doesn't run. Implement the CanRemoveSettings method with your own code that decides whether to include the setting. Return true to strip the setting, or false to include the setting. For example: using UnityEngine; using UnityEngine.Rendering; // Implement the IRenderPipelineGraphicsSettingsStripper interface, and pass in our settings class class SettingsStripper : IRenderPipelineGraphicsSettingsStripper<MySettings> { // Make this stripper active public bool active => true; // Implement the CanRemoveSettings method with our own code public bool CanRemoveSettings(MySettings settings) { // Strip the setting (return true) if useMyFeature is false return !settings.useMyFeature; } } If you implement IRenderPipelineGraphicsSettingsStripper multiple times for one setting, Unity only strips the setting if they all return true. Check if your build includes a setting You can check if a setting exists at runtime. A setting might not exist at runtime for one of the following reasons: Unity didn't include the setting in your build. The current pipeline doesn't support the setting. The setting is in an assembly that Unity doesn't include in your build. Refer to Organizing scripts into assemblies for more information. To check if the setting exists, use the TryGetRenderPipelineSettings API. TryGetRenderPipelineSettings puts the setting in an out variable if the setting exists. Otherwise it returns false. For example, the following code checks whether a settings group called MySettings exists at runtime: if (GraphicsSettings.TryGetRenderPipelineSettings<MySettings>(out var mySetting)){ Debug.Log(\"The setting is in the build and its value is {mySetting.myValue}\"); } Additional resources Organizing scripts into assemblies"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/custom-material-inspector.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/custom-material-inspector.html",
    "title": "Custom Material Inspector | Inventory System",
    "summary": "Custom Material Inspector Custom Material Inspectors enable you to define how Unity displays properties in the Material Inspector for a particular shader. This is useful if a shader includes a lot of properties and you want to organize them in the Inspector. The Universal Render Pipeline (URP) and High Definition Render Pipeline (HDRP) both support custom Material Inspectors, but the method to create them is slightly different. Creating a custom Material Inspector The implementation for custom Material Inspectors differs between URP and HDRP. For example, for compatibility purposes, every custom Material Inspector in HDRP must inherit from HDShaderGUI which does not exist in URP. For information on how to create custom Material Inspectors for the respective render pipelines, see: HDRP: HDRP custom Material Inspectors. URP: Unity Custom Shader GUI. Assigning a custom Material Inspector When you create a shader, either hand-written or using Shader Graph, both URP and HDRP provide a default editor for it to use. To override this default and provide your own custom Material Inspector, the method differs depending on whether you hand-wrote the shader or used Shader Graph. Using hand-written shaders To set a custom Material Inspector for a hand-written shader: Open the shader source file. Assign a string that contains the class name of the custom Material Inspector to the CustomEditor shader instruction. This is the same method as for the Built-in Renderer's custom shader GUI. For an example of how to do this, see the following shader code sample. In this example, the name of the custom Material Inspector class is ExampleCustomMaterialInspector: Shader \"Custom/Example\" { Properties { // Shader properties } SubShader { // Shader code } CustomEditor \"ExampleCustomMaterialInspector\" } Using Shader Graph To set a custom Material Inspector for a Shader Graph shader: Open the Shader Graph. In the Graph Inspector, open the Graph Settings tab. If Active Targets does not include the render pipeline your project uses, click the plus button then, in the drop-down, click the render pipeline. In the render pipeline section (HDRP or URP depending on the render pipeline your project uses) find the Custom Editor GUI property and provide it the name of the custom Material Inspector."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/customize-ui-for-a-setting.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/customize-ui-for-a-setting.html",
    "title": "Customize the UI of custom settings | Inventory System",
    "summary": "Customize the UI of custom settings To change the look of custom settings in the Graphics settings window, use the PropertyDrawer API. Follow these steps: Create a class that inherits from the PropertyDrawer class. Add the [CustomPropertyDrawer] attribute to the class, with a reference to your settings class. Override the PropertyDrawer.CreatePropertyGUI method, and return a VisualElement object that contains the UI elements you want to display. The following example creates a custom UI for a MySettings class that contains a Boolean and a float field. The Graphics settings window displays the float only when the Boolean field is enabled. For more information, refer to PropertyDrawer. using UnityEngine; using UnityEditor; using UnityEngine.UIElements; // Create a custom UI for the properties in the MySettings class [CustomPropertyDrawer(typeof(MySettings))] public class MySettingsPropertyDrawer : PropertyDrawer { // Override the CreatePropertyGUI method to define the custom UI public override VisualElement CreatePropertyGUI(SerializedProperty property) { // Create a container to hold the UI elements var container = new VisualElement(); // Find the properties to display var useProperty = property.FindPropertyRelative(\"m_UseMyFeature\"); var intensityProperty = property.FindPropertyRelative(\"m_MyFeatureIntensity\"); // Create property fields for each property var usePropertyField = new PropertyField(useProperty); var intensityPropertyField = new PropertyField(intensityProperty); // Enable or disable the intensity field based on the value of m_UseMyFeature usePropertyField.RegisterValueChangeCallback(evt => { intensityPropertyField.SetEnabled(useProperty.boolValue); }); // Add the property fields to the container container.Add(usePropertyField); container.Add(intensityPropertyField); // Return the container to be displayed in the Graphics settings window return container; } } Customize the More (⋮) menu of a settings group To add items to the More (⋮) menu of a settings group, follow these steps: Create a class that implements the IRenderPipelineGraphicsSettingsContextMenu interface. Implement the PopulateContextMenu method. To add an item, use the AddItem API. For example: public class MySettingsContextMenu : IRenderPipelineGraphicsSettingsContextMenu<MySettings> { void IRenderPipelineGraphicsSettingsContextMenu<MySettings>.PopulateContextMenu(MySettings setting, PropertyDrawer _, ref GenericMenu menu) { menu.AddItem(new GUIContent(\"My custom menu item\"), false, () => { Debug.Log(\"Menu item was selected.\"); }); } } Additional resources PropertyDrawer IRenderPipelineGraphicsSettingsContextMenu"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/generating-shader-includes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/generating-shader-includes.html",
    "title": "Synchronizing shader code and C# | Inventory System",
    "summary": "Synchronizing shader code and C# Unity can generate HLSL code based on C# structs to synchronize data and constants between shaders and C#. In Unity, the process of generating the HLSL code from C# code is called generating shader includes. When Unity generates shader includes, it parses all the C# files in the project and, for every file that contains a struct with a GenerateHLSL attribute, generates corresponding HLSL code. It places this HLSL code in a file with the same name as the origin, but uses the .cs.hlsl file extension. Generating shader includes To generate an HLSL equivalent for a C# struct: Add the GenerateHLSL attribute to the struct. To do this, above the line that declares the struct, add [GenerateHLSL(PackingRules.Exact, false)]. For an example on how to do this, see the sample code below. For more information about the GenerateHLSL attribute, see the API documentation. In the Unity Editor, go to Edit > Render Pipeline > Generate Shader Includes. The following code example is from the High Definition Render Pipeline (HDRP). It shows an extract of the C# representation of a directional light. The original file is LightDefinition.cs. When Unity generates the HLSL shader code, it places it in a new file called LightDefinition.cs.hlsl. // LightDefinition.cs [GenerateHLSL(PackingRules.Exact, false)] struct DirectionalLightData { public Vector3 positionRWS; public uint lightLayers; public float lightDimmer; public float volumetricLightDimmer; // Replaces 'lightDimer' public Vector3 forward; public Vector4 surfaceTextureScaleOffset; }; // LightDefinition.cs.hlsl // Generated from UnityEngine.Rendering.HighDefinition.DirectionalLightData // PackingRules = Exact struct DirectionalLightData { float3 positionRWS; uint lightLayers; float lightDimmer; float volumetricLightDimmer; float3 forward; float4 surfaceTextureScaleOffset; };"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/get-custom-graphics-settings.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/get-custom-graphics-settings.html",
    "title": "Get custom graphics settings | Inventory System",
    "summary": "Get custom graphics settings To get a custom setting and read its value, use the GetRenderPipelineSettings method. For example, the following script gets the MySettings settings class from the example in the Add a setting page, then logs the value of the mySetting setting: using UnityEngine; using UnityEngine.Rendering; public class LogMySettingsValue : MonoBehaviour { // Unity calls the Update method once per frame void Update() { // Get the MySettings settings var mySettings = GraphicsSettings.GetRenderPipelineSettings<MySettings>(); // Log the value of the MyValue setting Debug.Log(mySettings.mySetting); } } Get a notification when a setting changes To configure a property so it notifies other scripts when its value changes, use the SetValueAndNotify method. You can use this to debug, update UI elements, or trigger other actions when a setting changes. This only works while you're editing your project, not at runtime. If you use SetValueAndModify in a built application, Unity throws an exception. Follow these steps: Create a public getter and setter in your setting class. In the setter, set the value using the SetValueAndNotify method, so changing the setting value sends a notification to other scripts. For example: using UnityEngine; using UnityEngine.Rendering; using System; [Serializable] [SupportedOnRenderPipeline(typeof(UniversalRenderPipelineAsset))] // Create a settings group by implementing the IRenderPipelineGraphicsSettings interface public class MySettings : IRenderPipelineGraphicsSettings { // Implement the version field public int version => 0; // Create a MyValue setting and set its default value to 100 [SerializeField] private int MyValue = 100; public int myValue { get => MyValue; set => this.SetValueAndNotify(ref MyValue, value); } } Use the GraphicsSettings.Subscribe method to subscribe to notifications from the setting, and call an Action when the setting changes. For example: using System; using UnityEngine; using UnityEngine.Rendering; public class DetectSettingsChange : MonoBehaviour { // Unity calls the Awake method when it loads the script instance. void Awake() { // Log the new value of the setting Action<MySettings, string> onSettingChanged = (setting, name) => { Debug.Log($\"{name} changed to {setting.myValue}\"); }; // Subscribe to notifications from the MySettings settings, and call the OnSettingsChanged Action when notified GraphicsSettings.Subscribe<MySettings>(onSettingChanged); } } Unsubscribe from the notifications from a setting To stop calling a method when a setting changes, use the GraphicsSettings.Unsubscribe method. For example: GraphicsSettings.Unsubscribe<MySettings>(onSettingChanged); Additional resources IRenderPipelineGraphicsSettings"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/index.html",
    "title": "SRP Core | Inventory System",
    "summary": "SRP Core The Scriptable Render Pipeline (SRP) is a Unity feature that allows you to write C# scripts to control the way Unity renders each frame. SRP Core is a package that makes it easier to create or customize an SRP. SRP Core contains reusable code, including boilerplate code for working with platform-specific graphics APIs, utility functions for common rendering operations, and the shader libraries used in the High Definition Render Pipeline (HDRP) and Universal Render Pipeline (URP). If you are creating a custom SRP from scratch or customizing a prebuilt SRP, using SRP Core will save you time. For more information on SRP, including a guide to getting started with a custom SRP, see the SRP documentation. For more information on Unity's prebuilt SRPs, see the Universal Render Pipeline (URP) documentation, or the High Definition Render Pipeline (HDRP) documentation."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-benefits.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-benefits.html",
    "title": "Benefits of the render graph system | Inventory System",
    "summary": "Benefits of the render graph system Efficient memory management When you manage resource allocation manually, you have to account for scenarios when every rendering feature is active at the same time and thus allocate for the worst-case scenario. When particular rendering features are not active, the resources to process them are there, but the render pipeline does not use them. A render graph only allocates resources that the frame actually uses. This reduces the memory footprint of the render pipeline and means that there is no need to create complicated logic to handle resource allocation. Another benefit of efficient memory management is that, because a render graph can reuse resources efficiently, there are more resources available to create features for your render pipeline. Automatic synchronization point generation Asynchronous compute queues can run in parallel to the regular graphic workload and, as a result, may reduce the overall GPU time it takes to process a render pipeline. However, it can be difficult to manually define and maintain synchronization points between an asynchronous compute queue and the regular graphics queue. A render graph automates this process and, using the high-level declaration of the render pipeline, generates correct synchronization points between the compute and graphics queue. Maintainability One of the most complex issues in render pipeline maintenance is the management of resources. Because a render graph manages resources internally, it makes it much easier to maintain your render pipeline. Using the RenderGraph API, you can write efficient self-contained rendering modules that declare their input and output explicitly and are able to plug in anywhere in a render pipeline."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-fundamentals.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-fundamentals.html",
    "title": "Render graph fundamentals | Inventory System",
    "summary": "Render graph fundamentals This document describes the main principles of a render graph and an overview of how Unity executes it. Main principles Before you can write render passes with the RenderGraph API, you need to know the following foundational principles: You no longer handle resources directly and instead use render graph system-specific handles. All RenderGraph APIs use these handles to manipulate resources. The resource types a render graph manages are RTHandles, ComputeBuffers, and RendererLists. Actual resource references are only accessible within the execution code of a render pass. The framework requires an explicit declaration of render passes. Each render pass must state which resources it reads from and/or writes to. There is no persistence between each execution of a render graph. This means that the resources you create inside one execution of the render graph cannot carry over to the next execution. For resources that need persistence (from one frame to another for example), you can create them outside of a render graph, like regular resources, and import them in. They behave like any other render graph resource in terms of dependency tracking, but the graph does not handle their lifetime. A render graph mostly uses RTHandles for texture resources. This has a number of implications on how to write shader code and how to set them up. Resource Management The render graph system calculates the lifetime of each resource with the high-level representation of the whole frame. This means that when you create a resource via the RenderGraph API, the render graph system does not create the resource at that time. Instead, the API returns a handle that represents the resource, which you then use with all RenderGraph APIs. The render graph only creates the resource just before the first pass that needs to write it. In this case, “creating” does not necessarily mean that the render graph system allocates resources. Rather, it means that it provides the necessary memory to represent the resource so that it can use the resource during a render pass. In the same manner, it also releases the resource memory after the last pass that needs to read it. This way, the render graph system can reuse memory in the most efficient manner based on what you declare in your passes. If the render graph system does not execute a pass that requires a specific resource, then the system does not allocate the memory for the resource. Render graph execution overview Render graph execution is a three-step process that the render graph system completes, from scratch, every frame. This is because a graph can change dynamically from frame to frame, for example, depending on the actions of the user. Setup The first step is to set up all the render passes. This is where you declare all the render passes to execute and the resources each render pass uses. Compilation The second step is to compile the graph. During this step, the render graph system culls render passes if no other render pass uses their outputs. This allows for less organized setups because you can reduce specific logic when you set up the graph. A good example of that is debug render passes. If you declare a render pass that produces a debug output that you don't present to the back buffer, the render graph system culls that pass automatically. This step also calculates the lifetime of resources. This allows the render graph system to create and release resources in an efficient way as well as compute the proper synchronization points when it executes passes on the asynchronous compute pipeline. Execution Finally, execute the graph. The render graph system executes all render passes that it did not cull, in declaration order. Before each render pass, the render graph system creates the proper resources and releases them after the render pass if later render passes do not use them."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-system.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-system.html",
    "title": "The render graph system | Inventory System",
    "summary": "The render graph system The render graph system sits on top of Unity's Scriptable Render Pipeline (SRP). It allows you to author a custom SRP in a maintainable and modular way. Both Unity's High Definition Render Pipeline (HDRP) and Unity's Universal Render Pipeline (URP) use the render graph system. You use the RenderGraph API to create a render graph. A render graph is a high-level representation of the custom SRP's render passes, which explicitly states how the render passes use resources. Describing render passes in this way has two benefits: it simplifies render pipeline configuration, and it allows the render graph system to efficiently manage parts of the render pipeline, which can result in improved runtime performance. For more information on the benefits of the render graph system, see benefits of the render graph system. To use the render graph system, you need to write your code in a different way to a regular custom SRP. For more information on how to write code for the render graph system, see writing a render pipeline. For information on the technical principles behind the render graph system, see render graph fundamentals. This section contains the following pages: Render graph benefits Render graph fundamentals Writing a render pipeline"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-writing-a-render-pipeline.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/render-graph-writing-a-render-pipeline.html",
    "title": "Writing a render pipeline | Inventory System",
    "summary": "Writing a render pipeline This page covers the process of how to use the RenderGraph API to write a render pipeline. For information about the RenderGraph API, see render graph system and render graph fundamentals. Initialization and cleanup of Render Graph To begin, your render pipeline needs to maintain at least one instance of RenderGraph. This is the main entry point for the API. You can use more than one instance of a render graph, but be aware that Unity does not share resources across RenderGraph instances so for optimal memory usage, only use one instance. using UnityEngine.Rendering; using UnityEngine.Rendering.RenderGraphModule; public class MyRenderPipeline : RenderPipeline { RenderGraph m_RenderGraph; void InitializeRenderGraph() { m_RenderGraph = new RenderGraph(\"MyRenderGraph\"); } void CleanupRenderGraph() { m_RenderGraph.Cleanup(); m_RenderGraph = null; } ... } To initialize a RenderGraph instance, call the constructor with an optional name to identify the render graph. This also registers a render graph-specific panel in the SRP Debug window which is useful for debugging the RenderGraph instance. When you dispose of a render pipeline, call the Cleanup() method on the RenderGraph instance to properly free all the resources the render graph allocated. Starting a render graph Before you add any render passes to the render graph, you first need to initialize the render graph by calling the BeginRecording method. Once all the render passes have been added to the render graph, you can execute it by calling the EndRecordingAndExecute method. For details about the BeginRecording method's parameters, see the API documentation var renderGraphParams = new RenderGraphParameters() { scriptableRenderContext = renderContext, commandBuffer = cmd, currentFrameIndex = frameIndex }; m_RenderGraph.BeginRecording(renderGraphParams); // Add your passes here m_RenderGraph.EndRecordingAndExecute(); Creating resources for the render graph When you use a render graph, you never directly allocate resources yourself. Instead, the RenderGraph instance handles the allocation and disposal of its own resources. To declare resources and use them in a render pass, you use render graph specific APIs that return handles to the resource. There are two main types of resources that a render graph uses: Internal resources: These resources are internal to a render graph execution and you cannot access them outside of the RenderGraph instance. You also cannot pass these resources from one execution of a graph to another. The render graph handles the lifetime of these resources. Imported resources: These usually come from outside the render graph execution. Typical examples are the back buffer (provided by the camera) or buffers that you want the graph to use across multiple frames for temporal effects (like using the camera color buffer for temporal anti-aliasing). You are responsible for handling the lifetime of these resources. After you create or import a resource, the render graph system represents it as a resource type-specific handle (TextureHandle, BufferHandle, or RendererListHandle). This way, the render graph can use internal and imported resources in the same way in all of its APIs. public TextureHandle RenderGraph.CreateTexture(in TextureDesc desc); public BufferHandle RenderGraph.CreateComputeBuffer(in ComputeBufferDesc desc) public RendererListHandle RenderGraph.CreateRendererList(in RendererListDesc desc); public TextureHandle RenderGraph.ImportTexture(RTHandle rt); public TextureHandle RenderGraph.ImportBackbuffer(RenderTargetIdentifier rt); public BufferHandle RenderGraph.ImportBuffer(ComputeBuffer computeBuffer); The main ways to create resources are described above, but there are variations of these functions. For the complete list, see the API documentation. Note that the specific function to use to import the camera back buffer is RenderTargetIdentifier. To create resources, each API requires a descriptor structure as a parameter. The properties in these structures are similar to the properties in the resources they represent (respectively RTHandle, ComputeBuffer, and RendererLists). However, some properties are specific to render graph textures. Here are the most important ones: clearBuffer: This property tells the graph whether to clear the buffer when the graph creates it. This is how you should clear textures when using the render graph. This is important because a render graph pools resources, which means any pass that creates a texture might get an already existing one with undefined content. clearColor: This property stores the color to clear the buffer to, if applicable. There are also two notions specific to textures that a render graph exposes through the TextureDesc constructors: xrReady: This boolean indicates to the graph whether this texture is for XR rendering. If true, the render graph creates the texture as an array for rendering into each XR eye. dynamicResolution: This boolean indicates to the graph whether it needs to dynamically resize this texture when the application uses dynamic resolution. If false, the texture does not scale automatically. You can create resources outside render passes, inside the setup code for a render pass, but not in the rendering code. Creating a resource outside of all render passes can be useful for cases where the first pass uses a given resource that depends on logic in the code that might change regularly. In this case, you must create the resource before any of those passes. A good example is using the color buffer for either a deferred lighting pass or a forward lighting pass. Both of these passes write to the color buffer, but Unity only executes one of them depending on the current rendering path chosen for the camera. In this case, you would create the color buffer outside both passes and pass it to the correct one as a parameter. Creating a resource inside a render pass is usually for resources the render pass produces itself. For example, a blur pass requires an already existing input texture, but creates the output itself and returns it at the end of the render pass. Note that creating a resource like that does not allocate GPU memory every frame. Instead, the render graph system reuses pooled memory. In the context of the render graph, think of resource creation more in terms of data flow in the context of a render pass than actual allocation. If a render pass creates a whole new output then it “creates” a new texture in the render graph. Writing a render pass Before Unity can execute the render graph, you must declare all the render passes. You write a render pass in two parts: setup and rendering. Setup During setup, you declare the render pass and all the data it needs to execute. The render graph represents data by a class specific to the render pass that contains all the relevant properties. These can be regular C# constructs (struct, PoDs, etc) and render graph resource handles. This data structure is accessible during the actual rendering code. class MyRenderPassData { public float parameter; public TextureHandle inputTexture; public TextureHandle outputTexture; } After you define the pass data, you can then declare the render pass itself: using (var builder = renderGraph.AddRenderPass<MyRenderPassData>(\"My Render Pass\", out var passData)) { passData.parameter = 2.5f; passData.inputTexture = builder.ReadTexture(inputTexture); TextureHandle output = renderGraph.CreateTexture(new TextureDesc(Vector2.one, true, true) { colorFormat = GraphicsFormat.R8G8B8A8_UNorm, clearBuffer = true, clearColor = Color.black, name = \"Output\" }); passData.outputTexture = builder.WriteTexture(output); builder.SetRenderFunc(myFunc); // details below. } You define the render pass in the using scope around the AddRenderPass function. At the end of the scope, the render graph adds the render pass to the internal structures of the render graph for later processing. The builder variable is an instance of RenderGraphBuilder. This is the entry point to build the information relating to the render pass. There are several important parts to this: Declaring resource usage: This is one of the most important aspects of the RenderGraph API. Here you explicitly declare whether the render pass needs read and/or write access to the resources. This allows the render graph to have an overall view of the whole rendering frame and thus determine the best use of GPU memory and synchronization points between various render passes. Declaring the rendering function: This is the function in which you call graphics commands. It receives the pass data you define for the render pass as a parameter as well as the render graph context. You set the rendering function for a render pass via SetRenderFunc and the function runs after the graph compiles. Creating transient resources: Transient, or internal, resources are resources you create for the duration of this render pass only. You create them in the builder rather than the render graph itself to reflect their lifetime. Creating transient resources uses the same parameters as the equivalent function in the RenderGraph APIs. This is particularly useful when a pass uses temporary buffers that should not be accessible outside of the pass. Outside the pass where you declare a transient resource, the handle to the resource becomes invalid and Unity throws errors if you try to use it. The passData variable is an instance of the type you provide when you declare the pass. This is where you set the data that the rendering code can access. Note that the render graph does not use the contents of passData right away, but later in the frame, after it registers all the passes and the render graph compiles and executes. This means that any reference the passData stores must be constant across the whole frame. Otherwise, if you change the content before the render pass executes, it does not contain the correct content during the render pass. For this reason, it is best practice to only store value types in the passData unless you are certain that a reference stays constant until the pass finishes execution. For an overview of the RenderGraphBuilder APIs, see the below table. For more details, see the API documentation: Function Purpose TextureHandle ReadTexture(in TextureHandle input) Declares that the render pass reads from the input texture you pass into the function. TextureHandle WriteTexture(in TextureHandle input) Declares that the render pass writes to the input texture you pass into the function. TextureHandle UseColorBuffer(in TextureHandle input, int index) Same as WriteTexture but also automatically binds the texture as a render texture at the provided binding index at the beginning of the pass. TextureHandle UseDepthBuffer(in TextureHandle input, DepthAccess flags) Same as WriteTexture but also automatically binds the texture as a depth texture with the access flags you pass into the function. TextureHandle CreateTransientTexture(in TextureDesc desc) Create a transient texture. This texture exists for the duration of the pass. RendererListHandle UseRendererList(in RendererListHandle input) Declares that this render pass uses the Renderer List you pass in. The render pass uses the RendererList.Draw command to render the list. BufferHandle ReadComputeBuffer(in BufferHandle input) Declares that the render pass reads from the input ComputeBuffer you pass into the function. BufferHandle WriteComputeBuffer(in BufferHandle input) Declares that the render pass writes to the input Compute Buffer you pass into the function. BufferHandle CreateTransientComputeBuffer(in BufferDesc desc) Create a transient Compute Buffer. This texture exists for the duration of the Compute Buffer. void SetRenderFunc (RenderFunc renderFunc) where PassData : class, new() Set the rendering function for the render pass. void EnableAsyncCompute(bool value) Declares that the render pass runs on the asynchronous compute pipeline. void AllowPassCulling(bool value) Specifies whether Unity should cull the render pass (default is true). This can be useful when the render pass has side effects and you never want the render graph system to cull. void EnableFoveatedRasterization(bool value) Declares that the render pass runs with foveated rendering feature enabled. Rendering Code After you complete the setup, you can declare the function to use for rendering via the SetRenderFunc method on the RenderGraphBuilder. The function you assign must use the following signature: delegate void RenderFunc<PassData>(PassData data, RenderGraphContext renderGraphContext) where PassData : class, new(); You can either pass a render function as a static function or a lambda. The benefit of using a lambda function is that it can bring better code clarity because the rendering code is next to the setup code. Note that if you use a lambda, be very careful not to capture any parameters from the main scope of the function as that generates garbage, which Unity later locates and frees during garbage collection. If you use Visual Studio and hover over the arrow =>, it tells you if the lambda captures anything from the scope. Avoid accessing members or member functions because using either captures this. The render function takes two parameters: PassData data: This data is of the type you pass in when you declare the render pass. This is where you can access the properties initialized during the setup phase and use them for the rendering code. RenderGraphContext renderGraphContext. This stores references to the ScriptableRenderContext and the CommandBuffer that provide utility functions and allow you to write rendering code. Accessing resources in the render pass Inside the rendering function, you can access all the render graph resource handles stored inside the passData. The conversion to actual resources is automatic so, whenever a function needs an RTHandle, a ComputeBuffer, or a RendererList, you can pass the handle and the render graph converts the handle to the actual resource implicitly. Note that doing such implicit conversion outside of a rendering function results in an exception. This exception occurs because, outside of rendering, the render graph may have not allocated those resources yet. Using the RenderGraphContext The RenderGraphContext provides various functionality you need to write rendering code. The two most important are the ScriptableRenderContext and the CommandBuffer, which you use to call all rendering commands. The RenderGraphContext also contains the RenderGraphObjectPool. This class helps you to manage temporary objects that you might need for rendering code. Get temp functions Two functions that are particularly useful during render passes are GetTempArray and GetTempMaterialPropertyBlock. T[] GetTempArray<T>(int size); MaterialPropertyBlock GetTempMaterialPropertyBlock(); GetTempArray returns a temporary array of type T and size size. This can be useful to allocate temporary arrays for passing parameters to materials or creating a RenderTargetIdentifier array to create multiple render target setups without the need to manage the array’s lifetime yourself. GetTempMaterialPropertyBlock returns a clean material property block that you can use to set up parameters for a Material. This is particularly important because more than one pass might use a material and each pass could use it with different parameters. Because the rendering code execution is deferred via command buffers, copying material property blocks into the command buffer is mandatory to preserve data integrity on execution. The render graph releases and pools all the resources these two functions return automatically after the pass execution. This means you don’t have to manage them yourself and does not create garbage. Example render pass The following code example contains a render pass with a setup and render function: TextureHandle MyRenderPass(RenderGraph renderGraph, TextureHandle inputTexture, float parameter, Material material) { using (var builder = renderGraph.AddRenderPass<MyRenderPassData>(\"My Render Pass\", out var passData)) { passData.parameter = parameter; passData.material = material; // Tells the graph that this pass will read inputTexture. passData.inputTexture = builder.ReadTexture(inputTexture); // Creates the output texture. TextureHandle output = renderGraph.CreateTexture(new TextureDesc(Vector2.one, true, true) { colorFormat = GraphicsFormat.R8G8B8A8_UNorm, clearBuffer = true, clearColor = Color.black, name = \"Output\" }); // Tells the graph that this pass will write this texture and needs to be set as render target 0. passData.outputTexture = builder.UseColorBuffer(output, 0); builder.SetRenderFunc( (MyRenderPassData data, RenderGraphContext ctx) => { // Render Target is already set via the use of UseColorBuffer above. // If builder.WriteTexture was used, you'd need to do something like that: // CoreUtils.SetRenderTarget(ctx.cmd, data.output); // Setup material for rendering var materialPropertyBlock = ctx.renderGraphPool.GetTempMaterialPropertyBlock(); materialPropertyBlock.SetTexture(\"_MainTexture\", data.input); materialPropertyBlock.SetFloat(\"_FloatParam\", data.parameter); CoreUtils.DrawFullScreen(ctx.cmd, data.material, materialPropertyBlock); }); return output; } } Ending the frame Over the course of your application, the render graph needs to allocate various resources. It might use these resources for a time but then might not need them. For the graph to free up those resources, call the EndFrame() method once a frame. This deallocates any resources that the render graph has not used since the last frame. This also executes all internal processing the render graph requires at the end of the frame. Note that you should only call this once per frame and after all the rendering is complete (for example, after the last camera renders). This is because different cameras might have different rendering paths and thus need different resources. Calling the purge after each camera could result in the render graph releasing resources too early even though they might be necessary for the next camera."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system-fundamentals.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system-fundamentals.html",
    "title": "| Inventory System",
    "summary": "RTHandle system fundamentals This document describes the main principles of the RTHandle (RTHandle) system. The RTHandle system is an abstraction on top of Unity's RenderTexture API. It makes it trivial to reuse render textures across Cameras that use various resolutions. The following principles are the foundation of how the RTHandle system works: You no longer allocate render textures yourself with a fixed resolution. Instead, you declare a render texture using a scale related to the full screen at a given resolution. The RTHandle system allocates the texture only once for the whole render pipeline so that it can reuse it for different Cameras. There is now the concept of reference size. This is the resolution the application uses for rendering. It is your responsibility to declare it before the render pipeline renders every Camera at a particular resolution. For information on how to do this, see the Updating the RTHandle system section. Internally, the RTHandle system tracks the largest reference size you declare. It uses this as the actual size of render textures. The largest reference size is the maximum size. Every time you declare a new reference size for rendering, the RTHandle system checks if it is larger than the current recorded largest reference size. If it is, the RTHandle system reallocates all render textures internally to fit the new size and replaces the largest reference size with the new size. An example of this process is as follows. When you allocate the main color buffer, it uses a scale of 1 because it is a full-screen texture. You want to render it at the resolution of the screen. A downscaled buffer for a quarter-resolution transparency pass would use a scale of 0.5 for both the x-axis and y-axis. Internally the RTHandle system allocates render textures using the largest reference size multiplied by the scale you declare for the render texture. After that and before each Camera renders, you tell the system what the current reference size is. Based on that and the scaling factor for all textures, the RTHandle system determines if it needs to reallocate render textures. As mentioned above, if the new reference size is larger than the current largest reference size, the RTHandle system reallocates all render textures. By doing this, the RTHandle system ends up with a stable maximum resolution for all render textures, which is most likely the resolution of your main Camera. The key takeaway of this is that the actual resolution of the render textures is not necessarily the same as the current viewport: it can be bigger. This has implications when you write a renderer using RTHandles, which the Using the RTHandle system documentation explains. The RTHandleSystem also allows you to allocate textures with a fixed size. In this case, the RTHandle system never reallocates the texture. This allows you to use the RTHandle API consistently for both automatically-resized textures that the RTHandle system manages and regular fixed size textures that you manage."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system-using.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system-using.html",
    "title": "| Inventory System",
    "summary": "Using the RTHandle system This page covers how to use the RTHandle system to manage render textures in your render pipeline. For information about the RTHandle system, see RTHandle system and RTHandle system fundamentals. Initializing the RTHandle System All operations related to RTHandles require an instance of the RTHandleSystem class. This class contains all the APIs necessary to allocate RTHandles, release RTHandles, and set the reference size for the frame. This means that you must create and maintain an instance of RTHandleSystem in your render pipeline or make use of the static RTHandles class mentioned later in this section. To create your own instance of RTHandleSystem, see the following code sample: RTHandleSystem m_RTHandleSystem = new RTHandleSystem(); m_RTHandleSystem.Initialize(Screen.width, Screen.height); When you initialize the system, you must supply the starting resolution. The above code example uses the width and height of the screen. Because the RTHandle system only reallocates render textures when a Camera requires a resolution larger than the current maximum size, the internal RTHandle resolution can only increase from the value you pass in here. It is good practice to initialize this resolution to be the resolution of the main display. This means the system does not need to unnecessarily reallocate the render textures (and cause unwanted memory spikes) at the beginning of the application. You must only call the Initialize function once at the beginning of the application. After this, you can use the initialized instance to allocate textures. Because you allocate the majority of RTHandles from the same RTHandleSystem instance, the RTHandle system also provides a default global instance through the RTHandles static class. Rather than maintain your own instance of RTHandleSystem, this allows you to use the same API that you get with an instance, but not worry about the lifetime of the instance. Using the static instance, the initialization becomes this: RTHandles.Initialize(Screen.width, Screen.height); The code examples in the rest of this page use the default global instance. Updating the RTHandle System Before rendering with a Camera, you need to set the resolution the RTHandle system uses as a reference size. To do so, call the SetReferenceSize function. RTHandles.SetReferenceSize(width, height); Calling this function has two effects: If the new reference size you provide is bigger than the current one, the RTHandle system reallocates all the render textures internally to match the new size. After that, the RTHandle system updates internal properties that set viewport and render texture scales for when the system uses RTHandles as active render textures. Allocating and releasing RTHandles After you initialize an instance of RTHandleSystem, whether this is your own instance or the static default instance, you can use it to allocate RTHandles. There are three main ways to allocate an RTHandle. They all use the same Alloc method on the RTHandleSystem instance. Most of the parameters of these functions are the same as the regular Unity RenderTexture ones, so for more information see the RenderTexture API documentation. This section focuses on the parameters that relate to the size of the RTHandle: Vector2 scaleFactor: This variant requires a constant 2D scale for width and height. The RTHandle system uses this to calculate the resolution of the texture against the maximum reference size. For example, a scale of (1.0f, 1.0f) generates a full-screen texture. A scale of (0.5f 0.5f) generates a quarter-resolution texture. ScaleFunc scaleFunc: For cases when you don't want to use a constant scale to calculate the size of an RTHandle, you can provide a functor that calculates the size of the texture. The functor should take a Vector2Int as a parameter, which is the maximum reference size, and return a Vector2Int, which represents the size you want the texture to be. int width, int height: This is for fixed-size textures. If you allocate a texture like this, it behaves like any regular RenderTexture. There are also overrides that create RTHandles from RenderTargetIdentifier. RenderTextures, or Textures. These are useful when you want to use the RTHandle API to interact with all your textures, even though the texture might not be an actual RTHandle. The following code sample contains example uses of the Alloc function: // Simple Scale RTHandle simpleScale = RTHandles.Alloc(Vector2.one, depthBufferBits: DepthBits.Depth32, dimension: TextureDimension.Tex2D, name: \"CameraDepthStencil\"); // Functor Vector2Int ComputeRTHandleSize(Vector2Int screenSize) { return DoSpecificResolutionComputation(screenSize); } RTHandle rtHandleUsingFunctor = RTHandles.Alloc(ComputeRTHandleSize, colorFormat: GraphicsFormat.R32_SFloat, dimension: TextureDimension.Tex2D); // Fixed size RTHandle fixedSize = RTHandles.Alloc(256, 256, colorFormat: GraphicsFormat.R8G8B8A8_UNorm, dimension: TextureDimension.Tex2D); When you no longer need a particular RTHandle, you can release it. To do this, call the Release method. myRTHandle.Release(); Using RTHandles After you allocate an RTHandle, you can use it exactly like a regular RenderTexture. There are implicit conversions to RenderTargetIdentifier and RenderTexture, which means you can use them with regular related Unity APIs. However, when you use the RTHandle system, the actual resolution of the RTHandle might be different from the current resolution. For example, if the main Camera renders at 1920x1080 and a secondary Camera renders at 512x512, all RTHandle resolutions are based on the 1920x1080 resolution, even when rendering at lower resolutions. Because of this, take care when you set an RTHandle up as a render target. There are a number of APIs available in the CoreUtils class to help you with this. For example: public static void SetRenderTarget(CommandBuffer cmd, RTHandle buffer, ClearFlag clearFlag, Color clearColor, int miplevel = 0, CubemapFace cubemapFace = CubemapFace.Unknown, int depthSlice = -1) This function sets the RTHandle as the active render target but also sets up the viewport based on the scale of the RTHandle and the current reference size, not the maximum size. For example, when the reference size is 512x512, even if the maximum size is 1920x1080, a texture of scale (1.0f, 1.0f) uses the 512x512 size and therefore sets up a 512x512 viewport. A (0.5f, 0.5f) scaled texture sets up a viewport of 256x256 and so on. This means that, when using these helper functions, the RTHandle system generates the correct viewport based on the RTHandle parameters. This example is one of many different overrides for the SetRenderTarget function. For the full list of overrides, see the documentation. Using RTHandles in shaders When you sample from a full-screen render texture in a shader in the usual way, UVs span the whole 0 to 1 range. This is not always the case with RTHandles. The current rendering might only occur in a partial viewport. To take this into account, you must apply a scale to UVs when you sample RTHandles that use a scale. All the information necessary to handle RTHandles specificity inside shaders is in the RTHandleProperties structure that the RTHandleSystem instance provides. To access it, use: RTHandleProperties rtHandleProperties = RTHandles.rtHandleProperties; This structure contains the following properties: public struct RTHandleProperties { public Vector2Int previousViewportSize; public Vector2Int previousRenderTargetSize; public Vector2Int currentViewportSize; public Vector2Int currentRenderTargetSize; public Vector4 rtHandleScale; } This structure provides: The current viewport size. This is the reference size you set for rendering. The current render target size. This is the actual size of the render texture based on the maximum reference size. The rtHandleScale. This is the scale to apply to full-screen UVs to sample an RTHandle. Values for previous frames are also available. For more information, see Camera specific RTHandles. Generally, the most important property in this structure is rtHandleScale. It allows you to scale full-screen UV coordinates and use the result to sample an RTHandle. For example: float2 scaledUVs = fullScreenUVs * rtHandleScale.xy; However, because the partial viewport always starts at (0, 0), when you use integer pixel coordinates within the viewport to load content from a texture, there is no need to rescale them. Another important thing to consider is that, when you render a full-screen quad into a partial viewport, there is no benefit from standard UV addressing mechanisms such as wrap or clamp. This is because the texture might be bigger than the viewport. For this reason, take care when you sample pixels outside of the viewport. Custom SRP specific information There are no shader constants provided by default with SRP. So, when you use RTHandles with your own SRP, you must provide these constants to their shaders themselves. Camera specific RTHandles Most of the render textures that a rendering loop uses can be shared by all Cameras. If their content does not need to carry from one frame to another, this is fine. However, some render textures need persistence. A good example of this is using the main color buffer in subsequent frames for Temporal Anti-aliasing. This means that the Camera cannot share its RTHandle with other Cameras. Most of the time, this also means that these RTHandles must be at least double-buffered (written to during the current frame, read from during the previous frame). To address this problem, the RTHandle system includes BufferedRTHandleSystems. A BufferedRTHandleSystem is an RTHandleSystem that can multi-buffer RTHandles. The principle is to identify a buffer by a unique ID and provide APIs to allocate a number of instances of the same buffer then retrieve them from previous frames. These are history buffers. Usually, you must allocate one BufferedRTHandleSystem for each Camera. Each one owns their Camera-specific RTHandles. Not every Camera needs history buffers. For example, if a Camera does not need Temporal Anti-aliasing, you do not need to assign a BufferedRTHandleSystem to it. History buffers require memory which means you can save memory by not assigning history buffers to Cameras that do not need them. Another consequence is that the system only allocates history buffers at the resolution of the Camera that the buffers are for. If the main Camera is 1920x1080 and another Camera renders in 256x256 and needs a history color buffer, the second Camera only uses a 256x256 buffer and not a 1920x1080 buffer as the non-Camera specific RTHandles would. To create an instance of a BufferedRTHandleSystem, see the following code sample: BufferedRTHandleSystem m_HistoryRTSystem = new BufferedRTHandleSystem(); To allocate an RTHandle using a BufferedRTHandleSystem, the process is different from a normal RTHandleSystem: public void AllocBuffer(int bufferId, Func<RTHandleSystem, int, RTHandle> allocator, int bufferCount); The bufferId is a unique ID that the system uses to identify the buffer. The allocator is a function you provide to allocate the RTHandles when needed (all instances are not allocated upfront), and the bufferCount is the number of instances requested. From there, you can retrieve each RTHandle by its ID and instance index like so: public RTHandle GetFrameRT(int bufferId, int frameIndex); The frame index is between zero and the number of buffers minus one. Zero always represents the current frame buffer, one the previous frame buffer, two the one before that, and so on. To release a buffered RTHandle, call the Release function on the BufferedRTHandleSystem, passing in the ID of the buffer to release: public void ReleaseBuffer(int bufferId); In the same way that you provide the reference size for regular RTHandleSystems, you must do this for each instance of BufferedRTHandleSystem. public void SwapAndSetReferenceSize(int width, int height); This works the same way as regular RTHandleSystem but it also swaps the buffers internally so that the 0 index for GetFrameRT still references the current frame buffer. This slightly different way of handling Camera-specific buffers also has implications when you write shader code. With a multi-buffered approach like this, RTHandles from a previous frame might have a different size to the one from the current frame. For example, this can happen with dynamic resolution or even when you resize the window in the Editor. This means that when you access a buffered RTHandle from a previous frame, you must scale it accordingly. The scale Unity uses to do this is in RTHandleProperties.rtHandleScale.zw. Unity uses this in exactly the same way as xy for regular RTHandles. This is also the reason why RTHandleProperties contains the viewport and resolution of the previous frame. It can be useful when doing computation with history buffers. Dynamic Resolution One of the byproducts of the RTHandle System design is that you can also use it to simulate software dynamic resolution. Because the current resolution of the Camera is not directly correlated to the actual render texture objects, you can provide any resolution you want at the beginning of the frame and all render textures scale accordingly. Reset Reference Size Sometimes, you might need to render to a higher resolution than normal for a short period of time. If your application does not require this resolution anymore, the additional memory allocated is wasted. To avoid that, you can reset the current maximum resolution of an RTHandleSystem like so: RTHandles.ResetReferenceSize(newWidth, newHeight); This forces the RTHandle system to reallocate all RTHandles to the new provided size. This is the only way to shrink the size of RTHandles."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/rthandle-system.html",
    "title": "The RTHandle system | Inventory System",
    "summary": "The RTHandle system Render target management is an important part of any render pipeline. In a complicated render pipeline where there are many interdependent render passes that use many different render textures, it is important to have a maintainable and extendable system that allows for easy memory management. One of the biggest issues occurs when a render pipeline uses many different Cameras, each with their own resolution. For example, off-screen Cameras or real-time reflection probes. In this scenario, if the system allocated render textures independently for each Camera, the total amount of memory would increase to unmanageable levels. This is particularly bad for complex render pipelines that use many intermediate render textures. Unity can use temporary render textures, but unfortunately, they do not suit this kind of use case because temporary render textures can only reuse memory if a new render texture uses the exact same properties and resolution. This means that when rendering with two different resolutions, the total amount of memory Unity uses is the sum of all resolutions. To solve these issues with render texture memory allocation, Unity's Scriptable Render Pipeline includes the RTHandle system. This system is an abstraction layer on top of Unity's RenderTexture API that handles render texture management automatically. This section contains the following pages: RTHandle system fundamentals Using the RTHandle system"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/settings.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/settings.html",
    "title": "Custom graphics settings | Inventory System",
    "summary": "Custom graphics settings Add, store, and manage custom settings that control rendering features and behaviours in a Scriptable Render Pipeline. For example, quality or shader settings. Page Description Adding properties in the menu Add properties in the Core Render Pipeline settings section. Add a settings group To add custom graphics settings to a Scriptable Render Pipeline, implement the IRenderPipelineGraphicsSettings interface. Add a setting Add a simple property or a reference property to a custom graphics settings group. Customize the UI of a setting Customize how a setting displays in the graphics settings window, or add items to the More (⋮) menu of a settings group. Get custom graphics settings Get a custom graphics setting and read its value, or detect when a setting changes. Include or exclude a setting in your build Choose whether Unity includes or strips a graphics setting in your build, and check if a build includes a setting. Additional resources Graphics settings in the Unity manual"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/shaders.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/shaders.html",
    "title": "Shaders | Inventory System",
    "summary": "Shaders Work with shader code in the Scriptable Render Pipeline (SRP). Page Description Use shader methods from the SRP Core shader library SRP Core has a library of High-Level Shader Language (HLSL) shader files that contain helper methods. You can import these files into your custom shader files and use the helper methods. Synchronizing shader code and C# Generate HLSL code based on C# structs to synchronize data and constants between shaders and C#. Additional resources HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-callbacks-reference.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-callbacks-reference.html",
    "title": "Scriptable Render Pipeline callbacks reference | Inventory System",
    "summary": "Scriptable Render Pipeline callbacks reference When working with SRP, use these to make Unity call your C# code at specific times. RenderPipeline.Render is the main entry point to the SRP. Unity calls this method automatically. If you are writing a custom render pipeline, this is where you begin to write your code. The RenderPipelineManager class has the following events that you can subscribe to, so that you can execute custom code at specific points in the render loop: beginFrameRendering - Note: This can generate garbage. Use beginContextRendering instead. endFrameRendering - Note: This can generate garbage. Use endContextRendering instead. beginContextRendering endContextRendering beginCameraRendering endCameraRendering"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-creating-render-pipeline-asset-and-render-pipeline-instance.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-creating-render-pipeline-asset-and-render-pipeline-instance.html",
    "title": "Create a Render Pipeline Asset and Render Pipeline Instance in a custom render pipeline | Inventory System",
    "summary": "Create a Render Pipeline Asset and Render Pipeline Instance in a custom render pipeline If you are creating your own render pipeline based on the Scriptable Render Pipeline (SRP), your Project must contain: A script that inherits from RenderPipelineAsset and overrides its CreatePipeline() method. This script defines your Render Pipeline Asset. A script that inherits from RenderPipeline, and overrides its Render() method. This script defines your Render Pipeline Instance, and is where you write your custom rendering code. A Render Pipeline Asset that you have created from your RenderPipelineAsset script. This asset acts as a factory class for your Render Pipeline Instance. Because these elements are so closely related, you should create them at the same time. Creating a basic Render Pipeline Asset and Render Pipeline Instance The following example shows how to create a script for a basic custom Render Pipeline Asset that instantiates the Render Pipeline Instance, a script that defines the Render Pipeline Instance, and the Render Pipeline Asset itself. Create a C# script called ExampleRenderPipelineAsset.cs. Copy and paste the following code into the new script: using UnityEngine; using UnityEngine.Rendering; // The CreateAssetMenu attribute lets you create instances of this class in the Unity Editor. [CreateAssetMenu(menuName = \"Rendering/ExampleRenderPipelineAsset\")] public class ExampleRenderPipelineAsset : RenderPipelineAsset { // Unity calls this method before rendering the first frame. // If a setting on the Render Pipeline Asset changes, Unity destroys the current Render Pipeline Instance and calls this method again before rendering the next frame. protected override RenderPipeline CreatePipeline() { // Instantiate the Render Pipeline that this custom SRP uses for rendering. return new ExampleRenderPipelineInstance(); } } Create a C# script called ExampleRenderPipelineInstance.cs. Copy and paste the following code into the new script: using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipelineInstance : RenderPipeline { public ExampleRenderPipelineInstance() { } protected override void Render (ScriptableRenderContext context, Camera[] cameras) { // This is where you can write custom rendering code. Customize this method to customize your SRP. } } In the Project view, either click the add (+) button, or open the context menu and navigate to Create, and then choose Rendering > Example Render Pipeline Asset. Unity creates a new Render Pipeline Asset in the Project view. Creating a configurable Render Pipeline Asset and Render Pipeline Instance By default, a Render Pipeline Asset stores information about which Render Pipeline Instance to use for rendering, and the default Materials and Shaders to use in the Editor. In your RenderPipelineAsset script, you can extend your Render Pipeline Asset so that it stores additional data, and you can have multiple different Render Pipeline Assets with different configurations in your Project. For example, you might use a Render Pipeline Asset to hold configuration data for each different tier of hardware. The High Definition Render Pipeline (HDRP) and the Universal Render Pipeline (URP) include examples of this. The following example shows how to create a RenderPipelineAsset script that defines a Render Pipeline Asset with public data that you can set for each instance using the Inspector, and a Render Pipeline Instance that receives a Render Pipeline Asset in its constructor and uses data from that Render Pipeline Asset. Create a C# script called ExampleRenderPipelineAsset.cs. Copy and paste the following code into the new script: using UnityEngine; using UnityEngine.Rendering; // The CreateAssetMenu attribute lets you create instances of this class in the Unity Editor. [CreateAssetMenu(menuName = \"Rendering/ExampleRenderPipelineAsset\")] public class ExampleRenderPipelineAsset : RenderPipelineAsset { // This data can be defined in the Inspector for each Render Pipeline Asset public Color exampleColor; public string exampleString; // Unity calls this method before rendering the first frame. // If a setting on the Render Pipeline Asset changes, Unity destroys the current Render Pipeline Instance and calls this method again before rendering the next frame. protected override RenderPipeline CreatePipeline() { // Instantiate the Render Pipeline that this custom SRP uses for rendering, and pass a reference to this Render Pipeline Asset. // The Render Pipeline Instance can then access the configuration data defined above. return new ExampleRenderPipelineInstance(this); } } Create a C# script called ExampleRenderPipelineInstance.cs. Copy and paste the following code into the new script: using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipelineInstance : RenderPipeline { // Use this variable to a reference to the Render Pipeline Asset that was passed to the constructor private ExampleRenderPipelineAsset renderPipelineAsset; // The constructor has an instance of the ExampleRenderPipelineAsset class as its parameter. public ExampleRenderPipelineInstance(ExampleRenderPipelineAsset asset) { renderPipelineAsset = asset; } protected override void Render(ScriptableRenderContext context, Camera[] cameras) { // This is an example of using the data from the Render Pipeline Asset. Debug.Log(renderPipelineAsset.exampleString); // This is where you can write custom rendering code. Customize this method to customize your SRP. } } In the Project view, either click the add (+) button, or open the context menu and navigate to Create, and then choose Rendering > Example Render Pipeline Asset. Unity creates a new Render Pipeline Asset in the Project view."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-creating-simple-render-loop.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-creating-simple-render-loop.html",
    "title": "Create a simple render loop in a custom render pipeline | Inventory System",
    "summary": "Create a simple render loop in a custom render pipeline A render loop is the term for all of the rendering operations that take place in a single frame. This page contains information on creating a simple render loop in a custom render pipeline that is based on Unity's Scriptable Render Pipeline. The code examples on this page demonstrate the basic principles of using the Scriptable Render Pipeline. You can use this information to build your own custom Scriptable Render Pipeline, or to understand how Unity's prebuilt Scriptable Render Pipelines work. Preparing your project Before you begin writing the code for your render loop, you must prepare your project. The steps are as follows: Create an SRP-compatible shader. Create one or more GameObjects to render. Create the basic structure of your custom SRP. Optional: If you plan to extend your simple custom SRP to add more complex functionality, install the SRP Core package. The SRP Core package includes the SRP Core shader library (which you can use to make your shaders SRP Batcher compatible), and utility functions for common operations. Creating an SRP-compatible shader In the Scriptable Render Pipeline, you use the LightMode Pass tag to determine how to draw geometry. For more information on Pass tags, see ShaderLab: assigning tags to a Pass. This task shows you how to create a very simple unlit Shader object with a LightMode Pass tag value of ExampleLightModeTag. Create a new shader asset in your project. For instructions on creating a shader asset, see Shader assets. In your Project view, double click the shader asset to open the shader source code in a text editor. Replace the existing code with the following: // This defines a simple unlit Shader object that is compatible with a custom Scriptable Render Pipeline. // It applies a hardcoded color, and demonstrates the use of the LightMode Pass tag. // It is not compatible with SRP Batcher. Shader \"Examples/SimpleUnlitColor\" { SubShader { Pass { // The value of the LightMode Pass tag must match the ShaderTagId in ScriptableRenderContext.DrawRenderers Tags { \"LightMode\" = \"ExampleLightModeTag\"} HLSLPROGRAM #pragma vertex vert #pragma fragment frag float4x4 unity_MatrixVP; float4x4 unity_ObjectToWorld; struct Attributes { float4 positionOS : POSITION; }; struct Varyings { float4 positionCS : SV_POSITION; }; Varyings vert (Attributes IN) { Varyings OUT; float4 worldPos = mul(unity_ObjectToWorld, IN.positionOS); OUT.positionCS = mul(unity_MatrixVP, worldPos); return OUT; } float4 frag (Varyings IN) : SV_TARGET { return float4(0.5,1,0.5,1); } ENDHLSL } } } Creating a GameObject to render To test that your render loop works, you must create something to render. This task shows you how to put GameObjects in your scene that use the SRP-compatible shader that you created in the previous task. Create a new material asset in your Unity project. For instructions see Materials. Assign the shader asset to the material asset. For instructions, see Materials. Create a cube in your scene. For instructions, see Primitive objects. Assign the material to it. For instructions, see Materials. Creating the basic structure of your custom SRP The final stage of preparation is to create the basic source files needed for your custom SRP, and tell Unity to begin rendering using the custom SRP. Create a class that inherits from RenderPipeline and a compatible Render Pipeline Asset, following the instructions in Creating a Render Pipeline Instance and Render Pipeline Asset Set the active Render Pipeline Asset, following the instructions in How to get, set, and configure the active render pipeline. Unity will begin rendering using the custom SRP immediately, which means that your Scene view and Game view will be blank until you add code to your custom SRP. Creating the render loop In a simple render loop, the basic operations are: Clearing the render target, which means removing the geometry that was drawn during the last frame. Culling, which means filtering out geometry that is not visible to a Camera. Drawing, which means telling the GPU what geometry to draw, and how to draw it. Clearing the render target Clearing means removing the things that were drawn during the last frame. The render target is usually the screen; however, you can also render to textures to create a \"picture in picture\" effect. These examples demonstrate how to render to the screen, which is Unity's default behavior. To clear the render target in the Scriptable Render Pipeline, you do the following: Configure a CommandBuffer with a Clear command. Add the CommandBuffer to the queue of commands on the ScriptableRenderContext; to do this, call ScriptableRenderContext.ExecuteCommandBuffer. Instruct the graphics API to perform the queue of commands on the ScriptableRenderContext; to do this, call ScriptableRenderContext.Submit. As with all Scriptable Render Pipeline operations, you use the RenderPipeline.Render method as the entry point for this code. This example code demonstrates how to do this: /* This is a simplified example of a custom Scriptable Render Pipeline. It demonstrates how a basic render loop works. It shows the clearest workflow, rather than the most efficient runtime performance. */ using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipeline : RenderPipeline { public ExampleRenderPipeline() { } protected override void Render (ScriptableRenderContext context, Camera[] cameras) { // Create and schedule a command to clear the current render target var cmd = new CommandBuffer(); cmd.ClearRenderTarget(true, true, Color.black); context.ExecuteCommandBuffer(cmd); cmd.Release(); // Instruct the graphics API to perform all scheduled commands context.Submit(); } } Culling Culling is the process of filtering out geometry that is not visible to a Camera. To cull in the Scriptable Render Pipeline, you do the following: Populate a ScriptableCullingParameters struct with data about a Camera; to do this, call Camera.TryGetCullingParameters. Optional: Manually update the values of the ScriptableCullingParameters struct. Call ScriptableRenderContext.Cull, and store the results in a CullingResults struct. This example code extends the example above, and demonstrates how to clear the render target and then perform a culling operation: /* This is a simplified example of a custom Scriptable Render Pipeline. It demonstrates how a basic render loop works. It shows the clearest workflow, rather than the most efficient runtime performance. */ using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipeline : RenderPipeline { public ExampleRenderPipeline() { } protected override void Render (ScriptableRenderContext context, Camera[] cameras) { // Create and schedule a command to clear the current render target var cmd = new CommandBuffer(); cmd.ClearRenderTarget(true, true, Color.black); context.ExecuteCommandBuffer(cmd); cmd.Release(); // Iterate over all Cameras foreach (Camera camera in cameras) { // Get the culling parameters from the current Camera camera.TryGetCullingParameters(out var cullingParameters); // Use the culling parameters to perform a cull operation, and store the results var cullingResults = context.Cull(ref cullingParameters); } // Instruct the graphics API to perform all scheduled commands context.Submit(); } } Drawing Drawing is the process of instructing the graphics API to draw a given set of geometry with given settings. To draw in SRP, you do the following: Perform a culling operation, as described above, and store the results in a CullingResults struct. Create and configure FilteringSettings struct, which describes how to filter the culling results. Create and configure a DrawingSettings struct, which describes which geometry to draw and how to draw it. Optional: By default, Unity sets the render state based on the Shader object. If you want to override the render state for some or all of the geometry that you are about to draw, you can use a RenderStateBlock struct to do this. Call ScriptableRenderContext.DrawRenderers, and pass the structs that you created as parameters. Unity draws the filtered set of geometry, according to the settings. This example code builds on the examples above, and demonstrates how to clear the render target, perform a culling operation, and draw the resulting geometry: /* This is a simplified example of a custom Scriptable Render Pipeline. It demonstrates how a basic render loop works. It shows the clearest workflow, rather than the most efficient runtime performance. */ using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipeline : RenderPipeline { public ExampleRenderPipeline() { } protected override void Render (ScriptableRenderContext context, Camera[] cameras) { // Create and schedule a command to clear the current render target var cmd = new CommandBuffer(); cmd.ClearRenderTarget(true, true, Color.black); context.ExecuteCommandBuffer(cmd); cmd.Release(); // Iterate over all Cameras foreach (Camera camera in cameras) { // Get the culling parameters from the current Camera camera.TryGetCullingParameters(out var cullingParameters); // Use the culling parameters to perform a cull operation, and store the results var cullingResults = context.Cull(ref cullingParameters); // Update the value of built-in shader variables, based on the current Camera context.SetupCameraProperties(camera); // Tell Unity which geometry to draw, based on its LightMode Pass tag value ShaderTagId shaderTagId = new ShaderTagId(\"ExampleLightModeTag\"); // Tell Unity how to sort the geometry, based on the current Camera var sortingSettings = new SortingSettings(camera); // Create a DrawingSettings struct that describes which geometry to draw and how to draw it DrawingSettings drawingSettings = new DrawingSettings(shaderTagId, sortingSettings); // Tell Unity how to filter the culling results, to further specify which geometry to draw // Use FilteringSettings.defaultValue to specify no filtering FilteringSettings filteringSettings = FilteringSettings.defaultValue; // Schedule a command to draw the geometry, based on the settings you have defined context.DrawRenderers(cullingResults, ref drawingSettings, ref filteringSettings); // Schedule a command to draw the Skybox if required if (camera.clearFlags == CameraClearFlags.Skybox && RenderSettings.skybox != null) { context.DrawSkybox(camera); } // Instruct the graphics API to perform all scheduled commands context.Submit(); } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-custom-getting-started.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-custom-getting-started.html",
    "title": "Create a custom render pipeline | Inventory System",
    "summary": "Create a custom render pipeline This page contains information on how to get started with creating your own custom render pipeline based on the Scriptable Render Pipeline (SRP). Creating a new project and installing the packages needed for a custom render pipeline These instructions show you how to create a custom render pipeline using the SRP Core package. SRP Core is a package made by Unity that contains a reusable code to help you make your own render pipeline, including boilerplate code for working with platform-specific graphics APIs, utility functions for common rendering operations, and the shader library that URP and HDRP use. Create a new Unity Project. Use Git to create a clone of the SRP source code repository. You can place the SRP source code in any location on your disk, as long as it is not in one of the reserved Project sub-folders. Use Git to update your copy of the SRP source code to a branch that is compatible with your version of the Unity Editor. Read Using the latest version in the SRP repository documentation for information on branches and versions. Open your Project in Unity, and install the following packages from the SRP source code folder on your disk, in the following order. For information on installing packages from disk, see Installing a package from a local folder. com.unity.render-pipelines.core. Optional: com.unity.render-pipelines.shadergraph. Install this package if you intend to use Shader Graph or modify the Shader Graph source code as part of your custom SRP. Optional: com.unity.render-pipelines.visualeffectgraph. Install this package if you intend to use Visual Effect Graph or modify the Visual Effect Graph source code as part of your custom SRP. You can now debug and modify the scripts in your copy of the SRP source code, and see the results of your changes in your Unity Project. Creating a custom version of URP or HDRP The Universal Render Pipeline (URP) and the High Definition Render Pipeline (HDRP) offer extensive customization options to help you achieve the graphics and performance you need. However, if you want even more control, you can create a custom version of one of these render pipelines, and modify the source code. Follow steps 1-3 in the section above, Creating a new Project and installing the packages needed for a custom SRP. When you reach step 4, install the following packages in the following order: URP: com.unity.render-pipelines.core com.unity.render-pipelines.shadergraph com.unity.render-pipelines.universal HDRP: com.unity.render-pipelines.core com.unity.render-pipelines.shadergraph com.unity.render-pipelines.high-defintion"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-custom.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-custom.html",
    "title": "Creating a custom render pipeline | Inventory System",
    "summary": "Creating a custom render pipeline Unity provides two prebuilt render pipelines based on the Scriptable Render Pipeline (SRP): the High Definition Render Pipeline (HDRP), and the Universal Render Pipeline (URP). HDRP and URP offer extensive customization options; however, if you want even more control over your rendering pipeline, you can create your own custom render pipeline based on SRP. Page Description Create a custom Scriptable Render Pipeline Install the packages needed for a custom render pipeline based on SRP, or create a custom version of URP or HDRP. Create a Render Pipeline Asset and Render Pipeline Instance in a custom render pipeline Create scripts that inherit from RenderPipelineAsset and RenderPipeline, then create a Render Pipeline Asset. Create a simple render loop in the Scriptable Render Pipeline Create a simple loop to clear the render target, perform a culling operation, and draw geometry. Extend a Scriptable Render Pipeline with command buffers or API calls Use the ScriptableRenderContext API to configure and schedule rendering commands. Scriptable Render Pipeline callbacks reference Learn about the callbacks you can use to call your C# code at specific times. Additional resources Render pipelines"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-using-scriptable-render-context.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/srp-using-scriptable-render-context.html",
    "title": "Execute rendering commands in a custom render pipeline | Inventory System",
    "summary": "Execute rendering commands in a custom render pipeline This page explains how to schedule and execute rendering commands in the Scriptable Render Pipeline (SRP)ScriptableRenderPipeline, either by using CommandBuffers or by making direct API calls to the ScriptableRenderContext. The information on this page is applicable to the Universal Render Pipeline (URP), the High Definition Render Pipeline (HDRP), and custom render pipelines that are based on SRP. In SRP, you use C# scripts to configure and schedule rendering commands. You then tell Unity's low-level graphics architecture to execute them, which sends instructions to the graphics API. The main way of doing this is by making API calls to the ScriptableRenderContext, but you can also execute CommandBuffers immediately. Using the ScriptableRenderContext APIs In SRP, the ScriptableRenderContext class acts as an interface between the C# render pipeline code and Unity's low-level graphics code. SRP rendering works using delayed execution; you use the ScriptableRenderContext to build up a list of rendering commands, and then you tell Unity to execute them. Unity's low-level graphics architecture then sends instructions to the graphics API. To schedule rendering commands, you can: Pass CommandBuffers to the ScriptableRenderContext, using ScriptableRenderContext.ExecuteCommandBuffer Make direct API calls to the Scriptable Render Context, such as ScriptableRenderContext.Cull or ScriptableRenderContext.DrawRenderers To tell Unity to perform the commands that you have scheduled, call ScriptableRenderContext.Submit. Note that it does not matter whether you used a CommandBuffer to schedule the command, or whether you scheduled the command by calling an API; Unity schedules all rendering commands on the ScriptableRenderContext in the same way, and does not execute any of them until you call Submit(). This example code demonstrates how to schedule and perform a command to clear the current render target, using a CommandBuffer. using UnityEngine; using UnityEngine.Rendering; public class ExampleRenderPipeline : RenderPipeline { public ExampleRenderPipeline() { } protected override void Render(ScriptableRenderContext context, Camera[] cameras) { // Create and schedule a command to clear the current render target var cmd = new CommandBuffer(); cmd.ClearRenderTarget(true, true, Color.red); context.ExecuteCommandBuffer(cmd); cmd.Release(); // Tell the Scriptable Render Context to tell the graphics API to perform the scheduled commands context.Submit(); } } Executing CommandBuffers immediately You can execute CommandBuffers immediately without using the ScriptableRenderContext, by calling Graphics.ExecuteCommandBuffer. Calls to this API take place outside of the render pipeline. Additional information For more information on commands that you can schedule using CommandBuffers, see CommandBuffers API documentation."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-12.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-12.html",
    "title": "What's new in SRP Core version 12 / Unity 2021.2 | Inventory System",
    "summary": "What's new in SRP Core version 12 / Unity 2021.2 This page contains an overview of new features, improvements, and issues resolved in version 12 of the Core Render Pipeline package, embedded in Unity 2021.2. Improvements RTHandle System and MSAA The RTHandle System no longer requires you to specify the number of MSAA samples at initialization time. This means that you can now set the number of samples on a per texture basis, rather than for the whole system. In practice, this means that the initialization APIs no longer require MSAA related parameters. The Alloc functions have replaced the enableMSAA parameter and enables you to explicitly set the number of samples. New API to disable runtime Rendering Debugger UI It is now possible to disable the Rendering Debugger UI at runtime by using DebugManager.enableRuntimeUI. Added High performance sorting algorithms in CoreUnsafeUtils New high performance sorting algorithms in the CoreUnsafeUtils helper methods. The new sorting algorithms include: RadixSort - ideal for very large lists, more then 512 elements. MergeSort (non recursive) - ideal for mid size lists, less than 512 elements. InsertionSort - ideal for very small lists, less than 32 elements. The sorting algorithms only work on uint elements. They include methods that support standard c# arrays, NativeArray objects or raw pointers. RadixSort and MergeSort require support array data, which can be allocated by the user, or allocated automatically via ref parameter passing. InsertionSort is in-place and does not require support data. These algorithms are compatible with burst kernels when using raw pointers or NativeArray. Currently HDRP utilizes them to sort lights in the CPU lightloop."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-13.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-13.html",
    "title": "What's new in SRP Core version 13 / Unity 2022.1 | Inventory System",
    "summary": "What's new in SRP Core version 13 / Unity 2022.1 This page contains an overview of new features, improvements, and issues resolved in version 13 of the Core Render Pipeline package, embedded in Unity 2022.1. Added AMD Fidelity FX Super Sampling helper API - FSRUtils Introducing new stream lined API for AMD Fidelity FX Super Sampling. The new API is located in the static class FSRUtils and allows scriptable pipelines to have direct access / implement and integrate easilty FSR super sampler. For more information please review the API located in Runtime/Utitilies/FSRUtils.cs"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-17.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new-17.html",
    "title": "What's new in SRP Core version 17 / Unity 6 | Inventory System",
    "summary": "What's new in SRP Core version 17 / Unity 6 This page contains an overview of new features, improvements, and issues resolved in version 17 of the Scriptable Render Pipeline (SRP) Core package, embedded in Unity 6. Improvements Render graph system optimization The render graph system API and compiler are now carefully optimized to reduce their cost on the main CPU thread. To prevent Unity compiling the render graph each frame, there's now a caching system so Unity only compiles when the rendering is different from the previous frame. This means performance on the main CPU thread should be faster, especially in non-development builds. Native Render Pass support in the render graph system The render graph system API now provides automatic Native Render Pass support using the AddRasterRenderPass API. This means Unity can use framebuffer fetch operations on platforms with tile-based GPUs, which improves performance. Native Render Pass support is implemented in the Universal Render Pipeline (URP). For more information, refer to Render graph system in the URP manual. Note: You can't use the AddRasterRenderPass API with the existing AddRenderPass API. Instead, use the new AddComputePass and AddUnsafePass APIs."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/Documentation~/whats-new.html",
    "title": "What's new in SRP Core | Inventory System",
    "summary": "What's new in SRP Core This section contains information about changes to SRP Core. Each page contains a list of new features and, if relevant, a list of improvements and a list of resolved issues. The list of pages is as follows: 12 13 17"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@2be5e7224a10/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.render-pipelines.core copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [17.0.1] - 2023-12-21 This version is compatible with Unity 2023.3.0b2. Version Updated The version number for this package has increased due to a version update of a related graphics package. Started Changelog"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/Documentation~/api_index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/Documentation~/api_index.html",
    "title": "Universal Render Pipeline Configuration package scripting API | Inventory System",
    "summary": "Universal Render Pipeline Configuration package scripting API This is the documentation for the scripting APIs of the Universal Render Pipeline (URP) Configuration package."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/Documentation~/index.html",
    "title": "Universal Render Pipeline Configuration Package | Inventory System",
    "summary": "Universal Render Pipeline Configuration Package The Universal Render Pipeline (URP) uses this package to control the settings of some of its features. If you want to use this package to configure URP, you must link it as a local package. For information on how to set up and use the URP Config package, see URP Config. For documentation on URP itself, see URP documentation."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@dd206bf35d04/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.render-pipelines.universal-config copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [17.0.3] - 2025-02-13 This version is compatible with Unity 6000.0.39f1. Added RenderPipelineManager callbacks are raised from UniversalRenderPipeline.SingleCameraRequest. SetViewAndProjectionMatrices() helper function is available within a RasterRenderPass in RenderGraph. Changed Updated the RenderGraph samples to use the new helper functions to reduce boilerplate code. Changed the URP render pass names for consistency in the RenderGraph viewer, the Profiler, and the frame debugger. Sprite Default Material - Moved to Graphics Settings, Sprite Settings from Renderer2DData. Improve the sample code in the URP Post Processing Effect (with Volume) template to remove a copy render pass. Improved the depth copy scheduling in render graph path to allow copying after skybox rendering to improve pass merging. Enabled foveated rendering for UberPost pass when it is the last pass and FinalPostBlit pass. In the Render Graph Viewer, you can now open the tool when the compatibility mode is enabled. Fixed Fixed the Preview Camera drawing grid that appears on top of preview mesh with URP Render Graph when depth priming is active. Fixed a broken setting related to the Shadow rendering layer that wasn't changing shadow when using shadowRenderingLayers in the script. Fixed Native Render Pass to render RenderTextureDescriptor with the correct dimensions when the render scale is not equal to one. Added a warning the Scene to inform users about light limits. Fixed inconsistent text capitalizations in various parts of the Editor. Fixed an issue with corrupt cookie sampling when targeting mobile platforms. Hide unused Native Render Pass checkbox in UniversalRenderer when using Render Graph. Fixed obsolete API usages in URP samples. Disabled fallback behavior on FSR EASU shader to prevent build errors on machines with old GPUs. Fixed an issue where Shadow maps sometimes leaked when switching between quality levels. Render Pipeline Converter - Built in materials where not found properly the first time the Initialize Converter was called. Fixed visual issues caused by edge cases in alpha clipping logic when MSAA is enabled. Fixed errors when inspecting Universal Renderer assets with URP not as the active pipeline. Fixed an incorrect motion vectors with URP Deferred due to missing camera depth binding. Fixed broken \"Map Overlay\" modes in RenderGraph and aspect ratios in RenderGraph and non-RG paths. Added missing \"Map Overlay\" modes for Motion Vectors and Light Cookie Atlas. Disabled faulty NRP for Editor-only FinalCopyDepth pass in URP 3D. Reduced banding on FSR upscaled render target by changing render target formats. Fixed SRP per-XRPass control to disable FR for intermediate render passes on untethered XR device if renderViewportScale is active when using URP RenderGraph. Fixed an issue where shadows for additional lights would flicker if additional lights exceeded the maximum amount of shadow casting lights. Fixed an issue where shadows for additional lights were incorrectly ordered when using deferred rendering. Fixed an issue where shadows for additional lights were still rendering even though they were disabled in the URP Asset. Fixed a render graph bug where a pass-break between GBuffer and deferred lighting would cause an error. Made the gBuffer components non-global. Fixed render graph allocated textures not respecting dynamic scaling settings in some cases. Fixed render graph scheduling logic for CopyDepth pass when custom passes that read depth are present. Added warning box in the camera inspector when both TAA and MSAA is enabled to notify the user that TAA will be skiped with current settings. Fixed custom pass order in URP RenderGraph injected at AfterRenderingSkybox/BeforeRenderingTransparents. Fixed an issue where if the profiling sampler of a render graph pass is null, use an empty string instead of the name of the profiling sampler. Fixed an issue where multiview support for the XR Occlusion Mesh pass was missing. Fixed an issue where Shadow Near Plane on Spot Lights was incorrectly culling shadow casters. Fixed an issue with enabling instancing at runtime for a Decal material. Fixed the yflip issue when depth texture is required and color texture is not required in RenderGraph compatibility mode. Fixed CopyDepthPass setup causing Vulkan validation errors under specific circumstances. Fixed ScriptableRenderPass.profilerSampler being null in Compatibility mode. This will now only be null in release (non-dev) when using RenderGraph. This nullification was done previously as a small performance optimization. Fixed BlitAndSwapColorPass sample. Fixed an issue where reflection probes would render incorrectly on some platforms. Updated template (Create > Rendering > URP Post-Processing Effect (Renderer Feature with Volume). Fixed a shader compilation error on Apple platforms without Metal. Fixed an issue with the Inspector of Render2DData when selecting custom default material. Fixed URP Lens Flare with scaled pixelRect. Fixed an incorrect depth copy scheduling in deferred path when render graph was enabled. Fixed an issue by avoiding overwriting the cameraDepthTexture handle with gbuffer4 in deferred render graph path. Fixed an issue where glClientWaitSync: Expected application to have kicked everything until job: 96089 (possibly by calling glFlush)\" are thrown in the Android Player on some devices with PowerVR Rogue GE8320 GPU. Fixed an issue where Directional Light Shadows rendered incorrectly at close distance. Removed msaa sample count mismatch warning at first frame in IOS player. Fixed shadow-map sampling artifacts present when using the Unlit DrawMode in the SceneView. Fixed URP Full Screen Render Feature with RenderGraph to limit the use of global resources and improve memory usage. Fixed XR isLastCamera check. Fixed an issue with XRCopyDepth not working when running in RenderGraph. Fixed Forward+ always blending reflection probes regardless of setting. Fixed an issue where Color Lookup caused GC.Alloc every frame. Fixed camera offset in the UI editor for the RenderObject RenderFeature. Fixed an issue where lights would leak through objects when using Point Lights. Fixed an issue where Shader Prefiltering data wasn't updated properly for Asset Bundles. Fixed a RenderGraph issue where Invalid Depth format errors appeared when pressing CTRL in scene view. Fixed an issue scene-view wireframe rendering when using depth-priming. Fixed some shader warnings in builds. Fixed camera gizmos frustum that was not rendered correctly in the presence of a monobehaviour containing an OnGUI method. Fixed an issue where URP RawDepthHistory buffer created an unnecessary color resource, leading to unnecessary GPU memory usage. Fixed an issue to prevent repetitive error logs about C-buffer layout mispatch in GPU-instancing-enabled Speed Tree materials when enabling Rendering Layers. Enabled Native RenderPass option to follow Universal Renderer Data when rendering Game view. Fixed an issue with a missing depth prepass in deferred render graph path. Modified the scheduling of a motion vector pass in render graph path in order to ensure motion and depth data are always available together. Fixed an issue in RenderGraph where an extra copy was made of the Main and Additional light shadow textures. Fixed an issue with the depthStencil format for the _CameraDepthAttachment and the _CameraDepthTexture resource so they are now correctly set by the format settings on the Renderer asset. Fixed SpeedTree8 ShaderLab shader issue. Fixed render graph global textures persisting after graph execution. Fixed an issue in URP Forward Plus lighting where extra tiles were being incorrectly masked to be lit by spot lights that did not in fact affect them. Fixed camera stacking rendering to system backbuffer with Render Graph on iOS/macOS. Fixed an issue where shadows were rendering incorrectly when light sources were placed near shadow casting objects. Fixed the use of a potentially uninitialized variable warning in Core2D issue. Added shader stripping logic for STP to avoid URP project build failures when targeting Windows from a non-Windows platform. Updated RenderGraph samples (install through Package Manager) to the latest APIs and best practices. Fixed compile error in the lighting debug views when using APV with Shadowmask. Fixed missing geometry on Adreno GPUs by disabling GPU occlusion culling as a workaround. Removed usage of legacy depthBufferBits on RenderTextureDescriptor in URP 2D and 3D renderers to fix issues with incorrect depth stencil format for render textures. Fixed TAA frame index mismatch which was causing incorrect visuals when the camera history reset system was used with STP. Fixed the depth bias for motion vectors that was causing objects to leak through geometry. Fixed invalid viewport for post-process when using camera stacking with render scale. Fixed invalid alpha output for scaling setup shader when using camera stacking with render scale on URP compatibility path. Fixed incorrectly bright pixels by clamping alpha after additive blending to 0-1 range in post-processing when using camera stacking with render scale. Fixed black pixels (NaN) in Lens Distort post-processing effect. Fixed post-process FSR upscaling and _ScreenParams for stacked Overlay cameras. Remove \"AssertionException The RenderTextureDescriptor used to create a TextureDesc contains both graphicsFormat and depthStencilFormat\". Fixed spamming errors and broken visual when resizing GameView with Free Aspect in DepthBlit sample. Fixed an issue where WorldToCamera matrix wasn't set before rendering shadows. Fixed a redundant empty line in a tooltip for Cast Shadows toggle in the URP Asset for Additional lights. Fixed issue with spot light clipping incorrectly in URP Forward+. Remove 'implicit truncation of vector type' warnings at URP ScreenSpaceAmbientOcclusion.shader. Fixed an issue where Game View would flip upside down when using HDR Debug Mode. Fixed an issue with warning (Missing types referenced from component UniversalRenderPipelineGlobalSettings...) caused by URP Template project on platforms where ENABLE_VR is not defined. Fixed an issue where Transparent Receive Shadows setting didn't work for custom shaders. Fixed depth texture format used for URP 2D RenderPass with Android devices. Fixed the CameraDepthAttachment turning black for DX11. Fixed an issue by modifing final depth copy logic to read from depth attachment instead of depth texture to avoid errors when depth texture isn't available. Fixed sorting the Reflection Probe by resolution. Fixed an issue by adding SS Shadow coord transform to TransformWorldToShadowCoord. Fixed issue with URP lights where the Culling Mask property was ignored for shadow casters when using the GPU Resident Drawer. Fixed an issue where creating a light and undoing displayed a warning in the console. Fixed an issue where the shadow strength setting on lights did not work with shadow masks. Fixed an issue where SoftShadowsHigh global shader keyword is not initialized properly. Fixed an issue with aliased shadows when using medium or high soft shadow setting. Fixed an issue where variants were being stripped out in Scriptable Stripping when \"Strip Unused Variants\" was disabled. Fixed URP RenderGraph case with MSAA and camera stacking on Windows Player. Fixed an issue where undoing GameObject creation didn't work when the GameObject was focused. Fixed unclear error message while updating volume stack before Universal Render Pipeline is created. Fixed depth texture format exception when pressing the Ctrl key in the scene view with URP. Fixed light cookie texture memory leak when entering Playmode. Fixed an issue where blending DBuffer decal normals could causes NaNs. [17.0.2] - 2024-04-02 This version is compatible with Unity 6000.0.0b15. Changed SSAO CPU optimization. Many RasterPass into single UnsafePass. The Auto option in SH Evaluation Mode, in the URP Asset, now chooses Per Vertex instead of Per Pixel on mobile and similar devices. Bloom shader variants are now stripped per feature (LQ, LQ Dirt, HQ, HQ Dirt). Exposed additional depth formats for CameraDepthAttachment and CameraDepthTexture (URP). Improved MSL generation for Foveated Rendering. Fixed Fixed an issue where an obsolete attribute from EnqueuePass API was not removed. Fixed bright pixels when using a camera with skybox and MSAA rendering opaque objects with alpha clipping together with a transparent object if additive blending. Fixed an issue where Evaluate SH and SoftShadow keywords were incorrectly declared in ShaderGraph shaders. Fixed an \"undeclared identifier 'RemapFoveatedRenderingNonUniformToLimear\" in ShaderPassDecal.hlsl(252). Fixed an issue where LOD Crossfade was declared twice in Unlit ShaderGraph. Fixed an \"Implicit truncation of vector type\" warning in ShaderPassDecal.hlsl(221). Fixed an \"Output value 'fragmentOutput' is not completely initialized\" warning in ShaderPassDecal.hlsl(179). Fixed an error in Bloom.shader for foveated when the debug check is enabled inside FoveatedRendering.hlsl. Fixed an \"floating point division by zero\" warning in Shadows.hlsl(189) Fixed incorrect alpha-clip behavior on transparent surfaces. Fixed an issue where downsampled SSAO had serious artefacts on Android. RenderGraph: Removed unnecessary clear passes of the bloom pyramid render targets. Fixed an issue where NullReferenceExceptions appeared when switching between Quality Levels with Post Processing Volume Update mode set to ViaScripting. Fixed early return for renderer features which required color when color didn't exist for depth only output texture. Fixed NativeRenderPass store action. Fixed an issue where debug variants of the \"TerrainDetailLit\" shader would not compile. Fixed Skipped RenderObjects when rendering preview cameras. Fixed the FinalPostPass executing before \"AfterRenderingPostProcessing\" instead of after it. Fixed an issue where cameras flickered when using deferred rendering, rendering layers and two cameras. Fixed bloom shader not working with non uniform rasterisation based foveated rendering on VR platforms that support it. Added logic to enforce consistent hardware dynamic resolution settings during rendering to avoid issues when external code changes the global setting. Fixed incorrect viewport size adjustment logic in CopyDepthPass that caused issues when dynamic resolution was active. Correctly handle missing motion vectors for TAA. Fixes black screen on the 2D renderer when TAA is enabled. Reduce the number of active unique samplers by using shareable inline samplers for most of the URP internal textures and buffers. Helps to avoid hitting the graphics API limit in URP Lit or custom shaders. Fixed a warning in Lens flare shader for URP. Fixed errors when calling RTHandles.Alloc() inside ScriptableRendererFeature.Create(). Fixed Depth of Field for URP RenderGraph. Added UI features to encourage the use of Rendering Layers in URP to control selective lighting, instead of using culling mask. The former works across Deferred, Forward and Forward+, while the latter only works with Forward. Fixed an issue where keywords were incorrectly enabled/disabled when shadows were enabled in the URP Asset and \"Transparent Receive Shadows\" was disabled on the renderer. Fixed an issue to ensure motion vector depth buffer is valid for cameras with motion vectors enabled. Fixed an issue where using Alpha Clipped shaders and Depth Priming resulted in invisible objects. Fixed reflection probes are now sorted correctly for Forward+. Fixed an issue where SSAO didn't use the correct check for rendering mode. Disabled depth priming for cameras with depth-only render targets. Fixed an issue where Render Graph Viewer display did not display a user-friendly camera name. Fixed an issue with ScreenCaptureBridge under URP RenderGraph. Fixed an issue where an incorrect WorldToCamera matrix was used in the main and additional light shadow passes. Fixed an SRP Lens Flare rendering issue with Render Scale. Restore EditorGUIUtility.labelWidth to default after drawing MaterialHeaderScopes Add missing curve override indicator text to Color Curves volume component editor Fixed an issue where logging an error gave a NullReferenceException for Server Builds. Fixed false-negative missing RendererFeatures errors. Motion Vector pass can now render after opaques. It correctly follows its depth dependency in pass order. Fixed an issue where screen space decals wouldn't respect light cookies. Fixed an issue where using the \"Accurate G-buffer Normals\" feature for deferred rendering on mobile platforms would cause a large amount of artifacts. Scriptable TAA settings. Fixed XROcclusionMesh.shader and XRMirrorView.shader are not stripped down when XR Plugin is not installed [17.0.1] - 2023-12-21 This version is compatible with Unity 2023.3.0b2. Added Added RG path only function for AddRenderPasses using ContextContainer instead of RenderingData Exposed opaqueLayerMask and transparentLayerMask in UniversalRenderingData. Changed Added per renderer filtering for renderer features. Moved the RenderObjects renderer feature out of Experimental namespace. Added checks to avoid building shadow atlases, adjusting shadow resolution, calculating rendering layers, etc when features are disabled. Improved stripping logic for Accurate G-buffer normals when using Deferred rendering on Vulkan. Improved performance for AdditionalLightShadowCasterPass and BuildAdditionalLightsShadowAtlasLayout Improved performance for Deferred Rendering when using many lights. Improved performance when creating shadow data. Improved runtime performance by adding checks for _ALPHATEST_ON when rendering depth, shadows, and depth normals. New Renderer Feature updated with Render Graph code. Enabled renderViewportScale for XR intermediate textures. Updated NewRendererFeature Template. Enabled APV Disk Streaming in URP. Disable implicit use of all globals in URP passes Bloom post processing effect CPU optimization. Many RasterPass into single UnsafePass. Fixed Fixed scene elements not being sorted correctly when RenderGraph is enabled on M1/M2 Mac. Fixed scene wireframe mode when RenderGraph is enabled. Fix partially corrupted Android screen when Vulkan display rotation during rendering is enabled Fixed Color Grading Mode set to Low Dynamic Range on one camera in the stack despite HDR output active. Fixed blackscreen and NullReferenceException when using wireframe. Fixed an issue where some segements and corners of sprite shape shadows may not have been properly rendered. Fixed FRAMEBUFFER_INPUT redefinition warnings when compiling some shaders Fixed shadow flickering when using Screen Space shadows and have depth priming enabled. Fixed an issue where the RenderGraph CopyDepth pass injection point location now matches the non-RenderGraph path. Fixed Rendering Debugger issues when RenderGraph is enabled. Fixed an issue where NativeRenderPass was not disabled when RenderGraph is enabled on editor GLES. Fixed an issue where building a project using deferred with batchmode and nographics resulted in incorrect variant stripping. Fixed an issue where Unlit shaders would not output correct normals when using deferred and Accurate GBuffer Normals. Fixed an issue causing decals to be culled erroneously when using the Screen Space technique Fix VRR performance regression Fixed HDR Debug Views rendering a black screen with Render Graph. Fixed HDR Debug Views break the native render pass when enabled once. Added a test scene in URP's Foundation project for UseBufferRandomAccess and UseTextureRandomAccess. URP Renderer Features are now ignored if they are color dependent and drawing to an offscreen depth camera target. Disabled Motion Blur effect in EditMode to keep the game view clear while editing. Motion Blur works as before in PlayMode and standalone builds. Fixed an issue where _AmbientOcclusionParam wasn't updated correctly in RenderGraph. Fixed compile error in some shaders when Lightmapping and APV are used at the same time Fixed broken scene view depth. Fixed DefaultVolumeEditor assert when multiple inspectors are open. Fixed y-flip issues on GL platforms. Fixed GLES color grading banding artifacts and MSAA resolve surface errors. Fixed an issue where Light Layers did not check scene lighting setting when enabling the keyword. Fixed an issue where RenderGraph didn't enable the Panini Projection keyword correctly. Use local random state for post-processing. Fixed SH vertex evaluation mode in URPLit shader graph. Fixed an issue where Screen Space Decals keyword was missing when Strip Unused Variants was turned off. RenderGraph: Fixed an issue with YFlip on some platforms. RenderGraph: Fixed an issue where an incorrect texture was used when using Empty Additional Shadow path. Fixed an issue where screen space decals would not calculate ambient lighting correctly. The Fullscreen Render Feature doesn't cause rendering layers to run in the depth normals prepass anymore. Fixed the NativeRenderPass camera target MSAA logic to match the non-NRP path. Fixed an issue where the \"Sprite-Lit-Default\" did not function with certain debug views. Making sure the new renderer feature template sets up a render target Fixed an issue with offscreen depth when using RenderGraph. Fix Animation Preview artifacts Fix UniversalRendererResources settings getting incorrectly stripped from player builds Fix URP post-processing script template potentially trying to sample the backbuffer (not forcing intermediate texture rendering) Fix redundant pipeline recreate when opening Graphics settings Fix depth buffer disappearing after using SwapColorBuffer Fixed an issue where renderer features didn't pass validation if they inherit from another renderer feature. Fixed an issue where disabling SSAO feature didn't work in built projects when the SSAO disabled keyword had been stripped out. Fixed an issue where decals were not affecting grass when using Deferred Rendering. Y-flip for reflection probe atlas lookup is now handled correctly for OpenGL and GLES3 Fixed an issue where screen would in some cases be dark when using Decals and SSAO in RenderGraph Removed Mark non-rendergraph APIs as obsolete. [17.0.0] - 2023-09-26 This version is compatible with Unity 2023.3.0a8. Added Made Main Light Shadow Resolution and Additional Light Shadow Resolution settings public in the URP Asset. Made the cascade split settings public in the URP Asset. ContextContainer items used as frame data for UniversalRenderer and Renderer2D e.g. UniversalLightData & UniversalCameraData. Changed Enabled APV Lighting Scenario Baking in URP. Fixed Disabled Soft Shadow Quality per-light levels on Quest and HoloLens platforms to improve XR performance. Global Settings always exist when URP is the current active pipeline. Added depth and stencil operations to FullScreenPassRendererFeature and allowed users to opt-out of depth-stencil being bound per feature in the \"Additional Properties\" section. Fixed FullScreenPassRendererFeature only using the material of the last full screen feature in a frame, this allows multiple passes to work correctly within one frame. Fixed ArgumentNullException when trying to use a FullScreenPassRenderer feature with \"None\" in the requirements mask with Render Graph. Fixed missing \"_BlitScaleBias\" upload for text shaders using the CoreRP Blit.hlsl header. Fixed an issue where additional lights were not rendering correctly when using a mix of shadow settings in deferred. Fixed an issue where Shader ID's weren't reset properly in the DepthNormals pass. Fixed an issue where IndexOutOfRangeException was thrown when creating a stacked camera from script. Fixed an issue where NullReferenceException was thrown when camera prefab referenced a camera outside the prefab in the camera stack. Fixed an issue with Screen Space Decals where dark artefacts appeared in the editor. Fixed an issue where SSAO would not apply to a scene when using the Deferred Rendering Path and with no Directional light active. Fixed an issue causing 'implicit truncation of vector type' warning when using ShaderGraph shaders in the Forward+ Rendering Path Fixed noise and flicker caused by TAA when the Very High option is in use. Fixed memory leak from render texture when rtHandle realloc failed to be added to pool. Fixed an issue where Rendering Layers didn't work properly when opening a project. Fixed shader stripping when using APV. Add GBuffer (fill) passes to ComplexLit and Unlit shader to prevent GBuffer data holes. Fixed HDR output persisting even if the user explicitly turned it off. Fixed an issue where it wasn't possible to add a Renderer Feature on a renderer if another feature had a missing or broken script. This issue impacted the Universal Render Pipeline. Fixed an issue where reflection probes were not updating correctly when using Forward+. Fixed transparent materials getting marked as dirty during material UI updates and project saving. Fixed IndexOutOfRangeException error when using Native RenderPass on Deferred. Fixed scene elements not being sorted correctly when RenderGraph is enabled on OS. Fixed the URP Debug Rendering map overlays when RenderGraph is enabled. Fixed visible outline when composited ShadowCaster2Ds with transparency overlap Fixed missing padding at the bottom of URP's Global Settings Fixed an issue where selecting a stacked camera caused the editor to freeze and sometimes crash. Fix Overdraw and Wireframe debugger views not rendering correctly [16.0.3] - 2023-07-04 This version is compatible with Unity 2023.3.0a1. Changed Stripping or IRenderPipelineGraphicsSettings. Fixed Fixed an issue where rendering layers keywords were not enabled correctly when using Decals & SSAO in Deferred. Fixed an issue where incorrect Shader Keyword Prefiltering was used with SSAO when AfterOpaque was used. [16.0.2] - 2023-06-28 This version is compatible with Unity 2023.2.0a22. Changed Improved URP main thread usage in XR. Fixed Added workarounds for MSAA-specific visual artifacts on materials that use alpha clipping in unexpected ways. Fixed an issue where changing RenderSettings before camera rendering would not always take effect. Fixed null exceptions when ShadowCaster2D are included as part of a prefab. Fixed an issue where assets were incorrectly being saved when making builds. Added a missing G-buffer normal decoding for the URP Sample Buffer node in Fullscreen shadergraphs when using Accurate G-buffer normals in the deferred renderer. Note: The decoded normal values for background pixels are undefined. Fixed the Color Grading LUT not updating when enabling or disabling Render Graph repeatedly. Fixed Screen space Overlay UI rendered at the wrong size for scaling mode \"Constant Pixel Size\" or \"Constant Physical Size\", when HDR output is active. Updated the documentation to mention that the Screen Space decal technique does not support blending of normals when using the Deferred rendering path with Accurate G-Buffer Normals enabled. The Automatic decal technique now prefers the D-Buffer technique if Accurate G-Buffer Normals are enabled. changed the PostPro passes injection points to more correct locations. 2D - Fix additional draw call when Foremost Sorting Layer is enabled during unlit [16.0.1] - 2023-05-23 This version is compatible with Unity 2023.2.0a17. Added Added XR occlusionMesh scaling, occlusionMesh enable/disable, mirroView mode setter for SRP XR. Changed Enabled deferred renderer to now use Framebuffer Fetch for Shadowmask. Added HDR Output override per camera. Fixed Fixed errors caused by Camera's Preview window. Fixed the Screen flicker in Scene view. Fixed the broken links to documentation for volume components. Fixed Native RenderPass errors when using RendererFeature which is executed in between GBuffer and Deferred Lighting passes. Disabled MSAA on devices without MSAA store support (Apple GPUs A8 and lower). Fixed URP and core package leaking materials when entering and exiting Play Mode. Fixed removal of missing renderer feature. Fixed error message in filtered view when decals are enabled. Fixed missing y-flip for preview cameras. Increased lighting BRDF specular max for half float math (mobile) to match the visual look of full float math (desktop) better. Fixed rendering on HDR displays with the 2D renderer or the Universal renderer and no post processing. Fixed redundant blit is used due to postFX, although it is disabled in rendererData. Fixed volume and volume profile help URLs. Fixed HDR output so it is no longer too saturated when HDR rendering is disabled on the camera. Fixed incorrect MSAA sample count when using Deferred renderer and rendering to a target texture. Fixed ShaderGraph preview window displaying a blank window when using DepthNormals pass. Fixed HDR output from being too saturated by default when a camera doesn't have the additional camera data yet. Fixed an issue where the ShadowShape2DProvider_Collider would improperly track a collider using a Rigidbody2D. Enabled passes injected in RenderPassEvent.AfterRenderingPostProcessing to now execute before final blit and post-processing anti-aliasing effects rather than after, when using the Render Graph. Fixed HDR Debug Views without antialiasing, with Render Graph and with passes injected in RenderPassEvent.AfterRenderingPostProcessing. Enabled stripping BlitHDROverlay from build if HDR output is not allowed and stripping unused shader is allowed. Fixed an issue with reference images for Decal tests and lowered the threshold to catch issues better. Fixed an issue where using the Reflection Probe Node with the Forward+ rendering path would result in flickering on the object. Removed serialization and cache vertices and indices for sprite lights causing bloat in prefabs for 2D. Fixed TAA resource leak on entering or exiting the playmode. Changed the ScreenSpace Decals sorting criteria to None to fix flickering issues. Remove URP motion vector fallback shader. This fixes major TAA jittering and blurring artefacts with decals. Custom shader writers can still add ' UsePass \"Hidden/Universal Render Pipeline/ObjectMotionVectorFallback/MOTIONVECTORS\" ' to their shaders to use the fallback pass Remove URP motion vector fallback shader. This fixes major TAA jittering and blurring artefacts with terrain meshes (when they're offset from the origin). Custom shader writers can still add ' UsePass \"Hidden/Universal Render Pipeline/ObjectMotionVectorFallback/MOTIONVECTORS\" ' to their shaders to use the fallback pass Remove URP motion vector fallback shader. This fixes major TAA jittering and blurring artefacts on and around opaque shuriken particles when the emitter is moving. Custom shader writers can still add ' UsePass \"Hidden/Universal Render Pipeline/ObjectMotionVectorFallback/MOTIONVECTORS\" ' to their shaders to use the fallback pass [16.0.0] - 2023-03-22 This version is compatible with Unity 2023.2.0a9. Changed Disabled the ability for decals to enqueue passes when running on unsupported APIs, such as OpenGL or GLES3, instead of displaying the magenta error. Added sampling clamping functions to prevent out of viewport sampling in URP. Fixed Fixed an issue where scenes were not marked dirty after changing the volume update setting on cameras. Corrected the render scale value when rendering scene view. Fixed SMAA so it now works properly on mobile when Use defaults for sampler precision is selected as the Shader precision model in Project Settings. Fixed an issue causing Dynamic Resolution to be disabled during URP rendering. Fixed the 2D Sprite Light & Freeform Light fast normal map quality setting to correctly use the normal map. Fixed an issue where some sprites were causing null exception errors. Fixed a missing keyword in ParticlesSimpleLit for Lightmap shadow mixing. Fixed the debug rendering overlay not being rendered when FinalBlit pass is in use. Fixed light batching with Rendergraph2D passes. Fixed NullReferenceException being thrown when opening Light Explorer with 2D Lights. Fixed camera stacking causing a blackscreen and RG null pointer exception error. Fixed the warnings that appear in GlobalIllumination.hlsl regarding gradient instruction used in a loop. Fixed an issue where keywords used in Post Processing were also stripped in other shaders. Fixed various errors that appeared when Strict Variant Matching is enabled. Fixed an issue so that deferred rendering now works correctly in builds with Accurate GBuffer Normals enabled. Fixed an issue where the main light shadows were incorrect if the scene and game windows were open. Fixed an issue where instantiating and destroying cameras, with Volume Update Mode set to ViaScripting, would allocate each time. Fixed the HDR output so it is no longer overly saturated because of a Color Grading variant not included in builds. Fixed the additional light shadows and soft shadows missing on transparent lit objects when using the deferred renderer. Fixed an issue where the Depth Priming check was accidentally removed, which caused CI failures. Fixed an issue where Write Rendering Layers was sometimes incorrectly enabled in Deferred Rendering. Fixed the missing LOD-CrossFade and Alpha-Clip support in URP's motion vector pass. Fixed the offscreen depth pass in the RenderGraph path. Changed the ScreenSpace Decals sorting criteria to the same criteria used by DBuffer Decals. Fixed an issue where alpha clipping was not working with Unlit shader's DepthNormal pass. Disabled negative color and NaN write to TAA history. Fixed gbuffer resource leak in URP deferred. Fixed LOD crossfade when rendering with BatchRendererGroup. Added vertex SH option to URP rendering and fixed HL2 forward light perf regression. Fixed releasing releasing unnecessary Render Targets when using multiple cameras with different Renderer Assets. Fixed a null exception when adding a sorting layer. Fixed color and depth mismatch when scaling is on. 2D - Fix uninitialized SpriteProps in CanvasRenderer [15.0.3] - 2022-12-02 This version is compatible with Unity 2023.2.0a1. Changed Improved shadow atlas building performance when there are a lot of lights. Deprecated ScriptableRenderPipelineExtensionAttributeand LightingExplorerExtensionAttribute. Removed support for GLES2.0 and WebGL1.0. Disabled HDRP Global Settings when HDRP is not active. Removed shader parameters used by additional lights when additional lights are disabled in URP Assets. Added Shader Keyword Prefiltering for LOD Crossfade. Improved the stability and robustness of the Lens Flare Screen Space effect. Fixed Fixed an issue where a ParticlesUnlit.mat warning appeared when creating a new material. Fixed High Dynamic Range Grading Mode variants getting needlessly stripped when Strip Unused Post Processing Variants was selected (even though it's not a volume feature and is part of the UPR asset). Fixed an issue in deferred rendering mode where the Material inspector would log errors about color and depth dimensions not matching. Fixed decals for foveated rendering. Fixed artifacts that could appear in _MotionVectorTexture for some platforms. Released render targets of non-used renderers. Fixed post-process effects in scene view shaded mode. Fixed an issue with slower build-times caused by large Additional Light Shadows arrays in URP Shaders. Fixed ComplexLit mixed lighting by matching ComplexLit shader keywords with the Lit shader. Fixed an issue causing materials using Shader Graphs with material override to disappear when using the Deferred rendering path if alpha clipping is enabled in the material. Enabled Global Settings to always upgrade when opening an old URP project. Fixed a missing keyword in ParticleLit for Lightmap shadow mixing. Enabled RenderObjects Render Features to now render correctly when injected after rendering. Fixed an issue causing GPU hangs when using Forward+ for the default renderer while using Forward or Deferred for the active camera renderer. Fixed 2D game view flickering when using URP Pixel Perfect and Cinemachine Pixel Perfect Extension. Fixed an issue where the Universal Renderer could incorrectly clear the render target during the forward opaques pass even if the render target contains valid rendering data produced by a pass that ran before opaque rendering. [15.0.2] - 2022-11-04 This version is compatible with Unity 2023.1.0a23. Added Added Clearing of Multi Render Targets in RenderingCommandBuffer. Changed Improved the name for Dynamic Resolution property. Light soft shadow quality setting in URPAsset which lights use by default. Per light override is still possible. Messages regarding reducing resolution for additional punctual lights are now only displayed in debug builds. Removed Volume Update Mode from Additional Settings. Improved visual quality of FXAA so it no longer introduces structured noise and blurring. Performance should be mostly unchanged. Removed the remaining obsolete usages of render targets to use RTHandles properly. Replaced CustomEditorForRenderPipeline and VolumeComponentMenuForRenderPipeline with separate attributes. Disabled support for using Depth32Stencil8 format on Android due to crashes. Fixed Added force depth prepass option when requesting the Depth Texture. Fixed memory leak issue in URP deferred when resizing preview camera window. Fixed an issue that the Shaders now correctly fallback to error shader. Fixed decals to produce correct world to tangent matrix. Fixed decals to pass correct viewDirectionWS to screen space and gbuffer lighting. Fixed instacing error when decals loaded, but not the decal shaders. Fixed issue where selecting the URP asset could break HDRP blitter when HDRP is the active pipeline. Fixed soft shadow filtering quality when using large empty shadow atlas. Use allocated atlas size instead of requested size. Display Stats is now always shown in the first position on the Rendering Debugger. Fixed an issue and OnMouseOver now works with camera stacking. Fixed light banding artifacts on normal maps. Disabled depth priming on GLES when MSAA is enabled. Disabled depth priming when baking reflection probes. Fixed incorrect blit material set during Pixel Perfect Upscale pass. Set default contribution to 0 for ColorLookup VolumeComponent, which makes the interpolation with the implicit default global volume behave as expected. Fixed graphics stereo tests. Fixed for BatchRendererGroup global SH values and the URP unity_ProbesOcclusion that use float16 on iOS, which caused rendering problems. Fixed a resource leak when switching between scenes with different pipeline assets. Fixed the TerrainLit shader so that mixed light baking now works with shadow mask. Fixed lens flare position and occlusion for all OpenGL APIs. Added missing URL links to decal projector and 2D shadow casters. Fixed a case where TAA was flickering in XR. Fixed rare iOS shader building failure due to URP Lit Forward Pass shader varyings struct variable mismatch. Fixed SSAO in rendergraph on the SetSourceSize call. Fixed SSAO in URP when using non-uniform rendering. Fixed render scale with SMAA. Fixed Full Screen Pass functionality when used with XR. Removed Obsoleted ClipType, PolyType, PolyFillType, JoinType, and EndType enums from clipper. [15.0.1] - 2022-08-04 This version is compatible with Unity 2023.1.0a19. Added UniversalRenderPipeline.SingleCameraRequest. Use this as the RequestData parameter in SubmitRenderRequest to render a single camera. Added light cookies stripping. Exposed xrPass to public so that URP users could leverage Core XRSystem API to script XR rendering. Changed Tooltips improvement. Foveated Rendering is now integrated in URP for supported platforms. Improved motion vector pass. It should now use the same matrices as the Lit shader. Fixed Fixed Post Processing disabling MSAA on swapbuffer when it's needed. Fixed URP 2D - Fix Light2D upgrading issue with m_AlphaBlendOnOverlap property. Fixed an issue where camera UI inspector's clearFlag was not respected. Fixed a Gizmo and grid artifact in the editor view. Fixed an issue where the material upgrader was showing up when the URP package was being installed. Fixed Gizmos in Game View when using Viewports. Fixed SpeedTree Shadergraph causes errors spammed in console. Fixed specular highlight edges on Android. Fixed depth pre-pass being always executed on GLES devices. Fixed incorrect light brightness when using SimpleLit shader. Fixed a wireframe view issue in URP. Fixed an issue with 2D Spot Light artifacts in light. Fixed alpha discard on Unlit Sprite targets for Shadergraph. Removed RenderSingleCamera is now obsolete. Please use RenderPipeline.SubmitRenderRequest with RequestData of the SingleCameraRequest type. Graphics: Camera.SubmitRenderRequests is now obsolete. Please use RenderPipeline.SubmitRenderRequest with RequestData of a supported type such as RenderPipeline.StandardRequest. [15.0.0] - 2022-06-13 This version is compatible with Unity 2023.1.0a6. Added All pre-built URP shaders and URP Shader Graph shaders now support the Mesh LOD cross-fade. Use the UniversalRenderPipelineAsset.lodCrossFadeDitheringType property to select the type of the cross-fade. Add Alpha Clipping to shadergraph options for Sprite sub targets. Added Screen Coordinates Override feature. Adapted post effects to support Screen Coordinates Override. (Used, for example, to support Cluster Display.) Changed Changed the samples field to a dropdown: High (12 samples), Medium (8 samples) and Low (4 samples). Changed the the final After Opaque passes to be merged with the last blur pass. Downsampling will now not only affect the AO pass but also the blur passes. Improved Depth test to avoid incorrectly adding AO in places where two objects are far away from one another. Changed light and decal layers to rendering layers. Adapted URP to use Blitter interface for full screen draws. Removed DRAW_PROCEDURAL variant for shaders. Factored out full screen blits to utility function. Updated terrain SSAO tests for DX11 and DX12 by using the reference images from Vulkan. Improved edge quality for alpha-clipped materials when multisampling is used in URP. Reduced the number of memcpy operations from NativeArray access in URP for performance. Added tooltips for upscaling filters. Added Screen space for the Transform node. Integrated Foveated Rendering into URP for supported platforms. SSAO: The samples field has been changed to a dropdown: High (12 samples), Medium (8 samples) and Low (4 samples). SSAO: The final After Opaque passes have now been merged with the last blur pass. SSAO: Downsampling will now not only affect the AO pass but also the blur passes. SSAO: Depth test improved to avoid incorrectly adding AO in places where two objects are far away from one another. Moved Volume Update Mode out of Additional Settings. Avoid using Depth32Stencil8 format on Android. Fixed Fixed spot light distance attenuation artefact on some platforms due to fp16 precision issue. Fixed RenderGraph GBuffer pass not rendering. Fixed URP 2D - vertex color for sprite shapes. Fixed URP 2D - incorrect output when post process is enabled. Fixed so objects don't disappear when using Depth Priming and Rendering Debugger. Improved fallback to single shadow cascade on GLES2. Fixed materials that use Autodesk Interactive shader to convert correctly. Fixed a shader compilation error on certain platforms. (URP-1415). Fixed incorrect output when post process is enabled in URP 2D. Fixed vertex color for sprite shapes in URP 2D. Fixed Light2D upgrading issue with m_AlphaBlendOnOverlap property. Fixed Gizmo and grid artifact in editor view URP: Fixed SSAO being flipped in after opaque. URP: Fixed Decals being flipped. Fixed an issue with Depth Priming when executing the DepthNormals prepass with MSAA on. Fixed 2D Spot Light artifacts in light. Fixed additional light perf regression on Quest. Fixed excessive banding from FSR in URP. Fixed decals correctly handle last batch. Fixed decal msaa error then camera is selected in deferred rendering path. Fixed render scale correctly work with screen size property. This includes decals. Fixed decal screen space to work without intermediate texture and DBuffer to force using intermediate texture. Fixed wireframe view in URP (UUM-2548). 2D - Fixed incorrect blit material set during Pixel Perfect Upscale pass. Fixed missing Depth Copy texture in Scene view. Fixed an issue in deferred rendering mode where the Material inspector would log errors about color and depth dimensions not matching. Fixed an issue where a ParticlesUnlit.mat warning appeared when creating a new material. [14.0.3] - 2021-05-09 This version is compatible with Unity 2022.2.0a14. Added Soft Shadows filtering quality as per light option. Low, PCF 3x3 pixel area with fixed offsets which is recommended for mobile. Medium, Tent 5x5 pixel area as the default. High, Tent 7x7 pixel area. Default DOTS compatible loading shader (FallbackLoading.shader). #pragma editor_sync_compilation directive to FallbackError.shader. CommandBuffer variable to RenderingData struct and switched all of the renderer to use that buffer instead of creating local command buffers. Changed Changed PostProcessPass to internal visibility since it's in internal namespace. Removed SHADER_API_MOBILE from shaders in cases where it affected quality. Removed SHADER_HINT_NICE_QUALITY from shaders. Removed low quality light fade for lighting consistency on both desktop and mobile. Removed SHADER_QUALITY_LOW, SHADER_QUALITY_MEDIUM, SHADER_QUALITY_HIGH from shaders so everything is SHADER_QUALITY_HIGH. Merged the MaterialError.shader and FallbackError.shader. Added new UI/UX for the converter framework. Changed so Unity exports shader variants information into a file in a temp folder. Fixed Fixed camera sorting layer render target not being allocated in the 2d renderer. Fixed an issue with too many variants being included in ShaderGraph shaders used in URP. []. Fixed an issue in where a user could stack cameras with different renderers and not get a warning in the editor (this is not supported). Fixed decal automatic technique to correctly work with webgl. Fixed ScreenSpaceShadows target which was not bound during draw. Fixed setters so they don't cause an infinite loop in URP pipeline asset. Fixed spot and point light harsh distance falloff artefact on some platforms due to fp16 precision issue. Fixed _InternalLut so it isn't released too early and logs warnings when using post-processing in stacked camera's in URP 2D. Reverted behavior to allow FinalBlit to be skipped when you have no ScriptableRenderPasses with AfterRendering as renderEvent while finalPostProcessing is not needed. Fixed the shader graph usage of Unity cross fade. Fixed a stencil test issue when a RendererObjects feature is injected after Post Processing. Fixed incorrect Depth for Camera Stacks. Fixed a capture pass issue so the recorder screenshot doesn't miss the post processing results. Fixed a capture pass issue so the recorder screenshot doesn't miss the post processing results. Fixed stale light cookie data when the last cookie is removed inside a prefab. Added a warning when there are more visible lights than maximum light cookies. Added multi_compile_instancing to the SimpleLit shader on SM 2.0. [14.0.2] - 2021-02-04 This version is compatible with Unity 2022.2.0a8. Added Added automatic Alpha-To-Coverage feature which improves visual quality for alpha-clipped opaque geometry when MSAA is enabled Fixed Use D24_UNorm_S8_UInt depth buffer format on some platforms to improve performance. [14.0.1] - 2021-12-07 Added Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added batch mode support for the converters. Added FP16 camera render target option. Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added support for FidelityFX Super Resolution 1.0 upscaling filter. Added Downscale and Max Iterations options for Bloom Changed Re-added the menu button to be able to convert selected materials. Reverted intermediate texture behavior. Shader Variant Log Level moved from the URP Asset to URP Global Settings. Particle alpha channel blend mode to match standard shader. Removed skipIterations from Bloom settings. It has now been replaced with maxIterations. Fixed Fix mismatch on some platforms between Editor-side and Runtime-side implementations of UnityEngine.Rendering.Universal.DecalRendererFeature.IsAutomaticDBuffer() [case 1364134] Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed material converter not being able to be called in batch mode. [case 1375962] Fixed an issue where specular color was not matching behaviour in Legacy and HDRP. case 1326941 Fixed issue where ShadowCasterGroup2D would throw an exception when there were no shadow casters. case 1387201 Fixed a shader compiler issue with mismatching variable types when calling lerp. Fixed single channel compressed (BC4) cookies on main light. Fixed URP Deferred Fog pass does not work in XR singlepass. case 1390236 Fixed an issue where preview cameras were missing the descriptor for creating their RenderTexture case 1393818 Fixed max light count cpu/gpu mismatch on Windows Editor with Android target. case 1392965 Fixed missing shader keyword SHADOWS_SHADOWMASK for shader graph using deferred rendering. Fixed double alpha modulate for particle unlit shader. Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed Screen Space Decal to work with fog. 1383719 [14.0.0] - 2021-11-17 Added Renderer Features can now use the HelpURLAttribute to specify a documentation URL to be used in the inspector. Added inspector documentation URLs to the SSAO, Decal, and Render Objects renderer features. Changed \"_USE_DRAW_PROCEDURAL\" to be used only in vertex shader in Post Processing related shaders as they are not needed for fragment shaders. In result we now generate less shader variants. Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added missing documentation in UniversalRenderPipelineAsset. Reflection Probe sample showing how Probe Blending and box projection works. Fixed Fix shadow rendering correctly to work with shader stripping in WebGl. case 1381881 Fixed incorrect shadow batching and shadow length case 1387859 VFX: Incorrect Decal rendering when rendescale is different than one case 1343674 Fixed inspector documentation URLs for the URP asset and Universal Renderer asset. Fixed render scale setting unintentionally affecting the scene view camera. Fixed property wrappers around material properties. Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed an issue where specular color was not matching behaviour in Legacy and HDRP. case 1326941 [13.1.2] - 2021-11-05 Added Added minimal picking support for DOTS 1.0 (on parity with Hybrid Renderer V2) Added support for RTHandle. Changed Converted internal render targets to use RTHandle targets instead of RenderTargetHandle and RenderTargetIdentifier. Set usage of RenderTargetHandle and public functions using RenderTargetIdentifier as obsolete for future removal. Split RendererFeatures AddRenderPasses into two functions with SetupRenderPasses so render targets can be used after allocation. The \"Add Renderer Feature\" menu now supports filtering. Removed the name input for the SSAO and Screen Space Shadows renderer features. Fixed Fixed an issue where 2D global lights with shadows enabled could break light layer batching case 1376487 Fixed broken soft shadow filtering. case 1374960 Fixed Lens Flare not accounting Render Scale setting. case 1376820 Fixed an issue where SSAO would throw a \"RenderingCommandBuffer: invalid pass index\" errors. case 1374215 Fixed performance regression for 2D shaders where alpha discard was disabled. [case 1335648] Fixed an issue with MSAA falling back to the incorrect value when sample count 2 is not supported on some Android GPUs Fixed decals to work with native render pass case 1353141 Fixed decals to work with render scale 1353885 Fixed an issue in where the _ScreenParams is not setup correctly. Fixed an issue where intermediate rendertextures were not scaled when a camera was rendering to a texture case 1342895 [13.1.1] - 2021-10-04 Added Added Depth Texture setting for Overlay Camera. Added Depth Priming support for Vulkan with MSAA. Added Shadows and Additional Lights off variants stripping. Added Adaptive Performance Decals scaler. Exposed public API for DebugDisplaySettings. Added Display Stats panel to Rendering Debugger that displays CPU/GPU frame timings and bottlenecks. Preserve Specular blend mode toggle for glass like materials where the specular reflection itself is not transparent. Emulate alpha for multiply blend mode by whitening the base map colors using the alpha value. Keyword _ALPHAMODULATE_ON is set for multiply blend mode. Changed Main light shadow, additional light shadow and additional light keywords are now enabled based on urp setting instead of existence in scene. This allows better variant stripping. Now using the SpeedTree8 PBRLit shadergraph as the default SpeedTree8 shader for Universal. Changed default target sorting layers of Light2D to \"Everything\". Newly added sorting layers will be included in Light2Ds that have target sorting layers already set to \"Everything\". Separated Premultiplied blend mode and Preserve Specular Lighting feature from each other. Premultiplied blend mode is now true straight premultiply mode. Preserve Specular Lighting, which applies alpha differently for diffuse and specular parts of lighting, is now a separate option for Alpha and Additive blend modes. The results of previous Premultiplied blend implementation can be achieved by using Alpha blend mode with Preserve Specular Lighting toggled on. Multiply blend now keeps DstAlpha as it's RGB only. Particle AlphaModulate() renamed to AlphaModulateAndPremultiply() as it does both. Moved separate AlphaModulate() and AlphaPremultiply() to URP shader library. Fix double alpha multiply for ParticleLit. Improved blending modes trigger a material update which tries to keep the existing look intact. This is not always possible and manual blend mode changes might be required. Fixed Fixed incorrect premultiply blend mode. case 1260085, case 1357703, case 1347301 Fixed a regression where ShaderGraph screen position was not correct in game view and when using XR [1369450] Fixed overwriting of preview camera background color. case 1357004 Fixed ShadowCaster now requires varying normalWS to include changed normals from vertex shader in shader graph. Fixed typo in numIterationsEnclosingSphere api name Fix for rendering thumbnails. case 1348209 Fixed a regression bug where XR camera postion can not be modified in beginCameraRendering [case 1365000] Fixed an issue in where installing the Adaptive Performance package caused errors to the inspector UI 1368161 Fixed a regression where filtering the scene view yielded incorrect visual results 1360233 Fixed disabled debug lighting modes on Vulkan and OpenGL following a shader compiler fix. [case 1334240] Fixed an issue in where the Convert Renderering Settings would cause a freeze. case 1353885 Fixed incorrect behavior of Reflections with Smoothness lighting debug mode. [case 1374181] Fixed a performance regression in the 2D renderer regarding the PostProcessPass [case 1347893] Fixed light banding artifacts on some mobile platforms. case 1375791 [13.1.0] - 2021-09-24 Added Added public api and updated docs for Light2D shape properties. Changed URP will no longer render via an intermediate texture unless actively required by a Renderer Feature. See the upgrade guide for compatibility options and how assets are upgraded. MaterialReimporter.ReimportAllMaterials now batches the asset database changes to improve performance. Fixed Fixed post processing with Pixel Perfect camera case 1363763 Fixed the LensFlare flicker with TAA on SceneView (case 1356734). Fixed an issue where Unlit and ParticlesUnlit shaders did not have HDR color selection for albedo case 1283767 [13.0.0] - 2021-09-01 Added URP global setting for stripping post processing shader variants. URP global setting for stripping off shader variants. Terrain grass shader alpha changed to always write 1 to alpha. Enabled alpha channel write mask. Changed Removed experimental tile deferred code. VFX: New shadergraph support directly on Universal target. Fixed Added warning for lit shader detailed abledo, if texture is not linear. 1342011 Fixed lit detail correctly upgraded from standard shader. 1323725 URP asset can now use multi-edit. case 1364966 Fixed an issue in where the current open scene didn't load after running the converters. [case 1365101] Added \"Conservative Enclosing Sphere\" setting to fix shadow frustum culling issue where shadows are erroneously culled in corners of cascades case 1153151 Fixed memory leak with XR combined occlusion meshes. [case 1366173] Fixed a bug with Sprite Targets in ShaderGraph not rendering correctly in game view [1352225] Changed Remove use of deprecated UNITY_USE_NATIVE_HDR keyword in shaders. [12.0.0] - 2021-01-11 Added Added support for default sprite mask shaders for the 2D Renderer in URP. Added View Vector node to mimic old behavior of View Direction node in URP. Added support for the PlayStation 5 platform. Enabled deferred renderer in UI. Added support for light layers, which uses Rendering Layer Masks to make Lights in your Scene only light up specific Meshes. 2D Light Texture Node. A Shader Graph node that enable sampling of the Light Textures generated by the 2D Renderer in a lit scene. Fixed an error where multisampled texture being bound to a non-multisampled sampler in XR. case 1297013 Added _SURFACE_TYPE_TRANSPARENT keyword to URP shaders. Added Depth and DepthNormals passes to particles shaders. Added support for SSAO in Particle and Unlit shaders. Added Decal support. This includes new Decal Projector component, Decal renderer feature and Decal shader graph. Added a SpeedTree 8 Shader Graph but did not set it as the default when importing or upgrading Speed Tree 8 assets. Because URP doesn't yet support per-material culling, this Shader Graph does not yet behave in the same way as the existing handwritten SpeedTree 8 shader for URP. Added optional Depth Priming. Allows the forward opaque pass of the base camera to skip shading certain fragments if they don't contribute to the final opaque output. Added blending and box projection for reflection probes. Added 'Store Actions' option that enables bandwidth optimizations on mobile GPU architectures. Added \"Allow Material Override\" option to Lit and Unlit ShaderGraph targets. When checked, allows Material to control the surface options (transparent/opaque, blend mode, etc). Added a new UI for Render Pipeline Converters. Used now for Built-in to Universal conversion. Added sections on Light Inspector. Reorder camera inspector to be in the same order as HDRP. Added new URP Debug Views under Window/Analysis/Rendering Debugger. Added support for controlling Volume Framework Update Frequency in UI on Cameras and URP Asset as well as through scripting. Added URP Global Settings Asset to the Graphics Settings - a common place for project-wide URP settings. Added possibility to rename light layer values. Added Light cookies support to directional, point and spot light. Directional light cookie is main light only feature. Added GetUniversalAdditionalLightData, a method that returns the additional data component for a given light or create one if it doesn't exist yet. VFX: Basic support of Lit output. Added Motion Vector render pass for URP. VFX: Fix light cookies integration. Added Lights 2D to the Light Explorer window. Two new URP specific scene templates, Basic which has a camera and directional light, then Standard which has the addition of a global volume with basic post effects setup. Added Render Settings Converter to the Render Pipeline Converter, this tool creates and assigns URP Assets based off rendering settings of a Builtin project. XR: Added Late Latching support to reduce VR latency (Quest). Fixed incorrect shadow fade in deferred rendering mode. Added a help button on material editor to show the shader documentation page Added \"Copy Depth Mode\" Universal Renderer Data option that allows to specify if URP should copy the depth after the opaques pass or after the transparents pass. This can lead to bandwidth savings on mobile. Changed Moved fog evaluation from vertex shader to pixel shader. This improves rendering of fog for big triangles and fog quality. This can change the look of the fog slightly. UNITY_Z_0_FAR_FROM_CLIPSPACE now remaps to [0, far] range on all platforms consistently. Previously OpenGL platforms did not remap, discarding small amount of range [-near, 0]. Moved all 2D APIs out of experimental namespace. ClearFlag.Depth does not implicitely clear stencil anymore. ClearFlag.Stencil added. The Forward Renderer asset is renamed to the Universal Renderer asset. The Universal Renderer asset contains the property Rendering Path that lets you select the Forward or the Deferred Rendering Path. Improved PixelPerfectCamera UI/UX Changed Pixel Snapping and Upscale Render Texture in the PixelPerfectCamera to a dropdown. Move Assets/Create/Rendering/Universal Render Pipeline/Pipeline Asset (2D Renderer) to Assets/Create/Rendering/URP Asset (with 2D Renderer) Move Assets/Create/Rendering/Universal Render Pipeline/2D Renderer to Assets/Create/Rendering/URP 2D Renderer Move Assets/Create/Rendering/Universal Render Pipeline/Renderer Feature to Assets/Create/Rendering/URP Renderer Feature Move Assets/Create/Rendering/Universal Render Pipeline/Post-process Data to Assets/Create/Rendering/URP Post-process Data Move Assets/Create/Rendering/Universal Render Pipeline/Pipeline Asset (Forward Renderer) to Assets/Create/Rendering/URP Asset (with Forward Renderer) Move Assets/Create/Rendering/Universal Render Pipeline/XR System Data to Assets/Create/Rendering/URP XR System Data Move Assets/Create/Rendering/Universal Render Pipeline/Forward Renderer to Assets/Create/Rendering/URP Forward Renderer Removing unused temporary depth buffers for Depth of Field and Panini Projection. Optimized the Bokeh Depth of Field shader on mobile by using half precision floats. Changed UniversalRenderPipelineCameraEditor to URPCameraEditor Made 2D shadow casting more efficient Reduced the size of the fragment input struct of the TerrainLitPasses and LitGBufferPass, SimpleLitForwardPass and SimpleLitGBufferPass lighting shaders. Bokeh Depth of Field performance improvement: moved some calculations from GPU to CPU. Advanced Options > Priority has been renamed to Sorting Priority Opacity as Density blending feature for Terrain Lit Shader is now disabled when the Terrain has more than four Terrain Layers. This is now similar to the Height-blend feature for the Terrain Lit Shader. DepthNormals passes now sample normal maps if used on the material, otherwise output the geometry normal. SSAO Texture is now R8 instead of ARGB32 if supported by the platform. Enabled subsurface scattering with GI on handwritten Universal ST8 shader. Material upgrader now also upgrades AnimationClips in the project that have curves bound to renamed material properties. 2D Lights now inherit from Light2DBase. The behavior of setting a camera's Background Type to \"Dont Care\" has changed on mobile. Previously, \"Dont Care\" would behave identically to \"Solid Color\" on mobile. Now, \"Dont Care\" corresponds to the render target being filled with arbitrary data at the beginning of the frame, which may be faster in some situations. Note that there are no guarantees for the exact content of the render target, so projects should use \"Dont care\" only if they are guaranteed to render to, or otherwise write every pixel every frame. Stripping shader variants per renderer features instead of combined renderer features. When MSAA is enabled and a depth texture is required, the opaque pass depth will be copied instead of scheduling a depth prepass. URP Asset Inspector - Advanced settings have been reordered under Show Additional Properties on each section. Changed the default name when a new urp asset is created. URP Asset Inspector - General section has been renamed to Rendering. Refactored some of the array resizing code around decal projector rendering to use new APIs in render core UniversalRendererData and ForwardRendererData GUIDs have been reversed so that users coming from 2019LTS, 2020LTS and 2021.1 have a smooth upgrade path, you may encounter issues coming from 2021.2 Alpha/Beta versions and are recommended to start with a fresh library if initial upgrade fails. Fixed Fixed an issue in PostProcessPass causing OnGUI draws to not show on screen. [case 1346650] Fixed an issue with the blend mode in Sprite-Lit-Default shader causing alpha to overwrite the framebuffer. case 1331392 Fixed pixel perfect camera rect not being correctly initialized. case 1312646 Camera Inspector Stack list edition fixes. Fix indentation of Emission map on material editor. Fixed additional camera data help url Fixed additional light data help url Fixed Opacity as Density blending artifacts on Terrain that that caused Terrain to have modified splat weights of zero in some areas and greater than one in others. case 1283124 Fixed an issue where Sprite type Light2Ds would throw an exeception if missing a sprite Fixed an issue where Sprite type Light2Ds were missing a default sprite Fixed an issue where ShadowCasters were sometimes being rendered twice in the editor while in playmode. Fixed an issue where ShadowCaster2D was generating garbage when running in the editor. case 1304158 Fixed an issue where the 2D Renderer was not rendering depth and stencil in the normal rendering pass Fixed an issue where 2D lighting was incorrectly calculated when using a perspective camera. Fixed an issue where objects in motion might jitter when the Pixel Perfect Camera is used. case 1300474 Fixed an issue where filtering in the scene view would not properly highlight the filtered objects. case 1324359 Fixed an issue where the scene view camera was not correctly cleared for the 2D Renderer. case 1311377 Fixed an issue where the letter box/pillar box areas were not properly cleared when the Pixel Perfect Camera is used. case 1291224 Fixed an issue where the Cinemachine Pixel Perfect Extension might cause the Orthographic Size of the Camera to jump to 1 when the Scene is loaded. case 1249076 Fixed an issue where 2D Shadows were casting to the wrong layers [case 1300753][https://issuetracker.unity3d.com/product/unity/issues/guid/1300753/] Fixed an issue where Light2D did not upgrade Shadow Strength, Volumetric Intensity, Volumetric Shadow Strength correctly case 1317755 Fixed an issue where render scale was breaking SSAO in scene view. case 1296710 Fixed GC allocations from XR occlusion mesh when using multipass. SMAA post-filter only clear stencil buffer instead of depth and stencil buffers. Fixed an issue where the inspector of Renderer Data would break after adding RenderObjects renderer feature and then adding another renderer feature. Fixed an issue where soft particles did not work with orthographic projection. case 1294607 Fixed wrong shader / properties assignement to materials created from 3DsMax 2021 Physical Material. (case 1293576) Normalized the view direction in Shader Graph to be consistent across Scriptable Render Pieplines. Fixed material upgrader to run in batch mode [case 1305402] Fixed gizmos drawing in game view. case 1302504 Fixed an issue in shaderGraph target where the ShaderPass.hlsl was being included after SHADERPASS was defined Fixed base camera to keep render texture in sync with camera stacks. case 1288105 Fixed base camera to keep viewport in sync with camera stacks. case 1311268 Fixed base camera to keep display index in sync with camera stacks. case 1252265 Fixed base camera to keep display index in sync with camera stacks for canvas. case 1291872 Fixed render pass reusage with camera stack on vulkan. case 1226940 Fixed camera stack UI correctly work with prefabs. case 1308717 Fixed an issue where Particle Lit shader had an incorrect fallback shader [case 1312459] Fixed an issue with backbuffer MSAA on Vulkan desktop platforms. Fixed shadow cascade blend culling factor. Fixed remove of the Additional Light Data when removing the Light Component. Fixed remove of the Additional Camera Data when removing the Camera Component. Fixed shadowCoord error when main light shadow defined in unlit shader graph case 1175274 Removed Custom.meta which was causing warnings. case 1314288 Fixed a case where shadow fade was clipped too early. Fixed an issue where SmoothnessSource would be upgraded to the wrong value in the material upgrader. Fixed multi editing of Bias property on lights. [case 1289620] Fixed an issue where bokeh dof is applied incorrectly when there is an overlay camera in the camera stack. case 1303572 Fixed SafeNormalize returning invalid vector when using half with zero length. [case 1315956] Fixed lit shader property duplication issue. case 1315032 Fixed undo issues for the additional light property on the UniversalRenderPipeline Asset. [case 1300367] Fixed an issue where SSAO would sometimes not render with a recently imported renderer. Fixed a regression where the precision was changed. case 1313942 Fixed an issue where motion blur would allocate memory each frame. case 1314613 Fixed an issue where using Camera.targetTexture with Linear Color Space on an Android device that does not support sRGB backbuffer results in a RenderTexture that is too bright. [case 1307710] Fixed issue causing missing shaders on DirectX 11 feature level 10 GPUs. case 1278390 Fixed errors when the Profiler is used with XR multipass. case 1313141 Fixed materials being constantly dirty. Fixed double sided and clear coat multi editing shader. Fixed issue where copy depth depth pass for gizmos was being skipped in game view case 1302504 Fixed an issue where transparent objects sampled SSAO. Fixed an issue where Depth Prepass was not run when SSAO was set to Depth Mode. Fixed an issue where changing camera's position in the BeginCameraRendering do not apply properly. [case 1318629] (https://issuetracker.unity3d.com/issues/camera-doesnt-move-when-changing-its-position-in-the-begincamerarendering-and-the-endcamerarendering-methods) Fixed depth of field pass usage on unsupported devices. case 1327076 Fixed an issue where SMAA did not work for OpenGL case 1318214 Fixed an issue with Shader Graph Lit shaders where the normalized view direction produced incorrect lighting. [1332804] Fixed return values from GetStereoProjectionMatrix() and SetStereoViewMatrix(). case 1312813 Fixed CopyDepthPass incorrectly always enqueued when deferred rendering mode was enabled when it should depends on the pipeline asset settings. Fixed renderer post processing option to work with asset selector re-assing. case 1319454 Fixed post processing to be enabled by default in the renderer when creating URP asset option. case 1333461 Fixed shaderGraph shaders to render into correct depthNormals passes when deferred rendering mode and SSAO are enabled. Fixed ordering of subshaders in the Unlit Shader Graph, such that shader target 4.5 takes priority over 2.0. case 1328636 Fixed issue where it will clear camera color if post processing is happening on XR [case 1324451] Fixed a case where camera dimension can be zero. case 1321168 Fixed renderer creation in playmode to have its property reloaded. [case 1333463] Fixed gizmos no longer allocate memory in game view. [case 1328852] Fixed an issue where shadow artefacts appeared between cascades on Terrain Detail objects. Fixed ShaderGraph materials to select render queue in the same way as handwritten shader materials by default, but allows for a user override for custom behavior. [case 1335795] Fixed sceneview debug mode rendering (case 1211436). URP Global Settings can now be unassigned in the Graphics tab (case 1343570). VFX: Fixed soft particles when HDR or Opaque texture isn't enabled VFX: Fixed OpenGL soft particles fallback when depth texture isn't available Fixed soft shadows shader variants not set to multi_compile_fragment on some shaders (gbuffer pass, speedtree shaders, WavingGrass shader). Fixed issue with legacy stereo matrices with XR multipass. [case 1342416] Fixed unlit shader function name ambiguity Fixed Terrain holes not appearing in shadows [case 1349305] VFX: Compilation issue with ShaderGraph and planar lit outputs case 1349894 Fixed an issue where _AfterPostProcessTexture was no longer being assigned in UniversalRenderer. Fixed an issue where TerrainLit was rendering color lighter than Lit [case 1340751] (https://issuetracker.unity3d.com/product/unity/issues/guid/1340751/) Fixed Camera rendering when capture action and post processing present. [case 1350313] Fixed artifacts in Speed Tree 8 billboard LODs due to SpeedTree LOD smoothing/crossfading [case 1348407] Fix sporadic NaN when using normal maps with XYZ-encoding case 1351020 Support undo of URP Global Settings asset assignation (case 1342987). Removed unsupported fields from Presets of Light and Camera [case 1335979]. Fixed graphical artefact when terrain height map is used with rendering layer mask for lighting. Fixed URP's vignette effect to respect XR's view center, since with Asymmetric FOV, the center of the view is not always the center of the texture case 1358336 Fixed an issue where screen space shadows has flickering with deferred mode case 1354681 Fixed shadowCascadeBlendCullingFactor to be 1.0 Fixed missing property values in a RendererFeature of screen space shadows by adding tooltip for it instead of showing them. [case 1327356] Changed Change Asset/Create/Shader/Universal Render Pipeline/Lit Shader Graph to Asset/Create/Shader Graph/URP/Lit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Sprite Lit Shader Graph to Asset/Create/Shader Graph/URP/Sprite Lit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Unlit Shader Graph to Asset/Create/Shader Graph/URP/Unlit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Sprite Unlit Shader Graph to Asset/Create/Shader Graph/URP/Sprite Unlit Shader Graph Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project Materials to 2D Renderer Materials to Edit/Rendering/Materials/Convert All Built-in Materials to URP 2D Renderer Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Scene Materials to 2D Renderer Materials to Edit/Rendering/Materials/Convert All Built-in Scene Materials to URP 2D Renderer Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project URP Parametric Lights to Freeform to Edit/Rendering/Lights/Convert Project URP Parametric Lights to Freeform Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Scene URP Parametric Lights to Freeform to Edit/Rendering/Lights/Convert Scene URP Parametric Lights to Freeform Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project Materials to URP Materials to Edit/Rendering/Materials/Convert All Built-in Materials to URP Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Selected Materials to URP Materials to Edit/Rendering/Materials/Convert Selected Built-in Materials to URP Deprecated GetShadowFade in Shadows.hlsl, use GetMainLightShadowFade or GetAdditionalLightShadowFade. Improved shadow cascade GUI drawing with pixel perfect, hover and focus functionalities. Shadow fade now uses border value for calculating shadow fade distance and fall off linearly. Improved URP profiling scopes. Remove low impact scopes from the command buffer for a small performance gain. Fix the name and invalid scope for context.submit() scope. Change the default profiling name of ScriptableRenderPass to Unnamed_ScriptableRenderPass. Using the same MaterialHeaderScope for material editor as HDRP is using Removed Code to upgrade from LWRP to URP was removed. This means if you want to upgrade from LWRP you must first upgrade to previous versions of URP and then upgrade to this version. [11.0.0] - 2020-10-21 Added Added real-time Point Light Shadows. Added a supported MSAA samples count check, so the actual supported MSAA samples count value can be assigned to RenderTexture descriptors. Added the TerrainCompatible SubShader Tag. Use this Tag in your custom shader to tell Unity that the shader is compatible with the Terrain system. Added _CameraSortingLayerTexture global shader variable and related parameters Added preset shapes for creating a freeform light Added serialization of Freeform ShapeLight mesh to avoid CPU cost of generating them on the runtime. Added 2D Renderer Asset Preset for creating a Universal Renderer Asset Added an option to use faster, but less accurate approximation functions when converting between the sRGB and Linear color spaces. Added screen space shadow as renderer feature Added [DisallowMultipleRendererFeature] attribute for Renderer Features. Added support for Enlighten precomputed realtime Global Illumination. Changed Optimized 2D Renderer performance on mobile GPUs by reducing the number of render target switches. Optimized 2D Renderer performance by rendering the normal buffer at the same lower resolution as the light buffers. Improved Light2D UI/UX Improved 2D Menu layout Deprecated Light2D Parametric Light Deprecated Light2D point light cookie Renamed Light2D point light to spot light 2D Renderer: The per Blend Style render texture scale setting was replaced by a global scale setting for all Blend Styles. Optimized 2D Renderer performance by using a tiny light texture for layer/blend style pairs for which no light is rendered. Reorgnized the settings in 2D Renderer Data Inspector. FallOff Lookup Texture is now part of 2D RenderData. Creating a Shadow Caster 2D will use try and use sprite and physics bounds as the default shape Deleting all points in a Shadow Caster will cause the shape to use the bounds. Improved Geometry for Smooth Falloff of 2D Shape Lights. Updated the tooltips for Light 2D Inspector. Removed the Custom blend Mode option from the Blend Styles. New default Blend Styles when a new 2D Renderer Data asset is created. Added a supported MSAA samples count check, so the actual supported MSAA samples count value can be assigned to RenderTexture descriptors. Bloom in Gamma color-space now more closely matches Linear color-space, this will mean project using Bloom and Gamma color-space may need to adjust Bloom Intensity to match previous look. Autodesk Interactive Shader Graph files and folders containing them were renamed. The new file paths do not have spaces. Moved FinalPostProcessPass to AfterRenderingPostProcessing event from AfterRendering. This allows user pass to execute before and after FinalPostProcessPass and CapturePass to capture everything. Changed shader keywords of main light shadow from toggling to enumerating. Always use \"High\" quality normals, which normalizes the normal in pixel shader. \"Low\" quality normals looked too much like a bug. Re-enabled implicit MSAA resolve to backbuffer on Metal MacOS. Optimized 2D performance by rendering straight to the backbuffer if possible Changed Post Process Data to bool. When it is no enabled all post processing is stripped from build, when it is enabled you can still override resources there. Converted XR automated tests to use MockHMD. Improved 2D Renderer performance on mobile GPUs when using MSAA Reduced the size of the fragment input struct of the Terrain and Forward lighting shaders. Fixed Fixed an issue where additional lights would not render with WebGL 1 Fixed an issue where the 2D Renderer was incorrectly rendering transparency with normal maps on an empty background. Fixed an issue that that caused a null error when creating a Sprite Light. case 1307125 Fixed an issue where Sprites on one Sorting Layer were fully lit even when there's no 2D light targeting that layer. Fixed an issue where null reference exception was thrown when creating a 2D Renderer Data asset while scripts are compiling. case 1263040 Fixed an issue where no preview would show for the lit sprite master node in shadergraph Fixed an issue where no shader was generated for unlit sprite shaders in shadergraph Fixed an issue where Sprite-Lit-Default shader's Normal Map property wasn't affected by Tiling or Offset. case 1270850 Fixed an issue where normal-mapped Sprites could render differently depending on whether they're dynamically-batched. case 1286186 Removed the warning about mis-matched vertex streams when creating a default Particle System. case 1285272 Fixed latest mockHMD renderviewport scale doesn't fill whole view after scaling. [case 1286161] (https://issuetracker.unity3d.com/issues/xr-urp-renderviewportscale-doesnt-fill-whole-view-after-scaling) Fixed camera renders black in XR when user sets invalid MSAA value. Fixed an issue causing additional lights to stop working when set as the sun source. case 1278768 Fixed an issue causing passthrough camera to not render. case 1283894 Fixed an issue that caused a null reference when Lift Gamma Gain was being displayed in the Inspector and URP was upgraded to a newer version. case 1283588 Fixed an issue where soft particles were not rendered when depth texture was disabled in the URP Asset. case 1162556 Fixed an issue where soft particles were rendered opaque on OpenGL. case 1226288 Fixed an issue where the depth texture sample node used an incorrect texture in some frames. case 1268079 Fixed a compiler error in BakedLit shader when using Hybrid Renderer. Fixed an issue with upgrading material set to cutout didn't properly set alpha clipping. case 1235516 Fixed XR camera fov can be changed through camera inspector. Fixed an issue where Universal Render Pipeline with disabled antiAliasing was overwriting QualitySettings.asset on frequent cases. case 1219159 Fixed a case where overlay camera with output texture caused base camera not to render to screen. case 1283225 Fixed an issue where the scene view camera ignored the pipeline assets HDR setting. case 1284369 Fixed an issue where the Camera inspector was grabbing the URP asset in Graphics Settings rather than the currently active. Fixed an issue where the Light Explorer was grabbing the URP asset in Graphics Settings rather than the currently active. Fixed an issue causing materials to be upgraded multiple times. Fixed bloom inconsistencies between Gamma and Linear color-spaces. Fixed an issue in where all the entries in the Renderer List wasn't selectable and couldn't be deleted. Fixed Deferred renderer on some Android devices by forcing accurate GBuffer normals. [case 1288042] Fixed an issue where MSAA did not work in Editor Game View on Windows with Vulkan. Fixed issue where selecting and deselecting Forward Renderer asset would leak memory case 1290628 Fixed the default background color for previews to use the original color. Fixed an issue where the scene view would turn black when bloom was enabled. case 1298790 Fixed an issue where having \"Opaque Texture\" and MSAA enabled would cause the opaque texture to be rendered black on old Apple GPUs case 1247423 Fixed SAMPLE_TEXTURECUBE_ARRAY_LOD macro when using OpenGL ES. case 1285132 Fixed an issue such that it is now posible to enqueue render passes at runtime. Fixed SpeedTree LOD fade functionality. [case 1198135] [10.2.0] - 2020-10-19 Changed Changed RenderObjectsFeature UI to only expose valid events. Previously, when selecting events before BeforeRenderingPrepasses objects would not be drawn correctly as stereo and camera setup only happens before rendering opaques objects. Transparent Lit ShaderGraph using Additive blending will now properly fade with alpha [1270344] Fixed Fixed the Unlit shader not being SRP Batcher compatible on OpenGLES/OpenGLCore. case 1263720 Fixed an issue with soft particles not rendering correctly for overlay cameras with post processing. case 1241626 Fixed MSAA override on camera does not work in non-XR project if target eye is selected to both eye. [10.1.0] - 2020-10-12 Added support for the Shadowmask Mixed Lighting Mode (Forward only), which supports up to four baked-shadow Lights. Added ComplexLit shader for advanced material features and deferred forward fallback. Added Clear Coat feature for ComplexLit shader and for shader graph. Added Parallax Mapping to the Lit shader (Lit.shader). Added the Detail Inputs setting group in the Lit shader (Lit.shader). Added Smooth shadow fading. Added SSAO support for deferred renderer. The pipeline now outputs a warning in the console when trying to access camera color or depth texture when those are not valid. Those textures are only available in the context of ScriptableRenderPass. Added a property to access the renderer from the CameraData. Changed Shader functions SampleSH9, SampleSHPixel, SampleSHVertex are now gamma corrected in gamma space. As result LightProbes are gamma corrected too. The maximum number of visible lights when using OpenGL ES 3.x on Android now depends on the minimum OpenGL ES 3.x version as configured in PlayerSettings. The default value of the HDR property of a newly created Universal Render Pipeline Asset, is now set to true. Fixed Fixed an issue where the CapturePass would not capture the post processing effects. Fixed an issue were the filter window could not be defocused using the mouse. case 1242032 Fixed camera backgrounds not matching between editor and build when background is set to 'Uninitialized'. case 1224369 Fixed a case where main light hard shadows would not work if any other light is present with soft shadows.case 1250829 Fixed issue that caused color grading to not work correctly with camera stacking. case 1263193 Fixed an issue that caused an infinite asset database reimport when running Unity in command line with -testResults argument. Fixed ParticlesUnlit shader to use fog color instead of always black. [case 1264585] Fixed issue that caused some properties in the camera to not be bolded and highlighted when edited in prefab mode. case 1230082 Fixed issue where blur would sometimes flicker case 1224915 Fixed an issue in where the camera inspector didn't refresh properly when changing pipeline in graphic settings. case 1222668 Fixed depth of field to work with dynamic resolution. case 1225467 Fixed FXAA, SSAO, Motion Blur to work with dynamic resolution. Fixed an issue where Pixel lighting variants were stripped in builds if another URP asset had Additional Lights set to Per Vertex case 1263514 Fixed an issue where transparent meshes were rendered opaque when using custom render passes case 1262887 Fixed regression from 8.x.x that increased launch times on Android with GLES3. case 1269119 Fixed an issue with a render texture failing assertion when chosing an invalid format. case 1222676 Fixed an issue that caused the unity_CameraToWorld matrix to have z flipped values. case 1257518 Fixed not using the local skybox on the camera game object when the Skybox Material property in the Lighting window was set to null. Fixed an issue where, if URP was not in use, you would sometimes get errors about 2D Lights when going through the menus. Fixed GC when using XR single-pass automated tests. Fixed an issue that caused a null reference when deleting camera component in a prefab. case 1244430 Fixed resolution of intermediate textures when rendering to part of a render texture. case 1261287 Fixed indirect albedo not working with shadergraph shaders in some rare setups. case 1274967 Fixed XR mirroView sRGB issue when color space is gamma. Fixed an issue where XR eye textures are recreated multiple times per frame due to per camera MSAA change. Fixed an issue wehre XR mirror view selector stuck. Fixed LightProbes to have gamma correct when using gamma color space. case 1268911 Fixed GLES2 shader compilation. Fixed useless mip maps on temporary RTs/PostProcessing inherited from Main RT descriptor. Fixed issue with lens distortion breaking rendering when enabled and its intensity is 0. Fixed mixed lighting subtractive and shadowmask modes for deferred renderer. Fixed issue that caused motion blur to not work in XR. Fixed 2D renderer when using Linear rendering on Android directly to backbuffer. Fixed issue where multiple cameras would cause GC each frame. case 1259717 Fixed Missing camera cannot be removed after scene is saved by removing the Missing camera label. case 1252255 Fixed MissingReferenceException when removing Missing camera from camera stack by removing Missing camera label. case 1252263 Fixed slow down in the editor when editing properties in the UI for renderer features. case 1279804 Fixed test 130_UnityMatrixIVP on OpenGL ES 3 Fixed MSAA on Metal MacOS and Editor. [10.0.0] - 2020-06-10 Added Added the option to strip Terrain hole Shader variants. Added support for additional Directional Lights. The amount of additional Directional Lights is limited by the maximum Per-object Lights in the Render Pipeline Asset. Added Package Samples: 2 Camera Stacking, 2 Renderer Features Added default implementations of OnPreprocessMaterialDescription for FBX, Obj, Sketchup and 3DS file formats. Added Transparency Sort Mode and Transparency Sort Axis to 2DRendererData. Added support for a user defined default material to 2DRendererData. Added the option to toggle shadow receiving on transparent objects. Added XR multipass rendering. Multipass rendering is a requirement on many VR platforms and allows graceful fallback when single-pass rendering isn't available. Added support for Camera Stacking when using the Forward Renderer. This introduces the Camera Render Type property. A Base Camera can be initialized with either the Skybox or Solid Color, and can combine its output with that of one or more Overlay Cameras. An Overlay Camera is always initialized with the contents of the previous Camera that rendered in the Camera Stack. Added AssetPostprocessors and Shadergraphs to handle Arnold Standard Surface and 3DsMax Physical material import from FBX. Added [MainTexture] and [MainColor] shader property attributes to URP shader properties. These will link script material.mainTextureOffset and material.color to _BaseMap and _BaseColor shader properties. Added the option to specify the maximum number of visible lights. If you set a value, lights are sorted based on their distance from the Camera. Added the option to control the transparent layer separately in the Forward Renderer. Added the ability to set individual RendererFeatures to be active or not, use ScriptableRendererFeature.SetActive(bool) to set whether a Renderer Feature will execute, ScriptableRendererFeature.isActive can be used to check the current active state of the Renderer Feature. additional steps to the 2D Renderer setup page for quality and platform settings. If Unity Editor Analytics are enabled, Universal collects anonymous data about usage of Universal. This helps the Universal team focus our efforts on the most common scenarios, and better understand the needs of our customers. Added a OnCameraSetup() function to the ScriptableRenderPass API, that gets called by the renderer before rendering each camera Added a OnCameraCleanup() function to the ScriptableRenderPass API, that gets called by the renderer after rendering each camera Added Default Material Type options to the 2D Renderer Data Asset property settings. Added additional steps to the 2D Renderer setup page for quality and platform settings. Added option to disable XR autotests on test settings. Shader Preprocessor strips gbuffer shader variants if DeferredRenderer is not in the list of renderers in any Scriptable Pipeline Assets. Added an option to enable/disable Adaptive Performance when the Adaptive Performance package is available in the project. Added support for 3DsMax's 2021 Simplified Physical Material from FBX files in the Model Importer. Added GI to SpeedTree Added support for DXT5nm-style normal maps on Android, iOS and tvOS Added stencil override support for deferred renderer. Added a warning message when a renderer is used with an unsupported graphics API, as the deferred renderer does not officially support GL-based platforms. Added option to skip a number of final bloom iterations. Added support for Screen Space Ambient Occlusion and a new shader variant _SCREEN_SPACE_OCCLUSION. Added support for Normal Texture being generated in a prepass. Added a ConfigureInput() function to ScriptableRenderPass, so it is possible for passes to ask that a Depth, Normal and/or Opaque textures to be generated by the forward renderer. Added a float2 normalizedScreenSpaceUV to the InputData Struct. Added new sections to documentation: Writing custom shaders, and Using the beginCameraRendering event. Added support for GPU instanced mesh particles on supported platforms. Added API to check if a Camera or Light is compatible with Universal Render Pipeline. Changed Moved the icon that indicates the type of a Light 2D from the Inspector header to the Light Type field. Eliminated some GC allocations from the 2D Renderer. Added SceneSelection pass for TerrainLit shader. Remove final blit pass to force alpha to 1.0 on mobile platforms. Deprecated the CinemachineUniversalPixelPerfect extension. Use the one from Cinemachine v2.4 instead. Replaced PlayerSettings.virtualRealitySupported with XRGraphics.tryEnable. Blend Style in the 2DRendererData are now automatically enabled/disabled. When using the 2D Renderer, Sprites will render with a faster rendering path when no lights are present. Particle shaders now receive shadows The Scene view now mirrors the Volume Layer Mask set on the Main Camera. Drawing order of SRPDefaultUnlit is now the same as the Built-in Render Pipline. Made MaterialDescriptionPreprocessors private. UniversalRenderPipelineAsset no longer supports presets. Case 1197020. The number of maximum visible lights is now determined by whether the platform is mobile or not. Renderer Feature list is now redesigned to fit more closely to the Volume Profile UI, this vastly improves UX and reliability of the Renderer Features List. Default color values for Lit and SimpleLit shaders changed to white due to issues with texture based workflows. You can now subclass ForwardRenderer to create a custom renderer based on it. URP is now computing tangent space per fragment. Optimized the 2D Renderer to skip rendering into certain internal buffers when not necessary. You can now subclass ForwardRenderer to create a custom renderer based on it. URP shaders that contain a priority slider now no longer have an offset of 50 by default. The virtual ScriptableRenderer.FrameCleanup() function has been marked obsolete and replaced by ScriptableRenderer.OnCameraCleanup() to better describe when the function gets invoked by the renderer. DepthOnlyPass, CopyDepthPass and CopyColorPass now use OnCameraSetup() instead of Configure() to set up their passes before executing as they only need to get their rendertextures once per camera instead of once per eye. Updated shaders to be compatible with Microsoft's DXC. Mesh GPU Instancing option is now hidden from the particles system renderer as this feature is not supported by URP. The 2D Renderer now supports camera stacking. 2D shaders now use half-precision floats whenever precise results are not necessary. Removed the ETC1_EXTERNAL_ALPHA variant from Shader Graph Sprite shaders. Eliminated some unnecessary clearing of render targets when using the 2D Renderer. The rendering of 2D lights is more effient as sorting layers affected by the same set of lights are now batched. Removed the 8 renderer limit from URP Asset. Merged the deferred renderer into the forward renderer. Changing the default value of Skip Iterations to 1 in Bloom effect editor Use SystemInfo to check if multiview is supported instead of being platform hardcoded Default attachment setup behaviour for ScriptableRenderPasses that execute before rendering opaques is now set use current the active render target setup. This improves performance in some situations. Combine XR occlusion meshes into one when using single-pass (multiview or instancing) to reduce draw calls and state changes. Shaders included in the URP package now use local Material keywords instead of global keywords. This increases the amount of available global user-defined Material keywords. Fixed Fixed an issue that caused WebGL to render blank screen when Depth texture was enabled case 1240228 Fixed NaNs in tonemap algorithms (neutral and ACES) on platforms defaulting to lower precision. Fixed a performance problem with ShaderPreprocessor with large amount of active shader variants in the project Fixed an issue where linear to sRGB conversion occurred twice on certain Android devices. Fixed an issue where there were 2 widgets showing the outer angle of a spot light. Fixed an issue where Unity rendered fullscreen quads with the pink error shader when you enabled the Stop NaN post-processing pass. Fixed an issue where Terrain hole Shader changes were missing. Case 1179808. Fixed an issue where the Shader Graph SceneDepth node didn't work with XR single-pass (double-wide) rendering. See case 1123069. Fixed Unlit and BakedLit shader compilations in the meta pass. Fixed an issue where the Bokeh Depth of Field shader would fail to compile on a console platform. Fixed an issue where the Scene lighting button didn't work when you used the 2D Renderer. Fixed a performance regression when you used the 2D Renderer. Fixed an issue where the Freeform 2D Light gizmo didn't correctly show the Falloff offset. Fixed an issue where the 2D Renderer rendered nothing when you used shadow-casting lights with incompatible Renderer2DData. Fixed an issue where errors were generated when the Physics2D module was not included in the project's manifest. Fixed an issue where Prefab previews were incorrectly lit when you used the 2D Renderer. Fixed an issue where the Light didn't update correctly when you deleted a Sprite that a Sprite 2D Light uses. Fixed an issue where 2D Lighting was broken for Perspective Cameras. Fixed an issue where resetting a Freeform 2D Light would throw null reference exceptions. Case 1184536. Fixed an issue where Freeform 2D Lights were not culled correctly when there was a Falloff Offset. Fixed an issue where Tilemap palettes were invisible in the Tile Palette window when the 2D Renderer was in use. Case 1162550. Fixed issue where black emission would cause unneccesary inspector UI repaints. Case 1105661. Fixed user LUT sampling being done in Linear instead of sRGB. Fixed an issue when trying to get the Renderer via API on the first frame. Case 1189196. Fixed a material leak on domain reload. Fixed an issue where deleting an entry from the Renderer List and then undoing that change could cause a null reference. Case 1191896. Fixed an issue where the user would get an error if they removed the Additional Camera Data component. Case 1189926. Fixed post-processing with XR single-pass rendering modes. Fixed an issue where Cinemachine v2.4 couldn't be used together with Universal RP due to a circular dependency between the two packages. Fixed an issue that caused shaders containing HDRP string in their path to be stripped from the build. Fixed an issue that caused only selected object to render in SceneView when Wireframe drawmode was selected. Fixed Renderer Features UI tooltips. Case 1191901. Fixed multiple issues where Shader Graph shaders failed to build for XR in the Universal RP. Fixed an issue when using the 2D Renderer where some types of renderers would not be assigned the correct material. Fixed inconsistent lighting between the forward renderer and the deferred renderer, that was caused by a missing normalize operation on vertex normals on some speedtree shader variants. Fixed issue where XR Multiview failed to render when using URP Shader Graph Shaders Fixed lazy initialization with last version of ResourceReloader Fixed broken images in package documentation. Fixed an issue where viewport aspect ratio was wrong when using the Stretch Fill option of the Pixel Perfect Camera. case 1188695 Fixed an issue where setting a Normal map on a newly created material would not update. case 1197217 Fixed an issue where post-processing was not applied for custom renderers set to run on the \"After Rendering\" event case 1196219 Fixed an issue that caused an extra blit when using custom renderers case 1156741 Fixed an issue with transparent objects not receiving shadows when using shadow cascades. case 1116936 Fixed issue where using a ForwardRendererData preset would cause a crash. case 1201052 Fixed an issue where particles had dark outlines when blended together case 1199812 Fixed an issue with deleting shader passes in the custom renderer features list case 1201664 Fixed camera inverse view-projection matrix in XR mode, depth-copy and color-copy passes. Fixed an issue with the null check when UniversalRenderPipelineLightEditor.cs tries to access SceneView.lastActiveSceneView. Fixed an issue where the 'Depth Texture' drop down was incorrectly disabled in the Camera Inspector. Fixed an issue that caused errors if you disabled the VR Module when building a project. Fixed an issue where the default TerrainLit Material was outdated, which caused the default Terrain to use per-vertex normals instead of per-pixel normals. Fixed shader errors and warnings in the default Universal RP Terrain Shader. case 1185948 Fixed an issue where the URP Material Upgrader tried to upgrade standard Universal Shaders. case 1144710 Fixed an issue where some Materials threw errors when you upgraded them to Universal Shaders. case 1200938 Fixed issue where normal maps on terrain appeared to have flipped X-components when compared to the same normal map on a mesh. case 1181518 Fixed an issue where the editor would sometimes crash when using additional lights case 1176131 Fixed RemoveComponent on Camera contextual menu to not remove Camera while a component depend on it. Fixed an issue where right eye is not rendered to. case 1170619 Fixed issue where TerrainDetailLit.shader fails to compile when XR is enabled. Fixed an issue that allowed height-based blending on Terrains with more than 4 materials, which is not supported. Fixed an issue where opaque objects were outputting incorrect alpha values case 1168283 Fixed an issue where a depth texture was always created when post-processing was enabled, even if no effects made use of it. Fixed incorrect light attenuation on some platforms. Fixed an issue where the Volume System would not use the Cameras Transform when no Volume Trigger was set. Fixed an issue where post processing disappeared when using custom renderers and SMAA or no AA Fixed an issue where the 2D Renderer upgrader did not upgrade using the correct default material Fixed an issue with soft particles having dark blending when intersecting with scene geometry case 1199812 Fixed an issue with additive particles blending incorrectly case 1215713 Fixed an issue where camera preview window was missing in scene view. case 1211971 Fixed an issue with shadow cascade values were not readable in the render pipeline asset case 1219003 Fixed an issue where MSAA isn't applied until eye textures are relocated by changing their resolution. case 1197958 Fixed an issue where camera stacking didn't work properly inside prefab mode. case 1220509 Fixed the definition of mad() in SMAA shader for OpenGL. Fixed an issue where partical shaders failed to handle Single-Pass Stereo VR rendering with Double-Wide Textures. case 1201208 Fixed an issue that caused assets to be reimported if player prefs were cleared. case 1192259 Fixed missing Custom Render Features after Library deletion. case 1196338 Fixed not being able to remove a Renderer Feature due to tricky UI selection rects. case 1208113 Fixed an issue where the Camera Override on the Render Object Feature would not work with many Render Features in a row. case 1205185 Fixed UI clipping issue in Forward Renderer inspector. case 1211954 Fixed a Null ref when trying to remove a missing Renderer Feature from the Forward Renderer. case 1196651 Fixed data serialization issue when adding a Renderer Feature to teh Forward Renderer. case 1214779 Fixed issue with AssetPostprocessors dependencies causing models to be imported twice when upgrading the package version. Fixed an issue where NullReferenceException might be thrown when creating 2D Lights. case 1219374 Fixed an issue with a blurry settings icon. case 1201895 Fixed issue that caused the QualitySettings anti-aliasing changing without user interaction. case 1195272 Fixed an issue where Shader Graph shaders generate undeclared identifier 'GetWorldSpaceNormalizeViewDir' error. Fixed an issue where rendering into RenderTexture with Single Pass Instanced renders both eyes overlapping. Fixed an issue where Renderscale setting has no effect when using XRSDK. Fixed an issue where renderScale != 1 or Display.main.requiresBlitToBackbuffer forced an unnecessary blit on XR. Fixed an issue that causes double sRGB correction on Quest. case 1209292 Fixed an issue where terrain DepthOnly pass does not work for XR. Fixed an issue that caused depth texture to be flipped when sampling from shaders case 1225362 Fixed an issue with URP switching such that every avaiable URP makes a total set of supported features such that all URPs are taken into consideration. case 1157420 Fixed an issue where XR multipass repeatedly throws error messages \"Multi pass stereo mode doesn't support Camera Stacking\". Fixed an issue with shadows not appearing on terrains when no cascades were selected case 1226530 Fixed a shader issue that caused the Color in Sprite Shape to work improperly. Fixed an issue with URP switching such that every available URP makes a total set of supported features such that all URPs are taken into consideration. case 1157420 Metallic slider on the Lit shader is now linear meaning correct values are used for PBR. Fixed an issue where Post-Processing caused nothing to render on GLES2. Fixed an issue that causes viewport to not work correctly when rendering to textures. case 1225103 Fixed an issue that caused incorrect sampling of HDR reflection probe textures. Fixed UI text of RenderObjects feature to display LightMode tag instead of Shader Pass Name. case 1201696 Fixed an issue when Linear -> sRGB conversion would not happen on some Android devices. case 1226208 Fixed issue where using DOF at the same time as Dynamic Scaling, the depth buffer was smapled with incorrect UVs. case 1225467 Fixed an issue where an exception would be thrown when resetting the ShadowCaster2D component. case 1225339 Fixe an issue where using a Subtractive Blend Style for your 2D Lights might cause artifacts in certain post-processing effects. case 1215584 Fixed an issue where Cinemachine Pixel Perfect Extension didn't work when CinemachineBrain Update Method is anything other than Late Update. Fixed an issue where Sprite Shader Graph shaders weren't double-sided by default. Fixed an issue where particles using Sprite Shader Graph shaders were invisible. Fixed an issue where Scene objects might be incorrectly affected by 2D Lights from a previous Sorting Layer. Fixed an issue where errors would appear in the Console when entering Play Mode with a 2D Light selected in the Hierarchy. Case 1226918 Fixed an issue that caused Android GLES to render blank screen when Depth texture was enabled without Opaque texture case 1219325 Fixed an issue that caused transparent objects to always render over top of world space UI. case 1219877 Fixed issue causing sorting fudge to not work between shadergraph and urp particle shaders. case 1222762 Fixed shader compilation errors when using multiple lights in DX10 level GPU. case 1222302 Fixed an issue with shadows not being correctly calculated in some shaders. Fixed invalid implementation of one function in LWRP -> URP backward compatibility support. Fixed issue where maximum number of visible lights in C# code did not match maximum number in shader code on some platforms. Fixed OpenGL ES 3.0 support for URP ShaderGraph. case 1230890 Fixed an issue where multi edit camera properties didn't work. case 1230080 Fixed an issue where the emission value in particle shaders would not update in the editor without entering the Play mode. Fixed issues with performance when importing fbx files. Fixed issues with NullReferenceException happening with URP shaders. Fixed an issue that caused memory allocations when sorting cameras. case 1226448 Fixed an issue where grid lines were drawn on top of opaque objects in the preview window. Case 1240723. Fixed an issue where objects in the preview window were affected by layer mask settings in the default renderer. Case 1204376. Fixed an issue with reflections when using an orthographic camera case 1209255 Fixed issue that caused unity_AmbientSky, unity_AmbientEquator and unity_AmbientGround variables to be unintialized. Fixed issue that caused SHADERGRAPH_AMBIENT_SKY, SHADERGRAPH_AMBIENT_EQUATOR and SHADERGRAPH_AMBIENT_GROUND variables to be uninitialized. Fixed SceneView Draw Modes not being properly updated after opening new scene view panels or changing the editor layout. Fixed GLES shaders compilation failing on Windows platform (not a mobile platform) due to uniform count limit. Fixed an issue that caused the inverse view and projection matrix to output wrong values in some platforms. case 1243990 Fixed an issue where the Render Scale setting of the pipeline asset didn't properly change the resolution when using the 2D Renderer. case 1241537 Fixed an issue where 2D lights didn't respect the Camera's Culling Mask. case 1239136 Fixed broken documentation links for some 2D related components. Fixed an issue where Sprite shaders generated by Shader Graph weren't double-sided. case 1261232 Fixed an issue where the package would fail to compile if the Animation module was disabled. case 1227068 Fixed an issue where Stencil settings wasn't serialized properly in sub object case 1241218 Fixed an issue with not being able to remove Light Mode Tags case 1240895 Fixed an issue where preset button could still be used, when it is not supposed to. case 1246261 Fixed an issue where Model Importer Materials used the Standard Shader from the Built-in Render Pipeline instead of URP Lit shader when the import happened at Editor startup. Fixed an issue where only unique names of cameras could be added to the camera stack. Fixed issue that caused shaders to fail to compile in OpenGL 4.1 or below. Fixed an issue where camera stacking with MSAA on OpenGL resulted in a black screen. case 1250602 Optimized shader compilation times by compiling different variant sets for vertex and fragment shaders. Fixed shadows for additional lights by limiting MAX_VISIBLE_LIGHTS to 16 for OpenGL ES 2.0 and 3.0 on mobile platforms. case 1244391 Fixed Lit/SimpleLit/ParticlesLit/ParticlesSimpleLit/ParticlesUnlit shaders emission color not to be converted from gamma to linear color space. [case 1249615] Fixed missing unity_MatrixInvP for shader code and shaderGraph. Fixed XR support for deferred renderer. Fixing RenderObject to reflect name changes done at CustomForwardRenderer asset in project view. case 1246256 Fixing camera overlay stacking adding to respect unity general reference restrictions. case 1240788 Fixed profiler marker errors. case 1240963 Fixed issue that caused the pipeline to not create _CameraColorTexture if a custom render pass is injected. case 1232761 Fixed target eye UI for XR rendering is missing from camera inspector. case 1261612 Fixed an issue where terrain and speedtree materials would not get upgraded by upgrade project materials. case 1204189 Fixed an issue that caused renderer feature to not render correctly if the pass was injected before rendering opaques and didn't implement Configure method. case 1259750 Fixed an issue where postFX's temp texture is not released properly. Fixed an issue where ArgumentOutOfRangeException errors were thrown after removing Render feature case 1268147 Fixed an issue where depth and depth/normal of grass isn't rendered to depth texture. Fixed an issue that impacted MSAA performance on iOS/Metal case 1219054 Fixed an issue that caused a warning to be thrown about temporary render texture not found when user calls ConfigureTarget(0). case 1220871 Fixed performance issues in the C# shader stripper. [7.1.1] - 2019-09-05 Upgrade Guide The render pipeline now handles custom renderers differently. You must now set up renderers for the Camera on the Render Pipeline Asset. Render Pipeline Assets upgrades automatically and either creates a default forward renderer in your project or links the existing custom one that you've assigned. If you have custom renderers assigned to Cameras, you must now add them to the current Render Pipeline Asset. Then you can select which renderer to use on the Camera. Added Added shader function GetMainLightShadowParams. This returns a half4 for the main light that packs shadow strength in x component and shadow soft property in y component. Added shader function GetAdditionalLightShadowParams. This returns a half4 for an additional light that packs shadow strength in x component and shadow soft property in y component. Added a Debug Level option to the Render Pipeline Asset. With this, you can control the amount of debug information generated by the render pipeline. Added ability to set the ScriptableRenderer that the Camera renders with via C# using UniversalAdditionalCameraData.SetRenderer(int index). This maps to the Renderer List on the Render Pipeline Asset. Added shadow support for the 2D Renderer. Added ShadowCaster2D, and CompositeShadowCaster2D components. Added shadow intensity and shadow volume intensity properties to Light2D. Added new Gizmos for Lights. Added CinemachineUniversalPixelPerfect, a Cinemachine Virtual Camera Extension that solves some compatibility issues between Cinemachine and Pixel Perfect Camera. Added an option that disables the depth/stencil buffer for the 2D Renderer. Added manipulation handles for the inner cone angle for spot lights. Added documentation for the built-in post-processing solution and Volumes framework (and removed incorrect mention of the PPv2 package). Changed Increased visible lights limit for the forward renderer. It now supports 256 visible lights except in mobile platforms. Mobile platforms support 32 visible lights. Increased per-object lights limit for the forward renderer. It now supports 8 per-object lights in all platforms except GLES2. GLES2 supports 4 per-object lights. The Sprite-Lit-Default shader and the Sprite Lit Shader Graph shaders now use the vertex tangents for tangent space calculations. Temporary render textures for cameras rendering to render textures now use the same format and multisampling configuration as camera's target texture. All platforms now use R11G11B10_UFloat format for HDR render textures if supported. There is now a list of ScriptableRendererData on the Render Pipeline Asset as opposed to a renderer type. These are available to all Cameras and are included in builds. The renderer override on the Camera is now an enum that maps to the list of ScriptableRendererData on the Render Pipeline Asset. Pixel Perfect Camera now allows rendering to a render texture. Light2D GameObjects that you've created now have a default position with z equal to 0. Documentation: Changed the \"Getting Started\" section into \"Install and Configure\". Re-arranged the Table of Content. Fixed Fixed LightProbe occlusion contribution. case 1146667 Fixed an issue that caused a log message to be printed in the console when creating a new Material. case 1173160 Fixed an issue where OnRenderObjectCallback was never invoked. case 1122420 Fixed an issue where Sprite Masks didn't function properly when using the 2D Renderer. case 1163474 Fixed memory leaks when using the Frame Debugger with the 2D Renderer. Fixed an issue where materials using _Time did not animate in the scene. 1175396 Fixed an issue where the Particle Lit shader had artifacts when both soft particles and HDR were enabled. 1136285 Fixed an issue where the Area Lights were set to Realtime, which caused them to not bake. 1159838 Fixed an issue where the Disc Light did not generate any light. 1175097 Fixed an issue where the alpha was killed when an opaque texture was requested on an offscreen camera with HDR enabled case 1163320. Fixed an issue that caused Orthographic camera with far plane set to 0 to span Unity console with errors. case 1172269 Fixed an issue causing heap allocation in RenderPipelineManager.DoRenderLoop case 1156241 Fixed an issue that caused shadow artifacts when using large spot angle values case 1136165 Fixed an issue that caused self-shadowing artifacts when adjusting shadow near-plane on spot lights. Fixed an issue that caused specular highlights to disappear when the smoothness value was set to 1.0. case 1161827 Fixed an issue in the Material upgrader that caused transparent Materials to not upgrade correctly to Universal RP. case 1170419. Fixed an issue causing shadows to be incorrectly rendered when a light was close to the shadow caster. Fixed post-processing for the 2D Renderer. Fixed an issue in Light2D that caused a black line to appear for a 360 degree spotlight. Fixed a post-processing rendering issue with non-fullscreen viewport. case 1177660 Fixed an issue where Undo would not undo the creation of Additional Camera Data. case 1158861 Fixed an issue where selecting the same drop-down menu item twice would trigger a change event. case 1158861 Fixed an issue where selecting certain objects that use instancing materials would throw console warnings. case 1127324 Fixed a GUID conflict with LWRP. case 1179895 Fixed an issue where the Terrain shader generated NaNs. Fixed an issue that caused the Opaque Color pass to never render at half or quarter resolution. Fixed and issue where stencil state on a ForwardRendererData was reset each time rendering happened. [7.0.1] - 2019-07-25 Changed Platform checks now provide more helpful feedback about supported features in the Inspectors. Fixed Fixed specular lighting related artifacts on Mobile case 1143049 and case 1164822. Post-processing is no longer enabled in the previews. Unity no longer force-enables post-processing on a camera by default. Fixed an issue that caused the Scene to render darker in GLES3 and linear color space. case 1169789 [7.0.0] - 2019-07-17 Universal Render Pipeline LWRP has been renamed to the \"Universal Render Pipeline\" (UniversalRP). UniversalRP is the same as LWRP in terms of features and scope. Classes have moved to the Universal namespace (from LWRP). Upgrade Guide Upgrading to URP is designed to be almost seamless from the user side. LWRP package still exists, this forwards includes and classes to the UniversalRP Package. Please see the more involved upgrade guide (https://docs.google.com/document/d/1Xd5bZa8pYZRHri-EnNkyhwrWEzSa15vtnpcg--xUCIs/). Added Initial Stadia platform support. Added a menu option to create a new ScriptableRendererFeature script. To do so in the Editor, click on Asset > Create > Rendering > Lightweight Render Pipeline > Renderer Feature. Added documentation for SpeedTree Shaders in LWRP. Added extended features to LWRP Terrain Shader, so terrain assets can be forward-compatible with HDRP. Enabled per-layer advanced or legacy-mode blending in LWRP Terrain Shader. Added the documentation page \"Rendering in LWRP\", which describes the forward rendering camera loop. Added documentation overview for how Post Processing Version 2 works in LWRP. Added documentation notes and FAQ entry on the 2D Renderer affecting the LWRP Asset. Changed Replaced beginCameraRendering callbacks by non obsolete implementation in Light2D Updated ScriptableRendererFeature and ScriptableRenderPass API docs. Changed shader type Real to translate to FP16 precision on some platforms. Fixed Fixed a case where built-in Shader time values could be out of sync with actual time. case 1142495 Fixed an issue that caused forward renderer resources to not load properly when you upgraded LWRP from an older version to 7.0.0. case 1154925 Fixed GC spikes caused by LWRP allocating heap memory every frame. Fixed distortion effect on particle unlit shader. Fixed NullReference exception caused when trying to add a ScriptableRendererFeature. Fixed issue with certain LWRP shaders not showing when using forward/2D renderer. Fixed the shadow resolve pass and the final pass, so they're not consuming unnecessary bandwidth. case 1152439 Added missing page for 2D Lights in LWRP. Tilemap tiles no longer appear black when you use the 2D renderer. Sprites in the preview window are no longer lit by 2D Scene lighting. Fixed warnings for unsupported shadow map formats for GLES2 API. Disabled shadows for devices that do not support shadow maps or depth textures. Fixed support for LWRP per-pixel terrain. case 1110520 Fixed some basic UI/usability issues with LWRP terrain Materials (use of warnings and modal value changes). Fixed an issue where using LWRP and Sprite Shape together would produce meta file conflicts. Fixed specular calculation fp16 overflow on some platforms Fixed shader compilation errors for Android XR projects. Updated the pipeline Asset UI to cap the render scale at 2x so that it matches the render pipeline implementation limit. [6.7.0] - 2019-05-16 Added Added SpeedTree Shaders. Added two Shader Graph master nodes: Lit Sprite and Unlit Sprite. They only work with the 2D renderer. Added documentation for the 2D renderer. Changed The 2D renderer and Light2D component received a number of improvements and are now ready to try as experimental features. Updated the Feature Comparison Table page to reflect the current state of LWRP features. Fixed When in playmode, the error 'Non matching Profiler.EndSample' no longer appears. case 1140750 LWRP Particle Shaders now correctly render in stereo rendering modes. case 1106699 Shaders with 'debug' in the name are no longer stripped automatically. case 1112983 Fixed tiling issue with selection outline and baked cutout shadows. in the Shadergraph Unlit Master node, Premultiply no longer acts the same as Alpha. case 1114708 Fixed an issue where Lightprobe data was missing if it was needed per-pixel and GPU instancing was enabled. The Soft ScreenSpaceShadows Shader variant no longer gets stripped form builds. case 1138236 Fixed a typo in the Particle Unlit Shader, so Soft Particles now work correctly. Fixed emissive Materials not being baked for some meshes. case 1145297 Camera matrices are now correctly set up when you call rendering functions in EndCameraRendering. case 1146586 Fixed GI not baking correctly while in gamma color space. Fixed a NullReference exception when adding a renderer feature that is contained in a global namespace. case 1147068 Shaders are now set up for VR stereo instancing on Vulkan. case 1142952. VR stereo matrices and vertex inputs are now set up on Vulkan. case 1142952. Fixed the Material Upgrader so it's now run upon updating the LWRP package. 1148764 Fixed a NullReference exception when you create a new Lightweight Render Pipeline Asset. case 1153388 [6.6.0] - 2019-04-01 Added Added support for Baked Indirect mixed lighting. You can now use Light Probes for occlusion. This means that baked lights can now occlude dynamic objects. Added RenderObjects. You can add RenderObjects to a Renderer to perform custom rendering. (WIP) Added an experimental 2D renderer that implements a 2D lighting system. (WIP) Added a Light2D component that works with the 2D renderer to add lighting effects to 2D sprites. Fixed Fixed a project import issue in the LWRP template. Fixed the warnings that appear when you create new Unlit Shader Graphs using the Lightweight Render Pipeline. Fixed light attenuation precision on mobile platforms. Fixed split-screen rendering on mobile platforms. Fixed rendering when using an off-screen camera that renders to a depth texture. Fixed the exposed stencil render state in the renderer. Fixed the default layer mask so it's now applied to a depth pre-pass. Made several improvements and fixes to the render pass UI. Fixed artifacts that appeared due to precision errors in large scaled objects. Fixed an XR rendering issue where Unity required a depth texture. Fixed an issue that caused transparent objects to sort incorrectly. [6.5.0] - 2019-03-07 Added You can now create a custom forward renderer by clicking on Assets/Create/Rendering/Lightweight Render Pipeline/Forward Renderer. This creates an Asset in your Project. You can add additional features to it and drag-n-drop the renderer to either the pipeline Asset or to a camera. You can now add ScriptableRendererFeature to the ScriptableRenderer to extend it with custom effects. A feature is an ScriptableObject that can be drag-n-dropped in the renderer and adds one or more ScriptableRenderPass to the renderer. ScriptableRenderer now exposes interface to configure lights. To do so, implement SetupLights when you create a new renderer. ScriptableRenderer now exposes interface to configure culling. To do so, implement SetupCullingParameters when you create a new renderer. ScriptableRendererData contains rendering resources for ScriptableRenderer. A renderer can be overridden globally for all cameras or on a per-camera basis. ScriptableRenderPass now has a RenderPassEvents. This controls where in the pipeline the render pass is added. ScriptableRenderPass now exposes ConfigureTarget and ConfigureClear. This allows the renderer to automatically figure out the currently active rendering targets. ScriptableRenderPass now exposes Blit. This performs a blit and sets the active render target in the renderer. ScriptableRenderPass now exposes RenderPostProcessing. This renders post-processing and sets the active render target in the renderer. ScriptableRenderPass now exposes CreateDrawingSettings as a helper for render passes that need to call ScriptableRenderContext.DrawRenderers. Changed Removed RegisterShaderPassName from ScriptableRenderPass. Instead, CreateDrawingSettings now takes one or a list of ShaderTagId. Removed remaining experimental namespace from LWRP. All APIrelated to ScriptableRenderer, ScriptableRenderPass, and render pass injection is now out of preview. Removed SetRenderTarget from ScriptableRenderPass. You should never call it. Instead, call ConfigureTarget, and the renderer automatically sets up targets for you. Removed RenderFullscreenQuad from ScriptableRenderer. Use CommandBuffer.DrawMesh and RenderingUtils.fullscreenMesh instead. Removed RenderPostProcess from ScriptableRenderer. Use ScriptableRenderPass.RenderPostProcessing instead. Removed postProcessingContext property from ScriptableRenderer. This is now exposed in RenderingUtils.postProcessingContext. Removed GetCameraClearFlag from ScriptableRenderer. Fixed Fixed y-flip in VR when post-processing is active. Fixed occlusion mesh for VR not rendering before rendering opaques. Enabling or disabling SRP Batcher in runtime works now. Fixed video player recorder when post-processing is enabled. [6.4.0] - 2019-02-21 [6.3.0] - 2019-02-18 [6.2.0] - 2019-02-15 Changed Code refactor: all macros with ARGS have been swapped with macros with PARAM. This is because the ARGS macros were incorrectly named. [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Added You can now implement a custom renderer for LWRP. To do so, implement an IRendererData that contains all resources used in rendering. Then create an IRendererSetup that creates and queues ScriptableRenderPass. Change the renderer type either in the Pipeline Asset or in the Camera Inspector. LWRP now uses the Unity recorder extension. You can use this to capture the output of Cameras. You can now inject a custom render pass before LWRP renders opaque objects. To do so, implement an IBeforeRender interface. Distortion support in all Particle Shaders. An upgrade system for LWRP Materials with MaterialPostprocessor. An upgrade path for Unlit shaders Tooltips for Shaders. SRP Batcher support for Particle Shaders. Docs for these Shaders: Baked Lit, Particles Lit, Particles Simple Lit, and Particles Unlit. LWRP now supports dynamic resolution scaling. The target platform must also support it. LWRP now includes version defines for both C# and Shaders in the format of LWRP_X_Y_Z_OR_NEWER. For example, LWRP_5_3_0_OR_NEWER defines version 5.3.0. The Terrain Lit Shader now samples Spherical Harmonics if you haven't baked any lightmaps for terrain. Added a Priority option, which you can use to tweak the rendering order. This is similar to render queue in the built-in render pipeline. These Shaders now have this option: Lit, Simple Lit, Baked Lit, Unlit, and all three Particle Shaders. Added support for overriding terrain detail rendering shaders, via the render pipeline editor resources asset. Changed You can now only initialize a camera by setting a Background Type. The supported options are Skybox, Solid Color, and Don't Care. LWRP now uses non-square shadowmap textures when it renders directional shadows with 2 shadow cascades. LWRP now uses RGB111110 as the HDR format on mobile devices, when this format is supported. Removed IAfterDepthPrePass interface. We’ve redesigned the Shader GUI. For example, all property names in Shaders are now inline across the board The Simple Lit Shader now has Smoothness, which can be stored in the alpha of specular or albedo maps. The Simple Lit and Particles Simple Lit Shaders now take shininess from the length (brightness) of the specular map. The Double sided property is now Render Face. This means you can also do front face culling. Changed the docs for Lit Shader, Simple Lit Shader and Unlit Shader according to Shader GUI changes. When you create a new LWRP Asset, it will now be initialized with settings that favor performance on mobile platforms. Updated the FAQ section and the Built-in/LWRP feature comparison table. Fixed Several tweaks to reduce bandwidth consumption on mobile devices. The foldouts in the Lightweight Asset inspector UI now remember their state. Added missing meta file for GizmosRenderingPass.cs. Fixed artifacts when using multiple or Depth Only cameras. Case 1072615 Fixed a typo in ERROR_ON_UNSUPPORTED_FUNCTION() that was causing the shader compiler to run out of memory in GLES2. Case 1104271 LWRP now renders shadows on scaled objects correctly. Case 1109017 LWRP now allows some Asset settings to be changed at runtime. Case 1105552 Realtime shadows now work in GLES2. Case 1087251 Framedebugger now renders correctly when stepping through drawcalls. Cameras that request MSAA and Opaque Textures now use less frame bandwidth when they render. Fixed rendering in the gamma color space, so it doesn't appear darker. Particles SImple Lit and Particles Unlit Shaders now work correctly. Soft Particles now work correctly. Camera fading for particles. Fixed a typo in the Unlit IgnoreProjector tag. Particles render in both eyes with stereo instancing Fixed specular issues on mobile. case 1109017 Fixed issue causing LWRP to create MSAA framebuffer even when MSAA setting was disabled. Post-processing in mobile VR is now forced to be disabled. It was causing many rendering issues. Fixed Editor Previews breaking in Play Mode when VR is enabled. Case 1109009 A camera's HDR enable flag is now respected when rendering in XR. Terrain detail rendering now works correctly when LWRP is installed but inactive. [5.2.0] - 2018-11-27 Added LWRP now handles blits that are required by the device when rendering to the backbuffer. You can now enable the SRP Batcher. To do so, go to the Pipeline Asset. Under Advanced, toggle SRP Batcher. Changed Renamed shader variable unity_LightIndicesOffsetAndCount to unity_PerObjectLightData. Shader variables unity_4LightIndices0 and unity_4LightIndices1 are now declared as unity_PerObjectLightIndices array. [5.1.0] - 2018-11-19 Added The user documentation for LWRP is now in this GitHub repo, instead of in the separate GitHub wiki. You can find the most up-to-date pages in the TableOfContents.md file. Pages not listed in that file are still in progress. Changed The LWRP package is no longer in preview. LWRP built-in render passes are now internal. Changed namespace from UnityEngine.Experimental.Rendering.LightweightPipeline to UnityEngine.Rendering.LWRP. Changed namespace from UnityEditor.Experimental.Rendering.LightweightPipeline to UnityEditor.Rendering.LWRP. Fixed LWRP now respects the iOS Player setting Force hard shadows. When you enable this setting, hardware filtering of shadows is disabled. Scene view mode now renders baked lightmaps correctly. Case 1092227 Shadow bias calculations are now correct for both Shader Graph and Terrain shaders. Blit shader now ignores culling. When you select Per Vertex option for Additional Lights, the Per Object Limit option is not greyed out anymore. When you change camera viewport height to values above 1.0, the Unity Editor doesn't freeze anymore. Case 1097497 When you use AR with LWRP, the following error message is not displayed in the console anymore: \"The camera list passed to the render pipeline is either null or empty.\" [5.0.0-preview] - 2018-09-28 Added Added occlusion mesh rendering/hookup for VR You can now configure default depth and normal shadow bias values in the pipeline asset. You can now add the LWRPAdditionalLightData component to a Light to override the default depth and normal shadow bias. You can now log the amount of shader variants in your build. To do so, go to the Pipeline Asset. Under Advanced, select and set the Shader Variant Log Level. Changed Removed the supportedShaderFeatures property from LWRP core. The shader stripper now figures out which variants to strip based on the current assigned pipeline Asset in the Graphics settings. Fixed The following error does not appear in console anymore: (\"Begin/End Profiler section mismatch\") When you select a material with the Lit shader, this no longer causes the following error in the console: (\"Material doesn't have...\"). case 1092354 In the Simple Lit shader, per-vertex additional lights are now shaded properly. Shader variant stripping now works when you're building a Project with Cloud Build. This greatly reduces build times from Cloud Build. Dynamic Objects now receive lighting when the light mode is set to mixed. MSAA now works on Desktop platforms. The shadow bias value is now computed correctly for shadow cascades and different shadow resolutions. case 1076285 When you use Area Light with LWRP, Cast Shadows no longer overlaps with other UI elements in the Inspector. case 1085363 Changed Read/write XRGraphicsConfig -> Read-only XRGraphics interface to XRSettings. [4.0.0-preview] - 2018-09-28 Added When you have enabled Gizmos, they now appear correctly in the Game view. Added requiresDepthPrepass field to RenderingData struct to tell if the runtime platform requires a depth prepass to generate a camera depth texture. The RenderingData struct now holds a reference to CullResults. When HDR is enabled in the Camera but disabled in the Asset, an information box in the Camera Inspector informs you about it. When MSAA is enabled in the Camera but disabled in the Asset, an information box in the Camera Inspector informs you about it. Enabled instancing on the terrain shader. Sorting of opaque objects now respects camera opaqueSortMode setting. Sorting of opaque objects disables front-to-back sorting flag, when camera settings allow that and the GPU has hidden surface removal. LWRP now has a Custom Light Explorer that suits its feature set. LWRP now supports Vertex Lit shaders for detail meshes on terrain. LWRP now has three interactive Autodesk shaders: Autodesk Interactive, Autodesk Interactive Masked and Autodesk Interactive Transparent. [Shader API] The GetMainLight and GetAdditionalLight functions can now compute shadow attenuation and store it in the new shadowAttenuation field in LightData struct. [Shader API] Added a VertexPositionInputs struct that contains vertex position in difference spaces (world, view, hclip). [Shader API] Added a GetVertexPositionInputs function to get an initialized VertexPositionInputs. [Shader API] Added a GetPerObjectLightIndex function to return the per-object index given a for-loop index. [Shader API] Added a GetShadowCoord function that takes a VertexPositionInputs as input. [ShaderLibrary] Added VertexNormalInputs struct that contains data for per-pixel normal computation. [ShaderLibrary] Added GetVertexNormalInputs function to return an initialized VertexNormalInputs. Changed The RenderingData struct is now read-only. ScriptableRendereralways performs a Clear before calling IRendererSetup::Setup. ScriptableRenderPass::Execute no longer takes CullResults as input. Instead, use RenderingDataas input, since that references CullResults. IRendererSetup_Setup no longer takes ScriptableRenderContext and CullResults as input. Shader includes are now referenced via package relative paths instead of via the deprecated shader export path mechanism https://docs.unity3d.com/2018.3/Documentation/ScriptReference/ShaderIncludePathAttribute.html. The LWRP Asset settings were re-organized to be more clear. Vertex lighting now controls if additional lights should be shaded per-vertex or per-pixel. Renamed all Local Lights nomenclature to Additional Lights. Changed shader naming to conform to our SRP shader code convention. [Shader API] Renamed SpotAttenuation function to AngleAttenuation. [Shader API] Renamed _SHADOWS_ENABLED keyword to _MAIN_LIGHT_SHADOWS [Shader API] Renamed _SHADOWS_CASCADE keyword to _MAIN_LIGHT_SHADOWS_CASCADE [Shader API] Renamed _VERTEX_LIGHTS keyword to _ADDITIONAL_LIGHTS_VERTEX. [Shader API] Renamed _LOCAL_SHADOWS_ENABLED to _ADDITIONAL_LIGHT_SHADOWS [Shader API] Renamed GetLight function to GetAdditionalLight. [Shader API] Renamed GetPixelLightCount function to GetAdditionalLightsCount. [Shader API] Renamed attenuation to distanceAttenuation in LightData. [Shader API] Renamed GetLocalLightShadowStrength function to GetAdditionalLightShadowStrength. [Shader API] Renamed SampleScreenSpaceShadowMap functions to SampleScreenSpaceShadowmap. [Shader API] Renamed MainLightRealtimeShadowAttenuation function to MainLightRealtimeShadow. [Shader API] Renamed light constants from Directional and Local to MainLight and AdditionalLights. [Shader API] Renamed GetLocalLightShadowSamplingData function to GetAdditionalLightShadowSamplingData. [Shader API] Removed OUTPUT_NORMAL macro. [Shader API] Removed lightIndex and substractiveAttenuation from LightData. [Shader API] Removed ComputeShadowCoord function. GetShadowCoord is provided instead. All LightweightPipeline references in API and classes are now named LightweightRenderPipeline. Files no longer have the Lightweight prefix. Renamed Physically Based shaders to Lit, ParticlesLit, and TerrainLit. Renamed Simple Lighting shaders to SimpleLit, and ParticlesSimpleLit. [ShaderLibrary] Renamed InputSurfacePBR.hlsl, InputSurfaceSimple.hlsl, and InputSurfaceUnlit to LitInput.hlsl, SimpleLitInput.hlsl, and UnlitInput.hlsl. These files were moved from the ShaderLibrary folder to theShaders. [ShaderLibrary] Renamed LightweightPassLit.hlsl and LightweightPassLitSimple.hlsl to LitForwardPass.hlsl and SimpleLitForwardPass.hlsl. These files were moved from the ShaderLibrary folder to Shaders. [ShaderLibrary] Renamed LightweightPassMetaPBR.hlsl, LightweightPassMetaSimple.hlsl and LighweightPassMetaUnlit to LitMetaPass.hlsl, SimpleLitMetaPass.hlsl and UnlitMetaPass.hlsl. These files were moved from the ShaderLibrary folder to Shaders. [ShaderLibrary] Renamed LightweightPassShadow.hlsl to ShadowCasterPass.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed LightweightPassDepthOnly.hlsl to DepthOnlyPass.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfaceTerrain.hlsl to TerrainLitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed LightweightPassLitTerrain.hlsl to TerrainLitPases.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed ParticlesPBR.hlsl to ParticlesLitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfacePBR.hlsl to LitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfaceUnlit.hlsl to UnlitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputBuiltin.hlsl to UnityInput.hlsl. [ShaderLibrary] Renamed LightweightPassMetaCommon.hlsl to MetaInput.hlsl. [ShaderLibrary] Renamed InputSurfaceCommon.hlsl to SurfaceInput.hlsl. [ShaderLibrary] Removed LightInput struct and GetLightDirectionAndAttenuation. Use GetAdditionalLight function instead. [ShaderLibrary] Removed ApplyFog and ApplyFogColor functions. Use MixFog and MixFogColor instead. [ShaderLibrary] Removed TangentWorldToNormal function. Use TransformTangentToWorld instead. [ShaderLibrary] Removed view direction normalization functions. View direction should always be normalized per pixel for accurate results. [ShaderLibrary] Renamed FragmentNormalWS function to NormalizeNormalPerPixel. Fixed If you have more than 16 lights in a scene, LWRP no longer causes random glitches while rendering lights. The Unlit shader now samples Global Illumination correctly. The Inspector window for the Unlit shader now displays correctly. Reduced GC pressure by removing several per-frame memory allocations. The tooltip for the the camera MSAA property now appears correctly. Fixed multiple C# code analysis rule violations. The fullscreen mesh is no longer recreated upon every call to ScriptableRenderer.fullscreenMesh. [3.3.0-preview] - 2018-01-01 Added Added callbacks to LWRP that can be attached to a camera (IBeforeCameraRender, IAfterDepthPrePass, IAfterOpaquePass, IAfterOpaquePostProcess, IAfterSkyboxPass, IAfterTransparentPass, IAfterRender) ###Changed Clean up LWRP creation of render textures. If we are not going straight to screen ensure that we create both depth and color targets. UNITY_DECLARE_FRAMEBUFFER_INPUT and UNITY_READ_FRAMEBUFFER_INPUT macros were added. They are necessary for reading transient attachments. UNITY_MATRIX_I_VP is now defined. Renamed LightweightForwardRenderer to ScriptableRenderer. Moved all light constants to _LightBuffer CBUFFER. Now _PerCamera CBUFFER contains all other per camera constants. Change real-time attenuation to inverse square. Change attenuation for baked GI to inverse square, to match real-time attenuation. Small optimization in light attenuation shader code. Fixed Lightweight Unlit shader UI doesn't throw an error about missing receive shadow property anymore. [3.2.0-preview] - 2018-01-01 Changed Receive Shadows property is now exposed in the material instead of in the renderer. The UI for Lightweight asset has been updated with new categories. A more clean structure and foldouts has been added to keep things organized. Fixed Shadow casters are now properly culled per cascade. (case 1059142) Rendering no longer breaks when Android platform is selected in Build Settings. (case 1058812) Scriptable passes no longer have missing material references. Now they access cached materials in the renderer.(case 1061353) When you change a Shadow Cascade option in the Pipeline Asset, this no longer warns you that you've exceeded the array size for the _WorldToShadow property. Terrain shader optimizations. [3.1.0-preview] - 2018-01-01 Fixed Fixed assert errors caused by multi spot lights Fixed LWRP-DirectionalShadowConstantBuffer params setting [3.0.0-preview] - 2018-01-01 Added Added camera additional data component to control shadows, depth and color texture. pipeline now uses XRSEttings.eyeTextureResolutionScale as renderScale when in XR. New pass architecture. Allows for custom passes to be written and then used on a per camera basis in LWRP Changed Shadow rendering has been optimized for the Mali Utgard architecture by removing indexing and avoiding divisions for orthographic projections. This reduces the frame time by 25% on the Overdraw benchmark. Removed 7x7 tent filtering when using cascades. Screenspace shadow resolve is now only done when rendering shadow cascades. Updated the UI for the Lighweight pipeline asset. Update assembly definitions to output assemblies that match Unity naming convention (Unity.*). Fixed Post-processing now works with VR on PC. Console platform compiler error Fixed VR multiview rendering by forcing MSAA to be off. There's a current issue in engine that breaks MSAA and Texture2DArray. Fixed UnityPerDraw CB layout GLCore compute buffer compiler error Occlusion strength not being applied on LW standard shaders CopyDepth pass is being called even when a depth from prepass is available GLES2 shader compiler error in IntegrationTests Can't set RenderScale and ShadowDistance by script VR Single Pass Instancing shadows Fixed compilation errors on platforms with limited XRSetting support. [2.0.0-preview] - 2018-01-01 Added Explicit render target load/store actions were added to improve tile utilization Camera opaque color can be requested on the pipeline asset. It can be accessed in the shader by defining a _CameraOpaqueTexture. This can be used as an alternative to GrabPass. Dynamic Batching can be enabled in the pipeline asset Pipeline now strips unused or invalid variants and passes based on selected pipeline capabilities in the asset. This reduces build and memory consuption on target. Shader stripping settings were added to pipeline asset Changed Pipeline Pipeline code is now more modular and extensible. A ForwardRenderer class is initialized by the pipeline with RenderingData and it's responsible for enqueueing and executing passes. In the future pluggable renderers will be supported. On mobile 1 directional light + up to 4 local lights (point or spot) are computed On other platforms 1 directional light + up to 8 local lights are computed Multiple shadow casting lights are supported. Currently only 1 directional + 4 spots light shadows. Shading Framework Directional Lights are always considered a main light in shader. They have a fast shading path with no branching and no indexing. GetMainLight() is provided in shader to initialize Light struct with main light shading data. Directional lights have a dedicated shadowmap for performance reasons. Shadow coord always comes from interpolator. MainLigthRealtimeShadowAttenuation(float4 shadowCoord) is provided to compute main light realtime shadows. Spot and Point lights are always shaded in the light loop. Branching on uniform and indexing happens when shading them. GetLight(half index, float3 positionWS) is provided in shader to initialize Light struct for spot and point lights. Spot light shadows are baked into a single shadow atlas. Shadow coord for spot lights is always computed on fragment. Use LocalLightShadowAttenuation(int lightIndex, float3 positionWS) to comppute realtime shadows for spot lights. Fixed Issue that was causing VR on Android to render black Camera viewport issues UWP build issues Prevent nested camera rendering in the pipeline [1.1.4-preview] - 2018-01-01 Added Terrain and grass shaders ported Updated materials and shader default albedo and specular color to midgrey. Exposed _ScaledScreenParams to shader. It works the same as _ScreenParams but takes pipeline RenderScale into consideration Performance Improvements in mobile Fixed SRP Shader library issue that was causing all constants to be highp in mobile shader error that prevented LWRP to build to UWP shader compilation errors in Linux due to case sensitive includes Rendering Texture flipping issue Standard Particles shader cutout and blending modes crash caused by using projectors issue that was causing Shadow Strength to not be computed on mobile Material Upgrader issue that caused editor to SoftLocks GI in Unlit shader Null reference in the Unlit material shader GUI [1.1.2-preview] - 2018-01-01 Changed Performance improvements in mobile Fixed Shadows on GLES 2.0 CPU performance regression in shadow rendering Alpha clip shadow issues Unmatched command buffer error message Null reference exception caused by missing resource in LWRP Issue that was causing Camera clear flags was being ignored in mobile [1.1.1-preview] - 2018-01-01 Added Added Cascade Split selection UI Added SHADER_HINT_NICE_QUALITY. If user defines this to 1 in the shader Lightweight pipeline will favor quality even on mobile platforms. Changed Shadowmap uses 16bit format instead of 32bit. Small shader performance improvements Fixed Subtractive Mode Shadow Distance does not accept negative values anymore [0.1.24] - 2018-01-01 Added Added Light abstraction layer on lightweight shader library. Added HDR global setting on pipeline asset. Added Soft Particles settings on pipeline asset. Ported particles shaders to SRP library Changed HDR RT now uses what format is configured in Tier settings. Refactored lightweight standard shaders and shader library to improve ease of use. Optimized tile LOAD op on mobile. Reduced GC pressure Reduced shader variant count by ~56% by improving fog and lightmap keywords Converted LW shader library files to use real/half when necessary. Fixed Realtime shadows on OpenGL Shader compiler errors in GLES 2.0 Issue sorting issues when BeforeTransparent custom fx was enabled. VR single pass rendering. Viewport rendering issues when rendering to backbuffer. Viewport rendering issues when rendering to with MSAA turned off. Multi-camera rendering. [0.1.23] - 2018-01-01 Added UI Improvements (Rendering features not supported by LW are hidden) Changed Shaders were ported to the new SRP shader library. Constant Buffer refactor to use new Batcher Shadow filtering and bias improved. Pipeline now updates color constants in gamma when in Gamma colorspace. Optimized ALU and CB usage on Shadows. Reduced shader variant count by ~33% by improving shadow and light classification keywords Default resources were removed from the pipeline asset. Fixed Fixed shader include path when using SRP from package manager. Fixed spot light attenuation to match Unity Built-in pipeline. Fixed depth pre-pass clearing issue. [0.1.12] - 2018-01-01 Added Standard Unlit shader now has an option to sample GI. Added Material Upgrader for stock Unity Mobile and Legacy Shaders. UI improvements Changed Realtime shadow filtering was improved. Fixed Fixed an issue that was including unreferenced shaders in the build. Fixed a null reference caused by Particle System component lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "The content is moved to the Unity Manual"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/api_index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/api_index.html",
    "title": "Universal Render Pipeline scripting API | Inventory System",
    "summary": "Universal Render Pipeline scripting API This is the documentation for the scripting APIs of the Universal Render Pipeline (URP) package. Note: URP is built on the Scriptable Render Pipeline (SRP) Core package, and uses some class types that you can only find in the SRP Core scripting API."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Documentation~/index.html",
    "title": "Universal Render Pipeline (URP) | Inventory System",
    "summary": "Universal Render Pipeline (URP) The scripting API documentation is available on this website. The user guide for URP in Unity 6 is in the Unity Manual."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.render-pipelines.universal copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@a55da47cc43f/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: FXAA3_11.h (renamed to FXAA3_11.hlsl) License Type: FXAA3_11.h License Copyright (c) 2014-2015, NVIDIA CORPORATION. All rights reserved. https://github.com/hghdev/NVIDIAGameWorks-GraphicsSamples/blob/master/samples/es3-kepler/FXAA/FXAA3_11.h Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of NVIDIA CORPORATION nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [1.0.1] - 2024-01-08 Fixed Fixed UUM-59879: MissingComponentException when no MeshFilter is attached to a Terrain tree game object. [1.0.0] - 2023-04-25 Added Initial package release"
  },
  "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/Documentation~/index.html",
    "title": "Unity Light Transport Library | Inventory System",
    "summary": "Unity Light Transport Library Contains shared code used for writing raytracing or pathtracing algorithms. This is a package intended for internal use and as such this package is currently not supported. A public version of the API will be published in a future Editor's release."
  },
  "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.rendering.light-transport copyright © 2023 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/THIRD PARTY NOTICES.html": {
    "href": "Library/PackageCache/com.unity.rendering.light-transport@9bd588f963c0/THIRD PARTY NOTICES.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: RadeonRays 4.1 License Type: MIT License https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK Copyright (c) 2021 Advanced Micro Devices, Inc. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Bullet Physics SDK License Type: zlib License The files in this repository are licensed under the zlib license, except for the files under 'Extras' and examples/ThirdPartyLibs. Bullet Continuous Collision Detection and Physics Library http://bulletphysics.org This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This notice may not be removed or altered from any source distribution. Component Name: Sobol sampler License Type: MIT License https://github.com/lgruen/sobol Copyright (c) 2023 Leonhard Gruenschloss Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.searcher@1e17ce91558d/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.searcher@1e17ce91558d/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [4.9.3] - 2025-01-06 Fixed a bug where spaces are removed when highlighted. Changed VisualSplitter to twoPaneSplitView and updated indentation [4.9.2] - 2022-02-22 Fixed a bug that stopped keyboard keys from affecting navigation and interaction with search results list, unless user explicitly focused/click on list using the mouse [1396759] [4.9.1] - 2021-10-05 Fixed a usability issue where in some cases searcher would suggest one collapsed category of results that user would have to manually expand anyway Fixed bug that caused incorrect search results with non whitespaced queries for nodes with spaces in their name and for subgraphs [1359158] Fixed bug that causes search results to not be visible sometimes in the searcher window [1366061] Fixed bug that causes exceptions to be thrown when using the up/down arrow keys with search list focused [1358016] Fixed bug that causes some searcher items to be irreversibly collapsed due to expand icon disappearing on collapsing those items [1366074] [4.9.0] - 2021-09-07 Remove Lucene API and dlls [4.8.0] - 2021-02-17 Added ability for clients of searcher window to filter and prioritize search results as they need Fixed bug that causes searcher window to prioritize categories over node entries of the same name [case 1304055] Fixed bug that causes searcher window to close when double-clicking a category [case 1302267] Fixed bug that causes searcher window to be offset too far when accounting for host window boundaries [4.7.1] - 2020-10-15 Fix Regex error during highlighting when the query contains a backslash Fix serialization depth warning caused by a property's backing field getting serialized [4.7.0] - 2020-08-11 Added Lucene.Net DLLs and first version of the LuceneDatabase [4.6.0] - 2020-07-27 Added support for multi-select, enabled via MultiSelectEnabled in the SearcherAdapter. [4.5.0] - 2020-07-15 Add support for displaying icons in SearcherItem. [4.4.0] - 2020-07-13 Add custom UserData field to SearcherItem. Add SearcherTreeUtility to create a SearcherItem tree from a flat list of paths. [4.3.1] - 2020-06-08 Fix bug that cause keyboard navigation to fail. [case 1253544] [4.3.0] - 2020-05-27 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.3.0-preview.tgz Bump minor version for synonyms. [4.2.0] - 2020-04-30 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.2.0-preview.tgz Bump to minor version for API validation. [4.1.1] - 2020-04-30 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.1.1-preview.tgz Add all children is now an adapter override. [4.1.0] - 2020-03-20 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.1.0-preview.tgz Improve matching algorithm Add a splitter between searcher and details panel Fix adding all children of matching expanded categories [4.0.9] - 2019-10-22 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.9-preview.tgz Update ListView API [4.0.8] - 2019-09-16 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.8-preview.tgz Made SearcherItem Name property virtual [4.0.7] - 2019-08-29 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.7-preview.tgz Fix bold fonts (case 1178374) case 1178373 and 1071573014: minor examples tweaks [4.0.6] - 2019-08-01 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.6-preview.tgz Fix bug where items were selected twice when using keyboard inputs [4.0.5] - 2019-07-26 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.5-preview.tgz Fix searcher look to match Northstar changes [4.0.4] - 2019-07-23 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.4-preview.tgz Change the default size when the searcher has a details panel [4.0.3] - 2019-06-11 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.3-preview.tgz Added ability to use capital letters in a search bar Bugfix: Search bar focus after the escape button pressed [4.0.2] - 2019-05-24 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.2-preview API Make Match() virtual again in SearcherDatabase [4.0.1] - 2019-04-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.1-preview Bugfix: [MacOs] Fix issue where the searcher moves on the top left corner while resizing/moving [4.0.0] - 2019-04-24 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.0-preview Cleanup for promotion to production [3.0.12] - 2019-04-17 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.12 API: Make SearcherField public again [3.0.11] - 2019-04-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.11 Fix all issues flagged by ReSharper [3.0.10] - 2019-03-26 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.10 fix CI [3.0.9] - 2019-03-24 Package: none Add Yamato CI config [3.0.8] - 2019-03-24 Package: none Bugfix: Autocomplete text was misaligned. [3.0.7] - 2019-02-28 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.7 API: Remove Experimental API reference. [3.0.6] - 2019-09-27 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.6 UI: Restyling API: Add public ctor to SearcherDatabase [3.0.5] - 2018-12-18 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.5 Bugfix: Focus search text field when window is displayed [3.0.4] - 2018-11-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.4 Trigger callback when an item is selected instead of when the details panel is displayed [3.0.3] - 2018-11-28 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.3 Add alignments [3.0.2] - 2018-11-22 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.2 Bugfix: Searcher autocomplete label now bold to match text input style [3.0.1] - 2018-11-20 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.1 Bugfix [3.0.0] - 2018-11-20 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.0 Restyling and move + resize [2.1.1] - 2018-11-12 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.1.1 Fix text input filtering [2.1.0] - 2018-11-05 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.1.0 UIElements compatibility update [2.0.6] - 2018-08-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.6-preview Add possibility to sort items [2.0.5] - 2018-08-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.5-preview Filtering fix [2.0.4] - 2018-08-08 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.4-preview Added hooks for analytics [2.0.3] - 2018-08-07 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.3-preview The matchFilter is now also applied at database initial setup time [2.0.2] - 2018-08-02 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.2-preview Added matchFilter delegate on SearcherDatabase to further control the match criteria [2.0.1] - 2018-07-13 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.1-preview Fixed Exception when a whitespace query is entered [2.0.0] - 2018-07-12 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.0-preview Created a base class for Databases, renamed SearcherDatabase to LuceneDatabase, add a brand new SearcherDatabase written from scratch [1.0.6] - 2018-06-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.6-preview hotfix for left arrow on a child that cannot be collapsed will select the parent feature [1.0.5] - 2018-06-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.5-preview fixed an draw issue when expanding and collapsing an item on a small list - issue #25 pressing left arrow on a child that cannot be collapsed will select the parent [1.0.4] - 2018-05-16 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.4-preview fixed compilation error with latest trunk (around styles.flex) added third party notices file [1.0.3] - 2018-05-03 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.3-preview window close due to focus loss will now trigger the selection callback with null fixed potential null ref exception in sample code [1.0.2] - 2018-04-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.2-preview removed AutoCompleter in favor of a more robust top-result based approach [1.0.1] - 2018-04-26 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.1-preview now showing children of matching items - issue #19 fixed completion scoring with multiple databases search results in general have been improved [1.0.0] - 2018-04-25 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.0-preview added basic tests - issue #18 added a README and documentation fixed Searcher.Search() not returning anything if query contained capital letters - issue #22 [0.1.3] - 2018-04-23 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.3-preview added ability to add a title to the Searcher window - feature #3 removed Searcher arrow and moved default display point to top-right corner - related issues #2, #12, #16 fixed lingering arrow when bring Searcher window up from Inspector - issue #2 fixed SearcherWindow.Show() to always take world space display location - issue #17 [0.1.2] - 2018-04-18 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.2-experimental fixed Searcher's list is visually cut off when closing a parent SearcherItem - issue #9 scroll to selected item/best result add parents field, do not autocomplete it, search using a multi phrase query, auto create the parents path in overwritePath() fixed window arrow being removed AFTER the target window repaint, leaving remnant arrwos sometimes - issue #6 fixed Null Ref Exception when getting the selected item of an empty listview. only get it if relevant fixed bug where child was not under parent in Searcher [0.1.1] - 2018-03-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.1-experimental Minor fixes for VisualScripting [0.1.0] - 2018-03-05 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.0-experimental This is the first release of Unity Package Searcher. General search window for use in the Editor. First target use is for GraphView node search."
  },
  "Library/PackageCache/com.unity.searcher@1e17ce91558d/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.searcher@1e17ce91558d/Documentation~/index.html",
    "title": "Searcher | Inventory System",
    "summary": "Searcher Disclaimer Currently, the API for the Searcher is not intended for public use. Using the API in external custom scripts or modifying the API is not recommended or supported at this time. The Searcher package adds a powerful search window to Unity's Graph View tools which lets you quickly find, select, and place items into the graph window. Features The Searcher window uses a tree view to display the available options and the categories they belong to. As you type, the Searcher makes predictions and provides auto-complete options for the item you might be trying to select. The Searcher also highlights the matching text in the tree view to help you quickly find what you're looking for. Some instances of the Searcher also provide inline documentation or notes in an extra window to the right of the item tree. Navigating the Searcher You can navigate through the Searcher with either your mouse or keyboard. Use your mouse to scroll through tree menu items. To expand or collapse tree menu items click on them, and double-click the item to make your selection. To navigate up and down the list of items with your keyboard, press the Up arrow key or Down arrow key. To expand tree menus, press the Right arrow key, and press the Left arrow key to collapse the tree menus. To make a selection of the highlighted item, press the Enter key."
  },
  "Library/PackageCache/com.unity.searcher@1e17ce91558d/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.searcher@1e17ce91558d/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Unity Companion Package License v1.0 (\"License\") com.unity.searcher copyright © 2019 Unity Technologies ApS Unity hereby grants to you a worldwide, non-exclusive, no-charge, and royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute the software that is made available with this License (\"Software\"), subject to the following terms and conditions: Unity Companion Use Only. Exercise of the license granted herein is limited to exercise for the creation, use, and/or distribution of applications, software, or other content pursuant to a valid Unity development engine software license (\"Engine License\"). That means while use of the Software is not limited to use in the software licensed under the Engine License, the Software may not be used for any purpose other than the creation, use, and/or distribution of Engine License-dependent applications, software, or other content. No other exercise of the license granted herein is permitted. No Modification of Engine License. Neither this License nor any exercise of the license granted herein modifies the Engine License in any way. Ownership & Grant Back to You. 3.1. You own your content. In this License, \"derivative works\" means derivatives of the Software itself--works derived only from the Software by you under this License (for example, modifying the code of the Software itself to improve its efficacy); “derivative works” of the Software do not include, for example, games, apps, or content that you create using the Software. You keep all right, title, and interest to your own content. 3.2. Unity owns its content. While you keep all right, title, and interest to your own content per the above, as between Unity and you, Unity will own all right, title, and interest to all intellectual property rights (including patent, trademark, and copyright) in the Software and derivative works of the Software, and you hereby assign and agree to assign all such rights in those derivative works to Unity. 3.3. You have a license to those derivative works. Subject to this License, Unity grants to you the same worldwide, non-exclusive, no-charge, and royalty-free copyright license to derivative works of the Software you create as is granted to you for the Software under this License. Trademarks. You are not granted any right or license under this License to use any trademarks, service marks, trade names, products names, or branding of Unity or its affiliates (\"Trademarks\"). Descriptive uses of Trademarks are permitted; see, for example, Unity’s Branding Usage Guidelines at https://unity3d.com/public-relations/brand. Notices & Third-Party Rights. This License, including the copyright notice above, must be provided in all substantial portions of the Software and derivative works thereof (or, if that is impracticable, in any other location where such notices are customarily placed). Further, if the Software is accompanied by a Unity \"third-party notices\" or similar file, you acknowledge and agree that software identified in that file is governed by those separate license terms. DISCLAIMER, LIMITATION OF LIABILITY. THE SOFTWARE AND ANY DERIVATIVE WORKS THEREOF IS PROVIDED ON AN \"AS IS\" BASIS, AND IS PROVIDED WITHOUT WARRANTY OF ANY KIND, WHETHER EXPRESS OR IMPLIED, INCLUDING ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND/OR NONINFRINGEMENT. IN NO EVENT SHALL ANY COPYRIGHT HOLDER OR AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES (WHETHER DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL, INCLUDING PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, AND BUSINESS INTERRUPTION), OR OTHER LIABILITY WHATSOEVER, WHETHER IN AN ACTION OF CONTRACT, TORT, OR OTHERWISE, ARISING FROM OR OUT OF, OR IN CONNECTION WITH, THE SOFTWARE OR ANY DERIVATIVE WORKS THEREOF OR THE USE OF OR OTHER DEALINGS IN SAME, EVEN WHERE ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. USE IS ACCEPTANCE and License Versions. Your receipt and use of the Software constitutes your acceptance of this License and its terms and conditions. Software released by Unity under this License may be modified or updated and the License with it; upon any such modification or update, you will comply with the terms of the updated License for any use of any of the Software under the updated License. Use in Compliance with Law and Termination. Your exercise of the license granted herein will at all times be in compliance with applicable law and will not infringe any proprietary rights (including intellectual property rights); this License will terminate immediately on any breach by you of this License. Severability. If any provision of this License is held to be unenforceable or invalid, that provision will be enforced to the maximum extent possible and the other provisions will remain in full force and effect. Governing Law and Venue. This License is governed by and construed in accordance with the laws of Denmark, except for its conflict of laws rules; the United Nations Convention on Contracts for the International Sale of Goods will not apply. If you reside (or your principal place of business is) within the United States, you and Unity agree to submit to the personal and exclusive jurisdiction of and venue in the state and federal courts located in San Francisco County, California concerning any dispute arising out of this License (\"Dispute\"). If you reside (or your principal place of business is) outside the United States, you and Unity agree to submit to the personal and exclusive jurisdiction of and venue in the courts located in Copenhagen, Denmark concerning any Dispute."
  },
  "Library/PackageCache/com.unity.searcher@1e17ce91558d/README.html": {
    "href": "Library/PackageCache/com.unity.searcher@1e17ce91558d/README.html",
    "title": "Searcher | Inventory System",
    "summary": "Searcher Use the Searcher package to quickly search a large list of items via a popup window. For example, use Searcher to find, select, and put down a new node in a graph. The Searcher package also includes samples and tests. Features Popup Window Placement Tree View Keyboard Navigation Quick Search Auto-Complete Match Highlighting Multiple Databases Quick Usage Example void OnMouseDown( MouseDownEvent evt ) { var items = new List<SearcherItem> { new SearcherItem( \"Books\", \"Description\", new List<SearcherItem>() { new SearcherItem( \"Dune\" ), } ) }; items[0].AddChild( new SearcherItem( \"Ender's Game\" ) ); SearcherWindow.Show( this, // this EditorWindow items, \"Optional Title\", item => { Debug.Log( item.name ); return /*close window?*/ true; }, evt.mousePosition ); } Installing the Package Open this file in your project: Packages/manifest.json Add this to the dependencies array (makes sure to change the version string to your current version): \"com.unity.searcher\": \"4.0.0-preview\" For example, if this it he only package you depend on, you should have something like this (makes sure to change the version string to your current version): { \"dependencies\": { \"com.unity.searcher\": \"4.0.0-preview\" } } Enabling the Samples and Tests Right now, it seems Samples and Tests only show for local packages, meaning you cloned this repo inside your Packages folder. Given you've done that, open this file in your project: Packages/manifest.json Add a testables list with the package name so you get something like this (makes sure to change the version string to your current version): { \"dependencies\": { \"com.unity.searcher\": \"4.0.0-preview\" }, \"testables\" : [ \"com.unity.searcher\" ] } You should see a new top-level menu called Searcher and you should see Searcher tests in Test Runner. Searcher Creation from Database var bookItems = new List<SearcherItem> { new SearcherItem( \"Books\" ) }; var foodItems = new List<SearcherItem> { new SearcherItem( \"Foods\" ) }; // Create databases. var databaseDir = Application.dataPath + \"/../Library/Searcher\"; var bookDatabase = SearcherDatabase.Create( bookItems, databaseDir + \"/Books\" ); var foodDatabase = SearcherDatabase.Create( foodItems, databaseDir + \"/Foods\" ); // At a later time, load database from disk. bookDatabase = SearcherDatabase.Load( databaseDir + \"/Books\" ); var searcher = new Searcher( new SearcherDatabase[]{ foodDatabase, bookDatabase }, \"Optional Title\" ); Popup Window or Create Control Searcher m_Searcher; void OnMouseDown( MouseDownEvent evt ) { // Popup window... SearcherWindow.Show( this, m_Searcher, item => { Debug.Log( item.name ); return /*close window?*/ true; }, evt.mousePosition ); } // ...or create SearcherControl VisualElement void OnEnable() { // ...or create SearcherControl VisualElement var searcherControl = new SearcherControl(); searcherControl.Setup( m_Searcher, item => Debug.Log( item.name ) ); this.GetRootVisualContainer().Add( searcherControl ); } Customize the UI via ISearcherAdapter public interface ISearcherAdapter { VisualElement MakeItem(); VisualElement Bind( VisualElement target, SearcherItem item, ItemExpanderState expanderState, string text ); string title { get; } bool hasDetailsPanel { get; } void DisplaySelectionDetails( VisualElement detailsPanel, SearcherItem o ); void DisplayNoSelectionDetails( VisualElement detailsPanel ); void InitDetailsPanel( VisualElement detailsPanel ); } var bookDatabase = SearcherDatabase.Load( Application.dataPath + \"/Books\" ); var myAdapter = new MyAdapter(); // class MyAdapter : ISearcherAdapter var searcher = new Searcher( bookDatabase, myAdapter ); Technical details Requirements This version of Searcher is compatible with the following versions of the Unity Editor: 2019.1 and later (recommended) Known limitations Searcher version 1.0 includes the following known limitations: Only works with .Net 4.0 Package contents The following table indicates the main folders of the package: Location Description Editor/Resources Contains images used in the UI. Editor/Searcher Contains Searcher source files. Samples Contains the samples. Tests Contains the tests."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package are documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [17.0.3] - 2025-02-13 This version is compatible with Unity 6000.0.39f1. Changed Removed duplicate LIGHTMAP_ON and DIRLIGHTMAP_COMBINED variants when generating shaders for builtin-deferred. Added a new set of sample content - Shader Graph UGUI Shaders - to the Shader Graph package that contains examples of how to use the new Canvas target in Shader Graph to create dynamic UI elements. This new sample can be imported from the Sample tab of the Package Manager after selecting the Shader Graph package Fixed Added an issue where convert-to subgraph would sometimes result in an exception. Added an issue where the GI Node would only display correctly after deserialization. Added support for perceptual color mode for gradients in shader graph. Fixed an issue where an HDRP fullscreen shader graph imported into a URP project would fail to import under some circumstances. Fixed shader graph built-in pipeline variants not getting stripped when an SRP is active. Fixed an issue where moving a property node in a Shader Graph with no targets would log an error. Fixed an issue where the Custom Function node's \"Body\" field would expand off-screen instead of scrolling. Disallowed shader variant related settings to be set to negative values. Fixed a null reference exception when shader variant project settings were changed under certain circumstances. Fixed an issue where the Graph Inspector would not update after changing a node's precision from the context menu. Fixed an issue where using a color picker would cause the main preview to display cyan until the color picker was closed. Fixed an issue where some keyboard shortcuts did not display with the correct alignment in context menus. Fixed an issue so users can no longer select 'Delete' for context blocks. Fixed identifier collision detection on properties. Added sticky note checks to the group shortcuts. Fixed node previews toggle shortcut. Fixed an issue in ShaderGraph where undoing changes to a property after modifying its value in the Graph Inspector would cause the property to become deselected. Fixed an issue in Shader Graph with an undeclared identifier error around foveated rendering area. Fixed a bug that Normal From Height node in a shader graph might return an invalid value when using 16-bit half precision. Fixed 'Objects are trying to be loaded during a domain backup' errors due to invalid serialization of some shader graphs. Changed the name displayed in a Graph inspector when a selected BlockNode has changed. Fixed an issue so that pasting an empty group positions it based on the cursor's location. Fixed an issue with low quality Graph Inspector and Open Shader Graph User Manual icons. Added padding to Shader Graph Preferences settings. Addressed an issue where precision mismatch could result in an asset failing to import. Fixed an issue that caused errors in the Feature Examples sample content for Shader Graph. Fixed the issue with NullReferenceException when updating a legacy node for second time through undo. Fixed an issue where a shader graph was reverted to its last saved state when entering Play Mode without saving changes. [Metal] Fix shader compilation errors due to Foveated Rendering when building URP 3D template. Fixed an issue where Unity pragmas were not used in files included by the Custom Function Node, and added a \"Use Pragmas\" toggle to enable/disable them as needed. Fixed an issue where the Main Light Direction node always returned 0 on the built-in render pipeline. Fixed an issue where the shader graph was not marked dirty when toggling checkboxes in its Graph Settings. Fixed missing documentation about the Custom Render Texture in Shader Graph. Fixed \"Shader error in 'ProBuilder6/Standard Vertex Color': 'PBRDeferredFragment'\" error logged in the console when compiling the shader. [17.0.2] - 2024-04-02 This version is compatible with Unity 6000.0.0b15. Changed Now all the nodes connected to the BaseColor block are taken into shader codegen when generating the picking pass, allowing custom picking-specific code to be included through custom function nodes. Fixed Fixed issue when selecting options on the HDRP Target's Material Type would result in an unexpected error. Fixed an issue where hotkeys would be caught by unfocused floating editor windows. Fixed an issue where unexpected slowdowns may occur after dependent saving subgraphs. Fixed an issue where unexpected slowdowns may occur after dependent saving subgraphs. [17.0.1] - 2023-12-21 This version is compatible with Unity 2023.3.0b2. Changed Added setting to Canvas and Sprite SubTargets to disable the color tinting, allowing users to override the color completely or use vertex color node to perform custom tinting. Added support for UV3 and UV4 for the Canvas SubTarget. Improved performance of undo/redo in large graphs. Improved clarity and behavior of blackboard properties when options are changed. Renamed \"Exposed\" to \"Show in Inspector.\" Removed Global/Local scope for Keyword properties, replacing them with an \"Is Overridable\" toggle. Improved corresponding option enablement to clarify behavior. Exposed a scope option for Texture3D, CubeMap, and Texture2D Array blackboard properties. Fixed Fixed an issue where value nodes might appear on undo/redo where property nodes would be. Addressed issue with main preview window failing to refresh. Fix an issue where sprite previews were not rendering. Fixed an issue where drag-out node creation would leave the editor unresponsive. Fixed an issue where InstanceID node did not give the correct values when the ShaderGraph is used with all Draw APIs such as Graphics.DrawMeshInstancedIndirect, Graphics.DrawMeshInstancedProcedural, Graphics.DrawProcedural, Graphics.DrawProceduralIndirect, their CommandBuffer counterparts and the equivalent RenderMesh and RenderPrimitive counterparts. Fixed an issue where an open asset inspector for subgraphs may mangle the json serialized representation for that subgraph asset. Fixed the ShaderGraph codegen when an InstanceID node is used in a graph with keywords. Fixed typos in the text of the the Node Reference samples. [17.0.0] - 2023-09-26 This version is compatible with Unity 2023.3.0a8. Added Added the new Node Reference sample pack which adds 146 reference assets to help users learn more about available nodes Changed Added a shader variant limit to the project settings, clarified the difference between the variant limit in user preferences. Updated toolbar UI. Fixed Fixed a regression where adding nodes in large graphs caused a major slowdown. [16.0.3] - 2023-07-04 This version is compatible with Unity 2023.3.0a1. Version Updated The version number for this package has increased due to a version update of a related graphics package. [16.0.2] - 2023-06-28 This version is compatible with Unity 2023.2.0a22. Fixed Fixed Texture Size node causing compilation error in the Fullscreen ShaderGraph target. [16.0.1] - 2023-05-23 This version is compatible with Unity 2023.2.0a17. Changed Reduced the import times of shadergraphs. Fixed Fixed an issue where the Gradient Noise Node was causing implicit truncation warnings. Fixed an issue where custom interpolator previews would provide erroneous results when connecting through a reroute node. Fixed an issue where the reroute node would sometimes show the wrong color for its appropriate inputs. Fixed an issue where the subgraph gradient blackboard properties could have naming conflicts with parent graphs. Fixed an issue where the view position of the graph editor would sometimes be forgotten when swapping between two open shadergraph editor windows. Improved blackboard property drag speed when reordering the blackboard. Made adjustments to flipbook node to avoid dropping frames on AMD GPU. Fixed parallax nodes so that they use the default UV Input Slot correctly. Corrected a regression in float preview properties not updating previews. Added an issue where multi-selection events would trigger when you right-click on blackboard items. Enabled ShaderGraph styles to be applied correctly when the system locale is set in Turks. Fixed clicking or dragging on a text field and clicking in the Graph Inspector performing the wrong actions. Fixed Rename action by double-clicking in Blackboard not working. [16.0.0] - 2023-03-22 This version is compatible with Unity 2023.2.0a9. Fixed Improved performance of disconnecting nodes in large graphs. Fixed a typo in the Hyperbolic Cosine Node in Shader Graph. Fixed a bug where the nodes could not be created after entering then exiting play mode. [15.0.3] - 2022-12-02 This version is compatible with Unity 2023.2.0a1. Fixed Fixed multiple memory leaks in ShaderGraph so that windows and view elements now dispose of resources properly. Fixed rare line-ending conflict in shader graph node templates when source control rewrites EOL markers. [15.0.2] - 2022-11-04 This version is compatible with Unity 2023.1.0a23. Changed Modified the AssetPostprocessor for Shader Graph so it now performs the majority of its work when a shader-related asset has been changed. Fixed Improved the stability of shadergraph imports when doing operations with the package manager. Fixed shader graph incorrectly stripping variants for BiRP shaders that weren't built with shader graph. Fixed Shader Graph BiRP Target so it now works correctly with point lights and transparent objects. Fixed unity_StereoEyeIndex error when building XR project with URP Fullscreen master node containing Shader. [15.0.1] - 2022-08-04 This version is compatible with Unity 2023.1.0a19. Changed Reduced time taken by code generation when a shader graph asset is imported. Fixed Fixed a compilation bug in BiRP Target in some variants with lightmaps. Fixed the TimeManager for MaterialVariant tests. [15.0.0] - 2022-06-13 This version is compatible with Unity 2023.1.0a6. Fixed Fixed shader graph incorrectly stripping variants for BiRP shaders that weren't built with shader graph. Fixed unity_StereoEyeIndex error when building XR project with URP Fullscreen master node containing Shader. [14.0.3] - 2021-05-09 Fixed Fixed the sample buffer nodes in ShaderGraph. Set the default value of Normalize Output toggle in Transform Node to true to make different node versions consistent. [14.0.2] - 2021-02-04 Fixed Fixed ShaderGraph pixel and screen coordinates to work correctly with render scale [1387468] [14.0.1] - 2021-12-07 Added Added mip sampling modes for 2d textures, 2d texture arrays and 3d textures Fixed Fixed broken documentation URL for block nodes. 1381488 Fixed SRP-batching when PVT stacks are bound per material by properly declaring properties for PVT stacks [1372152] Fixed custom editor GUI support for the BuiltIn Target 1380485 [14.0.0] - 2021-11-17 Fixed Fixed issue where Duplicating/Copy-Pasting last keyword in the blackboard throws an exception [1394378] Fixed an issue where some graphs with incorrectly formatted data would not display their shader inputs in the blackboard [1384315] Fixed bug with Shader Graph subwindows having their header text overflow when the window is resized smaller than the title [1378203] Gradient field doesn't support HDR values Case 1381867 Fixed the behavior of checkerboard node with raytracing Fixed broken documentation URL for block nodes. 1381488 Fixed an issue where edges connected to SubGraphNodes would sometimes get lost on upgrading a pre-targets graphs 1379996 Added Added mip sampling modes for 2d textures, 2d texture arrays and 3d textures [13.1.2] - 2021-11-05 Added Added ability to set \"Global\" or \"Per Material\" shader declaration in PVT node settings [1372152] Show PVT stack names (needed for binding) under the Properties in the Shader Inspector Fixed Fixed a recent regression in ShaderGraph Screen Position behavior on some platforms in Built-in, Universal and HDRP [1369450] [13.1.1] - 2021-10-04 Added Adding ability to automatically cast Bools to Vector types in ShaderGraph [1359160] Added ShaderGraph import warning to old nodes and properties, and ability to dismiss the warning if old behavior is desired. Added normal transforms to the Transform node Added an automatically generated material subasset on ShaderGraphs. Changed Changed the title suffix on old nodes and properties rom \"Deprecated\" to \"Legacy\". Updated searcher package dependency version to 4.9.1 Renamed the Shader Graph Texel Size node to Texture Size and added two additional output ports that actually output the texel size in addition to the texture size. Fixed Fixed a usability issue where in some cases searcher would suggest one collapsed category of results that user would have to manually expand anyway Fixed bug that causes search results to not be visible sometimes in the searcher window [1366061] Fixed bug that causes exceptions to be thrown when using the up/down arrow keys with search list focused [1358016] Fixed bug that causes some searcher items to be irreversibly collapsed due to expand icon disappearing on collapsing those items [1366074] Fixed bug that caused incorrect search results with non whitespaced queries for nodes with spaces in their name and for subgraphs [1359158] Fixed Triplanar ShaderGraph node to handle arbitrary input and output coordinate spaces [1346477] (https://issuetracker.unity3d.com/issues/shader-graph-rotating-gameobject-get-material-stretched-when-using-triplanar-node) Fixed a bug that Parallax Mapping and Parallax Occlusion Mapping nodes don't use the same channel to sample heightmap by adding drop-downs for channel selecting to both of the nodes. [1347270] (https://fogbugz.unity3d.com/f/cases/1347270/) Fixed errors in the ShaderGraph Transform node [1368082] Fixed the Scene Depth node so it returns proper results in Eye space when using an orthographic camera [1311272] Fixed a bug where node preview doesn't update when a texture is changed in the explorer 1363784 Fixed missing shader keyword stage during keyword copying. Fixed a ShaderGraph warning when connecting a node using Object Space BiTangent to the vertex stage [1361512] (https://issuetracker.unity3d.com/issues/shader-graph-cross-implicit-truncation-of-vector-type-errors-are-thrown-when-connecting-transform-node-to-vertex-block) Fixed upgrade warnings on SpeedTree8 subgraphs. [13.1.0] - 2021-09-24 Fixed Fixed bug where an exception was thrown on undo operation after adding properties to a category [1348910] (https://fogbugz.unity3d.com/f/cases/1348910/) Fixed the sticky-note editable title text size in shader graph not matching the set font size [1357657]. Fixed unhandled exception when loading a subgraph with duplicate slots [1366200] (https://issuetracker.unity3d.com/product/unity/issues/guid/1366200/) [13.0.0] - 2021-09-01 Changed Remove use of deprecated UNITY_USE_NATIVE_HDR keyword in shaders. Added Adding control of anisotropic settings on inline Sampler state nodes in ShaderGraph. Fixed Fixed bug where it was not possible to switch to Graph Settings tab in Inspector if multiple nodes and an edge was selected [1357648] (https://fogbugz.unity3d.com/f/cases/1357648/) Fixed an incorrect direction transform from view to world space [1362034] (https://issuetracker.unity3d.com/product/unity/issues/guid/1362034/) Fixed ShaderGraph HDRP master preview disappearing for a few seconds when graph is modified [1330289] (https://issuetracker.unity3d.com/issues/shadergraph-hdrp-main-preview-is-invisible-until-moved) Fixed noise nodes to use a deterministic integer hash, instead of platform dependent floating point hashes [1156544] Fixed the appearance (wrong text color, and not wrapped) of a warning in Node Settings [1356725] (https://issuetracker.unity3d.com/product/unity/issues/guid/1356725/) Fixed the ordering of inputs on a SubGraph node to match the properties on the blackboard of the subgraph itself [1354463] Added more inputs to the Parallax Occlusion Mapping node to handle non-uniformly scaled UVs such as HDRP/Lit POM [1347008]. Fixed the wrong scaling of the main preview window [1356719] (https://issuetracker.unity3d.com/product/unity/issues/guid/1356719/) Fixed an issue where ShaderGraph \"view shader\" commands were opening in individual windows, and blocking Unity from closing [1367188] Improved screenspace position accuracy in the fragment shader by using VPOS [1352662] (https://issuetracker.unity3d.com/issues/shadergraph-dither-node-results-in-artifacts-when-far-from-origin-caused-by-screen-position-breaking-down) Fixed the node searcher results to prefer names over synonyms [1366058] Fixed the sticky-note editable title text size in shader graph not matching the set font size [1357657]. Fixed how graph errors were displayed when variant limits were reached [1355815] [12.0.0] - 2021-01-11 Added Added categories to the blackboard, enabling more control over the organization of shader properties and keywords in the Shader Graph tool. These categories are also reflected in the Material Inspector for URP + HDRP, for materials created from shader graphs. Added ability to define custom vertex-to-fragment interpolators. Support for the XboxSeries platform has been added. Stereo Eye Index, Instance ID, and Vertex ID nodes added to the shadergraph library. Added information about selecting and unselecting items to the Blackboard article. Added View Vector Node documentation Added custom interpolator thresholds on shadergraph project settings page. Added custom interpolator documentation Added subshadergraphs for SpeedTree 8 shadergraph support: SpeedTree8Wind, SpeedTree8ColorAlpha, SpeedTree8Billboard. Added an HLSL file implementing a version of the Unity core LODDitheringTransition function which can be used in a Shader Graph Added a new target for the built-in render pipeline, including Lit and Unlit sub-targets. Added stage control to ShaderGraph Keywords, to allow fragment or vertex-only keywords. For Texture2D properties, added linearGrey and red as options for default texture mode. For Texture2D properties, changed the \"bump\" option to be called \"Normal Map\", and will now tag these properties with the [NormalMap] tag. Added Branch On Input Connection node. This node can be used inside a subgraph to branch on the connection state of an exposed property. Added Use Custom Binding option to properties. When this option is enabled, a property can be connected to a Branch On Input Connection node. The user provides a custom label that will be displayed on the exposed property, when it is disconnected in a graph. Added new dropdown property type for subgraphs, to allow compile time branching that can be controlled from the parent graph, via the subgraph instance node. Added Dropdown node per dropdown property, that can be used to configure the desired branch control. Added selection highlight and picking shader passes for URP target. Added the ability to mark textures / colors as [MainTexture] and [MainColor]. Added the ability to enable tiling and offset controls for a Texture2D input. Added the Split Texture Transform node to allow using/overriding the provided tiling and offset from a texture input. Added Calculate Level Of Detail Texture 2D node, for calculating a Texture2D LOD level. Added Gather Texture 2D node, for retrieving the four samples (red component only) that would be used for bilinear interpolation when sampling a Texture2D. Added toggle \"Disable Global Mip Bias\" in Sample Texture 2D and Sample Texture 2D array node. This checkbox disables the runtimes automatic Mip Bias, which for instance can be activated during dynamic resolution scaling. Added Sprite option to Main Preview, which is similar to Quad but does not allow rotation. Sprite is used as the default preview for URP Sprite shaders. Added Tessellation Option to PositionNode settings, to provide access to the pre-displaced tessellated position. Added visible errors for invalid stage capability connections to shader graph. Added a ShaderGraph animated preview framerate throttle. Added many node synonyms for the Create Node search so that it's easier to find nodes. Changed Properties and Keywords are no longer separated by type on the blackboard. Categories allow for any combination of properties and keywords to be grouped together as the user defines. Vector2/Vector3/Vector4 property types will now be properly represented by a matching Vector2/Vector3/Vector4 UI control in the URP + HDRP Material Inspector as opposed to the fallback Vector4 field that was used for any multi-dimensional vector type in the past. Updated/corrected View Direction documentation Change Asset/Create/Shader/Blank Shader Graph to Asset/Create/Shader Graph/Blank Shader Graph Change Asset/Create/Shader/Sub Graph to Asset/Create/Shader Graph/Sub Graph Change Asset/Create/Shader/VFX Shader Graph to Asset/Create/Shader Graph/VFX Shader Graph Adjusted Blackboard article to clarify multi-select functionality Limited max number of inspectable items in the Inspector View to 20 items Added borders to inspector items styling, to better differentiate between separate items Updated Custom Function Node to use new ShaderInclude asset type instead of TextAsset (.hlsl and .cginc softcheck remains). Change BranchOnInputNode to choose NotConnected branch when generating Preview Only ShaderGraph keywords count towards the shader permutation variant limit, SubGraph keywords do not. ShaderGraph SubGraphs will now report errors and warnings in a condensed single error. Changed \"Create Node\" action in ShaderGraph stack separator context menu to \"Add Block Node\" and added it to main stack context menu GatherTexture2D and TexelSize nodes now support all shader stages. Fixed Fixed an issue where fog node density was incorrectly calculated. Fixed inspector property header styling Added padding to the blackboard window to prevent overlapping of resize region and scrollbars interfering with user interaction Blackboard now properly handles selection persistence of items between undo and redos Fixed the Custom Editor GUI field in the Graph settings that was ignored. Node included HLSL files are now tracked more robustly, so they work after file moves and renames [1301915] (https://issuetracker.unity3d.com/product/unity/issues/guid/1301915/) Prevent users from setting enum keywords with duplicate reference names and invalid characters [1287335] Fixed a bug where old preview property values would be used for node previews after an undo operation. Clean up console error reporting from node shader compilation so errors are reported in the graph rather than the Editor console [1296291] (https://issuetracker.unity3d.com/product/unity/issues/guid/1296291/) Fixed treatment of node precision in subgraphs, now allows subgraphs to switch precisions based on the subgraph node [1304050] (https://issuetracker.unity3d.com/issues/precision-errors-when-theres-a-precision-discrepancy-between-subgraphs-and-parent-graphs) Fixed an issue where the Rectangle Node could lose detail at a distance. New control offers additional method that preserves detail better [1156801] Fixed virtual texture layer reference names allowing invalid characters [1304146] Fixed issue with SRP Batcher compatibility [1310624] Fixed issue with Hybrid renderer compatibility [1296776] Fixed ParallaxOcclusionMapping node to clamp very large step counts that could crash GPUs (max set to 256). [1329025] (https://issuetracker.unity3d.com/issues/shadergraph-typing-infinity-into-the-steps-input-for-the-parallax-occlusion-mapping-node-crashes-unity) Fixed an issue where the shader variant limit exceeded message was not getting passed [1304168] (https://issuetracker.unity3d.com/product/unity/issues/guid/1304168) Fixed a bug in master node preview generation that failed compilation when a block was deleted [1319066] (https://issuetracker.unity3d.com/issues/shadergraph-deleting-stack-blocks-of-universal-rp-targeted-shadergraph-causes-the-main-preview-to-fail-to-compile) Fixed issue where vertex generation was incorrect when only custom blocks were present [1320695]. Fixed a bug where property deduplication was failing and spamming errors [1317809] (https://issuetracker.unity3d.com/issues/console-error-when-adding-a-sample-texture-operator-when-a-sampler-state-property-is-present-in-blackboard) Fixed a bug where big input values to the SimpleNoise node caused precision issues, especially noticeable on Mali GPUs. [1322891] (https://issuetracker.unity3d.com/issues/urp-mali-missing-glitch-effect-on-mali-gpu-devices) Fixed a bug where synchronously compiling an unencountered shader variant for preview was causing long delays in graph updates [1323744] Fixed a regression where custom function node file-included functions could not access shadergraph properties [1322467] Fixed an issue where a requirement was placed on a fixed-function emission property [1319637] Fixed default shadergraph precision so it matches what is displayed in the graph settings UI (single) [1325934] Fixed an unhelpful error message when custom function nodes didn't have a valid file [1323493]. Fixed an issue with how the transform node handled direction transforms from absolute world space in camera relative SRPs [1323726] Fixed a bug where changing a Target setting would switch the inspector view to the Node Settings tab if any nodes were selected. Fixed \"Disconnect All\" option being grayed out on stack blocks [1313201]. Fixed how shadergraph's prompt for \"unsaved changes\" was handled to fix double messages and incorrect window sizes [1319623]. Fixed an issue where users can't create multiple Boolean or Enum keywords on the blackboard. 1329021 Fixed an issue where generated property reference names could conflict with Shader Graph reserved keywords [1328762] (https://issuetracker.unity3d.com/product/unity/issues/guid/1328762/) Fixed a ShaderGraph issue where ObjectField focus and Node selections would both capture deletion commands [1313943]. Fixed a ShaderGraph issue where the right click menu doesn't work when a stack block node is selected [1320212]. Fixed a bug when a node was both vertex and fragment exclusive but could still be used causing a shader compiler error [1316128]. Fixed a ShaderGraph issue where a warning about an uninitialized value was being displayed on newly created graphs [1331377]. Fixed divide by zero warnings when using the Sample Gradient Node Fixed the default dimension (1) for vector material slots so that it is consistent with other nodes. (https://issuetracker.unity3d.com/product/unity/issues/guid/1328756/) Fixed reordering when renaming enum keywords. (https://issuetracker.unity3d.com/product/unity/issues/guid/1328761/) Fixed an issue where an integer property would be exposed in the material inspector as a float 1330302 Fixed a bug in ShaderGraph where sticky notes couldn't be copied and pasted [1221042]. Fixed an issue where upgrading from an older version of ShaderGraph would cause Enum keywords to be not exposed [1332510] Fixed an issue where a missing subgraph with a \"Use Custom Binding\" property would cause the parent graph to fail to load [1334621] (https://issuetracker.unity3d.com/issues/shadergraph-shadergraph-cannot-be-opened-if-containing-subgraph-with-custom-binding-that-has-been-deleted) Fixed a ShaderGraph issue where unused blocks get removed on edge replacement [1334341]. Fixed an issue where the ShaderGraph transform node would generate incorrect results when transforming a direction from view space to object space [1333781] (https://issuetracker.unity3d.com/product/unity/issues/guid/1333781/) Fixed a ShaderGraph issue where keyword properties could get stuck highlighted when deleted [1333738]. Fixed issue with ShaderGraph custom interpolator node dependency ordering [1332553]. Fixed SubGraph SamplerState property defaults not being respected [1336119] Fixed an issue where nested subgraphs with identical SamplerState property settings could cause compile failures [1336089] Fixed an issue where SamplerState properties could not be renamed after creation [1336126] Fixed loading all materials from project when saving a ShaderGraph. Fixed issues with double prompts for \"do you want to save\" when closing Shader Graph windows [1316104]. Fixed a ShaderGraph issue where resize handles on blackboard and graph inspector were too small [1329247] (https://issuetracker.unity3d.com/issues/shadergraph-resize-bounds-for-blackboard-and-graph-inspector-are-too-small) Fixed a ShaderGraph issue where a material inspector could contain an extra set of render queue, GPU instancing, and double-sided GI controls. Fixed a Shader Graph issue where property auto generated reference names were not consistent across all property types [1336937]. Fixed a warning in ShaderGraph about BuiltIn Shader Library assembly having no scripts. Fixed ShaderGraph BuiltIn target not having collapsible foldouts in the material inspector [1339256]. Fixed GPU instancing support in Shadergraph [1319655] (https://issuetracker.unity3d.com/issues/shader-graph-errors-are-thrown-when-a-propertys-shader-declaration-is-set-to-hybrid-per-instance-and-exposed-is-disabled). Fixed indent level in shader graph target foldout (case 1339025). Fixed ShaderGraph BuiltIn target shader GUI to allow the same render queue control available on URP with the changes for case 1335795. Fixed ShaderGraph BuiltIn target not to apply emission in the ForwardAdd pass to match surface shader results [1345574]. (https://issuetracker.unity3d.com/product/unity/issues/guid/1345574/) Fixed Procedural Virtual Texture compatibility with SRP Batcher [1329336] (https://issuetracker.unity3d.com/issues/procedural-virtual-texture-node-will-make-a-shadergraph-incompatible-with-srp-batcher) Fixed an issue where SubGraph keywords would not deduplicate before counting towards the permutation limit [1343528] (https://issuetracker.unity3d.com/issues/shader-graph-graph-is-generating-too-many-variants-error-is-thrown-when-using-subgraphs-with-keywords) Fixed an issue where an informational message could cause some UI controls on the graph inspector to be pushed outside the window [1343124] (https://issuetracker.unity3d.com/product/unity/issues/guid/1343124/) Fixed a ShaderGraph issue where selecting a keyword property in the blackboard would invalidate all previews, causing them to recompile [1347666] (https://issuetracker.unity3d.com/product/unity/issues/guid/1347666/) Fixed the incorrect value written to the VT feedback buffer when VT is not used. Fixed ShaderGraph isNaN node, which was always returning false on Vulkan and Metal platforms. Fixed ShaderGraph sub-graph stage limitations to be per slot instead of per sub-graph node [1337137]. Disconnected nodes with errors in ShaderGraph no longer cause the imports to fail [1349311] (https://issuetracker.unity3d.com/issues/shadergraph-erroring-unconnected-node-causes-material-to-become-invalid-slash-pink) ShaderGraph SubGraphs now report node warnings in the same way ShaderGraphs do [1350282]. Fixed ShaderGraph exception when trying to set a texture to \"main texture\" [1350573]. Fixed a ShaderGraph issue where Float properties in Integer mode would not be cast properly in graph previews 1330302 Fixed a ShaderGraph issue where hovering over a context block but not its node stack would not bring up the incorrect add menu 1351733 Fixed the BuiltIn Target to perform shader variant stripping [1345580] (https://issuetracker.unity3d.com/product/unity/issues/guid/1345580/) Fixed incorrect warning while using VFXTarget Fixed a bug with Sprite Targets in ShaderGraph not rendering correctly in game view [1352225] Fixed compilation problems on preview shader when using hybrid renderer v2 and property desc override Hybrid Per Instance Fixed a serialization bug wrt PVT property flags when using subgraphs. This fixes SRP batcher compatibility. [11.0.0] - 2020-10-21 Added Changed Fixed Fixed an issue where nodes with ports on one side would appear incorrectly on creation [1262050] Fixed a broken link in the TOC to Main Preview Fixed an issue with the Gradient color picker displaying different values than the selected color. Fixed an issue where blackboard properties when dragged wouldn't scroll the list of properties to show the user more of the property list [1293632] Fixed an issue where, when blackboard properties were dragged and then the user hit the \"Escape\" key, the drag indicator would still be visible Fixed an issue where renaming blackboard properties through the Blackboard wouldn't actually change the underlying property name Fixed an issue where blackboard wasn't resizable from all directions like the Inspector and Main Preview Fixed an issue where deleting a property node while your mouse is over it leaves the property highlighted in the blackboard [1238635] Fixed an issue where Float/Vector1 properties did not have the ability to be edited using a slider in the Inspector like the other Vector types Fixed an issue with inactive node deletion throwing a superfluous exception. Fixed an issue where interpolators with preprocessors were being packed incorrectly. Fixed rounded rectangle shape not rendering correctly on some platforms. Fixed an issue where generated BuildVertexDescriptionInputs() produced an HLSL warning, \"implicit truncation of vector type\" 1299179 Fixed an issue on upgrading graphs with inactive Master Nodes causing null ref errors. 1298867 Fixed an issue with duplicating a node with the blackboard closed 1294430 Fixed an issue where ShaderGraph stopped responding after selecting a node after opening the graph with the inspector window hidden 1304501 Fixed the InputNodes tests that were never correct. These were incorrect tests, no nodes needed tochange. Fixed the ViewDirection Node in Tangent space's calculation to match how the transform node works [1296788] Fixed an issue where SampleRawCubemapNode were requiring the Normal in Object space instead of World space [1307962] Boolean keywords now have no longer require their reference name to end in _ON to show up in the Material inspector [1306820] (https://issuetracker.unity3d.com/product/unity/issues/guid/1306820/) Newly created properties and keywords will no longer use obfuscated GUID-based reference names in the shader code [1300484] Fixed ParallaxMapping node compile issue on GLES2 Fixed a selection bug with block nodes after changing tabs [1312222] Fixed some shader graph compiler errors not being logged [1304162]. Fixed a shader graph bug where the Hue node would have a large seam with negative values [1340849]. Fixed an error when using camera direction with sample reflected cube map [1340538]. Fixed ShaderGraph's FogNode returning an incorrect density when the fog setting was disabled [1347235]. [10.3.0] - 2020-11-03 Added Users can now manually control the preview mode of nodes in the graph, and subgraphs Changed Adjusted and expanded Swizzle Node article as reviewed by docs editorial.(DOC-2695) Adjusted docs for SampleTexture2D, SampleTexture2DLOD, SampleTexture2DArray, SampleTexture3D, SampleCubemap, SampleReflectedCubemap, TexelSize, NormalFromTexture, ParallaxMapping, ParallaxOcclusionMapping, Triplanar, Sub Graphs, and Custom Function Nodes to reflect changes to texture wire data structures. (DOC-2568) Texture and SamplerState types are now HLSL structures (defined in com.unity.render-pipelines.core/ShaderLibrary/Texture.hlsl). CustomFunctionNode use of the old plain types is supported, but the user should upgrade to structures to avoid bugs. The shader graph inspector window will now switch to the \"Node Settings\" tab whenever a property/node/other selectable item in the graph is clicked on to save the user a click Fixed Fixed an issue where shaders could be generated with CR/LF (\"\\r\\n\") instead of just LF (\"\\n\") line endings [1286430] Fixed Custom Function Node to display the name of the custom function. [1293575] Addressed C# warning 0649 generated by unassigned structure members Fixed using TexelSize or reading sampler states from Textures output from a Subgraph or Custom Function Node [1284036] Shaders using SamplerState types now compile with GLES2 (SamplerStates are ignored, falls back to Texture-associated sampler state) [1292031] Fixed an issue where the horizontal scrollbar at the bottom of the shader graph inspector window could not be used due to the resizing widget always taking priority over it Fixed an issue where the shader graph inspector window could be resized past the edges of the shader graph view Fixed an issue where resizing the shader graph inspector window sometimes had unexpected results Fixed Graph Inspector scaling that was allocating too much space to the labels [1268134] Fixed some issues with our Convert To Subgraph contextual menu to allow passthrough and fix inputs/outputs getting lost. Fixed issue where a NullReferenceException would be thrown on resetting reference name for a Shader Graph property Fixed an upgrade issue where old ShaderGraph files with a weird/bugged state would break on update to master stack [1255011] Fixed a bug where non-word characters in an enum keyword reference name would break the graph. 1270168 Fixed issue where a NullReferenceException would be thrown on resetting reference name for a Shader Graph property [10.2.0] - 2020-10-19 Added Changed Renamed the existing Sample Cubemap Node to Sample Reflected Cubemap Node, and created a new Sample Cubemap Node that samples cubemaps with a direction. Removed unnecessary HDRP constant declarations used by Material inspector from the UnityPerMaterial cbuffer [1285701] Virtual Texture properties are now forced to be Exposed, as they do not work otherwise [1256374] Fixed Fixed an issue where old ShaderGraphs would import non-deterministically, changing their embedded property names each import [1283800] Using the TexelSize node on a ShaderGraph texture property is now SRP batchable [1284029] Fixed an issue where Mesh Deformation nodes did not have a category color. 1227081 Fixed SampleTexture2DLOD node to return opaque black on unsupported platforms [1241602] ShaderGraph now detects when a SubGraph is deleted while being used by a SubGraph node, and displays appropriate errors [1206438] Fixed an issue where the Main Preview window rendered too large on small monitors during first open. [1254392] Fixed an issue where Block nodes using Color slots would not be automatically removed from the Master Stack. [1259794] Fixed an issue where the Create Node menu would not close when pressing the Escape key. [1263667] Fixed an issue with the Preview Manager not updating correctly when deleting an edge that was created with a node (dragging off an existing node slot) Fixed an issue where ShaderGraph could not read matrices from a Material or MaterialPropertyBlock while rendering with SRP batcher [1256374] Fixed an issue where user setting a property to not Exposed, Hybrid-Instanced would result in a non-Hybrid Global property [1285700] Fixed an issue with Gradient when it is used as expose parameters. Generated code was failing [1285640 ] Fixed the subgraph slot sorting function [1286805] Fixed Parallax Occlusion Mapping not working in sub graphs. 1221317 All textures in a ShaderGraph, even those not used, will now be pulled into an Exported Package [1283902] Fixed an issue where the presence of an HDRP DiffusionProfile property or node would cause the graph to fail to load when HDRP package was not present [1287904] Fixed an issue where unknown type Nodes (i.e. HDRP-only nodes used without HDRP package) could be copied, resulting in an unloadable graph [1288475] Fixed an issue where dropping HDRP-only properties from the blackboard field into the graph would soft-lock the graph [1288887] Fixed an issue using the sample gradient macros in custom function nodes, which was using a scalar value instead of a vector value for the gradients [1299830] [10.1.0] - 2020-10-12 Added Added parallax mapping node and parallax occlusion mapping node. Added the possibility to have multiple POM node in a single graph. Added better error feedback when SampleVirtualTexture nodes run into issues with the VirtualTexture property inputs Added ability for Shader Graph to change node behavior without impacting existing graphs via the “Allow Deprecated Nodes” Changed Added method chaining support to shadergraph collection API. Optimized ShaderSubGraph import dependencies to minimize unnecessary reimports when using CustomFunctionNode Changed UI names from Vector1 to Float Renamed Float precision to Single Cleaned up the UI to add/remove Targets The * in the ShaderGraph title bar now indicates that the graph has been modified when compared to the state it was loaded, instead of compared to what is on disk Cancelling a \"Save changes on Close?\" will now cancel the Close as well When attempting to Save and encountering a Read Only file or other exception, ShaderGraph will allow the user to retry as many times as they like Fixed Fixed a bug where ShaderGraph subgraph nodes would not update their slot names or order Fixed an issue where very old ShaderGraphs would fail to load because of uninitialized data 1269616 Fixed an issue where ShaderGraph previews didn't display correctly when setting a texture to \"None\" [1264932] Fixed an issue with the SampleVirtualTexture node in ShaderGraph, where toggling Automatic Streaming would cause the node to incorrectly display four output slots [1271618] Fixed an issue in ShaderGraph with integer-mode Vector1 properties throwing errors when the value is changed [1264930] Fixed a bug where ShaderGraph would not load graphs using Procedural VT nodes when the nodes were the project had them disabled [1271598] Fixed an issue where the ProceduralVT node was not updating any connected SampleVT nodes when the number of layers was changed [1274288] Fixed an issue with how unknown nodes were treated during validation Fixed an issue where ShaderGraph shaders did not reimport automatically when some of the included files changed [1269634] Fixed an issue where building a context menu on a dragging block node would leave it floating and undo/redo would result in a soft-lock Fixed an issue where ShaderGraph was logging error when edited in play mode [1274148]. Fixed a bug where properties copied over with their graph inputs would not hook up correctly in a new graph [1274306] Fixed an issue where renaming a property in the blackboard at creation would trigger an error. Fixed an issue where ShaderGraph shaders did not reimport automatically when missing dependencies were reintroduced [1182895] Fixed an issue where ShaderGraph previews would not show error shaders when the active render pipeline is incompatible with the shader [1257015] ShaderGraph DDX, DDY, DDXY, and NormalFromHeight nodes do not allow themselves to be connected to vertex shader, as the derivative instructions can't be used [1209087] When ShaderGraph detects no active SRP, it will still continue to render the master preview, but it will use the error shader [1264642] VirtualTexture is no longer allowed as a SubGraph output (it is not supported by current system) [1254483] ShaderGraph Custom Function Node will now correctly convert function and slot names to valid HLSL identifiers [1258832] Fixed an issue where ShaderGraph Custom Function Node would reorder slots when you modified them [1280106] Fixed Undo handling when adding or removing Targets from a ShaderGraph [1257028] Fixed an issue with detection of circular subgraph dependencies [1269841] Fixed an issue where subgraph nodes were constantly changing their serialized data [1281975] Modifying a subgraph will no longer cause ShaderGraphs that use them to \"reload from disk?\" [1198885] Fixed issues with ShaderGraph title bar not correctly displaying the modified status * [1282031] Fixed issues where ShaderGraph could discard modified data without user approval when closed [1170503] Fixed an issue where ShaderGraph file dependency gathering would fail to include any files that didn't exist Fixed issues with ShaderGraph detection and handling of deleted graph files Fixed an issue where the ShaderGraph was corrupting the translation cache Fixed an issue where ShaderGraph would not prompt the user to save unsaved changes after an assembly reload Fixed an issue with Position Node not automatically upgrading Fixed an issue where failing SubGraphs would block saving graph files using them (recursion check would throw exceptions) [1283425] Fixed an issue where choosing \"None\" as the default texture for a texture property would not correctly preview the correct default color [1283782] Fixed some bugs with Color Nodes and properties that would cause incorrect collorspace conversions [10.0.0] - 2019-06-10 Added Added the Internal Inspector which allows the user to view data contained in selected nodes and properties in a new floating graph sub-window. Also added support for custom property drawers to let you visualize any data type you like and expose it to the inspector. Added samples for Procedural Patterns to the package. You can now use the right-click context menu to delete Sticky Notes. You can now save your graph as a new Asset. Added support for vertex skinning when you use the DOTS animation package. You can now use the right-click context menu to set the precision on multiple selected nodes. You can now select unused nodes in your graph. When you start the Editor, Shader Graph now displays Properties in the Blackboard as collapsed. Updated the zoom level to let you zoom in further. Blackboard properties now have a Duplicate menu option. When you duplicate properties, Shader Graph maintains the order, and inserts duplicates below the current selection. When you convert a node to a Sub Graph, the dialog now opens up in the directory of the original graph that contained the node. If the new Sub Graph is outside this directory, it also remembers that path for the next dialog to ease folder navigation. If Unity Editor Analytics are enabled, Shader Graph collects anonymous data about which nodes you use in your graphs. This helps the Shader Graph team focus our efforts on the most common graph scenarios, and better understand the needs of our customers. We don't track edge data and cannot recreate your graphs in any form. The Create Node Menu now has a tree view and support for fuzzy field searching. When a Shader Graph or Sub Graph Asset associated with a open window has been deleted, Unity now displays a dialog that asks whether you would like to save the graph as a new Asset or close the window. Added a drop-down menu to the PBR Master Node that lets you select the final coordinate space of normals delivered from the fragment function. Added support for users to drag and drop Blackboard Properties from one graph to another. Breaking out GraphData validation into clearer steps. Added AlphaToMask render state. Added a field to the Master Nodes that overrides the generated shader's ShaderGUI, which determines how a Material that uses a Shader Graph looks. Added Redirect Nodes. You can now double-click an edge to add a control point that allows you to route edges around other nodes and connect multiple output edges. Added Compute Deformation Node to read deformed vertex data from Dots Deformations. Added new graph nodes that allow sampling Virtual Textures Shader Graph now uses a new file format that is much friendlier towards version control systems and humans. Existing Shader Graphs and will use the new format next time they are saved. Added 'Allow Material Override' option to the built-in target for shader graph. Changed Changed the Branch node so that it uses a ternary operator (Out = bool ? a : B) instead of a linear interpolate function. Copied nodes are now pasted at the cursor location instead of slightly offset from their original location. Error messages reported on Sub Graph output nodes for invalid previews now present clearer information, with documentation support. Updated legacy COLOR output semantic to SV_Target in pixel shader for compatibility with DXC. Updated the functions in the Normal From Height node to avoid NaN outputs. Changed the Voronoi Node algorithm to increase the useful range of the input values and to always use float values internally to avoid clipping. Changed the Reference Suffix of Keyword Enum entries so that you cannot edit them, which ensures that material keywords compile properly. Updated the dependent version of Searcher to 4.2.0. Added support for Linear Blend Skinning Node to Universal Render Pipeline. Moved all code to be under Unity specific namespaces. Changed ShaderGraphImporter and ShaderSubgraphImporter so that graphs are imported before Models. Remove VFXTarget if VisualEffect Graph package isn't included. VFXTarget doesn't overwrite the shader export anymore, VFXTarget can be active with another target. Fixed Edges no longer produce errors when you save a Shader Graph. Shader Graph no longer references the NUnit package. Fixed a shader compatibility issue in the SRP Batcher when you use a hybrid instancing custom variable. Fixed an issue where Unity would crash when you imported a Shader Graph Asset with invalid formatting. Fixed an issue with the animated preview when there is no Camera with animated Materials in the Editor. Triplanar nodes no longer use Camera-relative world space by default in HDRP. Errors no longer occur when you activate Enable GPU Instancing on Shader Graph Materials. 1184870 Errors no longer occur when there are multiple tangent transform nodes on a graph. 1185752 The Main Preview for Sprite Lit and Sprite Unlit master nodes now displays the correct color. 1184656 Shader Graph shaders in Always Include Shaders no longer crash builds. 1191757 The Transform node now correctly transforms Absolute World to Object. Errors no longer occur when you change the precision of Sub Graphs. 1158413 Fixed an error where the UV channel drop-down menu on nodes had clipped text. 1188710 Added StencilOverride support. Sticky Notes can now be grouped properly. Fixed an issue where nodes couldn't be copied from a group. Fixed a bug that occurred when you duplicated multiple Blackboard properties or keywords simultaneously, where Shader Graph stopped working, potentially causing data loss. Fixed a bug where you couldn't reorder Blackboard properties. Shader Graph now properly duplicates the Exposed status for Shader properties and keywords. Fixed a bug where the Save Graph As dialog for a Shader or Sub Graph sometimes appeared in the wrong Project when you had multiple Unity Projects open simultaneously. Fixed an issue where adding the first output to a Sub Graph without any outputs prior caused Shader Graphs containing the Sub Graph to break. Fixed an issue where Shader Graph shaders using the CameraNode failed to build on PS4 with \"incompatible argument list for call to 'mul'\". Fixed a bug that caused problems with Blackboard property ordering. Fixed a bug where the redo functionality in Shader Graph often didn't work. Fixed a bug where using the Save As command on a Sub Graph raised an exception. Fixed a bug where the input fields sometimes didn't render properly. 1176268 Fixed a bug where the Gradient property didn't work with all system locales. 1140924 Fixed a bug where Properties in the Blackboard could have duplicate names. Fixed a bug where you could drag the Blackboard into a graph even when you disabled the Blackboard. Fixed a bug where the Vertex Normal slot on master nodes needed vertex normal data input to compile. 1193348 Fixed a bug where GetWorldSpaceNormalizeViewDir() could cause undeclared indentifier errors. 1190606 Fixed a bug where Emission on PBR Shader Graphs in the Universal RP would not bake to lightmaps. 1190225 Fixed a bug where Shader Graph shaders were writing to POSITION instead of SV_POSITION, which caused PS4 builds to fail. Fixed a bug where Object to Tangent transforms in the Transform node used the wrong matrix. 1162203 Fixed an issue where boolean keywords in a Shader Graph caused HDRP Material features to fail. 1204827 Fixed a bug where Object space normals scaled with Object Scale. Documentation links on nodes now point to the correct URLs and package versions. Fixed an issue where Sub Graphs sometimes had duplicate names when you converted nodes into Sub Graphs. Fixed an issue where the number of ports on Keyword nodes didn't update when you added or removed Enum Keyword entries. Fixed an issue where colors in graphs didn't update when you changed a Blackboard Property's precision while the Color Mode is set to Precision. Fixed a bug where custom mesh in the Master Preview didn't work. Fixed a number of memory leaks that caused Shader Graph assets to stay in memory after closing the Shader Graph window. You can now smoothly edit controls on the Dielectric Specular node. Fixed Blackboard Properties to support scientific notation. Fixed a bug where warnings in the Shader Graph or Sub Graph were treated as errors. Fixed a bug where the error Output value 'vert' is not initialized displayed on all PBR graphs in Universal. 1210710 Fixed a bug where PBR and Unlit master nodes in Universal had Alpha Clipping enabled by default. Fixed an issue in where analytics wasn't always working. Fixed a bug where if a user had a Blackboard Property Reference start with a digit the generated shader would be broken. Avoid unintended behavior by removing the ability to create presets from Shader Graph (and Sub Graph) assets. 1220914 Fixed a bug where undo would make the Master Preview visible regardless of its toggle status. Fixed a bug where any change to the PBR master node settings would lose connection to the normal slot. Fixed a bug where the user couldn't open up HDRP Master Node Shader Graphs without the Render Pipeline set to HDRP. Fixed a bug where adding a HDRP Master Node to a Shader Graph would softlock the Shader Graph. Fixed a bug where shaders fail to compile due to #pragma target generation when your system locale uses commas instead of periods. Fixed a compilation error when using Hybrid Renderer due to incorrect positioning of macros. Fixed a bug where the Create Node Menu lagged on load. Entries are now only generated when property, keyword, or subgraph changes are detected. 1209567. Fixed a bug with the Transform node where converting from Absolute World space in a sub graph causes invalid subscript errors. 1190813 Fixed a bug where depndencies were not getting included when exporting a shadergraph and subgraphs Fixed a bug where adding a \" to a property display name would cause shader compilation errors and show all nodes as broken Fixed a bug where the Position node would change coordinate spaces from World to Absolute World when shaders recompile. 1184617 Fixed a bug where instanced shaders wouldn't compile on PS4. Fixed a bug where switching a Color Nodes' Mode between Default and HDR would cause the Color to be altered incorrectly. Fixed a bug where nodes dealing with matricies would sometimes display a preview, sometimes not. Optimized loading a large Shader Graph. 1209047 Fixed NaN issue in triplanar SG node when blend goes to 0. Fixed a recurring bug where node inputs would get misaligned from their ports. [1224480] Fixed an issue where Blackboard properties would not duplicate with Precision or Hybrid Instancing options. Fixed an issue where Texture properties on the Blackboard would not duplicate with the same Mode settings. Fixed an issue where Keywords on the Blackboard would not duplicate with the same Default value. Shader Graph now requests preview shader compilation asynchronously. 1209047 Fixed an issue where Shader Graph would not compile master previews after an assembly reload. Fixed issue where Linear Blend Skinning node could not be converted to Sub Graph 1227087 Fixed a compilation error in preview shaders for nodes requiring view direction. Fixed undo not being recorded properly for setting active master node, graph precision, and node defaults. Fixed an issue where Custum Function nodes and Sub Graph Output nodes could no longer rename slots. Fixed a bug where searcher entries would not repopulate correctly after an undo was perfromed (https://fogbugz.unity3d.com/f/cases/1241018/) Fixed a bug where Redirect Nodes did not work as inputs to Custom Function Nodes. 1235999 Fixed a bug where changeing the default value on a keyword would reset the node input type to vec4 (https://fogbugz.unity3d.com/f/cases/1216760/) Fixed a soft lock when you open a graph when the blackboard hidden. Fixed an issue where keyboard navigation in the Create Node menu no longer worked. [1253544] Preview correctly shows unassigned VT texture result, no longer ignores null textures Don't allow duplicate VT layer names when renaming layers Moved VT layer TextureType to the VTProperty from the SampleVT node Fixed the squished UI of VT property layers Disallow Save As and Convert to Subgraph that would create recursive dependencies Fixed an issue where the user would not get a save prompt on application close 1262044 Fixed bug where output port type would not visually update when input type changed (for example from Vec1 to Vec3) 1259501 Fixed an issue with how we collected/filtered nodes for targets. Applied the work to the SearchWindowProvider as well Fixed a bug where the object selector for Custom Function Nodes did not update correctly. 1176129 Fixed a bug where whitespaces were allowed in keyword reference names Fixed a bug where the Create Node menu would override the Object Field selection window. 1176125 Fixed a bug where the Main Preview window was no longer a square aspect ratio. 1257053 Fixed a bug where the size of the Graph Inspector would not save properly. 1257084 Replace toggle by an enumField for lit/unlit with VFXTarget Alpha Clipping option in Graph inspector now correctly hides and indents dependent options. (https://fogbugz.unity3d.com/f/cases/1257041/) Fixed a bug where changing the name of a property did not update nodes on the graph. 1249164 Fixed a crash issue when ShaderGraph included in a project along with DOTS assemblies Added missing SampleVirtualTextureNode address mode control in ShaderGraph Fixed a badly named control on SampleVirtualTextureNode in ShaderGraph Fixed an issue where multiple SampleVirtualTextureNodes created functions with names that may collide in ShaderGraph Made sub graph importer deterministic to avoid cascading shader recompiles when no change was present. Adjusted style sheet for Blackboard to prevent ui conflicts. Fixed a bug where the SampleVirtualTexture node would delete slots when changing its LOD mode Use preview of the other target if VFXTarget is active. [7.1.1] - 2019-09-05 Added You can now define shader keywords on the Blackboard. Use these keywords on the graph to create static branches in the generated shader. The tab now shows whether you are working in a Sub Graph or a Shader Graph file. The Shader Graph importer now bakes the output node type name into a meta-data object. Fixed The Shader Graph preview no longer breaks when you create new PBR Graphs. Fixed an issue where deleting a group and a property at the same time would cause an error. Fixed the epsilon that the Hue Node uses to avoid NaN on platforms that support half precision. Emission nodes no longer produce errors when you use them in Sub Graphs. Exposure nodes no longer produce errors when you use them in Sub Graphs. Unlit master nodes no longer define unnecessary properties in the Universal Render Pipeline. Errors no longer occur when you convert a selection to a Sub Graph. Color nodes now handle Gamma and Linear conversions correctly. Sub Graph Output nodes now link to the correct documentation page. When you use Keywords, PBR and Unlit master nodes no longer produce errors. PBR master nodes now calculate Global Illumination (GI) correctly. PBR master nodes now apply surface normals. PBR master nodes now apply fog. The Editor now displays correct errors for missing or deleted Sub Graph Assets. You can no longer drag and drop recursive nodes onto Sub Graph Assets. [7.0.1] - 2019-07-25 Changed New Shader Graph windows are now docked to either existing Shader Graph windows, or to the Scene View. Fixed Fixed various dependency tracking issues with Sub Graphs and HLSL files from Custom Function Nodes. Fixed an error that previously occurred when you used Sampler State input ports on Sub Graphs. Normal Reconstruct Z node is now compatible with both fragment and vertex stages. Position node now draws the correct label for Absolute World. Node previews now inherit preview type correctly. Normal maps now unpack correctly for mobile platforms. Fixed an error that previously occurred when you used the Gradient Sample node and your system locale uses commas instead of periods. Fixed an issue where you couldn't group several nodes. [7.0.0] - 2019-07-10 Added You can now use the SHADERGRAPH_PREVIEW keyword in Custom Function Node to generate different code for preview Shaders. Color Mode improves node visibility by coloring the title bar by Category, Precision, or custom colors. You can now set the precision of a Shader Graph and individual nodes. Added the _TimeParameters variable which contains Time, Sin(Time), and Cosine(Time) Absolute World space on Position Node now provides absolute world space coordinates regardless of the active render pipeline. You can now add sticky notes to graphs. Changed The Custom Function Node now uses an object field to reference its source when using File mode. To enable master nodes to generate correct motion vectors for time-based vertex modification, time is now implemented as an input to the graph rather than as a global uniform. World space on Position Node now uses the default world space coordinates of the active render pipeline. Fixed Fixed an error in Custom Function Node port naming. Sampler State properties and nodes now serialize correctly. Labels in the Custom Port menu now use the correct coloring when using the Personal skin. Fixed an error that occured when creating a Sub Graph from a selection containing a Group Node. When you change a Sub Graph, Shader Graph windows now correctly reload. When you save a Shader Graph, all other Shader Graph windows no longer re-compile their preview Shaders. Shader Graph UI now draws with correct styling for 2019.3. When deleting edge connections to nodes with a preview error, input ports no longer draw in the wrong position. Fixed an error involving deprecated components from VisualElements. When you convert nodes to a Sub Graph, the nodes are now placed correctly in the Sub Graph. The Bitangent Vector Node now generates all necessary shader requirements. [6.7.0-preview] - 2019-05-16 Added Added a hidden path namespace for Sub Graphs to prevent certain Sub Graphs from populating the Create Node menu. Changed Anti-aliasing (4x) is now enabled on Shader Graph windows. Fixed When you click on the gear icon, Shader Graph now focuses on the selected node, and brings the settings menu to front view. Sub Graph Output and Custom Function Node now validate slot names, and display an appropriate error badge when needed. Remaining outdated documentation has been removed. When you perform an undo or redo to an inactive Shader Graph window, the window no longer breaks. When you rapidly perform an undo or redo, Shader Graph windows no longer break. Sub Graphs that contain references to non-existing Sub Graphs no longer break the Sub Graph Importer. You can now reference sub-assets such as Textures. You can now reference Scene Color and Scene Depth correctly from within a Sub Graph. When you create a new empty Sub Graph, it no longer shows a warning about a missing output. When you create outputs that start with a digit, Shader generation no longer fails. You can no longer add nodes that are not allowed into Sub Graphs. A graph must now always contain at least one Master Node. Duplicate output names are now allowed. Fixed an issue where the main preview was always redrawing. When you set a Master Node as active, the Main Preview now shows the correct result. When you save a graph that contains a Sub Graph node, the Shader Graph window no longer freezes. Fixed an error that occured when using multiple Sampler State nodes with different parameters. Fixed an issue causing default inputs to be misaligned in certain cases. You can no longer directly connect slots with invalid types. When the graph detects that situation, it now doesn't break and gives an error instead. [6.6.0] - 2019-04-01 Added You can now add Matrix, Sampler State and Gradient properties to the Blackboard. Added Custom Function node. Use this node to define a custom HLSL function either via string directly in the graph, or via a path to an HLSL file. You can now group nodes by pressing Ctrl + G. Added \"Delete Group and Contents\" and removed \"Ungroup All Nodes\" from the context menu for groups. You can now use Sub Graphs in other Sub Graphs. Preview shaders now compile in the background, and only redraw when necessary. Changed Removed Blackboard fields, which had no effect on Sub Graph input ports, from the Sub Graph Blackboard. Subgraph Output node is now called Outputs. Subgraph Output node now supports renaming of ports. Subgraph Output node now supports all port types. Subgraph Output node now supports reordering ports. When you convert nodes to a Sub Graph, Shader Graph generates properties and output ports in the Sub Graph, and now by default, names those resulting properties and output ports based on their types. When you delete a group, Shader Graph now deletes the Group UI, but doesn't delete the nodes inside. Fixed You can now undo edits to Vector port default input fields. You can now undo edits to Gradient port default input fields. Boolean port input fields now display correct values when you undo changes. Vector type properties now behave as expected when you undo changes. Fixed an error that previously occurred when you opened saved Shader Graphs containing one or more Voronoi nodes. You can now drag normal map type textures on to a Shader Graph to create Sample Texture 2D nodes with the correct type set. Fixed the Multiply node so default input values are applied correctly. Added padding on input values for Blend node to prevent NaN outputs. Fixed an issue where IsFaceSign would not compile within Sub Graph Nodes. Null reference errors no longer occur when you remove ports with connected edges. Default input fields now correctly hide and show when connections change. [6.5.0] - 2019-03-07 Fixed Fixed master preview for HDRP master nodes when alpha clip is enabled. [6.4.0] - 2019-02-21 Fixed Fixed the Transform node, so going from Tangent Space to any other space now works as expected. [6.3.0] - 2019-02-18 Fixed Fixed an issue where the Normal Reconstruct Z Node sometimes caused Not a Number (NaN) errors when using negative values. [6.2.0] - 2019-02-15 Fixed Fixed the property blackboard so it no longer goes missing or turns very small. Changed Code refactor: all macros with ARGS have been swapped with macros with PARAM. This is because the ARGS macros were incorrectly named. [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Added When you hover your cursor over a property in the blackboard, this now highlights the corresponding property elements in your Shader Graph. Similarly, if you hover over a property in the Shader Graph itself, this highlights the corresponding property in the blackboard. Property nodes in your Shader Graph now have a similar look and styling as the properties in the blackboard. Changed Errors in the compiled shader are now displayed as badges on the appropriate node. In the Scene Depth node you can now choose the depth sampling mode: Linear01, Raw or Eye. Fixed When you convert an inline node to a Property node, this no longer allows duplicate property names. When you move a node, you'll now be asked to save the Graph file. You can now Undo edits to Property parameters on the Blackboard. You can now Undo conversions between Property nodes and inline nodes. You can now Undo moving a node. You can no longer select the Texture2D Property type Mode, if the Property is not exposed. The Vector1 Property type now handles default values more intuitively when switching Mode dropdown. The Color node control is now a consistent width. Function declarations no longer contain double delimiters. The Slider node control now functions correctly. Fixed an issue where the Editor automatically re-imported Shader Graphs when there were changes to the asset database. Reverted the visual styling of various graph elements to their previous correct states. Previews now repaint correctly when Unity does not have focus. Code generation now works correctly for exposed Vector1 shader properties where the decimal separator is not a dot. The Rotate About Axis node's Modes now use the correct function versions. Shader Graph now preserves grouping when you convert nodes between property and inline. The Flip node now greys out labels for inactive controls. The Boolean property type now uses the ToggleUI property attribute, so as to not generate keywords. The Normal Unpack node no longer generates errors in Object space. The Split node now uses values from its default Port input fields. The Channel Mask node now allows multiple node instances, and no longer generates any errors. Serialized the Alpha control value on the Flip node. The Is Infinite and Is NaN nodes now use Vector 1 input ports, but the output remains the same. You can no longer convert a node inside a Sub Graph into a Sub Graph, which previously caused errors. The Transformation Matrix node's Inverse Projection and Inverse View Projection modes no longer produce errors. The term Shader Graph is now captilized correctly in the Save Graph prompt. [5.2.0] - 2018-11-27 Added Shader Graph now has Group Node, where you can group together several nodes. You can use this to keep your Graphs organized and nice. Fixed The expanded state of blackboard properties are now remembered during a Unity session. [5.1.0] - 2018-11-19 Added You can now show and hide the Main Preview and the Blackboard from the toolbar. Changed The Shader Graph package is no longer in preview. Moved NormalBlendRNM node to a dropdown option on Normal Blend node. Sample Cubemap node now has a SamplerState slot. New Sub Graph assets now default to the \"Sub Graphs\" path in the Create Node menu. New Shader Graph assets now default to the \"Shader Graphs\" path in the Shader menu. The Light Probe node is now a Baked GI node. When you use LWRP with lightmaps, this node now returns the correct lightmap data. This node is supported in HDRP. Reflection Probe nodes now only work with LWRP. This solves compilation errors in HDRP. Ambient nodes now only work with LWRP. This solves compilation errors in HDRP. Fog nodes now only work with LWRP. This solves compilation errors in HDRP. In HDRP, the Position port for the Object node now returns the absolute world position. The Baked GI, Reflection Probe, and Ambient nodes are now in the Input/Lighting category. The master node no longer has its own preview, because it was redundant. You can see the results for the master node in the Main Preview. Fixed Shadow projection is now correct when using the Unlit master node with HD Render Pipeline. Removed all direct references to matrices Matrix Construction nodes with different Mode values now evaluate correctly. Is Front Face node now works correctly when connected to Alpha and AlphaThreshold slots on the PBR master node. Corrected some instances of incorrect port dimensions on several nodes. Scene Depth and Scene Color nodes now work in single pass stereo in Lightweight Render Pipeline. Channel Mask node controls are now aligned correctly. In Lightweight Render Pipeline, Pre-multiply surface type now matches the Lit shader. Non-exposed properties in the blackboard no longer have a green dot next to them. Default reference name for shader properties are now serialized. You cannot change them after initial creation. When you save Shader Graph and Sub Graph files, they're now automatically checked out on version control. Shader Graph no longer throws an exception when you double-click a folder in the Project window. Gradient Node no longer throws an error when you undo a deletion. [5.0.0-preview] - 2018-09-28 [4.0.0-preview] - 2018-09-28 Added Shader Graph now supports the High Definition Render Pipeline with both PBR and Unlit Master nodes. Shaders built with Shader Graph work with both the Lightweight and HD render pipelines. You can now modify vertex position via the Position slot on the PBR and Unlit Master nodes. By default, the input to this node is object space position. Custom inputs to this slot should specify the absolute local position of a given vertex. Certain nodes (such as Procedural Shapes) are not viable in the vertex shader. Such nodes are incompatible with this slot. You can now edit the Reference name for a property. To do so, select the property and type a new name next to Reference. If you want to reset to the default name, right-click Reference, and select Reset reference. In the expanded property window, you can now toggle whether the property is exposed. You can now change the path of Shader Graphs and Sub Graphs. When you change the path of a Shader Graph, this modifies the location it has in the shader selection list. When you change the path of Sub Graph, it will have a different location in the node creation menu. Added Is Front Face node. With this node, you can change graph output depending on the face sign of a given fragment. If the current fragment is part of a front face, the node returns true. For a back face, the node returns false. Note: This functionality requires that you have enabled two sided on the Master node. Gradient functionality is now available via two new nodes: Sample Gradient and Gradient Asset. The Sample Gradient node samples a gradient given a Time parameter. You can define this gradient on the Gradient slot control view. The Gradient Asset node defines a gradient that can be sampled by multiple Sample Gradient nodes using different Time parameters. Math nodes now have a Waves category. The category has four different nodes: Triangle wave, Sawtooth wave, Square wave, and Noise Sine wave. The Triangle, Sawtooth, and Square wave nodes output a waveform with a range of -1 to 1 over a period of 1. The Noise Sine wave outputs a standard Sine wave with a range of -1 to 1 over a period of 2 * pi. For variance, random noise is added to the amplitude of the Sine wave, within a determined range. Added Sphere Mask node for which you can indicate the starting coordinate and center point. The sphere mask uses these with the Radius and Hardness parameters. Sphere mask functionality works in both 2D and 3D spaces, and is based on the vector coordinates in the Coords and Center input. Added support for Texture 3D and Texture 2D Array via two new property types and four new nodes. A new node Texture 2D LOD has been added for LOD functionality on a Texture 2D Sample. Sample Texture 2D LOD uses the exact same input and output slots as Sample Texture 2D, but also includes an input for level of detail adjustments via a Vector1 slot. Added Texel Size node, which allows you to get the special texture properties of a Texture 2D Asset via the {texturename}_TexelSize variable. Based on input from the Texture 2D Asset, the node outputs the width and height of the texel size in Vector1 format. Added Rotate About Axis node. This allows you to rotate a 3D vector space around an axis. For the rotation, you can specify an amount of degrees or a radian value. Unpacking normal maps in object space. Unpacking derivative maps option on sample texture nodes. Added Uint type for instancing support. Added HDR option for color material slots. Added definitions used by new HD Lit Master node. Added a popup control for a string list. Added conversion type (position/direction) to TransformNode. In your preview for nodes that are not master nodes, pixels now display as pink if they are not finite. Changed The settings for master nodes now live in a small window that you can toggle on and off. Here, you can change various rendering settings for your shader. There are two Normal Derive Nodes: Normal From Height and Normal Reconstruct Z. Normal From Height uses Vector1 input to derive a normal map. Normal Reconstruct Z uses the X and Y components in Vector2 input to derive the proper Z value for a normal map. The Texture type default input now accepts render textures. HD PBR subshader no longer duplicates surface description code into vertex shader. If the current render pipeline is not compatible, master nodes now display an error badge. The preview shader now only considers the current render pipeline. Because of this there is less code to compile, so the preview shader compiles faster. When you rename a shader graph or sub shader graph locally on your disk, the title of the Shader Graph window, black board, and preview also updates. Removed legacy matrices from Transfomation Matrix node. Texture 2D Array and Texture 3D nodes can no longer be used in the vertex shader. Normal Create node has been renamed to Normal From Texture. When you close the Shader Graph after you have modified a file, the prompt about saving your changes now shows the file name as well. Blend node now supports Overwrite mode. Simple Noise node no longer has a loop. The Polygon node now calculates radius based on apothem. Normal Strength node now calculates Z value more accurately. You can now connect Sub Graphs to vertex shader slots. If a node in the Sub Graph specifies a shader stage, that specific Sub Graph node is locked to that stage. When an instance of a Sub Graph node is connected to a slot that specifies a shader stage, all slots on that instance are locked to the stage. Separated material options and tags. Master node settings are now recreated when a topological modification occurs. Fixed Vector 1 nodes now evaluate correctly. (#334 and #337) Properties can now be copied and pasted. Pasting a property node into another graph will now convert it to a concrete node. (#300 and #307) Nodes that are copied from one graph to another now spawn in the center of the current view. (#333) When you edit sub graph paths, the search window no longer yields a null reference exception. The blackboard is now within view when deserialized. Your system locale can no longer cause incorrect commands due to full stops being converted to commas. Deserialization of subgraphs now works correctly. Sub graphs are now suffixed with (sub), so you can tell them apart from other nodes. Boolean and Texture type properties now function correctly in sub-graphs. The preview of a node does not obstruct the selection outliner anymore. The Dielectric Specular node no longer resets its control values. You can now copy, paste, and duplicate sub-graph nodes with vector type input ports. The Lightweight PBR subshader now normalizes normal, tangent, and view direction correctly. Shader graphs using alpha clip now generate correct depth and shadow passes. Normal Create node has been renamed to Normal From Texture. The preview of nodes now updates correctly. Your system locale can no longer cause incorrect commands due to full stops being converted to commas. Show Generated Code no longer throws an \"Argument cannot be null\" error. Sub Graphs now use the correct generation mode when they generate preview shaders. The CodeFunctionNode API now generates correct function headers when you use DynamicMatrix type slots. Texture type input slots now set correct default values for 'Normal' texture type. SpaceMaterialSlot now reads correct slot. Slider node control now functions correctly. Shader Graphs no longer display an error message intended for Sub Graphs when you delete properties. The Shader Graph and Sub Shader Graph file extensions are no longer case-sensitive. The dynamic value slot type now uses the correct decimal separator during HLSL generation. Fixed an issue where Show Generated Code could fail when external editor was not set. In the High Definition Render Pipeline, Shader Graph now supports 4-channel UVs. The Lightweight PBR subshader now generates the correct meta pass. Both PBR subshaders can now generate indirect light from emission. Shader graphs now support the SRP batcher. Fixed an issue where floatfield would be parsed according to OS locale settings with .NET 4.6"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Absolute-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Absolute-Node.html",
    "title": "Absolute Node | Inventory System",
    "summary": "Absolute Node Description Returns the absolute value of the input In. Components of the input Dynamic Vector that are positive will remain positive and components that are negative will be inverted and become positive. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Absolute_float4(float4 In, out float4 Out) { Out = abs(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Add-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Add-Node.html",
    "title": "Add Node | Inventory System",
    "summary": "Add Node Description Returns the sum of the two input values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Add_float4(float4 A, float4 B, out float4 Out) { Out = A + B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/All-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/All-Node.html",
    "title": "All Node | Inventory System",
    "summary": "All Node Description Returns true if all components of the input In are non-zero. This is useful for Branching. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_All_float4(float4 In, out float Out) { Out = all(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ambient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ambient-Node.html",
    "title": "Ambient Node | Inventory System",
    "summary": "Ambient Node Description Provides access to the Scene's Ambient color values. When Environment Lighting Source is set to Gradient Port Color/Sky returns the value Sky Color. When Environment Lighting Source is set to Color Port Color/Sky returns the value Ambient Color. Ports Equator and Ground always return the values Equator Color and Ground Color regardless of the current Environment Lighting Source. Note: Values of this Node are only updated when entering Play mode or saving the current Scene/Project. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Color/Sky Output Vector 3 None Color (Color) or Sky (Gradient) color value Equator Output Vector 3 None Equator (Gradient) color value Ground Output Vector 3 None Ground (Gradient) color value Generated Code Example The following example code represents one possible outcome of this node. float3 _Ambient_ColorSky = SHADERGRAPH_AMBIENT_SKY; float3 _Ambient_Equator = SHADERGRAPH_AMBIENT_EQUATOR; float3 _Ambient_Ground = SHADERGRAPH_AMBIENT_GROUND;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/And-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/And-Node.html",
    "title": "And Node | Inventory System",
    "summary": "And Node Description Returns true if both the inputs A and B are true. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example void Unity_And(float A, float B, out float Out) { Out = A && B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Any-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Any-Node.html",
    "title": "Any Node | Inventory System",
    "summary": "Any Node Description Returns true if any of the components of the input In are non-zero. This is useful for Branching. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Any_float4(float4 In, out float Out) { Out = any(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arccosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arccosine-Node.html",
    "title": "Arccosine Node | Inventory System",
    "summary": "Arccosine Node Description Returns the arccosine of each component of the input In as a vector of the same dimension and equal length. Each component should be within the range of -1 to 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arccosine_float4(float4 In, out float4 Out) { Out = acos(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arcsine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arcsine-Node.html",
    "title": "Arcsine Node | Inventory System",
    "summary": "Arcsine Node Description Returns the arcsine of each component of the input In as a vector of the same dimension and equal length. Each component should be within the range of -Pi/2 to Pi/2. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arcsine_float4(float4 In, out float4 Out) { Out = asin(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arctangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arctangent-Node.html",
    "title": "Arctangent Node | Inventory System",
    "summary": "Arctangent Node Description Returns the arctangent of the value of input In. Each component should be within the range of -Pi/2 to Pi/2. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arctangent_float4(float4 In, out float4 Out) { Out = atan(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arctangent2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Arctangent2-Node.html",
    "title": "Arctangent2 Node | Inventory System",
    "summary": "Arctangent2 Node Description Returns the arctangent of the values of both input A and input B. The signs (whether they are positive or negative values) of the input values are used to determine whether the output components, or channels, are positive or negative within a range of -Pi to Pi. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arctangent2_float4(float4 A, float4 B, out float4 Out) { Out = atan2(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Artistic-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Artistic-Nodes.html",
    "title": "Artistic Nodes | Inventory System",
    "summary": "Artistic Nodes Adjustment Channel Mixer Contrast Controls the amount each of the channels of input In contribute to each of the output channels. Adjusts the contrast of input In by the amount of input Contrast. Hue Invert Colors Offsets the hue of input In by the amount of input Offset. Inverts the colors of input In on a per channel basis. Replace Color Saturation Replaces values in input In equal to input From to the value of input To. Adjusts the saturation of input In by the amount of input Saturation. White Balance Adjusts the temperature and tint of input In by the amount of inputs Temperature and Tint respectively. Blend Blend Blends the value of input Blend onto input Base using the blending mode defined by parameter Mode. Filter Dither Dither is an intentional form of noise used to randomize quantization error. It is used to prevent large-scale patterns such as color banding in images.. Mask Channel Mask Color Mask Masks values of input In on channels selected in dropdown Channels. Creates a mask from values in input In equal to input Mask Color. Normal Normal Blend Normal From Height Blends two normal maps defined by inputs A and B together. Creates a normal map from a height map defined by input Texture. Normal Strength Normal Unpack Adjusts the strength of the normal map defined by input In by the amount of input Strength. Unpacks a normal map defined by input In. Utility Colorspace Conversion Returns the result of converting the value of input In from one colorspace space to another."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Baked-GI-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Baked-GI-Node.html",
    "title": "Baked GI Node | Inventory System",
    "summary": "Baked GI Node Description Provides access to the Baked GI values at the vertex or fragment's position. Requires Position and Normal input for light probe sampling, and lightmap coordinates Static UV and Dynamic UV for all potential lightmap sampling cases. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support This node is compatible with both the High Definition Render Pipeline (HDRP) and the Universal Render Pipeline (URP). However, this node does not work within unlit shaders for either pipeline. Ports Name Direction Type Binding Description Position Input Vector 3 Position (world space) Mesh vertex/fragment's Position Normal Input Vector 3 Normal (world space) Mesh vertex/fragment's Normal Static UV Input Vector 2 UV1 Lightmap coordinates for the static lightmap Dynamic UV Input Vector 2 UV2 Lightmap coordinates for the dynamic lightmap Out Output Vector 3 None Output color value Controls Name Type Options Description Apply Lightmap Scaling Toggle True, False If enabled lightmaps are automatically scaled and offset. Generated Code Example The following example code represents one possible outcome of this node. void Unity_BakedGI_float(float3 Position, float3 Normal, float2 StaticUV, float2 DynamicUV, out float Out) { Out = SHADERGRAPH_BAKED_GI(Position, Normal, StaticUV, DynamicUV, false); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Bitangent-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Bitangent-Vector-Node.html",
    "title": "Bitangent Node | Inventory System",
    "summary": "Bitangent Node Description Provides access to the mesh vertex or fragment's Bitangent Vector, depending on the effective Shader Stage of the graph section the Node is part of. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Bitangent Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Bitangent Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blackboard.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blackboard.html",
    "title": "Blackboard | Inventory System",
    "summary": "Blackboard Description You can use the Blackboard to define, order, and categorize the Properties and Keywords in a graph. From the Blackboard, you can also edit the path for the selected Shader Graph Asset or Sub Graph. Accessing the Blackboard The Blackboard is visible by default, and you cannot drag it off the graph and lose it. However, you are able to position it anywhere in the Shader Graph Window. It always maintains the same distance from the nearest corner, even if you resize the window. Adding properties and keywords to the Blackboard To create a new property or keyword, click the Add (+) button on the Blackboard's title bar and select a type. For a full list of property types, see Property Types. Editing properties and keywords Select a property or keyword in the Blackboard or graph to modify its settings in the Node Settings Menu. Setting Description Name The property's display name. The Editor strips quotation marks from display names and replaces them with underscores. Rename an item via the Blackboard by double-clicking on its name. Reference The name that Shader Graph uses internally for this property. Although the Editor populates this value by default, you can modify it. To revert to the original reference name, right-click on the word Reference (not the entry field) and select Reset Reference in the context menu. If the Reference Name contains any characters that HLSL does not support, the Editor replaces those characters with underscores. Default The default value of this property in any Material based on this Shader Graph. For example, if you have a Shader Graph for grass and expose the grass color as a property, you might set the default to Green. Precision Set the precision mode for the property. See Precision Modes. Exposed Enable this setting to make the property available for you to edit via the C# API. Enabled by default. Modifying and selecting keywords and properties To reorder items listed on the Blackboard, drag and drop them. To delete items, use the Delete key on Windows or Command + Backspace keys on macOS. To select multiple items, hold down the Ctrl key while making your selections. To cancel the selection of one or multiple items, hold down the Ctrl key while clicking on the items you want to remove from the selection. Using Blackboard categories To make the properties in your shader more discoverable, organize them into categories. Expand and collapse categories to make the Blackboard easier to navigate. Creating, renaming, moving, and deleting categories To add a category, use + on the Blackboard. To rename a category, double-click on the category name, or right-click and select Rename. To move a category within the Blackboard, select and drag it. To remove a category, select it and press Delete, or right-click and select Delete. Deleting a category also deletes the properties within it, so move those you wish to keep. Adding, removing, and reordering properties and keywords To add a property or keyword to a category, expand the category with the foldout (⌄) symbol, then drag and drop the property or keyword onto the expanded category. To remove a property or keyword, select it and press Delete, or right-click and select Delete. To re-order properties or keywords, drag and drop them within a category or move them into other categories. Creating a category for specific properties and keywords Select multiple properties or keywords and use + on the Blackboard to create a category that contains all of the items you have selected. Copying and pasting categories, with or without properties You can paste empty categories, categories with all of their properties, and categories with some of their properties into one or more graphs. To copy a category with all of its properties: Select the property. Copy it with Ctrl+C. Paste it into your target graph with Ctrl+V. To copy a specific set of properties: Select the category. Hold down the Ctrl key. Click the properties you do not want to include to remove them from the selection. Copy the property with Ctrl+C. Paste it into your target graph with Ctrl+V. Using categories in the Material Inspector To modify a material you have created with a Shader Graph, you can adjust specific property or keyword values in the Material Inspector, or edit the graph itself. Working with Streaming Virtual Textures Streaming Virtual Texture Properties sample texture layers. To access these layers in the Material Inspector, expand the relevant Virtual Texture section with the ⌄ symbol next to its name. You can add and remove layers via the Inspector. Exposing properties and keywords Unity exposes properties and keywords by default. This enables write access from scripts, so that you can edit them via the C# API, in addition to the graph. Exposed items have a green dot in their label. Enable or disable this feature in the Node Settings menu. Creating nodes Drag a property or keyword from the Blackboard into the graph to create a node of that kind. Settings for a node in the graph are identical to those for the related property or keyword in the Blackboard. Expand these nodes to use a sub-member of the property value. Property node names include a green dot if the property is exposed."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blackbody-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blackbody-Node.html",
    "title": "Blackbody Node | Inventory System",
    "summary": "Blackbody Node Description Samples a Gradient that simulates the effect of black body radiation. The calculations in this node are based on data gathered by Mitchell Charity. This node outputs color in linear RGB space and preforms the conversion using a D65 whitepoint and a CIE 1964 10 degree color space. For more information, see What color is a blackbody? Ports Name Direction Type Binding Description Temperature Input Float None Temperature or temperature map in Kelvin to sample. Out Output Vector 3 None Intensity represented by color in Vector 3. Generated Code Example The following example code represents one possible outcome of this node. void Unity_Blackbody_float(float Temperature, out float3 Out) { float3 color = float3(255.0, 255.0, 255.0); color.x = 56100000. * pow(Temperature,(-3.0 / 2.0)) + 148.0; color.y = 100.04 * log(Temperature) - 623.6; if (Temperature > 6500.0) color.y = 35200000.0 * pow(Temperature,(-3.0 / 2.0)) + 184.0; color.z = 194.18 * log(Temperature) - 1448.6; color = clamp(color, 0.0, 255.0)/255.0; if (Temperature < 1000.0) color *= Temperature/1000.0; Out = color; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Blend-Node.html",
    "title": "Blend Node | Inventory System",
    "summary": "Blend Node Description Blends the value of input Blend onto input Base using the blending mode defined by the Mode parameter. The strength of the blend is defined by input Opacity. An Opacity value of 0 will return the input Base, unaltered. Ports Name Direction Type Binding Description Base Input Dynamic Vector None Base layer value Blend Input Dynamic Vector None Blend layer value Opacity Input Float None Strength of blend Out Output Dynamic Vector None Output value Controls Name Type Options Description Mode Dropdown Burn, Darken, Difference, Dodge, Divide, Exclusion, HardLight, HardMix, Lighten, LinearBurn, LinearDodge, LinearLight, LinearLightAddSub, Multiply, Negation, Overlay, PinLight, Screen, SoftLight, Subtract, VividLight, Overwrite Blend mode to apply Generated Code Example The following example code represents one possible outcome of this node per blend mode. Burn void Unity_Blend_Burn_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - (1.0 - Blend)/Base; Out = lerp(Base, Out, Opacity); } Darken void Unity_Blend_Darken_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = min(Blend, Base); Out = lerp(Base, Out, Opacity); } Difference void Unity_Blend_Difference_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = abs(Blend - Base); Out = lerp(Base, Out, Opacity); } Dodge void Unity_Blend_Dodge_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base / (1.0 - Blend); Out = lerp(Base, Out, Opacity); } Divide void Unity_Blend_Divide_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base / (Blend + 0.000000000001); Out = lerp(Base, Out, Opacity); } Exclusion void Unity_Blend_Exclusion_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend + Base - (2.0 * Blend * Base); Out = lerp(Base, Out, Opacity); } HardLight void Unity_Blend_HardLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - 2.0 * (1.0 - Base) * (1.0 - Blend); float4 result2 = 2.0 * Base * Blend; float4 zeroOrOne = step(Blend, 0.5); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } HardMix void Unity_Blend_HardMix_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = step(1 - Base, Blend); Out = lerp(Base, Out, Opacity); } Lighten void Unity_Blend_Lighten_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = max(Blend, Base); Out = lerp(Base, Out, Opacity); } LinearBurn void Unity_Blend_LinearBurn_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base + Blend - 1.0; Out = lerp(Base, Out, Opacity); } LinearDodge void Unity_Blend_LinearDodge_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base + Blend; Out = lerp(Base, Out, Opacity); } LinearLight void Unity_Blend_LinearLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend < 0.5 ? max(Base + (2 * Blend) - 1, 0) : min(Base + 2 * (Blend - 0.5), 1); Out = lerp(Base, Out, Opacity); } LinearLightAddSub void Unity_Blend_LinearLightAddSub_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend + 2.0 * Base - 1.0; Out = lerp(Base, Out, Opacity); } Multiply void Unity_Blend_Multiply_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base * Blend; Out = lerp(Base, Out, Opacity); } Negation void Unity_Blend_Negation_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - abs(1.0 - Blend - Base); Out = lerp(Base, Out, Opacity); } Overlay void Unity_Blend_Overlay_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - 2.0 * (1.0 - Base) * (1.0 - Blend); float4 result2 = 2.0 * Base * Blend; float4 zeroOrOne = step(Base, 0.5); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } PinLight void Unity_Blend_PinLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 check = step (0.5, Blend); float4 result1 = check * max(2.0 * (Base - 0.5), Blend); Out = result1 + (1.0 - check) * min(2.0 * Base, Blend); Out = lerp(Base, Out, Opacity); } Screen void Unity_Blend_Screen_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - (1.0 - Blend) * (1.0 - Base); Out = lerp(Base, Out, Opacity); } SoftLight void Unity_Blend_SoftLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 2.0 * Base * Blend + Base * Base * (1.0 - 2.0 * Blend); float4 result2 = sqrt(Base) * (2.0 * Blend - 1.0) + 2.0 * Base * (1.0 - Blend); float4 zeroOrOne = step(0.5, Blend); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } Subtract void Unity_Blend_Subtract_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base - Blend; Out = lerp(Base, Out, Opacity); } VividLight void Unity_Blend_VividLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - (1.0 - Blend) / (2.0 * Base); float4 result2 = Blend / (2.0 * (1.0 - Base)); float4 zeroOrOne = step(0.5, Base); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } Overwrite void Unity_Blend_Overwrite_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = lerp(Base, Blend, Opacity); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Block-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Block-Node.html",
    "title": "Block Node | Inventory System",
    "summary": "Block Node Description A Block is a specific type of node for the Master Stack. A Block represents a single piece of the surface (or vertex) description data that Shader Graph uses in the final shader output. Built In Block nodes are always available, but nodes that are specific to a certain render pipeline are only available for that pipeline. For example, Universal Block nodes are only available for the Universal Render Pipeline (URP), and High Definition Block nodes are only available for the High Definition Render Pipeline (HDRP). Some blocks are only compatible with specific Graph Settings, and might become active or inactive based on the graph settings you select. You can't cut, copy, or paste Blocks. Add and Remove Block Nodes To add a new Block node to a Context in the Master Stack, place the cursor over an empty area in the Context, then press the Spacebar or right-click and select Create Node. This brings up the Create Node menu, which displays only Block nodes that are valid for the Context. For example, Vertex Blocks don't appear in the Create Node menu of a Fragment Context. Select a Block node from the menu to add it to the Context. To remove a Block from the Context, select the Block node in the Context, then press the Delete key or right-click and select Delete. Automatically Add or Remove Blocks You can also enable or disable an option in the Shader Graph Preferences to automatically add and remove Blocks from a Context. If you enable Automatically Add or Remove Blocks, Shader Graph automatically adds the required Block nodes for that particular asset's Target or material type. It automatically removes any incompatible Block nodes that have no connections and default values. If you disable Automatically Add or Remove Blocks, Shader Graph doesn't automatically add and remove Block nodes. You must manually add and remove all Block nodes. Active and Inactive Blocks Active Block nodes are Blocks that contribute to the final shader. Inactive Block nodes are Blocks that are present in the Shader Graph, but don't contribute to the final shader. When you change the graph settings, certain Blocks might become active or inactive. Inactive Block nodes and any node streams that are connected only to Inactive Block nodes appear grayed out."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Boolean-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Boolean-Node.html",
    "title": "Boolean Node | Inventory System",
    "summary": "Boolean Node Description Defines a constant Boolean value in the Shader Graph, although internally to the shader this is treated as a constant float value that is ether 0 or 1, similar to Shaderlab's Toggle property. Can be converted to a Boolean type Property via the Node's context menu. Ports Name Direction Type Binding Description Out Output Boolean None Output value Controls Name Type Options Description Toggle Defines the output value. Generated Code Example The following example code represents one possible outcome of this node. float _Boolean = 1;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Branch-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Branch-Node.html",
    "title": "Branch Node | Inventory System",
    "summary": "Branch Node Description Provides a dynamic branch to the shader. If input Predicate is true, this node returns input True, otherwise it returns input False. The Branch Node evaluates the Predicate per vertex or per pixel depending on shader stage. Both sides of the branch are evaluated in the shader, and the branch not used is discarded. Ports Name Direction Type Binding Description Predicate Input Boolean None Determines which input to return. True Input Dynamic Vector None Returned if Predicate is true. False Input Dynamic Vector None Returned if Predicate is false. Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Branch_float4(float Predicate, float4 True, float4 False, out float4 Out) { Out = Predicate ? True : False; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Branch-On-Input-Connection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Branch-On-Input-Connection-Node.html",
    "title": "Branch On Input Connection node | Inventory System",
    "summary": "Branch On Input Connection node The Branch On Input Connection node allows you to change the behavior of a Subgraph based on the connected state of an input property in the parent Shader Graph. You should use the Branch On Input Connection node when you want to create a default input for a port Shader Graph determines whether the property in the parent Shader Graph is connected, or not connected, and chooses a value to use as an output based on that connection state. Shader Graph uses two ports when it determines the node's connection state: The Branch On Input Connection node's Input port. The Subgraph node's matching Property port in the parent Shader Graph. For more information on Subgraph nodes, see Subgraph node. The Branch On Input Connection node's functionality is based on the Branch node. Note You can't use the Branch On Input Connection node with a Streaming Virtual Texture Property. For more information on Streaming Virtual Texturing, see Using Streaming Virtual Texturing in Shader Graph. The Branch On Input Connection node generates branching HLSL source code, but during compilation, the branch is optimized out of your shader. Create Node menu category The Branch On Input Connection node is under the Utility > Logic category in the Create Node menu. You can only use it in a Shader Subgraph. To use the Branch On Input Connection node in a Subgraph: Open the Subgraph where you want to add a Branch On Input Connection node. In the Blackboard, do one of the following: To add a new property, select Add (+), then select a property type from the menu. Enter a name for your new property and press Enter. Then, select your property in the Blackboard and drag it onto your graph to create a Property node. Select an existing property in the Blackboard and drag it onto your graph to create a Property node. With your Property node selected, in the Graph Inspector, enable Use Custom Binding. Note If you disable Use Custom Binding, you can't connect your Property node to the Branch On Input Connection node. If you've already made a connection, the Unity Editor breaks the connection and displays a warning on the node. In the Label field, enter the label for the default value that displays on your Subgraph node's port binding in its parent Shader Graph. For more information on port bindings, see Port Bindings. Press Spacebar or right-click and select Create Node. Find the Branch On Input Connection node in the Create Node Menu, then double-click or press Enter with the node selected to add it to your Subgraph. On your Property node, select the output port and drag its new connection to the Branch On Connection node's Input port. To specify the value Shader Graph uses when the Input port is connected on the Subgraph node in the parent Shader Graph, connect a node to the Connected port. To specify the value that Shader Graph uses when the Input port isn't connected, connect another node to the NotConnected port. To specify how Shader Graph uses your Connected or NotConnected values in your shader, connect any valid node to the Output port on the Branch On Input Connection node. Compatibility The Branch On Input Connection node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes Inputs The Branch On Input Connection node has the following input ports: Name Type Description Input Property The property that determines the branching logic in the node, based on its connection state in the parent Shader Graph. Connected Dynamic Vector The value to send to the Out port when Input is connected in the parent Shader Graph. NotConnected Dynamic Vector The value to send to the Out port when Input isn't connected in the parent Shader Graph. Outputs The Branch On Input Connection node has one output port: Name Type Description Out Dynamic Vector Outputs the value of either Connected or NotConnected, based on the Input property's connection state in the parent Shader Graph. Example Subgraph usage In the following example, a Branch On Input Connection node specifies the default behavior for a UV Subgraph input property. When a value for the UV property is connected in the parent graph, then the value from that property is passed to the Checkerboard node to determine the UV coordinates for the checkerboard pattern. When the UV property isn't connected, then the Branch On Input Connection node uses the UV0 channel from the UV node for the Checkerboard node's UV coordinates: Note When you preview a Subgraph, the Branch On Input Connection node always uses its NotConnected value. Related nodes The following nodes are related or similar to the Branch On Input Connection node: Branch node Subgraph node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Built-In-Blocks.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Built-In-Blocks.html",
    "title": "Built In Blocks | Inventory System",
    "summary": "Built In Blocks Vertex Blocks Name Type Binding Description Position Vector 3 Object Space Position Defines the absolute object space vertex position per vertex. Normal Vector 3 Object Space Normal Defines the absolute object space vertex normal per vertex. Tangent Vector 3 Object Space Tangent Defines the absolute object space vertex tangent per vertex. Color Vector 4 Vertex Color Defines vertex color. Expected range 0 - 1. Fragment Blocks Name Type Binding Description Base Color Vector 3 None Defines material's base color value. Expected range 0 - 1. Normal (Tangent Space) Vector 3 Tangent Space Normal Defines material's normal value in tangent space. Normal (Object Space) Vector 3 Object Space Normal Defines material's normal value in object space. Normal (World Space) Vector 3 World Space Normal Defines material's normal value in world space. Emission Vector 3 None Defines material's emission color value. Expects positive values. Metallic Float None Defines material's metallic value, where 0 is non-metallic and 1 is metallic. Specular Vector 3 None Defines material's specular color value. Expected range 0 - 1. Smoothness Float None Defines material's smoothness value. Expected range 0 - 1. Ambient Occlusion Float None Defines material's ambient occlusion value. Expected range 0 - 1. Alpha Float None Defines material's alpha value. Used for transparency and/or alpha clip. Expected range 0 - 1. Alpha Clip Threshold Float None Fragments with an alpha below this value are discarded. Expected range 0 - 1."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Calculate-Level-Of-Detail-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Calculate-Level-Of-Detail-Texture-2D-Node.html",
    "title": "Calculate Level Of Detail Texture 2D node | Inventory System",
    "summary": "Calculate Level Of Detail Texture 2D node The Calculate Level of Detail Texture 2D node takes an input Texture 2D and outputs the mip level of a Texture sample. This node is useful in situations where you need to know the mip level of a Texture, such as when you might want to modify the mip level before sampling in your shader. The Calculate Level of Detail Texture 2D node also has a clamped and unclamped mode: Clamped: The node clamps the returned mip level to the actual mips available on the Texture. The node uses the CalculateLevelOfDetail HLSL intrinsic function. Use this mode when you want to know which mip to sample your Texture from and restrict the result to an existing mip. Unclamped: The node returns the ideal mip level, based on an idealized Texture with all its mips present. The node uses the CalculateLevelOfDetailUnclamped HLSL intrinsic function. Use this mode when you need a more generic value for your mip level. For example, a Texture might only have 3 mips: a 64×64 mip, a 32×32 mip, and a 16×16 mip. When you use the Calculate Level Of Detail Texture 2D node in its Clamped mode, the node restricts the LOD output to one of the 3 mips on the Texture, even if the ideal mip level might be a smaller resolution, such as an 8×8 version. In its Unclamped mode, the node outputs the ideal 8×8 mip level, even though it doesn't exist on the Texture. Note On platforms where these HLSL functions don't exist, Shader Graph determines an appropriate approximation to use, instead. Create Node menu category The Calculate Level of Detail Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Calculate Level of Detail Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes The Calculate Level of Detail Texture 2D node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack. Inputs The Calculate Level of Detail Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture to use in the mip level calculation. UV Vector 2 UV The UV coordinate to use to calculate the Texture's mip level. Sampler SamplerState None The Sampler State and corresponding settings to use to calculate the Texture's mip level. Controls The Calculate Level of Detail Texture 2D node has one control: Name Type Options Description Clamp Toggle True, False When enabled, Shader Graph clamps the output mip level to the actual mips present on the provided Texture input. When disabled, Shader Graph returns an ideal mip level, based on an idealized Texture with all its mips present. Outputs The Calculate Level of Detail Texture 2D node has one output port: Name Type Description LOD Float The final calculated mip level of the Texture. Example graph usage In the following example, a Calculate Level of Detail Texture 2D node calculates the mip level of the Leaves_Albedo Texture for a set of UV coordinates and a specific Sampler State. It sends the calculated mip level for the Texture to the LOD input port on a Sample Texture 2D LOD node, which samples the same Texture: Related nodes The following nodes are related or similar to the Calculate Level of Detail Texture 2D node: Sample Texture 2D LOD node Sampler State node Gather Texture 2D node Texture 2D Asset node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Camera-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Camera-Node.html",
    "title": "Camera Node | Inventory System",
    "summary": "Camera Node Description Provides access to various parameters of the Camera currently being used for rendering. This is comprised of values the Camera's GameObject, such as Position and Direction, as well as various projection parameters. Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Position Output Vector 3 None Position of the Camera's GameObject in world space Direction Output Vector 3 None The Camera's forward vector direction Orthographic Output Float None Returns 1 if the Camera is orthographic, otherwise 0 Near Plane Output Float None The Camera's near plane distance Far Plane Output Float None The Camera's far plane distance Z Buffer Sign Output Float None Returns -1 when using a reversed Z Buffer, otherwise 1 Width Output Float None The Camera's width if orthographic Height Output Float None The Camera's height if orthographic Generated Code Example The following example code represents one possible outcome of this node. float3 _Camera_Position = _WorldSpaceCameraPos; float3 _Camera_Direction = -UNITY_MATRIX_V[2].xyz; float _Camera_Orthographic = unity_OrthoParams.w; float _Camera_NearPlane = _ProjectionParams.y; float _Camera_FarPlane = _ProjectionParams.z; float _Camera_ZBufferSign = _ProjectionParams.x; float _Camera_Width = unity_OrthoParams.x; float _Camera_Height = unity_OrthoParams.y;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ceiling-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ceiling-Node.html",
    "title": "Ceiling Node | Inventory System",
    "summary": "Ceiling Node Description Returns the smallest integer value, or whole number, that is greater than or equal to the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Ceiling_float4(float4 In, out float4 Out) { Out = ceil(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Mask-Node.html",
    "title": "Channel Mask Node | Inventory System",
    "summary": "Channel Mask Node Description Masks values of input In on channels selected in dropdown Channels. Outputs a vector of the same length as the input vector but with the selected channels set to 0. Channels available in the dropdown Channels will represent the amount of channels present in input In. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Channels Mask Dropdown Dynamic Selects any number of channels to mask Generated Code Example The following example code represents one possible outcome of this node. void Unity_ChannelMask_RedGreen_float4(float4 In, out float4 Out) { Out = float4(0, 0, In.b, In.a); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Mixer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Mixer-Node.html",
    "title": "Channel Mixer Node | Inventory System",
    "summary": "Channel Mixer Node Description Controls the amount each of the channels of input In contribute to each of the channels of output Out. The slider parameters on the node control the contribution of each of the input channels. The toggle button parameters control which of the output channels is currently being edited. Slider controls for editing the contribution of each input channnel range between -2 and 2. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Out Output Vector 3 None Output value Controls Name Type Options Description Toggle Button Array R, G, B Selects the output channel to edit. R Slider Controls contribution of input red channel to selected output channel. G Slider Controls contribution of input green channel to selected output channel. B Slider Controls contribution of input blue channel to selected output channel. Shader Function Generated Code Example The following example code represents one possible outcome of this node. _ChannelMixer_Red = float3 (OutRedInRed, OutRedInGreen, OutRedInBlue); _ChannelMixer_Green = float3 (OutGreenInRed, OutGreenInGreen, OutGreenInBlue); _ChannelMixer_Blue = float3 (OutBlueInRed, OutBlueInGreen, OutBlueInBlue); void Unity_ChannelMixer_float(float3 In, float3 _ChannelMixer_Red, float3 _ChannelMixer_Green, float3 _ChannelMixer_Blue, out float3 Out) { Out = float3(dot(In, _ChannelMixer_Red), dot(In, _ChannelMixer_Green), dot(In, _ChannelMixer_Blue)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Channel-Nodes.html",
    "title": "Channel Nodes | Inventory System",
    "summary": "Channel Nodes Combine Flip Creates new vectors from the four inputs R, G, B and A. Flips the individual channels of input In selected by the Node's parameters. Split Swizzle Splits the input vector In into four Float outputs R, G, B and A. Creates a new vector from the reordered elements of the input vector."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Checkerboard-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Checkerboard-Node.html",
    "title": "Checkerboard Node | Inventory System",
    "summary": "Checkerboard Node Description Generates a checkerboard of alternating colors between inputs Color A and Color B based on input UV. The checkerboard scale is defined by input Frequency. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Color A Input Color RGB None First checker color Color B Input Color RGB None Second checker color Frequency Input Vector 2 None Scale of checkerboard per axis Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Checkerboard_float(float2 UV, float3 ColorA, float3 ColorB, float2 Frequency, out float3 Out) { UV = (UV.xy + 0.5) * Frequency; float4 derivatives = float4(ddx(UV), ddy(UV)); float2 duv_length = sqrt(float2(dot(derivatives.xz, derivatives.xz), dot(derivatives.yw, derivatives.yw))); float width = 1.0; float2 distance3 = 4.0 * abs(frac(UV + 0.25) - 0.5) - width; float2 scale = 0.35 / duv_length.xy; float freqLimiter = sqrt(clamp(1.1f - max(duv_length.x, duv_length.y), 0.0, 1.0)); float2 vector_alpha = clamp(distance3 * scale.xy, -1.0, 1.0); float alpha = saturate(0.5f + 0.5f * vector_alpha.x * vector_alpha.y * freqLimiter); Out = lerp(ColorA, ColorB, alpha.xxx); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Circle-Pupil-Animation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Circle-Pupil-Animation-Node.html",
    "title": "Circle Pupil Animation Node | Inventory System",
    "summary": "Circle Pupil Animation Node This node applies a deformation to a normalized IrisUV coordinate to simulate the opening and closure of the pupil. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Circle Pupil Animation Node No Yes Ports name Direction type description IrisUV Input Vector2 Position of the fragment to shade in object space. Pupil Radius Input float Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. Maximal Pupil Aperture Input float The normal of the eye surface in object space. Minimal Pupil Aperture Input float The index of refraction of the eye (1.333 by default). Pupil Apertur Input float Distance between the end of the cornea and the iris plane. For the default model, this value should be 0.02 IrisUV Output Vector2 Position of the refracted point on the iris plane in object space."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Clamp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Clamp-Node.html",
    "title": "Clamp Node | Inventory System",
    "summary": "Clamp Node Description Returns the input In clamped between the minimum and maximum values defined by inputs Min and Max respectively. Ports Name Direction Type Description In Input Dynamic Vector Unclamped input value Min Input Dynamic Vector Minimum value Max Input Dynamic Vector Maximum value Out Output Dynamic Vector Clamped output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Clamp_float4(float4 In, float4 Min, float4 Max, out float4 Out) { Out = clamp(In, Min, Max); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Mask-Node.html",
    "title": "Color Mask Node | Inventory System",
    "summary": "Color Mask Node Description Creates a mask from values in input In equal to input Mask Color. Input Range can be used to define a wider range of values around input Mask Color to create the mask. Colors within this range will return 1, otherwise the node will return 0. Input Fuzziness can be used to soften the edges around the selection similar to anti-aliasing. Ports Name Direction Type Binding Description In Input Vector 3 None Input value. Mask Color Input Vector 3 Color Color to use for mask. Range Input Float None Select colors within this range from input Mask Color. Fuzziness Input Float None Feather edges around selection. Higher values result in a softer selection mask. Out Output Float None Output mask value. Generated Code Example The following example code represents one possible outcome of this node. void Unity_ColorMask_float(float3 In, float3 MaskColor, float Range, float Fuzziness, out float4 Out) { float Distance = distance(MaskColor, In); Out = saturate(1 - (Distance - Range) / max(Fuzziness, 1e-5)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Modes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Modes.html",
    "title": "Color Modes | Inventory System",
    "summary": "Color Modes Description Shader Graph can display colors on nodes in your graph to improve readability. This feature uses Color Modes to change which colors to display in the graph. Use the Color Mode: drop-down menu in the top right corner of the Shader Graph Window to change the Color Modes. Modes Name Description None Does not display colors on the nodes. All nodes use the default gray. Category Displays colors on the nodes based on their assigned category. See Category Colors below. Heatmap Displays colors on the nodes based on the nodes relative performance cost. By default, dark colored nodes contribute very little to the overall GPU performance cost of the shader and brighter colored nodes require more GPU computation to run. Precision Displays colors on the nodes based on the current Precision Mode in use. User Defined Lets you set the display colors on a per-node basis. These are custom colors for your graph. See User Defined Colors below. Category Colors This mode displays colors on the nodes based on their category. See the Node Library to learn about the different categories available. The table below lists current categories and their corresponding colors. Name Color Hex Value Artistic #DB773B Channel #97D13D Input #CB3022 Math #4B92F3 Procedural #9C4FFF Utility #AEAEAE UV #08D78B Note: Sub Graph nodes in a main Shader Graph fall in the Utility category. If you select Category mode, all Sub Graphs use the Utility color. Precision Colors This mode displays colors on the nodes based on their current precision. If you set a node to Inherit Precision, the display color reflects the currently active precision. See Precision Modes for more information about inheritance. User Defined Colors This mode displays colors on the nodes based on user preferences. In this mode, the user defines colors for each node. If a custom color is not set, the node displays in the default gray. To set a custom color for a node, right-click on the target node to bring up the the context menu, and select Color. Option Description Change... Brings up a color picker menu and lets you set your own custom color on the node. Reset Removes the currently selected color and sets it to the default gray. Overriding Default Colors For each project, you can override preset colors in the Category and Precision modes. Unity uses a .uss style sheet and Hex color codes to set colors. The default style sheet in your project is Packages/com.unity.shadergraph/Editor/Resources/Styles/ColorMode.uss. The best practice is to create a copy of this file to override the presets. Under your project's Assets folder, create a new Editor/Resources/Styles folder structure, and place a copy of ColorMode.uss in the Styles folder. Change the Hex color codes in this .uss file to override the presets and use your own custom colors for the Category and Precision modes."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Color-Node.html",
    "title": "Color Node | Inventory System",
    "summary": "Color Node Description Defines a constant Vector 4 value in the shader using a Color field. Can be converted to a Color Property Type via the Node's context menu. The value of the Mode parameter will also respected when generating the Property. NOTE: In versions prior to 10.0, Shader Graph assumed that HDR colors from the Color Node were in gamma space. Version 10.0 corrected this behavior, and Shader Graph now interprets HDR colors in linear space. HDR Color nodes that you created with older versions maintain the old behavior, but you can use the Graph Inspector to upgrade them. To mimic the old behavior on a new HDR Color node, you can use a Colorspace Conversion Node to convert the HDR color from RGB to Linear. Ports Name Direction Type Binding Description Out Output Vector 4 None Output value Controls Name Type Options Description Color Defines the output value. Mode Dropdown Default, HDR Sets properties of the Color field Generated Code Example The following example code represents one possible outcome of this node. float4 _Color = IsGammaSpace() ? float4(1, 2, 3, 4) : float4(SRGBToLinear(float3(1, 2, 3)), 4);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Colorspace-Conversion-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Colorspace-Conversion-Node.html",
    "title": "Colorspace Conversion Node | Inventory System",
    "summary": "Colorspace Conversion Node Description Returns the result of converting the value of input In from one colorspace space to another. The spaces to transform from and to are defined by the values of the dropdowns on the node. Ports Name Direction Type Description In Input Vector 3 Input value Out Output Vector 3 Output value Controls Name Type Options Description From Dropdown RGB, Linear, HSV Selects the colorspace to convert from To Dropdown RGB, Linear, HSV Selects the colorspace to convert to Generated Code Example The following example code represents one possible outcome of this node per from/to permutation. RGB > RGB void Unity_ColorspaceConversion_RGB_RGB_float(float3 In, out float3 Out) { Out = In; } RGB > Linear void Unity_ColorspaceConversion_RGB_Linear_float(float3 In, out float3 Out) { float3 linearRGBLo = In / 12.92;; float3 linearRGBHi = pow(max(abs((In + 0.055) / 1.055), 1.192092896e-07), float3(2.4, 2.4, 2.4)); Out = float3(In <= 0.04045) ? linearRGBLo : linearRGBHi; } RGB > HSV void Unity_ColorspaceConversion_RGB_HSV_float(float3 In, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; Out = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); } Linear > RGB void Unity_ColorspaceConversion_Linear_RGB_float(float3 In, out float3 Out) { float3 sRGBLo = In * 12.92; float3 sRGBHi = (pow(max(abs(In), 1.192092896e-07), float3(1.0 / 2.4, 1.0 / 2.4, 1.0 / 2.4)) * 1.055) - 0.055; Out = float3(In <= 0.0031308) ? sRGBLo : sRGBHi; } Linear > Linear void Unity_ColorspaceConversion_Linear_Linear_float(float3 In, out float3 Out) { Out = In; } Linear > HSV void Unity_ColorspaceConversion_Linear_HSV_float(float3 In, out float3 Out) { float3 sRGBLo = In * 12.92; float3 sRGBHi = (pow(max(abs(In), 1.192092896e-07), float3(1.0 / 2.4, 1.0 / 2.4, 1.0 / 2.4)) * 1.055) - 0.055; float3 Linear = float3(In <= 0.0031308) ? sRGBLo : sRGBHi; float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(Linear.bg, K.wz), float4(Linear.gb, K.xy), step(Linear.b, Linear.g)); float4 Q = lerp(float4(P.xyw, Linear.r), float4(Linear.r, P.yzx), step(P.x, Linear.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; Out = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); } HSV > RGB void Unity_ColorspaceConversion_HSV_RGB_float(float3 In, out float3 Out) { float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P = abs(frac(In.xxx + K.xyz) * 6.0 - K.www); Out = In.z * lerp(K.xxx, saturate(P - K.xxx), In.y); } HSV > Linear void Unity_ColorspaceConversion_HSV_Linear_float(float3 In, out float3 Out) { float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P = abs(frac(In.xxx + K.xyz) * 6.0 - K.www); float3 RGB = In.z * lerp(K.xxx, saturate(P - K.xxx), In.y); float3 linearRGBLo = RGB / 12.92; float3 linearRGBHi = pow(max(abs((RGB + 0.055) / 1.055), 1.192092896e-07), float3(2.4, 2.4, 2.4)); Out = float3(RGB <= 0.04045) ? linearRGBLo : linearRGBHi; } HSV > HSV void Unity_ColorspaceConversion_HSV_HSV_float(float3 In, out float3 Out) { Out = In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Combine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Combine-Node.html",
    "title": "Combine Node | Inventory System",
    "summary": "Combine Node Description Creates new vectors from the four inputs R, G, B and A. Output RGBA is a Vector 4 composed of inputs R, G, B and A. Output RGB is a Vector 3 composed of inputs R, G and B. Output RG is a Vector 2 composed of inputs R and G. Ports Name Direction Type Binding Description R Input Float None Defines red channel of output G Input Float None Defines green channel of output B Input Float None Defines blue channel of output A Input Float None Defines alpha channel of output RGBA Output Vector 4 None Output value as Vector 4 RGB Output Vector 3 None Output value as Vector 3 RG Output Vector 2 None Output value as Vector 2 Generated Code Example The following example code represents one possible outcome of this node. void Unity_Combine_float(float R, float G, float B, float A, out float4 RGBA, out float3 RGB, out float2 RG) { RGBA = float4(R, G, B, A); RGB = float3(R, G, B); RG = float2(R, G); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Comparison-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Comparison-Node.html",
    "title": "Comparison Node | Inventory System",
    "summary": "Comparison Node Description Compares the two input values A and B based on the condition selected on the dropdown. This is often used as an input to the Branch Node. Ports Name Direction Type Binding Description A Input Float None First input value B Input Float None Second input value Out Output Boolean None Output value Controls Name Type Options Description Dropdown Equal, NotEqual, Less, LessOrEqual, Greater, GreaterOrEqual Condition for comparison Generated Code Example The following example code represents one possible outcome of this node per comparison type. Equal void Unity_Comparison_Equal_float(float A, float B, out float Out) { Out = A == B ? 1 : 0; } NotEqual void Unity_Comparison_NotEqual_float(float A, float B, out float Out) { Out = A != B ? 1 : 0; } Less void Unity_Comparison_Less_float(float A, float B, out float Out) { Out = A < B ? 1 : 0; } LessOrEqual void Unity_Comparison_LessOrEqual_float(float A, float B, out float Out) { Out = A <= B ? 1 : 0; } Greater void Unity_Comparison_Greater_float(float A, float B, out float Out) { Out = A > B ? 1 : 0; } GreaterOrEqual void Unity_Comparison_GreaterOrEqual_float(float A, float B, out float Out) { Out = A >= B ? 1 : 0; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Compute-Deformation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Compute-Deformation-Node.html",
    "title": "Compute Deformation Node | Inventory System",
    "summary": "Compute Deformation Node Description This node lets you pass compute deformed vertex data to a vertex shader, and only works with the Entities Graphics package. You must provide DeformedVertexData in the _DeformedMeshData buffer. The node uses the _ComputeMeshIndex property to calculate where the DeformedVertexData associated with the current mesh are located in the _DeformedMeshData buffer. To output data, you must either install both the Entities Graphics package and DOTS Animation packages, or use a custom solution. Ports Name Direction Type Stage Description Position Output Vector3 Vertex Outputs the deformed vertex position. Normal Output Vector3 Vertex Outputs the deformed vertex normal. Tangent Output Vector3 Vertex Outputs the deformed vertex tangent."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Constant-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Constant-Node.html",
    "title": "Constant Node | Inventory System",
    "summary": "Constant Node Description Defines a Float of a mathematical constant value in the shader. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Mode Dropdown PI, TAU, PHI, E, SQRT2 Sets output constant value Generated Code Example The following example code represents one possible outcome of this node per constant type. PI float _Constant_PI = 3.1415926; TAU float _Constant_TAU = 6.28318530; PHI float _Constant_PHI = 1.618034; E float _Constant_E = 2.718282; SQRT2 float _Constant_SQRT2 = 1.414214;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Contrast-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Contrast-Node.html",
    "title": "Contrast Node | Inventory System",
    "summary": "Contrast Node Description Adjusts the contrast of input In by the amount of input Contrast. A Contrast value of 1 will return the input unaltered. A Contrast value of 0 will return the midpoint of the input. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Contrast Input Float None Contrast value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Contrast_float(float3 In, float Contrast, out float3 Out) { float midpoint = pow(0.5, 2.2); Out = (In - midpoint) * Contrast + midpoint; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cornea-Refraction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cornea-Refraction-Node.html",
    "title": "Cornea Refraction Node | Inventory System",
    "summary": "Cornea Refraction Node This node performs the refraction of the view ray in object space and returns the object space position that results. This is used to simulate the refraction that can be seen when looking at an eye. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Cornea Refraction Node No Yes Ports name Direction type description Position OS Input Vector3 Position of the fragment to shade in object space. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. Cornea Normal OS Input Vector3 The normal of the eye surface in object space. Cornea IOR Input float The index of refraction of the eye (1.333 by default). Iris Plane Offset Input float Distance between the end of the cornea and the iris plane. For the default model, this value should be 0.02 RefractedPositionOS Output Vector3 Position of the refracted point on the iris plane in object space."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cosine-Node.html",
    "title": "Cosine Node | Inventory System",
    "summary": "Cosine Node Description Returns the cosine of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Cosine_float4(float4 In, out float4 Out) { Out = cos(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Create-Node-Menu.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Create-Node-Menu.html",
    "title": "Create Node Menu | Inventory System",
    "summary": "Create Node Menu Description Use the Create Node Menu to create nodes in Shader Graph. To open the Create Node Menu, either right-click on the workspace in the Shader Graph Window and select Create Node, or press the spacebar. At the top of the Create Node Menu is a search bar. To search for a node, type any part of its name in the search field. The search box gives you autocomplete options, and you can press Tab to accept the predictive text. It highlights matching text in yellow. The Create Node Menu lists all nodes that are available in Shader Graph, categorized by their function. User-created Sub Graphs are also available in the Create Node Menu under Sub Graph Assets, or in a custom category that you define in the Sub Graph Asset. To add a node to the workspace, double-click it in the Create Node Menu. Contextual Create Node Menu A contextual Create Node Menu filters the available nodes, and only shows those that use the Data Type of a selected edge. It lists every available Port on nodes that match that Data Type. To open a contextual Create Node Menu, click and drag an Edge from a Port, and then release it in an empty area of the workspace. Master Stack Create Node Menu To add a new Block Node to the Master Stack, either right click and select Create Node or press spacebar with the stack selected. The Create Node Menu will display all available blocks for the master stack based on the render pipelines in your project. Any block can be added to the master stack via the Create Node Menu. If the block added is not compatible with the current Graph settings, the block will be disabled until the settings are configured to support it."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Create-Shader-Graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Create-Shader-Graph.html",
    "title": "Creating a new Shader Graph Asset | Inventory System",
    "summary": "Creating a new Shader Graph Asset After you configure an SRP, you can create a new Shader Graph Asset. Right-click the Project window, locate Create > Shader Graph in the context menu, then select your desired type of Shader Graph. The type of Shader Graph available is dependent on the render pipelines present in your project. Some options may or may not be present based on the render pipelines. The following options are always available: Blank Shader Graph A completely blank shader graph. No target is selected and no blocks are added to the Master Stack. Sub Graph A blank sub graph asset. A sub menu for each installed render pipeline may be present containing template stacks for standard shading models ( Lit, Unlit, etc ). For a full list of provided options, refer to the Universal Render Pipeline and High Definition Render Pipeline documentation. For this example, Universal is installed so a Unversal Lit Shader Graph has been created. Double-click your newly created Shader Graph Asset to open it in the Shader Graph window. Shader Graph window The Shader Graph window consists of the Master Stack, the Preview Window, the Blackboard, and the Graph Inspector. Master Stack The final connection that determines your shader output. Refer to Master Stack for more information. Preview window An area to preview the current shader output. Here, you can rotate the object, and zoom in and out. You can also change the basic mesh on which the shader is previewed. Refer to Main Preview for more information. Blackboard An area that contains all of the shader's properties in a single, collected view. Use the Blackboard to add, remove, rename, and reorder properties. Refer to Blackboard for more information. After you've set up a project, and become familiar with the Shader Graph window, refer to My first Shader Graph for more information on how to get started. Internal Inspector An area that contains information contextual to whatever the user is currently clicking on. It's a window that automatically is hidden by default and only appears when something is selected that can be edited by the user. Use the Internal Inspector to display and modify properties, node options, and the graph settings. Refer to Internal Inspector for more information."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cross-Product-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cross-Product-Node.html",
    "title": "Cross Product Node | Inventory System",
    "summary": "Cross Product Node Description Returns the cross product of the values of the inputs A and B. The cross product of two vectors results in a third vector which is perpendicular to the two input vectors. The result's magnitude is equal to the magnitudes of the two inputs multiplied together and then multiplied by the sine of the angle between the inputs. You can determine the direction of the result vector using the \"left hand rule\". Ports Name Direction Type Description A Input Vector 3 First input value B Input Vector 3 Second input value Out Output Vector 3 Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_CrossProduct_float(float3 A, float3 B, out float3 Out) { Out = cross(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cubemap-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Cubemap-Asset-Node.html",
    "title": "Cubemap Asset Node | Inventory System",
    "summary": "Cubemap Asset Node Description Defines a constant Cubemap Asset for use in the shader. To sample the Cubemap Asset it should be used in conjunction with a Sample Cubemap Node. When using a separate Cubemap Asset Node you can sample a Cubemap twice, with different parameters, without defining the Cubemap itself twice. Ports Name Direction Type Binding Description Out Output Cubemap None Output value Controls Name Type Options Description Object Field (Cubemap) Defines the cubemap asset from the project."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Function-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Function-Node.html",
    "title": "Custom Function Node | Inventory System",
    "summary": "Custom Function Node Description The Custom Function Node enables you to inject your own custom HLSL code in Shader Graphs. This provides you with an extra level of control when you need it (for example, to do some fine-grained optimization). You can either write small functions directly into graphs by using the string mode, or reference external HLSL include files. Use the Custom Port Menu to define your own input and output ports on the node itself. How to Use Use the Create Node Menu to create Custom Function nodes. By default, new Custom Function nodes don't have any input or output ports. In the Graph Inspector, open the Node Settings to access the Custom Function and Custom Port Menu menus. Custom Function menu Menu Item Description Inputs A Custom Port Menu that defines the node's input ports. Outputs A Custom Port Menu that defines the node's input ports. Type A function type selector. Choose File to reference an external file or string to directly input functions to the node. Name Part of the name this custom function has in the final generated code. Suffixed by the function type _half or _float. Source An asset field to reference the external HLSL include file. Only available in File mode. Body A text box where you enter HLSL code. Only available in String mode. Defining the Function via string If you select String mode, the graph generates the shader function. The Name field defines the name of the generated function, and the Body field defines the contents of the generated function. Unity handles the arguments, braces, and indent scope automatically. In String mode you may use the token $precision instead of half or float in the Body field. Unity replaces this with the correct type, based on that node's precision, when the node is processed. The example in the image above generates the following function: void MyFunction_float(float3 A, float B, out float3 Out) { Out = A + B + 1/2; } Defining the Function via file If you select File mode, the graph does not automatically generate the shader function. This mode injects an include reference in the final generated shader, and uses a function from within the referenced file. The Name field must match the name of the function you wish to call. The Source field contains a reference to the HLSL file that includes the function. When you use File mode for the Custom Function node, you must manually format the functions properly. One thing to note when creating custom functions for Shader Graph is the precision suffixes. The generated code appends a precision suffix to function names. Your include file function must also append your desired precision suffix (shown below with _float), or contain multiple functions with both _float and _half suffixes, but your Name field must not include the precision suffix. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED void MyFunction_float(float3 A, float B, out float3 Out) { Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED File mode allows for more flexbility with custom functions in a graph. You can define uniform variables outside of the function scope, as shown here with a matrix. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED float4x4 _MyMatrix; void MyFunction_float(float3 A, float B, out float3 Out) { A = mul(float4(A, 0.0), _MyMatrix).rgb; Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED You can define multiple functions in the same file, and call them from your referenced function. Alternatively, you can reference the same file, but use different functions from different Custom Function nodes. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED float3 MyOtherFunction_float(float3 In) { return In * In; } void MyFunction_float(float3 A, float B, out float3 Out) { A = MyOtherFunction_float(A); Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED You can even include other files that contain other functions. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED #include \"Assets/MyOtherInclude.hlsl\" void MyFunction_float(float3 A, float B, out float3 Out) { A = MyOtherFunction_float(A); Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED Reusing Custom Function Nodes The Custom Function node, on its own, is a single node instance. If you wish to re-use the same custom functions without re-creating the inputs, outputs, and function referencing, use Sub Graphs. Sub Graphs appear in the Create Node Menu, and they enable you to share or re-use your custom functions. Create your custom function either directly in a Sub Graph, or right-click the existing Custom Function node and select Convert to Sub Graph. To add the appropriate input and output ports, use the Graph Inspector and Custom Port Menu. After this, you can reuse your custom function as many times as needed, even within other Sub Graphs. Working with texture wires From version 10.3, Shader Graph has five new data structures to ensure that Custom Function Nodes (CFNs) and SubGraphs input and output data from texture wires in a consistent way. The new structures also make it possible for SamplerState to compile on GLES2 platforms and access data associated with textures via myInputTex.samplerstate and myInputTex.texelSize. Four structures are for the texture types, and one is for the sampler state: UnityTexture2D UnityTexture2DArray UnityTexture3D UnityTextureCube UnitySamplerState CFNs you create with earlier versions of Shader Graph continue to work after this change. As part of the automatic update, Unity transitions them to the new Bare node type. This type replicates the old input and output behavior. All other types pass the new structs. However, you should manually upgrade CFNs that produce texture or samplerstate types as output to ensure that they behave consistently—and to gain the benefits of the new design. Unity flags this type of outdated Custom Function Nodes with a warning when you open your Shader Graph in 10.3 or later. How to upgrade Change all of the input and output types from Bare to non-Bare. String type: Ensure that your HLSL string already uses Unity's texture access macros (such as SAMPLE_TEXTURE2D). File type: Replace Bare types (such as Texture2D) with the new struct types (such as UnityTexture2D) in your function parameters. If your HLSL code is using platform-specific or non-standard texture operations, you'll need to convert the way you access textures to take that structure into account. For example, myInputTex.GetDimensions(...) would become myInputTex.tex.GetDimensions(...) From version 10.3, you can access data associated with textures via myInputTex.samplerstate and myInputTex.texelSize."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Interpolators.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Interpolators.html",
    "title": "Custom Interpolators | Inventory System",
    "summary": "Custom Interpolators Description The Custom Interpolator feature provides fine-grained control over the specific calculations Shader Graph uses to bring data from the vertex stage to the pixel stage. There are two target audiences for Custom Interpolators: Technical Directors and Lead Technical Artists setting up environments for their teams. Graphics programmers helping artists to optimize content performance. Supported data types Custom interpolators support float, vec2, vec3, and vec4 options. Channel limits The Custom Interpolator feature supports a maximum of 32 channels. A channel is equivalent to four floats. Each float is an interpolator variable. Different platforms and GPUs have different interpolator variable limits. Exceeding the interpolator limitations of your target platform prevents your shaders from compiling. For detailed information about the number of interpolators supported by common interfaces, see the Unity documentation on Shader semantics, and view the section Interpolator count limits. Test your Custom Interpolators on your target configuration to ensure that your content compiles properly. Technical directors can set warnings and errors to help their team members avoid creating graphs with too many channels to be compatible with their target pipeline, platform, or GPU. See Creating channel warnings and errors below. How to use To use this feature, create a Custom Interpolator block in the Vertex context of the Master Stack and set a name and a data type. Create a vertex node to write data to that interpolator. Use the interpolator in your graph, then connect your graph to the relevant block in the Fragment context. These instructions include a contextual example illustrating the process of using a Custom Interpolator to fetch per-vertex data from a texture. To read the HLSL you use to replicate this behavior with the Built In Render Pipeline, see the Unity documentation on Shader semantics and view the section Vertex ID: SV_VertexID. Creating channel warnings and errors It is not possible to limit the number of channels a user can create in a Shader Graph. However, it is possible to create alerts to let users know when they are close to or exceeding a certain number of channels. The Warning Threshold lets users know that they are approaching the channel limit, and the Error Threshold informs them if they have reached or surpassed that limit. The Warning Threshold value must be between 8 and 32 channels. The Error Threshold value must be higher than the Warning Threshold, and has a minimum value of 8 channels. To configure these parameters, go to the Unity Editor Project Settings menu and open the Custom Interpolator Channel Settings. Adding a Custom Interpolator block to the Master Stack Right-click in the Vertex contex to create a block node. Select Custom Interpolator. Select a data type. Enter a name for this interpolator. In the illustrated example, you use the Vector 4 (vec4) data type. Writing data to the interpolator Right-click in your graph to create a node. Select the type Vertex ID. Connect this node to the Custom Interpolator block. In the example, you write Vertex ID values from your graph into the Custom Interpolator. Reading data from the interpolator Right-click in your graph to create a node. Select Custom Interpolator. Connect the Custom Interpolator node to the relevant block in the Fragment context. In this example, you connect to the Base Color block in order to pass the Vertex ID from the vertex shader to the fragment shader and use it as color output. Deleting the block from the Master Stack If you delete a Custom Interpolator which is associated with nodes that are still in your graph, Unity displays an alert. If you want to keep using these nodes, you can create a new Custom Interpolator and associate them with it. This prevents the alert from appearing."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Port-Menu.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Port-Menu.html",
    "title": "Custom Port Menu | Inventory System",
    "summary": "Custom Port Menu Description The Custom Port Menu is displayed in the Node Settings tab of the Graph Inspector by clicking on the Custom Function Node and Sub Graph output node. This menu allows you to add, remove, rename, reorder, and define the types of your custom input and output ports. How to Use Select the Custom Function Node or the Sub Graph output node to view the Custom Port Menu in the Inspector. To close the menu, click anywhere in the graph or on another graph-element. Adding and Removing Ports To add ports, click the + icon at the bottom right corner of the port list. To remove ports, select a port using the hamburger icon on the left, and click the - icon at the bottom right corner of the port list. Renaming Ports To rename a port, double-click its text field and enter the new name. Currently, only the following characters are valid for port names: A-Z, a-z, 0-9, _, ( ), and whitespace. If the name contains an invalid character, an error badge appears. Reordering Ports To reorder ports, click and hold the hamburger icon on the left, and drag the port to your desired place in the list. Changing Port Types To change a port type, use the Type drop-down menu on the right. See the Data Types page for a list of currently valid port types."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Accessing.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Accessing.html",
    "title": "Access Custom Render Texture shader properties | Inventory System",
    "summary": "Access Custom Render Texture shader properties If you want to create shaders, in Shader Graph, for use with Custom Render Textures, you need to understand how to access specific texture coordinates and other shader properties. Accessing the texture coordinates Shader Graph provides access to local and global texture coordinates via the UV Node: Channel 0 (localTexcoord): Provides the local texture coordinates. Channel 1 (globalTexcoord): Provides the global texture coordinates. To access these channels, add a UV node to your Shader Graph and select the appropriate channel. Access the cubemap view direction For shaders that interact with Cubemaps, use the View Direction node to retrieve the direction for the Cubemap sampling . Make sure that the space is set to World Space to get the correct direction vector. Access the Update Zone Index You can access the update zone index via the UV Node as well. Channel 2 (PrimitiveID): Provides the Primitive ID. The primitive ID corresponds to the index of the update zone being rendered. Additional resources Custom Render Textures Custom Render Texture Nodes UV node View Direction node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Example.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Example.html",
    "title": "Example Custom Render Texture with Shader Graph | Inventory System",
    "summary": "Example Custom Render Texture with Shader Graph This example demonstrates how to set up a Shader Graph for Custom Render Texture shaders to create a self-healing deformation effect that could be used for snow, sand, etc. For this effect, we need a Render Texture that contains the pixels we want to displace. This Render Texture is displayed at the top left corner of the preceding image. It was directly assigned to a camera that renders the objects in red above the UV plane. Create a Custom Render Texture Shader Graph as follows: Right-click in the Project window. Select Create > Shader Graph > Custom Render Texture and name your shader. Create a new Custom Render Texture as follows: Select Create > Rendering > Custom Render Texture. Configure the parameters to match the following image. Note: The material in the Material field was created. This Shader Graph reads the output of the Camera Render Texture, as well as the Self texture, then adds them and lerps the result so that it tends towards 0 over time. You should end up with something similar to the following: Finally you need to assign the Custom Render Texture to a material that can deform the geometry (tessellation or pixel displacement). New ShaderGraph Nodes for Custom Render Textures Three new ShaderGraph nodes have been introduced to facilitate working with Custom Render Textures: Custom Render Texture Self Outputs the double-buffered texture from the previous update. It provides three outputs for different types of textures: 2D, 3D, and Cube textures. Custom Render Texture Size Outputs the width, height, and volume depth of the current Custom Render Texture. Use this node to determine the size of the texture being worked with. Custom Render Texture Slice Outputs the current slice for 2D Texture Arrays or the Cubemap face index being updated. Known Limitations When working with Custom Render Texture shaders, be aware of the following limitations: Rendering Order The Custom Render Texture update loop runs before any rendering operations. This means: You cannot access any render pipeline-specific information in the shader, such as depth, normal, or scene color. Despite this, you can rely on the content of the Custom Render Texture being ready for use in the scene when the camera renders. Additional resources Custom Render Textures Custom Render Texture Nodes"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture-Nodes.html",
    "title": "Custom Render Texture Nodes | Inventory System",
    "summary": "Custom Render Texture Nodes Custom Render Texture Slice Custom Render Texture Size Custom Render Texture Self Access the custom render texture slice index and cubemap face. Access the custom render texture size. Access the custom render texture from the previous update."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Render-Texture.html",
    "title": "Custom Render Textures | Inventory System",
    "summary": "Custom Render Textures With Custom Render Textures, you can use Shader Graph to create shaders that are compatible with Custom Render Texture Update and Initialization materials. The following topics describe how to access the shader properties and set up a Shader Graph for Custom Render Texture shaders. Topic Description Access Custom Render Texture shader properties Access specific texture coordinates and other shader properties. Example Custom Render Texture with Shader Graph Set up a Shader Graph for Custom Render Texture shaders to create a self-healing deformation effect that could be used for snow, sand, etc. Additional resources Custom Render Textures."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Self.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Self.html",
    "title": "Custom Render Texture Self Node | Inventory System",
    "summary": "Custom Render Texture Self Node Description Provides the texture that contains the result of the previous update of the Custom Render Texture. Use the output that corresponds to the type of Custom Render Texture used. For more information on Custom Render Textures, refer to the Unity Manual. Ports Name Direction Type Binding Description Self Texture 2D Output Texture2D None 2D Texture object that contains the update result of the previous Custom Render Texture. Self Texture Cube Output Cubemap None Cubemap object that contains the update result of the previous Custom Render Texture. Self Texture 3D Output Texture3D None 3D Texture object that contains the update result of the previous Custom Render Texture. Generated Code Example The following example code represents one possible outcome of this node. UnityBuildTexture2DStructNoScale(_SelfTexture2D)"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Size.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Size.html",
    "title": "Custom Render Texture Size Node | Inventory System",
    "summary": "Custom Render Texture Size Node Description Provides the size of the current Custom Render Texture. For more information on Custom Render Textures, refer to the Unity Manual. Ports Name Direction Type Binding Description Texture Width Output Float None Width of the Custom Render Texture. Texture Height Output Float None Height of the Custom Render Texture. Texture Depth Output Float None Volume depth of the Custom Render Texture. This is valid only for 3D texture and 2D texture array types. Generated Code Example The following example code represents one possible outcome of this node. _CustomRenderTextureWidth"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Slice.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Custom-Texture-Slice.html",
    "title": "Custom Render Texture Slice Node | Inventory System",
    "summary": "Custom Render Texture Slice Node Description Provides the slice index or cubemap face of the current Custom Render Texture. When a Custom Render Texture is a Cubemap, 3D texture, or 2D texture array, Shader Graph issues multiple draw calls to update each slice or face separately. Use this node to get the slice index or cubemap face. For more information on Custom Render Textures, refer to the Unity Manual. Ports Name Direction Type Binding Description Texture Cube Face Output Float None The current face of the Custom Render Texture being updated. This value is an integer between 0 and 5 included. Texture Depth Slice Output Float None The current slice index of the Custom Render Texture being updated. This value is an integer between 0 and the volume depth of the texture. Generated Code Example The following example code represents one possible outcome of this node. _CustomRenderTextureCubeFace"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDX-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDX-Node.html",
    "title": "DDX Node | Inventory System",
    "summary": "DDX Node Description Returns the partial derivative of the input In with respect to the screen-space x-coordinate. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDX_float4(float4 In, out float4 Out) { Out = ddx(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDXY-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDXY-Node.html",
    "title": "DDXY Node | Inventory System",
    "summary": "DDXY Node Description Returns the sum of both partial derivatives of input In, with respect to the screen-space x-coordinate and screen-space y-coordinate respectively. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDXY_float4(float4 In, out float4 Out) { Out = ddxy(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDY-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/DDY-Node.html",
    "title": "DDY Node | Inventory System",
    "summary": "DDY Node Description Returns the partial derivative of the input In with respect to the screen-space y-coordinate. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDY_float4(float4 In, out float4 Out) { Out = ddy(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Data-Types.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Data-Types.html",
    "title": "Data Types | Inventory System",
    "summary": "Data Types Description There are a number of Data Types in Shader Graph. Each Port on a Node has an associated Data Type that defines what edges can be connected to it. The Data Types have colors for usability, these colors are applied to ports and edges of that Data Type. Some Data Types have associated Property Types for exposing these values to the Inspector for Materials that use the shader. Data Types Name Color Description Float Light Blue A Float or scalar value Vector 2 Green A Vector 2 value Vector 3 Yellow A Vector 3 value Vector 4 Pink A Vector 4 value Dynamic Vector Light Blue See Dynamic Data Types below Matrix 2 Blue A Matrix 2x2 value Matrix 3 Blue A Matrix 3x3 value Matrix 4 Blue A Matrix 4x4 value Dynamic Matrix Blue See Dynamic Data Types below Dynamic Blue See Dynamic Data Types below Boolean Purple A Boolean value. Defined as a float in the generated shader Texture 2D Red A Texture 2D asset Texture 2D Array Red A Texture 2D Array asset Texture 3D Red A Texture 3D asset Cubemap Red A Cubemap asset Virtual Texture Gray A Texture Stack Gradient Gray A Gradient value. Defined as a struct in the generated shader SamplerState Gray A state used for sampling a texture Promoting/Truncating All Vector types can be promoted or truncated to match any Vector type Port. This behaviour occurs only when the Port in question is not of type Dynamic Vector. When truncating, excess channels are simply removed. When promoting, the extra required channels are filled by default values. These values are (0, 0, 0, 1). Dynamic Data Types Some Data Types are dynamic. This means a port using these Data Types can change their underlying Concrete Data Type based on what Data Type is connected to it. By default, Nodes using dynamic Data Types can only have one Concrete Data Type, meaning that once a connected edge has applied its Data Type to that port, all other Dynamic Data Type slots of that Node will apply the same Data Type. One notable exception to this is the Multiply Node which allows both Dynamic Matrix and Vector types. Dynamic Vector The Dynamic Vector type allows connected edges of any Vector type. All connected edges are automatically truncated to the type with the lowest dimension, unless the lowest dimension is 1, in which case the Float is promoted. Dynamic Matrix The Dynamic Matrix type allows connected edges of any Matrix type. All connected edges are automatically truncated to the type with the lowest dimension. Dynamic The Dynamic type is a special case. Nodes that support it must define how it is validated. In the case of the Multiply Node, it allows connections of any Vector or Matrix type, ensuring the correct multiplication is applied depending on the mix of Data Types."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Degrees-To-Radians-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Degrees-To-Radians-Node.html",
    "title": "Degrees To Radians Node | Inventory System",
    "summary": "Degrees To Radians Node Description Returns the value of input In converted from degrees to radians. One degree is equivalent to approximately 0.0174533 radians and a full rotation of 360 degrees is equal to 2 Pi radians. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DegreesToRadians_float4(float4 In, out float4 Out) { Out = radians(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dielectric-Specular-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dielectric-Specular-Node.html",
    "title": "Dielectric Specular Node | Inventory System",
    "summary": "Dielectric Specular Node Description Returns a Dielectric Specular F0 value for a physically based material. The material to use can be selected with the Material dropdown parameter on the Node. A Common Material type defines a range between 0.034 and 0.048 sRGB values. The value between this range can be selected with the Range parameter. This Material type should be used for various materials such as plastics and fabrics. You can use Custom material type to define your own physically based material value. The output value in this case is defined by its index of refraction. This can be set by the parameter IOR. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Material Dropdown Common, RustedMetal, Water, Ice, Glass, Custom Selects the material value to output. Range Slider Controls output value for Common material type. IOR Slider Controls index of refraction for Custom material type. Generated Code Example The following example code represents one possible outcome of this node per Material mode. Common float _DielectricSpecular_Range = 0.5; float _DielectricSpecular_Out = lerp(0.034, 0.048, _DielectricSpecular_Range); RustedMetal float _DielectricSpecular_Out = 0.030; Water float _DielectricSpecular_Out = 0.020; Ice float _DielectricSpecular_Out = 0.018; Glass float _DielectricSpecular_Out = 0.040; Custom float _DielectricSpecular_IOR = 1; float _DielectricSpecular_Out = pow(_Node_IOR - 1, 2) / pow(_DielectricSpecular_IOR + 1, 2);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Diffusion-Profile-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Diffusion-Profile-Node.html",
    "title": "Diffusion Profile Node | Inventory System",
    "summary": "Diffusion Profile Node The Diffusion Profile Node allows you to sample a Diffusion Profile Asset in your Shader Graph. For information on what a Diffusion Profile is and the properties that it contains, see the Diffusion Profile documentation. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Diffusion Profile Node No Yes Ports name Direction type description Out Output float Outputs a unique float that the Shader uses to identify the Diffusion Profile. Notes The output of this Node is a float value that represents a Diffusion Profile. The Shader can use this value to find settings for the Diffusion Profile Asset that this value represents. If you modify the output value, the Shader can no longer use it to find the settings for the Diffusion Profile Asset. You can use this behavior to enable and disable Diffusion Profiles in your Shader Graph. To disable a Diffusion Profile, multiply the output by 0. To enable a Diffusion Profile, multiply the output by 1. This allows you to use multiple Diffusion Profiles in different parts of your Shader Graph. Be aware that the High Definition Render Pipeline (HDRP) does not support blending between Diffusion Profiles. This is because HDRP can only evaluate a single Diffusion Profile per pixel."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Distance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Distance-Node.html",
    "title": "Distance Node | Inventory System",
    "summary": "Distance Node Description Returns the euclidean distance between the values of the inputs A and B. This is useful for, among other things, calculating the distance between two points in space and is commonly used in calculating a Signed Distance Function. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Distance_float4(float4 A, float4 B, out float Out) { Out = distance(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dither-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dither-Node.html",
    "title": "Dither Node | Inventory System",
    "summary": "Dither Node Description Dither is an intentional form of noise used to randomize quantization error. It is used to prevent large-scale patterns such as color banding in images. The Dither node applies dithering in screen-space to ensure a uniform distribution of the pattern. This can be adjusted by connecting another node to input Screen Position. This Node is commonly used as an input to Alpha Clip Threshold on the Master Node to give the appearance of transparency to an opaque item. This is useful for creating geometry that appears to be transparent but has the advantages of rendering as opaque, such as writing depth or being rendered in deferred. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Screen Position Input Vector 4 Screen Position Coordinates used to apply dither pattern Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Dither_float4(float4 In, float4 ScreenPosition, out float4 Out) { float2 uv = ScreenPosition.xy * _ScreenParams.xy; float DITHER_THRESHOLDS[16] = { 1.0 / 17.0, 9.0 / 17.0, 3.0 / 17.0, 11.0 / 17.0, 13.0 / 17.0, 5.0 / 17.0, 15.0 / 17.0, 7.0 / 17.0, 4.0 / 17.0, 12.0 / 17.0, 2.0 / 17.0, 10.0 / 17.0, 16.0 / 17.0, 8.0 / 17.0, 14.0 / 17.0, 6.0 / 17.0 }; uint index = (uint(uv.x) % 4) * 4 + uint(uv.y) % 4; Out = In - DITHER_THRESHOLDS[index]; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Divide-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Divide-Node.html",
    "title": "Divide Node | Inventory System",
    "summary": "Divide Node Description Returns the result of input A (dividend) divided by input B (divisor). Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Divide_float4(float4 A, float4 B, out float4 Out) { Out = A / B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dot-Product-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Dot-Product-Node.html",
    "title": "Dot Product Node | Inventory System",
    "summary": "Dot Product Node Description Returns the dot product, or scalar product, of the two input vectors A and B. The dot product is a value equal to the magnitudes of the two vectors multiplied together and then multiplied by the cosine of the angle between them. For normalized input vectors, the Dot Product node returns 1 if they point in exactly the same direction, -1 if they point in completely opposite directions and 0 if the vectors are perpendicular. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DotProduct_float4(float4 A, float4 B, out float Out) { Out = dot(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Edge.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Edge.html",
    "title": "Edge | Inventory System",
    "summary": "Edge Description An Edge defines a connection between two Ports. Edges define how data flows through the Shader Graph node network. They can only be connected from an input Port to an output Port. Each Edge has a Data Type which defines what Ports it can be connected to. Each Data Type has an associated color for identifying its type. You can create a new Edge by clicking and dragging from a Port with the left mouse button. Edges can be deleted with Delete (Windows), Command + Backspace (OSX) or from the context menu by right clicking on the Node. You can open a contextual Create Node Menu by dragging an Edge from a Port with the left mouse button and releasing it in an empty area of the workspace."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ellipse-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Ellipse-Node.html",
    "title": "Ellipse Node | Inventory System",
    "summary": "Ellipse Node Description Generates an ellipse shape based on input UV at the size specified by inputs Width and Height. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating dot effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Ellipse width Height Input Float None Ellipse height Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Ellipse_float(float2 UV, float Width, float Height, out float4 Out) { float d = length((UV * 2 - 1) / float2(Width, Height)); Out = saturate((1 - d) / fwidth(d)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Emission-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Emission-Node.html",
    "title": "Emission Node | Inventory System",
    "summary": "Emission Node The Emission Node allows you to apply emission in your Shader Graph. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Emission No Yes Ports Name Direction Type Description color Input LDR Color(RGB) Sets the low dynamic range (LDR) color of the emission. intensity Input Float Sets the intensity of the emission color. output Output HDR Color(RGB) Outputs the high dynamic range (HDR) color that this Node produces. Notes Emission Unit You can use two physical light units to control the strength of the emission: Nits. EV100. Exposure Weight You can use Exposure Weight to determine how exposure affects emission. It is a value between 0 and 1 where. A value of 0 means that exposure does not effect this part of the emission. A value of 1 means that exposure fully affects this part of the emission."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Exponential-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Exponential-Node.html",
    "title": "Exponential Node | Inventory System",
    "summary": "Exponential Node Description Returns the exponential value of input In. The exponential base can be switched between base-e and base 2 from the Base dropdown on the node. Base E : Returns e to the power of input In Base 2 : Returns 2 to the power of input In Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Base Dropdown BaseE, Base2 Selects the exponential base Generated Code Example The following example code represents one possible outcome of this node per Base mode. Base E void Unity_Exponential_float4(float4 In, out float4 Out) { Out = exp(In); } Base 2 void Unity_Exponential2_float4(float4 In, out float4 Out) { Out = exp2(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Exposure-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Exposure-Node.html",
    "title": "Exposure Node | Inventory System",
    "summary": "Exposure Node The Exposure Node allows you to get the Camera's exposure value from the current or previous frame. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Exposure No Yes Ports name Direction type description Output Output float The exposure value. Exposure Type You can use Exposure Type to select which exposure value to get. | name | description | |--- | ---| | CurrentMultiplier | Gets the Camera's exposure value from the current frame. | | InverseCurrentMultiplier | Gets the inverse of the Camera's exposure value from the current frame. | | PreviousMultiplier | Gets the Camera's exposure value from the previous frame. | | InversePreviousMultiplier | Gets the inverse of the Camera's exposure value from the previous frame. |"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Eye-Index-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Eye-Index-Node.html",
    "title": "Eye Index Node | Inventory System",
    "summary": "Eye Index Node Description Provides access to the Eye Index when stereo rendering is enabled. Ports Name Direction Type Binding Description Out Output Float None Eye Index for the camera of a stereo draw."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Eye-Surface-Type-Debug-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Eye-Surface-Type-Debug-Node.html",
    "title": "Eye Surface Type Debug Node | Inventory System",
    "summary": "Eye Surface Type Debug Node Debug node that allows you to visually validate the current pupil radius. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Eye Surface Type Debug Node No Yes Ports name Direction type description PositionOS Input Vector3 Position in object space of the current fragment to shade. EyeColor Input Color Final Diffuse color of the Eye. IrisRadius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. Pupil Radius Input float Radius of the pupil in the iris texture as a percentage. IsActive Input bool Flag that defines if the node should be active. SurfaceColor Output Color Final Diffuse color of the Eye."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fade-Transition-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fade-Transition-Node.html",
    "title": "Fade Transition Node | Inventory System",
    "summary": "Fade Transition Node Description Fade Transition is a method of adding noise to add variation while a function transitions from on to off. This node takes in a fade value and remaps it using the noise value (usually from a texture). When FadeValue is 0, the output is always 0, and when FadeValue is 1, the output is always exactly 1. In between 0 and 1 the transition will follow the pattern in the noise. This Node is commonly used as an input to Alpha on a Master Node to provide an LOD transition. Ports Name Direction Type Binding Description Texture Input Texture 2D None Input value Noise Input Float None The noise variation to apply to the fade function FadeValue Input Float None The amount of transition to apply FadeContrast Input Float None The contrast at which a single pixel goes from fully transparent to fully opaque. Higher values cause sharper edges in the transition Fade Output Float None The resulting fade value Generated Code Example The following example code represents one possible outcome of this node. float Unity_FadeTransitionNode_ApplyFade_float(float noise, float fadeValue, float fadeContrast) { float ret = saturate(fadeValue*(fadeContrast+1)+(noise-1)*fadeContrast); return ret; } float Result = Unity_FadeTransitionNode_ApplyFade_float( _NoiseValue, _FadeValue, _FadeContrast);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/First-Shader-Graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/First-Shader-Graph.html",
    "title": "My first Shader Graph | Inventory System",
    "summary": "My first Shader Graph Before you begin, make sure that your project is set up properly, and the graphs are loading correctly. See Getting started with Shader Graph for more information. Create a New Graph Use the Project Browser to create a new Shader Graph Asset in your project. The Create > Shader Graph will display the various creation options. A Blank Shader Graph will create a Shader Graph with no selected active targets or block nodes. You will need to select a target via the Graph Settings Menu to continue. Certain integrations, like Render Pipelines, can also provide pre-configured options for Shader Graphs. For this example, a Universal > Lit Shader Graph has been created and opened. Create a new node Use the Create Node menu to create new nodes. There are two ways to open the menu: Right click, and select Create Node from the context menu. Press the spacebar. In the menu, you can type in the search bar to look for specific nodes, or browse all nodes in the library. In this example, we'll create a Color node. First, type \"color\" in the Create Node menu's search bar. Then, click Color, or highlight Color and press Enter to create a Color node. Connect nodes To build a graph, you need to connect nodes together. To do so, click the Output Slot of a node, and drag that connection into the Input Slot of another node. Start by connecting the Color node to the Base Color block of our Fragment Stack. Change node output Notice that the connection updated the main preview, and the 3D Object in the Main Preview is now black, which is the color specified in the Color node. You can click on the color bar in that node, and use the color picker to change the color. Any changes you make on the node updates the object in the Main Preview in real time. For example, if you pick red, the 3D Object immediately reflects this change. Save the graph Currently, Shader Graphs do not automatically save. There are two ways to save your changes: Click the Save Asset button in the top left corner of the window. Close the graph. If Unity detects any unsaved changes, a pop-up window appears, and asks if you want to save those changes. Create a Material After saving your graph, use the shader to create a new Material. The process of creating a new Material and assigning it a Shader Graph shader is the same as that for regular shaders. In either the main menu or the Project View context menu, select Assets > Create > Material. Select the Material you just created. In its Inspector window, select the Shader drop-down menu, click Shader Graphs, and choose the Shader Graph shader you wish to apply to the Material. You can also right-click the Shader Graph shader, and select Create > Material. This method automatically assigns that Shader Graph shader to the newly created Material. A Material is also automatically generated as a subasset of the Shader Graph. You can assign it directly to an object in your scene. Modifying a property from the Blackboard on the Shader Graph will update this material in real time, which allows for quick visualization in the scene. Put the Material in the Scene Now that you have assigned your shader to a Material, you can apply it to objects in the Scene. Drag and drop the Material onto an object in the Scene. Alternatively, in the object's Inspector window, locate Mesh Renderer > Materials, and apply the Material to the Element. Use properties to edit the graph You can also use properties to alter your shader's appearance. Properties are options that are visible from the Material's Inspector, which lets others change settings in your shader without the need to open the Shader Graph. To create a new property, use the Add (+) button on the top right corner of the Blackboard, and select the type of property to create. In this example, we'll select Color. This adds a new property in the Blackboard with the following options in the Node Settings tab of the Graph Inspector when the property is selected. Option Description Property button To change the name of the property, right-click the button in the Blackboard, select Rename, then enter a new property name. To delete the property, right-click the button, and select Delete. Exposed Enable this checkbox to make the property visible from the Material's Inspector. Reference The property's name that appears in C# scripts. To change the Reference name, enter a new string. Default The default value of the property. Mode The mode of the property. Each property has different modes. For Color, you can select either Default or HDR. Precision The default precision of the property. Hybrid Instanced An experimental feature that enables this property to be instanced when using the Hybrid DOTS renderer. There are two ways to reference a property in your graph: Drag the property from the Blackboard onto the graph. Right-click and select Create Node. The property is listed in the Properties category. Try connecting the property to the Base Color block. The object immediately changes to black. Save your graph, and return to the Material's Inspector. The property now appears in the Inspector. Any changes you make to the property in the Inspector affects all objects that use this Material. More Tutorials Older tutorials use an outdated format of Shader Graph with master nodes. When looking at older tutorials, reference the Upgrade Guide for tips on how to convert the master node to a Master Stack. To keep exploring how to use Shader Graph to author shaders, check out these blog posts: Art That Moves: Creating Animated Materials with Shader Graph Custom Lighting in Shader Graph: Expanding Your Graphs in 2019 You can also visit the Unity YouTube Channel and look for video tutorials on Shader Graph, or head to our user forum to find the latest information and conversations about Shader Graph."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Flip-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Flip-Node.html",
    "title": "Flip Node | Inventory System",
    "summary": "Flip Node Description Flips the individual channels of input In selected by the Node's parameters. Positive values become negative values and vice versa. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Red Toggle True, False If true red channel will be flipped. Green Toggle True, False If true green channel will be flipped. Disabled if In is Float. Blue Toggle True, False If true blue channel will be flipped. Disabled if In is Vector 2 or smaller. Alpha Toggle True, False If true alpha channel will be flipped. Disabled if In is Vector 3 or smaller. Generated Code Example The following example code represents one possible outcome of this node. float2 _Flip_Flip = float4(Red, Green, Blue, Alpha); void Unity_Flip_float4(float4 In, float4 Flip, out float4 Out) { Out = (Flip * -2 + 1) * In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Flipbook-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Flipbook-Node.html",
    "title": "Flipbook Node | Inventory System",
    "summary": "Flipbook Node Description Creates a flipbook, or texture sheet animation, of the UVs supplied to input UV. The amount of tiles on the sheet are defined by the values of the inputs Width and Height. The index of the current tile is defined by the value of the input Tile. This node can be used to create a texture animation functionality, commonly used for particle effects and sprites, by supplying Time to the input Tile and outputting to the UV input slot of a Texture Sampler. UV data is typically in the range of 0 to 1 starting from the bottom left of UV space. This can be seen by the black value at the bottom left corner of a UV preview. As flipbooks typically start from top left the parameter Invert Y is enabled by default, however you can change the direction of the Flipbook by switching the Invert X and Invert Y parameters. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Amount of horizontal tiles Height Input Float None Amount of vertical tiles Tile Input Float None Current tile index Out Output Vector 2 None Output UV value Controls Name Type Options Description Invert X Toggle True, False If enabled tiles are iterated from right to left Invert Y Toggle True, False If enabled tiles are iterated from top to bottom Generated Code Example The following example code represents one possible outcome of this node. float2 _Flipbook_Invert = float2(FlipX, FlipY); void Unity_Flipbook_float(float2 UV, float Width, float Height, float Tile, float2 Invert, out float2 Out) { Tile = floor(fmod(Tile + float(0.00001), Width*Height)); float2 tileCount = float2(1.0, 1.0) / float2(Width, Height); float base = floor((Tile + float(0.5)) * tileCount.x); float tileX = (Tile - Width * base); float tileY = (Invert.y * Height - (base + Invert.y * 1)); Out = (UV + float2(tileX, tileY)) * tileCount; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Float.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Float.html",
    "title": "Float Node | Inventory System",
    "summary": "Float Node Description Defines a Float value in the shader. If Port X is not connected with an Edge this Node defines a constant Float. Ports Name Direction Type Binding Description X Input Float None Input x component value Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. float _Vector1_Out = X;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Floor-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Floor-Node.html",
    "title": "Floor Node | Inventory System",
    "summary": "Floor Node Description Returns the largest integer value, or whole number, that is less than or equal to the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Floor_float4(float4 In, out float4 Out) { Out = floor(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fog-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fog-Node.html",
    "title": "Fog Node | Inventory System",
    "summary": "Fog Node Description Provides access to the Scene's Fog parameters. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Position Input Vector 3 Position (object space) Mesh vertex/fragment's position Color Output Vector 4 None Fog color Density Output Float None Fog density based on depth. Returns a value between 0 and 1, where 0 is no fog and 1 is full fog. Generated Code Example The following example code represents one possible outcome of this node. void Unity_Fog_float(float3 Position, out float4 Color, out float Density) { SHADERGRAPH_FOG(Position, Color, Density); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fraction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fraction-Node.html",
    "title": "Fraction Node | Inventory System",
    "summary": "Fraction Node Description Returns the fractional (or decimal) part of input In; which is greater than or equal to 0 and less than 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Fraction_float4(float4 In, out float4 Out) { Out = frac(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fresnel-Effect-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fresnel-Effect-Node.html",
    "title": "Fresnel Effect Node | Inventory System",
    "summary": "Fresnel Effect Node Description Fresnel Effect is the effect of differing reflectance on a surface depending on viewing angle, where as you approach the grazing angle more light is reflected. The Fresnel Effect node approximates this by calculating the angle between the surface normal and the view direction. The wider this angle is, the greater the return value will be. This effect is often used to achieve rim lighting, common in many art styles. Ports Name Direction Type Description Normal Input Vector 3 Normal direction. By default bound to World Space Normal View Dir Input Vector 3 View direction. By default bound to World Space View Direction Power Input Float Exponent of the power calculation Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_FresnelEffect_float(float3 Normal, float3 ViewDir, float Power, out float Out) { Out = pow((1.0 - saturate(dot(normalize(Normal), normalize(ViewDir)))), Power); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fresnel-Equation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Fresnel-Equation-Node.html",
    "title": "Fresnel Equation Node | Inventory System",
    "summary": "Fresnel Equation Node Description The Fresnel Equation Node adds equations that affect Material interactions to the Fresnel Component. You can select an equation in the Mode dropdown. You can find Numerical values of refractive indices at refractiveindex.info. Ports (Schlick) Name Direction Type Binding Description f0 Input Vector{1, 2, 3} None Represente the reflection of the surface when we face typically 0.02-0.08 for a dielectric material. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None Fresnel coefficient, which describe the amount of light reflected or transmitted. Ports (Dielectric) Name Direction Type Binding Description IOR Source Input Vector None The refractive index of the medium the light source originates in. IOR Medium Input Vector None The refractive index of the medium that the light refracts into. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None The fresnel coefficient, which describe the amount of light reflected or transmitted. Ports (DielectricGeneric) Name Direction Type Binding Description IOR Source Input Vector None The refractive index of the medium the light source originates in. IOR Medium Input Vector None The refractive index of the medium that the light refracts into. IOR MediumK Input Vector None The refractive index Medium (imaginary part), or the medium causing the refraction. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None Fresnel coefficient, which describe the amount of light reflected or transmitted. Controls Name Type Options Description Mode Dropdown • Schlick: This mode produces an approximation based on Schlick's Approximation. Use the Schlick mode for interactions between air and dielectric materials. • Dielectric: Use this mode for interactions between two dielectric Materials. For example, air to glass, glass to water, or water to air. • DielectricGeneric: This mode computes a Fresnel equation for interactions between a dielectric and a metal. For example, clear-coat- to metal, glass to metal, or water to metal. Note: if the IORMediumK value is 0, DielectricGeneric behaves in the same way as the Dielectric mode. Generated Code Example The following example code represents one possible outcome of this node. void Unity_FresnelEquation_Schlick(out float Fresnel, float cos0, float f0) { Fresnel = F_Schlick(f0, cos0); } void Unity_FresnelEquation_Dielectric(out float3 Fresnel, float cos0, float3 iorSource, float3 iorMedium) { FresnelValue = F_FresnelDielectric(iorMedium/iorSource, cos0); } void Unity_FresnelEquation_DielectricGeneric(out float3 Fresnel, float cos0, float3 iorSource, float3 iorMedium, float3 iorMediumK) { FresnelValue = F_FresnelConductor(iorMedium/iorSource, iorMediumK/iorSource, cos0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gather-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gather-Texture-2D-Node.html",
    "title": "Gather Texture 2D node | Inventory System",
    "summary": "Gather Texture 2D node The Gather Texture 2D node samples the red channel of four neighboring pixels from a sample point. It returns a value of RRRR, and takes each R value from a different neighbor. Normal Texture sampling reads all four channels (RGBA) of a Texture. This node is useful when you want to modify the bilinear interpolation between pixels, such as when you want to create custom blends. This node uses the Gather HLSL intrinsic function. For platforms where this intrinsic function doesn't exist, Shader Graph uses an appropriate approximation, instead. Note When you use the Metal graphics API, the sample, sample_compare, gather, and gather_compare intrinsics use an integer (int2) offset argument when sampling or gathering from a 2D Texture. The intrinsics apply this value to Texture coordinates before looking up each pixel. The offset value must be in the range of -8 to +7, or the Metal API clamps the offset value. The pixels that the Gather Texture 2D samples are always from the top mip level of the Texture, from a 2×2 block of pixels around the sample point. Rather than blending the 2×2 sample, it returns the sampled pixels in counter-clockwise order. It starts with the sample to the lower left of the query location: Create Node menu category The Gather Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Gather Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes The Gather Texture 2D node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack. Inputs The Gather Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture to sample. UV Vector 2 UV The UV coordinates to use to take the sample. Sampler SamplerState None The Sampler State and its corresponding settings to use for the sample. Offset Vector 2 None The pixel offset to apply to the sample's UV coordinates. The Offset value is in pixels, not UV space. Outputs The Gather Texture 2D node has the following output ports: Name Type Description RGBA Vector 4 The sample value. This is the red channels of the 4 neighboring pixels from the specified sample position on the given Texture. R Float The first neighboring pixel's red channel. G Float The second neighboring pixel's red channel. B Float The third neighboring pixel's red channel. A Float The fourth neighboring pixel's red channel. Example graph usage In the following example, a Gather Texture 2D node creates a blurred version of a Texture by averaging its 4 samples: Then, the rest of the Shader Graph uses a Sample Texture 2D node to sample the Texture again, and uses a Lerp node to determine when to use the blurred Texture and when to use the regular Texture: By changing the value provided to the T port on the Lerp node, you can change whether you want to blur or sharpen the Texture in your Shader Graph: Related nodes The following nodes are related or similar to the Gather Texture 2D node: Sample Texture 2D node Sample Texture 2D LOD node Sampler State node Texture 2D Asset node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Getting-Started.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Getting-Started.html",
    "title": "Getting started with Shader Graph | Inventory System",
    "summary": "Getting started with Shader Graph Use Shader Graph with either of the Scriptable Render Pipelines (SRPs) available in Unity version 2018.1 and later: The High Definition Render Pipeline (HDRP) The Universal Render Pipeline (URP) As of Unity version 2021.2, you can also use Shader Graph with the Built-In Render Pipeline. Note Shader Graph support for the Built-In Render Pipeline is for compatibility purposes only. Shader Graph doesn't receive updates for Built-In Render Pipeline support, aside from bug fixes for existing features. It's recommended to use Shader Graph with the Scriptable Render Pipelines. When you install HDRP or URP into your project, Unity also installs the Shader Graph package automatically. You can manually install Shader Graph for use with the Built-In Render Pipeline on Unity version 2021.2 and later with the Package Manager. For more information on how to install a package, see Adding and removing packages in the Unity User Manual. For more information about how to set up a Scriptable Render Pipeline, see Getting started with HDRP or Getting started with URP."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gradient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gradient-Node.html",
    "title": "Gradient Node | Inventory System",
    "summary": "Gradient Node Description Defines a constant Gradient for use in Shader Graph, although internally to the shader this is defined as a struct. To sample the Gradient it should be used in conjunction with a Sample Gradient Node. When using a separate Gradient Node, you can sample a Gradient multiple times with different Time parameters. Ports Name Direction Type Description Out Output Gradient Output value Controls Name Type Options Description Gradient Field Defines the gradient. Generated Code Example The following example code represents one possible outcome of this node. Gradient Unity_Gradient_float() { Gradient g; g.type = 1; g.colorsLength = 4; g.alphasLength = 4; g.colors[0] = 0.1; g.colors[1] = 0.2; g.colors[2] = 0.3; g.colors[3] = 0.4; g.colors[4] = 0; g.colors[5] = 0; g.colors[6] = 0; g.colors[7] = 0; g.alphas[0] = 0.1; g.alphas[1] = 0.2; g.alphas[2] = 0.3; g.alphas[3] = 0.4; g.alphas[4] = 0; g.alphas[5] = 0; g.alphas[6] = 0; g.alphas[7] = 0; return g; } Gradient _Gradient = Unity_Gradient_float();"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gradient-Noise-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Gradient-Noise-Node.html",
    "title": "Gradient Noise Node | Inventory System",
    "summary": "Gradient Noise Node Description Generates a gradient, or Perlin, noise based on input UV. The scale of the generated noise is controlled by input Scale. In terms of performance cost, Gradient Noise node can be slightly more computationally intensive than sampling a texture map. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Gradient Noise node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Because the UV value is used as the seed for the noise generation, you can offset, scale, or distort the UV value to generate different noise patterns. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Scale Input Float None Noise scale Out Output Float None Output value in the range 0.0 to 1.0 Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacyMod Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. float2 unity_gradientNoise_dir(float2 p) { p = p % 289; float x = (34 * p.x + 1) * p.x % 289 + p.y; x = (34 * x + 1) * x % 289; x = frac(x / 41) * 2 - 1; return normalize(float2(x - floor(x + 0.5), abs(x) - 0.5)); } float unity_gradientNoise(float2 p) { float2 ip = floor(p); float2 fp = frac(p); float d00 = dot(unity_gradientNoise_dir(ip), fp); float d01 = dot(unity_gradientNoise_dir(ip + float2(0, 1)), fp - float2(0, 1)); float d10 = dot(unity_gradientNoise_dir(ip + float2(1, 0)), fp - float2(1, 0)); float d11 = dot(unity_gradientNoise_dir(ip + float2(1, 1)), fp - float2(1, 1)); fp = fp * fp * fp * (fp * (fp * 6 - 15) + 10); return lerp(lerp(d00, d01, fp.y), lerp(d10, d11, fp.y), fp.x); } void Unity_GradientNoise_float(float2 UV, float Scale, out float Out) { Out = unity_gradientNoise(UV * Scale) + 0.5; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Graph-Settings-Tab.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Graph-Settings-Tab.html",
    "title": "Graph Settings Tab | Inventory System",
    "summary": "Graph Settings Tab Description The Graph Settings tab on the Graph Inspector make it possible to change settings that affect the Shader Graph as a whole. Graph Settings options Menu Item Description Precision A Precision Mode drop-down menu that lets you set the default precision for the entire graph. You can override the Precision setting here at the node level in your graph. Preview Mode (Subgraphs only) Your options are Inherit, Preview 2D, and Preview 3D. Active Targets A list that contains the Targets you've selected. You can add or remove entries using the Add (+) and Remove (-) buttons. Shader Graph supports three targets: the Universal Render Pipeline, the High Definition Render Pipeline, and Built-In Render Pipeline. Target-specific settings appear below the standard setting options. The displayed Target-specific settings change according to which Targets you select."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Graph-Target.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Graph-Target.html",
    "title": "Graph Target | Inventory System",
    "summary": "Graph Target A Target determines the end point compatibility of a shader you generate using Shader Graph. You can select Targets for each Shader Graph asset, and use the Graph Settings Menu to change the Targets. Targets hold information such as the required generation format, and variables that allow compatibility with different render pipelines or integration features like Visual Effect Graph. You can select any number of Targets for each Shader Graph asset. If a Target you select isn't compatible with other Targets you've already selected, an error message that explains the problem appears. Target Settings are specific to each Target, and can vary between assets depending on which Targets you've selected. Be aware that Universal Render Pipeline (URP) Target Settings and High Definition Render Pipeline (HDRP) Target Settings might change in future versions. Typically, each Target you select generates a valid subshader from the graph. For example, a Shader Graph asset with both URP and HDRP Targets will generate two subshaders. When you use a graph that targets multiple render pipelines, you must reimport the Shader Graph asset if you change the active render pipeline. This updates the Material Inspector for any Materials that use your graph. Shader Graph supports three targets: the Universal Render Pipeline, the High Definition Render Pipeline, and the Built-In Render Pipeline. Not all blocks are compatible with all targets. If a block in your graph becomes inactive when you choose a target, that block is not compatible with that target. The visual results of a graph are not the same in all render pipelines. This is because of the technical differences between URP, Built-In, and HDRP. Shader Graphs that target the Built-In Render Pipeline replicate the results of shaders handwritten in ShaderLab, with the exception of normal maps. For mathematical correctness, normal maps created with Shader Graph behave as they do in URP even when your build targets the Built-In Render Pipeline."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Custom-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Custom-Color-Node.html",
    "title": "Custom Color Node (HDRP) | Inventory System",
    "summary": "Custom Color Node (HDRP) The Custom Color Node accesses the custom pass color buffer allocated by HDRP. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Custom Color Node No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Output Output Vector 4 None The value the custom pass color buffer contains at the sampled coordinates. Generated Code Example The following example code represents one possible outcome of this node. void Unity_CustomDepth_LinearEye_float(float4 UV, out float Out) { Out = SampleCustomColor(UV.xy); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Custom-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Custom-Depth-Node.html",
    "title": "Custom Depth Node (HDRP) | Inventory System",
    "summary": "Custom Depth Node (HDRP) The Custom Depth Node accesses the custom pass depth buffer allocated by HDRP. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Custom Depth Node No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates that this node samples. Output Output Vector 4 None The output value of this node. Depth Sampling modes Name Description Linear01 The linear depth value between 0 and 1. Raw The raw depth value. Eye The depth value converted to eye space units. Generated Code Example The following example code represents one possible outcome of this node. void Unity_CustomDepth_LinearEye_float(float4 UV, out float Out) { Out = LinearEyeDepth(SampleCustomDepth(UV.xy), _ZBufferParams); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Sample-Buffer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Sample-Buffer-Node.html",
    "title": "HD Sample Buffer Node | Inventory System",
    "summary": "HD Sample Buffer Node Description The HD Sample Buffer Node samples a buffer directly from the Camera. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Sample Buffer No Yes Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value. Sampler Input SamplerState None Determines the sampler that Unity uses to sample the buffer. Layer Mask Input Float None Set the number of the Layer to sample. This port appears when you select Thickness in the Source Buffer dropdown. Output Output Changes to one of the following depending on the Source Buffer you select: • Float • Vector 2 • Vector 3 • Vector 4 None Output value. Thickness Output Float None Sample the Worldspace value, in meters, between the near and the far plane of the camera.This port appears when you select Thickness in the Source Buffer dropdown. Overlap Count Output Float None Count the number of triangles for a given pixel. This is useful for vegetation or flat surfaces. This port appears when you select Thickness in the Source Buffer dropdown. Controls Name Type Options Description Source Buffer Dropdown • NormalWorldSpace • Smoothness • MotionVectors • IsSky • PostProcessInput • RenderingLayerMask • Thickness Determines which buffer to sample. Generated Code Example The following example code represents one possible outcome of this node: float4 Unity_HDRP_SampleBuffer_float(float2 uv, SamplerState samplerState) { return SAMPLE_TEXTURE2D_X_LOD(_CustomPostProcessInput, samplerState, uv * _RTHandlePostProcessScale.xy, 0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Scene-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Scene-Color-Node.html",
    "title": "HD Scene Color Node | Inventory System",
    "summary": "HD Scene Color Node The HD Scene Color Node does the same thing as the Scene Color Node, but allows you to access the mips of the color buffer. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Scene Color No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Lod Input float None Sets the mip level that the sampler uses to sample the color buffer. Output Output Vector 3 None Output value Notes Exposure You can use the Exposure property to specify if you want to output the Camera color with exposure applied or not. By default, this property is disabled to avoid double exposure. The sampler that this Node uses to sample the color buffer is in trilinear clamp mode. This allows the sampler to smoothly interpolate between the mip maps."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Scene-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/HD-Scene-Depth-Node.html",
    "title": "HD Scene Depth Node | Inventory System",
    "summary": "HD Scene Depth Node Description The HD Scene Depth node uses a UV input to access the current Camera's depth buffer. Unity expects normalized screen coordinates for this value. You can also use this node to access the mipmaps in the depth buffer. You can only use the HD Scene Depth node in the Fragment Shader Stage and with non-opaque materials. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Scene Color No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Lod Input float None Sets the mip level that the sampler uses to sample the depth buffer. Output Output Vector 3 None Output value. Depth Sampling modes Name Description Linear01 Linear depth value between 0 and 1 Raw Raw depth value Eye Depth converted to eye space units Notes To use the HD Scene Depth node in a Custom Render Pipeline, you need to explicitly define its behavior, otherwise it returns white."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hue-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hue-Node.html",
    "title": "Hue Node | Inventory System",
    "summary": "Hue Node Description Offsets the hue of input In by the amount of input Offset. The unit of the offset can be set with the parameter Range. Offset in Degrees is in the range -180 to 180. In Radians it is -Pi to Pi. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Offset Input Float None Amount to offset hue Out Output Vector 3 None Output value Controls Name Type Options Description Range Dropdown Degrees, Radians The unit used for the input Offset Generated Code Example The following example code represents one possible outcome of this node per Base mode. Degrees void Unity_Hue_Degrees_float(float3 In, float Offset, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; float3 hsv = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); float hue = hsv.x + Offset / 360; hsv.x = (hue < 0) ? hue + 1 : (hue > 1) ? hue - 1 : hue; float4 K2 = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P2 = abs(frac(hsv.xxx + K2.xyz) * 6.0 - K2.www); Out = hsv.z * lerp(K2.xxx, saturate(P2 - K2.xxx), hsv.y); } Radians void Unity_Hue_Radians_float(float3 In, float Offset, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; float3 hsv = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); float hue = hsv.x + Offset; hsv.x = (hue < 0) ? hue + 1 : (hue > 1) ? hue - 1 : hue; // HSV to RGB float4 K2 = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P2 = abs(frac(hsv.xxx + K2.xyz) * 6.0 - K2.www); Out = hsv.z * lerp(K2.xxx, saturate(P2 - K2.xxx), hsv.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Cosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Cosine-Node.html",
    "title": "Hyperbolic Cosine Node | Inventory System",
    "summary": "Hyperbolic Cosine Node Description Returns the hyperbolic cosine of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicCosine_float4(float4 In, out float4 Out) { Out = cosh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Sine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Sine-Node.html",
    "title": "Hyperbolic Sine Node | Inventory System",
    "summary": "Hyperbolic Sine Node Description Returns the hyperbolic sine of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicSine_float4(float4 In, out float4 Out) { Out = sinh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Tangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Hyperbolic-Tangent-Node.html",
    "title": "Hyperbolic Tangent Node | Inventory System",
    "summary": "Hyperbolic Tangent Node Description Returns the hyperbolic tangent of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicTangent_float4(float4 In, out float4 Out) { Out = tanh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Input-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Input-Nodes.html",
    "title": "Input Nodes | Inventory System",
    "summary": "Input Nodes Basic Boolean Color Defines a constant Boolean value in the shader. Defines a constant Vector 4 value in the shader using a Color field. Constant Integer Defines a Float of a mathematical constant value in the shader. Defines a constant Float value in the shader using an Integer field. Slider Time Defines a constant Float value in the shader using a Slider field. Provides access to various Time parameters in the shader. Float Vector 2 Defines a Float value in the shader. Defines a Vector 2 value in the shader. Vector 3 Vector 4 Defines a Vector 3 value in the shader. Defines a Vector 4 value in the shader. Geometry Bitangent Vector Normal Vector Provides access to the mesh vertex or fragment's Bitangent Vector. Provides access to the mesh vertex or fragment's Normal Vector. Position Screen Position Provides access to the mesh vertex or fragment's Position. Provides access to the mesh vertex or fragment's Screen Position. Tangent Vector UV Provides access to the mesh vertex or fragment's Tangent Vector. Provides access to the mesh vertex or fragment's UV coordinates. Vertex Color View Direction Provides access to the mesh vertex or fragment's Vertex Color value. Provides access to the mesh vertex or fragment's View Direction vector. Vertex ID Provides access to the mesh vertex or fragment's Vertex ID value. Gradient Blackbody Gradient Samples a radiation based gradient from temperature input (in Kelvin). Defines a constant Gradient in the shader. Sample Gradient Samples a Gradient given the input of Time. Matrix Matrix 2x2 Matrix 3x3 Defines a constant Matrix 2x2 value in the shader. Defines a constant Matrix 3x3 value in the shader. Matrix 4x4 Transformation Matrix Defines a constant Matrix 4x4 value in the shader. Defines a constant Matrix 4x4 value for a default Unity Transformation Matrix in the shader. Mesh Deformation Compute Deformation Node Linear Blend Skinning Node Passes compute deformed vertex data to a vertex shader. Only works with the Entities Graphics package. Applies Linear Blend Vertex Skinning. Only works with the Entities Graphics package. PBR Dielectric Specular Metal Reflectance Returns a Dielectric Specular F0 value for a physically based material. Returns a Metal Reflectance value for a physically based material. Scene Ambient Camera Provides access to the Scene's Ambient color values. Provides access to various parameters of the current Camera. Fog Baked GI Provides access to the Scene's Fog parameters. Provides access to the Baked GI values at the vertex or fragment's position. Object Reflection Probe Provides access to various parameters of the Object. Provides access to the nearest Reflection Probe to the object. Scene Color Scene Depth Provides access to the current Camera's color buffer. Provides access to the current Camera's depth buffer. Screen Eye Index Provides access to parameters of the screen. Provides access to the Eye Index when stereo rendering. Texture Cubemap Asset Sample Cubemap Defines a constant Cubemap Asset for use in the shader. Samples a Cubemap and returns a Vector 4 color value for use in the shader. Sample Reflected Cubemap Node Sample Texture 2D Samples a Cubemap with reflected vector and returns a Vector 4 color value for use in the shader. Samples a Texture 2D and returns a color value for use in the shader. Sample Texture 2D Array Sample Texture 2D LOD Samples a Texture 2D Array at an Index and returns a color value for use in the shader. Samples a Texture 2D at a specific LOD and returns a color value for use in the shader. Sample Texture 3D Sample Virtual Texture Samples a Texture 3D and returns a color value for use in the shader. Samples a Virtual Texture and returns color values for use in the shader. Sampler State Texture Size Defines a Sampler State for sampling textures. Returns the Width and Height of the texel size of Texture 2D input. Texture 2D Array Asset Texture 2D Asset Defines a constant Texture 2D Array Asset for use in the shader. Defines a constant Texture 2D Asset for use in the shader. Texture 3D Asset Defines a constant Texture 3D Asset for use in the shader."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Instance-ID-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Instance-ID-Node.html",
    "title": "Instance ID Node | Inventory System",
    "summary": "Instance ID Node Description When Unity renders with GPU instancing, it assigns an Instance ID to each geometry. Use this node to capture Instance ID values in Graphics.DrawMeshInstanced API calls. When Unity does not render with GPU instancing, this ID is 0. When Unity uses dynamic instancing, instance IDs might not be consistent across multiple frames. Ports Name Direction Type Binding Description Out Output Float None Instance ID for mesh of a given instanced draw call."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Integer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Integer-Node.html",
    "title": "Integer Node | Inventory System",
    "summary": "Integer Node Description Defines a constant Float value in the shader using an Integer field. Can be converted to a Float type Property with a Mode setting of Integer via the Node's context menu. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Integer Defines the output value. Generated Code Example The following example code represents one possible outcome of this node. float _Integer = 1;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Internal-Inspector.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Internal-Inspector.html",
    "title": "Graph Inspector | Inventory System",
    "summary": "Graph Inspector Description The Graph Inspector makes it possible for you to interact with any selectable graph elements and graph-wide settings for a Shader Graph Asset. You can use the Graph Inspector to edit attributes and default values. When you open a Shader Graph, the Graph Inspector displays the Graph Settings tab by default. Graph-wide settings for that specific Shader Graph appear in this tab. How to use Select a node in the graph to display settings available for that node in the Graph Inspector. Settings available for that node appear in the Node Settings tab of the Graph Inspector. For example, if you select a Property node either in the graph or the Blackboard, the Node Settings tab displays attributes of the Property that you can edit. Graph elements that currently work with the Graph Inspector: Properties Keywords Custom Function nodes Subgraph Output nodes Per-node precision Graph elements that currently do not work with the Graph Inspector: Edges Sticky Notes Groups Material Override Enabling the Allow Material Override option in the Graph Settings makes it possible for you to override certain graph properties via the Material Inspector."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Inverse-Lerp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Inverse-Lerp-Node.html",
    "title": "Inverse Lerp Node | Inventory System",
    "summary": "Inverse Lerp Node Description Returns the linear parameter that produces the interpolant specified by input T within the range of input A to input B. Inverse Lerp is the inverse operation of the Lerp Node. It can be used to determine what the input to a Lerp was based on its output. For example, the value of a Lerp between 0 and 2 with a T value of 0.5 is 1. Therefore the value of an Inverse Lerp between 0 and 2 with a T value of 1 is 0.5. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value T Input Dynamic Vector Time value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_InverseLerp_float4(float4 A, float4 B, float4 T, out float4 Out) { Out = (T - A)/(B - A); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Invert-Colors-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Invert-Colors-Node.html",
    "title": "Invert Colors Node | Inventory System",
    "summary": "Invert Colors Node Description Inverts the colors of input In on a per channel basis. This Node assumes all input values are in the range 0 - 1. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Red Toggle True, False If true red channel is inverted Green Toggle True, False If true green channel is inverted. Disabled if input vector dimension is less than 2 Blue Toggle True, False If true blue channel is inverted. Disabled if input vector dimension is less than 3 Alpha Toggle True, False If true alpha channel is inverted. Disabled if input vector dimension is less than 4 Generated Code Example The following example code represents one possible outcome of this node. float2 _InvertColors_InvertColors = float4(Red, Green, Blue, Alpha); void Unity_InvertColors_float4(float4 In, float4 InvertColors, out float4 Out) { Out = abs(InvertColors - In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Limbal-Ring-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Limbal-Ring-Node.html",
    "title": "Iris Limbal Ring Node | Inventory System",
    "summary": "Iris Limbal Ring Node Calculates the intensity of the Limbal ring, a darkening feature of eyes. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Limbal Ring Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates that can be used to sample either a texture or procedurally generate an Iris Texture. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. LimbalRingSize Input float Normalized [0, 1] value that defines the relative size of the limbal ring. LimbalRingFade Input float Normalized [0, 1] value that defines strength of the fade out of the limbal ring. LimbalRingIntensity Input float Positive value that defines how dark the limbal ring is. Iris Limbal Ring Color Output Color Intensity of the limbal ring."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Offset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Offset-Node.html",
    "title": "Iris Offset Node | Inventory System",
    "summary": "Iris Offset Node Applies an offset to the center of the Iris as real world eyes are never symmetrical and centered. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Offset Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture. IrisOffset Input Vector2 Normalized [0, 1]x[0,1] value that defines on each axis the intensity of the offset of the Center of the pupil. IrisUV Output Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Out-Of-Bound-Color-Clamp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-Out-Of-Bound-Color-Clamp-Node.html",
    "title": "Iris Out of Bound Color Clamp Node | Inventory System",
    "summary": "Iris Out of Bound Color Clamp Node Clamps the color of the Iris to a given color. This is useful in case the refraction ray reaches the inside of the cornea. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Out of Bound Color Clamp Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture. Iris Color Input Color Previously sampled or generated color of the Iris. Clamp Color Input Color The color to clamp the Iris to. Iris Color Output Color Result Iris color for the rest of the pipeline."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-UV-Location-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Iris-UV-Location-Node.html",
    "title": "Iris UV Location Node | Inventory System",
    "summary": "Iris UV Location Node This node converts the object position of the cornea/iris to a UV Sampling coordinate. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris UV Location Node No Yes Ports name Direction type description Position OS Input Vector3 Position on the iris Plane in object space. Iris Radius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. IrisUV Output Vector2 ormalized UV coordinates that can be used to sample either a texture or procedurally generate an Iris Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-Front-Face-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-Front-Face-Node.html",
    "title": "Is Front Face Node | Inventory System",
    "summary": "Is Front Face Node Description Returns true if currently rendering a front face and false if rendering a back face. This value is always true unless the Master Node's Two Sided value is set to true in the Material Options. This is useful for Branching. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description Out Output Boolean None Output value"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-Infinite-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-Infinite-Node.html",
    "title": "Is Infinite Node | Inventory System",
    "summary": "Is Infinite Node Description Returns true if the input In is an infinite value. This is useful for Branching. Ports Name Direction Type Binding Description In Input Float None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_IsInfinite_float(float In, out float Out) { Out = isinf(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-NaN-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Is-NaN-Node.html",
    "title": "Is NaN Node | Inventory System",
    "summary": "Is NaN Node Description Returns true if the input In is not a number (NaN). This is useful for Branching. Ports Name Direction Type Binding Description In Input Float None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_IsNan_float(float In, out float Out) { Out = (In < 0.0 || In > 0.0 || In == 0.0) ? 0 : 1; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keyboard-shortcuts.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keyboard-shortcuts.html",
    "title": "Shader Graph keyboard shortcuts reference | Inventory System",
    "summary": "Shader Graph keyboard shortcuts reference Shader Graph provides several keyboard shortcuts to help you work more efficiently. This page lists the keyboard shortcuts available in Shader Graph. You can use the keyboard shortcuts to perform many tasks, such as the following: Add nodes to the graph. Group and ungroup nodes. Open node documentation. Toggle some UI elements on and off. You can also use the Shortcuts Manager to customize the keyboard shortcuts to suit your preferences. For more information on how to customize, refer to Shortcuts Manager. Built-in keyboard shortcuts The following table lists the built-in keyboard shortcuts available in Shader Graph. You can't customize the built-in keyboard shortcuts. Command Windows macOS Description Frame All A A Display the entire graph in the Shader Graph window. Frame Selection F F Display the selected nodes of the graph in the Shader Graph window. Duplicate Ctrl + D Cmd + D Duplicate the selected nodes. Copy Ctrl + C Cmd + C Copy the selected nodes to the clipboard. Cut Ctrl + X Cmd + X Remove the selected nodes from the graph and place them in the clipboard. Paste Ctrl + V Cmd + V Paste the nodes from the clipboard. Undo Ctrl + Z Cmd + Z Undo the last action. Redo Ctrl + Y Cmd + Y Redo the last action. Open Create Node menu Space Space Open the (Create Node menu)[Create-Node-Menu.md] to add nodes to your graph. Customizable shortcuts The following table lists the keyboard shortcuts available in Shader Graph that you can customize with Shortcuts Manager. Command Windows macOS Description Close Tab Ctrl + F4 Cmd + F4 Close the selected tab. Cycle Color Mode Shift + 4 Shift + 4 Cycle through the different color modes. Group Selected Nodes Ctrl + G Cmd + G Group the selected nodes. Insert Redirect Node Ctrl + R Cmd + R Insert a redirect node in the selected connection. Open Documentation F1 F1 Open the documentation for the selected node. Save Ctrl + S Cmd + S Save your graph. Save As... Ctrl + Shift + S Cmd + Shift + S Save your graph with a new name. Toggle Blackboard Shift + 1 Shift + 1 Toggle the Blackboard on and off. Toggle Inspector Shift + 2 Shift + 2 Toggle the Graph Inspector on and off. Toggle Main Preview Shift + 3 Shift + 3 Toggle the Main Preview on and off. Toggle Node Collapsed Ctrl + P Cmd + P Toggle the selected node's collapsed state. Toggle Node Previews Ctrl + T Cmd + T Toggle the selected node's preview on and off. Ungroup Nodes Ctrl + U Cmd + U Ungroup the selected nodes. Node creation keyboard shortcuts The following table lists the keyboard shortcuts you can use to add nodes in Shader Graph. You can also customize these keyboard shortcuts with the Shortcuts Manager. Node Windows macOS Absolute Alt + \\ Option + \\ Add Alt + A Option + A Blend Alt + B Option + B Boolean Alt + 0 Option + 0 Branch Alt + Y Option + Y Ceiling Alt + ] Option + ] Clamp Alt + = Option + = Color Alt + C Option + C Combine Alt + K Option + K Cross Product Alt + H Option + H Custom Function Alt + ; Option + ; Divide Alt + D Option + D Dot Product Alt + . Option + . Float Alt + 1 Option + 1 Floor Alt + [ Option + [ Fraction Alt + / Option + / Fresnel Effect Alt + F Option + F Gradient Alt + G Option + G Lerp Alt + L Option + L Multiply Alt + M Option + M Negate Alt + - Option + - Normal Vector Alt + N Option + N Normalize Alt + Z Option + Z One Minus Alt + | Option + | Position Alt + V Option + V Power Alt + P Option + P Remap Alt + R Option + R Sample Texture 2D Alt + X Option + X Saturate Alt + Q Option + Q Smoothstep Alt + \" Option + \" Split Alt + E Option + E Step Alt + J Option + J Subtract Alt + S Option + S Swizzle Alt + W Option + W Tiling and Offset Alt + O Option + O Time Alt + T Option + T UV Alt + U Option + U Vector 2 Alt + 2 Option + 2 Vector 3 Alt + 3 Option + 3 Vector 4 Alt + 4 Option + 4 Additional resources Blackboard Create Node menu Graph Inspector Main Preview Shader Graph window Shortcuts Manager"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keyword-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keyword-Node.html",
    "title": "Keyword node | Inventory System",
    "summary": "Keyword node Description You can use a Keyword node to create a static branch in your Shader Graph that references a Keyword on the Blackboard. The appearance of a Keyword node, including its available ports, changes based on the Keyword it references. Creating new Keyword Nodes Because each Keyword node references a specific Keyword, you must first define at least one Keyword on the Blackboard. Drag a Keyword from the Blackboard to the workspace to make a Keyword node that corresponds to that Keyword. You can also right-click anywhere on the workspace, and use the Create Node menu to make a new Keyword node. Under Keywords, there is a list of Keywords that you defined on the Blackboard. Click on a Keyword in that list to create a corresponding Keyword node."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keywords.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Keywords.html",
    "title": "Keywords | Inventory System",
    "summary": "Keywords Description Use Keywords to create different variants for your Shader Graph. Keywords enable you to create shaders: With features that you can turn on or off for each Material instance. With features that behave differently on certain platforms. That scale in complexity based on conditions you set. There are three types of Keywords: Boolean, Enum, and Built-in. Unity defines a Keyword in the graph, shader, and optionally, the Material Inspector based on its type. See Boolean Keyword, Enum Keyword, and Built-in Keyword for more information about Keyword types. For more information about how these Keywords affect the final shader, see documentation on Making multiple shader program variants. In Shader Graph, you first define a Keyword on the Blackboard, then use a Keyword Node to create a branch in the graph. The Editor is able to compile variants on demand when it needs them to render content. If you declare many different variants, you can end up with millions or trillions of possibilities. However, the Player needs to determine at build time which variants are in use and include them when it pre-compiles your shaders. To manage memory effectively, the Player strips unused variants based on their keyword and Editor settings. See the next section, Common parameters, to learn more about how you can give the Player hints about what it needs to compile and what it can ignore. When the Player strips out a variant in the build process, it displays the pink error shader. Common parameters Although some fields are specific to certain types of Keywords, all Keywords have the following parameters. Name Type Description Display Name String The display name of the Keyword. Unity shows this name in the title bar of nodes that reference the corresponding Keyword, and also in the Material Inspector if you expose that Keyword. Exposed Boolean When you set this parameter to true, Unity displays this Keyword in the Material Inspector. If you set it to false, the Keyword does not appear in the Material Inspector. If you intend to access a GLOBAL shader variable, be sure to add it as you would normally add an input variable, but deselect Exposed. Reference Name String The internal name for the Keyword in the shader. If you overwrite the Reference Name parameter, take note of the following: Keyword Reference Names are always in full capitals, so Unity converts all lowercase letters to uppercase. If the Reference Name contains any characters that HLSL does not support, Unity replaces those characters with underscores. Right-click on a Reference Name, and select Reset Reference to revert to the default Reference Name. Definition Enum Sets how the Keyword is defined in the shader. Determines when to compile keyword variants. There are three available options: Shader Feature: Unity only compiles keyword variants when a Material selects the relevant option. For this option to be available in the Player, a Material selecting it must exist at build-time. Multi Compile: Pre-compiles all the variant possibilities. This is slower and uses more memory, but allows the option to be dynamically switched in the Player. Predefined: The render pipeline defines this keyword and controls the settings for it. Scope Enum Sets the scope at which to define the Keyword. The following options are available: Global Keywords: Defines Keyword for the entire project, and it counts towards the global keyword limit. Local Keywords: Defines Keyword for only one shader, which has its own local keyword limit. When you use Predefined Keywords, Unity disables this field. Stages Set the stage the keyword applies to. The following options are available: All - Applies this keyword to all shader stages. Vertex - Applies this keyword to the vertex stage. Fragment - Applies this keyword to the fragment stage. Boolean Keywords Boolean Keywords are either on or off. This results in two shader variants. Unity exposes Boolean Keywords in the Material Inspector if the Exposed parameter is set to is true. To enable the keyword from a script, use EnableKeyword on the keyword's Reference name. DisableKeyword disables the keyword. To learn more about Boolean Keywords, see Shader variants and keywords. Type-specific parameters Boolean Keywords have one Boolean-specific parameter in addition to the common parameters listed above. Name Type Description Default Boolean Enable this parameter to set the Keyword's default state to on, and disable it to set the Keyword's default state to off. This parameter determines the value to use for the Keyword when Shader Graph generates previews. It also defines the Keyword's default value when you use this shader to create a new Material. Enum Keywords Enum Keywords can have two or more states, which you define in the Entries list. If you expose an Enum Keyword, the Display Names in its Entries list appear in a dropdown menu in the Material Inspector. Special characters such as ( ) or ! @ are not valid in the Entry Name of an Enum Keyword. Shader Graph converts invalid characters to underscores ( _ ). When you define an Enum Keyword, Shader Graph displays labels for each state consisting of a sanitized version of the Enum's Entry Name appended to the main Reference name. When controlling a keyword via script with a, Material.EnableKeyword or Shader.EnableKeyword function, enter the state label in the format {REFERENCE}_{REFERENCESUFFIX}. For example, if your reference name is MYENUM and the desired entry is OPTION1, then you would call Material.EnableKeyword(\"MYENUM_OPTION1\"). When you select an option, this disables the other options. Type-specific parameters In addition to the common parameters listed above, Enum Keywords have the following additional parameters. Name Type Description Default Enum Select an entry from the drop-down menu to determine which value to use for the Keyword when Shader Graph generates previews. This also defines the Keyword's default value when you use this shader to create a new Material. When you edit the Entries list, Shader Graph automatically updates the options in this control. Entries Reorderable List This list defines all the states for the Keyword. Each state has a separate Display Name and Reference Suffix. • Display Name: Appears in drop-down menus for the Keyword on the Internal Inspector and the Material Inspector. Shader Graph also uses this name for port labels on nodes that reference the Keyword. • Reference Suffix: This is the final keyword, presented in the format Reference_ReferenceSuffix. Built-in Keywords Built-in Keywords are always of either the Boolean or Enum type, but they behave slightly differently from Boolean or Enum Keywords that you create. The Unity Editor or active Render Pipeline sets their values, and you cannot edit these. All Built-in Keyword fields in the Node Settings tab of the Graph Inspector are grayed out except for the Default field, which you can enable or disable to show the differences in Shader Graph previews. You also cannot expose Built-in Keywords in the Material Inspector. In an HDRP project, you can find the current quality level in the Material section of the HDRP Asset. For URP projects, the feature is not supported, but you can use the SetGloalShaderKeywords command to set the MaterialQuality Enum in the script. For example, the following line would set Material Quality to High: MaterialQualityUtilities.SetGlobalShaderKeywords( MaterialQuality.High );"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Length-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Length-Node.html",
    "title": "Length Node | Inventory System",
    "summary": "Length Node Description Returns the length of input In. This is also known as magnitude. A vector's length is calculated with Pythagorean Theorum. The length of a Vector 2 can be calculated as: Where x and y are the components of the input vector. Length can be calculated for other dimension vectors by adding or removing components. And so on. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Length_float4(float4 In, out float Out) { Out = length(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Lerp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Lerp-Node.html",
    "title": "Lerp Node | Inventory System",
    "summary": "Lerp Node Description Returns the result of linearly interpolating between input A and input B by input T. For example, when the value of input T is 0 the return value is equal to the value of input A, when it is 1 the return value is equal to the value of input B and when it is 0.5 the return value is the midpoint of the two inputs A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value T Input Dynamic Vector Time value. Typical range: 0 to 1. Though you can use values outside of this range they may cause unpredictable results. Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Lerp_float4(float4 A, float4 B, float4 T, out float4 Out) { Out = lerp(A, B, T); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Linear-Blend-Skinning-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Linear-Blend-Skinning-Node.html",
    "title": "Linear Blend Skinning Node | Inventory System",
    "summary": "Linear Blend Skinning Node Description This node lets you apply Linear Blend Vertex Skinning, and only works with the Entities Graphics package. You must provide skinned matrices in the _SkinMatrices buffer. The node uses the _SkinMatrixIndex property to calculate where the matrices associated with the current mesh are located in the _SkinMatrices buffer. Ports Name Direction Type Stage Description Position Input Vector3 Vertex Position of the vertex in object space. Normal Input Vector3 Vertex Normal of the vertex in object space. Tangent Input Vector3 Vertex Tangent of the vertex in object space. Position Output Vector3 Vertex Outputs the skinned vertex position. Normal Output Vector3 Vertex Outputs the skinned vertex normal. Tangent Output Vector3 Vertex Outputs the skinned vertex tangent."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Log-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Log-Node.html",
    "title": "Log Node | Inventory System",
    "summary": "Log Node Description Returns the logarithm of input In. Log is the inverse operation to the Exponential Node. For example, the result of a base-2 Exponential using an input value of 3 is 8. Therefore the result of a base-2 Log using an input value of 8 is 3. The logarithmic base can be switched between base-e, base-2 and base-10 from the Base dropdown on the node. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Base Dropdown BaseE, Base2, Base10 Selects the logarithmic base Generated Code Example The following example code represents one possible outcome of this node per Base mode. Base E void Unity_Log_float4(float4 In, out float4 Out) { Out = log(In); } Base 2 void Unity_Log2_float4(float4 In, out float4 Out) { Out = log2(In); } Base 10 void Unity_Log10_float4(float4 In, out float4 Out) { Out = log10(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Main-Light-Direction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Main-Light-Direction-Node.html",
    "title": "Get Main Light Direction Node | Inventory System",
    "summary": "Get Main Light Direction Node Description Provides access to the direction of the main directional light in the scene. The main directional light is the one casting shadows if there is any. Otherwise, it fallbacks to the first non shadow casting directional light. Ports Name Direction Type Description Direction Output Vector3 The normalized direction of the sun light in world space."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Main-Preview.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Main-Preview.html",
    "title": "Main Preview | Inventory System",
    "summary": "Main Preview Description The Main Preview displays a representation of the shader on the active Render Pipeline. It updates in real-time and automatically updates to display any changes you make in the Shader Graph. The title bar of the Main Preview displays the name of the current shader. The Main Preview can be moved to anywhere in the Shader Graph Window and will automatically move with the nearest corner of that window. Preview Mesh You can rotate the preview mesh by holding left mouse button and dragging on the Main Preview and you can scale it by using the scroll wheel. The preview mesh can be changed by right clicking on the Main Preview. Here you can select from any primitive mesh types or select a custom mesh."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Master-Stack.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Master-Stack.html",
    "title": "Master Stack | Inventory System",
    "summary": "Master Stack Description The Master Stack is the end point of a Shader Graph that defines the final surface appearance of a shader. Your Shader Graph should always contain only one Master Stack. The content of the Master Stack might change depending on the Graph Settings you select. The Master Stack is made up of Contexts, which contain Block nodes. Contexts The Master Stack contains two Contexts: Vertex and Fragment. These represent the two stages of a shader. Nodes that you connect to Blocks in the Vertex Context become part of the final shader's vertex function. Nodes that you connect to Blocks in the Fragment Context become part of the final shader's fragment (or pixel) function. If you connect any nodes to both Contexts, they are executed twice, once in the vertex function and then again in the fragment function. You can't cut, copy, or paste Contexts."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Math-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Math-Nodes.html",
    "title": "Math Nodes | Inventory System",
    "summary": "Math Nodes Advanced Absolute Exponential Returns the absolute value of input In. Returns the exponential value of input In. Length Log Returns the length of input In. Returns the logarithm of input In. Modulo Negate Returns the remainder of input A divided by input B. Returns the inverse value of input In. Normalize Posterize Returns the normalized vector of input In. Returns the input In converted into a number of values defined by input Steps. Reciprocal Reciprocal Square Root Returns the result of 1 divided by input In. Returns the result of 1 divided by the square root of input In. Basic Add Divide Returns the sum of the two input values. Returns the result of input A divided by input B. Multiply Power Returns the result of input A multiplied by input B. Returns the result of input A to the power of input B. Square Root Subtract Returns the square root of input In. Returns the result of input A minus input B. Derivative DDX DDXY Returns the partial derivative with respect to the screen-space x-coordinate. Returns the sum of both partial derivatives. DDY Returns the partial derivative with respect to the screen-space y-coordinate. Interpolation Inverse Lerp Lerp Returns the parameter that produces the interpolant specified by input T within the range of input A to input B. Returns the result of linearly interpolating between input A and input B by input T. Smoothstep Returns the result of a smooth Hermite interpolation between 0 and 1, if input In is between inputs Edge1 and Edge2. Matrix Matrix Construction Matrix Determinant Constructs square matrices from the four input vectors M0, M1, M2 and M3. Returns the determinant of the matrix defined by input In. Matrix Split Matrix Transpose Splits a square matrix defined by input In into vectors. Returns the transposed value of the matrix defined by input In. Range Clamp Fraction Returns the input In clamped between the minimum and maximum values defined by inputs Min and Max respectively. Returns the fractional (or decimal) part of input In; which is greater than or equal to 0 and less than 1. Maximum Minimum Returns the largest of the two inputs values A and B. Returns the smallest of the two inputs values A and B. One Minus Random Range Returns the result of input In subtracted from 1. Returns a pseudo-random number that is between the minimum and maximum values defined by inputs Min and Max. Remap Saturate Remaps the value of input In from between the values of input Out Min Max to between the values of input In Min Max. Returns the value of input In clamped between 0 and 1. Round Ceiling Floor Returns the smallest integer value, or whole number, that is greater than or equal to the value of input In. Returns the largest integer value, or whole number, that is less than or equal to the value of input In. Round Sign Returns the value of input In rounded to the nearest integer, or whole number. Returns -1 if the value of input In is less than zero, 0 if equal to zero and 1 if greater than zero. Step Truncate Returns 1 if the value of input In is greater than or equal to the value of input Edge, otherwise returns 0. Returns the integer, or whole number, component of the value of input In. Trigonometry Arccosine Arcsine Returns the arccosine of each component the input In as a vector of equal length. Returns the arcsine of each component the input In as a vector of equal length. Arctangent Arctangent2 Returns the arctangent of the value of input In. Each component should be within the range of -Pi/2 to Pi/2. Returns the arctangent of the values of both input A and input B. Cosine Degrees to Radians Returns the cosine of the value of input In. Returns the value of input In converted from degrees to radians. Hyperbolic Cosine Hyperbolic Sine Returns the hyperbolic cosine of input In. Returns the hyperbolic sine of input In. Hyperbolic Tangent Radians to Degrees Returns the hyperbolic tangent of input In. Returns the value of input In converted from radians to degrees. Sine Tangent Returns the sine of the value of input In. Returns the tangent of the value of input In. Vector Cross Product Distance Returns the cross product of the values of the inputs A and B. Returns the Euclidean distance between the values of the inputs A and B. Dot Product Fresnel Effect Returns the dot product, or scalar product, of the values of the inputs A and B. Fresnel Effect is the effect of differing reflectance on a surface depending on viewing angle, where as you approach the grazing angle more light is reflected. Projection Reflection Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Returns a reflection vector using input In and a surface normal Normal. Rejection Rotate About Axis Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. Rotates the input vector In around the axis Axis by the value of Rotation. Projection Rejection Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. Sphere Mask Transform Creates a sphere mask originating from input Center. Returns the result of transforming the value of input In from one coordinate space to another. Wave Noise Sine Wave Sawtooth Wave Returns the sine of the value of input In. For variance, random noise is added to the amplitude of the sine wave. Returns a sawtooth wave from the value of input In. Matrix Split Matrix Transpose Splits a square matrix defined by input In into vectors. Returns the transposed value of the matrix defined by input In. Noise Sine Wave Sawtooth Wave Square Wavve Triangle Wave"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-2x2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-2x2-Node.html",
    "title": "Matrix 2x2 Node | Inventory System",
    "summary": "Matrix 2x2 Node Description Defines a constant Matrix 2x2 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 2 None Output value Controls Name Type Options Description Matrix 2x2 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float2x2 _Matrix2x2 = float2x2(1, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-3x3-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-3x3-Node.html",
    "title": "Matrix 3x3 Node | Inventory System",
    "summary": "Matrix 3x3 Node Description Defines a constant Matrix 3x3 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 3 None Output value Controls Name Type Options Description Matrix 3x3 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float3x3 _Matrix3x3 = float3x3(1, 0, 0, 0, 1, 0, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-4x4-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-4x4-Node.html",
    "title": "Matrix 4x4 Node | Inventory System",
    "summary": "Matrix 4x4 Node Description Defines a constant Matrix 4x4 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 4 None Output value Controls Name Type Options Description Matrix 4x4 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float4x4 _Matrix4x4 = float4x4(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Construction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Construction-Node.html",
    "title": "Matrix Construction Node | Inventory System",
    "summary": "Matrix Construction Node Description Constructs square matrices from the four input vectors M0, M1, M2 and M3. This node can be used to generate matrices of types Matrix 2x2, Matrix 3x3 and Matrix 4x4. The dropdown on the node can be used to select whether the inputs values specify the matrix rows or columns. Row : Input vectors specify matrix rows from top to bottom. Column : Input vectors specify matrix columns from left to right. Matrix outputs are taken from the top left corner of the construction of the inputs. This can be used to generate different dimension square matrices from different dimension vectors. For example, connecting Vector 2 type values to inputs M0 and M1 will generate the desired matrix from the output 2x2. Ports Name Direction Type Description M0 Input Vector 4 First row or column M1 Input Vector 4 Second row or column M2 Input Vector 4 Third row or column M3 Input Vector 4 Fourth row or column 4x4 Output Matrix 4x4 Output as Matrix 4x4 3x3 Output Matrix 3x3 Output as Matrix 3x3 2x2 Output Matrix 2x2 Output as Matrix 2x2 Controls Name Type Options Description Dropdown Row, Column Selects how the output matrix should be filled Generated Code Example The following example code represents one possible outcome of this node per mode. Row void Unity_MatrixConstruction_Row_float(float4 M0, float4 M1, float4 M2, float3 M3, out float4x4 Out4x4, out float3x3 Out3x3, out float2x2 Out2x2) { Out4x4 = float4x4(M0.x, M0.y, M0.z, M0.w, M1.x, M1.y, M1.z, M1.w, M2.x, M2.y, M2.z, M2.w, M3.x, M3.y, M3.z, M3.w); Out3x3 = float3x3(M0.x, M0.y, M0.z, M1.x, M1.y, M1.z, M2.x, M2.y, M2.z); Out2x2 = float2x2(M0.x, M0.y, M1.x, M1.y); } Column void Unity_MatrixConstruction_Column_float(float4 M0, float4 M1, float4 M2, float3 M3, out float4x4 Out4x4, out float3x3 Out3x3, out float2x2 Out2x2) { Out4x4 = float4x4(M0.x, M1.x, M2.x, M3.x, M0.y, M1.y, M2.y, M3.y, M0.z, M1.z, M2.z, M3.z, M0.w, M1.w, M2.w, M3.w); Out3x3 = float3x3(M0.x, M1.x, M2.x, M0.y, M1.y, M2.y, M0.z, M1.z, M2.z); Out2x2 = float2x2(M0.x, M1.x, M0.y, M1.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Determinant-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Determinant-Node.html",
    "title": "Matrix Determinant | Inventory System",
    "summary": "Matrix Determinant Description Returns the determinant of the matrix defined by input In. It can be viewed as the scaling factor of the transformation described by the matrix. Ports Name Direction Type Description In Input Dynamic Matrix Input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_MatrixDeterminant_float4x4(float4x4 In, out float Out) { Out = determinant(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Split-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Split-Node.html",
    "title": "Matrix Split Node | Inventory System",
    "summary": "Matrix Split Node Description Splits a square matrix defined by input In into vectors. Output vector dimension is defined by the dimension of the input matrix. The dropdown on the node can be used to select whether the output values are taken from the rows or columns of the input matrix. Row : Output vectors are composed of matrix rows from top to bottom. Column : Output vectors are composed of matrix columns from left to right. An input matrix of type Matrix 2x2 or Matrix 3x3 will return 0 values in the rows (or columns, depending on dropdown selection) that are beyond their dimension. For example, connecting Matrix 2x2 type to input In will return the correct Vector 2 type outputs to output slots M0 and M1, leaving outputs M2 and M3 to return 0 values. Ports Name Direction Type Description In Input Dynamic Matrix Input value M0 Output Dynamic Vector First row or column M1 Output Dynamic Vector Second row or column M2 Output Dynamic Vector Third row or column M3 Output Dynamic Vector Fourth row or column Controls Name Type Options Description Dropdown Row, Column Selects how the output vectors should be filled Generated Code Example The following example code represents one possible outcome of this node. float2 _MatrixSplit_M0 = float2(In[0].r, In[0].g); float2 _MatrixSplit_M1 = float2(In[1].r, In[1].g); float2 _MatrixSplit_M2 = float2(0, 0); float2 _MatrixSplit_M3 = float2(0, 0);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Transpose-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Matrix-Transpose-Node.html",
    "title": "Matrix Transpose | Inventory System",
    "summary": "Matrix Transpose Description Returns the transposed value of the matrix defined by input In. This can be seen as the operation of flipping the matrix over its diagonal. The result is that it switches the row and column indices of the matrix. Ports Name Direction Type Description In Input Dynamic Matrix Input value Out Output Dynamic Matrix Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_MatrixTranspose_float4x4(float4x4 In, out float4x4 Out) { Out = transpose(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Maximum-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Maximum-Node.html",
    "title": "Maximum Node | Inventory System",
    "summary": "Maximum Node Description Returns the largest of the two inputs values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Maximum_float4(float4 A, float4 B, out float4 Out) { Out = max(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Metal-Reflectance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Metal-Reflectance-Node.html",
    "title": "Metal Reflectance Node | Inventory System",
    "summary": "Metal Reflectance Node Description Returns a Metal Reflectance value for a physically based material. The material to use can be selected with the Material dropdown parameter on the Node. When using Specular Workflow on a PBR Master Node this value should be supplied to the Specular Port. When using Metallic Workflow this value should be supplied to the Albedo Port. Ports Name Direction Type Binding Description Out Output Vector 3 None Output value Controls Name Type Options Description Material Dropdown Iron, Silver, Aluminium, Gold, Copper, Chromium, Nickel, Titanium, Cobalt, Platform Selects the material value to output. Generated Code Example The following example code represents one possible outcome of this node. Iron float3 _MetalReflectance_Out = float3(0.560, 0.570, 0.580); Silver float3 _MetalReflectance_Out = float3(0.972, 0.960, 0.915); Aluminium float3 _MetalReflectance_Out = float3(0.913, 0.921, 0.925); Gold float3 _MetalReflectance_Out = float3(1.000, 0.766, 0.336); Copper float3 _MetalReflectance_Out = float3(0.955, 0.637, 0.538); Chromium float3 _MetalReflectance_Out = float3(0.550, 0.556, 0.554); Nickel float3 _MetalReflectance_Out = float3(0.660, 0.609, 0.526); Titanium float3 _MetalReflectance_Out = float3(0.542, 0.497, 0.449); Cobalt float3 _MetalReflectance_Out = float3(0.662, 0.655, 0.634); Platinum float3 _MetalReflectance_Out = float3(0.672, 0.637, 0.585);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Minimum-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Minimum-Node.html",
    "title": "Minimum Node | Inventory System",
    "summary": "Minimum Node Description Returns the smallest of the two inputs values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Minimum_float4(float4 A, float4 B, out float4 Out) { Out = min(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Modulo-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Modulo-Node.html",
    "title": "Modulo Node | Inventory System",
    "summary": "Modulo Node Description Returns the remainder of dividing input A by input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Modulo_float4(float4 A, float4 B, out float4 Out) { Out = fmod(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Multiply-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Multiply-Node.html",
    "title": "Multiply Node | Inventory System",
    "summary": "Multiply Node Description Returns the result of input A multiplied by input B. If both inputs are a vector type, the output type will be a vector type with the same dimension as the evaluated type of those inputs. If both inputs are a matrix type, the output type will be a matrix type with the same dimension as the evaluated type of those inputs. If one input is a vector type and the other is a matrix type, then output type will be a vector with the same dimension as the vector type input. Ports Name Direction Type Description A Input Dynamic First input value B Input Dynamic Second input value Out Output Dynamic Output value Generated Code Example The following example code represents different possible outcomes of this node. Vector * Vector void Unity_Multiply_float4_float4(float4 A, float4 B, out float4 Out) { Out = A * B; } Vector * Matrix void Unity_Multiply_float4_float4x4(float4 A, float4x4 B, out float4 Out) { Out = mul(A, B); } Matrix * Matrix void Unity_Multiply_float4x4_float4x4(float4x4 A, float4x4 B, out float4x4 Out) { Out = mul(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Nand-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Nand-Node.html",
    "title": "Nand Node | Inventory System",
    "summary": "Nand Node Description Returns true if both the inputs A and B are false. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Nand_float(float A, float B, out float Out) { Out = !A && !B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Negate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Negate-Node.html",
    "title": "Negate Node | Inventory System",
    "summary": "Negate Node Description Returns the flipped sign value of input In. Positive values become negative and negative values become positive. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Negate_float4(float4 In, out float4 Out) { Out = -1 * In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Node-Library.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Node-Library.html",
    "title": "Node Library | Inventory System",
    "summary": "Node Library Description The Node Library contains documentation for all the individual Nodes in Shader Graph; including descriptions, ports, parameters, shader code and example images. The Nodes are organised in the same categories as found in the Create Node Menu for convenience. Graph Nodes Artistic Channel Input Math Procedural Utility UV Block Nodes Built In Universal High Definition"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Node.html",
    "title": "Node | Inventory System",
    "summary": "Node Description A Node defines an input, output or operation on the Shader Graph, depending on its available Ports. A Node may have any number of input and/or output ports. You create a Shader Graph by connecting these ports with Edges. A Node might also have any number of Controls, these are controls on the Node that do not have ports. You can collapse a Node by clicking the Collapse button in the top-right corner of the Node. This will hide all unconnected ports. For components of a Node see: Port Edge There are many available Nodes in Shader Graph. For a full list of all available Nodes see the Node Library. Preview Many nodes include a preview. This preview displays the main output value at that stage in the graph. Hide this preview with the Collapse control that displays when you hover over the node. You can also collapse and expand node previews via the Context Menu in the Shader Graph Window. To configure the appearance of node previews, see Preview Mode Control. Context Menu Right clicking on a Node will open a context menu. This menu contains many operations that can be performed on the Node. Note that when multiple nodes are selected, these operations will be applied to the entire selection. Item Description Copy Shader Copies the generated HLSL code at this stage in the graph to the clipboard Disconnect All Removes all edges from all ports on the Node(s) Cut Cuts selected Node(s) to the clipboard Copy Copies selected Nodes(s) to the clipboard Paste Pastes Node(s) in the clipboard Delete Deletes selected Node(s) Duplicate Duplicates selected Node(s) Convert To Sub-graph Creates a new Sub-graph Asset with the selected Node(s) included Convert To Inline Node Converts a Property Node into a regular node of the appropriate Data Type Convert To Property Converts a Node into a new Property on the Blackboard of the appropriate Property Type Open Documentation Opens a new web browser to the selected Nodes documentation page in the Node Library Color Mode Nodes interact with the Shader Graph Window's Color Modes. Colors are displayed on nodes underneath the text on the node title bar. See Color Modes for more information on available colors for nodes."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Noise-Sine-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Noise-Sine-Wave-Node.html",
    "title": "Noise Sine Wave Node | Inventory System",
    "summary": "Noise Sine Wave Node Description Returns the sine of the value of input In. For variance, psuedo-random noise is added to the amplitude of the sine wave, within a range determined by input Min Max. Ports Name Direction Type Description In Input Dynamic Vector Input value Min Max Input Vector 2 Minimum and Maximum values for noise intensity Out Output Dynamic Vector Output value Generated Code Example void Unity_NoiseSineWave_float4(float4 In, float2 MinMax, out float4 Out) { float sinIn = sin(In); float sinInOffset = sin(In + 1.0); float randomno = frac(sin((sinIn - sinInOffset) * (12.9898 + 78.233))*43758.5453); float noise = lerp(MinMax.x, MinMax.y, randomno); Out = sinIn + noise; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Blend-Node.html",
    "title": "Normal Blend Node | Inventory System",
    "summary": "Normal Blend Node Description Blends two normal maps defined by inputs A and B together, normalizing the result to create a valid normal map. Ports Name Direction Type Binding Description A Input Vector 3 None First input value B Input Vector 3 None Second input value Out Output Vector 3 None Output value Controls Name Type Options Description Mode Dropdown Default, Reoriented Selects the the method used for blending. Generated Code Example The following example code represents one possible outcome of this node per Mode. Default void Unity_NormalBlend_float(float3 A, float3 B, out float3 Out) { Out = normalize(float3(A.rg + B.rg, A.b * B.b)); } Reoriented void Unity_NormalBlend_Reoriented_float(float3 A, float3 B, out float3 Out) { float3 t = A.xyz + float3(0.0, 0.0, 1.0); float3 u = B.xyz * float3(-1.0, -1.0, 1.0); Out = (t / t.z) * dot(t, u) - u; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-From-Height-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-From-Height-Node.html",
    "title": "Normal From Height Node | Inventory System",
    "summary": "Normal From Height Node Description Creates a normal map from a height value defined by input Input with a strength defined by input Strength. Ports Name Direction Type Description In Input Float Input height value Strength Input Float The strength of the output normal. Considered in real-world units, recommended range is 0 - 0.1 . Out Output Vector 3 Output value Controls Name Type Options Description Output Space Dropdown Tangent, World Sets the coordinate space of the output normal. Generated Code Example The following example code represents one possible outcome of this node per Output Space mode. Tangent void Unity_NormalFromHeight_Tangent_float(float In, float Strength, float3 Position, float3x3 TangentMatrix, out float3 Out) { float3 worldDerivativeX = ddx(Position); float3 worldDerivativeY = ddy(Position); float3 crossX = cross(TangentMatrix[2].xyz, worldDerivativeX); float3 crossY = cross(worldDerivativeY, TangentMatrix[2].xyz); float d = dot(worldDerivativeX, crossY); float sgn = d < 0.0 ? (-1.0f) : 1.0f; float surface = sgn / max(0.000000000000001192093f, abs(d)); float dHdx = ddx(In); float dHdy = ddy(In); float3 surfGrad = surface * (dHdx*crossY + dHdy*crossX); Out = normalize(TangentMatrix[2].xyz - (Strength * surfGrad)); Out = TransformWorldToTangent(Out, TangentMatrix); } World void Unity_NormalFromHeight_World_float(float In, float Strength, float3 Position, float3x3 TangentMatrix, out float3 Out) { float3 worldDerivativeX = ddx(Position); float3 worldDerivativeY = ddy(Position); float3 crossX = cross(TangentMatrix[2].xyz, worldDerivativeX); float3 crossY = cross(worldDerivativeY, TangentMatrix[2].xyz); float d = dot(worldDerivativeX, crossY); float sgn = d < 0.0 ? (-1.0f) : 1.0f; float surface = sgn / max(0.000000000000001192093f, abs(d)); float dHdx = ddx(In); float dHdy = ddy(In); float3 surfGrad = surface * (dHdx*crossY + dHdy*crossX); Out = normalize(TangentMatrix[2].xyz - (Strength * surfGrad)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-From-Texture-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-From-Texture-Node.html",
    "title": "Normal From Texture Node | Inventory System",
    "summary": "Normal From Texture Node Description Converts a height map defined by input Texture into a normal map. UV values and sampler state can be defined by inputs UV and Sampler respectively. If nothing is connected to these ports they will use default values from the inputs. See Port Bindings for more information. The strength of the created normal map can be defined by inputs Offset and Strength, where Offset defines the maximum distance of a normal detail and Strength acts as a multiplier to the result. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Texture Input Texture None Height map UV Input Vector 2 UV Texture coordinates Sampler Input Sampler State None Sampler for Texture Offset Input Float None Amount to offset samples Strength Input Float None Strength multiplier Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalFromTexture_float(Texture texture, SamplerState Sampler, float2 UV, float Offset, float Strength, out float3 Out) { Offset = pow(Offset, 3) * 0.1; float2 offsetU = float2(UV.x + Offset, UV.y); float2 offsetV = float2(UV.x, UV.y + Offset); float normalSample = Texture.Sample(Sampler, UV); float uSample = Texture.Sample(Sampler, offsetU); float vSample = Texture.Sample(Sampler, offsetV); float3 va = float3(1, 0, (uSample - normalSample) * Strength); float3 vb = float3(0, 1, (vSample - normalSample) * Strength); Out = normalize(cross(va, vb)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Reconstruct-Z-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Reconstruct-Z-Node.html",
    "title": "Normal Reconstruct Z Node | Inventory System",
    "summary": "Normal Reconstruct Z Node Description Derives the correct Z value for generated normal maps using a given X and Y value from input In. Ports Name Direction Type Description In Input Vector 2 Normal X and Y value Out Output Vector 3 Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalReconstructZ_float(float2 In, out float3 Out) { float reconstructZ = sqrt(1.0 - saturate(dot(In.xy, In.xy))); float3 normalVector = float3(In.x, In.y, reconstructZ); Out = normalize(normalVector); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Strength-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Strength-Node.html",
    "title": "Normal Strength Node | Inventory System",
    "summary": "Normal Strength Node Description Adjusts the strength of the normal map defined by input In by the amount of input Strength. A Strength value of 1 will return the input unaltered. A Strength value of 0 will return a blank normal map. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Strength Input Float None Strength value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalStrength_float(float3 In, float Strength, out float3 Out) { Out = {precision}3(In.rg * Strength, lerp(1, In.b, saturate(Strength))); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Unpack-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Unpack-Node.html",
    "title": "Normal Unpack Node | Inventory System",
    "summary": "Normal Unpack Node Description Unpacks a normal map defined by input In. This node is used to unpack a texture that is defined as a Normal Map in its Texture Import Settings when it is sampled as if it were a default texture. Note that in most cases this node is unnecessary as the normal map should be sampled as such by setting its Type parameter to Normal when it is sampled using a Sample Texture 2D or Triplanar node. Ports Name Direction Type Binding Description In Input Vector 4 None Input value Out Output Vector 3 None Output value Controls Name Type Options Description Space Dropdown Tangent, Object Sets the coordinate space of the input normal. Generated Code Example The following example code represents one possible outcome of this node per Space mode. Tangent void Unity_NormalUnpack_float(float4 In, out float3 Out) { Out = UnpackNormalMapRGorAG(In); } Object void Unity_NormalUnpackRGB_float(float4 In, out float3 Out) { Out = UnpackNormalmapRGB(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normal-Vector-Node.html",
    "title": "| Inventory System",
    "summary": "Description Provides access to the mesh vertex or fragment's Normal Vector. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Mesh's Normal Vector. Parameters Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Normal Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normalize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Normalize-Node.html",
    "title": "Normalize Node | Inventory System",
    "summary": "Normalize Node Description Returns the normalized value of input In. The output vector will have the same direction as input In but a length of 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Normalize_float4(float4 In, out float4 Out) { Out = normalize(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Not-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Not-Node.html",
    "title": "Not Node | Inventory System",
    "summary": "Not Node Description Returns the opposite of input In. If In is true the output will be false, otherwise it will be true. This is useful for Branching. Ports Name Direction Type Binding Description In Input Boolean None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalUnpack_float(float In, out float Out) { Out = !In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Object-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Object-Node.html",
    "title": "Object Node | Inventory System",
    "summary": "Object Node Description Provides access to various parameters of the currently rendering Object. Note: The behaviour of the Position Port can be defined per Render Pipeline. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. Unity Render Pipelines Support Universal Render Pipeline High Definition Render Pipeline Ports Name Direction Type Binding Description Position Output Vector 3 None Object position in world space Scale Output Vector 3 None Object scale in world space World Bounds Min Output Vector 3 None Minimum value of the renderer bounds in world space World Bounds Max Output Vector 3 None Maximum value of the renderer bounds in world space Bounds Size Output Vector 3 None Size of the renderer bounds Note: the bounds values are the equivalent of the bounds in the renderer component. This means that vertex deformation done in ShaderGraph doesn't affect these values. Generated Code Example The following example code represents one possible outcome of this node. float3 _Object_Position = SHADERGRAPH_OBJECT_POSITION; float3 _Object_Scale = float3(length(float3(UNITY_MATRIX_M[0].x, UNITY_MATRIX_M[1].x, UNITY_MATRIX_M[2].x)), length(float3(UNITY_MATRIX_M[0].y, UNITY_MATRIX_M[1].y, UNITY_MATRIX_M[2].y)), length(float3(UNITY_MATRIX_M[0].z, UNITY_MATRIX_M[1].z, UNITY_MATRIX_M[2].z))); float3 _Object_WorldBoundsMin = SHADERGRAPH_RENDERER_BOUNDS_MIN; float3 _Object_WorldBoundsMax = SHADERGRAPH_RENDERER_BOUNDS_MAX; float3 _Object_BoundsSize = (SHADERGRAPH_RENDERER_BOUNDS_MAX - SHADERGRAPH_RENDERER_BOUNDS_MIN);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/One-Minus-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/One-Minus-Node.html",
    "title": "One Minus Node | Inventory System",
    "summary": "One Minus Node Description Returns the result of input In subtracted from 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_OneMinus_float4(float4 In, out float4 Out) { Out = 1 - In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Or-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Or-Node.html",
    "title": "Or Node | Inventory System",
    "summary": "Or Node Description Returns true if either of the inputs A and B are true. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Or_float(float In, out float Out) { Out = A || B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Parallax-Mapping-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Parallax-Mapping-Node.html",
    "title": "Parallax Mapping Node | Inventory System",
    "summary": "Parallax Mapping Node Description The Parallax Mapping node lets you create a parallax effect that displaces a Material's UVs to create the illusion of depth inside a Material. This implementation uses the single step process that does not account for occlusion. For information on how the effect looks, see the Height Map page. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Description Heightmap Input Texture2D The Texture that specifies the depth of the displacement. Heightmap Sampler Input Sampler State The Sampler to sample Heightmap with. Amplitude Input Float A multiplier to apply to the height of the Heightmap (in centimeters). UVs Input Vector2 The UVs that the sampler uses to sample the Texture. Parallax UVs Output Vector2 The UVs after adding the parallax offset. Generated Code Example The following example code represents one possible outcome of this node. float2 _ParallaxMapping_ParallaxUVs = UVs.xy + ParallaxMapping(Heightmap, Heightmap_Sampler, IN.TangentSpaceViewDirection, Amplitude * 0.01, UVs.xy);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Parallax-Occlusion-Mapping-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Parallax-Occlusion-Mapping-Node.html",
    "title": "Parallax Occlusion Mapping Node | Inventory System",
    "summary": "Parallax Occlusion Mapping Node Description You can use the Parallax Occlusion Mapping (POM) node to create a parallax effect that displaces a material's UVs and depth to create the illusion of depth inside that material. If you receive a texture sampling error while using this node in a graph that includes Custom Function nodes or Subgraphs, try upgrading to Shader Graph version 10.3 or later. This may resolve the errors. When you assign the same Texture2D to a POM node and a Sample Texture 2D node, you need to avoid transforming the UV coordinates twice. To prevent this, connect the Split Texture Transform node’s Texture Only port to the Sample Texture 2D Node’s UV port. Ports Name Direction Type Description Heightmap Input Texture2D The Texture that specifies the depth of the displacement. Heightmap Sampler Input Sampler State The Sampler to sample Heightmap with. Amplitude Input Float A multiplier to apply to the height of the Heightmap (in centimeters). Steps Input Float The number of steps that the linear search of the algorithm performs. UVs Input Vector2 The UVs that the sampler uses to sample the Texture. Tiling Input Vector2 The tiling to apply to the input UVs. Offset Input Vector2 The offset to apply to the input UVs. Primitive Size Input Vector2 Size of the UV space in object space. For example, a Unity built-in Plane mesh has a primitive size of (10,10). LOD Input Float The level of detail to use to sample the Heightmap. This value should always be positive. LOD Threshold Input Float The Heightmap mip level where the Parallax Occlusion Mapping effect begins to fade out. This is equivalent to the Fading Mip Level Start property in the High Definition Render Pipeline's (HDRP) Lit Material. Pixel Depth Offset Output Float The offset to apply to the depth buffer to produce the illusion of depth. Connect this output to the Depth Offset on the Master Node to enable effects that rely on the depth buffer, such as shadows and screen space ambient occlusion. Parallax UVs Output Vector2 UVs that you have added the parallax offset to. Generated Code Example The following example code represents one possible outcome of this node. float3 ParallaxOcclusionMapping_ViewDir = IN.TangentSpaceViewDirection * GetDisplacementObjectScale().xzy; float ParallaxOcclusionMapping_NdotV = ParallaxOcclusionMapping_ViewDir.z; float ParallaxOcclusionMapping_MaxHeight = Amplitude * 0.01; ParallaxOcclusionMapping_MaxHeight *= 2.0 / ( abs(Tiling.x) + abs(Tiling.y) ); float2 ParallaxOcclusionMapping_UVSpaceScale = ParallaxOcclusionMapping_MaxHeight * Tiling / PrimitiveSize; // Transform the view vector into the UV space. float3 ParallaxOcclusionMapping_ViewDirUV = normalize(float3(ParallaxOcclusionMapping_ViewDir.xy * ParallaxOcclusionMapping_UVSpaceScale, ParallaxOcclusionMapping_ViewDir.z)); // TODO: skip normalize PerPixelHeightDisplacementParam ParallaxOcclusionMapping_POM; ParallaxOcclusionMapping_POM.uv = UVs.xy; float ParallaxOcclusionMapping_OutHeight; float2 _ParallaxOcclusionMapping_ParallaxUVs = UVs.xy + ParallaxOcclusionMapping(Lod, Lod_Threshold, Steps, ParallaxOcclusionMapping_ViewDirUV, ParallaxOcclusionMapping_POM, ParallaxOcclusionMapping_OutHeight); float _ParallaxOcclusionMapping_PixelDepthOffset = (ParallaxOcclusionMapping_MaxHeight - ParallaxOcclusionMapping_OutHeight * ParallaxOcclusionMapping_MaxHeight) / max(ParallaxOcclusionMapping_NdotV, 0.0001);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Polar-Coordinates-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Polar-Coordinates-Node.html",
    "title": "Polar Coordinates Node | Inventory System",
    "summary": "Polar Coordinates Node Description Converts the value of input UV to polar coordinates. In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The resulting effect is that the x channel of the input to UV is converted to a distance value from the point specified by the value of input Center and the y channel of same input is converted to the value of an angle of rotation around that point. These values can be scaled by the values of inputs Radial Scale and Length Scale respectively. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Radial Scale Input Float None Scale of distance value Length Scale Input Float None Scale of angle value Out Output Vector 2 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_PolarCoordinates_float(float2 UV, float2 Center, float RadialScale, float LengthScale, out float2 Out) { float2 delta = UV - Center; float radius = length(delta) * 2 * RadialScale; float angle = atan2(delta.x, delta.y) * 1.0/6.28 * LengthScale; Out = float2(radius, angle); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Polygon-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Polygon-Node.html",
    "title": "Polygon Node | Inventory System",
    "summary": "Polygon Node Description Generates a regular polygon shape based on input UV at the size specified by inputs Width and Height. The polygon's amount of sides is determined by input Sides. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating polygon effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment shader stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Sides Input Float None Amount of sides Width Input Float None Polygon width Height Input Float None Polygon height Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Polygon_float(float2 UV, float Sides, float Width, float Height, out float Out) { float pi = 3.14159265359; float aWidth = Width * cos(pi / Sides); float aHeight = Height * cos(pi / Sides); float2 uv = (UV * 2 - 1) / float2(aWidth, aHeight); uv.y *= -1; float pCoord = atan2(uv.x, uv.y); float r = 2 * pi / Sides; float distance = cos(floor(0.5 + pCoord / r) * r - pCoord) * length(uv); Out = saturate((1 - distance) / fwidth(distance)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Port-Bindings.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Port-Bindings.html",
    "title": "Port Bindings | Inventory System",
    "summary": "Port Bindings Description Some input Ports might have Port Bindings. This means there is an expectation of the data that should be supplied to the Port, such as a Normal Vector or UV. However, a Port Binding only affects a Port that does not have a connected Edge. These Ports still have a regular Data Type that define what Edges can be connected to them. In practice this means that if no Edge is connected to the Port the default data used in that port will be taken from its Port Binding. A full list of Port Bindings and their associated default options is found below. Port Bindings List Name Data Type Options Description Bitangent Vector 3 Vertex or fragment bitangent, label describes expected transform space Color Vector 4 RGBA Color picker ColorRGB Vector 3 RGB Color picker Normal Vector 3 Vertex or fragment normal vector, label describes expected transform space Position Vector 3 Vertex or fragment position, label describes expected transform space Screen Position Vector 4 Default, Raw, Center, Tiled Vertex or fragment position in screen space. Dropdown selects mode. See Screen Position Node for details Tangent Vector 3 Vertex or fragment tangent vector, label describes expected transform space UV Vector 2 UV0, UV1, UV2, UV3 Mesh UV coordinates. Dropdown selects UV channel. Vertex Color Vector 4 RGBA vertex color value. View Direction Vector 3 Vertex or fragment view direction vector, label describes expected transform space"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Port.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Port.html",
    "title": "Port | Inventory System",
    "summary": "Port Description A Port defines an input or output on a Node. Connecting Edges to a Port allows data to flow through the Shader Graph node network. Each Port has a Data Type which defines what edges can be connected to it. Each data type has an associated color for identifying its type. Only one edge can be connected to any input Port but multiple edges can be connected to an output Port. You can open a contextual Create Node Menu by dragging an edge from a Port with left mouse button and releasing it in an empty area of the workspace. Default Inputs Each Input Port, a Port on the left side of a node implying that it is for inputting data into the node, has a Default Input. This appears as a small field connected to the Port when there is no edge connected. This field will display an input for the ports data type unless the Port has a Port Binding. If a Port does have a port binding the default input field might display a special field, such as a dropdown for selecting UV channels, or just a label to help you understand the intended input, such as coordinate space labels for geometry data."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Position-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Position-Node.html",
    "title": "Position Node | Inventory System",
    "summary": "Position Node Description Provides access to the mesh vertex's or fragment's Position, depending on the effective Shader Stage of the graph section that the Node is part of. Use the Space drop-down parameter to select the coordinate space of the output value. Ports Name Direction Type Binding Description Out Output Vector 3 None Position for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent, Absolute World Selects the coordinate space of Position to output. World and Absolute World The Position Node provides drop-down options for both World and Absolute World space positions. The Absolute World option always returns the absolute world position of the object in the Scene for all Scriptable Render Pipelines. The World option returns the default world space of the selected Scriptable Render Pipeline. The High Definition Render Pipeline uses Camera Relative as its default world space. The Universal Render Pipeline uses Absolute World as its default world space. Upgrading from previous versions If you use a Position Node in World space on a graph authored in Shader Graph version 6.7.0 or earlier, it automatically upgrades the selection to Absolute World. This ensures that the calculations on your graph remain accurate to your expectations, since the World output might change. If you use a Position Node in World space in the High Definition Render Pipeline to manually calculate Camera Relative world space, you can now change your node from Absolute World to World, which lets you use Camera Relative world space out of the box."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Posterize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Posterize-Node.html",
    "title": "Posterize Node | Inventory System",
    "summary": "Posterize Node Description Posterization or posterisation of an image entails conversion of a continuous gradation of tone to several regions of fewer tones, with abrupt changes from one tone to another. https://en.wikipedia.org/wiki/Posterization This node returns the posterized (also known as quantized) value of the input In into an amount of values specified by input Steps. Ports Name Direction Type Description In Input Dynamic Vector Input value Steps Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Posterize_float4(float4 In, float4 Steps, out float4 Out) { Out = floor(In / (1 / Steps)) * (1 / Steps); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Power-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Power-Node.html",
    "title": "Power Node | Inventory System",
    "summary": "Power Node Description Returns the result of input A to the power of input B. Note: If the input A is negative, the output might be inconsistent or NaN. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Power_float4(float4 A, float4 B, out float4 Out) { Out = pow(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Precision-Modes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Precision-Modes.html",
    "title": "Precision Modes | Inventory System",
    "summary": "Precision Modes Description Shader Graph provides specific data precision modes for nodes, graphs, and Sub Graphs to help you optimize your content for different platforms. To set the precision of an entire graph, select the Graph Settings tab in the Graph Inspector and adjust the Precision control. Select a node in your graph and select the Node Settings tab in the Graph Inspector to adjust the precision of individual nodes. Precision mode settings Name Description Single This is a high-precision floating point value. The number of bits is platform-specific. For modern desktop computers, it is 32 bits. This mode is useful for world space positions, texture coordinates, and scalar computations that involve complex functions such as trigonometry, power, and exponentiation. Half This is a low-precision floating point value. The number of bits is platform-specific. For modern desktop computers, it is 16 bits. This mode is useful for short vectors, directions, object space positions, and many high dynamic range colors, but not very strong light sources, such as the sun. Switchable This mode is only for Sub Graphs. When you enable this mode for a Sub Graph, the default precision of the Sub Graph is decided by its Sub Graph node. See Use Graph Precision below. Inherit This mode determines a node's precision based on a set of inheritance rules. See Precision inheritance. Use Graph Precision This mode forces this node to use the same precision setting as the graph. If this is a node in a Sub Graph, and that Sub Graph’s Precision is set to Switchable, then the precision of this node is the precision of the Sub Graph node representing this Sub Graph. Using Precision Modes Visualizing Precision in a graph To visualize data precision in a graph, set the Color Mode control to Precision. This applies color coding to your nodes: Single nodes are blue Half nodes are red Switchable nodes are Green. Setting graph Precision To set the default precision for the entire graph to Single or Half, open the Graph Settings and set the Precision property. Newly-created nodes in a graph default to the Inherit precision mode, and inherit the graph's precision. Setting node Precision Select a node to access its precision setting. The precision you set for a node determines the precision of the data types which that node uses for its calculations. Precision Inheritance All nodes use the Inherit precision mode by default. In this mode, a node that has one or more edge connections takes on the precision mode of an incoming edge. Nodes that do not have any edge connections take on Graph Precision. If you change the Graph Precision mode, the precision of those nodes also changes. Inputs on the node Final precision determined by inheritance No inputs Graph Precision Only Half inputs Half Only Single inputs Single Half and Single inputs Single Only Switchable inputs Switchable Switchable and Half inputs Switchable Switchable and Single inputs Single Switchable, Half and Single inputs Single Simple inheritance Simple inheritance refers to the inheritance behaviour of a node with only one precision type on its inputs. In the figure below, Node A has the Inherit mode. Because it has no incoming edge, it takes the Graph Precision, which is Half. Node B also has the Inherit mode, so it inherits the Half precision mode from Node A. Complex inheritance Complex inheritance refers to the inheritance behaviour of a node with multiple precision types on its inputs. A node reads precision settings from each input port. If you connect a node to several others with a variety of precision modes, the node with the highest resolution determines the precision mode for the group. In the figure below, node D has the Inherit mode. It receives input from the adjacent edges via inputs 1 and 2. Node B passes the Half mode through input 1. Node C passes the Single mode through input 2. Because Single is 32-bit and Half only 16-bit, Single takes precedence, so Node D uses Single precision. Mixed inheritance Mixed inheritance refers to the inheritance behaviour on a node with both simple and complex inheritance types. Nodes with no input ports, such as Input nodes, inherit the Graph Precision. However, complex inheritance rules still affect other nodes in the same group, as illustrated in the figure below. Switchable precision The Switchable mode overrides Half mode but not Single. Sub Graph precision Precision behavior and user interface elements for Sub Graphs and their nodes do not differ from other graphs and nodes. Sub Graphs represent a function, and you can affect that function's inputs, outputs, and operators by modifying the relevant set of precision settings. The Sub Graph properties correspond to the function's inputs. The internal node properties correspond to the function's operators. The output node corresponds to the function's outputs. Outputs To manually determine the precision of a Sub Graph's output, modify the Output node’s Precision Mode setting. Inputs To manually determine the precision of Sub Graph Inputs, open the Graph Inspector and set precision modes for each individual Property. Properties that use the Inherit option take on the Graph Precision you set for the Sub Graph. Sub Graph Precision within other graphs By default, a Sub Graph has a Precision Mode of Switchable. You can modify Precision Mode of any Sub Graph node for that Sub Graph, as long as you set the Precision Mode on the Sub Graph as Switchable. Shader Graph won't allow you to change the Precision Mode for any Sub Graph node that doesn't have its Sub Graph set to Switchable. This is because the input and output precision you set in a Sub Graph define the precision of its associated Sub Graph Node. For example, let's say that Sub Graph A is Switchable. You open Graph 1, which includes a Sub Graph Node referencing Sub Graph A. Like all other nodes, Sub Graph Node A defaults to Inherit. You change the precision of Sub Graph Node A to Half. The precision of Sub Graph A also becomes Half."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Preview-Mode-Control.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Preview-Mode-Control.html",
    "title": "Preview mode control | Inventory System",
    "summary": "Preview mode control Description This control enables you to manually select your preferred preview mode for a node that has a preview. When you select Inherit in the Preview Mode Control, the Editor automatically selects the preview mode to use. That decision is determined by either the type of the node you are previewing, the Sub Graph setting (if this node is in a Sub Graph) or other upstream nodes. To override the inheritance mode, select Preview 2D or Preview 3D. This mode control functionality also applies to Sub Graph previews. See Graph Settings menu. How to use For nodes: Add a node which includes a preview. Select the node. In the Graph Inspector or Node Settings, find the Preview control. Select an option. For SubGraphs: Select a mode in the Sub Graph Graph Settings menu. Related Preview node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Preview-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Preview-Node.html",
    "title": "Preview Node | Inventory System",
    "summary": "Preview Node Description This node enables you to inspect a preview at a specific point in a Shader Graph. It does not modify any input values. By default, the Editor automatically selects a preview mode. That decision is determined by both the type of the node you are previewing and other upstream nodes. With Preview Mode Control, you can manually select your preferred preview mode. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Preview_float4(float4 In, out float4 Out) { Out = In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Procedural-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Procedural-Nodes.html",
    "title": "Procedural Nodes | Inventory System",
    "summary": "Procedural Nodes Checkerboard Generates a checkerboard of alternating colors between inputs Color A and Color B based on input UV. Noise Gradient Noise Simple Noise Generates a gradient, or Perlin, noise based on input UV. Generates a simple, or Value, noise based on input UV. Voronoi Generates a Voronoi, or Worley, noise based on input UV. Shape Ellipse Polygon Generates an ellipse shape based on input UV at the size specified by inputs Width and Height. Generates a regular polygon shape based on input UV at the size specified by inputs Width and Height. The polygon's amount of sides is determined by input Sides. Rectangle Rounded Rectangle Generates a rectangle shape based on input UV at the size specified by inputs Width and Height. Generates a rounded rectangle shape based on input UV at the size specified by inputs Width and Height. The input Radius defines the radius of each corner. Rounded Polygon Generates a rounded polygon shape based on input UV at the size specified by inputs Width and Height. The input Sides specifies the number of sides, and the input Roundness defines the roundness of each corner."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Projection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Projection-Node.html",
    "title": "Projection Node | Inventory System",
    "summary": "Projection Node Description Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Projection_float4(float4 A, float4 B, out float4 Out) { Out = B * dot(A, B) / dot(B, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Property-Types.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Property-Types.html",
    "title": "Property Types | Inventory System",
    "summary": "Property Types Description Property Types are the types of Property than can be defined on the Blackboard for use in the Graph. These Properties are exposed to the Inspector for Materials that use the shader. Each property has an associated Data Type. See Data Types for more information. Common Parameters In addition to values specific to their Data Types, most properties have the following common parameters. Name Type Description Display Name String The display name of the property Exposed Boolean If true this property will be exposed on the material inspector Reference Name String The internal name used for the property inside the shader Override Property Declaration Boolean An advanced option to enable explicit control of the shader declaration for this property Shader Declaration Enumeration Controls the shader declaration of this property NOTE: If you overwrite the Reference Name parameter be aware of the following conditions: If your Reference Name does not begin with an underscore, one will be automatically appended. If your Reference Name contains any characters which are unsupported in HLSL they will be removed. You can revert to the default Reference Name by right clicking on it and selecting Reset Reference. Float Defines a Float value. Data Type Modes Float Default, Slider, Integer Default Displays a scalar input field in the material inspector. Field Type Description Default Float The default value of the Property. Slider Displays a slider field in the material inspector. Field Type Description Default Float The default value of the Property. Min Float The minimum value of the slider. Max Float The maximum value of the slider. Integer Displays an integer input field in the material inspector. Field Type Description Default Integer The default value of the Property. Vector 2 Defines a Vector 2 value. Displays a Vector 4 input field in the material inspector, where the z and w components are not used. Data Type Modes Vector 2 Field Type Description Default Vector 2 The default value of the Property. Vector 3 Defines a Vector 3 value. Displays a Vector 4 input field in the material inspector, where the w component is not used. Data Type Modes Vector 3 Field Type Description Default Vector 3 The default value of the Property. Vector 4 Defines a Vector 4 value. Displays a Vector 4 input field in the material inspector. Data Type Modes Vector 4 Field Type Description Default Vector 4 The default value of the Property. Color Defines a Color value. If the Property Inspector displays Main Color, this is the Main Color for the shader. To select or deselect this node as the Main Color, right-click it in the graph or Blackboard and select Set as Main Color or Clear Main Color. Corresponds to the MainColor ShaderLab Properties attribute. Data Type Modes Color Default, HDR Default Displays an sRGB color field in the material inspector. Field Type Description Default Vector 4 The default value of the Property. HDR Displays an HDR color field in the material inspector. Field Type Description Default Vector 4 The default value of the Property. NOTE: In versions prior to 10.0, Shader Graph didn't correct HDR colors for the project colorspace. Version 10.0 corrected this behavior. HDR color properties that you created with older versions maintain the old behavior, but you can use the Graph Inspector to upgrade them. To mimic the old behavior in a gamma space project, you can use the Colorspace Conversion Node to convert a new HDR Color property from RGB to Linear space. Texture 2D Defines a Texture 2D value. Displays an object field of type Texture in the material inspector. If the Property Inspector displays Main Texture, this is the Main Texture for the shader. To select or deselect this node as the Main Texture, right-click on it in the graph or Blackboard and select Set as Main Texture or Clear Main Texture. Corresponds to the MainTexture ShaderLab Properties attribute. Data Type Modes Texture White, Black, Grey, Bump Field Type Description Default Texture The default value of the Property. Use Tiling and Offset Boolean When set to false, activates the property NoScaleOffset, to enable manipulation of scale and offset separately from other texture properties. See SplitTextureTransformNode. Texture 3D Defines a Texture 3D value. Displays an object field of type Texture 3D in the material inspector. Data Type Modes Texture Field Type Description Default Texture The default value of the Property. Texture 2D Array Defines a Texture 2D Array value. Displays an object field of type Texture 2D Array in the material inspector. Data Type Modes Texture Field Type Description Default Texture The default value of the Property. Cubemap Defines a Cubemap value. Displays an object field of type Texture in the material inspector. Data Type Modes Cubemap Field Type Description Default Cubemap The default value of the Property. Virtual Texture Defines a Texture Stack, which appears as object fields of type Texture in the Material Inspector. The number of fields correspond to the number of layers in the property. Data Type Modes Virtual Texture Field Type Description Default Texture The default value of the Property. Boolean Defines a Boolean value. Displays a ToggleUI field in the material inspector. Note that internally to the shader this value is a Float. The Boolean type in Shader Graph is merely for usability. Data Type Modes Boolean Field Type Description Default Boolean The default value of the Property."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Radial-Shear-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Radial-Shear-Node.html",
    "title": "Radial Shear Node | Inventory System",
    "summary": "Radial Shear Node Description Applies a radial shear warping effect similar to a wave to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RadialShear_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float delta2 = dot(delta.xy, delta.xy); float2 delta_offset = delta2 * Strength; Out = UV + float2(delta.y, -delta.x) * delta_offset + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Radians-To-Degrees-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Radians-To-Degrees-Node.html",
    "title": "Radians To Degrees Node | Inventory System",
    "summary": "Radians To Degrees Node Description Returns the value of input In converted from radians to degrees. One radian is equivalent to approximately 57.2958 degrees and a full rotation of 2 Pi radians is equal to 360 degrees. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RadiansToDegrees_float4(float4 In, out float4 Out) { Out = degrees(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Random-Range-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Random-Range-Node.html",
    "title": "Random Range Node | Inventory System",
    "summary": "Random Range Node Description Returns a pseudo-random number value based on input Seed that is between the minimum and maximum values defined by inputs Min and Max respectively. Whilst the same value in input Seed will always result in the same output value, the output value itself will appear random. Input Seed is a Vector 2 value for the convenience of generating a random number based on a UV input, however for most cases a Float input will suffice. Ports Name Direction Type Description Seed Input Vector 2 Seed value used for generation Min Input Float Minimum value Max Input Float Maximum value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RandomRange_float(float2 Seed, float Min, float Max, out float Out) { float randomno = frac(sin(dot(Seed, float2(12.9898, 78.233)))*43758.5453); Out = lerp(Min, Max, randomno); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reciprocal-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reciprocal-Node.html",
    "title": "Reciprocal Node | Inventory System",
    "summary": "Reciprocal Node Description Returns the result of dividing 1 by the input In. This can be calculated by a fast approximation on Shader Model 5 by setting Method to Fast. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Method Dropdown Default, Fast Selects the method used Generated Code Example The following example code represents one possible outcome of this node per Method mode. Default void Unity_Reciprocal_float4(float4 In, out float4 Out) { Out = 1.0/In; } Fast (Requires Shader Model 5) void Unity_Reciprocal_Fast_float4(float4 In, out float4 Out) { Out = rcp(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reciprocal-Square-Root-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reciprocal-Square-Root-Node.html",
    "title": "Reciprocal Square Root Node | Inventory System",
    "summary": "Reciprocal Square Root Node Description Returns the result of 1 divided by the square root of the input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReciprocalSquareRoot_float4(float4 In, out float4 Out) { Out = rsqrt(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rectangle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rectangle-Node.html",
    "title": "Rectangle Node | Inventory System",
    "summary": "Rectangle Node Description Generates a rectangle shape based on input UV at the size specified by inputs Width and Height. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating rectangle effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rectangle width Height Input Float None Rectangle height Out Output Float None Output value Controls Name Type Options Description Dropdown Fastest, Nicest Robustness of computation Generated Code Example The following example code represents one possible outcome of this node. void Unity_Rectangle_float(float2 UV, float Width, float Height, out float Out) { float2 d = abs(UV * 2 - 1) - float2(Width, Height); d = 1 - d / fwidth(d); Out = saturate(min(d.x, d.y)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reflection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reflection-Node.html",
    "title": "Reflection Node | Inventory System",
    "summary": "Reflection Node Description Returns a reflection vector using input In and a surface normal Normal. Ports Name Direction Type Description In Input Dynamic Vector Incident vector value Normal Input Dynamic Vector Normal vector value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Reflection_float4(float4 In, float4 Normal, out float4 Out) { Out = reflect(In, Normal); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reflection-Probe-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Reflection-Probe-Node.html",
    "title": "Reflection Probe Node | Inventory System",
    "summary": "Reflection Probe Node Description Provides access to the nearest Reflection Probe to the object. Requires Normal and View Direction to sample the probe. You can achieve a blurring effect by sampling at a different Level of Detail using the LOD input. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description View Dir Input Vector 3 View Direction (object space) Mesh's view direction Normal Input Vector 3 Normal (object space) Mesh's normal vector LOD Input Float None Level of detail for sampling Out Output Vector 3 None Output color value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReflectionProbe_float(float3 ViewDir, float3 Normal, float LOD, out float3 Out) { Out = SHADERGRAPH_REFLECTION_PROBE(ViewDir, Normal, LOD); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Refract-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Refract-Node.html",
    "title": "Refract Node | Inventory System",
    "summary": "Refract Node Description You can use the Refract node to give a shader a refraction effect. The Refract node generates a refraction using the following to produce a new refracted vector: A normalized incident vector. A normalized normal vector of the surface. The refractive index of the source and the medium. The Refract node uses the principles described in Snell's Law. A medium's refractive index has an angle where the surface behaves like a perfect mirror. This angle is called total internal reflection. To avoid a NaN result, set the Refract node's Mode to Safe. This makes the Refract node generate a null vector when it reaches the critical angle before total internal reflection. Ports Name Direction Type Binding Description Incident Input Vector None The normalized vector from the light source to the surface. For example, this could be from a light source to a pixel, or from the Camera to a surface. Normal Input Vector None The normalized normal of the surface that causes the refraction. IOR Source Input Float None The refractive index of the medium the light source originates in. IOR Medium Input Float None The refractive index of the medium that the light refracts into. Refracted Output Vector None The refracted vector. Intensity Output Float None Intensity of the refraction. Controls Name Type Options Description Mode Dropdown • Safe: Returns a null vector result instead of a NaN result at the point of critical angle refraction. • CriticalAngle: Avoids the Safe check for a potential NaN result. Generated Code Example The following example code represents one possible outcome of this node. void Unity_RefractCriticalAngle(float3 Incident, float3 Normal, float IORInput, float IORMedium, out float Out) { $precision internalIORInput = max(IORInput, 1.0); $precision internalIORMedium = max(IORMedium, 1.0); $precision eta = internalIORInput/internalIORMedium; $precision cos0 = dot(Incident, Normal); $precision k = 1.0 - eta*eta*(1.0 - cos0*cos0); Refracted = k >= 0.0 ? eta*Incident - (eta*cos0 + sqrt(k))*Normal : reflect(Incident, Normal); Intensity = internalIORSource <= internalIORMedium ?; saturate(F_Transm_Schlick(IorToFresnel0(internalIORMedium, internalIORSource), -cos0)) : (k >= 0.0 ? saturate(F_FresnelDielectric(internalIORMedium/internalIORSource, -cos0)) : 0.0); } void Unity_RefractSafe(float3 Incident, float3 Normal, float IORInput, float IORMedium, out float Out) { $precision internalIORInput = max(IORInput, 1.0); $precision internalIORMedium = max(IORMedium, 1.0); $precision eta = internalIORInput/internalIORMedium; $precision cos0 = dot(Incident, Normal); $precision k = 1.0 - eta*eta*(1.0 - cos0*cos0); Refracted = eta*Incident - (eta*cos0 + sqrt(max(k, 0.0)))*Normal; Intensity = internalIORSource <= internalIORMedium ?; saturate(F_Transm_Schlick(IorToFresnel0(internalIORMedium, internalIORSource), -cos0)) : (k >= 0.0 ? saturate(F_FresnelDielectric(internalIORMedium/internalIORSource, -cos0)) : 1.0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rejection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rejection-Node.html",
    "title": "Rejection Node | Inventory System",
    "summary": "Rejection Node Description Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. The value of the rejection vector is equal to the original vector, the value of input A, minus the value of the Projection of the same inputs. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Rejection_float4(float4 A, float4 B, out float4 Out) { Out = A - (B * dot(A, B) / dot(B, B)) }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Remap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Remap-Node.html",
    "title": "Remap Node | Inventory System",
    "summary": "Remap Node Description Returns a value between the x and y components of input Out Min Max based on the linear interpolation of the value of input In between the x and y components of input In Min Max. Ports Name Direction Type Description In Input Dynamic Vector Input value In Min Max Input Vector 2 Minimum and Maximum values for input interpolation Out Min Max Input Vector 2 Minimum and Maximum values for output interpolation Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Remap_float4(float4 In, float2 InMinMax, float2 OutMinMax, out float4 Out) { Out = OutMinMax.x + (In - InMinMax.x) * (OutMinMax.y - OutMinMax.x) / (InMinMax.y - InMinMax.x); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Replace-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Replace-Color-Node.html",
    "title": "Replace Color Node | Inventory System",
    "summary": "Replace Color Node Description Replaces values in input In equal to input From to the value of input To. Input Range can be used to define a wider range of values around input From to replace. Input Fuzziness can be used to soften the edges around the selection similar to anti-aliasing. Ports Name Direction Type Binding Description In Input Vector 3 None Input value From Input Vector 3 Color Color to replace To Input Vector 3 Color Color to replace with Range Input Float None Replace colors within this range from input From Fuzziness Input Float None Soften edges around selection Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReplaceColor_float(float3 In, float3 From, float3 To, float Range, float Fuzziness, out float3 Out) { float Distance = distance(From, In); Out = lerp(To, In, saturate((Distance - Range) / max(Fuzziness, 1e-5f))); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rotate-About-Axis-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rotate-About-Axis-Node.html",
    "title": "Rotate About Axis Node | Inventory System",
    "summary": "Rotate About Axis Node Description Rotates the input vector In around the axis Axis by the value of Rotation. The unit for rotation angle can be selected by the parameter Unit. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Axis Input Vector 3 None Axis to rotate around Rotation Input Float None Amount of rotation to apply Out Output Vector 3 None Output value Controls Name Type Options Description Unit Dropdown Radians, Degrees Switches the unit for input Rotation Generated Code Example The following example code represents one possible outcome of this node per Unit mode. Radians void Unity_RotateAboutAxis_Radians_float(float3 In, float3 Axis, float Rotation, out float3 Out) { float s = sin(Rotation); float c = cos(Rotation); float one_minus_c = 1.0 - c; Axis = normalize(Axis); float3x3 rot_mat = { one_minus_c * Axis.x * Axis.x + c, one_minus_c * Axis.x * Axis.y - Axis.z * s, one_minus_c * Axis.z * Axis.x + Axis.y * s, one_minus_c * Axis.x * Axis.y + Axis.z * s, one_minus_c * Axis.y * Axis.y + c, one_minus_c * Axis.y * Axis.z - Axis.x * s, one_minus_c * Axis.z * Axis.x - Axis.y * s, one_minus_c * Axis.y * Axis.z + Axis.x * s, one_minus_c * Axis.z * Axis.z + c }; Out = mul(rot_mat, In); } Degrees void Unity_RotateAboutAxis_Degrees_float(float3 In, float3 Axis, float Rotation, out float3 Out) { Rotation = radians(Rotation); float s = sin(Rotation); float c = cos(Rotation); float one_minus_c = 1.0 - c; Axis = normalize(Axis); float3x3 rot_mat = { one_minus_c * Axis.x * Axis.x + c, one_minus_c * Axis.x * Axis.y - Axis.z * s, one_minus_c * Axis.z * Axis.x + Axis.y * s, one_minus_c * Axis.x * Axis.y + Axis.z * s, one_minus_c * Axis.y * Axis.y + c, one_minus_c * Axis.y * Axis.z - Axis.x * s, one_minus_c * Axis.z * Axis.x - Axis.y * s, one_minus_c * Axis.y * Axis.z + Axis.x * s, one_minus_c * Axis.z * Axis.z + c }; Out = mul(rot_mat, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rotate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rotate-Node.html",
    "title": "Rotate Node | Inventory System",
    "summary": "Rotate Node Description Rotates value of input UV around a reference point defined by input Center by the amount of input Rotation. The unit for rotation angle can be selected by the parameter Unit. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center point to rotate around Rotation Input Float None Amount of rotation to apply Out Output Vector 2 None Output UV value Controls Name Type Options Description Unit Dropdown Radians, Degrees Switches the unit for input Rotation Generated Code Example The following example code represents one possible outcome of this node per Unit mode. Radians void Unity_Rotate_Radians_float(float2 UV, float2 Center, float Rotation, out float2 Out) { UV -= Center; float s = sin(Rotation); float c = cos(Rotation); float2x2 rMatrix = float2x2(c, -s, s, c); rMatrix *= 0.5; rMatrix += 0.5; rMatrix = rMatrix * 2 - 1; UV.xy = mul(UV.xy, rMatrix); UV += Center; Out = UV; } Degrees void Unity_Rotate_Degrees_float(float2 UV, float2 Center, float Rotation, out float2 Out) { Rotation = Rotation * (3.1415926f/180.0f); UV -= Center; float s = sin(Rotation); float c = cos(Rotation); float2x2 rMatrix = float2x2(c, -s, s, c); rMatrix *= 0.5; rMatrix += 0.5; rMatrix = rMatrix * 2 - 1; UV.xy = mul(UV.xy, rMatrix); UV += Center; Out = UV; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Round-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Round-Node.html",
    "title": "Round Node | Inventory System",
    "summary": "Round Node Description Returns the value of input In rounded to the nearest integer, or whole number. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Round_float4(float4 In, out float4 Out) { Out = round(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rounded-Polygon-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rounded-Polygon-Node.html",
    "title": "Rounded Polygon Node | Inventory System",
    "summary": "Rounded Polygon Node Description Generates a rounded polygon shape based on input UV at the size specified by inputs Width and Height. The input Sides specifies the number of sides, and the input Roundness defines the roundness of each corner. You can connect a Tiling And Offset Node to offset or tile the shape. To preserve the ability to offset the shape within the UV space, the shape does not automatically repeat if you tile it. To achieve a repeating rounded polygon effect, first connect your UV input through a Fraction Node. You can only use the Rounded Polygon Node in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rounded Polygon width Height Input Float None Rounded Polygon height Sides Input Float None Number of sides of the polygon Roundness Input Float None Roundness of corners Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void RoundedPolygon_Func_float(float2 UV, float Width, float Height, float Sides, float Roundness, out float Out) { UV = UV * 2. + float2(-1.,-1.); float epsilon = 1e-6; UV.x = UV.x / ( Width + (Width==0)*epsilon); UV.y = UV.y / ( Height + (Height==0)*epsilon); Roundness = clamp(Roundness, 1e-6, 1.); float i_sides = floor( abs( Sides ) ); float fullAngle = 2. * PI / i_sides; float halfAngle = fullAngle / 2.; float opositeAngle = HALF_PI - halfAngle; float diagonal = 1. / cos( halfAngle ); // Chamfer values float chamferAngle = Roundness * halfAngle; // Angle taken by the chamfer float remainingAngle = halfAngle - chamferAngle; // Angle that remains float ratio = tan(remainingAngle) / tan(halfAngle); // This is the ratio between the length of the polygon's triangle and the distance of the chamfer center to the polygon center // Center of the chamfer arc float2 chamferCenter = float2( cos(halfAngle) , sin(halfAngle) )* ratio * diagonal; // starting of the chamfer arc float2 chamferOrigin = float2( 1., tan(remainingAngle) ); // Using Al Kashi algebra, we determine: // The distance distance of the center of the chamfer to the center of the polygon (side A) float distA = length(chamferCenter); // The radius of the chamfer (side B) float distB = 1. - chamferCenter.x; // The refence length of side C, which is the distance to the chamfer start float distCref = length(chamferOrigin); // This will rescale the chamfered polygon to fit the uv space // diagonal = length(chamferCenter) + distB; float uvScale = diagonal; UV *= uvScale; float2 polaruv = float2 ( atan2( UV.y, UV.x ), length(UV) ); polaruv.x += HALF_PI + 2*PI; polaruv.x = fmod( polaruv.x + halfAngle, fullAngle ); polaruv.x = abs(polaruv.x - halfAngle); UV = float2( cos(polaruv.x), sin(polaruv.x) ) * polaruv.y; // Calculate the angle needed for the Al Kashi algebra float angleRatio = 1. - (polaruv.x-remainingAngle) / chamferAngle; // Calculate the distance of the polygon center to the chamfer extremity float distC = sqrt( distA*distA + distB*distB - 2.*distA*distB*cos( PI - halfAngle * angleRatio ) ); Out = UV.x; float chamferZone = ( halfAngle - polaruv.x ) < chamferAngle; Out = lerp( UV.x, polaruv.y / distC, chamferZone ); // Output this to have the shape mask instead of the distance field Out = saturate((1 - Out) / fwidth(Out)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rounded-Rectangle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Rounded-Rectangle-Node.html",
    "title": "Rounded Rectangle Node | Inventory System",
    "summary": "Rounded Rectangle Node Description Generates a rounded rectangle shape based on input UV at the size specified by inputs Width and Height. The radius of each corner is defined by input Radius. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating rounded rectangle effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rounded Rectangle width Height Input Float None Rounded Rectangle height Radius Input Float None Corner radius Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RoundedRectangle_float(float2 UV, float Width, float Height, float Radius, out float Out) { Radius = max(min(min(abs(Radius * 2), abs(Width)), abs(Height)), 1e-5); float2 uv = abs(UV * 2 - 1) - float2(Width, Height) + Radius; float d = length(max(0, uv)) / Radius; Out = saturate((1 - d) / fwidth(d)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Cubemap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Cubemap-Node.html",
    "title": "Sample Cubemap Node | Inventory System",
    "summary": "Sample Cubemap Node Description Samples a Cubemap and returns a Vector 4 color value for use in the shader. Requires a Direction (Dir) input in world space to sample the Cubemap. You can achieve a blurring effect by using the LOD input to sample at a different Level of Detail. You can also use the Sampler input to define a custom Sampler State. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Cube Input Cubemap None Cubemap to sample Dir Input Vector 3 Normal (world space) Direction or Mesh's normal vector Sampler Input Sampler State Default sampler state Sampler for the Cubemap LOD Input Float None Level of detail for sampling Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _SampleCubemap_Out = SAMPLE_TEXTURECUBE_LOD(Cubemap, Sampler, Dir, LOD);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Gradient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Gradient-Node.html",
    "title": "Sample Gradient Node | Inventory System",
    "summary": "Sample Gradient Node Description Samples a Gradient given the input of Time. Returns a Vector 4 color value for use in the shader. Ports Name Direction Type Binding Description Gradient Input Gradient None Gradient to sample Time Input Float None Point at which to sample gradient (0.0–1.0) Out Output Vector 4 None Output value as Vector4 Generated Code Example The following example code represents one possible outcome of this node. void Unity_SampleGradient_float(float4 Gradient, float Time, out float4 Out) { float3 color = Gradient.colors[0].rgb; [unroll] for (int c = 1; c < 8; c++) { float colorPos = saturate((Time - Gradient.colors[c-1].w) / (Gradient.colors[c].w - Gradient.colors[c-1].w)) * step(c, Gradient.colorsLength-1); color = lerp(color, Gradient.colors[c].rgb, lerp(colorPos, step(0.01, colorPos), Gradient.type)); } #ifndef UNITY_COLORSPACE_GAMMA color = SRGBToLinear(color); #endif float alpha = Gradient.alphas[0].x; [unroll] for (int a = 1; a < 8; a++) { float alphaPos = saturate((Time - Gradient.alphas[a-1].y) / (Gradient.alphas[a].y - Gradient.alphas[a-1].y)) * step(a, Gradient.alphasLength-1); alpha = lerp(alpha, Gradient.alphas[a].x, lerp(alphaPos, step(0.01, alphaPos), Gradient.type)); } Out = float4(color, alpha); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Reflected-Cubemap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Reflected-Cubemap-Node.html",
    "title": "Sample Reflected Cubemap Node | Inventory System",
    "summary": "Sample Reflected Cubemap Node Description Samples a Cubemap with reflected vector and returns a Vector 4 color value for use in the shader. Requires View Direction (View Dir) and Normal inputs to sample the Cubemap. You can achieve a blurring effect by using the LOD input to sample at a different Level of Detail. You can also use the Sampler input to define a custom Sampler State. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Cube Input Cubemap None Cubemap to sample View Dir Input Vector 3 View Direction (object space) Mesh's view direction Normal Input Vector 3 Normal (object space) Mesh's normal vector Sampler Input Sampler State Default sampler state Sampler for the Cubemap LOD Input Float None Level of detail for sampling Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _SampleCubemap_Out = SAMPLE_TEXTURECUBE_LOD(Cubemap, Sampler, reflect(-ViewDir, Normal), LOD);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-Array-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-Array-Node.html",
    "title": "Sample Texture 2D Array node | Inventory System",
    "summary": "Sample Texture 2D Array node The Sample Texture 2D Array node samples a Texture 2D Array asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. The node's Index input port specifies which index of a Texture 2D Array to sample. For more information about Texture 2D Arrays, see Texture Arrays in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D Array node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 3D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 3D node has the following input ports: Name Type Binding Description Texture Array Texture 2D Array None The Texture 2D Array asset to sample. Index Float None The index of the specific Texture in the Texture array to sample. The index value is the Texture's location in the Texture array. The index values in an array always start at 0. An array with four textures would have locations 0, 1, 2, and 3. UV Vector 2 None UV coordinates to use to sample the Texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD NOTE: The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. The specific mip to use when sampling the Texture. UV Vector 2 UV The UV coordinates to use to sample the texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Bias Float Bias NOTE: The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, refer to Additional node settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDY NOTE: The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDX value to use to calculate the texture's mip when sampling. For more information on DDX values for mipmaps, refer to Mipmaps introduction in the Unity User Manual. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDY value to use to calculate the texture's mip when sampling. For more information on DDY values for mipmaps, refer to Mipmaps introduction> in the Unity User Manual. Additional node settings The Sample Texture 3D node has some additional settings that you can access from the Graph Inspector: Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual. Outputs The Sample Texture 3D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 2D Array node samples a Texture array that has 4 different cloth normal maps. Change the number given to the Index port as an input, and the Sample Texture 2D Array node can sample a specific normal map from the array. The Index value changes the output the node sends to the Normal Unpack node, and the Normal (Tangent Space) Block node in the Master Stack. Generated code example The following code represents this node in Unity's shader code: float4 _SampleTexture2DArray_RGBA = SAMPLE_TEXTURE2D_ARRAY(Texture, Sampler, UV, Index); float _SampleTexture2DArray_R = _SampleTexture2DArray_RGBA.r; float _SampleTexture2DArray_G = _SampleTexture2DArray_RGBA.g; float _SampleTexture2DArray_B = _SampleTexture2DArray_RGBA.b; float _SampleTexture2DArray_A = _SampleTexture2DArray_RGBA.a; Related nodes The following nodes are related or similar to the Sample Texture 3D node: Sample Texture 2D node Sample Texture 3D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-LOD-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-LOD-Node.html",
    "title": "Sample Texture 2D LOD Node | Inventory System",
    "summary": "Sample Texture 2D LOD Node Description Samples a Texture 2D and returns a Vector 4 color value for use in the shader. You can override the UV coordinates using the UV input and define a custom Sampler State using the Sampler input. Use the LOD input to adjust the level of detail of the sample. To use the Sample Texture 2D LOD Node to sample a normal map, set the Type dropdown parameter to Normal. This Node is useful for sampling a Texture in the vertex Shader Stage as the Sample Texture 2D Node is unavailable in this Shader Stage. On platforms that do not support this operation, opaque black is returned instead. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Texture Input Texture 2D None Texture 2D to sample UV Input Vector 2 UV UV coordinates Sampler Input Sampler State Default sampler state Sampler for the texture LOD Input Float None Level of detail to sample RGBA Output Vector 4 None Output value as RGBA R Output Float None red (x) component of RGBA output G Output Float None green (y) component of RGBA output B Output Float None blue (z) component of RGBA output A Output Float None alpha (w) component of RGBA output Controls Name Type Options Description Type Dropdown Default, Normal Selects the texture type Generated Code Example The following example code represents one possible outcome of this node per Type mode. Default float4 _SampleTexture2DLOD_RGBA = SAMPLE_TEXTURE2D_LOD(Texture, Sampler, UV, LOD); float _SampleTexture2DLOD_R = _SampleTexture2DLOD_RGBA.r; float _SampleTexture2DLOD_G = _SampleTexture2DLOD_RGBA.g; float _SampleTexture2DLOD_B = _SampleTexture2DLOD_RGBA.b; float _SampleTexture2DLOD_A = _SampleTexture2DLOD_RGBA.a; Normal float4 _SampleTexture2DLOD_RGBA = SAMPLE_TEXTURE2D_LOD(Texture, Sampler, UV, LOD); _SampleTexture2DLOD_RGBA.rgb = UnpackNormalRGorAG(_SampleTexture2DLOD_RGBA); float _SampleTexture2DLOD_R = _SampleTexture2DLOD_RGBA.r; float _SampleTexture2DLOD_G = _SampleTexture2DLOD_RGBA.g; float _SampleTexture2DLOD_B = _SampleTexture2DLOD_RGBA.b; float _SampleTexture2DLOD_A = _SampleTexture2DLOD_RGBA.a;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-2D-Node.html",
    "title": "Sample Texture 2D node | Inventory System",
    "summary": "Sample Texture 2D node The Sample Texture 2D node samples a Texture 2D asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. A Sample Texture 2D node can also sample a normal map. For more information, see the Controls section, or Normal map (Bump mapping) in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture 2D asset to sample. UV Vector 2 UV The UV coordinates to use to sample the texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Bias Float Bias NOTE: The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, refer to Additional node settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDY NOTE: The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDX value to use to calculate the texture's mip when sampling. For more information on DDX values for mipmaps, refer to Mipmaps introduction in the Unity User Manual. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDY value to use to calculate the texture's mip when sampling. For more information on DDY values for mipmaps, refer to Mipmaps introduction> in the Unity User Manual. Controls The Sample Texture 2D node has the following controls: Name Type Description Type Dropdown Select whether the texture is a Texture asset or a normal map. Default The texture is a Texture asset. Normal The texture is a normal map. Space Dropdown When the node's Type is Normal to use a texture as a normal map, choose the Space for the normal map. Tangent Use a Tangent normal map whenever the mesh for a geometry needs to deform or change, such as when animating a character. With Tangent Space, the normal map's normals are relative to the existing vertex normals of any geometry rendered with your Shader Graph. Your Shader Graph only adjusts the vertex normals and not override them. Object Use an Object normal map whenever the mesh for a geometry is static and doesn't deform. With Object Space, the normal map's normals are explicit and override the normals of any geometry rendered with your Shader Graph. Because a static mesh's normals never change, an Object normal map also maintains consistent lighting across different levels of detail (LODs). For more information about normal maps, see Normal map (Bump mapping) in the User manual. Additional node settings The Sample Texture 2D node has some additional settings that you can access from the Graph Inspector: Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual. Outputs The Sample Texture 2D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 2D node uses a Subgraph node that generates UV coordinates in latitude and longitude format. These latitude and longitude UV coordinates help render the latlong_test 2D Texture asset, which was created and formatted with a latitude and longitude projection. The generated latitude and longitude UVs accurately map the 2D Texture asset onto a spherical geometry. If the Sample Texture 2D node uses the Standard Mip Sampling Mode, the Texture displays with a seam along the side of the sphere where the left and right sides of the texture meet. The latitude and longitude UV coordinates for sampling the texture jump from 0 to 1 at the seam on the model, which causes a problem with the mip level calculation in the sample. The error in the mip level calculation causes the seam. The texture requires a different mip sampling mode to remove the seam. When the Mip Sampling Mode is set to Gradient, the Sample Texture 2D node can use the standard set of UVs for the model in the mip level calculation, instead of the latitude and longitude UVs needed for sampling the texture. The new UV coordinates passed into the DDX and DDY input ports result in a continuous mip level, and remove the seam. Generated code example The following code represents this node in Unity's shader code, based on the selected Type on the Sample Texture 2D node: Default float4 _SampleTexture2D_RGBA = SAMPLE_TEXTURE2D(Texture, Sampler, UV); float _SampleTexture2D_R = _SampleTexture2D_RGBA.r; float _SampleTexture2D_G = _SampleTexture2D_RGBA.g; float _SampleTexture2D_B = _SampleTexture2D_RGBA.b; float _SampleTexture2D_A = _SampleTexture2D_RGBA.a; Normal float4 _SampleTexture2D_RGBA = SAMPLE_TEXTURE2D(Texture, Sampler, UV); _SampleTexture2D_RGBA.rgb = UnpackNormalMapRGorAG(_SampleTexture2D_RGBA); float _SampleTexture2D_R = _SampleTexture2D_RGBA.r; float _SampleTexture2D_G = _SampleTexture2D_RGBA.g; float _SampleTexture2D_B = _SampleTexture2D_RGBA.b; float _SampleTexture2D_A = _SampleTexture2D_RGBA.a; Related nodes The following nodes are related or similar to the Sample Texture 2D node: Sample Texture 2D Array node Sample Texture 3D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-3D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Texture-3D-Node.html",
    "title": "Sample Texture 3D node | Inventory System",
    "summary": "Sample Texture 3D node The Sample Texture 3D node samples a Texture 3D asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. For more information about Texture 3D assets, see 3D textures in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 3D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 3D node has the following input ports: Name Type Binding Description Texture Texture 3D None The 3D Texture asset to sample. UV Vector 3 None The 3D UV coordinates to use to sample the Texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Additional node settings The Sample Texture 3D node has some additional settings that you can access from the Graph Inspector: Name Type Description Mip Sampling Mode Dropdown Choose the sampling mode that the Sample Texture 3D node uses to calculate the mip level of the texture. Standard The mip is calculated and selected automatically for the texture. LOD Set an explicit mip for the texture. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. If the Mip Sampling Mode is set to LOD, you can connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Outputs The Sample Texture 3D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 3D node samples a 3D fractal noise Texture asset. It takes its input UV coordinates from a Position node, set to Object Space. The Sample Texture 3D node needs a Vector 3 for its UV coordinate input, rather than a Vector 2, because the Texture asset exists as a volume in imaginary 3D space. The node uses the default Sampler State because there is no Sampler State node connected. This specific Texture 3D asset stores its Texture data in the Alpha channel, so the Sample Texture 3D node uses its A output port as an input for the Base Color Block node in the Fragment Context of the Master Stack: Generated code example The following code represents this node in Unity's shader code: float4 _SampleTexture3D_Out = SAMPLE_TEXTURE3D(Texture, Sampler, UV); Related nodes The following nodes are related or similar to the Sample Texture 3D node: Sample Texture 2D Array node Sample Texture 2D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Virtual-Texture-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sample-Virtual-Texture-Node.html",
    "title": "Sample Virtual Texture Node | Inventory System",
    "summary": "Sample Virtual Texture Node Description Samples a Virtual Texture and returns up to four Vector 4 color values for use in the shader. You can use the UV input to override the UV coordinate. The Sample Virtual Texture node takes one UV coordinate as the input, and uses that UV coordinate to sample all of the textures in the Virtual Texture. If you want to use the Sample Virtual Texture node to sample normal maps, navigate to each layer that you want to sample as a normal map, open the Layer Type drop-down menu, and select Normal. By default, you can only use this node in the fragment shader stage. For more information about how to use this node, or how to configure it for use in the vertex shader stage, see Using Streaming Virtual Texturing in Shader Graph. If you disable Virtual Texturing in your project, this node works the same way as the Sample 2D Texture Node, and performs standard 2D sampling on each texture. You must connect a Sample Virtual Texture node to a Virtual Texture property for the Shader Graph Asset to compile. If you don't connect the node to a property, an error appears, indicating that the node requires a connection. For information about Streaming Virtual Texturing, see Streaming Virtual Texturing. Ports Name Direction Type Binding Description UV Input Vector 2 UV The UV coordinate. VT Input Virtual Texture None The Virtual Texture to sample. Must be connected to a Virtual Texture property. Out Output Vector 4 None The output value of layer 1 as RGBA. Out2 Output Vector 4 None The output of layer 2 as RGBA. Out3 Output Vector 4 None The output of layer 3 as RGBA. Out4 Output Vector 4 None The output of layer 4 as RGBA. Settings The Sample Virtual Texture node has several settings available for you to specify its behavior. These settings work in combination with any scripts you might have set up in your project. To view the settings, select the node with the Graph Inspector open. For more information, see Streaming Virtual Texturing. Name Type Options Description Lod Mode Dropdown Automatic, Lod Level, Lod Bias, Derivatives Sets the specific Lod mode to use when sampling the textures. Quality Dropdown Low, High Sets the quality mode to use when sampling the textures. Automatic Streaming Toggle Enabled/Disabled Determines whether the node uses automatic streaming or manual streaming. Enable Global Mip Bias Toggle Enabled/Disabled Enables the global mipmap bias that Unity automatically imposes at runtime. Unity sets this bias during certain dynamic resolution scaling algorithms to improve detail reconstruction. Layer 1 Type Dropdown Default, Normal The texture type of layer 1. Layer 2 Type Dropdown Default, Normal The texture type of layer 2. Layer 3 Type Dropdown Default, Normal The texture type of layer 3. This option only appears if the Virtual Texture has at least 3 layers. Layer 4 Type Dropdown Default, Normal The texture type of layer 4. This option only appears if the Virtual Texture has at least 4 layers. Generated Code Example The following example code represents one possible outcome of this node. float4 SampleVirtualTexture(float2 uv, VTPropertyWithTextureType vtProperty, out float4 Layer0) { VtInputParameters vtParams; vtParams.uv = uv; vtParams.lodOrOffset = 0.0f; vtParams.dx = 0.0f; vtParams.dy = 0.0f; vtParams.addressMode = VtAddressMode_Wrap; vtParams.filterMode = VtFilter_Anisotropic; vtParams.levelMode = VtLevel_Automatic; vtParams.uvMode = VtUvSpace_Regular; vtParams.sampleQuality = VtSampleQuality_High; #if defined(SHADER_STAGE_RAY_TRACING) if (vtParams.levelMode == VtLevel_Automatic || vtParams.levelMode == VtLevel_Bias) { vtParams.levelMode = VtLevel_Lod; vtParams.lodOrOffset = 0.0f; } #endif StackInfo info = PrepareVT(vtProperty.vtProperty, vtParams); Layer0 = SampleVTLayerWithTextureType(vtProperty, vtParams, info, 0); return GetResolveOutput(info); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sampler-State-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sampler-State-Node.html",
    "title": "Sampler State Node | Inventory System",
    "summary": "Sampler State Node Description Defines a Sampler State for sampling textures. It should be used in conjunction with sampling Nodes such as the Sample Texture 2D Node. You can set a filter mode with the dropdown parameter Filter and a wrap mode with the dropdown parameter Wrap. When using a separate Sample State Node you can sample a Texture 2D twice, with different sampler parameters, without defining the Texture 2D itself twice. Not all filtering, wrap, and Anisotropic filtering modes are available on all platforms. Ports Name Direction Type Binding Description Out Output Sampler State None Output value Controls Name Type Options Description Filter Dropdown Linear, Point, Trilinear Specifies which filtering mode to use for sampling. Wrap Dropdown Repeat, Clamp, Mirror, MirrorOnce Specifies which wrap mode to use for sampling. Node Settings Controls The following control appears on the Node Settings tab of the Graph Inspector when you select the Sampler State Node. Name Type Options Description Anisotropic Filtering Dropdown None, x2, x4, x8, x16 Specifies the level of Anisotropic filtering to use to sample textures. Generated Code Example The following example code represents one possible outcome of this node. SamplerState _SamplerState_Out = _SamplerState_Linear_Repeat_sampler;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Saturate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Saturate-Node.html",
    "title": "Saturate Node | Inventory System",
    "summary": "Saturate Node Description Returns the value of input In clamped between 0 and 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Saturate_float4(float4 In, out float4 Out) { Out = saturate(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Saturation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Saturation-Node.html",
    "title": "Saturation Node | Inventory System",
    "summary": "Saturation Node Description Adjusts the saturation of input In by the amount of input Saturation. A Saturation value of 1 will return the input unaltered. A Saturation value of 0 will return the input completely desaturated. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Saturation Input Float None Saturation value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Saturation_float(float3 In, float Saturation, out float3 Out) { float luma = dot(In, float3(0.2126729, 0.7151522, 0.0721750)); Out = luma.xxx + Saturation.xxx * (In - luma.xxx); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sawtooth-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sawtooth-Wave-Node.html",
    "title": "Sawtooth Wave Node | Inventory System",
    "summary": "Sawtooth Wave Node Description Returns a sawtooth wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SawtoothWave_float4(float4 In, out float4 Out) { Out = 2 * (In - floor(0.5 + In)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Color-Node.html",
    "title": "Scene Color Node | Inventory System",
    "summary": "Scene Color Node Description Provides access to the current Camera's color buffer using input UV, which is expected to be normalized screen coordinates. The behavior of the Scene Color node isn't defined globally. The executed HLSL code for the Scene Color node is defined per Render Pipeline, and different Render Pipelines can produce different results. Custom Render Pipelines that wish to support the Scene Color node need to explicitly define the behavior for it. If the behavior is undefined, the Scene Color node returns 0 (black). In the Universal Render Pipeline the Scene Color node returns the value of the Camera Opaque Texture. Refer to the Universal Render Pipeline for more documentation on this feature. The contents of this texture are only available for Transparent objects. Set the Surface Type dropdown on the Material Options panel of the Master Node to Transparent to receive the correct values from this node. Note You can only use the Scene Color node in the Fragment Shader Stage. Supported Unity render pipelines The following table indicates which render pipelines support the Scene Color node. When used with unsupported render pipelines, the Scene Color node returns 0 (black). Pipeline Supported Built-in Render Pipeline No Universal Render Pipeline Yes High Definition Render Pipeline Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Normalized screen coordinates Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SceneColor_float(float4 UV, out float3 Out) { Out = SHADERGRAPH_SAMPLE_SCENE_COLOR(UV); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Depth-Difference-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Depth-Difference-Node.html",
    "title": "Scene Depth Difference | Inventory System",
    "summary": "Scene Depth Difference Description Provide a difference between a World Space Position and a Depth value for a given UV. Ports Name Direction Type Binding Description Scene UV Input Vector4 None UV where to sample the depth. Position WS Input Vector3 None The world space position to compare with scene depth. Out Output Float None The difference between PositionWS and the depth. The difference is given relative to camera with Eye mode, in depth-buffer-value with Raw mode and in Linear value remap between 0 and 1 with the Linear01 Mode. Controls Name Type Options Description Mode Dropdown Select Linear01 to have a value between 0 and 1, Eye to have a World-Space value comparable to unit used on the scene and Raw if it's used with SceneDepthBuffer."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Scene-Depth-Node.html",
    "title": "Scene Depth Node | Inventory System",
    "summary": "Scene Depth Node Description Provides access to the current Camera's depth buffer using input UV, which is expected to be normalized screen coordinates. Note: Depth buffer access requires depth buffer to be enabled on the active Render Pipeline. This process is different per Render Pipeline. It is recommended you read the documentation of your active Render Pipeline for information on enabling the depth buffer. If the depth buffer is unavailable this Node will return mid grey. Note: The executed HLSL code for this Node is defined per Render Pipeline, and different Render Pipelines may produce different results. Custom Render Pipelines that wish to support this Node will also need to explicitly define the behaviour for it. If undefined this Node will return 1 (white). NOTE: This Node can only be used in the Fragment Shader Stage and it is not guaranteed to work with an opaque material. Unity Render Pipelines Support High Definition Render Pipeline Universal Render Pipeline Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Normalized screen coordinates Out Output Float None Output value Depth Sampling modes Name Description Linear01 Linear depth value between 0 and 1 Raw Raw depth value Eye Depth converted to eye space units Generated Code Example The following example code represents one possible outcome of this node. void Unity_SceneDepth_Raw_float(float4 UV, out float Out) { Out = SHADERGRAPH_SAMPLE_SCENE_DEPTH(UV); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-Iris-Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-Iris-Blend-Node.html",
    "title": "Sclera Iris Blend Node | Inventory System",
    "summary": "Sclera Iris Blend Node This node blends all the properties of the Iris and the Sclera so that they can be fed to the master node. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera Iris Blend Node No Yes Ports name Direction type description Sclera Color Input Color Color of the sclera at the target fragment. Sclera Normal Input Vector3 Normal of the sclera at the target fragment. Sclera Smoothness Input float Smoothness of the sclera at the target fragment. Iris Color Input Color Color of the iris at the target fragment. Iris Normal Input Vector3 Normal of the iris at the target fragment. Cornea Smoothness Input float Smoothness of the cornea at the target fragment. IrisRadius Input float The radius of the Iris in the model. For the default model, this value should be 0.225. PositionOS Input Vector3 Position in object space of the current fragment to shade. Diffusion Profile Sclera Input Diffusion Profile Diffusion profile used to compute the subsurface scattering of the sclera. Diffusion Profile Iris Input Diffusion Profile Diffusion profile used to compute the subsurface scattering of the iris. EyeColor Output Color Final Diffuse color of the Eye. Surface Mask Output float Linear, normalized value that defines where the fragment is. On the Cornea, this is 1 and on the Sclera, this is 0. Diffuse Normal Output Vector3 Normal of the diffuse lobes. Specular Normal Output Vector3 Normal of the specular lobes. EyeSmoothness Output float Final smoothness of the Eye. SurfaceDiffusionProfile Output Diffusion Profile Diffusion profile of the target fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-Limbal-Ring-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-Limbal-Ring-Node.html",
    "title": "Sclera Limbal Ring Node | Inventory System",
    "summary": "Sclera Limbal Ring Node Calculates the intensity of the Sclera ring, a darkening feature of eyes. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera Limbal Ring Node No Yes Ports name Direction type description PositionOS Input Vector3 Position in object space of the current fragment to shade. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. IrisRadius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. LimbalRingSize Input float Normalized [0, 1] value that defines the relative size of the limbal ring. LimbalRingFade Input float Normalized [0, 1] value that defines strength of the fade out of the limbal ring.** LimbalRing Intensity Input float Positive value that defines how dark the limbal ring is. Iris Limbal Ring Color Output Color Intensity of the limbal ring (blackscale)."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-UV-Location-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sclera-UV-Location-Node.html",
    "title": "Sclera UV Location Node | Inventory System",
    "summary": "Sclera UV Location Node This node converts the object position of the sclera to a UV Sampling coordinate. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera UV Location Node No Yes Ports name Direction type description PositionOS Input Vector3 Position of the fragment to shade in object space. ScleraUV Output Vector2 Normalized UV coordinates that can be used to sample either a texture or procedurally generate a Sclera Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Screen-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Screen-Node.html",
    "title": "Screen Node | Inventory System",
    "summary": "Screen Node Description Provides access to parameters of the screen. Unity Render Pipelines Support Universal Render Pipeline Note: when dynamic resolution is enabled, this node will return the current viewport of the rendering camera. After the upscaling pass, the output of this node will be equal to the screen size. Ports Name Direction Type Binding Description Width Output Float None Screen's width in pixels Height Output Float None Screen's height in pixels Generated Code Example The following example code represents one possible outcome of this node. float _Screen_Width = _ScreenParams.x; float _Screen_Height = _ScreenParams.y;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Screen-Position-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Screen-Position-Node.html",
    "title": "Screen Position Node | Inventory System",
    "summary": "Screen Position Node Description Provides access to the screen position of the mesh vertex or fragment. The X and Y values represent the horizontal and vertical positions respectively. Use the Mode dropdown control to select the mode of the output value. The available modes are as follows: Default - Returns X and Y values that represent the normalized Screen Position. The normalized Screen Position is the Screen Position divided by the clip space position W component. The X and Y value ranges are between 0 and 1 with position float2(0,0) at the lower left corner of the screen. The Z and W values aren't used in this mode, so they're always 0. Raw - Returns the raw Screen Position values, which are the Screen Position values before the clip space position W component is divided out. Position float2(0,0) is at the lower left corner of the screen. This mode is useful for projection. Center - Returns X and Y values that represent the normalized Screen Position offset so position float2(0,0) is at the center of the screen. The range of the X and Y values is –1 to 1. The Z and W values aren't used in this mode, so they're always 0. Tiled - Returns Screen Position offset so position float2(0,0) is at the center of the screen and tiled using frac. Pixel - Returns Screen Position in terms of the actual pixel width and height values of the screen. In this mode, position float2(0,0) is at the lower left corner of the screen. Whereas the range of Default mode is always 0 to 1, the range of Pixel mode depends on the screen resolution. The Z and W values aren't used in this mode, so they're always 0. Ports Name Direction Type Binding Description Out Output Vector 4 None Get the Screen Position of the mesh. Controls Name Type Options Description Mode Dropdown Default, Raw, Center, Tiled, Pixel Select which coordinate space to use for the Screen Position output. Generated Code Example The following code examples represent one possible outcome for each mode. Default float4 Out = float4(IN.NDCPosition.xy, 0, 0); Raw float4 Out = IN.ScreenPosition; Center float4 Out = float4(IN.NDCPosition.xy * 2 - 1, 0, 0); Tiled float4 Out = frac(float4((IN.NDCPosition.x * 2 - 1) * _ScreenParams.x / _ScreenParams.y, IN.{0}.y * 2 - 1, 0, 0)); Pixel float4 Out = float4(IN.PixelPosition.xy, 0, 0);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Asset.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Asset.html",
    "title": "Shader Graph Asset | Inventory System",
    "summary": "Shader Graph Asset Description The Shader Graph Asset is the new Asset type introduced with the shader graph. You can create a Shader Graph Asset from the Project Window from the Create menu. For convenience there is a Create menu entry for Blank Shader Graph and Sub-graph. They can be found in the Shader sub-menu. Additional options may be provided by render pipelines. These options will create a new Shader Graph with required settings and Block nodes in the Master Stack for the selected shading model. You can open the Shader Graph Window by double clicking a Shader Graph Asset or by clicking Open Shader Editor in the Inspector when the Shader Graph Asset is selected."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Preferences.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Preferences.html",
    "title": "Shader Graph Preferences | Inventory System",
    "summary": "Shader Graph Preferences Use the Shader Graph preferences to define shader graph settings for your system. To access the Shader Graph system preferences, do the following: From the main menu select Edit > Preferences (macOS: Unity > Settings). The Preferences window is displayed. Select Shader Graph. Settings Name Description Preview Variant Limit Set the maximum number of variants allowed in local projects. This is a local version of the Shader Variant Limit in the project settings. If your graph exceeds this maximum value, Unity returns the following error: Validation: Graph is generating too many variants. Either delete Keywords, reduce Keyword variants or increase the Shader Variant Limit in Preferences > Shader Graph. For more information about shader variants, refer to Making multiple shader program variants. For more information about the Shader Variant Limit, refer to Shader graph project settings Automatically Add and Remove Block Nodes Automatically add Block nodes to, or remove them from, the Master Stack as needed. If you select this option, any Block nodes that your Shader graph needs are added to the Master Stack automatically. Any incompatible Block nodes that have no incoming connections will be removed from the Master Stack. If you don't select this option, no Block nodes are added to, or removed from, the Master Stack automatically. Enable Deprecated Nodes Disable warnings for deprecated nodes and properties. If you select this option, Shader Graph doesn't display warnings if your graph contains deprecated nodes or properties. If you don't select this option, Shader Graph displays warnings for deprecated nodes and properties, and any new nodes and properties you create use the latest version. Zoom Step Size Control how much the camera in Shader Graph zooms each time you roll the mouse wheel. This makes it easier to control the difference in zoom speed between the touchpad and mouse. A touchpad simulates hundreds of steps, which causes very fast zooms, whereas a mouse wheel steps once with each click. Additional resources Making multiple shader program variants Master Stack Shader graph project settings"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Project-Settings.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Project-Settings.html",
    "title": "Shader Graph project settings reference | Inventory System",
    "summary": "Shader Graph project settings reference Use the Shader Graph project settings to define shader graph settings for your entire project. To access the Shader Graph project settings, do the following: From the main menu select Edit > Project Settings. The Project Settings window is displayed. Select ShaderGraph. Property Description Shader Variant Limit Set the maximum number of variants allowed in the project. If your graph exceeds this maximum value, Unity returns the following error: Validation: Graph is generating too many variants. Either delete Keywords, reduce Keyword variants or increase the Shader Variant Limit in Preferences > Shader Graph. For more information about shader variants, refer to Making multiple shader program variants. Custom Interpolator Channel Settings It's impossible to limit the number of channels users can create in a Shader Graph. Use Custom Interpolator Channel Settings to create alerts that let users know when they're close to, or have exceeded, the channel limit for the target platform. Unity uses these settings to help Shader Graph users maintain compatibility with target platforms when using custom interpolators. For more information, refer to Custom interpolators. Property Description Error Threshold Specify the number of channels at which users are notified that they're at, or have surpassed, the channel limit. This property has a minimum value of 8 channels and must be higher than Warning Threshold. Warning Threshold Specify the number of channels at which users are warned that they are close to the channel limit. This property must be lower than Error Threshold and between 8 and 32 channels. Heatmap Color Mode Settings You can create multiple customized heatmap values assets and swap them in and out based on the current needs of your project. Use Heatmap Color Mode Settings to specify which custom heatmap values asset to use for your project. Property Description Custom Values Specify which set of customized heatmap values to use for your project. Additional resources Custom interpolators Making multiple shader program variants"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Feature-Examples.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Feature-Examples.html",
    "title": "Feature Examples | Inventory System",
    "summary": "Feature Examples The Shader Graph Feature Examples sample content is a collection of Shader Graph assets that demonstrate how to achieve common techniques and effects in Shader Graph. The goal of this sample pack is to help users see what is required to achieve specific effects and provide examples to make it easier for users to learn. The sample content is broken into the following categories: Blending Masks - these samples generate masks based on characteristics of the surface - such as height, facing angle, or distance from the camera. Custom Interpolator - here we show how to use the Custom Interpolator feature in Shader Graph to move calculations from the fragment stage to the vertex stage to save performance. Detail Mapping - techniques for adding additional detail to a surface that isn’t contained in the base set of texture maps. Procedural Noise and Shapes - methods for creating shapes or patterns that use math instead of texture samples. Shader Graph Feature Examples - examples of using specific Shader Graph features - such as the Custom Code node or the Custom Interpolator UV Projection - methods of creating texture coordinates to achieve specific effects such as parallax occlusion mapping, or triplanar projection Vertex Animation - techniques for adjusting the position of the vertices to create effects such as waves, animated flags, or camera-facing billboards. Particles - shows how a full-featured particle system can be built using just Shader Graph Conditions - demonstrates branching based on graphics quality setting and based on the active render pipeline. Custom Lighting - shows how Shader Graph can be used to build custom lighting models - including PBR, simple, and cel shading. Blend Masks A major part of creating shaders is determining where specific effects should be applied. This is done by creating a mask and then using the mask to separate areas where the effect should be applied versus where it should not be applied. This set of samples provides examples of various methods of creating these masks. Altitude Mask The Altitude Mask is black below the minimum altitude, transitions from black to white between the minimum and maximum altitudes, and then stays white above the maximum altitude. You can use the AltitudeMask subgraph to create this effect. The Altitude Mask example shows how to use the Altitude Mask subgraph in the shader to blend between two materials. Below the minimum altitude, the cobblestones material is used. Between minimum and maximum, the materials blend from cobblestones to gold, and then above the maximum, the gold material is used. You can use the Falloff Type dropdown on the Altitude subgraph node to select the type of blend ramp to use. Linear will make the mask a direct line from minimum to maximum, while Smoothstep will create smooth transitions using a more S shaped curve. Angle Mask The Angle Mask uses the direction that a surface is facing to determine if the mask should be black or white. If the surface is pointing in the direction of the given input vector, the mask is white. If it’s pointing away from the given vector, the mask is black. The Angle Mask example uses the AngleMask subgraph to generate a mask, and then the mask is used to blend between the cobblestones material and a white, snow-like material. In this example, the AngleMask subgraph node’s MaskVector input is set to 0,1,0 - which is a vector pointing in the up direction (positive Y). When the object’s surface is pointing in that direction, the mask is white. When the surface is pointing away from that direction, the mask is black. The Max and Min input values on the AngleMask subgraph are used to control the falloff of the mask. Both values should use numbers between zero and one. When the Max and Min values are close together (0.5 and 0.48 for example), the falloff will be sharper. When they’re farther apart (0.8 and 0.3 for example), the falloff will be more gradual and blurry. When Max and Min are closer to a value of 1, the surface direction must match the MaskVector much more closely for the mask to be white. When Max and Min are closer to a value of zero, the mask will be white even with a larger difference between the surface direction and the MaskVector. Camera Distance Mask The Camera Distance Mask uses the distance from the camera location to the object’s surface to determine if the mask should be black or white. When the camera is close to the surface, the mask is black and when it’s further away, the mask is white. In this example, we apply the cobblestones material when the camera is close to the object and as the camera moves away we blend to the gold material. The Start Distance and Length values on the CameraDistanceMask subgraph control how the mask functions. The Start Distance value controls where the mask starts the transition from black to white. In this case, it’s set to 2 meters - which means that between 0 and 2 meters, the mask will be black. The Length value controls how long the transition is between black and white. In this case, it’s also set to 2 meters, so from a 2 meter distance to a 4 meter distance the mask will transition from black to white. Any distance beyond 4 meters will create a white mask. Height Mask The Height Mask uses the material height data of two materials to blend them together, creating a much more realistic looking intersection between them. Instead of fading between two materials, we can apply one material in the cracks and crevices of the other. In this example, we use U texture coordinate as a smooth gradient mask, and then modify the mask using the heights of the two materials. Instead of a smooth blend, we end up with the gold material being applied in the lower areas of the cobblestones first and then gradually rising until just the tops of the cobblestones show before being replaced completely by the gold. In order for this effect to work correctly, one or both of the materials need good height data. This type of a transition works best on materials with varying heights - like the cobblestones. Materials that are mostly flat won’t generate interesting effects with this technique. Custom Interpolator The Custom Interpolator feature in Shader Graph allows you to do any type of calculation in the Vertex Stage and then interpolate the results to be used in the Fragment Stage. Doing calculations in the Vertex Stage can give a major performance boost since math is only done once per vertex instead of for every pixel. However, per-vertex calculations can cause artifacts as illustrated in the Artifacts example. Be careful to only do math with low-frequency variations to avoid these artifacts. Interpolation Artifacts This example shows the types of artifacts that can occur when we do math in the vertex stage. In order to be smooth, lighting needs to be calculated at each pixel - but here we’re doing the calculations per-vertex instead and then interpolating the results to the pixels. The interpolation is linear, so we don’t get enough accuracy and the result looks angular and jagged instead of smooth - especially on the specular highlight. Interpolation Savings This example demonstrates a use case where custom interpolators can be highly beneficial. When creating shaders, it's common to tile and offset UVs multiple times. This behavior can become quite costly, especially when scrolling UVs on a fairly large object. For instance, consider a water shader where the water plane covers most of the terrain. Tiling the UVs in the fragment stage means performing the calculation for every pixel the water plane covers. One way to optimize this is to use custom interpolators to calculate the UVs in the vertex stage first and then pass the data to the fragment stage. Since there are fewer vertices than pixels on the screen, the computational cost will be lower. In this case, unlike the Custom Interpolator NdotL example, we do the samping after so that the rendering results are almost unnoticeable. When \"InFragStage\" is set to \"true\", the UVs calculated in the fragment stage are used. When \"InFragStage\" is set to \"false\", the UVs are scrolled in the vertex stage. In this case, scrolling UVs in either the vertex or fragment stages won't cause a noticeable difference in the rendering result. However, it's much more cost-friendly to perform the calculations in the vertex stage and pass the data using custom interpolators. Detail Mapping Detail Mapping refers to a set of techniques where additional detail is added to the surface of a model that is not contained in the model’s base set of textures. These techniques are used when the camera needs to get closer to a model than the resolution of the textures would typically allow, or when the object is so large that the resolution of the base textures is insufficient. In the three Detail Mapping examples, we’re using a texture packing format for our detail texture called NOS - which is short for Normal, Occlusion, Smoothness. This indicates that the Normal is stored in the red and green channels of the texture, the ambient occlusion is stored in the blue channel, and the smoothness is stored in the alpha channel. Packing the data together in this way allows us to get maximum use from our single detail texture - and we can add detail to the color, normal, smoothness, and AO with just a single texture sample. To simplify the process, we use the UnpackDetailNOS subgraph to sample the NOS detail texture and unpack the data. Detail Map Color For the Color Detail Map example, we simply multiply the Albedo output of the UnpackDetailNOS subgraph with the base color texture. The NOS texture format stores ambient occlusion data in the blue channel of the detail texture - and this occlusion data is what the UnpackDetailNOS subgraph passes to the Albedo output port. So for color detail, we’re just multiplying our base color by the detail AO. Notice that the effect is quite subtle. In the past, when detail mapping was a new technique, most surfaces used only color textures - so color detail mapping was the main technique used. Now that materials use normals, smoothness, occlusion, etc, it works much better to use detail mapping for all of the maps instead of just the color. Detail Map Normal For the Detail Map Normal example we combine the Normal output of the UnpackDetailNOS subgraph with the base normal map. Here we’re using the Normal Blend node to combine the two normals together and we have the Reoriented mode selected for best quality. Notice that the Detail Map Normal example is significantly more impactful than the Detail Map Color example. The detail normals are changing the perceived shape of the surface - which has a very strong effect on the lighting, whereas the Color Detail example is only changing the color - which is less effective. This indicates that if you can only apply detail to one of the textures in your material, the normal is the most effective one to add detail to. If you wanted to make this effect slightly cheaper to render, you could set the Normal Blend node to the Default mode instead (which uses the Whiteout normal blend technique instead). For another optimization, you could also set the Quality dropdown on the UnpackDetailNOS subgraph to Fast instead of Accurate. Both of these optimizations together would reduce the number of instructions required to render the effect. The results would be slightly less accurate, but this might not be noticeable. Try it out in your own shaders and see. If you can’t tell the difference, use the cheaper techniques for better performance! Detail Map Full The Detail Map Full example adds detail to the color, normal, ambient occlusion, and smoothness components of the material - so we’re adding additional detail to almost all of the material components. This is the most effective way to add detail to a surface, but also a little more expensive than the Color or Normal examples. Take special note of the way that we’re blending each of the outputs of the UnpackDetailNOS subgraph with their counterparts in the main material. For color, we’re using Multiply - so the detail color data darkens the base color. For Normal, we’re using the Normal Blend node. For Ambient Occlusion, we’re using the Minimum node, so the result is whichever result is darker. We’re using the Minimum node instead of Multiply to prevent the ambient occlusion from getting too dark. And finally, for the smoothness, we’re using Add. This is because the Smoothness data is in the -0.5 to 0.5 range and adding this range to the base smoothness acts like an overlay with darks darkening and brights brightening. Procedural Noise and Shapes In shaders, the term “procedural” refers to techniques that generate shapes and patterns using a series of math formulas - computed in real-time - instead of sampling texture maps. Procedural noise patterns and shapes have various advantages over texture maps including using no texture memory, covering infinite surface area without repetition or tiling, and being independent of texture resolution. Hex Grid A Hexagon grid is useful for all types of projects so we decided to include one in the examples. In the example the Grid output port of the HexGrid subgraph is simply connected to the Base Color of the Master Stack. The HexGrid subgraph also has an EdgeDistance output port and a TileID output port. The Edge Distance output provides a signed distance field value that represents the distance to the nearest hexagon edge. So the pixels right in the center of each hexagon are white and then the closer you get to hexagon edges, the darker the pixels become. The TileID output port provides a different random value for each tile. The HexGrid subgraph node also has some useful input ports. The UV input allows you to control the UV coordinates that are used to generate the pattern. The Scale input gives you control over the dimensions of the effect on both the X and Y axis. Finally, the Line Width input controls the thickness of the grid outlines. Line Width only applied to the Grid output and does not change the output of Edge Distance or TileID. Procedural Brick The Procedural Brick example shows how a brick pattern can be generated using pure math and no texture samples. If you’re developing on a platform that is fast at doing math but slow at texture samples, sometimes it can be much more performant to generate patterns like bricks procedurally rather than by sampling textures. Another advantage is that the variations in the brick patterns don’t repeat - so if you need a pattern to cover a large area without any repetition, procedural generation might be your best option. SDF Shapes Shader Graph comes with a set of nodes for creating shapes procedurally (Ellipse, Polygon, Rectangle, Rounded Rectangle, Rounded Polygon) but frequently developers find that a signed distance field of the shape is more useful than the shape itself. SDFs can be joined together in interesting ways and give developers more flexibility and control in generating results than just having the shape itself. This is why we’ve included these SDF shapes in the examples. Shader Graph Feature Examples The Shader Graph tool has several more advanced features - such as port defaults and Custom Interpolators - that can be tricky to set up. This section contains examples for those features to help users know what is required to set up and use these more advanced features. Subgraph Dropdown When creating a subgraph node, it’s possible to add a dropdown control to allow users to make a selection. This is useful when there are several different methods of achieving a similar result and you want to allow the user of the subgraph to select which method to use. This example illustrates how to add a dropdown box to your subgraph. After creating your subgraph asset, open it in the editor and open the Blackboard panel. Click the plus icon at the top and select Dropdown at the bottom of the list of parameter types. Now give your dropdown a name. Once the dropdown parameter is named, select it and open the Graph Inspector. Here you can control the number and names of the options in the dropdown list. Use the plus and minus icons at the bottom of the list to add and remove items. And click on individual items in the list to change their names. Once you have the number of items you want in the list, go back to the Blackboard and drag and drop your Blackboard parameter into the graph. It will appear as a node with input ports to match the list items you created in the Graph Inspector. For each of the input ports, create a graph that generates the results that you want for that option. The dropdown node acts as a switch to switch between the inputs depending on what is selected with the dropdown. When the subgraph is added to a graph, the user will be able to select an option from the dropdown and the graph will use the branch of the graph that has been selected. Since the branch is static, only the selected branch will be included in the shader at runtime so no additional shader variants will be generated and no performance penalty will be incurred. Subgraph Port Defaults You can use the Branch on Input Connection node to set up defaults for the input ports of your subgraphs and even create large graph trees to use if nothing is connected to a specific input port. The Subgraph Port Defaults example shows how to do that. After creating your subgraph asset, open it in the editor and open the Blackboard panel. Click the plus icon at the top and select a data type. In our example, we selected a Vector 2 type because we’re making an input port for UV coordinates. Once you’ve selected a type, give your parameter a name. We named ours UV. Before adding the parameter to your graph, select it and open the Graph Inspector. In the Graph Inspector, check the “Use Custom Binding” checkbox and give the parameter a Label. This is the name that will show up as connected to the port when no external wires are connected. Now, drag and drop your parameter from the Blackboard into the graph. Next, hit the spacebar and add a Branch on Input Connection node. The node can be found in the Searcher under Utilities->Logic. This node will allow you to set up a default input value or graph branch to use when nothing is connected to the input port. Connect your input parameter’s output port to the Input and Connected input ports of the Branch on Input Connection node. This will allow the input port to function correctly when a wire is connected to it. Now you can connect a node or node tree to the NotConnected input port. Whatever is connected here will be what gets used when nothing is connected to this subgraph’s input port. In our example, we’ve connected the UV node and used the Swizzle node so only the X and Y coordinates are used. So with this setup, UV0 will be used if nothing is connected to the input port. UV Projection UV coordinates are used to translate the 3d surface area of models into 2d space that can be used to apply texture maps. This section contains a set of examples for creating, manipulating, and applying UV coordinates to achieve many different types of effects. Flipbook A flipbook is an effect where a series of frames is played back in sequence. The frames are arranged in a grid pattern on a texture map. Shader Graph has a built-in node that generates the UVs required to jump from one frame to the next on the texture. In this example, we show how to use Shader Graph’s built-in Flipbook node to create an animated effect. We also show that you can use a pair of Flipbook nodes to set up an effect that blends smoothly from one frame to the next instead of jumping. Notice that in the Blackboard, we’ve exposed a Texture parameter for selecting a flipbook texture, Rows and Columns parameters to describe the layout of the flipbook texture, a Speed parameter to control the playback rate of the frames, and a Flip Mode dropdown. With the Flip Mode dropdown, you can select to Flip from one frame to the next, or to Blend between frames. Notice that if you select the Blend option, the playback appears much more smooth even though the frame rate remains the same. Using this Blend mode is a good way to improve the appearance of the effect and make it feel less choppy, even if the frame rate is low. Flow Mapping Flow Mapping is a technique that creates the illusion of flowing movement in a texture. It’s achieved by warping the texture coordinates along a specific flow direction over time in two separate phases. When the warping of the first phase becomes too severe, we blend to the second phase which is not yet warped and then warp that while removing the warping from the first phase while it is not displayed. We can blend back and forth between the two phases over and over to create the illusion of motion. In the example, we’re using the UVFlowMap subgraph which does the main work of the effect. We give it a Flow Map - which is the direction to push the movement. In our case we’ve used a texture (similar to a normal map) to specify the direction. Then we give it a Strength value - which controls the distance that the UVs get warped. Flow Time can be as simple as just the Time node, but you can also connect a Flow Map Time subgraph which varies the time in different areas to break up the strobing effect. The UV input controls how the texture is applied. Notice that we’re using a Tiling And Offset node here to tile the texture 8 times. And finally the Offset value controls the midpoint of the stretching effect. The default value of 0.5 means that each of the phases starts out half stretched in the negative direction, moves to unstretched, and then moves to half stretched in the positive direction. This will give the best results in most cases. In our example, we have exposed a Temporal Mode dropdown which illustrates the usefulness of the Flow Map Time subgraph. When Temporal Mode is set to Time Only, we’re only using Time as the Flow Time input. There is a noticeable strobing effect where the entire model appears to be pulsing in rhythm. This is because the blending between phase 1 and phase 2 is happening uniformly across the whole surface. When we set Temporal Mode to Flow Map Time, we’re using the Flow Map Time subgraph as the Flow Time input. The Flow Map Time subgraph breaks up the phase blending into smooth gradients across the surface so that it’s non-uniform and removes the strobing effect. Interior Cube Mapping Interior Cube Mapping is a technique that creates the illusion of building interiors as seen through windows where no interior mesh exists. The effect can be used to make very simple exterior building meshes appear to have complex interiors and is much cheaper than actually modeling interiors. In our example, the UVInteriorCubemap subgraph generates the direction vector that we need for sampling our cube map. The cube map creates the illusion of the interiors. And then the rest of the graph creates the exterior building and windows. The UVInteriorCubemap subgraph has inputs for specifying the number of windows and controlling whether or not to randomize the walls of the cube map. The randomization rotates the walls of the cube map so that each interior has different walls on the sides and back. There is also a dropdown for controlling whether the projection is happening in object space or in UV space. Lat Long Projection The Lat Long Projection example demonstrates the math required to use a texture map in the Latitude Longitude format. Many high dynamic range environment images are stored in this format so it’s useful to know how to use this type of image. You can tell an image is in LatLong format because it has a 2 to 1 aspect ratio and usually has the horizon running through the middle. In our example, we’re using the UVLatLong subgraph. This node generates the UV coordinates needed to sample a texture map in the LatLong format. By default, the UVLatLong subgraph uses a reflection vector as input - so the result acts like a reflection on the surface of your model. But if you wanted the result to be stuck to the surface instead, you could use the Normal Vector. If you select the Sample Texture 2D node and open the Graph Inspector, notice that the Mip Sampling Mode is set to Gradient. With that setting, the Sample Texture 2D node has DDX and DDY input ports - which we have connected to the DDX and DDY nodes. We’re doing this because the texture coordinates generated for the LatLong projection have a hard seam where the left and right sides of the projection wrap around and come together. If we were to set the Mip Sampling Mode to Standard instead, we would end up with a hard seam where the texture sampler failed because there is a large discontinuity in the mip values of the texture coordinates. The Gradient Mip Sampling Mode allows us to manually calculate our own mip level with the DDX and DDY nodes instead of allowing the sampler to do it. Mat Cap (Sphere Mapping) The Mat Cap Material example demonstrates the math required to project a sphere map onto a surface. This effect is often called a Mat Cap - or material capture, because you can represent the properties of a material - like reflections or subsurface scattering - in the way the texture is created. Some 3d sculpting software uses MatCap projection to render objects. You can tell that a texture is a sphere map (or MatCap) because it looks a bit like a picture of a chrome ball. Sphere maps are the cheapest form of reflection - both in texture memory and in the low cost of math. But they’re not accurate because they always face the camera. In our example, we’re using the UVSphereMap subgraph to generate the texture coordinates to sample the sphere map. The subgraph has an input for the surface normal - and you can use the dropdown to select the space that the normal is in. By default, the Vertex Normal is used, but you could also connect a normal map to it if you wanted to give the surface more detail. Parallax Mapping There are many techniques that attempt to add more detail to the shape of a surface than is actually represented in the geometry of the surface. The Parallax Mapping example demonstrates three of these examples, and you can select which example to display with the Bump Type dropdown box in the material. Normal Only This technique is the cheapest and most common. It uses a normal map to change the apparent shape of the surface - where each pixel in the map represents the direction that the surface is facing at that point. Because there is no offsetting of the surface happening, this technique also looks fairly flat compared to the other two. Parallax Parallax Mapping samples a height map and then uses the value to offset the UV coordinates based on their height relative to the view direction. This causes parallax motion to occur on the surface and makes the surface feel like it has actual depth. However, when seen at steep angles, the effect often has artifacts. Where there are steep changes in the height map, there are visible stretching artifacts. Parallax Occlusion Parallax Occlusion Mapping samples a height map multiple times (based on the number of Steps) in a path along the view vector and reconstructs the scene depth of the surface. It uses this depth information to derive UV coordinates for sampling the textures. This process is expensive - especially with a high number of Steps, but can be made cheaper by creating a mask to reduce the number of Steps based on the camera distance and angle of the surface. Our example illustrates this technique. Triplanar Projection Triplanar projection projects a texture onto the surface of a model from the front, side, and top. It’s useful when you want to apply a texture but the model doesn’t have good UV coordinates, or when the UVs are laid out for something else. It’s also useful when you want to project the same texture or material on many objects in close proximity and have the projection be continuous across them. There are several methods for projecting a texture onto a surface. Our example shows four of them and you can select the method you want to see using the Projection Type dropdown in the material. They’re in order from most expensive to least. Triplanar Texture projection The Triplanar Textures technique uses the built-in Triplanar node in Shader Graph. This node samples each of your textures three times - for the top, front, and side projections and then blends between the three samples. This technique is the nicest looking since it blends between the samples, but it’s also the most expensive. Biplanar Texture projection This is a clever optimization to triplanar projection that uses two texture samples instead of three. The shader figures out which two faces are most important to the projection and only samples those two instead of all three. On most platforms, it will be cheaper than Triplanar Textures, but more expensive than Triplanar UVs. Depending on the textures you’re sampling, you may notice a small singularity artifact at the corner where the three faces come together. Triplanar UV projection The Triplanar UVs technique uses the UVTriplanar subgraph to project the UV coordinates from the top front and side and then use those to sample the textures only one time instead of three. Because it’s only sampling each texture one time, this technique is cheaper. The UV coordinates can’t be blended like the textures can - so this technique has hard seams where projections come together instead of blending like the Triplanar Textures technique. However, these seams aren’t very noticeable on some materials, so this may be an acceptable alternative if you need to do triplanar projection more cheaply. Notice that the normal map needs to be plugged into the UVTriplanarNormalTransform node when using this technique in order to get the normals transformed correctly. UV This option just applies the textures using standard UV coordinates. It’s here so that you can easily compare it with the other two techniques. Vertex Animation Generally, we think of shaders as changing the color and appearance of pixels. But shaders can also be applied to vertices - to change the position of the points of a mesh. The model’s vertices can be manipulated by a shader to create all sorts of animated effects - as shown in this section. Animated Flag This example shows a simple method for making a flag that ripples in the wind. The effect centers around the Sine node - which is what creates the rippling motion. We take the X position of the vertices and multiply them by a value that controls the length of the waves. We multiply that by Time and then pass that into the Sine node. Finally, we multiply the result of the Sine wave with a mask that goes from 0 at the point where the flag attaches to the pole, 1 at the tip of the flat where the effect should be strongest. The result is a simple rippling flag. You could add additional detail to this effect if you combined several different sine waves that move at different speeds and wavelengths to vary and randomize the results. But something as simple as this example may be all that is needed if your flag is seen at a distance. Bend Deformer - Grass This example shows the math required to bend a rectangle-shaped strip in an arc shape without changing its length. This can be used for animating blades of grass. The BendDeformer subgraph adjusts both the position and the normal of the vertices - so we get proper lighting on the updated shape. Billboard The billboard example illustrates the math that we use to make a flat plane face the camera. Notice that the Billboard subgraph has a dropdown that allows us to select the initial direction that our plane is facing. Selecting the correct option here will ensure that our plane turns toward the camera correctly and not some other direction. Gerstner Wave In this example, we use several instances of the GerstnerWave subgraph to animate waves in our mesh. The GerstnerWave subgraph does the math required to realistically simulate the movement of a single wave. Notice that each of the three instances has a different direction, wave length, and wave height. Combining these three different wave sizes together creates a really nice-looking wave simulation. The Offset values are added together and then added to the Position. The normals are combined using the Normal Blend node and then used directly as the Normal. Particles This example shows that it’s possible to create a simple particle system using nothing but Shader Graph! This method of creating particles is cheap because it’s done 100% on the GPU and almost all of the shader work happens in the vertex shader. This shader is not intended as a replacement for any of the other particle systems in Unity, but simply as an illustration of what’s possible to do with just Shader Graph alone. It could potentially be cheaper to make simple particle effects using this shader than with other methods. It’s definitely not as powerful or as full-featured as something made with VFX Graph, for example. We start by creating a stack of planes where each plane in the stack has a slightly different vertex color. We use this value as an ID to differentiate each plane in the stack. This sample set comes with 3 stacks of planes that can be used. One with 25 planes, one with 50 planes, and one with 100 planes. Note that most particle systems dynamically generate particles based on the number that the system needs, but we’re using static geometry, so we’re locked in to using the number of planes in the geometry we choose. If the system we create with the material parameters requires more particles, the only way to fix it is to swap out the mesh that we’re using - so this is one major downside to this method. We use the Billboard subgraph to make all of the planes face the camera and we use the Flipbook node to add an animated effect to the particles. We also add gravity and wind to control the movement of the particles. In the pixel shader, we expose control over the opacity and even fade out particle edges where they intersect with other scene geometry. Here’s a description of the exposed material parameters that control the appearance and behavior of the particles: Emitter Dimensions - controls the size of the particle emitter in X,Y, and Z. Particles will be born in random locations within the volume specified by these dimensions. Color This is a color value that gets multiplied by the FlipbookTexture color. The StartColor blends to the EndColor throughout the lifetime of the particle. The alpha value of the color gets multiplied by the alpha value of the FlipbookTexture to contribute to the opacity of the particles. Start Color - the color multiplier for the particle at the beginning of its life EndColor - the color multiplier for the particle at the end of its life Opacity These controls change the opacity/transparency behavior of the particles. Opacity - the overall opacity multiplier. Values above one are acceptable and can make subtle particles more visible. FadeInPower - controls the falloff curve of the particle fade-in. FadeOutPower - controls the falloff curve of the particle fade-out. SoftEdges - enables the soft edges feature which fades out the particles where they intersect with scene geometry. AlphaClipThreshold - controls the opacity cut-off below which pixels are discarded and not drawn. The higher this value is, the more pixels can be discarded to reduce particle overdraw. Scale Controls the size of the particles. Particles transition from the ParticleStartSize to the ParticleEndSize over their lifetime. ParticleStartSize - the size of the particle (in meters) when it is born. ParticleEndSize - the size of the particle (in meters) when it dies. Movement These controls affect the movement of the particles. ConstantFlow - the smoothness of the flow of the particles. A value of 1 distributes particle flow evenly over time. A value of 0 spawns all of the particles and once right at the beginning of the phase. Values in between make particle birthrate/flow more random and hitchy. ParticleSpeed - controls the overall speed of the particles ParticleDirection - the main direction of particle movement ParticleSpread - the width of the particle emission cone in degrees. A value of 0 will emit particles in single direction and a value of 360 will emit particles in all directions (a sphere) ParticleVelocityStart - controls how fast the particles are moving when they’re first born. ParticleVelocityEnd - controls how fast the particles are moving when they die. Rotation Controls the rotation behavior of the particles. Rotation - the static amount of rotation to apply to each particle in degrees. RotationRandomOffset - when checked, applies a random rotation amount to each particle RotationSpeed - the speed of rotation of each particle RandomizeRotationDirection - when true, each particle randomly either goes clockwise or counterclockwise. Flipbook Controls the behavior of the animated texture that is applied to the particles. FlipbookTexture - the flipbook texture to apply to the particles FlipbookDimensions - the number of rows and columns in the selected flipbook texture FlipbookSpeed - the playback frame rate of the flipbook. MatchParticlePhase - when true, the first frame of the flipbook will play when the particle is born and the last frame will play just before the particle dies - so the flipbook playback length will match the particle’s lifetime. Forces Control the external forces that affect the particle movement. Gravity - the pull of gravity on the particles. This is typically 0,-9.8, 0 - but some types of material, such as smoke or mist may be warm or lighter than air, which would cause them to move upward instead of getting pulled down by gravity. Wind - the direction and strength of the wind. Debug These controls allow you to debug specific parts of the particle system. DebugTime - When true, allows you to scrub time backwards and forward manually with the ManualTime slider. ManualTime - when DebugTime is true, you can use this slider to scrub time backwards and forward to see how the particles behave at different points during their lifetime. Conditions This section illustrates two ways to branch your shader. Branch On Render Pipeline Shader Graph allows you to create shaders that can be used in multiple render pipelines- Built-In, URP, and HDRP. This can be done by opening the shader in Shader Graph and adding the targets for all of the pipelines you want the shader to support in the Active Targets section under Graph Settings in the Graph Inspector window. When supporting multiple render pipelines, it’s occasionally necessary to do different things in the graph depending on which pipeline is being used. In order to do that, you need to branch the shader based on the active render pipeline. There isn’t an official node in Shader Graph for performing that branching operation, but it is possible to create a subgraph that contains a Custom Function node that does the branch. In this example, we use that Branch On RP to create a different outcome depending which render pipeline is active. In our simple example, we just make the cube a different color - green for URP, blue for HDRP, and yellow for the Built-In render pipeline - but you can do much more complex operations that are specific to each render pipeline using this same technique. Branch On Material Quality With Shader Graph, you can create one shader that has multiple different ways of achieving the same effect depending on how much GPU processing power you want to dedicate to it. This example illustrates that. We show three different methods of combining two normal maps together. The first method (at the top of the graph) is using the Normal Blend node set to Reoriented mode. This is the most accurate method that provides the best looking results, but it also requires the most compute power. The second method (in the middle of the graph) is almost as nice and a little bit cheaper. The third method (at the bottom of the graph) is the cheapest and produces the lowest quality result. On the right side of the graph, you can see that the three different methods are connected to the Material Quality node. You can add a Material Quality node by opening the Blackboard and selecting Keyword->Material Quality from the add menu. Then drag the Material Quality parameter from the Blackboard into your graph. This node will select the top, middle, or bottom part of the graph depending on the Quality level that is selected. In HDRP, the Quality setting is defined by the Default Material Quality Level setting found in the Material section of the HD Render Pipeline Asset. So for each Quality level, you define a pipeline asset, and that asset has the setting that controls which quality level the shader uses. In a URP project, you can use the SetGlobalShaderKeywords command in the script that gets run when the user selects options in the application’s UI. For example, the following command will set Material Quality to High: MaterialQualityUtilities.SetGlobalShaderKeywords( MaterialQuality.High ); Using the Material Quality node in Shader Graph enables you to provide the user with the ability to customize their experience in the application. They can choose to see higher quality visuals at a lower frame rate, or lower-quality visuals at a higher frame rate. And you control what these options do in the shader itself."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Decal.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Decal.html",
    "title": "Decals | Inventory System",
    "summary": "Decals Decals allow you to apply local material modifications to specific places in the world. You might think of things like applying graffiti tags to a wall or scattering fallen leaves below a tree. But decals can be used for a lot more. In these examples, we see decals making things look wet, making surfaces appear to have flowing water across them, projecting water caustics, and blending specific materials onto other objects. Decals are available to use in both HDRP and URP, but they need to be enabled in both render pipelines. To use decals, refer to the documentation in both HDRP and URP. Material Projection This decal uses triplanar projection to project a material in 3D space. It projects materials correctly onto any mesh that intersects the decal volume. It can be used to apply terrain materials on to other objects like rocks so that they blend in better with the terrain. Water Caustics When light shines through rippling water, the water warps and focuses the light, casting really interesting rippling patterns on surfaces under the water. This shader creates these rippling caustic patterns. If you place decals using this shader under your water planes, you’ll get projected caustics that imitate the behavior of light shining through the water. Running Water This decal creates the appearance of flowing water across whatever surfaces are inside the decal. It can be used on the banks of streams and around waterfalls to support the appearance of water flowing. With material parameters, you can control the speed of the water flow, the opacity of both the wetness and the water, and the strength of the flowing water normals. Water Wetness The wetness decal makes surfaces look wet by darkening color and increasing smoothness. It uses very simple math and no texture samples so it is very performance efficient. It can be used along the banks of bodies of water to better integrate the water with the environment."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Detail.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Detail.html",
    "title": "Production Ready Shaders | Inventory System",
    "summary": "Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment. The sample content is broken into the following categories: Lit shaders - Introduces Shader Graph versions of the HDRP and URP Lit shaders. Users often want to modify the Lit shaders but struggle because they’re written in code. Now you can use these instead of starting from scratch. Decal shaders - Introduces shaders that allow you to enhance and add variety to your environment. Examples include running water, wetness, water caustics, and material projection. Detail shaders - Introduces shaders that demonstrate how to create efficient terrain details that render fast and use less texture memory. Examples include clover, ferns, grass, nettle, and pebbles Rock - A robust, modular rock shader that includes base textures, macro and micro detail, moss projection, and weather effects. Water - Water shaders for ponds, flowing streams, lakes, and waterfalls. These include depth fog, surface ripples, flow mapping, refraction and surface foam. Post-Process - Shaders to add post-processing effects to the scene, including edge detection, half tone, rain on the lens, an underwater look, and VHS video tape image degradation. Weather - Weather effects including rain drops, rain drips, procedural puddles, puddle ripples, and snow Miscellaneous - A couple of additional shaders - volumetric ice, and level blockout shader. Lit Shaders Both URP and HDRP come with code-based shaders. The most commonly used shader for each of the SRPs is called Lit. For projects that use it, it’s often applied to just about every mesh in the game. Both the HDRP and URP versions of the Lit shader are very full-featured. However, sometimes users want to add additional features to get just the look they’re trying to achieve, or remove unused features to optimize performance. For users who aren’t familiar with shader code, this can be very difficult. For that reason, we’ve included Shader Graph versions of the Lit shader for both URP and HDRP in this sample pack. Users will be able to make a copy of the appropriate Shader Graph Lit shader, and then change any material that’s currently referencing the code version of the Lit shader with the Shader Graph version. All of the material settings will correctly be applied and continue to work. They’ll then be able to make changes to the Shader Graph version as needed. Please note that most but not all of the features of the code-based shaders are duplicated in the Shader Graph versions. Some lesser-used features may be missing from the Shader Graph versions due to the differences in creating shader with Shader Graph vs creating them with code. Also note - If you’re going to use the Lit shader as is, we recommend sticking with the code version. Only swap out the shader for the Shader Graph version if you’re making changes. We also recommend removing unused features from the Shader Graph version for better performance. For example, if you’re not using Emissive or Detail Maps, you can remove those parts of the shader (both graph nodes and Blackboard parameters) for faster build times and better performance. The real power of Shader Graph is its flexibility and how easy it is to change, update, and improve shaders. URP Lit Just like the code version, this shader offers the Metallic workflow or the Specular workflow. Shaders can be either opaque or transparent, and there are options for Alpha Clipping, Cast Shadows, and Receive Shadows. For the main surface, users can apply a base map, metallic or specular map, normal map, height map, occlusion map, and emission map. Parameters are available to control the strength of the smoothness, height, normal, and occlusion and control the tiling and offset of the textures. Users can also add base and normal detail maps and mask off where they appear using the mask map. For more details on each of the parameters in the shader, see the Lit Shader documentation for URP. Shader Variant Limit In order to be able to use this shader, you’ll need to increase the Shader Variant Limit to at least 513. This should be done on both the Shader Graph tab in Project Settings as well as the Shader Graph tab in the Preferences. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: UnityEditor.Rendering.Universal.ShaderGUI.LitShader This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. HDRP Lit Just like the code version, this shader offers opaque and transparent options. It supports Pixel displacement (Parallax Occlusion mapping) and all of the parameters that go with it. (It does not support Material Types other than standard.) For the main surface, users can apply a base map, mask map, normal map, bent normal map, and height map. Options are also available to use a detail map and emissive map. For more details on each of the parameters in the shader, see the Lit Shader documentation for HDRP. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: Rendering.HighDefinition.LitGUI This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. Decals Decals allow you to apply local material modifications to specific places in the world. You might think of things like applying graffiti tags to a wall or scattering fallen leaves below a tree. But decals can be used for a lot more. In these examples, we see decals making things look wet, making surfaces appear to have flowing water across them, projecting water caustics, and blending specific materials onto other objects. Decals are available to use in both HDRP and URP, but they need to be enabled in both render pipelines. To use decals, see the documentation in both HDRP and URP. Material Projection This decal uses triplanar projection to project a material in 3D space. It projects materials correctly onto any mesh that intersects the decal volume. It can be used to apply terrain materials on to other objects like rocks so that they blend in better with the terrain. Water Caustics When light shines through rippling water, the water warps and focuses the light, casting really interesting rippling patterns on surfaces under the water. This shader creates these rippling caustic patterns. If you place decals using this shader under your water planes, you’ll get projected caustics that imitate the behavior of light shining through the water. Running Water This decal creates the appearance of flowing water across whatever surfaces are inside the decal. It can be used on the banks of streams and around waterfalls to support the appearance of water flowing. With material parameters, you can control the speed of the water flow, the opacity of both the wetness and the water, and the strength of the flowing water normals. Water Wetness The wetness decal makes surfaces look wet by darkening color and increasing smoothness. It uses very simple math and no texture samples so it is very performance efficient. It can be used along the banks of bodies of water to better integrate the water with the environment. Details In this context, Details refer to meshes that are added to terrain - such as grass, weeds, undergrowth, pebbles, etc. To learn more, read the terrain documentation on details. Detail meshes have some specific requirements for shaders. First, because of the high number of these meshes used on the terrain, we have to make their shaders as fast and efficient as possible. That mainly means keeping the number of texture samples low and doing more work in the vertex shader instead of the pixel shader. And second, because these meshes stop rendering and pop out at a specific distance, we have to use a method to dissolve them out to prevent the harsh pop and make it less obvious that they’re being removed. In each of the shaders, you’ll see the Distance Mask or Distance Cutoff node used to create a mask that dissolves away the mesh at a distance before the mesh stops rendering. Clover The shader for the clover uses just one single channel texture to reduce cost and save texture memory. Color is generated by lerping between a bright color and a dark color using the greyscale value from the texture. Each instance of clover uses a slightly different color variation. We generate a random value based on the position of each instance and that's used to give each instance a color variation. The Distance Mask is calculated in the vertex shader to save performance and then passed to the pixel shader where it’s combined with the texture and some screen space noise. Together, these elements are passed into the Fade Transition node which makes the mesh dissolve between the Clip Offset and Clip Distance values. Ferns The fern shader uses a color, normal, and mask texture to define the fern material. It animates the ferns based on wind settings. It also creates a subsurface scattering effect so that the fern fronds are illuminated on the reverse side from the sunlight. For ambient occlusion, we darken the AO close to the ground. As with the other detail shaders, we also dissolve the fern as we move away to prevent it from popping out. Grass Usually, grass is created with billboards using a grass texture. This shader is different. We use mesh for each individual blade of grass. To keep the meshes as cheap as possible, our grass blade meshes have only 12 vertices and 10 triangles. They don’t have UV coordinates, normals, or vertex colors - so the only data stored in the mesh is position. The meshes are as simple as they can possibly be. We also do as much work as possible in the vertex shader for lower cost. Wind, color, translucency, and distance fade are all calculated in the vertex shader. The shader generates wind forces and then uses them to bend the blades of grass. The wind forces vary in direction and gust strength so the movement of the blades feels natural. Nettle The nettle shader is for simple, broad-leaf undergrowth. It’s a variation of the fern shader - so it has similar features. The main difference is that it has been adapted to only use one texture sample to reduce both texture memory usage and shader cost. The texture has the normal X and Y in the red and green channels. The blue channel is a combination of the opacity and a grayscale mask that is used to modulate smoothness, AO, and color. Pebbles As with the rest of the detail shaders, the pebble shader is designed to be as cheap as possible. It only uses one small noise texture. It creates color variation using the noise texture and the instance IDs so that each pebble cluster has its own unique color. And it fades the pebbles out at a distance to prevent popping. Rock This is a full-featured, modular rock shader that can be used for everything from small pebbles to boulders up to large cliff faces. It has features that can be turned on and off in the material depending on the application. Each of the features is encapsulated in a subgraph so it’s easy to remove features that you don’t need. You can also add new features in the chain of modules if you need something else. Each module takes in color and smoothness in one input port and normal and ambient occlusion in a second input. Inside the subgraph, it alters these, and then it outputs the result again in the same format - color and smoothness in the first output port, and normal and AO in the second. Using this input/output port format keeps all of the modules organized and in a nice, neat line. To help with performance, the shader has an LOD0 boolean parameter exposed to the material. For materials applied to LOD0 of your rocks, this should be true. For materials applied to the other LODs, this boolean should be false. This feature turns off extra features that are only visible when the rock is close so that non-LOD0 versions of your rocks render faster. Additionally, this shader branches using the Material Quality built-in enum keyword. This means that the shader is already set up to create a low quality, medium quality, and high quality version of itself depending on project settings. Features will be turned on and off, or different variations of features will be used depending on the project’s Material Quality setting. Base Textures In order to reduce the total number of texture samples in the shader (sampling textures is the most expensive operation that shaders do, so reducing the number of texture samples can significantly improve shader performance), we’ve used a two-texture format for our base textures instead of 3. The format is as follows: CS Texture (BC7 format) - RGB - color, Alpha - smoothness NO Texture (BC7 format) - RGB - normal, Alpha - ambient occlusion Note that the NO texture is NOT saved as a normal map. If you set it to be a normal map, the ambient occlusion data in the alpha channel will be lost. Macro Detail The purpose of the Macro Detail module is to add large-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. For rocks that are large, a single texture set is often not high enough resolution and the base textures look blurry or blocky, even from a distance. The Macro Detail module solves this problem. For rocks that are smaller than 1 meter cubed, this feature should be turned off by unchecking Rock Features/MarcoDetail in the rock’s material. This feature references a texture - Rock_Macro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single macro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Color Projection For large boulders and cliff faces, you may want to add colored effects to the rocks such as bleaching. The Color Projection module can handle this. It projects color alterations using world space. The nice thing about this effect is that if your rock formation is made up of multiple rocks all jammed together, the color projection will tie them together and make them feel more cohesive - as if they’re one unified formation rather than just a collection of jammed-together rocks. This effect does use 5 texture samples, so if you don’t need it, or if you’re on a very performance sensitive platform such as a mobile device, you should definitely turn it off in the material to improve performance. Micro Detail The purpose of the Micro Detail module is to add small-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. When you get really close to the rocks, sometimes the resolution of the base textures is not high enough and they look blurry or blocky. The Micro Detail module solves this problem by adding very high resolution micro detail to the rock surface. This feature references a texture - Rock_Micro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single micro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Deposition Moss The Deposition Moss module applies moss to the tops of the rocks. To define the moss, it uses a Moss_CO texture (color with occlusion in the alpha channel) and a Moss_N texture (normal). The alpha channel of the Moss_CO texture is also used to create smoothness. It’s also possible to use this module to apply other types of materials to the tops of the rocks - such as sand, ash, snow, etc. To do that, you’d just need to set the Deposition Moss module to use textures for your chosen material instead. These textures are not exposed to the material, but they are available to be changed on the module. Rain When the IsRaining parameter is set to 1, the Rain module applies rain effects to the rocks, including animated rain drops on the tops of the rocks, and drips running down the sides of the rocks. The module also makes the rocks look wet. Water The sample set comes with four different water shaders. Each one uses reflection, refraction, surface ripples using scrolling normal maps, and depth fog. Each also uses a few additional features that are unique to that type of water. WaterLake This is the simplest water shader of the group. Because it’s meant to be applied to larger bodies of water, it has two different sets of scrolling normals for the surface ripples - one large, one small - to break up the repetition of the ripples. It also fades the ripples out at a distance both to hide the tiling patterns and to give the lake a mirror finish at a distance. WaterSimple_FoamMask This shader is intended to be used on ponds or other small bodies of non-flowing water. It uses 3 Gerstner waves subgraphs to animated the vertices in a chaotic wave pattern. It also adds foam around the edges of the water where it intersects with other objects. The unique thing about the foam implementation in this shader is that it allows you to additionally paint a texture mask that determines where foam can be placed manually. This manual placed foam could be used for a spot where a waterfall is hitting the water - for example. WaterStream The water stream shader is intended to be used on small, flowing bodies of water. Instead of standard scrolling normal maps for ripples, it uses flow mapping to make the water flow slowly along the edges of the stream and faster in the middle. It also uses the same animated foam technique as the WaterSimple shader - but without the mask. This shader uses the puddle_norm texture. Notice that we save a little bit of shader performance by NOT storing this texture as a normal map. After the two samples are combined, then we expand the data to the -1 to 1 range, so we don’t have to do it twice. WaterStreamFalls This is the same shader as the WaterStream, but it’s intended to be used on a waterfall mesh. It fades out at the start and the end of the mesh so that it can be blended in with the stream meshes at the top and bottom of the falls, and it adds foam where the falls are vertical. Post-Process The post process shaders can be used to apply modifications to the rendered image once the scene has been drawn. Edge Detection The edge detection shader checks the four neighboring pixels to the current one to find “edges” or places where the normal or depth has changed rapidly. It creates a mask where edges exist and then uses the mask to blend between the original scene color and the edge color. Half Tone The halftone shader turns the rendered image into a halftone image - simulating the pattern of larger and smaller circle patterns that you might see in newsprint or comic books. First it generates a procedural grid of signed distance field circles - one for each of red, green, and blue. Then it uses inverse lerp to convert the SDF circle grid into dots - where the size of the dot represents the brightness of the color at that location. Finally it combines the red, green, and blue dot grids into one color. Rain On Lens The rain-on-the-lens post process shader applies refraction to the rendered scene as if there were rain on the camera lens - so some areas of the image are warped by rain drops and other areas are distorted by drips running down the screen. Underwater The underwater post process shader makes the scene look like it’s under water by applying several effects including blurring the screen around the edges, distorting the image is large, ripple patterns, and applying a blue/green fog based on the scene depth. VHS The VHS post process shader mimics the appearance of the scene being played back on an old VHS video cassette recorder. Artifacts include scan line jitter, read head drift, chromatic aberration, and color degradation in the YIQ color space. Weather This sample comes with a full set of weather-related subgraphs (rain and snow) that can be mixed and matched depending on the requirements of the object type they’re applied to. Rain There are several subgraphs that generate rain effects. Each has a different subset of the available rain effects. Applying all of the effects at once is a bit expensive on performance, so it’s best to choose the option with just the effects you need for the specific type of object/surface. Rain The Rain subgraph combines all of the rain effect - drops, drips, puddles, wetness - to create a really nice rain weather effect - but it’s the most expensive on performance. Puddles are a bit expensive to generate as are drips, so this version should only be used on objects that will have both flat horizontal surfaces as well as vertical surfaces. Rain Floor The Rain Floor subgraph creates puddle and drop effects, but it does not have the drip effects that would run down vertical surfaces. This subgraph is best used for flat, horizontal surfaces. Rain Props The Rain Props subgraph has the drop and drip effects but does not include the puddles. It’s best for small prop objects. Rain Rocks The Rain Rocks subgraph has been specifically tuned for use on rocks. It includes drips and drops, but not puddles. It also includes the LOD0 parameter that is meant to turn off close-up features on LODs other than the first one. Components Puddles The puddles subgraph creates procedurally-generated puddles on flat, up-facing surfaces. It outputs a mask that controls where the puddles appear and normals from the puddles. It uses the PuddleWindRipples and RainRipples subgraph to generate both wind and rain ripples in the puddles. PuddleWindRipples The PuddleWindRipples subgraph creates puddle wind ripples by scrolling two normal map textures. It’s used by the Puddles subgraph. Rain_Drips This subgraph creates drips that drip down the sides of an object. The drips are projected in world space, so they work well for static objects but are not meant for moving objects. The speed of the drips is controlled by the permeability of the material. Smooth, impermeable surfaces have fast moving drips while permeable surfaces have slow-moving drips. Rain_DripsOnTheLens This subgraph is very similar to the Rain_Drips subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. Rain_Drops This subgraph applies animated rain drops to objects. The drops are projected in world space from the top down. Because of the world space projection, these rain drops are not designed to be added to objects that move in the scene but instead should be used for static objects. The IsRaining input port turns the effect on and off (when the input value is 1 and 0). Rain_Parameters A common set of rain parameters used by most of the rain subgraphs. Setting parameters once in this subgraph means you don’t have to set them all over in multiple places. RainDropsOnTheLens This subgraph is very similar to the RainDrops subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. RainRipple Creates an animated circular ripple pattern. This subgraph is used multiple times in the RainRipples subgraph to create a really nice-looking pattern of multiple overlapping ripples. RainRipples The RainRipples subgraph creates ripples from rain drops in a puddle or pool of water. It combines four instances of the RainRipple subgraph (each with its own scale, position, and timing offset) to create the chaotic appearance of multiple ripples all happening at once. It’s used by the Puddles subgraph to add rain ripples to the puddles. Wet This subgraph makes surfaces look wet by darkening and saturating their base color and by increasing their smoothness. The effect is different depending on how permeable the surface is. Snow The Snow subgraph creates a snow effect and applies it to the tops of objects. The snow material includes color, smoothness, normal, metallic, and emissive - where the emissive is used to apply sparkles to the snow. Miscellaneous shaders Blockout Grid Apply this simple shader to a 1 meter cube. You can then scale and stretch the cube to block out your level. The grid projected on the cube doesn't stretch but maintains its world-space projection so it's easy to see distances and heights. It's a great way to block out traversable paths, obstacles, and level layouts. Turn on the EnableSlopeWarning parameter to shade meshes red where they’re too steep to traverse. Ice This ice shader uses up to three layers of parallax mapping to create the illusion that the cracks and bubbles are embedded in the volume of the ice below the surface though there is no transparency or actual volume. It also uses a Fresnel effect to brighten the edges and create a frosted look. Forest Stream Construction Tutorial This tutorial shows you, step by step, how to use the assets included in this sample to construct a forest stream environment. Step 1 - Sculpt Terrain We start by blocking out the main shapes of the terrain. We use the Set Height brush to create a sloping terrain by creating a series of terraces and then using the Smooth brush to smooth out the hard edges between the terraces. Then we cut in our stream channel with the Set Height brush in several different tiers heading down the slope. After cutting in the stream, we smooth out the hard edges using the Smooth brush. We finalize the terrain shape by adding polish using the Raise/Lower Height brush and the Smooth brush to add touch-ups and variety. In this process, we start out with large brushes and end up using small ones. Once this step is done, we do revisit the terrain shape occasionally to add additional touch ups, especially after adding in the water meshes in steps 3 and 4, to ensure that the water meshes and terrain shape work together. Step 2 - Paint Terrain Materials Next, it’s time to add materials to our terrain. We have four material layers - cobblestone rocks for our stream bed, dry dirt, rocky moss, and mossy grass. To apply the materials, we begin by establishing guidelines. The stones material goes in the stream bed. The dirt material goes along the banks of the stream. As a transition between the first and the grass, we use the rocky moss material. And finally, we use the grass material for the background. We first block in the materials according to our guidelines with large, hard-edged brushes. Then we go back and blend the materials together using smaller brushes. We paint one material over the other using brushes with a low opacity value to blend the two materials together. Even though our terrain materials exhibit tiling artifacts by themselves, we’re able to hide the tiling by giving each material a different tiling frequency. When the materials are blended, they break up each others tiling artifacts. We also cover the terrain with detail meshes (step 7) which further hides the tiling. Step 3 - Add Water Planes The stream itself is constructed from simple planes that are added to the scene by right clicking in the Hierarchy panel and selecting 3D Object->Plane. Then we apply the WaterStream material. The planes are placed in the stream channel that’s cut into the terrain, and then scaled along the Z axis to stretch them along the length of the stream. Water flows in the local -Z direction of the planes. Planes are scaled as long as they need to be in order to reach from one stream height drop to the next. Notice that the edges of the stream mesh are transparent at the start and at the end. This is to allow the stream meshes to blend together correctly with the waterfall meshes that link the stream planes together. Step 4 - Add Waterfall Meshes The waterfall meshes are designed to connect one level of stream plane to the next lower level. They are placed at the end of a stream plane and slope down to connect to the next stream plane. We rotate the waterfall meshes around the Y axis to align the waterfall mesh between the two stream planes. The pivot point of the waterfall is lined up vertically with the top portion of the waterfall, so you can place the waterfall mesh at the exact same height as the top stream plane, and then scale the waterfall mesh so that the bottom portion of the waterfall mesh aligns with the lower stream plane. Notice that the Sorting Priority parameter in the Advanced Options of the material has been set to -1. This makes the waterfall meshes draw behind the stream meshes so there isn’t a draw order conflict. Step 5 - Add Rocks Streams are often filled with rocks that have been pushed by the current. To save memory and reduce draw calls, we’re just using two different rock meshes that both use the same texture set. The rocks are rotated and scaled to give a variety of appearances. Notice that we’ve created visual variety by creating two different sizes of rocks - large boulders, and smaller rocks. Overall, the rocks break up the shape of the stream and change the pattern of the foam on the water surface. Step 6 - Add Water Decals We use the Water Wetness and Water Caustics decal to more tightly integrate the stream water with the terrain and rocks. The Wetness decal makes the terrain and other meshes around the stream look like they’re wet, and the Caustics decal imitates the appearance of lighting getting refracted by the surface of the water and getting focused in animated patterns on the bottom of the stream. For the Wetness decal, it should be created and scaled so that the top of the decal extends around half a meter above the surface of the water. The top of the Caustics decal should be just under the water. For both decals, the decal volumes should be kept as small as possible in all three dimensions - just large enough to cover their intended use and no larger. You can also save some performance by lowering the Draw Distance parameter on each decal so they are not drawn at a distance. Step 7 - Add Reflection Probes Reflections are a critical component of realistic-looking water. To improve the appearance of the water reflections, we create a Reflection Probe for each of the stream segments and place it at about head height and in the middle of the stream. If were are objects like rocks and trees nearby, they will be captured in the Reflection Probes and then reflected more accurately in the water. Especially notice how water to the right of this point is correctly reflecting the high bank behind the signs while water to the left is only reflecting the sky. This additional realism is contributed by the Reflection Probes. Step 8 - Add Terrain Detail Meshes Our last step is to add detail meshes to the terrain. We have pebble meshes that are added everywhere, including under the water. We have broad-leaf nettle plants that are added around the edges of the water in the dirt areas. We have ferns (3 variations) that are added just above the nettle in the transition between dirt and grass, and we have clover that is added in between the ferns and the grass. For the grass, we have three different meshes that each fade out at a different distance from the camera to soften the fade-out so that it doesn’t happen all at once. The most dense grass is only visible at 10 meters from the camera to improve performance. The three different grass layers are painted somewhat randomly with all three layers being applied where the terrain grass material is most dense and the most sparse grass being painted around the edges. Each grass mesh also has slightly different wind direction and intensity values in the material to give variety to the grass appearance. Only one of the three grass meshes has shadows turned on - which gives the impression of grass shadows without paying the full performance cost. To save on performance, our terrain is set to fade out the detail meshes at 30 meters. This allows us to achieve a nice density of meshes up close and then get rid of them further away where they’re not as visible. We hide the transition by dither fading the meshes in the shader before the 30 meter point so there’s not popping. Additional Ideas We have a pretty nice looking environment here, but there’s a lot more that could be done. You could complete this environment by adding your own trees, stumps and fallen logs."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Lit.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Lit.html",
    "title": "Lit Shaders | Inventory System",
    "summary": "Lit Shaders Both URP and HDRP come with code-based shaders. The most commonly used shader for each of the SRPs is called Lit. For projects that use it, it’s often applied to just about every mesh in the game. Both the HDRP and URP versions of the Lit shader are very full-featured. However, sometimes users want to add additional features to get just the look they’re trying to achieve, or remove unused features to optimize performance. For users who aren’t familiar with shader code, this can be very difficult. For that reason, we’ve included Shader Graph versions of the Lit shader for both URP and HDRP in this sample pack. Users will be able to make a copy of the appropriate Shader Graph Lit shader, and then change any material that’s currently referencing the code version of the Lit shader with the Shader Graph version. All of the material settings will correctly be applied and continue to work. They’ll then be able to make changes to the Shader Graph version as needed. Please note that most but not all of the features of the code-based shaders are duplicated in the Shader Graph versions. Some lesser-used features may be missing from the Shader Graph versions due to the differences in creating shader with Shader Graph vs creating them with code. Also note - If you’re going to use the Lit shader as is, we recommend sticking with the code version. Only swap out the shader for the Shader Graph version if you’re making changes. We also recommend removing unused features from the Shader Graph version for better performance. For example, if you’re not using Emissive or Detail Maps, you can remove those parts of the shader (both graph nodes and Blackboard parameters) for faster build times and better performance. The real power of Shader Graph is its flexibility and how easy it is to change, update, and improve shaders. URP Lit Just like the code version, this shader offers the Metallic workflow or the Specular workflow. Shaders can be either opaque or transparent, and there are options for Alpha Clipping, Cast Shadows, and Receive Shadows. For the main surface, users can apply a base map, metallic or specular map, normal map, height map, occlusion map, and emission map. Parameters are available to control the strength of the smoothness, height, normal, and occlusion and control the tiling and offset of the textures. Users can also add base and normal detail maps and mask off where they appear using the mask map. For more details on each of the parameters in the shader, refer to the Lit Shader documentation for URP. Shader Variant Limit In order to be able to use this shader, you’ll need to increase the Shader Variant Limit to at least 513. This should be done on both the Shader Graph tab in Project Settings as well as the Shader Graph tab in the Preferences. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: UnityEditor.Rendering.Universal.ShaderGUI.LitShader This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. HDRP Lit Just like the code version, this shader offers opaque and transparent options. It supports Pixel displacement (Parallax Occlusion mapping) and all of the parameters that go with it. (It does not support Material Types other than standard.) For the main surface, users can apply a base map, mask map, normal map, bent normal map, and height map. Options are also available to use a detail map and emissive map. For more details on each of the parameters in the shader, refer to the Lit Shader documentation for HDRP. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: Rendering.HighDefinition.LitGUI This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Misc.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Misc.html",
    "title": "Miscellaneous shaders | Inventory System",
    "summary": "Miscellaneous shaders Blockout Grid Apply this simple shader to a 1 meter cube. You can then scale and stretch the cube to block out your level. The grid projected on the cube doesn't stretch but maintains its world-space projection so it's easy to see distances and heights. It's a great way to block out traversable paths, obstacles, and level layouts. Turn on the EnableSlopeWarning parameter to shade meshes red where they’re too steep to traverse. Ice This ice shader uses up to three layers of parallax mapping to create the illusion that the cracks and bubbles are embedded in the volume of the ice below the surface though there is no transparency or actual volume. It also uses a Fresnel effect to brighten the edges and create a frosted look."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Post.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Post.html",
    "title": "Post-Process | Inventory System",
    "summary": "Post-Process The post process shaders can be used to apply modifications to the rendered image once the scene has been drawn. Edge Detection The edge detection shader checks the four neighboring pixels to the current one to find “edges” or places where the normal or depth has changed rapidly. It creates a mask where edges exist and then uses the mask to blend between the original scene color and the edge color. Half Tone The halftone shader turns the rendered image into a halftone image - simulating the pattern of larger and smaller circle patterns that you might see in newsprint or comic books. First it generates a procedural grid of signed distance field circles - one for each of red, green, and blue. Then it uses inverse lerp to convert the SDF circle grid into dots - where the size of the dot represents the brightness of the color at that location. Finally it combines the red, green, and blue dot grids into one color. Rain On Lens The rain-on-the-lens post process shader applies refraction to the rendered scene as if there were rain on the camera lens - so some areas of the image are warped by rain drops and other areas are distorted by drips running down the screen. Underwater The underwater post process shader makes the scene look like it’s under water by applying several effects including blurring the screen around the edges, distorting the image is large, ripple patterns, and applying a blue/green fog based on the scene depth. VHS The VHS post process shader mimics the appearance of the scene being played back on an old VHS video cassette recorder. Artifacts include scan line jitter, read head drift, chromatic aberration, and color degradation in the YIQ color space."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Rock.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Rock.html",
    "title": "Rock | Inventory System",
    "summary": "Rock This is a full-featured, modular rock shader that can be used for everything from small pebbles to boulders up to large cliff faces. It has features that can be turned on and off in the material depending on the application. Each of the features is encapsulated in a subgraph so it’s easy to remove features that you don’t need. You can also add new features in the chain of modules if you need something else. Each module takes in color and smoothness in one input port and normal and ambient occlusion in a second input. Inside the subgraph, it alters these, and then it outputs the result again in the same format - color and smoothness in the first output port, and normal and AO in the second. Using this input/output port format keeps all of the modules organized and in a nice, neat line. To help with performance, the shader has an LOD0 boolean parameter exposed to the material. For materials applied to LOD0 of your rocks, this should be true. For materials applied to the other LODs, this boolean should be false. This feature turns off extra features that are only visible when the rock is close so that non-LOD0 versions of your rocks render faster. Additionally, this shader branches using the Material Quality built-in enum keyword. This means that the shader is already set up to create a low quality, medium quality, and high quality version of itself depending on project settings. Features will be turned on and off, or different variations of features will be used depending on the project’s Material Quality setting. Base Textures In order to reduce the total number of texture samples in the shader (sampling textures is the most expensive operation that shaders do, so reducing the number of texture samples can significantly improve shader performance), we’ve used a two-texture format for our base textures instead of 3. The format is as follows: CS Texture (BC7 format) - RGB - color, Alpha - smoothness NO Texture (BC7 format) - RGB - normal, Alpha - ambient occlusion [!NOTE] <The NO texture is NOT saved as a normal map. If you set it to be a normal map, the ambient occlusion data in the alpha channel will be lost.> Macro Detail The purpose of the Macro Detail module is to add large-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. For rocks that are large, a single texture set is often not high enough resolution and the base textures look blurry or blocky, even from a distance. The Macro Detail module solves this problem. For rocks that are smaller than 1 meter cubed, this feature should be turned off by unchecking Rock Features/MarcoDetail in the rock’s material. This feature references a texture - Rock_Macro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single macro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Color Projection For large boulders and cliff faces, you may want to add colored effects to the rocks such as bleaching. The Color Projection module can handle this. It projects color alterations using world space. The nice thing about this effect is that if your rock formation is made up of multiple rocks all jammed together, the color projection will tie them together and make them feel more cohesive - as if they’re one unified formation rather than just a collection of jammed-together rocks. This effect does use 5 texture samples, so if you don’t need it, or if you’re on a very performance sensitive platform such as a mobile device, you should definitely turn it off in the material to improve performance. Micro Detail The purpose of the Micro Detail module is to add small-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. When you get really close to the rocks, sometimes the resolution of the base textures is not high enough and they look blurry or blocky. The Micro Detail module solves this problem by adding very high resolution micro detail to the rock surface. This feature references a texture - Rock_Micro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single micro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Deposition Moss The Deposition Moss module applies moss to the tops of the rocks. To define the moss, it uses a Moss_CO texture (color with occlusion in the alpha channel) and a Moss_N texture (normal). The alpha channel of the Moss_CO texture is also used to create smoothness. It’s also possible to use this module to apply other types of materials to the tops of the rocks - such as sand, ash, snow, etc. To do that, you’d just need to set the Deposition Moss module to use textures for your chosen material instead. These textures are not exposed to the material, but they are available to be changed on the module. Rain When the IsRaining parameter is set to 1, the Rain module applies rain effects to the rocks, including animated rain drops on the tops of the rocks, and drips running down the sides of the rocks. The module also makes the rocks look wet."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Tutorial.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Tutorial.html",
    "title": "Forest Stream Construction Tutorial | Inventory System",
    "summary": "Forest Stream Construction Tutorial This tutorial shows you, step by step, how to use the assets included in this sample to construct a forest stream environment. Sculpt Terrain Paint Terrain Materials Add Water Planes Add Waterfall Meshes Add Rocks Add Water Decals Add Reflection Probes Add Terrain Detail Meshes Additional Ideas Step 1 - Sculpt Terrain Start by blocking out the main shapes of the terrain. Use the Set Height brush to create a sloping terrain by creating a series of terraces and then use the Smooth brush to smooth out the hard edges between the terraces. Cut in the stream channel with the Set Height brush in several different tiers heading down the slope. After you cut in the stream, smooth out the hard edges with the Smooth brush. Add polish to finalize the terrain shape. Use the Raise/Lower Height brush and the Smooth brush to add touch-ups and variety. In this process, start out with large brushes and end with the small ones. When this step is done, you can revisit the terrain shape occasionally to add additional touch ups, especially after adding in the water meshes in steps 3 and 4, to ensure that the water meshes and terrain shape work together. Step 2 - Paint Terrain Materials Next, it’s time to add materials to our terrain. We have four material layers - cobblestone rocks for our stream bed, dry dirt, rocky moss, and mossy grass. To apply the materials, we begin by establishing guidelines. The stones material goes in the stream bed. The dirt material goes along the banks of the stream. As a transition between the first and the grass, we use the rocky moss material. And finally, we use the grass material for the background. First block in the materials according to the guidelines with large, hard-edged brushes. Then we go back and blend the materials together using smaller brushes. Paint one material over the other using brushes with a low opacity value to blend the two materials together. Even though our terrain materials exhibit tiling artifacts by themselves, we’re able to hide the tiling by giving each material a different tiling frequency. When the materials are blended, they break up each others tiling artifacts. We also cover the terrain with detail meshes (step 7) which further hides the tiling. Step 3 - Add Water Planes The stream itself is constructed from simple planes that are added to the scene. Right-click in the Hierarchy panel and select 3D Object>Plane. Then apply the WaterStream material. Place the planes in the stream channel that’s cut into the terrain. Scale the planes along the Z axis to stretch them along the length of the stream. Water flows in the local -Z direction of the planes. Planes are scaled as long as they need to be in order to reach from one stream height drop to the next. Notice that the edges of the stream mesh are transparent at the start and at the end. This is to allow the stream meshes to blend together correctly with the waterfall meshes that link the stream planes together. Step 4 - Add Waterfall Meshes The waterfall meshes are designed to connect one level of stream plane to the next lower level. Place the waterfall meshes at the end of a stream plane. They slope down to connect to the next stream plane. Rotate the waterfall meshes around the Y axis to align the waterfall mesh between the two stream planes. Scale the waterfall mesh on the Y axis so that the bottom portion of the waterfall mesh aligns with the lower stream plane. The pivot point of the waterfall is lined up vertically with the top portion of the waterfall, so you can place the waterfall mesh at the exact same height as the top stream plane, and then scale to meet the lower stream plane. Notice that the Sorting Priority parameter in the Advanced Options of the material has been set to -1. This makes the waterfall meshes draw behind the stream meshes so there isn’t a draw order conflict. Step 5 - Add Rocks Streams are often filled with rocks that have been pushed by the current. To save memory and reduce draw calls, we’re just using two different rock meshes that both use the same texture set. Place rocks at random intervals along the length of the stream. Rotate and scale the rocks to give a variety of appearances. Notice that we’ve created visual variety by creating two different sizes of rocks - large boulders, and smaller rocks. Overall, the rocks break up the shape of the stream and change the pattern of the foam on the water surface. Step 6 - Add Water Decals We use the Water Wetness and Water Caustics decal to more tightly integrate the stream water with the terrain and rocks. The Wetness decal makes the terrain and other meshes around the stream look like they’re wet, and the Caustics decal imitates the appearance of lighting getting refracted by the surface of the water and getting focused in animated patterns on the bottom of the stream. Create and scale the Wetness decals so that the top of the decal extends around half a meter above the surface of the water. The top of the Caustics decal should be just under the water. Create and scale the caustics decals so that the caustic patterns are only projected under the water planes. For both decals, the decal volumes should be kept as small as possible in all three dimensions - just large enough to cover their intended use and no larger. You can also save some performance by lowering the Draw Distance parameter on each decal so they are not drawn at a distance. Step 7 - Add Reflection Probes Reflections are a critical component of realistic-looking water. To improve the appearance of the water reflections, create a Reflection Probe for each of the stream segments and place it at about head height and in the middle of the stream. If there are objects like rocks and trees nearby, they will be captured in the Reflection Probes and then reflected more accurately in the water. Especially notice how water to the right of this point correctly reflects the high bank behind the signs while water to the left only reflects the sky. The Reflection Probes contribute this additional realism. Step 8 - Add Terrain Detail Meshes Our last step is to add detail meshes to the terrain. Add pebble meshes everywhere, including under the water. Add broad-leaf nettle plants around the edges of the water in the dirt areas. Add ferns (3 variations) just above the nettle in the transition between dirt and grass. Add clover in between the ferns and the grass. For the grass, add the three different meshes. Each of them fade out at a different distance from the camera to soften the fade-out so that it doesn’t happen all at once. The most dense grass is only visible at 10 meters from the camera to improve performance. Paint the three different grass layers somewhat randomly with all three layers being applied where the terrain grass material is most dense and the most sparse grass being painted around the edges. Each grass mesh also has slightly different wind direction and intensity values in the material to give variety to the grass appearance. Only one of the three grass meshes has shadows turned on - which gives the impression of grass shadows without paying the full performance cost. To save on performance, our terrain is set to fade out the detail meshes at 30 meters. This allows us to achieve a nice density of meshes up close and then get rid of them further away where they’re not as visible. We hide the transition by dither fading the meshes in the shader before the 30 meter point so there’s no popping. Additional Ideas We have a pretty nice looking environment here, but there’s a lot more that could be done. You could complete this environment by adding your own trees, stumps and fallen logs."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Water.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Water.html",
    "title": "Water | Inventory System",
    "summary": "Water The sample set comes with four different water shaders. Each one uses reflection, refraction, surface ripples using scrolling normal maps, and depth fog. Each also uses a few additional features that are unique to that type of water. WaterLake This is the simplest water shader of the group. Because it’s meant to be applied to larger bodies of water, it has two different sets of scrolling normals for the surface ripples - one large, one small - to break up the repetition of the ripples. It also fades the ripples out at a distance both to hide the tiling patterns and to give the lake a mirror finish at a distance. WaterSimple_FoamMask This shader is intended to be used on ponds or other small bodies of non-flowing water. It uses 3 Gerstner waves subgraphs to animated the vertices in a chaotic wave pattern. It also adds foam around the edges of the water where it intersects with other objects. The unique thing about the foam implementation in this shader is that it allows you to additionally paint a texture mask that determines where foam can be placed manually. This manual placed foam could be used for a spot where a waterfall is hitting the water - for example. WaterStream The water stream shader is intended to be used on small, flowing bodies of water. Instead of standard scrolling normal maps for ripples, it uses flow mapping to make the water flow slowly along the edges of the stream and faster in the middle. It also uses the same animated foam technique as the WaterSimple shader - but without the mask. This shader uses the puddle_norm texture. Notice that we save a little bit of shader performance by NOT storing this texture as a normal map. After the two samples are combined, then we expand the data to the -1 to 1 range, so we don’t have to do it twice. WaterStreamFalls This is the same shader as the WaterStream, but it’s intended to be used on a waterfall mesh. It fades out at the start and the end of the mesh so that it can be blended in with the stream meshes at the top and bottom of the falls, and it adds foam where the falls are vertical."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Weather.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready-Weather.html",
    "title": "Weather | Inventory System",
    "summary": "Weather This sample comes with a full set of weather-related subgraphs (rain and snow) that can be mixed and matched depending on the requirements of the object type they’re applied to. Rain There are several subgraphs that generate rain effects. Each has a different subset of the available rain effects. Applying all of the effects at once is a bit expensive on performance, so it’s best to choose the option with just the effects you need for the specific type of object/surface. Rain The Rain subgraph combines all of the rain effect - drops, drips, puddles, wetness - to create a really nice rain weather effect - but it’s the most expensive on performance. Puddles are a bit expensive to generate as are drips, so this version should only be used on objects that will have both flat horizontal surfaces as well as vertical surfaces. Rain Floor The Rain Floor subgraph creates puddle and drop effects, but it does not have the drip effects that would run down vertical surfaces. This subgraph is best used for flat, horizontal surfaces. Rain Props The Rain Props subgraph has the drop and drip effects but does not include the puddles. It’s best for small prop objects. Rain Rocks The Rain Rocks subgraph has been specifically tuned for use on rocks. It includes drips and drops, but not puddles. It also includes the LOD0 parameter that is meant to turn off close-up features on LODs other than the first one. Components Puddles The puddles subgraph creates procedurally-generated puddles on flat, up-facing surfaces. It outputs a mask that controls where the puddles appear and normals from the puddles. It uses the PuddleWindRipples and RainRipples subgraph to generate both wind and rain ripples in the puddles. PuddleWindRipples The PuddleWindRipples subgraph creates puddle wind ripples by scrolling two normal map textures. It’s used by the Puddles subgraph. Rain_Drips This subgraph creates drips that drip down the sides of an object. The drips are projected in world space, so they work well for static objects but are not meant for moving objects. The speed of the drips is controlled by the permeability of the material. Smooth, impermeable surfaces have fast moving drips while permeable surfaces have slow-moving drips. Rain_DripsOnTheLens This subgraph is very similar to the Rain_Drips subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. Rain_Drops This subgraph applies animated rain drops to objects. The drops are projected in world space from the top down. Because of the world space projection, these rain drops are not designed to be added to objects that move in the scene but instead should be used for static objects. The IsRaining input port turns the effect on and off (when the input value is 1 and 0). Rain_Parameters A common set of rain parameters used by most of the rain subgraphs. Setting parameters once in this subgraph means you don’t have to set them all over in multiple places. RainDropsOnTheLens This subgraph is very similar to the RainDrops subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. RainRipple Creates an animated circular ripple pattern. This subgraph is used multiple times in the RainRipples subgraph to create a really nice-looking pattern of multiple overlapping ripples. RainRipples The RainRipples subgraph creates ripples from rain drops in a puddle or pool of water. It combines four instances of the RainRipple subgraph (each with its own scale, position, and timing offset) to create the chaotic appearance of multiple ripples all happening at once. It’s used by the Puddles subgraph to add rain ripples to the puddles. Wet This subgraph makes surfaces look wet by darkening and saturating their base color and by increasing their smoothness. The effect is different depending on how permeable the surface is. Snow The Snow subgraph creates a snow effect and applies it to the tops of objects. The snow material includes color, smoothness, normal, metallic, and emissive - where the emissive is used to apply sparkles to the snow."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-Production-Ready.html",
    "title": "Production Ready Shaders | Inventory System",
    "summary": "Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment. The sample content is broken into the following categories: Topic Description Lit shaders Introduces Shader Graph versions of the HDRP and URP Lit shaders. Users often want to modify the Lit shaders but struggle because they’re written in code. Now you can use these instead of starting from scratch. Decal shaders Introduces shaders that allow you to enhance and add variety to your environment. Examples include running water, wetness, water caustics, and material projection. Detail shaders Introduces shaders that demonstrate how to create efficient terrain details that render fast and use less texture memory. Examples include clover, ferns, grass, nettle, and pebbles. Rock A robust, modular rock shader that includes base textures, macro and micro detail, moss projection, and weather effects. Water Water shaders for ponds, flowing streams, lakes, and waterfalls. These include depth fog, surface ripples, flow mapping, refraction and surface foam. Post-Process Shaders to add post-processing effects to the scene, including edge detection, half tone, rain on the lens, an underwater look, and VHS video tape image degradation. Weather Weather effects including rain drops, rain drips, procedural puddles, puddle ripples, and snow. Miscellaneous A couple of additional shaders - volumetric ice, and level blockout shader. Forest Stream Construction Tutorial A tutorial that describes how to combine multiple assets from this sample to create a forest stream."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Custom-UI-components.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Custom-UI-components.html",
    "title": "Custom UI components | Inventory System",
    "summary": "Custom UI components The sample contains a few custom UI components to reproduce the behavior of some elements such as buttons, toggles and sliders, passing data to the material assigned. You can add these components from the main menu Component > UI > Shader Graph Samples. Component Description RectTransform Size Passes the gameObject's RectTransform's size to the graphic's material, as a _RectTransformSize Vector2 property. This is then fetched in a Shader Graph or Subgraph by using the RectTransform Size custom node (see below). Button Reproduces the behavior of a UI Button component. The button state is fetched in a Shader Graph or Subgraph by using the Selectable State custom node (see below). Toggle Reproduces the behavior of a UI Toggle component. The toggle 'on' state is fetched in a Shader Graph or Subgraph by using the Toggle State custom node (see below). Its state as a selectable is fetched in a Shader Graph or Subgraph by using the Selectable State custom node (see below). Meter A passive meter to be used as a progress indicator or gauge. It passes a normalized value to the Graphics material as a float \"_MeterValue\" property. Use the MeterValue node to fetch the value in a Shader Graph or Subgraph. RangeBar A passive range bar to be used as a progress bar, or in combination with a Range Slider. Slider A custom slider, handling drag events. Its value is fetched in a Shader Graph or Subgraph by using the Slider Value custom node (see below). Its state as a selectable is fetched in a Shader Graph or Subgraph by using the Selectable State custom node (see below)."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Custom-nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Custom-nodes.html",
    "title": "Custom nodes | Inventory System",
    "summary": "Custom nodes The sample contains a few custom shader graph nodes to facilitate the setup. The custom nodes are broken into two categories: Inline Properties - These nodes automatically add a hidden property to the shader graph and fetch its value. Branch - These nodes enable branching on the value of specific inputs such as a Button state. Inline Property Nodes These nodes automatically add a hidden property to the shader graph and fetch its value. You can also just manually add the property to the shader graph, but these custom nodes let you nest them in subgraphs. Node Description RectTransform Size Adds a _RectTransformSize Vector2 hidden property to the graph and outputs its value. This is fed by the RectTransformSize component required by some subgraphs to perform aspect ratio based math. Selectable State Adds a _State float hidden property to the graph and outputs its value. This is fed by the Selectable components (CustomButton, CustomToggle and Slider). The value represents the mutually exclusive state such as: 0 - Normal, 1 - Highlighted, 2 - Pressed, 3 - Selected, 4 - Disabled Toggle State Adds a _isOn Boolean hidden property to the graph and outputs its value. This is fed by the CustomToggle component. Meter Value Adds a _MeterValue float hidden property to the graph and outputs its value. This is fed by the Meter component and allows creating progress, health or other indicators. Slider Value Adds a _SliderValue Vector3 hidden property to the graph and outputs its value as: Value - The normalized Slider Value as float. Direction - The normalized Slider Direction as Vector2. This is fed by the Slider component and allows creating sliders of which the direction and value can be set from the component. Range Bar Adds a _RangeBar Vector4 hidden property to the graph and outputs its value as: Min - The normalized Slider Min Value as float. Max - The normalized Slider Max Value as float. Direction - The normalized Slider Direction as Vector2. This is fed by the RangeBar component and allows creating range bars of which the direction and min/max values can be set from the component. Branch Nodes These nodes let you branch on the value of specific inputs such as a Button state. The motivation behind making them custom nodes rather than subgraphs lies in the ability to feature dynamic ports. SelectableBranch This node lets you branch depending on the state of a Selectable element such as a CustomButton."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Examples.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Examples.html",
    "title": "Examples | Inventory System",
    "summary": "Examples These example shaders are built using the subgraph nodes. They show how the subgraph nodes work and how you can combine them to create backgrounds, buttons, and meters. Backgrounds The background examples are shaders that you can assign to Canvas Image objects that serve as backgrounds for other UI elements. 80sSunset This example combines the LinearTime, Perspective, Move, SquareTiles, Bars, and AntiAliasing nodes to generate a perspective grid that scrolls into the distance. Library Subgraph Nodes used in this example: Perspective LinearTime Move SquareTiles LinearGradient Bars AntiAliasing Gradients Animated Clouds This example combines animated procedural noise to create interesting dynamic patterns. Blurred Hexagon This example uses the SceneColorBlurred node to create a blurred version of the scene behind the user interface. It also uses the HexagonTiles node to generate a hexagon grid pattern. You can use the HexagonDisolve parameter to shrink and grow the size of the hexagons, which makes the pattern appear to dissolve. Library Subgraph Nodes used in this example: SceneColorBlurred HexagonTiles Halftone This example uses the Halftone node to convert the rendered scene behind the UI elements into a halftone pattern. It converts each of the three channels (red, green, and blue) into a halftone dot pattern, then recombines them to create the final image. Library Subgraph Nodes used in this example: Halftone LavaLamp This is an illustration of how distorted circle shapes can be animated to move around in random directions, and how signed distance field shapes can be blended together using the Smooth output of the SDFUnite node to merge the shapes. Library Subgraph Nodes used in this example: SineTime Move Circle SDFUnite Pixelation This example shows how to use the PosterizeUV node to quantize the UV coordinates used to sample the scene. The result is a version of the scene that appears to be made of larger pixels. Library Subgraph Nodes used in this sample: PosterizeUV RoundedRectangleBubble This example shows how to create a rounded frame as a background, including an outline and a drop shadow, for other UI elements. To maintain the correct aspect ratio of the rounded corners in this shader, connect the exposed WidthHeight parameter of this shader to the UI Image element’s Width and Height parameters. You can do this with the ImageSize script. Refer to How to make shapes that adapt to the aspect ratio of the UI element for details on how to accomplish this. Library Subgraph Nodes used in this sample: Scale LinearGradient Move Rectangle TechGrid This example uses the SquareTiles node to generate a grid pattern and the AnimatedClouds node to create a smooth noise. These effects together create a nice tech grid for a background. Library Subgraph Nodes used in this sample: AnimatedClouds SquareTiles WarpedGradient This example shows how to warp UV coordinates with procedural noise and then use those warped coordinates to generate a deformed and blurry circle. It also darkens the corners of the screen using the Vignette node. Library Subgraph Nodes used in this sample: Move Circle Vignette Buttons These examples show how to create buttons of various visual styles. Each button has exposed parameters that control the button’s visual states - selected, pressed, and active. In the example scene, you can take a look at how these material parameters are connected to the button’s state events to drive the appearance of the button. Many shape elements of the buttons use the AntiAliasing node which converts SDFs and gradients to perfectly anti-aliased shapes, regardless of scale or camera position. For more details on how to accomplish this, refer to How to create a resolution-independent shape. AquaButton This example shows how to create an aqua-style button and includes a specular highlight, gradient shading, a fresnel outline, and a colored drop shadow. It adjusts to the aspect ratio of the button object it’s assigned to using the WidthHeight parameter. In the sample scene, notice that this material parameter is connected to the UI object’s width and height values using the ImageSize script. Library Subgraph Nodes used in this sample: Move AspectRatio AnimatedSheen Pill SciFiButton This example uses multiple circular elements and illustrates how multiple elements can be combined with subtract, maximum, lerp, and multiply. Library Subgraph Nodes used in this sample: Circle CircleSegments AntiAliasing Scale PlayerIcon SciFiButton2 This button example is similar to the Tech Grid background. It uses the SquareTiles node to create a grid and the AnimatedClouds node to create a smooth noise background. It also illustrates the use of the Tilt node to turn the rectangle shape into a parallelogram. Library Subgraph Nodes used in this sample: AspectRatio LinearTime CircleSegments Rectangle AntiAliasing AnimatedSheen SquareTiles SimpleButton This is an example of how you can create a simple button with a smooth gradient color, a drop shadow, and Selected, Pressed, and Active states. Library Subgraph Nodes used in this sample: Move Scale LinearGradient Rectangle AntiAliasing Indicators These UI elements indicate things to the player visually such as health level, ammo count, shield power, etc. All of them have an exposed material parameter called “Health” that drives the level of the meter. Using a script, you can connect this parameter to any value in your project to indicate its level to the player. AquaMeter The style of this meter matches the AquaButton example - but instead of exposing button states, it has a controllable fill meter. Library Subgraph Nodes used in this sample: AspectRatio Pill AntiAliasing HistogramScan DialMeter This example uses polar coordinates to create a circular-shaped meter. It also uses drop-shadows on both the inner circle and the outer shape. The player icon at the center could be replaced with a texture sample or another SDF shape. Library Subgraph Nodes used in this sample: AspectRatio Pill AntiAliasing HistogramScan FantasyMeter This example could be used as a health or mana indicator for a fantasy game. It uses the SphereGradient node to generate fake lighting and reflections based on a procedurally-generated sphere shape. The sphere defaults to being filled with red liquid, but you can easily change the color to anything you like by using the exposed Color parameter. Library Subgraph Nodes used in this sample: LinearGradient PosterizeGradient Hash11 LinearTime GridTiles Move Circle HistogramScan Waves AntiAliasing Gradients SphereGradient SciFiMeter This meter could be used to indicate ammo or shield level in a sci-fi-themed game. The cool thing about this one is that it starts to shake when the indicator gets low - to emphasize the urgency of low ammo or shields. Library Subgraph Nodes used in this sample: Shake AspectRatio Tilt Rectangle AntiAliasing WindowBlinds PosterizeGradient HistogramScan Progress Bars FancyLoading This is a circle that’s made of circles. Each circle starts large and then gets smaller over time and the effect is offset so it happens in a wave pattern. The larger circle pattern also appears to move and change perspective over time as if it were tilting around in a 3D space. These effects are all achieved by chaining together various nodes from the Subgraph Library. Library Subgraph Nodes used in this sample: SineTime Perspective Scale Move LinearTime GridTiles Circle AntiAliasing GradientBar This is a pill-shaped bar that fills up as the progress parameter increases from zero to one. The aspect ratio adapts if it’s correctly connected to the width and height parameters of the Canvas Image element it’s assigned to. Library Subgraph Nodes used in this sample: Move Pill AntiAliasing Invert LinearGradient Scale Gradients ProgressCircle This is a round dial that fills up in a circle shape as the progress parameter increases from zero to one. The start color and end color are exposed as parameters and can be adjusted to create different looks. Library Subgraph Nodes used in this sample: Invert PosterizeGradient HistogramScan Circle AntiAliasing CircleSegments SimpleLoading This is a circle made of pill-shaped elements that fade from white to black over time. Each element fades in a wave-like pattern that appears to go around the circle. This type of animation is very commonly used as a loading indicator. Library Subgraph Nodes used in this sample: Tilt Scale LinearTime GridTiles Pill AntiAliasing"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Getting-Started.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Getting-Started.html",
    "title": "Getting Started | Inventory System",
    "summary": "Getting Started After you import the sample from the Package Manager open this scene: Assets\\Samples\\Shader Graph\\<version number>\\UGUI Shaders\\Scenes\\UISampleScene.unity Here you can see some sample buttons, indicators, and backgrounds. All of these UI elements were constructed in Shader Graph using the subgraphs in this sample. To see the subgraphs in a gallery, open this Shader Graph file: Assets/Samples/Shader Graph/<version number>/UGUI Shaders/Subgraphs/SubgraphLibrary.shadergraph Here you’ll see all of the subgraphs grouped according to the category they’re in. You can double-click any of them to jump into the subgraph to see what it does. You can also right click in any Shader Graph shader and find the subgraphs in the UI category in the Add Node window. To see examples of how to use the subgraphs, open the following Shader Graph asset: Assets/Samples/Shader Graph/17.0.3/UGUI Shaders/Examples/SimpleExamples.shadergraph This file contains several simple examples that show how the UI subgraphs can be used together to create interesting effects. It’s a good demonstration of the functionality of the subgraph nodes. To see examples of how to create UI buttons and indicators, open this Shader Graph file: Assets/Samples/Shader Graph/17.0.3/UGUI Shaders/Examples/ButtonsAndIndicators.shadergraph This file contains several example buttons and indicators. You can double click on any of them to open the Shader Graph assets and see how they’re constructed."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-Button.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-Button.html",
    "title": "How to create a functioning button | Inventory System",
    "summary": "How to create a functioning button Buttons have multiple states depending on the user’s interaction with them. The button may change its appearance when the user’s mouse is hovering over the button. And when it’s pressed, the button may also change to indicate the press. That means that the shader needs to create the various visual styles and expose parameters to trigger them. You’ll then need to connect those exposed parameters to the button’s events. Follow these steps to learn how to do that. Create a new Shader Graph asset. In the Graph Inspector, make sure that the Shader Graph’s Material setting is set to Canvas. Open the shader’s Blackboard and add two boolean parameters. Name the parameters Selected and Pressed. Drag these parameters into your graph and use them to create a shader that changes depending on if the values are true or false. The SimpleButton Shader Graph asset is a good example of this. Find it here: Assets/Samples/Shader Graph/<your version>/UGUI Shaders/Examples/Buttons/SimpleButton In your scene, create a new Canvas element (if there isn’t one already) in the Hierarchy panel. (Right click in the Hierarchy panel and select UI > Canvas). Add a Button element to the Canvas. (Right click on the Canvas element and select UI > Button - TextMeshPro) Then select the Button element. Select the material associated with your shader in the Project panel and drag and drop it into the Material slot in the Inspector for the Image UI element. Now your shader’s material is assigned to the UI element. Set the button’s Source Image and Transition to None. The shader provides these. Now click the Add Component button at the bottom of the Inspector and add the script called UI Material. This script exposes the Selected and Pressed parameters so they can be used by other scripts. Click Add Component again and add the script called ButtonMaterial. This script connects the material’s exposed button parameters to the button’s events. Now you have a button that correctly passes information to its material when the mouse pointer hovers over the button, presses down on the button, stops pressing the button, and moves off of the button. You can set up the shader to respond to these events visually in whatever way makes sense for the style. For example, when the button is pressed, you might move the button down slightly, invert its color, or get darker. When the mouse is hovering over the button, you might make an outline appear around it, or turn on an animated sheen effect."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-Res-indepenent.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-Res-indepenent.html",
    "title": "How to create a resolution-independent shape | Inventory System",
    "summary": "How to create a resolution-independent shape When creating a UI element, it’s very useful to be able to make it resolution-independent - meaning that it looks sharp and crisp regardless of if it’s rendered at very high resolution or very low resolution. UI elements that are based on textures are resolution dependent. The texture itself has a specific resolution - so if the UI element is rendered at a higher resolution than the texture, the result will be blurry, and if the texture is a higher resolution than the UI element is rendered, you’ll get filtering artifacts and waste texture memory. With the nodes in the library included with this sample set, you can generate shapes procedurally instead of with textures. You can render these shapes at any resolution and they will always look perfectly sharp and smoothly anti-aliased. Here’s how to do it: Add one of the SDF shape nodes (Circle, Hexagon, Pill, Rectangle, Star, or Triangle) to your graph. You can find them in the Add Node menu under UI/SDFs. These nodes generate shapes using signed distance fields. If you grab the output from the Fill output port, you’ll get a shape, but you can also get the raw SDF output from the SDF output port. Each pixel in the SDF is a value that represents the distance to the nearest edge of the shape. Pixels that are inside the shape have a negative value to indicate that. Add an AntiAliasing node to your graph. You can find it in the Add Node menu under UI/Helpers. The AntiAliasing node is designed to “resolve” an SDF into an anti-aliased shape in a resolution-independent way. Connect the SDF output port of your SDF shape node to the Gradient input port of the AntiAliasing node. Set the Cutoff port to a default value of zero. The AntiAliasing node will convert the shape’s SDF into a solid shape using a method that correctly adapts to the number of pixels on the screen. To make your shape white and the background black, connect the Out port of the AntiAliasing node to a One Minus node to invert the result. You now have a resolution-independent shape. You can fill the whole screen with this shape and render it at 8k, or scale it down to a tiny portion of the screen and render it on a low-end smartphone and it will have a sharp, anti-aliased edge in all cases."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-aspect-ratio.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos-aspect-ratio.html",
    "title": "How to make shapes that adapt to the aspect ratio of the UI element | Inventory System",
    "summary": "How to make shapes that adapt to the aspect ratio of the UI element Buttons and other UI elements come in all shapes and sizes. Frequently, the same style of button or background element needs to work with many different shapes or adapt to a changing width and height. Many of the UI elements in this sample are designed to adapt to changing dimensions. Follow these steps to create a UI element that can do that. Create a new Shader Graph asset. In the Graph Inspector, set the Shader Graph’s Material setting to Canvas. Add an SDF Pill node to the new Shader Graph file. ( You can find this node in the Add Node menu under UI/SDFs.) Connect the Pill node’s Fill output port to the Base Color input port of the Master Stack. Now you’ve created a shader for a UI element that’s meant to be square. If you assign this shader to a non-square UI element, it will stretch and not look like a proper pill shape. Notice that the Pill node’s last input port is called WidthHeight. This is an input for the width and height data of the UI element that the shader will be assigned to. By default, the Pill node assumes the UI element will be square, but if you plan to use a different aspect ratio, you can enter other values. Rather than entering the values manually, it’s best to connect them to the actual UI element values. That’s what we’ll do next. Open the Blackboard and add a new Vector2 parameter. Name the parameter WidthHeight. Drag the parameter into the graph and connect it to the WidthHeight input port on the Pill node. You’ve now exposed the WidthHeight parameter so it can be connected outside the shaders. In your scene, create a new Canvas element (if there isn’t one already) in the Hierarchy panel. (Right click in the Hierarchy panel and select UI > Canvas). Then add an Image element to the Canvas. (Right click on the Canvas element and select UI > Image) Select the Image element. Select the material associated with your shader in the Project panel and drag and drop it into the Material slot in the Inspector for the Image UI element. Now your shader’s material is assigned to the UI element. Click the Add Component button at the bottom of the Inspector. Select and assign the Image Size script to the Image element. This script connects the Image element’s Width and Height parameters to the WidthHeight parameter of your shader, so when the Width or Height values change, the shader adapts. Now you have a shader that will adapt to the aspect ratio of the UI element it’s assigned to. You can adjust the Width and Height parameters of the Image element and the Pill shape will maintain its rounded shape. This same feature is also available on many of the other nodes in the node library. You can control any subgraph node with a WidthHeight input port in this same way."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-How-tos.html",
    "title": "How Tos | Inventory System",
    "summary": "How Tos The following topics provide examples of UI elements that you can create with shader graph. Topic Description How to create a resolution-independent shape Learn how to create UI elements based on textures. How to create a functioning button Learn how to create a button that changes appearance depending on the user action. How to make shapes that adapt to the aspect ratio of the UI element Learn how to create UI elements that can adapt to changing dimensions."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Notes-on-performance.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Notes-on-performance.html",
    "title": "Notes On Performance | Inventory System",
    "summary": "Notes On Performance The techniques on display in these example shaders use pure math to generate visuals (procedural generation) instead of sampling texture maps. While it’s obvious that these methods will use less memory than texture map based methods, the main question is whether it’s cheaper to sample a texture map, or generate the visuals procedurally. In our internal testing, the performance difference between rendering a texture-based button and a procedurally-generated button was less than 0.01 milliseconds so the difference was so small that it was almost not measurable. Of course it would be possible to create a significantly more complex shader that would be more expensive than a texture sample, but at the level of complexity of the examples we’ve created, there’s almost no performance difference between these and traditional texture-based UI elements. Given this understanding, in addition to the other benefits of these techniques (described at the top of this documentation), it seems obvious that this is a very efficient and effective way to create UI elements."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Subgraph-nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders-Subgraph-nodes.html",
    "title": "Subgraph Nodes | Inventory System",
    "summary": "Subgraph Nodes The subgraphs have been created to help speed up the process of creating user interface elements. They’re building blocks that can be strung together quickly to achieve various appearances and functionalities. You can see all of the subgraph nodes in the collection by opening this shader file: Assets/Samples/Shader Graph/ /UGUI Shaders/Subgraphs/SubgraphLibrary The subgraphs are broken into the following categories: Inputs - These subgraphs provide input data. Utilities - These subgraphs feature simple utilities to help with input data. Gradients - These nodes generate gradients in various shapes including linear, spherical, square, and custom. Helpers - these subgraphs provide commonly-used operations for building UI elements Patterns - These nodes generate procedural patterns that can be used as backgrounds or masks. The patterns include clouds, bars, checkers, circle segments, hexagon tiles, player icon, rings, ring segments, square tiles, wedges, and window blinds. SDFs - Signed Distance Field shapes are the basis for UI elements. The value of each pixel in an SDF represents the distance to the edge of the shape. You can use the SDF data to create resolution-independent shapes that are either sharp or blurry. Shapes in the set include circle, hexagon, pill, rectangle, star, and triangle. This collection also contains operators for combining SDF shapes. Time - These nodes output time in various forms - looping, mirroredm, sine wave, etc. UV - These nodes manipulate UV coordinates including move, scale, tilt, mirror, invert, and more. Shapes and elements can be transformed by adjusting their UV coordinates with these nodes. Inputs Canvas Color This subgraph outputs the UI element color in linear space, performing color space conversion on vertex color if the Canvas is set to store vertex colors in gamma space. Make sure to check \"Disable Color Tint\" in the Graph Settings when using the Canvas Color node, to not tint the final output. Utilities SelectableStateCompare This subgraph takes a Selectable State as a float and outputs Boolean values to inform on the states. SelectableStatePreview This subgraph takes a Selectable State as a float input and features a dropdown to override its value withing Shader Graph only. This allows previewing what things look like when in a given state. This has no effect on the final shader that will always use the provided input. SliderDirectionCompare This subgraph takes a Direction as a Vector2 and outputs Boolean values to inform on cardinals. SliderDirectionPreview This subgraph takes a Direction as a Vector2 input and features a dropdown to override its value withing Shader Graph only. This allows previewing what things look like with a different direction is used. This has no effect on the final shader that will always use the provided input. Gradients This node is a collection of commonly used gradients. You can select the gradient you want to use from the Style dropdown. By default, a horizontal LinearGradient is used as the input, but you can pass in any input gradient you want. Cone Gradient Creates a Gradient, Normals, Height, and a Mask for a procedurally-generated cone. This allows you to create 3d effects in a 2d environment. The Size input port controls the size of the generated cone relative to the UV space. ConeHeight input controls the height above the base of the cone’s center point. The LightDirection input port is a vector that determines the direction the light is coming from for the Diffuse gradient output. The Diffuse output uses the cone’s normals and the incoming LightDirection to calculate diffuse lighting. Areas of the Diffuse gradient facing away from the LightDirection will have negative values, so you may need to use a Saturate node to limit the range of the output to zero to one. The NormalTS output is a normalized vector that indicates the direction each pixel on the cone’s surface is facing. The Height output is a heightmap for the cone. The Mask output is white inside the cone and black outside. Usage Examples: Examples/Backgrounds/80sSunset Examples/Indicators/FantasyMeter Linear Gradient This node uses UV coordinates to create a vertical or horizontal gradient from black to white. By default, the node uses the UV coordinates from the UI element, but you can also pass in your own coordinates to the UV input port. The U output port creates a horizontal gradient and the V output port creates a vertical gradient. Usage Examples: Examples/Backgrounds/80sSunset Examples/ProgressBars/GradientBar Cube Gradient Creates a gradient, normals, height, and a mask for a procedurally-generated cube. This allows you to create 3d effects in a 2d environment. The InnerSize and OuterSize input ports control the size of the generated cube relative to the UV space. The LightDirection input port is a vector that determines the direction the light is coming from for the Diffuse gradient output. The Diffuse output uses the cube’s normals and the incoming LightDirection to calculate diffuse lighting. Areas of the Diffuse gradient facing away from the LightDirection will have negative values, so you may need to use a Saturate node to limit the range of the output to zero to one. The NormalTS output is a normalized vector that indicates the direction each pixel on the sphere’s surface is facing. The Mask output is white inside the sphere and black outside. Sphere Gradient Creates a gradient, normals, height, and a mask for a procedurally-generated sphere. This allows you to create 3d effects in a 2d environment. The Size input port controls the size of the generated sphere relative to the UV space. The LightDirection input port is a vector that determines the direction the light is coming from for the Diffuse gradient output. The Diffuse output uses the sphere’s normals and the incoming LightDirection to calculate diffuse lighting. Areas of the Diffuse gradient facing away from the LightDirection will have negative values, so you may need to use a Saturate node to limit the range of the output to zero to one. The NormalTS output is a normalized vector that indicates the direction each pixel on the sphere’s surface is facing. The Mask output is white inside the sphere and black outside. Usage Examples: Examples/Indicators/FantasyMeter Helpers Anti Aliasing You can use this node to create a perfectly anti-aliased edge from any SDF shape or gradient regardless of the size of the shape or the camera’s distance from the UI element. You can use it to create resolution-independent UI elements. The Cutoff input controls the point along the input gradient where the hard edge should be. See the documentation section entitled “How to create a resolution-independent shape” for instructions on using this node. Usage Examples: Examples/Indicators/FantasyMeter Examples/Backgrounds/LavaLamp Aspect Ratio Given the Width and Height of the UI element, this node calculates the aspect ratio of the UI element. It can be used to create buttons and widgets that correctly adapt to changes in the width or height of the assigned UI element. It works best when the WidthHeight input port is connected to the Width and Height parameters of the assigned UI element. See the documentation section entitled “How to make shapes that adapt to the aspect ratio of the UI element” for more information. Usage Examples: Examples/Indicators/AquaMeter Subgraphs/SDFs/Pill Ease Curves This node adjusts the falloff curve of the input gradient. There are 9 available falloff curves. More information on the falloff curves can be found here: https://easings.net/ By default, the input Gradient is LinearTimeMirror, but you can use any type of gradient you want. Hash11 Given an input value In and a Seed, this node generates a deterministic random value in the 0 to 1 range as output. Time is used as the default input, but you can use any input value you want. Usage Examples: Examples/Indicators/FantasyMeter Hash21 Given a vector2 value UV (such as UV coordinates) and a Seed, this node generates a deterministic random value as output. UV0 is the default UV input, but you can use any vector 2 value you want. Histogram Scan This node allows you to convert a gradient or SDF into a solid shape. You can control the Position along the gradient where the solid edge forms as well as the hardness of the edge using Contrast input. The lower the Contrast value, the softer the edge. Usage Examples: Examples/ProgressBars/ProgressCircle Examples/Indicators/DialMeter Lerp Multiple This node works in a similar way as the Lerp node, but allows you to blend between 3 or 4 values instead of just 2. FracTime is used as the default for the T value but you can use any value you want. Mirror This node flips the input value back and forth. The number of times to repeat the back and forth pattern is determined by the Subdivisions input. Usage Examples: Subgraphs/SDFs/Wave PosterizeGradient This node quantizes gradients into discrete steps. The number of steps is controlled by the Steps input. The step divisions can be divided to preserve the overall range or to preserve the step distance. Usage Examples: Examples/ProgressBars/ProgressCircle Examples/Indicators/SciFiMeter Random Given UV coordinates and a Seed, this node generates random values - either Vector 2 or Float. Because the method used to generate the values uses a sine function, it is non-deterministic, may vary on various hardware platforms (depending on the hardware implementation of sine), and may exhibit repetitive patterns when given large input values. If you are seeing these issues, use the Hash11 or Hash21 nodes instead. Usage Examples: Subgraphs/UV/Shake.shadersubgraph RoundedCorners This is a helper node used by the SDF Rectangle node. It helps to generate the rounded corners of the rectangle. Usage Examples: Subgraphs/SDFs/Rectangle Scene Color Blurred This node samples the Scene Color node in a spiral pattern and averages the result to create the appearance of blurring the scene background behind the UI element. Cycles is the number of turns of the spiral. Use Samples Per Cycle to control the number of samples in each cycle. The total number of samples is Cycles times Samples Per Cycle. Higher numbers of samples result in smoother blur appearance but higher cost. Lower sample numbers give better performance but grainier results. See the Sticky Notes inside the subgraph for more information. Usage Examples: Examples/Backgrounds/BlurredHexagon Patterns Animated Clouds Generates an animated cloud pattern. By default, the clouds are generated in screen space, but you can also pass in your own UV coordinates. You can control the color of the clouds with the Color1 and Color2 inputs. The speed of cloud movement is controlled with the Speed input. And the size of the clouds can be controlled with the Scale input. Usage Examples: Examples/Backgrounds/TechGrid Examples/Buttons/SciFiButton2 Animated Sheen This node creates a scrolling highlight gradient. It’s intended to create the animated sheen on buttons - especially when the button is selected or the user’s mouse is hovering over the button. You can control the size of the effect with the Scale input. The angle of tilt can be adjusted with the Tilt input value. And you can control the Speed that the effect scrolls with the Speed input. Usage Examples: Examples/Buttons/AquaButton Examples/Buttons/SciFiButton2 Bars This node generates vertical or horizontal bars (an alternating black and white pattern) depending on the output port you use. You can control the number of bars using the Bars input. Checkers This node generates a simple checkerboard pattern. You can control the scale of the pattern using the Tiles input. Circle Segments This node divides a circle into the given number of segments and alternates them between black and white. The width and blur of the segments can be controlled with the Spacing and Blur inputs. The segments can be output as triangles or lines. You can also rotate the pattern using the Rotation input. Usage Example: Examples/Buttons/SciFiButton Hexagon Tiles This node creates a hexagon grid. The Tiles input controls the scale of the hexagon tiles. The Thickness input controls the width of the Stroke outlines. The Distance input controls the size of the white parts of the tiles relative to the black lines. The Blur input controls the blurriness of the tile outlines. An interesting and useful inverse SDF effect can be achieved by setting the Distance input to 0 and the Blur input to 0.5. Usage Examples: Examples/Backgrounds/BlurredHexagon Player Icon This node creates an avatar icon. It combines the Circle and Pill SDF nodes. It’s a good example of how SDFs can be combined to create other shapes. Usage Examples: Examples/Buttons/SciFiButton Examples/Indicators/DialMeter Rings This subgraph generates a series of concentric rings. You can select the number of rings with the Segments input. You can control how sharp or blurry the rings are with the Glow Min Max input. You can crop the rings at the edges with the Mask To Bounds input. The Offset input moves the rings toward or away from the center. By default it’s set to LinearTime but you can use any input value. Ring Segments This node generates a set of rotating ring segments. You can control the number of segments with the Segments input. The Size input controls how far the segments are from the center. The Blur input controls how sharp or blurry the edges of the segments are. The Thickness input controls the width of the segments. The Contrast input controls the falloff of the segment’s tail. The Rotation input controls the movement or position around the circle of the segments. Square Tiles This node generates a grid pattern of square tiles. The Tiles input controls the number of tiles in each dimension. Size controls the size of the white squares vs black lines in both dimensions. The lower these values are, the thicker the black outlines will be. Blur controls the sharpness/blurriness of the white squares. You’ll most likely need to turn the Size value down in order to make room for blurry edges. Usage Examples: Examples/Backgrounds/TechGrid Examples/Buttons/SciFiButton2 Wedges This node generates wedge patterns of various types. The type can be selected with the dropdown box. Usage Examples: Subgraphs/Gradients/SquareGradient Window Blinds This node generates a bar pattern that can expand or contract to give the appearance of opening and closing window blinds. The Rotation input controls the orientation of the blinds in degrees. The Segments input controls the number of blinds. The Progress input controls the balance between black and white. Higher values make the white bars larger and lower values make the black bars larger. Blur controls the sharpness/blurriness of the bard edges. Usage Example: Examples/Indicators/SciFiMeter SDFs SDFs or Signed Distance Fields are a very useful way of representing procedurally-generated shapes. The value of each pixel in the SDF represents the distance to the nearest shape edges. Pixels inside the shape have negative values - also indicating the distance to the nearest edge. SDFs can be used to create a final shape using the Fill output of the SDF node, using the Histogram Scan node, or the AntiAliasing node. The AntiAliasing node specifically will create shapes that are perfectly anti-aliased regardless of scale, camera distance, or resolution. Each of the SDF shape nodes outputs the shape from the Fill output. The Stroke port outputs an outline of the shape. The Stroke Thickness input parameter controls the width of the Stroke outline. The nodes also output the SDF itself as well as the Stroke SDF. You can control the sharpness or blurriness of the Fill shape by using the Edge Min and Edge Max controls. The closer together the values are, the sharper the edge of the shape will be. The farther apart the values are, the softer/blurrier the edges will be. A blurry SDF shape makes a great drop shadow. Circle Creates a circle shape. Usage Examples: Examples/Buttons/SciFiButton Examples/Indicators/FantasyMeter Examples/Indicators/DialMeter Hexagon Creates a hexagon shape. It’s possible to round the corners of the hexagon using the Corner Radius input parameter. Pill Generates a pill shape. You can control the height of the pill with the Size parameter. You can control the width of the pill with the Width parameter. To control the aspect ratio of the pill, use the WidthHeight parameter to enter the dimensions of the UI element. Usage Examples: Examples/Buttons/AquaButton Examples/ProgressBars/GradientBar Rectangle Creates a rectangle shape. You can round the corners of the rectangle using the four Corner Radii input values. To control the aspect ratio of the rectangle, use the WidthHeight parameter to enter the dimensions of the UI element. Usage Examples: Examples/Buttons/SimpleButton Examples/Backgrounds/RoundedRectangleBubble Star Creates a star shape. You can control the number of points and the point distance. Triangle Creates a triangle shape. It’s possible to round the corners of the triangle using the Corner Radius input parameter. Waves Generates an animated wave pattern from any SDF. You can control the number of waves and the movement of the waves using the Repetitions and Movement parameters. Usage Example: Examples/Indicators/FantasyMeter SDF Intersect This is a basic boolean intersection operation between two SDFs. The result is the intersection where the two shapes overlap. Using the Smooth output allows the result to have a soft blend instead of the hard edge. SDF Subtract This is a basic boolean intersection operation between two SDFs. The result is the second SDF subtracted from the first. Using the Smooth output allows the result to have a soft blend instead of the hard edge. SDF Unite This is a basic boolean intersection operation between two SDFs. The result is the two SDF shapes combined together. Using the Smooth output allows the result to have a soft blend instead of the hard edge. Usage Example: Examples/Backgrounds/LavaLamp Time LinearTime Outputs time values that increase linearly. The Loop output increases linearly from 0 to 1 and then jumps back to zero. The Mirror output increases linearly from 0 to 1 and then decreases linearly back to 0 and repeats this back and forth cycle. The Switch output jumps from 0 directly to 1 and then back to 0 again. Usage Examples: Examples/Backgrounds/80sSunset Examples/Buttons/SciFiButton2 Examples/Indicators/FantasyMeter SineTime The Raw output flows in a smooth curve from -1 to 1 and back. The Normalized output flows in a smooth curve between 0 and 1. Usage Examples: Examples/ProgressBars/FancyLoading Examples/Backgrounds/LavaLamp TimeOffset Allows you to use a mask to determine areas where time is offset. The maximum offset value is defined by the Offset input. Areas where the Mask is 1 are time offset by the maximum amount. Areas where the Mask is 0 are not time offset. UV GridTiles Divides the UV space into the number of tiles defined by Tile U and Tile V. Aspect ratio can be maintained by inputting correct values into WidthHeight Usage Examples: Examples/Indicators/FantasyMeter Examples/ProgressBars/FancyLoading Halftone Divides the UV space into halftone space or outputs a halftone pattern based on the input gradient where the size of the dots are determined by the shades in the input gradient. Areas where the input gradient is white have the largest halftone dots. Usage Example: Examples/Backgrounds/Halftone Invert Flips the U coordinate, the V coordinate, or both. Usage Example: Examples/Indicators/DialMeter Examples/ProgressBars/GradientBar Examples/ProgressBars/ProgressCircle MirrorUV Takes UV coordinates in the 0 to 1 range and converts them to go from 0 to 1 to 0 again. You can control the offset, rotation, scale, and axis to mirror. Move Moves UV coordinates the amount specified by the Move input. Usage Examples: Examples/Backgrounds/80sSunset Examples/Backgrounds/LavaLamp Examples/Backgrounds/WarpedGradient Examples/Buttons/SimpleButton Perspective Distorts UV coordinates to make it look like perspective is applied as if the object were rotated away from the camera. Because of the perspective warping, some empty space is created around the edges. This empty space is black in the Alpha output. The Alpha Threshold and Alpha Feather inputs control the edges of the empty space. Usage Examples: Examples/ProgressBars/FancyLoading Examples/Backgrounds/80sSunset PosterizeUV Divides smooth UV coordinates into discrete, quantized units. The number of units can be specified with the Steps input. This node works well to convert a high resolution image into a low resolution one. Usage Example: Examples/Backgrounds/Pixelation Scale Scales texture coordinates by the amount specified in Scale around the point specified by Pivot Point. Usage Examples: Examples/Backgrounds/RoundedRectangleBubble Examples/Buttons/SciFiButton Examples/Indicators/DialMeter Shake Oscillates UV coordinates back and forth quickly by a random amount and using the Speed and Strength inputs. Usage Example: Examples/Indicators/SciFiMeter Tilt Tilts the UV coordinates so that the resulting object slants to the left or right. Usage Examples: Examples/Indicators/SciFiMeter Examples/ProgressBars/SimpleLoading Waves Distorts the UV coordinates in a wave pattern. The strength and size of the waves can be controlled with the Amplitude and Frequency inputs. Usage Example: Examples/Indicators/FantasyMeter"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Sample-UGUI-Shaders.html",
    "title": "UGUI Shaders | Inventory System",
    "summary": "UGUI Shaders The Shader Graph UGUI Shaders sample is a collection of Shader Graph subgraphs that serve as building blocks for building user interface elements. They speed up the process of building widgets, buttons, and backgrounds for the user interface of your project. Using these tools, you can build dynamic, procedural UI elements that don’t require any texture memory and scale correctly for any resolution screen. In addition to the subgraphs, the sample also includes example buttons, indicators, and backgrounds built using the subgraphs. The examples show how the subgraphs function in context and help you learn how to use them. We have two main objectives with this sample set: Demonstrate Shader Graph’s ability to create dynamic, resolution-independent user interface elements in a wide variety of shapes and styles. Make it easier and faster to create UI elements by providing a large set of UI-specific subgraph nodes that can be used as building blocks to speed up the creation process. Using Shader Graph and UGUI, you can create user interface elements that are resolution independent, require zero texture memory, can be authored and edited directly in Shader Graph inside of Unity, automatically adapt to aspect ratio, and contain all visual states and behaviors. That’s a lot, so let’s unpack it! Resolution Independent - These UI elements are procedurally-generated, so they look perfectly crisp whether displayed on a small smartphone screen or a 100 inch 8k TV. You can zoom in on them as close as you want and they’ll always be tack sharp. Zero Texture Memory - The visuals for these UI elements are created using math, so they don’t rely on textures at all. That means they require zero texture memory. Authored In Shader Graph - If you’re frustrated by the back and forth workflow of editing your UI images outside of Unity, chopping them up into textures, importing them, and then going back to make adjustments, you’ll be glad to hear that these UI elements are created entirely in Shader Graph, so there’s no export/import loop. Adjustments require simply changing shader parameters or re-wiring a few nodes. Automatically Adapt To Aspect Ratio - By passing the width and height values of the assigned UI element into the shader, the shader can automatically adapt the visuals to fit that ratio. No more making different button shapes to fit different size buttons or fiddling with 9 slicing. Contain all visual states and behaviors - One shader can contain all the information needed for a hover state, and active/inactive state, a pressed down state, etc, so you don’t need to manage multiple image assets for each button or widget. This set of samples demonstrates how to use all of these advanced techniques for generating UI, and provides tools to make the process easier. Documentation for this set of samples is broken into the following pages: Getting started Custom UI componenents Custom nodes Subgraph nodes Examples How tos How to create a resolution-independent shape How to create a functioning button How to make shapes that adapt to the aspect ratio of the UI element Notes on performance"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Window.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Graph-Window.html",
    "title": "Shader Graph Window | Inventory System",
    "summary": "Shader Graph Window Description The Shader Graph Window contains the workspace for creating shaders with the Shader Graph system. To open the Shader Graph Window, you must first create a Shader Graph Asset. For more information, refer to the Getting Started section. The Shader Graph window contains various individual elements such as the Blackboard, Graph Inspector, and Main Preview. You can move these elements around inside the workspace. They automatically anchor to the nearest corner when scaling the Shader Graph Window. Toolbar The toolbar at the top of the Shader Graph Window contains the following commands. Icon Item Description Save Asset Save the graph to update the Shader Graph Asset. Save As Save the Shader Graph Asset under a new name. Show In Project Highlight the Shader Graph Asset in the Project Window. Check Out If version control is enabled, check out the Shader Graph Asset from the source control provider. Color Mode Selector Select a Color Mode for the graph. Blackboard Toggle the visibility of the Blackboard. Graph Inspector Toggle the visibility of the Graph Inspector. Main Preview Toggle the visibility of the Main Preview. Help Open the Shader Graph documentation in the browser. Resources Contains links to Shader Graph resources (like samples and User forums). Workspace The workspace is where you create Node networks. To navigate the workspace, do the following: Press and hold the Alt key and drag with the left mouse button to pan. Use the mouse scroll wheel to zoom in and out. You can hold the left mouse button and drag to select multiple Nodes with a marquee. There are also various shortcut keys you can use for better workflow. Context Menu Right-click within the workspace to open a context menu. However, if you right-click on an item within the workspace, such as a Node, the context menu for that item opens. The workspace context menu provides the following options. Item Description Create Node Opens the Create Node Menu. Create Sticky Note Creates a new Sticky Note on the Graph. Collapse All Previews Collapses previews on all Nodes. Cut Removes the selected Nodes from the graph and places them in the clipboard. Copy Copies the selected Nodes to the clipboard. Paste Pastes the Nodes from the clipboard. Delete Deletes the selected Nodes. Duplicate Duplicates the selected Nodes. Select / Unused Nodes Selects all nodes on the graph that are not contributing to the final shader output from the Master Stack. View / Collapse Ports Collapses unused ports on all selected Nodes. View / Expand Ports Expands unused ports on all selected Nodes. View / Collapse Previews Collapses previews on all selected Nodes. View / Expand Previews Expands previews on all selected Nodes. Precision / Inherit Sets the precision of all selected Nodes to Inherit. Precision / Float Sets the precision of all selected nodes to Float. Precision / Half Sets the precision of all selected nodes to Half. Additional resources Color Modes Create Node Menu Keyboard shortcuts Master Stack Nodes Sticky Notes"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Stage.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Shader-Stage.html",
    "title": "Shader Stage | Inventory System",
    "summary": "Shader Stage Description Shader Stage refers to the part of the shader pipeline a Node or Port is part of. For example, Vertex or Fragment. In Shader Graph, Shader Stage is defined per port but often all ports on a node are locked to the same Shader Stage. Ports on some nodes are unavailable in certain Shader Stages due to limitations in the underlying shader language. See the Node Library documentation for nodes that have Shader Stage restrictions. Shader Stage List Name Description Vertex Operations calculated per vertex Fragment Operations calculated per fragment"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/ShaderGraph-Samples.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/ShaderGraph-Samples.html",
    "title": "Shader Graph samples | Inventory System",
    "summary": "Shader Graph samples Description The Shader Graph package offers sample Assets, which you can download through Package Manager. When you import these samples, Unity places the files in your Project's Asset folder. The files contain examples that demonstrate how to use Shader Graph features. Add samples To add samples to your Project, go to Window > Package Manager. Locate Shader Graph in the list of available packages, and select it. Under the package description, there is list of available samples. Click the Import into Project button next to the sample you wish to add. Unity places imported samples in your Project's Asset folder under Assets > Samples > Shader Graph > [version number] > [sample name]. The example below shows the samples for Procedural Patterns. Available samples The following samples are currently available for Shader Graph. Procedural Patterns This collection of Assets showcases various procedural techniques possible with Shader Graph. Use them directly in your Project, or edit them to create other procedural patterns. The patterns in this collection are: Bacteria, Brick, Dots, Grid, Herringbone, Hex Lattice, Houndstooth, Smooth Wave, Spiral, Stripes, Truchet, Whirl, Zig Zag. Node Reference This set of Shader Graph assets provides reference material for the nodes available in the Shader Graph node library. Each graph contains a description for a specific node, examples of how it can be used, and useful tips. Some example assets also show a break-down of the math that the node is doing. You can use these samples along with the documentation to learn more about the behavior of individual nodes. Feature Examples This is a collection of over 30 Shader Graph files. Each file demonstrates a specific shader technique such as angle blending, triplanar projection, parallax mapping, and custom lighting. While you won’t use these shaders directly in your project, you can use them to quickly learn and understand the various techniques, and recreate them into your own work. Each file contains notes that describe what the shader is doing, and most of the shaders are set up with the core functionality contained in a subgraph that’s easy to copy and paste directly into your own shader. The sample also has extensive documentation describing each of the samples to help you learn. Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample includes the Shader Graph versions of the HDRP and URP Lit shaders. It also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment. UGUI Shaders The Shader Graph UGUI Shaders sample is a collection of Shader Graph subgraphs that you can use to build user interface elements. They speed up the process of building widgets, buttons, and backgrounds for the user interface of your project. With these tools, you can build dynamic, procedural UI elements that don’t require any texture memory and scale correctly for any resolution screen. In addition to the subgraphs, the sample also includes example buttons, indicators, and backgrounds built with the subgraphs. The examples show how the subgraphs function in context and help you learn how to use them."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sign-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sign-Node.html",
    "title": "Sign Node | Inventory System",
    "summary": "Sign Node Description Per component, returns -1 if the value of input In is less than zero, 0 if equal to zero and 1 if greater than zero. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Sign_float4(float4 In, out float4 Out) { Out = sign(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Simple-Noise-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Simple-Noise-Node.html",
    "title": "Simple Noise Node | Inventory System",
    "summary": "Simple Noise Node Description Generates a simple, or Value, noise based on input UV. The scale of the generated noise is controlled by input Scale. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Simple Noise node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Scale Input Float None Noise scale Out Output Float None Output value Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacySine Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. inline float unity_noise_randomValue (float2 uv) { return frac(sin(dot(uv, float2(12.9898, 78.233)))*43758.5453); } inline float unity_noise_interpolate (float a, float b, float t) { return (1.0-t)*a + (t*b); } inline float unity_valueNoise (float2 uv) { float2 i = floor(uv); float2 f = frac(uv); f = f * f * (3.0 - 2.0 * f); uv = abs(frac(uv) - 0.5); float2 c0 = i + float2(0.0, 0.0); float2 c1 = i + float2(1.0, 0.0); float2 c2 = i + float2(0.0, 1.0); float2 c3 = i + float2(1.0, 1.0); float r0 = unity_noise_randomValue(c0); float r1 = unity_noise_randomValue(c1); float r2 = unity_noise_randomValue(c2); float r3 = unity_noise_randomValue(c3); float bottomOfGrid = unity_noise_interpolate(r0, r1, f.x); float topOfGrid = unity_noise_interpolate(r2, r3, f.x); float t = unity_noise_interpolate(bottomOfGrid, topOfGrid, f.y); return t; } void Unity_SimpleNoise_float(float2 UV, float Scale, out float Out) { float t = 0.0; float freq = pow(2.0, float(0)); float amp = pow(0.5, float(3-0)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; freq = pow(2.0, float(1)); amp = pow(0.5, float(3-1)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; freq = pow(2.0, float(2)); amp = pow(0.5, float(3-2)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; Out = t; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sine-Node.html",
    "title": "Sine Node | Inventory System",
    "summary": "Sine Node Description Returns the sine of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value in radians. Out Output Dynamic Vector Output value. Range (-1 to +1). Generated Code Example The following example code represents one possible outcome of this node. void Unity_Sine_float4(float4 In, out float4 Out) { Out = sin(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Slider-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Slider-Node.html",
    "title": "Slider Node | Inventory System",
    "summary": "Slider Node Description Defines a constant Float value in the shader using a Slider field. Can be converted to a Float type Property with a Mode setting of Slider via the Node's context menu. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Slider Defines the output value. Min Float Defines the slider parameter's minimum value. Max Float Defines the slider parameter's maximum value. Generated Code Example The following example code represents one possible outcome of this node. float _Slider_Out = 1.0;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Smoothstep-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Smoothstep-Node.html",
    "title": "Smoothstep Node | Inventory System",
    "summary": "Smoothstep Node Description Returns the result of a smooth Hermite interpolation between 0 and 1, if the value of input In is between the values of inputs Edge1 and Edge2 respectively. Returns 0 if the value of input In is less than the value of input Edge1 and 1 if greater than the value of input Edge2. The Smoothstep node is similar to the Lerp Node but there are two notable differences. Firstly, with the Smoothstep node, the user specifies the range and the return value is between 0 and 1. You can consider this the opposite of the Lerp Node. Secondly, the Smoothstep node uses smooth Hermite interpolation instead of linear interpolation, which means the interpolation gradually speeds up from the start and slows down toward the end. This interpolation is useful for creating natural-looking animation, fading, and other transitions. Ports Name Direction Type Description Edge1 Input Dynamic Vector Minimum step value Edge2 Input Dynamic Vector Maximum step value In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Smoothstep_float4(float4 Edge1, float4 Edge2, float4 In, out float4 Out) { Out = smoothstep(Edge1, Edge2, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/SpeedTree8-SubGraphAssets.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/SpeedTree8-SubGraphAssets.html",
    "title": "SpeedTree 8 Sub Graph Assets | Inventory System",
    "summary": "SpeedTree 8 Sub Graph Assets Prerequisite information This documentation assumes that you are already familiar with the concepts described in the following pages: SpeedTree Sub Graph Nodes Sub Graph Assets Keywords The documentation on ShaderLab material properties might also be contextually helpful. Description SpeedTree is a third-party solution that includes both ready-to-use tree assets, and modeling software for creating your own tree assets. Shader Graph has three built-in SpeedTree Sub Graph Assets: SpeedTree8ColorAlpha SpeedTree8Wind SpeedTree8Billboard These Sub Graph Assets provide SpeedTree 8 functionality for both the Universal Render Pipeline (URP) and High Definition Render Pipeline (HDRP), so that you can work with SpeedTree 8 assets and create your own custom SpeedTree 8 Shader Graphs. Note: The URP-specific versions of these SpeedTree 8 Sub Graph Assets use transparent billboard back faces instead of culling billboard back faces. These Sub Graph Assets can only replace their URP equivalents as a default once URP supports per-material culling overrides in Shader Graphs. SpeedTree8ColorAlpha Each SpeedTree asset has four maps: a basemap (color/albedo), bump map (which provides surface normals), extra map (which provides metallic and ambient occlusion data), and subsurface map (which provides the subsurface scattering color). The basemap provides input color and alpha data. This Sub Graph Asset applies all SpeedTree 8 features that modify the basemap's color and alpha data. These features are particularly useful for the following actions: Tinting the basemap color Varying tree hues Crossfading between levels of detail (LODs) Hiding geometry seams Tinting the basemap color You can use the SpeedTree8ColorAlpha Sub Graph Asset to apply a tint to the basemap color. This is useful if, for example, you want to adjust tree colors for different seasons of the year. Property Support Purpose Behavior _ColorTint URP, HDRP Tint the basemap. Multiplies the _ColorTint property value by the basemap color. Varying tree hues To improve the visual diversity of SpeedTrees, you can use this Sub Graph Asset to modify the color of each tree instance. Both _OldHueVarBehavior and _HueVariationColor use the tree’s absolute world-space position to determine a pseudorandomized hue variation intensity value. Property Support Purpose Behavior _OldHueVarBehavior URP To match the behavior of URP-specific and Built-In SpeedTree 8 shaders. Uses the pseudorandom hue variation intensity value to parameterize the linear interpolation between the basemap color (t=0) and HueVariation color (t=1) . _HueVariationColor URP, HDRP To provide SpeedTrees with more hue diversity. Uses the pseudorandom hue variation intensity value as its opacity and applies that to the basemap color as an overlay blend. A more subtle effect than that provided by _OldHueBehavior. EFFECT_HUE_VARIATION N/A N/A This keyword was used in handwritten SpeedTree 8 shaders, but it's not used in these SpeedTree 8 Shader Graphs. This is to ensure compliance with the default shader variant limit. _HueVariationKwToggle URP, HDRP, Built-In Only to support upgrade functionality. See SpeedTreeImporter.hueVariation. Crossfading between levels of detail (LODs) Crossfading dithers between different levels of detail (LODs) to minimize popping during abrupt transitions. The SpeedTree8ColorAlpha Sub Graph Asset uses a Custom Function Node for that purpose. This Custom Function Node is not SpeedTree-specific. Enable Animate Cross-fading and select an LOD Fade setting to use it with any asset that has the LOD Group component. See Transitioning between LOD levels for more information. Hiding geometry seams The SpeedTree8ColorAlpha Sub Graph asset applies an alpha gradient to soften the transitions between geometry segments that sample different parts of the basemap. SpeedTree8Wind The SpeedTree8Wind Sub Graph Asset uses a Custom Function Node to deform the vertices of SpeedTree 8 models in response to your application’s wind data. You can use this to make trees appear to bend in the wind. Unity applies wind data to the SpeedTree8Wind Sub Graph Asset is as follows: When a WindZone affects a SpeedTree 8 GameObject that has Wind enabled, Unity generates SpeedTree 8 wind simulation data. Unity populates the SpeedTreeWind Cbuffer with that wind simulation data. The SpeedTree8Wind Sub Graph Asset bases its deformation behavior on the data in the SpeedTreeWind Cbuffer. This asset includes automated LOD vertex interpolation when LOD Fade is set to SpeedTree. However, it does not support instancing. SpeedTree8Billboard The SpeedTree8Billboard Sub Graph Asset calculates billboard normals from a SpeedTree 8 model's bump map, geometric tangent, and bitangent data. It includes dithering functionality to improve the appearance of billboards at view angles diagonal to the model. The keyword toggle associated with this feature is named EFFECT_BILLBOARD.This supports backwards compatibility with previous versions of ShaderGraph, which require keywords and their toggling properties to have identical names. SpeedTree 8 InterpolatedNormals All SpeedTree 8 shaders that Unity provides interpolate geometric normals, tangents, and bitangents in the vertex stage, because this results in a better visual appearance than the per-pixel data that Shader Graph nodes provide. You do not need to use this feature if your SpeedTree 8 Shader Graph does not include custom interpolators. HDRP and URP do not have identical backface normal transformation behavior. This can become a problem when you use Custom Interpolators for geometric normal, tangent, and bitangent data. The purpose of the SpeedTree 8 InterpolatedNormals Sub Graph Asset is to allow for that difference. It combines geometric normal data with bump maps in a way that is compatible with the target pipeline's backface normal transformation behavior."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sphere-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sphere-Mask-Node.html",
    "title": "Sphere Mask Node | Inventory System",
    "summary": "Sphere Mask Node Description Creates a sphere mask originating from input Center. The sphere is calculated using Distance and modified using the Radius and Hardness inputs. Sphere mask functionality works in both 2D and 3D spaces, and is based on the vector coordinates in the Coords input. These vector coordinates can either be 3D like world space position, or 2D like UV coordinates. Ports Name Direction Type Binding Description Coords Input Dynamic Vector None Coordinate space input Center Input Dynamic Vector None Coordinates of the sphere origin Radius Input Float None Radius of the sphere Hardness Input Float None Soften falloff of the sphere Out Output Dynamic Vector None Output mask value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SphereMask_float4(float4 Coords, float4 Center, float Radius, float Hardness, out float4 Out) { Out = 1 - saturate((distance(Coords, Center) - Radius) / (1 - Hardness)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Spherize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Spherize-Node.html",
    "title": "Spherize Node | Inventory System",
    "summary": "Spherize Node Description Applies a spherical warping effect similar to a fisheye camera lens to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Spherize_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float delta2 = dot(delta.xy, delta.xy); float delta4 = delta2 * delta2; float2 delta_offset = delta4 * Strength; Out = UV + delta * delta_offset + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Split-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Split-Node.html",
    "title": "Split Node | Inventory System",
    "summary": "Split Node Description Splits the input vector In into four Float outputs R, G, B and A. These output vectors are defined by the individual channels of the input In; red, green, blue and alpha respectively. If the input vector In's dimension is less than 4 (Vector 4) the output values not present in the input will be 0. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value R Output Float None Red channel from input G Output Float None Green channel from input B Output Float None Blue channel from input A Output Float None Alpha channel from input Generated Code Example The following example code represents one possible outcome of this node. float _Split_R = In[0]; float _Split_G = In[1]; float _Split_B = 0; float _Split_A = 0;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Split-Texture-Transform-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Split-Texture-Transform-Node.html",
    "title": "Split Texture Transform Node | Inventory System",
    "summary": "Split Texture Transform Node Description This node makes it possible to separately output tiling, offset, and texture data for a Texture 2D asset. That enables you to present an asset differently in a specific context—to warp it in a mirror, for example—and put it into the UV without modifying the original asset. This node outputs the texture with its tiling set to (0,0) and scale set to (1,1). That activates the shader property NoScaleOffset, which enables you to modify Tiling Offset values via the Material Inspector. Another term you may hear for tiling in this context is scale. Both terms refer to the size of the texture tiles. Ports Name Direction Type Description In Input Texture2D The Texture 2D Node input. Tiling Output Vector 2 Amount of tiling to apply per channel, set via the Material Inspector. Offset Output Vector 2 Amount of offset to apply per channel, set via the Material Inspector. Texture Only Output Vector 2 The input Texture2D, without tiling and offset data."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Square-Root-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Square-Root-Node.html",
    "title": "Square Root Node | Inventory System",
    "summary": "Square Root Node Description Returns the square root of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SquareRoot_float4(float4 In, out float4 Out) { Out = sqrt(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Square-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Square-Wave-Node.html",
    "title": "Square Wave Node | Inventory System",
    "summary": "Square Wave Node Description Returns a square wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SquareWave_float4(float4 In, out float4 Out) { Out = 1.0 - 2.0 * round(frac(In)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Step-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Step-Node.html",
    "title": "Step Node | Inventory System",
    "summary": "Step Node Description Per component, returns 1 if the value of input In is greater than or equal to the value of input Edge, otherwise returns 0. Ports Name Direction Type Description Edge Input Dynamic Vector Step value In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Step_float4(float4 Edge, float4 In, out float4 Out) { Out = step(Edge, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sticky-Notes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sticky-Notes.html",
    "title": "Sticky Notes | Inventory System",
    "summary": "Sticky Notes Sticky Notes are objects in a graph view that you can write in. They are the graph view equivalent of a comment in code, and consist of a title and body. You can create as many as you want in the graph, and use them for a variety of purposes, for example: To describe how a section of your graph works. To leave notes for yourself or others collaborating in your Unity Project. As a to-do list that includes tasks to complete at a later date. Using Sticky Notes To create a Sticky Note, right-click an empty space in the graph view and, in the context menu, click Create Sticky Note. You can then customize and add content to the new Sticky Note. There are two text areas that you can write in: Title: The text area at the top of the Sticky Note is the title. You can use it to concisely describe what information the Sticky Note contains. Body: The larger text area below the title area is the body. You can write the full contents of the note here. Editing text To edit text on a Sticky Note, double-click on a text area. This also selects the entire text area, so be sure to move the cursor before you edit the text. Moving and resizing You can move Sticky Notes anywhere on the graph. You can also click and drag to manually resize Sticky Notes, or have a Sticky Note automatically resize itself to fit the content. For information on how to make the Sticky Note resize itself, see Fit To Text in the Context menu section below. Duplicating Use the following keyboard shortcuts to cut, copy, paste, and duplicate Sticky Notes. Copy: Ctrl+C Cut: Ctrl+X Paste: Ctrl+V Duplicate: Ctrl+D Context menu To open the context menu for a Sticky Note, right-click anywhere on it. The options in the context menu are as follows. Option Description Dark Theme/Light Theme Toggles the color theme of the Sticky Note between light theme and dark theme. Text Size Resizes the font in the text areas to the following point values. Small Title: 20, Body: 11 Medium Title: 40, Body: 24 Large Title: 60, Body: 36 Huge Title: 80, Body: 56 Fit To Text Resizes the Sticky Note so that it precisely fits the text areas. If your title exceeds a single line, Unity resizes the Sticky Note such that title text fits on a single line. Delete Deletes the Sticky Note you selected. Group Selection Places any Sticky Notes you select in a group. Ungroup Selection Removes any Sticky Notes you select from the group."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-Graph-Dropdown-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-Graph-Dropdown-Node.html",
    "title": "Subgraph Dropdown node | Inventory System",
    "summary": "Subgraph Dropdown node The Subgraph Dropdown node is a node representation of a Dropdown property. It allows you to create a custom dropdown menu on a Subgraph node in its parent Shader Graph. You can specify the number of options that appear in the dropdown menu, and their names. After you create a Dropdown property and add a Dropdown node to a Subgraph, the Subgraph node in any parent Shader Graph displays with a dropdown control: Create Node menu category The Subgraph Dropdown node isn't accessible from the Create Node menu. To add a Subgraph Dropdown node to a Subgraph: In the Shader Graph window, open a Subgraph. In the Blackboard, select Add (+) and select Dropdown. Enter a name for your new Dropdown property, and press Enter. Select your Dropdown property and drag it onto your graph to create a new Subgraph Dropdown node. Select your new Dropdown node in your graph or the Dropdown property in the Blackboard and open the Graph Inspector. Select the Node Settings tab. In the Entries table, select Add to the list (+) to add a new option to your dropdown. Each Entry adds a corresponding input port to your node. To remove an Entry, select its handle in the list and select Remove selection from the list (-). (Optional) In the Default list, select the default Entry that you want Shader Graph to select on your property. Compatibility The Subgraph Dropdown node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes Ports Note The Subgraph Dropdown node's number of input ports and their names directly correspond to the settings you specify in the Graph Inspector's Node Settings tab. The node always has one output port. A Subgraph Dropdown node's input ports always have the DynamicVector type. This means that you can make a connection to an input port from any node that outputs a float, Vector 2, Vector 3, Vector 4, or Boolean value. For more information, see Dynamic Data Types. It has one output port: Name Type Description Out DynamicVector The selected option from the dropdown menu on the parent Shader Graph's Subgraph node. This value can also be the specified Default for the property in the Graph Inspector's Node Settings tab. Example graph usage In the following example, a Subgraph Dropdown node changes the UV channel it sends to the Subgraph's Output node. The selection on the Subgraph node in the parent graph changes whether the Subgraph outputs UV1 or UV0. If the Subgraph is used in multiple Shader Graphs, the Subgraph Dropdown node can change the UV channel output without changing the Subgraph: Related nodes The following nodes are related or similar to the Subgraph Dropdown node: Subgraph node"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph-Asset.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph-Asset.html",
    "title": "Subgraph Asset | Inventory System",
    "summary": "Subgraph Asset Description The Subgraph Asset is a new Asset type introduced with the Shader Graph. A Subgraph Asset defines a Subgraph. This is different to a Shader Graph. You can create a Subgraph Asset from the Project window from the Create menu via Subgraph in the Shader sub-menu. You can open the Shader Graph Window by double clicking a Subgraph Asset or by clicking Open Shader Editor in the Inspector when the Subgraph Asset is selected."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph-Node.html",
    "title": "Subgraph node | Inventory System",
    "summary": "Subgraph node Description Provides a reference to a Subgraph Asset. All ports on the reference node are defined by the properties and outputs defined in the Subgraph Asset. This is useful for sharing functionality between graphs or duplicating the same functionality within a graph. The preview used for a Subgraph Node is determined by the first port of that Subgraph Output node. Valid Data Types for the first port are Float, Vector 2, Vector 3, Vector 4, Matrix2, Matrix3, Matrix4, and Boolean. Any other data type will produce an error in the preview shader and the Subgraph will become invalid. Subgraph Nodes and Shader Stages If a Node within a Subgraph specifies a Shader Stage, such as how Sample Texture 2D Node specifies the fragment Shader Stage, then that entire Subgraph) is now locked to that stage. As such a Subgraph node that references the graph will also be locked to that Shader Stage. Furthermore, when an Edge connected to an output Port on a Subgraph Node flows into a port on the Master Stack that Subgraph Node is now locked to the Shader Stage of that Block Node in the Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Sub-graph.html",
    "title": "Sub Graph | Inventory System",
    "summary": "Sub Graph Description A Sub Graph is a special type of Shader Graph, which you can reference from inside other graphs. This is useful when you wish to perform the same operations multiple times in one graph or across multiple graphs. A Sub Graph differs from a Shader Graph in three main ways: Properties in the Blackboard of a Sub Graph define the input Ports of a Sub Graph Node when you reference the Sub Graph from inside another graph. A Sub Graph has its own Asset type. For more information, including instructions on how to make a new Sub Graph, see Sub Graph Asset. A Sub Graph does not have a Master Stack. Instead, it has a Node called Output. For information about the components of a Sub Graph, see Sub Graph Asset. Output Node The Output Node defines the output ports of a Sub Graph Node when you reference the Sub Graph from inside another graph. To add and remove ports, use the Custom Port Menu in the Node Settings tab of the Graph Inspector by clicking on the Sub Graph Output node. The preview used for Sub Graphs is determined by the first port of the Output Node. Valid Data Types for the first port are Float, Vector 2, Vector 3, Vector 4, Matrix2, Matrix3, Matrix4, and Boolean. Any other data type will produce an error in the preview shader and the Sub Graph will become invalid. Sub Graphs and shader stages If a Node within a Sub Graph specifies a shader stage (for example, how the Sample Texture 2D Node specifies the fragment shader stage), the Editor locks the entire Sub Graph to that stage. You cannot connect any Nodes that specify a different shader stage to the Sub Graph Output Node, and the Editor locks any Sub Graph Nodes that references the graph to that shader stage. From 10.3 onward, Texture and SamplerState type inputs and outputs to Sub Graphs benefit from an improved data structure. For a detailed explanation, see Custom Function Node. Sub Graphs and Keywords Keywords that you define on the Blackboard in a Sub Graph behave similarly to those in regular Shader Graphs. When you add a Sub Graph Node to a Shader Graph, Unity defines all Keywords in that Sub Graph in the Shader Graph as well, so that the Sub Graph works as intended. To use a Sub Graph Keyword inside a Shader Graph, or to expose that Keyword in the Material Inspector, copy it from the Sub Graph to the Shader Graph's Blackboard."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Subtract-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Subtract-Node.html",
    "title": "Subtract Node | Inventory System",
    "summary": "Subtract Node Description Returns the result of input A minus input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Subtract_float4(float4 A, float4 B, out float4 Out) { Out = A - B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Swizzle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Swizzle-Node.html",
    "title": "Swizzle Node | Inventory System",
    "summary": "Swizzle Node Description Creates a new vector from the reordered elements of the input vector. This is called swizzling. To specify how input elements should be swizzled, enter a formatting string in the input mask. To invert the order of the input elements, for example, use the string \"wzyx\" or \"abgr\". The length of the input mask determines the dimensions of the output vector. The error \"Invalid Mask\" indicates an input mask value which includes one or more channels that do not exist in the input vector. To output a vector3 with the x, y and z elements of the input vector, for example, use the input mask “xyz” or “rgb”. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Mask Inputfield x, y, z, w (depending on input vector dimension) The swizzle mask is a combination of one to four characters that can be x, y, z, w (or r, g, b, a). The size of output value depends on the length of the mask input. Generated Code Example The following example code represents one possible outcome of this node. float4 _Swizzle_Out = In.wzyx;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "About Shader Graph Getting started with Shader Graph Creating a new Shader Graph Asset My first Shader Graph Shader Graph Window Blackboard Main Preview Graph Inspector Create Node Menu Graph Settings Tab Master Stack Sticky Notes Sub Graph Color Modes Precision Modes Preview Mode Control Custom Function Node Custom Render Textures Accessing Example Shader Graph Preferences Shader Graph Project Settings Shader Graph Keyboard Shortcuts Material Variants Upgrade Guides Upgrade to Shader Graph 10.0.x Inside Shader Graph Shader Graph Asset Graph Target Sub Graph Asset SpeedTree 8 Sub Graph Assets Node Port Custom Port Menu Edge Property Types Keywords Data Types Port Bindings Shader Stage Surface options Custom Interpolators Node Library Artistic Adjustment Channel Mixer Contrast Hue Invert Colors Replace Color Saturation White Balance Blend Blend Filter Dither Fade Transition Mask Channel Mask Color Mask Normal Normal Blend Normal From Height Normal From Texture Normal Reconstruct Z Normal Strength Normal Unpack Utility Colorspace Conversion Channel Combine Flip Split Swizzle Custom Render Texture Nodes Self Size Slice Input Basic Boolean Color Constant Integer Slider Time Float Vector 2 Vector 3 Vector 4 Geometry Bitangent Vector Instance ID Normal Vector Position Screen Position Tangent Vector UV Vertex Color Vertex ID View Direction View Vector Gradient Blackbody Gradient Sample Gradient High Definition Render Pipeline Custom Color Buffer Custom Depth Buffer Diffusion Profile Exposure HD Scene Color HD Scene Depth HD Sample Buffer Lighting Ambient Baked GI Main Light Direction Reflection Probe Matrix Matrix 2x2 Matrix 3x3 Matrix 4x4 Transformation Matrix Mesh Deformation Compute Deformation Linear Blend Skinning Sprite Deformation Sprite Skinning PBR Dielectric Specular Metal Reflectance Fresnel Equation Scene Camera Eye Index Fog Object Scene Color Scene Depth Scene Depth Difference Screen Texture Calculate Level Of Detail Texture 2D Node Cubemap Asset Gather Texture 2D Node Sample Cubemap Sample Reflected Cubemap Sample Texture 2D Sample Texture 2D Array Sample Texture 2D LOD Sample Texture 3D Sample Virtual Texture Sampler State Split Texture Transform Texture 2D Array Asset Texture 2D Asset Texture 3D Asset Texture Size Math Advanced Absolute Exponential Length Log Modulo Negate Normalize Posterize Reciprocal Reciprocal Square Root Basic Add Divide Multiply Power Square Root Subtract Derivative DDX DDXY DDY Interpolation Inverse Lerp Lerp Smoothstep Matrix Matrix Construction Matrix Determinant Matrix Split Matrix Transpose Range Clamp Fraction Maximum Minimum One Minus Random Range Remap Saturate Round Ceiling Floor Round Sign Step Truncate Trigonometry Arccosine Arcsine Arctangent Arctangent2 Cosine Degrees To Radians Hyperbolic Cosine Hyperbolic Sine Hyperbolic Tangent Radians To Degrees Sine Tangent Vector Cross Product Distance Dot Product Fresnel Effect Projection Reflection Refract Rejection Rotate About Axis Sphere Mask Transform Wave Noise Sine Wave Sawtooth Wave Square Wave Triangle Wave Procedural Noise Gradient Noise Simple Noise Voronoi Shapes Ellipse Polygon Rectangle Rounded Polygon Rounded Rectangle Checkerboard Utility Logic All And Any Branch Branch On Input Connection Comparison Is Front Face Is Infinite Is NaN Nand Not Or High Definition Render Pipeline Emission Eye CirclePupilAnimation CorneaRefraction EyeSurfaceTypeDebug IrisLimbalRing IrisOffset IrisOutOfBoundColorClamp IrisUVLocation ScleraIrisBlend ScleraLimbalRing ScleraUVLocation Fabric *ThreadMapDetail UVCombine Custom Function Keyword Preview Subgraph Subgraph Dropdown node UV Flipbook Polar Coordinates Radial Shear Rotate Spherize Tiling And Offset Triplanar Twirl Parallax Mapping Parallax Occlusion Mapping Block Nodes Built In Blocks Samples Feature Examples Production Ready Shaders Lit Shaders Decal shaders Detail shaders Rock shaders Water shaders Post-process shaders Weather shaders Miscellaneous shaders Forest Stream Construction Tutorial UGUI Shaders Getting started Custom UI componenents Custom nodes Subgraph nodes Examples How tos How to create a resolution-independent shape How to create a functioning button How to make shapes that adapt to the aspect ratio of the UI element Notes on performance"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tangent-Node.html",
    "title": "Tangent Node | Inventory System",
    "summary": "Tangent Node Description Returns the tangent of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Tangent_float4(float4 In, out float4 Out) { Out = tan(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tangent-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tangent-Vector-Node.html",
    "title": "| Inventory System",
    "summary": "Description Provides access to the mesh vertex or fragment's Tangent Vector. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Mesh's Tangent Vector. Parameters Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Tangent Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-2D-Array-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-2D-Array-Asset-Node.html",
    "title": "Texture 2D Array Asset Node | Inventory System",
    "summary": "Texture 2D Array Asset Node Description Defines a constant Texture 2D Array Asset for use in the shader. To sample the Texture 2D Array Asset it should be used in conjunction with a Sample Texture 2D Array Node. When using a separate Texture 2D Array Asset Node, you can sample a Texture 2D Array twice, with different parameters, without defining the Texture 2D Array itself twice. Ports Name Direction Type Description Out Output Texture 2D Array Output value Controls Name Type Options Description Object Field (Texture 2D Array) Defines the texture 2D array asset from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE2D_ARRAY(_Texture2DArrayAsset); SAMPLER(sampler_Texture2DArrayAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-2D-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-2D-Asset-Node.html",
    "title": "Texture 2D Asset Node | Inventory System",
    "summary": "Texture 2D Asset Node Description Defines a constant Texture 2D Asset for use in the shader. To sample the Texture 2D Asset it should be used in conjunction with a Sample Texture 2D Node. When using a separate Texture 2D Asset Node, you can sample a Texture 2D twice, with different parameters, without defining the Texture 2D itself twice. Ports Name Direction Type Description Out Output Texture 2D Output value Controls Name Type Options Description Object Field (Texture) Defines the texture 3D asset from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE2D(_Texture2DAsset); SAMPLER(sampler_Texture2DAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-3D-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-3D-Asset-Node.html",
    "title": "Texture 3D Asset Node | Inventory System",
    "summary": "Texture 3D Asset Node Description Defines a constant Texture 3D Asset for use in the shader. To sample the Texture 3D Asset it should be used in conjunction with a Sample Texture 3D Node. When using a separate Texture 3D Asset Node, you can sample a Texture 3D twice, with different parameters, without defining the Texture 3D itself twice. Ports Name Direction Type Description Out Output Texture 3D Output value Controls Name Type Options Description Object Field (Texture 3D) Defines the texture 3D asset from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE3D(_Texture3DAsset); SAMPLER(sampler_Texture3DAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-Size-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Texture-Size-Node.html",
    "title": "Texture Size Node | Inventory System",
    "summary": "Texture Size Node The Texture Size node takes a Texture 2D input and returns the width and height texel resolution of the texture. It also returns the width and height size of each texel of the texture. The node uses the built in variable {texturename}_TexelSize to access the special properties of the given Texture 2D input. The term \"texel\" is short for \"texture element\" or \"texture pixel.\" It represents a single pixel in the texture. So, for example, if Texture resolution is 512x512 texels, the texture is sampled over the range [0-1] in UV space, so each texel is 1/512 x 1/512 in size in UV coordinates. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading your version of Shader Graph to version 10.3 or later. Note Don't use the default input to reference your Texture 2D, as this affects the performance of your graph. Connect a Texture 2D Asset Node to the Texture Size node's Texture input port and re-use this definition for sampling. Create Node menu category The Texture Size node is under the Input > Texture category in the Create Node menu. Compatibility The Texture Size node is compatible with all render pipelines. Ports Name Direction Type Binding Description Texture Input Texture None The Texture 2D asset to measure. Width Output Float None The width of the Texture 2D asset in texels. Height Output Float None The height of the Texture 2D asset in texels. Texel Width Output Float None The texel width of the Texture 2D asset in UV coordinates. Texel Height Output Float None The texel height of the Texture 2D asset in UV coordinates. Generated Code Example The following example code represents one possible outcome of this node. float _TexelSize_Width = Texture_TexelSize.z; float _TexelSize_Height = Texture_TexelSize.w;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/ThreadMapDetail-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/ThreadMapDetail-Node.html",
    "title": "ThreadMapDetail node | Inventory System",
    "summary": "ThreadMapDetail node The ThreadMapDetail node adds tileable thread map detail information to a fabric material. The node outputs a thread map that you can apply to a fabric material. Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph. A thread map is a Texture with 4 channels. Like a detail map, a thread map contains information about ambient occlusion, the normal x-axis and normal y-axis, and smoothness. For more information on Detail maps, see Secondary Maps (Detail Maps) & Detail Mask in the Unity User Manual. Create Node menu category The ThreadMapDetail node is under the Utility > High Definition Render Pipeline > Fabric category in the Create Node menu. Compatibility node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes For more information on the HDRP, see Unity's HDRP package documentation. node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack. Inputs node has the following input ports: Name Type Binding Description Use Thread Map Boolean None Use the port's default input to enable or disable the ThreadMapDetail node. You can also connect a node that outputs a Boolean to choose when to enable or disable the thread map. ThreadMap Texture 2D None The texture that contains the detailed information of a fabric's thread pattern. The texture should contain 4 channels: R - The ambient occlusion G - The normal Y-axis B - The smoothness A - The normal X-axis UV Vector 2 UV The UV coordinates the ThreadMapDetail node should use to map the ThreadMap texture on the geometry. Normals Vector 3 None The base normal map that you want your Shader Graph to apply to the geometry before it applies the thread map. Smoothness Float None The base smoothness value that you want your Shader Graph to apply to the geometry before it applies the thread map. Alpha Float None The base alpha value that you want your Shader Graph to apply to the geometry before it applies the thread map. Ambient Occlusion Float None The base ambient occlusion value that you want your Shader Graph to apply to the geometry before it applies the thread map. Thread AO Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's ambient occlusion should impact the final shader result: If you provide a value of 0, the ThreadMap's ambient occlusion has no effect on the final output of the shader. If you provide a value of 1, Shader Graph multiplies your base Ambient Occlusion value by the ambient occlusion value specified in your ThreadMap to determine the final output of the shader. Thread Normal Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's normal should impact the final shader result: If you provide a value of 0, the ThreadMap's normal has no effect on the final output of the shader. If you provide a value of 1, Shader Graph blends the values from your base Normals with the normal specified in your ThreadMap to determine the final output of the shader. Thread Smoothness Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's smoothness should impact the final shader result: If you provide a value of 0, the ThreadMap's smoothness value has no effect on the final output of the shader. If you provide a value of 1, Shader Graph adds the smoothness value specified in your ThreadMap to your base Smoothness value to determine the final output of the shader. For this calculation, Shader Graph remaps the value of your ThreadMap's smoothness from (0,1) to (-1, 1). Outputs node has the following output ports: Name Type Description Normal Vector 3 The final normal output of the thread map. Smoothness Float The final smoothness output of the thread map. Ambient Occlusion Float The final ambient occlusion output of the thread map. Alpha Float The final alpha output of the thread map. Shader Graph calculates this alpha value by multiplying the input Alpha value by the Thread AO Strength value. Example graph usage For an example use of the ThreadMapDetail node, see either of the HDRP's Fabric shaders. To view these Shader Graphs: Create a new material and assign it the HDRP > Fabric > Silk or HDRP > Fabric > CottonWool shader, as described in the Unity User Manual section Creating a material asset, and assigning a shader to it. Next to the Shader dropdown, select Edit. Your chosen Fabric's Shader Graph opens. You can view the ThreadMapDetail node, its Subgraph, and the other nodes that create HDRP's Fabric shaders."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tiling-And-Offset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Tiling-And-Offset-Node.html",
    "title": "Tiling And Offset Node | Inventory System",
    "summary": "Tiling And Offset Node Description Tiles and offsets the value of input UV by the inputs Tiling and Offset respectively. This is commonly used for detail maps and scrolling textures over Time. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Tiling Input Vector 2 None Amount of tiling to apply per channel Offset Input Vector 2 None Amount of offset to apply per channel Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_TilingAndOffset_float(float2 UV, float2 Tiling, float2 Offset, out float2 Out) { Out = UV * Tiling + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Time-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Time-Node.html",
    "title": "Time Node | Inventory System",
    "summary": "Time Node Description Provides access to various Time parameters in the shader. Ports Name Direction Type Binding Description Time Output Float None Time value Sine Time Output Float None Sine of Time value Cosine Time Output Float None Cosine of Time value Delta Time Output Float None Current frame time Smooth Delta Output Float None Current frame time smoothed Generated Code Example The following example code represents one possible outcome of this node. float Time_Time = _Time.y; float Time_SineTime = _SinTime.w; float Time_CosineTime = _CosTime.w; float Time_DeltaTime = unity_DeltaTime.x; float Time_SmoothDelta = unity_DeltaTime.z;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Transform-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Transform-Node.html",
    "title": "Transform Node | Inventory System",
    "summary": "Transform Node Description Returns the result of transforming the input value (In) from one coordinate space to another. Select dropdown options on the node to define which spaces to transform from and to. Ports Name Direction Type Description In Input Vector 3 Input value Out Output Vector 3 Output value Controls Name Type Options Description From Dropdown Object, View, World, Tangent, Absolute World, Screen Select the space to convert from. To Dropdown Object, View, World, Tangent, Absolute World, Screen Select the space to convert to. Type Dropdown Position, Direction, Normal Select how you want to handle the conversion. Node Settings Controls The following control appears on the Node Settings tab of the Graph Inspector when you select the Direction or Normal conversion types for the Transform Node. The Normalize Output setting helps to improve performance as you can disable it if the output is already normalized, or if you don't need the output to remain normalized. Name Type Description Normalize Output Checkbox Reduces the length of the output vector to 1. World and Absolute World Use the World and Absolute World space options to transform the coordinate space of position values. The World space option uses the Scriptable Render Pipeline default world space to convert position values. The Absolute World space option uses absolute world space to convert position values in all Scriptable Render Pipelines. If you use the Transform Node to convert coordinate spaces that aren't for position values, Unity recommends that you use the World space option. Using Absolute World on values that don't represent position might result in unexpected behavior. Conversion type Select the Position type to apply translation to the transformation. Select Direction if the input doesn't describe a surface normal (the direction a surface faces). Select Normal if the input describes a surface normal (the direction the surface faces). Generated Code Example The following example code represents one possible outcome of this node per Base mode. World > World float3 _Transform_Out = In; World > Object float3 _Transform_Out = TransformWorldToObject(In); World > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(In, tangentTransform_World); World > View float3 _Transform_Out = TransformWorldToView(In); World > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(In); World > Screen float4 hclipPosition = TransformWorldToHClipDir(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Object > World float3 _Transform_Out = TransformObjectToWorld(In); Object > Object float3 _Transform_Out = In; Object > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(TransformObjectToWorld(In), tangentTransform_World); Object > View float3 _Transform_Out = TransformWorldToView(TransformObjectToWorld(In)); Object > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(TransformObjectToWorld(In)); Object > Screen float4 hclipPosition = TransformObjectToHClip(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Tangent > World float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = mul(In, transposeTangent).xyz; Tangent > Object float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = TransformWorldToObject(mul(In, transposeTangent).xyz); Tangent > Tangent float3 _Transform_Out = In; Tangent > View float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = TransformWorldToView(mul(In, transposeTangent).xyz); Tangent > Absolute World float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = GetAbsolutePositionWS(mul(In, transposeTangent)).xyz; Tangent > Screen float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float4 hclipPosition = TransformWorldToHClipDir(mul(In, transposeTangent).xyz); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); View > World float3 _Transform_Out = mul(UNITY_MATRIX_I_V, float4(In, 1)).xyz; View > Object float3 _Transform_Out = TransformWorldToObject(mul(UNITY_MATRIX_I_V, float4(In, 1) ).xyz); View > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(mul(UNITY_MATRIX_I_V, float4(In, 1) ).xyz, tangentTransform_World); View > View float3 _Transform_Out = In; View > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(mul(UNITY_MATRIX_I_V, float4(In, 1))).xyz; View > Screen float4 hclipPosition = TransformWViewToHClip(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Absolute World > World float3 _Transform_Out = GetCameraRelativePositionWS(In); Absolute World > Object float3 _Transform_Out = TransformWorldToObject(In); Absolute World > Object (in the High Definition Render Pipeline) float3 _Transform_Out = TransformWorldToObject(GetCameraRelativePositionWS(In)); Absolute World > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(In, tangentTransform_World); Absolute World > View float3 _Transform_Out = GetCameraRelativePositionWS(In) Absolute World > Absolute World float3 _Transform_Out = In; Absolute World > Screen float4 hclipPosition = TransformWorldToHClip(GetCameraRelativePositionWS(In)); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Screen > World float3 _Transform_Out = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); Screen > Object float3 worldPos = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); float3 _Transform_Out = TransformWorldToObject(worldPos); Screen > Tangent float3 worldPos = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(worldPos, tangentTransform_World); Screen > View float4 positionCS = ComputeClipSpacePosition(In.xy, In.z); float4 result = mul(UNITY_MATRIX_I_V, positionCS); float3 _Transform_Out = result.xyz / result.w; Screen > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP));"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Transformation-Matrix-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Transformation-Matrix-Node.html",
    "title": "Transformation Matrix Node | Inventory System",
    "summary": "Transformation Matrix Node Description Defines a constant Matrix 4x4 value for a common Transformation Matrix in the shader. The Transformation Matrix can be selected from the dropdown parameter. Two output value options for this node, Inverse Projection and Inverse View Projection, are not compatible with the Built-In Render Pipeline target. When you choose either of these options and target the Built-In Render Pipeline, this node produces an entirely black result. Ports Name Direction Type Binding Description Out Output Matrix 4 None Output value Controls Name Type Options Description Dropdown Model, InverseModel, View, InverseView, Projection, InverseProjection, ViewProjection, InverseViewProjection Sets output value Generated Code Example The following example code represents one possible outcome of this node per mode. Model float4x4 _TransformationMatrix_Out = UNITY_MATRIX_M; InverseModel float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_M; View float4x4 _TransformationMatrix_Out = UNITY_MATRIX_V; InverseView float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_V; Projection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_P; InverseProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_P; ViewProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_VP; InverseViewProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_VP;"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Triangle-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Triangle-Wave-Node.html",
    "title": "Triangle Wave Node | Inventory System",
    "summary": "Triangle Wave Node Description Returns a triangle wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_TriangleWave_float4(float4 In, out float4 Out) { Out = 2.0 * abs( 2 * (In - floor(0.5 + In)) ) - 1.0; }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Triplanar-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Triplanar-Node.html",
    "title": "Triplanar Node | Inventory System",
    "summary": "Triplanar Node Description Generates UVs and samples a texture by projecting in world space. This method is commonly used to texture large models such as terrain, where hand authoring UV coordinates would either be problematic or not performant. Samples the input Texture 3 times, once in each of the world x, y, and z axes. The resulting information is planar projected onto the model, blended by the normal, or surface angle. You can scale the generated UVs with the input Tile and you can control the final blending strength with the input Blend. Blend controls the way the normal affects the blending of each plane sample and should be greater than or equal to 0. The larger Blend is, the more contribution will be given to the sample from the plane towards which the normal is most oriented. (The maximum blend exponent is between 17 and 158 depending on the platform and the precision of the node.) A Blend of 0 makes each plane get equal weight regardless of normal orientation. To choose the projection, change the Input Space. You can also modify the projection via the inputs Position and Normal. Use the Type dropdown to change the expected type of the input Texture. If set to Normal, the Out port returns the blended normals in Normal Output Space. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, upgrade to version 10.3 or later. NOTE: You can only use the Triplanar Node in the Fragment shader stage. Ports Name Direction Type Binding Description Texture Input Texture None Input texture value Sampler Input Sampler State None Sampler for input Texture Position Input Vector 3 Input Space Position Fragment position Normal Input Vector 3 Input Space Normal Fragment normal Tile Input Float None Tiling amount for generated UVs Blend Input Float None Blend factor between different samples Out Output Vector 4 None Output value Controls Name Type Options Description Type Dropdown Default, Normal Type of input Texture Node Settings Controls The following controls appear on the Node Settings tab of the Graph Inspector, when you select the Triplanar Node. Name Type Options Description Input Space Dropdown Object, View, World, Tangent, AbsoluteWorld Controls the coordinate space used by the input ports Position and Normal. When you change the Input Space value, it changes the bindings on the Position and Normal ports to use the specified space. The default value is AbsoluteWorld. Normal Output Space Dropdown Object, View, World, Tangent, AbsoluteWorld Controls the coordinate space used for the Out port. The Normal Output Space control is only available when Type is set to Normal. The default value is Tangent. Generated Code Example The following example code represents one possible outcome of this node. Default float3 Node_UV = Position * Tile; float3 Node_Blend = pow(abs(Normal), Blend); Node_Blend /= dot(Node_Blend, 1.0); float4 Node_X = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.zy); float4 Node_Y = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xz); float4 Node_Z = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xy); float4 Out = Node_X * Node_Blend.x + Node_Y * Node_Blend.y + Node_Z * Node_Blend.z; Normal float3 Node_UV = Position * Tile; float3 Node_Blend = max(pow(abs(Normal), Blend), 0); Node_Blend /= (Node_Blend.x + Node_Blend.y + Node_Blend.z ).xxx; float3 Node_X = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.zy)); float3 Node_Y = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xz)); float3 Node_Z = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xy)); Node_X = float3(Node_X.xy + Normal.zy, abs(Node_X.z) * Normal.x); Node_Y = float3(Node_Y.xy + Normal.xz, abs(Node_Y.z) * Normal.y); Node_Z = float3(Node_Z.xy + Normal.xy, abs(Node_Z.z) * Normal.z); float4 Out = float4(normalize(Node_X.zyx * Node_Blend.x + Node_Y.xzy * Node_Blend.y + Node_Z.xyz * Node_Blend.z), 1); float3x3 Node_Transform = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); Out.rgb = TransformWorldToTangent(Out.rgb, Node_Transform);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Truncate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Truncate-Node.html",
    "title": "Truncate Node | Inventory System",
    "summary": "Truncate Node Description Returns the integer, or whole number, component of the value of input In. For example, given an input value of 1.7, this node will return the value 1.0. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Truncate_float4(float4 In, out float4 Out) { Out = trunc(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Twirl-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Twirl-Node.html",
    "title": "Twirl Node | Inventory System",
    "summary": "Twirl Node Description Applies a twirl warping effect similar to a black hole to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Twirl_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float angle = Strength * length(delta); float x = cos(angle) * delta.x - sin(angle) * delta.y; float y = sin(angle) * delta.x + cos(angle) * delta.y; Out = float2(x + Center.x + Offset.x, y + Center.y + Offset.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UV-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UV-Node.html",
    "title": "UV Node | Inventory System",
    "summary": "UV Node Description Provides access to the mesh vertex or fragment's UV coordinates. The coordinate channel of the output value can be selected with the Channel dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 4 None Mesh's UV coordinates. Controls Name Type Options Description Channel Dropdown UV0, UV1, UV2, UV3 Selects coordinate channel of UV to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UV-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UV-Nodes.html",
    "title": "UV Nodes | Inventory System",
    "summary": "UV Nodes Flipbook Polar Coordinates Creates a flipbook, or texture sheet animation, of the UVs supplied to input In. Converts the value of input UV to polar coordinates. Radial Shear Rotate Applies a radial shear warping effect similar to a wave to the value of input UV. Rotates the value of input UV around a reference point defined by input Center by the amount of input Rotation. Spherize Tiling and Offset Applies a spherical warping effect similar to a fisheye camera lens to the value of input UV. Tiles and offsets the value of input UV by the inputs Tiling and Offset respectively. Triplanar Twirl A method of generating UVs and sampling a texture by projecting in world space. Applies a twirl warping effect similar to a black hole to the value of input UV. Parallax Mapping Parallax Occlusion Mapping Creates a parallax effect that displaces a material's UVs. Creates a parallax effect that displaces a material's UVs and depth."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UVCombine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/UVCombine-Node.html",
    "title": "UVCombine node | Inventory System",
    "summary": "UVCombine node The UVCombine node lets you select which UV channel you want to use for mapping your shader to geometry in your application. You can also choose to apply tiling and offset to your UV coordinates. Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph. Create Node menu category The UVCombine node is under the Utility > High Definition Render Pipeline category in the Create Node menu. Compatibility node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes For more information on the HDRP, see Unity's HDRP package documentation. node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack. Inputs node has the following input ports: Name Type Description UV Channel Mask Vector 4 Select which UV channel you want to use for your UV coordinates by entering a 1 in the corresponding default input on the port: X: UV channel 0 Y: UV channel 1 Z: UV channel 2 W: UV channel 3 Set all other default inputs to 0. You can also connect a node that outputs a Vector 4. UV Tile and Offset Vector 4 Use the port's default input to specify the amount of offset or tiling that you want to apply to your shader's UV coordinates: Use X and Y to specify the tiling. Use W and Z to specify the offset. You can also connect a node that outputs a Vector 4. Outputs node has one output port: Name Type Binding Description UV Vector 2 UV The final UV output, after selecting a UV channel and, if specified, any tiling or offset. Example graph usage For an example use of the UVCombine node, see either of the HDRP's Fabric shaders. To view these Shader Graphs: Create a new material and assign it the HDRP > Fabric > Silk or HDRP > Fabric > CottonWool shader, as described in the Unity User Manual section Creating a material asset, and assigning a shader to it. Next to the Shader dropdown, select Edit. Your chosen Fabric's Shader Graph opens. You can view the UVCombine node, its Subgraph, and the other nodes that create HDRP's Fabric shaders."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Upgrade-Guide-10-0-x.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Upgrade-Guide-10-0-x.html",
    "title": "Upgrade to version 10.0.x of Shader Graph | Inventory System",
    "summary": "Upgrade to version 10.0.x of Shader Graph Renamed Vector 1 property and Float precision Shader Graph has renamed the Vector 1 property as Float in both the Vector 1 node and the exposed parameter list. The Float precision was also renamed as Single. Behavior is exactly the same, and only the names have changed. Renamed Sample Cubemap Node Shader Graph has renamed the previous Sample Cubemap Node to Sample Reflected Cubemap Node, and has added a new Sample Cubemap Node, which uses world space direction. Master Stack graph output Shader Graph has removed the Master Nodes and introduced a more flexible Master Stack solution for defining graph output in 10.0. You can still open all graphs created in previous versions, because Shader Graph automatically upgrades them. This page describes the expected behavior and explains when you might need to perform manual upgrade steps. Automatic upgrade from Master Nodes Upgrade one Master Node to the Master Stack If your graph only has one Master Node, Shader Graph automatically upgrades all of the data from that Master Node to a Master Stack output, as described in this section. Shader Graph automatically adds the correct Targets to the Graph Settings tab of the Graph Inspector. It also copies all settings from the Master Node settings menu (gear icon) that describe surface options from the Master Node to the Target Settings. Shader Graph then adds a Block node for each port on the Master Node to the Master Stack. It connects any nodes that you connected to the Master Node ports to the corresponding Block node. Also, Shader Graph copies any values that you entered into the default value inputs of the Master Node ports to the corresponding Block node. After this upgrade process, the final shader is identical in appearance. Upgrade multiple Master Nodes to the Master Stack If your graph has more than one Master Node, Shader Graph applies the above process for automatically upgrading one Master Node to the currently selected Active Master Node. When you upgrade to the Master Stack format, Shader Graph removes any inactive Master Nodes from your graph, and you might lose this data. If you plan to upgrade a graph with multiple Master Nodes, it's best practice to keep a record of the ports, connected nodes, and any non-default settings in the settings menu (gear icon) of inactive Master Nodes. After the upgrade, you can add any required Block nodes that went missing, and reconnect the nodes to the Master Stack. You also need to go to the Graph Inspector > Graph Settings tab > settings menu (gear icon), and manually enter the settings for inactive Master Nodes in the corresponding Target Setting. Upgrade cross-pipeline Master Nodes to the Master Stack If your graph contains PBR or Unlit Master Nodes that are compatible with both the Universal Render Pipeline (URP) and the High Definition Render Pipeline (HDRP), Shader Graph automatically upgrades them to the Master Stack based on the render pipeline currently available in your project. With Master Stacks, when you switch from one render pipeline to another, you must reimport your Shader Graph assets to update the Material Inspector for any Materials in your project. In URP, you can now find all PBR Master Node settings in the URP Lit Target. The Unlit Master Node settings are in the URP Unlit Target. These settings are the same, and the final shader should appear the same as before the upgrade. In HDRP, settings from the PBR and Unlit Master Nodes are not the same as the HDRP Lit and Unlit Targets. Thus, there might be unexpected behavior when you upgrade PBR or Unlit Master Nodes to HDRP Lit and Unlit Master Stacks. The final shader might not appear the same as before the upgrade. When this happens, you can use the Bug Reporter to submit your upgrade issue, but keep in mind that some upgrade paths don't have immediate automated solutions and will require manual adjustments. \"View Generated Shader\" has moved Previously, you could right-click the Master Node to bring up a context menu, and select View Generated Shader to preview the generated shader. In 10.0, you must now use the Unity Inspector, and click the View Generated Shader button on the Shader Graph asset. Settings in Graph Inspector Shader Graph introduced an internal Graph Inspector in version 10.0. The Graph Inspector is a floating window that displays settings related to objects you select in the graph. Graph settings Graph-wide settings are now available only in the Graph Inspector's Graph Settings tab. Most notably, you can now go to the Graph Settings tab to access the Precision toggle, which was previously located on the Shader Graph Toolbar. There were no changes to data, and things like the Precision setting of the graph remain the same. In the Graph Settings tab, you can also find settings that describe surface options for each Target, which were previously located in the Master Node cog menu. For more information about how Shader Graph automatically upgrades this data, see Automatic upgrade from Master Nodes above. Property settings Property settings that were previously in Blackboard foldouts are now available in the Graph Inspector. You can now select multiple properties from the Blackboard and edit them all at the same time. There were no changes to data, and all settings you made on properties of the graph remain the same. Per-Node settings All per-node settings that you previously managed by opening a settings (gear icon) sub-menu are now accessible through the Graph Inspector. There were no changes to data, and all settings you previously set on nodes, such as precision settings and Custom Function Node settings, remain the same. Any settings on the Master Node that define surface options are now located in the Graph Inspector’s Graph Settings tab. For more information, see Automatic upgrade from Master Nodes above. Custom Function Nodes and Shader Graph Preview To avoid errors in the preview shader compilation for Custom Function Nodes, you might need to use keywords for the in-graph preview rendering. If you have any Custom Function Nodes with custom Shader Graph Preview code that uses #if SHADERGAPH_PREVIEW, you need to upgrade it to an #ifdef declaration, as follows. #ifdef SHADERGAPH_PREVIEW Out = 1; #else Out = MainLight; #endif Deprecated node and property behaviors Previously, some nodes and properties such as the Color Node didn't behave as intended, but they now work correctly in Shader Graph version 10.0. Older graphs that rely on the incorrect behavior still function the same as before, and you can choose to individually upgrade any deprecated nodes and properties. If you don't enable Allow Deprecated Behaviors in Shader Graph Preferences, newly-created nodes and properties use the latest version node and property behaviors. For deprecated nodes, (Deprecated) appears after the node title in the main graph view. For deprecated properties, (Deprecated) appears after the property name in the Blackboard. When you select a deprecated node or property, a warning appears in the Internal Inspector along with an Update button that allows you to upgrade the selection. You can use undo/redo to reverse this upgrade process. If you enable Allow Deprecated Behaviors in Shader Graph Preferences, Shader Graph displays the version of the deprecated node or property, and doesn't display any warnings even though the Update button appears. You can also use the Blackboard or Searcher to create deprecated nodes and properties."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Utility-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Utility-Nodes.html",
    "title": "Utility Nodes | Inventory System",
    "summary": "Utility Nodes Preview Sub-Graph Provides a preview window and passes the input value through without modification. Provides a reference to a Sub-graph asset. Logic All And Returns true if all components of the input In are non-zero. Returns true if both the inputs A and B are true. Any Branch Returns true if any of the components of the input In are non-zero. Provides a dynamic branch to the shader. Comparison Is Infinite Compares the two input values A and B based on the condition selected on the dropdown. Returns true if any of the components of the input In is an infinite value. Is NaN Nand Returns true if any of the components of the input In is not a number (NaN). Returns true if both the inputs A and B are false. Not Or Returns the opposite of input In. If In is true, the output is false. Otherwise, it returns true. Returns true if either input A or input B is true."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-2-Node.html",
    "title": "Vector 2 Node | Inventory System",
    "summary": "Vector 2 Node Description Defines a Vector 2 value in the shader. If Ports X and Y are not connected with Edges this Node defines a constant Vector 2, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Out Output Vector 2 None Output value Generated Code Example The following example code represents one possible outcome of this node. float2 _Vector2_Out = float2(X, Y);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-3-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-3-Node.html",
    "title": "Vector 3 Node | Inventory System",
    "summary": "Vector 3 Node Description Defines a Vector 3 value in the shader. If Ports X, Y and Z are not connected with Edges this Node defines a constant Vector 3, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Z Input Float None Input z component value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. float3 _Vector3_Out = float3(X, Y, Z);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-4-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vector-4-Node.html",
    "title": "Vector 4 Node | Inventory System",
    "summary": "Vector 4 Node Description Defines a Vector 4 value in the shader. If Ports X, Y, Z and W are not connected with Edges this Node defines a constant Vector 4, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Z Input Float None Input z component value W Input Float None Input w component value Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _Vector4_Out = float4(X, Y, Z, W);"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vertex-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vertex-Color-Node.html",
    "title": "Vertex Color Node | Inventory System",
    "summary": "Vertex Color Node Description Provides access to the mesh vertex or fragment's Vertex Color value. Ports Name Direction Type Binding Description Out Output Vector 4 None Vertex Color for the Mesh Vertex/Fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vertex-ID-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Vertex-ID-Node.html",
    "title": "Vertex ID Node | Inventory System",
    "summary": "Vertex ID Node Description Provides access to the mesh vertex or fragment's Vertex ID value. Ports Name Direction Type Binding Description Out Output Float None Vertex ID for the Mesh Vertex/Fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/View-Direction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/View-Direction-Node.html",
    "title": "View Direction Node | Inventory System",
    "summary": "View Direction Node Description Provides access to the mesh vertex or fragment's View Direction vector. This is the vector from the vertex or fragment to the camera. Select a Space to modify the coordinate space of the output value. Prior to version 11.0, the View Direction Node works differently in HDRP than in URP. In URP, it only stored Object space vectors normalized. HDRP stores all vectors normalized. From 11.0 onwards, this node stores all vectors normalized in both the High-Definition Render Pipeline and the Universal Render Pipeline. If you want to keep using the old behavior in URP outside of object space, replace this node with a View Vector Node. Ports Name Direction Type Binding Description Out Output Vector 3 None View Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of View Direction to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/View-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/View-Vector-Node.html",
    "title": "View Vector Node | Inventory System",
    "summary": "View Vector Node Description This node provides access to an unnormalized version of the mesh vertex or fragment's View Direction vector. It does not normalize any of the values it stores. For a normalized option, see View Direction Node. Select a Space to modify the output value's coordinate space. Ports Name Direction Type Binding Description Out Output Vector 3 None View Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of View Direction to output."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Voronoi-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/Voronoi-Node.html",
    "title": "Voronoi Node | Inventory System",
    "summary": "Voronoi Node Description Generates a Voronoi, or Worley, noise based on input UV. Voronoi noise is generated by calculating distances between a pixel and a lattice of points. By offsetting these points by a pseudo-random number, controlled by input Angle Offset, a cluster of cells can be generated. The scale of these cells, and the resulting noise, is controlled by input Cell Density. The output Cells contains the raw cell data. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Voronoi node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Angle Offset Input Float None Offset value for points Cell Density Input Float None Density of cells generated Out Output Float None Output noise value Cells Output Float None Raw cell data Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacySine Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. inline float2 unity_voronoi_noise_randomVector (float2 UV, float offset) { float2x2 m = float2x2(15.27, 47.63, 99.41, 89.98); UV = frac(sin(mul(UV, m)) * 46839.32); return float2(sin(UV.y*+offset)*0.5+0.5, cos(UV.x*offset)*0.5+0.5); } void Unity_Voronoi_float(float2 UV, float AngleOffset, float CellDensity, out float Out, out float Cells) { float2 g = floor(UV * CellDensity); float2 f = frac(UV * CellDensity); float t = 8.0; float3 res = float3(8.0, 0.0, 0.0); for(int y=-1; y<=1; y++) { for(int x=-1; x<=1; x++) { float2 lattice = float2(x,y); float2 offset = unity_voronoi_noise_randomVector(lattice + g, AngleOffset); float d = distance(lattice + offset, f); if(d < res.x) { res = float3(d, offset.x, offset.y); Out = res.x; Cells = res.y; } } } }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/White-Balance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/White-Balance-Node.html",
    "title": "White Balance Node | Inventory System",
    "summary": "White Balance Node Description Adjusts the temperature and tint of input In by the amount of inputs Temperature and Tint respectively. Temperature has the effect of shifting the values towards yellow or blue. Tint has the effect of shifting towards pink or green. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Temperature Input Float None Temperature offset value Tint Input Float None Tint offset value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_WhiteBalance_float(float3 In, float Temperature, float Tint, out float3 Out) { // Range ~[-1.67;1.67] works best float t1 = Temperature * 10 / 6; float t2 = Tint * 10 / 6; // Get the CIE xy chromaticity of the reference white point. // Note: 0.31271 = x value on the D65 white point float x = 0.31271 - t1 * (t1 < 0 ? 0.1 : 0.05); float standardIlluminantY = 2.87 * x - 3 * x * x - 0.27509507; float y = standardIlluminantY + t2 * 0.05; // Calculate the coefficients in the LMS space. float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65 white point // CIExyToLMS float Y = 1; float X = Y * x / y; float Z = Y * (1 - x - y) / y; float L = 0.7328 * X + 0.4296 * Y - 0.1624 * Z; float M = -0.7036 * X + 1.6975 * Y + 0.0061 * Z; float S = 0.0030 * X + 0.0136 * Y + 0.9834 * Z; float3 w2 = float3(L, M, S); float3 balance = float3(w1.x / w2.x, w1.y / w2.y, w1.z / w2.z); float3x3 LIN_2_LMS_MAT = { 3.90405e-1, 5.49941e-1, 8.92632e-3, 7.08416e-2, 9.63172e-1, 1.35775e-3, 2.31082e-2, 1.28021e-1, 9.36245e-1 }; float3x3 LMS_2_LIN_MAT = { 2.85847e+0, -1.62879e+0, -2.48910e-2, -2.10182e-1, 1.15820e+0, 3.24281e-4, -4.18120e-2, -1.18169e-1, 1.06867e+0 }; float3 lms = mul(LIN_2_LMS_MAT, In); lms *= balance; Out = mul(LMS_2_LIN_MAT, lms); }"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/api_index.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/api_index.html",
    "title": "Shader Graph scripting API | Inventory System",
    "summary": "Shader Graph scripting API This is the documentation for the scripting APIs of the Shader Graph package."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/index.html",
    "title": "About Shader Graph | Inventory System",
    "summary": "About Shader Graph Description Shader Graph enables you to build shaders visually. Instead of writing code, you create and connect nodes in a graph framework. Shader Graph gives instant feedback that reflects your changes, and it’s simple enough for users who are new to shader creation. For an introduction to Shader Graph, see Getting Started. Shader Graph is available through the Package Manager window in supported versions of the Unity Editor. If you install a Scriptable Render Pipeline (SRP) such as the Universal Render Pipeline (URP) or the High Definition Render Pipeline (HDRP), Unity automatically installs Shader Graph in your project. Shader Graph package versions on Unity Engine 2018.x are Preview versions, which do not receive bug fixes and feature maintenance. To work with an actively supported version of Shader Graph, use Unity Engine 2019.1 or higher. SRP packages are part of the core With the release of Unity 2021.1, graphics packages are relocating to the core of Unity. This move simplifies the experience of working with new Unity graphics features, as well as ensuring that your projects are always running on the latest verified graphics code. For each release of Unity (alpha / beta / patch release) graphics packages are embedded within the main Unity installer. When you install the latest release of Unity, you also get the latest Universal Render Pipeline (URP), High Definition Render Pipeline (HDRP), Shader Graph, Visual Effect (VFX) Graph packages, among others. Tying graphics packages to the main Unity release allows better testing to ensure that the graphics packages you use have been tested extensively with the version of Unity you have downloaded. You can also use a local copy or a custom version of the graphics packages with an override in the manifest file. For more information, see the following post on the forum: SRP v11 beta is available now."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/materialvariant-SG.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/materialvariant-SG.html",
    "title": "Material Variants | Inventory System",
    "summary": "Material Variants When you create materials in a project, you might want to create variations based on a single material: outfits with different color schemes, damaged and undamaged versions of scenery, or shiny and weathered instances of props. You can use Material Variants to manage these variations. For more information on Material Variants in Unity, see Material Variants in the Unity User Manual. You can create a Material Variant from any Shader Graph material. For more information on how to create a Material Variant, see Create, modify, and apply Material Variants in the User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/hdrp-latest-link.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/hdrp-latest-link.html",
    "title": "hdrp-latest-link | Inventory System",
    "summary": "For more information on the HDRP, see Unity's HDRP package documentation."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-additional-settings.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-additional-settings.html",
    "title": "nodes-additional-settings | Inventory System",
    "summary": "node has some additional settings that you can access from the Graph Inspector:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-all-contexts.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-all-contexts.html",
    "title": "nodes-all-contexts.md | Inventory System",
    "summary": "node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-compatibility-all.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-compatibility-all.html",
    "title": "nodes-compatibility-all | Inventory System",
    "summary": "node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-compatibility-hdrp.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-compatibility-hdrp.html",
    "title": "nodes-compatibility-hdrp | Inventory System",
    "summary": "node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-controls.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-controls.html",
    "title": "nodes-controls | Inventory System",
    "summary": "node has the following controls:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-fragment-only.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-fragment-only.html",
    "title": "nodes-fragment-only | Inventory System",
    "summary": "node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-generated-code.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-generated-code.html",
    "title": "nodes-generated-code | Inventory System",
    "summary": "The following code represents this node in Unity's shader code"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-inputs.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-inputs.html",
    "title": "nodes-inputs | Inventory System",
    "summary": "node has the following input ports:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-outputs.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-outputs.html",
    "title": "nodes-outputs | Inventory System",
    "summary": "node has the following output ports:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-related.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-related.html",
    "title": "nodes-related | Inventory System",
    "summary": "The following nodes are related or similar to the"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-control.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-control.html",
    "title": "nodes-single-control | Inventory System",
    "summary": "node has one control:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-input.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-input.html",
    "title": "nodes-single-input | Inventory System",
    "summary": "node has one input port:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-output.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-single-output.html",
    "title": "nodes-single-output | Inventory System",
    "summary": "node has one output port:"
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-subgraph-node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/nodes-subgraph-node.html",
    "title": "nodes-subgraph-node | Inventory System",
    "summary": "Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-errors.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-errors.html",
    "title": "nodes-sample-errors | Inventory System",
    "summary": "Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-fragment-lod.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-fragment-lod.html",
    "title": "nodes-sample-fragment-lod | Inventory System",
    "summary": "With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-mip-bias-sample-mode-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-mip-bias-sample-mode-table.html",
    "title": "nodes-sample-mip-bias-sample-mode-table.md | Inventory System",
    "summary": "Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-mip-mode-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-mip-mode-table.html",
    "title": "nodes-sample-mip-mode-table | Inventory System",
    "summary": "LOD Float LOD NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, see Additional Node Settings. The specific mip that the node uses when sampling the Texture. Bias Float Bias NOTE The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, see Additional Node Settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDX NOTE The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, see Additional Node Settings. The specific DDX value to use to calculate the Texture's mip when sampling. For more information on DDX values for mipmaps, see Mipmaps introduction in the Unity User Manual.. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, see Additional Node Settings. The specific DDY value to use to calculate the Texture's mip when sampling. For more information on DDY values for mipmaps, see Mipmaps introduction in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-rgba-output-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sample-nodes/nodes-sample-rgba-output-table.html",
    "title": "nodes-sample-rgba-output-table | Inventory System",
    "summary": "Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sg-node-fragment-only.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/snippets/sg-node-fragment-only.html",
    "title": "node-fragment-only | Inventory System",
    "summary": "node can only connect to a Block node in the Fragment Context of your Shader Graph. For more information on Block nodes and Contexts, see Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/surface-options.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/Documentation~/surface-options.html",
    "title": "Modify surface options without changing your graph | Inventory System",
    "summary": "Modify surface options without changing your graph Description Enable Allow Material Override to modify a specific set of properties for Universal Render Pipeline Lit and Unlit Shader Graphs and for Built-In Render Pipeline Shader Graphs in the Material Inspector. Property URP Lit URP Unlit Built-In Render Pipeline Workflow Mode See the URP documentation for the Lit URP Shader. Not applicable. Not applicable. Receive Shadows Cast Shadows This property is only exposed if Allow Material Override is enabled for this Shader Graph. Enable this property to make it possible for a GameObject using this shader to cast shadows onto itself and other GameObjects. This corresponds to the SubShader Tag ForceNoShadowCasting. Not applicable. Surface Type See the URP documentation for the Lit and Unlit Shaders. In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Render Face In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Alpha Clipping In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Depth Write This property is only exposed if Allow Material Override is enabled for this Shader Graph. Use this property to determine whether the GPU writes pixels to the depth buffer when it uses this shader to render geometry. Options: Auto (default): Unity writes pixels to the depth buffer for opaque materials, but not for transparent materials. Force Enabled Unity always writes pixels to the depth buffer. Force Disabled Unity never writes pixels to the depth buffer. This option's functionality corresponds to the command ZWrite in ShaderLab. To override this setting in a RenderStateBlock, set the depthState. Depth Test This property is only exposed if Allow Material Override is enabled for this Shader Graph. Use this property to set the conditions under which pixels pass or fail depth testing. The GPU does not draw pixels that fail a depth test. If you choose anything other than LEqual (the default setting for this property), consider also changing the rendering order of this material. Options: LEqual (default): Unity draws the pixel, if its depth value is less than or equal to the value on the depth texture. Less: Unity draws pixels of the affected surface if their coordinates are less than the current depth buffer value. Never: Unity never draws the pixels of the affected surface. Less: Unity draws pixels of the affected surface if their coordinates are less than the current depth buffer value. Greater: Unity draws pixels of the affected surface if their coordinates are greater than the current depth buffer value. GEqual: Unity draws pixels of the affected surface if their coordinates are greater than or equal to the current depth buffer value. Equal: Unity draws pixels of the affected surface if their coordinates are equal to the current depth buffer value. NotEqual: Unity draws pixels of the affected surface if their coordinates are not the same as the current depth buffer value. Always: Unity draws this surface to your screen regardless of its z-coordinate. This option's functionality corresponds to the command ZTest in ShaderLab. To override this setting in a RenderStateBlock, set the depthState property. Support VFX Graph This property is only available if the Visual Effect Graph package is installed. Indicates whether this Shader Graph supports the Visual Effect Graph. If you enable this property, output contexts can use this Shader Graph to render particles. The internal setup that Shader Graph does to support visual effects happens when Unity imports the Shader Graph. This means that if you enable this property, but don't use the Shader Graph in a visual effect, there is no impact on performance. It only affects the Shader Graph import time. Not applicable. How to use To use the Material Override feature: Create a new graph in Shader Graph. Save this graph. Open the Graph Inspector. Set Active Targets to Universal or Built In. In the Graph Inspector’s Universal or Built In section, enable Allow Material Override. Create or select a Material or GameObject which uses your Shader Graph. In the Material Inspector, modify Surface Options for the target Material or GameObject."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.shadergraph copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/README.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@052d95cfe62a/README.html",
    "title": "Shader Graph | Inventory System",
    "summary": "Shader Graph A Shader Graph enables you to build shaders visually. Instead of hand writing code you create and connect nodes in a graph network. The graph framework gives instant feedback on the changes, and it’s simple enough that new users can become involved in shader creation. Unless you intend to modify Shader Graph or want to try out the latest and unsupported features, Unity recommends that you install Shader Graph through the Unity Package Manager: Open a Unity project. Open the Package Manager window (Window > Package Manager). In the Package Manager window, in the Packages menu, select Unity Registry. Do one of the following, based on your project needs: To use Shader Graph and the Universal Render Pipeline (URP) in your project, select Universal RP. To use Shader Graph and the High Definition Render Pipeline (HDRP), select High Definition RP. To use Shader Graph with Unity's Built-In Render Pipeline, select Shader Graph. Unity recommends using Shader Graph with URP or HDRP. Instructions If you want to try out the latest features, we recommend obtaining the most recent version of Shader Graph through the Unity Scriptable Render Pipeline (SRP) repository, which includes the Shader Graph project as a Git submodule. For more information on Git submodules, see Git's documentation on Submodules. If you don't install Shader Graph through the SRP repository, you don't have any Master Node backends available and your shaders are invalid. Invalid shaders appear pink in the Unity Editor. Installing through the repository also ensures you have a compatible set of render pipeline and Shader Graph versions. For more detailed instructions for installing from the repository, see the SRP repository's README."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [3.1.0] - 2025-03-28 Added Added an optional command-line argument \"perfTestResults\" to control the target location of performance test run results file. Fixed Warmup cycles no longer record GC measurements. Setup and Cleanup cycles no longer contribute to GC measurements. [3.0.3] - 2023-09-11 Fixed Fixed issue where exception in OnTestEnded callback would result in EndTest method not finalising properly Changed Temporarily removed \"Open Script\" from Performance Benchmark Window Some clarifications in documentation were added (\"Extension\" naming changed to \"Package\", Package limitations clarified) [3.0.2] - 2023-06-29 Changed Added additional InternalsVisibleTo attribute for internal test assembly [3.0.1] - 2023-06-23 Changed Removed false \"unityRelease\" field from package.json [3.0.0] - 2023-06-05 Added \"Open Source Code\" menu item to test results Test Filter to filter results by test name Changed Items in test results are grouped by classname Make Sample Groups to be shown only when clicking on items with them \"New Data available\" label re-located Replaced CamelCase headers with regular text headers in csv report Replaced TRUE/FALSE with Yes/No in the \"Increase Is Better\" column in csv report Renamed the default report name to PerformanceTestResults Documentation updates to reflect API changes Fixed Median calculation in case of even number of samples Deviation division by zero Exception thrown after clicking Cancel button (during Test Result export) The issue where the last column was always empty in csv report [3.0.0-pre.2] - 2023-04-06 Added Help button, which redirects the user to documentation website Clear Results button, which clears all Performance test results Updated CI to support more Unity versions and expand test coverage Changed Updated the style of toolbar buttons to match that of the Test Runner window for consistency Export button is now disabled instead of hidden when there are no Performance test results Made AutoRefresh toggle retain its state after closing and reopening the window Moved the Performance Test Report from 'Window/Analysis' to 'Window/General' near Test Runner for better accessibility Removed Build project from CI Fixed Issue where running tests with the Test Report window open would cause the error message \"The object of type 'Material' has been destroyed\" to appear Issues where incorrect labels were displayed at certain scenarios Issues flagged by SonarQube [3.0.0-pre.1] - 2023-03-02 Added Merged 2.8.1 changes that weren't reflected in 2.10.0 release Fixed Fixing issues from SonarQube check Updating obsolete API's that stopped working with recent Unity versions Clarified how to add package in Unity project in documentation [2.10.0] - 2021-11-01 Added Support for dynamic measurement count in Measure.Method and Measure.Frames [2.9.0] - 2021-04-14 Added Support for overriding measurement count [2.8.1] - 2021-03-16 Removed Setting up date when building player. It will set up at the beginning of the run. [2.8.0] - 2021-03-16 Added Overloads to measurements for overriding sample unit Fixed Cases where cleanup throws an exception [2.7.0] - 2021-02-19 Changed Reduce metadata overhead when running locally by caching dependencies Restructured documentation Removed The need for link.xml Fixed Method measurement IterationsPerMeasurement [2.6.0] - 2021-01-12 Added Build configuration support [2.5.1] - 2021-01-05 Fixed Serialization for Performance Test Report window [2.5.0] - 2020-12-29 Added Domain reload support Changed Switched from Newtonsoft.Json to Unity json module [2.4.1] - 2020-11-05 Changed Metadata collection was made public [2.4.0] - 2020-09-16 Added Performance Test Report window updates: CSV export option. Monitoring of results file timestamp to support auto refresh when a new file is found. Display of timestamp of last loaded results file. Option to sort test report window by order the tests ran in (index). This is now the default. Min and max to the table. Improved titles and tooltips on columns Changed Upgraded json dependency to release version Reduced overhead introduced when running tests [2.3.1] - 2020-07-01 Fixed Overhead introduced with Measure.Method no longer calculates execution time of Setup and Cleanup changes [2.3.0] - 2020-06-17 Fixed Measure.Method overhead Measure.Method no longer calculates execution time of Setup and Cleanup Overwritten test name will be displayed with method name in Test Result viewer [2.2.0] - 2020-05-26 Added Support for custom metadata [2.1.0] - 2020-05-14 Added Flexible horizontal splitter for report window Fixed Date format [2.0.9] - 2020-03-23 Fixed Profiler measurements for method measurements Throw exceptions when measuring NaN [2.0.8] - 2020-02-20 Fixed Fix profiler marker capture when changing scenes in editor tests Only shift samplegroups for UI [2.0.7] - 2020-02-14 Fixed Results parsing [2.0.6] - 2020-01-13 Fixed Development player field [2.0.5] - 2020-01-13 Changed Disallow multiple performance attributes Disallow empty samplegroup name Assign samplegroup name to frames measurements [2.0.4] - 2019-12-05 Changed Update json package to support AOT platforms [2.0.3] - 2019-11-20 Added New fields to data format BuildTarget, StereoRenderingPath [2.0.2] - 2019-11-20 Changed Increased test serialization version [2.0.1] - 2019-11-20 Fixed Player callbacks when no tests were executed [2.0.0] - 2019-11-19 Added Tests to package testables Changed Refactored data format, reduced nesting Slight refactor on measurement API Shift sample units when printing results Switched to newtosoft json package Removed Unused fields Deprecated attributes Fixed Resources cleanup meta files [1.3.1] - 2019-11-05 Fixed Warning after cleaning resources Test suite when running in the editor [1.3.0] - 2019-08-26 Changed Switch to errors from exceptions when parsing results Increase minimum unity version to 2019.3 Removed Metadata collectors tests [1.2.6] - 2019-08-22 Changed Categorize performance tests as performance ProfilerMarkers can now be called with string params Switch measuring frames and methods to stopwatch Removed Profiler section on docs as the feature was removed [1.2.5] - 2019-06-17 Added Test publish for CI [1.2.4] - 2019-06-17 Added Test publish for CI [1.2.3] - 2019-06-14 Changed Updated changelog [1.2.2] - 2019-06-13 Added Support for domain reload [1.2.1] - 2019-06-07 Fixed Bug that would cause player build failures [1.2.0] - 2019-05-23 Changed Increase unity version to 2019.2 [1.1.0] - 2019-05-22 Changed Update assembly definition formats to avoid testables in package manifest [1.0.9] - 2019-05-21 Changed Update scripting runtime setting for 2019.3 [1.0.8] - 2019-03-08 Added Automation test deploy [1.0.7] - 2019-03-08 Added Automation test deploy [1.0.6] - 2019-03-04 Changed Updated changelog [1.0.5] - 2019-03-04 Added Conditional support for 2019.1 [1.0.4] - 2019-02-18 Removed Unnecessary meta files [1.0.3] - 2019-02-18 Changed package.json update [1.0.2] - 2019-02-18 Changed package.json update [1.0.1] - 2019-02-18 Changed Updated Documentation to reflect breaking changes [1.0.0] - 2019-02-15 Changed Refactor attributes [0.1.50] - 2019-01-15 Changed Results paths to persistent data [0.1.49] - 2018-12-04 Changed Revert changes to profiler and GC [0.1.48] - 2018-11-22 Changed Doc updates and ignore GC api in editor due to api issues [0.1.47] - 2018-11-14 Removed Debug logs [0.1.46] - 2018-11-14 Fixed Breaking changes introduced by testrunner API rename [0.1.45] - 2018-11-08 Fixed Breaking changes to data submodule [0.1.44] - 2018-11-08 Changed Disable GC and update API to work around warning [0.1.43] - 2018-10-30 Fixed Method measurements setup and cleanup [0.1.42] - 2018-10-15 Added Button on report window to open profiler output for test Save profiler output on perf tests Removed Unsupported features for legacy scripting runtime Unnecessary assembly definition Fixed Version attribute for test cases [0.1.41] - 2018-10-02 Added Test report graph [0.1.40] - 2018-09-17 Changed Update documentation [0.1.39] - 2018-09-14 Removed Duplicate module from docs [0.1.38] - 2018-09-14 Changed Updated documentation [0.1.36] - 2018-08-27 Changed ProfilerMarkers now take params as arguments [0.1.35] - 2018-08-27 Added Measure.Method improvements: Add GC allocation to Measure.Method Add setup/cleanup for Measure.Method Move order of calls for Measure.Scope [0.1.34] - 2018-08-16 Fixed Obsolete warnings [0.1.33] - 2018-08-03 Fixed Obsolete warnings, doc update with modules and internals, ValueSource fix [0.1.32] - 2018-07-09 Added Method and Frames measurements can now specify custom warmup, measurement and iteration counts [0.1.31] - 2018-07-04 Changed Marked metadata tests with performance category [0.1.30] - 2018-06-27 Fixed Method measurement [0.1.29] - 2018-06-12 Changed Moving back to json in xml due to multiple instabilities [0.1.28] - 2018-06-01 Removed json printing from output [0.1.27] - 2018-05-31 Added Meta files to npm ignore [0.1.26] - 2018-05-31 Changed Preparing package for moving to public registry: Inversed changelog order Excluded CI files from published package [0.1.25] - 2018-05-31 Removed Missing meta files [0.1.24] - 2018-05-31 Changed Print out json to xml by default for backwards compatability [0.1.23] - 2018-05-30 Fixed Issues with packman, bumping up version [0.1.22] - 2018-05-29 Added Option to specify custom Measure.Method Execution and Warmup count [0.1.21] - 2018-05-25 Fixed Issues introduced by .18 fix [0.1.19] - 2018-05-24 Changed Package has been renamed to com.unity.test-framework.performance to match test framework [0.1.18] - 2018-05-24 Fixed Fix SetUp and TearDown for 2018.1 [0.1.17] - 2018-05-23 Changed Refactor Method and Frames measurements Metadata collected using internal test runner API and player connection for 2018.3+ [0.1.16] - 2018-05-09 Fixed Bug fix regarding measureme methods being disposed twice [0.1.15] - 2018-05-02 Fixed Metadata test, the test was failing if a json file was missing for playmode tests [0.1.14] - 2018-04-30 Added Addition of measuring a method or frames for certain amount of times or for duration Introduced SampleGroupDefinition Changed Refactored measuring methods Removed Removes linq usage for due to issues with AOT platforms [0.1.13] - 2018-04-15 Added Added total, std and sample count aggregations Added sample unit to multi sample groups Removed Removed totaltime from frametime measurements Fixed Fixed android metadata collecting [0.1.12] - 2018-04-11 Changed Naming Fixed json serialization [0.1.11] - 2018-04-09 Fixed 2018.1 internal namespaces [0.1.10] - 2018-04-09 Added Added editmode and playmode tests that collect metadata Changed Change fields to UpperCamelCase [0.1.9] - 2018-04-06 Added json output for 2018.1 which will be printed after test run [0.1.8] - 2018-04-03 Fixed Fix an exception on 2018.1 [0.1.7] - 2018-04-03 Changed Changed some of the names to match new convention Addressed typos in docs Multiple overloads replaced by using default arguments [0.1.6] - 2018-03-28 Added Measure.Custom got a new overload with SampleGroup Readme now includes installation and more examples [0.1.5] - 2018-03-20 Added Checks for usage outside of Performance tests [0.1.4] - 2018-03-20 Added System info to performance test output Preparing for reporting test data [0.1.3] - 2018-03-14 Removed Temporarily removing tests from the package into separate repo [0.1.2] - 2018-03-14 Fixed Update for a missing bracket [0.1.1] - 2018-03-14 Added Test output now includes json that can be used to parse performance data from TestResults.xml Added defines to be compatible with 2018.1 and newer Measurement methods can now take in SampleGroup as argument Removed Removed unnecessary overloads for measurements due to introduction of SampleGroup [0.1.0] - 2018-02-27 This is the first release of Unity Package performancetesting. Initial version."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Performance Testing Package overview Taking measurements Measure.Method Measure.Frames Measure.Scope Measure.ProfileMarkers Measure.Custom Writing tests Viewing results [Reference] Classes Test attributes Command-line arguments"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/classes.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/classes.html",
    "title": "Classes | Inventory System",
    "summary": "Classes This section contains a reference for classes relevant when working with the Performance Testing Package. SampleGroup class SampleGroup - represents a group of samples with the same purpose that share a name, sample unit and whether an increase is better. Optional parameters Name : Name of the measurement. If unspecified, \"Time\" is used as the default name. Unit : Unit of the measurement to report samples in. Possible values are: Nanosecond, Microsecond, Millisecond, Second, Byte, Kilobyte, Megabyte, Gigabyte IncreaseIsBetter : If true, an increase in the measurement value is considered a performance improvement (progression). If false, an increase is treated as a performance regression. False by default."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/cmd-line-args.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/cmd-line-args.html",
    "title": "Command-line arguments | Inventory System",
    "summary": "Command-line arguments This section lists Unity arguments supported by the package when running performance tests from the command line. For a general overview of the topic, see the Unity Test Framework documentation. Supported arguments perfTestResults The path where Unity should save the JSON file with performance test run results. By default, Unity saves it in the Application.persistentDataPath folder. Please note that when this argument is not provided, Unity generates two report files at the default results location - the JSON file with performance test run results as well as the NUnit test results XML file that these results are extracted from. This behaviour currently exists for backwards compatibility reasons and will be deprecated over time, as the destination path of the test results XML file is already controlled by the testResults command-line argument of the Unity Test Framework package. Example of command-line usage Unity.exe -runTests -batchmode -projectPath PATH_TO_YOUR_PROJECT -testResults C:\\temp\\results.xml -perfTestResults C:\\temp\\perfResults.json"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/index.html",
    "title": "Performance Testing Package for Unity Test Framework | Inventory System",
    "summary": "Performance Testing Package for Unity Test Framework The Unity Performance Testing Package extends Unity Test Framework with performance testing capabilities. It provides an API and test case decorators for taking measurements/samples of Unity profiler markers, and other custom metrics, in the Unity Editor and built players. It also collects configuration metadata that is useful for comparing data across different hardware and configurations, such as build and player settings. The Performance Testing Package is intended for use with the Unity Test Framework. You should be familiar with how to create and run tests as described in the Unity Test Framework documentation. Note: When tests are run with Unity Test Framework, a development player is always built to support communication between the editor and player, effectively overriding the development build setting from the build settings UI or scripting API. Installing the Performance Testing Package Install the Performance Testing Package package using one of the following methods: Add the package by installing from a Git URL. Add the package as a dependency to the project manifest. Example: Open the manifest.json file for your Unity project (located in the YourProject/Packages directory) in a text editor. Add \"com.unity.test-framework.performance\": \"3.0.3\", to the dependencies. Save the manifest.json file. Verify the Performance Testing Package is now installed by opening the Unity Package Manager window. When the package is installed, add a reference to Unity.PerformanceTesting in your assembly definition to access the performance testing APIs. Unity version compatibility Unity releases can often include changes that break compatibility with the Performance Testing Package, so we cannot currently guarantee latest package version compatability with every Unity version. The table below shows which version of the package is compatible with which Unity release streams. Unity stream Package version 2023.2 3.0.3 2023.1 3.0.3 2022.2 3.0.3 2022.1 3.0.3 2021.3 3.0.3 2020.3 3.0.3 2019.4 2.8.1-preview Tips Project settings Remove all but one of the Quality level settings in Project Settings > Quality. Otherwise, you may have different configurations when running on different platforms. If you require different settings per platform then make sure they are being set as expected. Disable VSync under Project Settings > Quality. Some platforms like Android have a forced VSync and this will not be possible. Disable HW Reporting PlayerSettings -> Other -> Disable HW Reporting. Remove camera and run in batchmode if you are not measuring rendering. Generating assets Use IPrebuildSetup attribute when you need to generate assets. Place assets in Resources or StreamingAssets folders, scenes can be placed anywhere in the project, but should be added to build settings. Example 1: IPrebuildSetup implementation public class TestsWithPrebuildStep : IPrebuildSetup { public void Setup() { // this code is executed before entering playmode or the player is executed } } public class MyAmazingPerformanceTest { [Test, Performance] [PrebuildSetup(typeof(TestsWithPrebuildStep))] public void Test() { ... } } When loading scenes in IPrebuildSetup you have to use LoadSceneMode.Additive. Example 2: Using EditorSceneManager to create new scenes additively, save and add them to build settings. private static string m_ArtifactsPath = \"Assets/Artifacts/\"; public static Scene NewScene(NewSceneSetup setup) { Scene scene = EditorSceneManager.NewScene(setup, NewSceneMode.Additive); EditorSceneManager.SetActiveScene(scene); return scene; } public static void SaveScene(Scene scene, string name, bool closeScene = true) { EditorSceneManager.SaveScene(scene, GetScenePath(name)); if (closeScene) { foreach (var sceneSetting in EditorBuildSettings.scenes) if (sceneSetting.path == GetScenePath((name))) return; EditorSceneManager.CloseScene(scene, true); EditorSceneManager.SetActiveScene(EditorSceneManager.GetSceneAt(0)); var newListOfScenes = new List<EditorBuildSettingsScene>(); newListOfScenes.Add(new EditorBuildSettingsScene(GetScenePath(name), true)); newListOfScenes.AddRange(EditorBuildSettings.scenes); EditorBuildSettings.scenes = newListOfScenes.ToArray(); } } public static string GetScenePath(string name) { return m_ArtifactsPath + name + \".unity\"; }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-custom.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-custom.html",
    "title": "Measure.Custom() | Inventory System",
    "summary": "Measure.Custom() When you want to record samples outside of frame time, method time, or profiler markers, use a custom measurement. It can be any value. Example: Use a custom measurement to capture total allocated memory [Test, Performance] public void Test() { SampleGroup sampleGroup = new SampleGroup(\"TotalAllocatedMemory\", SampleUnit.Megabyte, false); var allocatedMemory = UnityEngine.Profiling.Profiler.GetTotalAllocatedMemoryLong() / 1048576f; Measure.Custom(sampleGroup, allocatedMemory); }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-frames.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-frames.html",
    "title": "Measure.Frames() | Inventory System",
    "summary": "Measure.Frames() Records time per frame by default and provides additional properties/methods to control how the measurements are taken: WarmupCount(int n) - number of times to execute before measurements are collected. If unspecified, a default warmup is executed for 80 ms or until at least 3 full frames have rendered, whichever is longest. MeasurementCount(int n) - number of frames to capture measurements for. If this value is not specified, as many frames as possible are captured until approximately 500 ms has elapsed. DynamicMeasurementCount(OutlierMode outlierMode) - dynamically find a suitable measurement count based on the margin of error of the samples. The measurements will stop once a certain amount of samples (specified by a confidence interval) falls within an acceptable error range from the result (defined by a relative error of the mean). A default margin of error range of 2% and a default confidence interval of 99% will be used. Statistical outliers will not be taken into account unless different behaviour is specified through the outlierMode argument. DynamicMeasurementCount(double maxRelativeError, ConfidenceLevel confidenceLevel, OutlierMode outlierMode) - dynamically find a suitable measurement count based on the margin of error of the samples and using the provided confidence interval and error range. DontRecordFrametime() - disables frametime measurement. ProfilerMarkers(...) - sample profile markers per frame. Does not work for deep profiling and Profiler.BeginSample() SampleGroup(string name) - name of the measurement, defaults to \"Time\" if unspecified. Scope() - measures frame times in a given coroutine scope. By default it uses a SampleGroup named \"Time\" with Milliseconds as measurement unit. You can also create your own SampleGroup, specifying a custom name and the measurement unit you want your results in, see example 5. Limitations Not supported in Unity Test Framework Edit Mode tests. Example 1: Simple frame time measurement using default values of at least 7 frames and default WarmupCount (see description above). [UnityTest, Performance] public IEnumerator Test() { ... yield return Measure.Frames().Run(); } Example 2: Sample profile markers per frame, disable frametime measurement If you'd like to sample profiler markers across multiple frames and don't need to record frametime, it is possible to disable the frame time measurement. [UnityTest, Performance] public IEnumerator Test() { ... yield return Measure.Frames() .ProfilerMarkers(...) .DontRecordFrametime() .Run(); } Example 3: Sample frame times in a scope [UnityTest, Performance] public IEnumerator Test() { using (Measure.Frames().Scope()) { yield return ...; } } Example 4: Specify custom WarmupCount and MeasurementCount per frame If you want more control, you can specify how many frames you want to measure. [UnityTest, Performance] public IEnumerator Test() { ... yield return Measure.Frames() .WarmupCount(5) .MeasurementCount(10) .Run(); } Example 5: Specify Custom SampleGroup in the Scope [UnityTest, Performance] public IEnumerator Test() { var sg = new SampleGroup(\"MarkerName\", SampleUnit.Second); using (Measure.Frames().Scope(sg)) { yield return ...; } } Example 6: Sample profile markers per frame with custom SampleGroups that change sample unit [UnityTest, Performance] public IEnumerator Test() { var sampleGroup = new SampleGroup(\"Name\", SampleUnit.Milliseconds); var profileMarkersSampleGroups = new []{ new SampleGroup(\"MarkerName\", SampleUnit.Second), new SampleGroup(\"MarkerName1\", SampleUnit.Nanosecond) }; yield return Measure.Frames().SampleGroup(sg).ProfilerMarkers(profileMarkersSampleGroups).Run(); ... }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-method.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-method.html",
    "title": "Measure.Method() | Inventory System",
    "summary": "Measure.Method() Executes the provided method, sampling performance using the following additional properties/methods to control how the measurements are taken: WarmupCount(int n) - number of times to execute before measurements are collected. If unspecified, a default warmup is executed for 100 ms or until at least 3 method executions have completed, whichever is longer. MeasurementCount(int n) - number of measurements to capture, defaults to 9 if not specified. DynamicMeasurementCount(OutlierMode outlierMode) - dynamically find a suitable measurement count based on the margin of error of the samples. The measurements will stop once a certain amount of samples (specified by a confidence interval) falls within an acceptable error range from the result (defined by a relative error of the mean). A default margin of error range of 2% and a default confidence interval of 99% will be used. Statistical outliers will not be taken into account unless different behaviour is specified through the outlierMode argument. DynamicMeasurementCount(double maxRelativeError, ConfidenceLevel confidenceLevel, OutlierMode outlierMode) - dynamically find a suitable measurement count based on the margin of error of the samples and using the provided confidence interval and error range. IterationsPerMeasurement(int n) - number of method executions per measurement to use. If this value is not specified, the method is executed as many times as possible until approximately 100 ms has elapsed. SampleGroup(string name) - name of the measurement, defaults to \"Time\" if unspecified. SampleGroup(SampleGroup sampleGroup) - a sample group with a custom name and measurement unit. This will override the otherwise default value of \"Time\". GC() - if specified, measures the total number of Garbage Collection allocation calls. SetUp(Action action) - is called every iteration before method execution. Setup time is not measured. CleanUp(Action action) - is called every iteration after method execution. Cleanup time is not measured. Example 1: Simple method measurement using default values [Test, Performance] public void Test() { Measure.Method(() => { ... }).Run(); } Example 2: Customize Measure.Method properties [Test, Performance] public void Test() { Measure.Method(() => { ... }) .WarmupCount(10) .MeasurementCount(10) .IterationsPerMeasurement(5) .GC() .SetUp(()=> {/*setup code*/}) .CleanUp(()=> {/*cleanup code*/}) .Run(); } Example 3: Measure.Method, SampleGroup and ProfilerMarkers [Test, Performance] public void Test() { var sg = new SampleGroup(\"Name\", SampleUnit.Microsecond); var sgMarker = new SampleGroup(\"MarkerName\", SampleUnit.Seconds); Measure.Method(() => { ... }).SampleGroup(sg).ProfilerMarkers(sgMarker).Run(); }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-profile-markers.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-profile-markers.html",
    "title": "Measure.ProfilerMarkers() | Inventory System",
    "summary": "Measure.ProfilerMarkers() Used to record profiler markers. Profiler marker timings are recorded automatically and sampled within the scope of the using statement. Names should match profiler marker labels. Profiler markers are sampled once per frame. Sampling the same profiler marker per frame will result in the sum of all invocations. You can also create your own SampleGroups, specifying a custom name and the measurement units you want your results in, see example 2. Limitations Not supported in Unity Test Framework Edit Mode tests. Not supported in the Unity Profiler's Deep Profiling mode. Profiler markers created using Profiler.BeginSample() are not supported, switch to ProfilerMarker if possible. Example: Measuring profiler markers in a scope [Test, Performance] public void Test() { string[] markers = { \"Instantiate\", \"Instantiate.Copy\", \"Instantiate.Produce\", \"Instantiate.Awake\" }; using(Measure.ProfilerMarkers(markers)) { ... } } Example 2: Measuring profiler markers in a scope with custom SampleGroups [UnityTest, Performance] public IEnumerator Test() { var sampleGroups = new []{ new SampleGroup(\"Instantiate\", SampleUnit.Second), new SampleGroup(\"Instantiate.Copy\", SampleUnit.Nanosecond), new SampleGroup(\"Instantiate.Awake\", SampleUnit.Microsecond) }; using (Measure.ProfilerMarkers(sampleGroups)) { ... } }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-scope.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/measure-scope.html",
    "title": "Measure.Scope(string name = \"Time\") | Inventory System",
    "summary": "Measure.Scope(string name = \"Time\") Measures execution time for the scope as a single time, for both synchronous and coroutine methods. Passing the name argument overrides the name of the created SampleGroup. The defualt SampleGroup is named \"Time\" and with Milliseconds as measurement unit. You can also create your own SampleGroup, specifying a custom name and the measurement unit you want your results in, see example 2. Example 1: Measuring a scope; execution time is measured for everything in the using statement [Test, Performance] public void Test() { using(Measure.Scope()) { ... } } Example 2: Specify Custom SampleGroup [Test, Performance] public void Test() { var sampleGroup = new SampleGroup(\"Scope\", SampleUnit.Microsecond); using (Measure.Scope(sg)) { ... } }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/taking-measurements.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/taking-measurements.html",
    "title": "Taking measurements | Inventory System",
    "summary": "Taking measurements The Performance Testing Package provides several API methods for taking measurements in your performance test, depending on what you need to measure and how you want to do it. Include using Unity.PerformanceTesting at the top of your script to access the methods. The pages in this section detail the specifics of each measurement method with examples: Measure.Method Measure.Frames Measure.Scope Measure.ProfilerMarkers Measure.Custom"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/test-attributes.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/test-attributes.html",
    "title": "Test Attributes | Inventory System",
    "summary": "Test Attributes This section contains a reference for attributes supported by the Performance Testing Package. [Performance] - Use this with Test and UnityTest attributes. It will initialize necessary test setup for performance tests. [Test] - Non-yielding test. This type of test starts and ends within the same frame. [UnityTest] - Yielding test. This is a good choice if you want to sample measurements across multiple frames. For more on the difference between [Test] and [UnityTest], see the Unity Test Framework documentation. [Version(string version)] - Performance tests should be versioned with every change. If not specified, the default used is 1. This is essential when comparing results as results will vary any time the test changes."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/viewing-results.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/viewing-results.html",
    "title": "| Inventory System",
    "summary": "Output When a test is selected in the Test Runner window in the Unity Editor, each performance test will have a performance test summary. This summary includes every sample group's aggregated samples such as median, min, max, average, standard deviation, sample count and sum of all samples. Example: Performance Test Summary from Test Runner window Time Microsecond Median:2018.60 Min:1903.00 Max:2819.80 Avg:2186.35 Std:368.42 SampleCount: 4 Sum: 8745.40 The Performance Test Report The Performance Test Report (Window > General > Performance Test Report) shows a detailed breakdown of individual test runs. This can be used to assess the stability of each test. It provides a visualization of each individual sample recorded within a sample group along with summary statistics for the selected test. The Performance Test Report is split into two views: the test view and the sample group view. Test View: Provides a list of all tests. Tests are separated by class names. Each of the columns can be clicked to sort the view. Column values show the sample group with highest deviation. Name - Name of the test. Deviation - The deviation is calculated by dividing the standard deviation by the median for a sample group. It shows the sample group with the highest 'deviation' value. Useful for defining stability of the test. Standard Deviation - Standard deviation of the samples in a sample group. It shows the sample group with the highest standard deviation. Sample Group View: Visualizes sample groups for the test selected in the Test View. Provides: Sample group summary displaying the min, max, and median values for a given sample group. Samples displayed in a bar chart, ordered by time, with a blue line indicating the median. Box plot showing upper (75%) and lower (25%) quartiles, min, max and median of the samples for a given sample group."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/writing-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Documentation~/writing-tests.html",
    "title": "Writing a simple test | Inventory System",
    "summary": "Writing a simple test This example uses Measure.Method to measure the performance of Vector2 operations. This executes the provided method and samples performance. Increasing MeasurementCount from the default of 7 to 20 improves performance test stability. You can execute a Vector2.MoveTowards test in Edit Mode or Play Mode. [Test, Performance] public void Vector2_operations() { var a = Vector2.one; var b = Vector2.zero; Measure.Method(() => { Vector2.MoveTowards(a, b, 0.5f); Vector2.ClampMagnitude(a, 0.5f); Vector2.Reflect(a, b); Vector2.SignedAngle(a, b); }) .MeasurementCount(20) .Run(); } To view the results, go to Window > Analysis > Performance Test Report. In this example, the results show that the first method execution took five times longer than the subsequent methods, and those subsequent method executions were unstable. Also, you can't tell from these test results how long it took for each Vector2 operation to execute. Improving test stability Now we'll look at how to improve the stability of our test. Instability can occur at the beginning of a test for several reasons, such as entering Play Mode or method initialization, because the tested method is quite fast and more sensitive to other running background processes. To improve stability, use WarmupCount(n). This allows you to execute methods before recording data, so Unity doesn't record method initialization. The simplest way to increase test execution time is to repeat the method in a loop. Avoid having measurements that are less than 1ms because they are usually more sensitive to unstable environments. To help you track the execution time for each operation, split the Vector2 operations into several tests. Often, when writing tests, we use setup and clean up methods to isolate the test environment. However, in this case, methods are isolated and do not affect other methods, so we don't need a cleanup or setup. The following code example shows a performance test for the Vector2.MoveTowards operation. Other Vector2 performance tests are identical. [Test, Performance] public void Vector2_MoveTowards() { Measure.Method(() => { Vector2.MoveTowards(Vector2.one, Vector2.zero, 0.5f); }) .WarmupCount(5) .IterationsPerMeasurement(10000) .MeasurementCount(20) .Run(); } With 100000 iterations in this test, we see a small fluctuation in method execution time but the standard deviation is low, which means the test is reasonably stable. Measure a Play Mode only method To measure a method that only runs in Play Mode (for example Physics.Raycast), you can use Measure.Frames(), which records time per frame by default. To only measure Physics.Raycast time, you can disable frame time measurements with DontRecordFrametime and just measure the Physics.Raycast profiler marker. This test creates objects that you need to dispose of at the end of each test, because multiple unnecessary objects can affect the next test results. Use the SetUp method to create GameObjects, and the TearDown method to destroy the created GameObjects after each test. [SetUp] public void SetUp() { for (int i = 0; i < 100; ++i) { GameObject raycaster = new GameObject(\"raycast\", typeof(Raycast)); raycaster.transform.SetParent(_parent.transform); } } [UnityTest, Performance] public IEnumerator Physics_RaycastTests() { string profilierMarker = \"Physics.Raycast\"; yield return Measure.Frames() .WarmupCount(3) .DontRecordFrametime() .MeasurementCount(10) .ProfilerMarkers(profilierMarker) .Run(); } public class Raycast : MonoBehaviour { private void Update() { RaycastHit hit; bool ray = Physics.Raycast( transform.position, Vector3.forward, out hit, Mathf.Infinity); } } [TearDown] public void TearDown() { GameObject.DestroyImmediate(_parent); } To record your own measurements, create a new sample group and record a custom metric. The following example measures Allocated and Reserved memory. [Test, Performance] public void Empty() { var allocated = new SampleGroup(\"TotalAllocatedMemory\", SampleUnit.Megabyte); var reserved = new SampleGroup(\"TotalReservedMemory\", SampleUnit.Megabyte); using (Measure.Scope()) { Measure.Custom(allocated, UnityEngine.Profiling.Profiler.GetTotalAllocatedMemoryLong() / 1048576f); Measure.Custom(reserved, UnityEngine.Profiling.Profiler.GetTotalReservedMemoryLong() / 1048576f); } } Before you start to collect package performance data, make sure the tests you run locally are stable (the data set deviation is <5%). In the Performance Test Report window, ensure the test isn't fluctuating and that the results between runs are similar. Results of performance tests run on a local machine can be significantly different to previous test runs because of other applications running in the background, CPU overheating, or CPU boosting. Make sure that CPU intensive applications are turned off where possible. You can disable CPU boost in the BIOS or with third-party software such as Real Temp. For comparing performance data between runs, use the Unity Performance Benchmark Reporter, which provides a graphical HTML report that enables you to compare performance metric baselines and subsequent performance metrics. Further examples Example 1: Measure Frame Time For Scene [UnityTest, Performance, Version(\"4\")] public IEnumerator MainSceneFrameTime_StartPosition() { SceneManager.LoadScene(\"Demo\", LoadSceneMode.Single); // Measure initial time of first 25 frames after loading the scene using(Measure.Frames().Scope(\"FrameTime.FirstFramesAfterLoadingScene\")) { for (var i = 0; i < 25; i++) { yield return null; } } // Measure frame times for ten seconds during rest of the \"Demo\" scene using (Measure.Frames().Scope(\"FrameTime.Main\")) { yield return new WaitForSeconds(10); } } Example 2: Measure execution time to serialize simple object to JSON [Test, Performance, Version(\"2\")] public void Serialize_SimpleObject() { var obj = new SimpleObject(); obj.Init(); Measure.Method(() => JsonUtility.ToJson(obj)).Run(); } [Serializable] public class SimpleObject { public int IntField; public string StringField; public float FloatField; public bool BoolField; [Serializable] public struct NestedStruct { public int A, B; } public NestedStruct Str; public Vector3 Position; public void Init() { IntField = 1; StringField = \"Test\"; FloatField = 2.0f; BoolField = false; Str.A = 15; Str.B = 20; } } Example 3: Measure execution time to create 5000 simple cubes string[] markers = { \"Instantiate\", \"Instantiate.Copy\", \"Instantiate.Produce\", \"Instantiate.Awake\" }; [Test, Performance] public void Instantiate_CreateCubes() { using (Measure.ProfilerMarkers(markers)) { using(Measure.Scope()) { var cube = GameObject.CreatePrimitive(PrimitiveType.Cube); for (var i = 0; i < 5000; i++) { UnityEngine.Object.Instantiate(cube); } } } } Example 4: Custom measurement to capture total allocated and reserved memory [Test, Performance, Version(\"1\")] public void Measure_Empty() { var allocated = new SampleGroup(\"TotalAllocatedMemory\", SampleUnit.Megabyte); var reserved = new SampleGroup(\"TotalReservedMemory\", SampleUnit.Megabyte); Measure.Custom(allocated, UnityEngine.Profiling.Profiler.GetTotalAllocatedMemoryLong() / 1048576f); Measure.Custom(reserved, UnityEngine.Profiling.Profiler.GetTotalReservedMemoryLong() / 1048576f); }"
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.test-framework.performance copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.test-framework.performance@92d1d09a72ed/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Perfolizer License Type: MIT Copyright © 2020 Andrey Akinshin; Copyright © 2013-2020. NET Foundation and contributors https://github.com/AndreyAkinshin/perfolizer Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [1.5.1] - 2025-02-26 Move com.unity.test-framework to Unity source code - now it's an embedded package. Fixed an issue where retry or repeat would reset on domain reloads. Added support for selecting different architectures on the MacOS and Windows platforms. Added support for IPlatformSetup for GameCore platforms. Add on Setup callback - SCID,TitleID and MSAAppId to the game config. Fixed an issue where retry or repeat would reset on domain reloads. Added documentation for public fields that were missing documentation. Added support for architecture for macOS anb Windows platforms. Fixed an issue where the progress bar would be left visible, if the editor is restarted during a player run. Any exception thrown during OneTimeTeardown will now correctly be flagged as happening during TearDown, rather than during Setup. An total duration is now shown for each suite in the test runner UI, when selected. Note that this does not take into account OneTimeSetup and OneTimeTearDown durations. Fixed an issue where TestFinished was duplicated when running tests, containing domain reload. Fixed an issue were parent node result was not updated after all tests under the node were finished. [1.5.0] - 2024-08-29 Added UnityOneTimeSetUp and UnityOneTimeTearDown attributes, allowing for setup and teardown with yields to be run only once for each test fixture. Use a reduced player path when building a test player for GameCoreXboxSeries and GameCoreXboxOne platforms, avoiding a build error due to the path length in long project paths (DSTR-1060). Fixed a regression where the \"Rerun failed tests\" button would not work correctly in the test runner UI. ITestAction and IOuterUnityTestAction was not triggering correctly when defined on a fixture level, this is now fixed (UTF-582). Improved test assembly build times in some cases by ensuring that the test runner utilizes the full editor update to construct the test tree (UTF-592). Fixed an issue where changing between EditMode and PlayMode would not update the search bar as intended. [1.4.5] - 2024-07-02 Fixed an issue where batchmode test runs would never finish if a test yielded WaitForEndOfFrame (DSTR-1009). Fixed an issue where the location prompt was required when using the Install all tests in 'build' folder option during test builds. Canceling a PlayMode test run now correctly restores the scene setup, instead of leaving the editor in the test scene. Fixed an issue where UnitySetUp did not fail when nested coroutines threw an exception (DSTR-1007). When selecting multiple tests and running them, the test runner now correctly updates the details of the first selected test (UTF-602). The interaction mode and application idle time settings is now being changes when running tests, resulting in faster test runs if not already in use (applies to 2020.3 and later) (DSTR-690). Fixed an issue where some NUnit attributes caused errors and stopped async test runs (DSTR-1040). Added support for the MaxTime attribute on async and UnityTest methods (DSTR-1040). Fixed a memory leak issue where a large number of domain reloads within the same test could crash the editor (DSTR-1023). Changed to use a progress bar inside the test runner window when running tests. This ensures that the progress bar is not fighting to display when e.g. compiling scripts and also makes it easier to cancel a run. This progress bar is displayed for all types of runs (EditMode, PlayMode and Player). (UTF-596). Fixed an issue where ignored tests with an attributes did not display the ignore reason in the test runner UI. Having multiple tests with the same unique id no longer gives a error with 'An item with the same key has already been added', but instead logs an warning about the duplicate id. The result icons for test suites should no longer flicker when running tests. Ensured that test results ignored in the editor but run on a player are not overwritten with ignore status when shown in the UI (DSTR-1042). Fixed an issue where the RunStarted event was not invoked correctly during a test run (DSTR-1046). Fixed an issue where TestStarted and TestFinished events were repeated for ignored test fixtures after a domain reload (DSTR-986). [1.4.4] - 2024-04-11 Fix the issue where playmode controller wasn't being set and cleaned up correctly, causing issues post test run. (DSTR-1025) Fixed an issue where Oculus Quest headsets might timeout before the test run starts (DSTR-404). Fixed a regression where the console output would no longer get attached to the test result for PlayMode. [1.4.3] - 2024-01-15 Fixed a performance issue in relation to the new ui, where running a large selection of tests did not perform well. (DSTR-983) The test tree no longer is fully expanded when the window is first opened, fixing test tree explosion. (DSTR-985) Fixed an issue in Solution 13 of Samples where the path was pointing to a wrong location. (DSTR-1005) Updated documentation of Solution 13 of Samples to reflect more accurate solution for the example. (DSTR-1005) Added ability to build all or selected tests from test runner UI. (UTF-553) [1.4.2] - 2023-12-05 Issue where playmode tests were not recording test results correctly after the first run was fixed. (DSTR-984) A timeout message is now printed when the test failures occurs before the test finishes. (DSTR-476) Nested enumerators are now having their first step executed in the same frame as the parent enumerator. (DSTR-888) Fixed an issue where test projects without PlayMode tests would give the error \"No callbacks received.\" when running in batchmode on some Unity versions. [1.4.1] - 2023-11-13 Multiple improvements to the UI, including better dropdowns, filtering, and a new test list view for Player. Fixed uncategorized UI tests filtering for parameterized tests (DSTR-219). In async tests, any failing logs will now first be evaluated after the async method has completed. (DSTR-839) [1.4.0] - 2023-11-10 Added api for saving test results to a file. Added a button for saving the test results of the latest run. Applied filtering to the ITestAdaptor argument of ICallbacks.RunStarted so that it corresponds to the actual test tree being run. When running in player: the save scene dialog is shown when there are changes in the scene. the scene setup is restored after a completed run. When running in playmode: the scene setup is restored after a completed run. Added overloads of LogAssert.Expect which allow users to expect a log message without specifying a severity, which will match logged messages of any severity. Added new [ParametrizedIgnore] attribute which allows ignoring tests based on arguments which were passed to the test method. Added a new PreservedValuesAttribute to allow for using the nunit ValuesAttribute at players with a high stripping level (case DSTR-33). Added api for canceling test runs. [1.3.9] - 2023-08-21 Removed player metadata fields that were using obsolete APIs (DSTR-880). Added note to documentation on mitigation of problem reported in (DSTR-600). Fixed an issue where the test runner ui causes progress bars to flicker or not show at all (DSTR-828). [1.3.8] - 2023-07-05 Send new UTP messages regarding player and system settings (DSTR-831) [1.3.7] - 2023-06-07 The UTF version now automatically updates for SRP tests [1.3.6] - 2023-06-01 By using the editor command line new argument -randomOrderSeed x you can run the tests in a randomized order, where x is an integer different from 0. If a new test is added in the project the random order passing the same seed will be kept, and the new test will be placed in the random list accordigly. Fix for WebGL platform target to close the browser tab when the run is completed. Added TestFileReferences.json to be generated on build step of the player, so can be consumed later by Test runners to enrich data for run part. [1.3.5] - 2023-05-16 It’s now possible to retry and repeat tests on test level, meaning as soon as the test finishs running the first iteration, we now retry or repeat it. Command line arguments to pass to the Editor: -repeat x runs the test x amount of times or until it fails. It is useful for testing unstable tests -retry x if a test fails, run that test x amount of times or until it succeeds. Fixed various documentation bugs reported via the docs user feedback system. Added separate reference docs page for TestSettings options to distinguish them from regular command line arguments. Fixed TestMode not being set correctly on root level of test tree (DSTP-674). It's now possible to select browser for running WebGL player tests in player settings. (DSTR-811) [1.3.4] - 2023-03-24 Fixes output message concurrency issue with async Setup. Fixed multiple issues where tests would not time out, when running longer than the default timeout or the timeout defined in a TimeoutAttribute (DSTR-607). Added UNITY_TEST_FRAMEWORK define constraint to filter out test framework assemblies from normal platform and asset bundle builds. (DSTR-791) Ensured that all playmode tests have a disabled splashscreen and unity logo by default if Unity license permits such action. Added strictDomainReload feature to enable cheching for pending domain reloads/compilations at the end of managed tests (DSTR-793). [1.3.3] - 2023-02-10 Fixes an issue where a test body would be skipped under certain conditions regarding domain reload. Fixed an issue where the \"uncategorized\" category filter would not apply correctly to parameterized tests with a category in the fixture (DSTR-700). Ensured that all samples can be loaded at once without assembly name collisions. [1.3.2] - 2022-12-07 Fixed context not being restored after a domain reload outside tests (DSTR-678) Fixed TestMode being set only in on the aseembly level (DSTP-674) Fixed an issue where RunFinished callbacks sometimes would not be executed before the editor quits in batchmode (DSTR-692). Fixed problem of samples not loading for import in Package Manager window. (DSTR-702) Fixed issue GuiHelper depending on FilePath being abosolute. Updated to handle both cases. Fixed an issue where ITestRunCallback are invoked double when run in EditMode. [1.3.1] - 2022-10-18 Fixed an issue where TestFinished sometimes causes failures when receiving fixture test results from a player (internal). [1.3.0] - 2022-10-11 Fixed Xcode not closing after building iOS/tvOS project via batchmode -runTests command (ANT-679). Added TestSettings file options for setting Target SDK for iOS/tvOS (ANT-132). Async test support with documentation and support for SetUp and TearDown. Compute and share OneTimeSetup and OneTimeTearDown durations, these will be visible in the XML result under outputs (DSTR-597). Made test method/fixture arguments available in the ITestAdaptor as the Arguments property (DSTR-592). Added Learn Unity Test Framework section of documentation and related project files as importable package samples (DOCES-558). Fix NullReferenceException when yielding EditMode intructions in PlayMode tests (DSTR-622). [1.1.33] - 2022-07-12 Fixed an issue where using Assert.Expect with the same string multiple times can lead to incorrect errors in some cases (DSTR-442). Improved the logging when using multiple Assert.Expect that the logs appear in another order than expected (DSTR-442). Moved the targetPlatform specified when running tests in the TestRunnerApi from the Filter to the ExecutionSettings (DSTR-186). Fixed an issue where an inheritance of UnityPlatformAttribute which was not working (ESTT-70). Fixed the log of excluded platforms which was not displaying the right information. Added filename and linenumber to test finished message (DSTR-505). Add the possibility of running tests in a specified order from a test list (DSTR-494). [1.1.32] - 2022-04-06 Ensured that BuildTargetGroup is set correctly before TestPlayerBuildModifier is invoked (DSTR-394). Added a TestSetting that allows to build an Android App Bundle instead of APK. [1.1.31] - 2022-02-03 Fixed \"Open source code\" on tests when located inside a package. Added editor analytics events. Added buildPlayerPath argument. Path to where built player with tests is saved. [1.1.30] - 2021-10-15 Added validation of IEnumerator return type for parameterized tests with UnityTest attribute (DSTP-743). Fixed runInBackground reset to original value after finishing to run playmode tests (DSTR-248). Fixed issue with circular assembly references when constructing the test tree (DSTR-300). [1.1.29] - 2021-08-12 Nested enumerator execution order fix (DSTR-227). Fix UI not running any tests if run select on a nested namespaces (DSTR-256). [1.1.28] - 2021-06-25 Fix CountDownEvent reference due to com.unity.ext.nunit update. Various performance optimization to fix \"Test execution timed out. No activity received from the player in 600 seconds.\"(DSTR-100). [1.1.27] - 2021-06-15 Fix empty reason on passed tests results xml (DSTR-63) Fix Repeat and Retry attribute for UnityTest in PlayMode (DSTR-237). Remove XDK Xbox One platform after Unity 2020.3 Fixed issue when . suffix was applied to BuildTargets without extension. Added support for GameCoreXboxOne and GameCoreXboxSeries reduced location path length. [1.1.26] - 2021-05-25 Fix html bug in TestRunnerApi API code snippet (DS-1973). Fix typo bug in PreBuildSetup code example (DS-1974). Fix incorrect syntax in command line reference (DS-1971). Fixed a bug where test filter would match project or player path (DSTP-412). Added playerGraphicsAPI TestSettings parameter [1.1.25] - 2021-05-05 Fixed a bug where test filter would match project or player path (DSTP-412). Added playerGraphicsAPI TestSettings parameter [1.1.24] - 2021-03-04 Improving UTF documentation(DSTR-120) Updated \"Actions outside of tests\" section of user manual. Added flow charts to clarify execution order for SetUp/TearDown, TestActions, and complete flow (DSTR-121). Fixed accepted values for scriptingBackend argument to be string literals instead of int values (DSTR-122). Fixed possible values of ResultState to be Passed, Failed, Skipped, Inconclusive, plus labels instead of Success and Failure (DSTR-125). Added NUNit version information (DSTR-130). Added namespace information for LogAsset in user manual (DSTR-124). Added instructions for creating additional sets of tests (DSTR-129). Added information on testResults XML output format and exit codes (DSTR-131). Updated description of testPlatform command line argument to clarify accepted values and their meaning (DSTR-123). Reduce time taken by filtering operations when only a subset of tests is run. Reduced the time taken to rebuild the test tree and to scan for assets a test created but did not delete. Reduce the per-test overhead of running tests in the editor. Added profiler markers around test setup, teardown, and execution. Fixed unstable timeout bug (DSTR-21). [1.1.23] - 2021-01-21 Improving UTF documentation(DSTR-120) Updated \"Actions outside of tests\" section of user manual. Added flow charts to clarify execution order for SetUp/TearDown, TestActions, and complete flow (DSTR-121). Fixed accepted values for scriptingBackend argument to be string literals instead of int values (DSTR-122). Fixed possible values of ResultState to be Passed, Failed, Skipped, Inconclusive, plus labels instead of Success and Failure (DSTR-125). Added NUNit version information (DSTR-130). Added namespace information for LogAsset in user manual (DSTR-124). Added instructions for creating additional sets of tests (DSTR-129). Added information on testResults XML output format and exit codes (DSTR-131). Updated description of testPlatform command line argument to clarify accepted values and their meaning (DSTR-123). [1.1.22] - 2021-01-21 Fixed issue where test result of an explicit test was set to skipped in case it was passing and running from command line with testfilter set to the explicit test (DS-1236). Fixed an issue where tests located in assemblies that did not directly reference any test assemblies were not included (DSTR-30). Fixed an issue where UnitySetup methods were incorrectly being rerun when entering playmode, rather than being skipped (DSTR-68). Internal: Remove ##utp message AssemblyCompilationErrors (DS-1277) Fixed issue where if the timeout was exceeded in SetUp the timeout exception was not thrown(DSTR-21). Removed ability to Enable playmode tests for all assemblies from the TestRunner UI, since it is a deprecated behavior. It enforces to use of assembly definition files (DSTR-45). Fixed typo in LogAssert.cs documentation. [1.1.21] - 2020-12-04 Fixed issue where test result of an explicit test was set to skipped in case it was passing and running from command line with testfilter set to the explicit test (DS-1236). Fixed an issue where tests located in assemblies that did not directly reference any test assemblies were not included (DSTR-30). Fixed an issue where UnitySetup methods were incorrectly being rerun when entering playmode, rather than being skipped (DSTR-68). Internal: Remove ##utp message AssemblyCompilationErrors (ds-1277) Fixed issue where if the timeout was exceeded in SetUp the timeout exception was not thrown(DSTR-21). Removed ability to Enable playmode tests for all assemblies from the TestRunner UI, since it is a deprecated behavior. It enforces to use of assembly definition files (DSTR-45). [1.1.20] - 2020-12-04 The logscope is now available in OneTimeTearDown. Fixed an issue where failing tests would not result in the correct exit code if a domain reload happens after the test has run (DS-1304). If a player build fails, the test specific build settings should be cleaned up and the original values restored as intended (DS-1001). Added better error message when using TestRunCallbackAttribute and the implementation is stripped away (DS-454). Fixed an issue where the test results xml would have a zero end-time for tests executed before a domain reload (DSTR-63). Fixed OpenSource in case of a Test in a nested class (DSTR-6) UnityTests with a domain reload now works correctly in combination with Retry and Repeat attributes (DS-428). Fixed OpenSource in case of Tests located inside a package (DS-432) [1.1.19] - 2020-11-17 Command line runs with an inconclusive test result now exit with exit code 2 (case DS-951). Fixed timeout during UnitySetUp which caoused test to pass instead of failing due to wrong time format. Timeout exeption thrown when timeout time is exeded in the UnitySetup when using WaitForSeconds(n). Updating com.unity.ext.nunit version Method marked with UnityTest that are not returning IEnumerator is now giving a proper error (DS-1059). [1.1.18] - 2020-10-07 Fixed issue of timeout during UnitySetUp which wasn't detected and allowed the test to pass instead of failing (case DSTR-21) [1.1.17] - 2020-10-05 Fixed an issue where the WaitForDomainReload yield instruction would sometimes let the test continue for one frame before the domain reload. Added support for negation in filters using !. E.g. !CategoryToExclude. Fixed an issue where if the first test enters PlayMode from UnitySetup then the test body will not run on consecutive runs (case 1260901). Clear Results button clears the test results in the GUI (DSTR-16) Improved UI in Test Runner window, added new options: Run Selected Tests in player Build/Export project with all tests in player Build/Export project with selected tests in player Fixed issue on loading EditMode or Playmode test tree in the wrong tab when switching between tabs when TestRunner is loading (DS-865) [1.1.16] - 2020-07-09 Follow up on fix when UTF picks up on outdated compilation errors [1.1.15] - 2020-07-02 Fixed an issue where an exception is thrown on getting the enumerator of a UnityTest would result in stopping the test run instead of failing it (case 1212000). Including a trailing semi-colon in a testName filter no longer results in all tests being run (case 1171200). Fixed and issue when Unity Test Framework exits editor on an outdated script compilation error (during api updates) [1.1.14] - 2020-04-03 Added the 'assemblyNames' command line argument for filtering on the assembly level. The dll and project level of the tree view should now correctly show the results when running tests in a player (case 1197026). Optimize usage of player connection when transfering test results (case 1229200). Ignore internal test framework tests assertions (case 1206961). [1.1.13] - 2020-03-16 Fixed an issue where a combination of Entering / Exiting playmode and recompiling scripts would result in the test run repeating (case 1213958). Fixed a regression from 1.1.12 where prefabs left in the scene would be cleaned up to aggressively. Fixed Test execution timed out. No activity received from the player in 600 seconds error when player is not supposed to start (case 1225147) [1.1.12] - 2020-03-02 Now 'Open error line' for a failed UTF test does not throw exceptions for corrupted testable pdb in Editor release mode (case 1118259) Fixed an issue where running a test fixture would also run other fixtures with the same full name (namespace plus classname) in other assemblies (case 1197385). Running tests with the same full name, with a domain reload inbetween, will no longer fail to initialize the fixture of the second class (case 1205240). Running a playmode tests with \"Maximize on Play\" will now correctly show the result of the tests in the test runner window (case 1014908). Fixed an issue where leaving a game object in a scene with a DontSaveInEditor hideFlags would result in an error on cleanup (case 1136883). Now ITestPlayerBuildModifier.ModifyOptions is called as expected when running tests on a device (case 1213845) [1.1.11] - 2020-01-16 Fixed test runner dlls got included into player build (case 1211624) Passing a non-full-path of XML file for -testResults in Unity Batchmode issue resolved, now passing \"result.xml\" creates the result file in the project file directory (case 959078) Respect Script Debugging build setting when running tests [1.1.10] - 2019-12-19 Introduced PostSuccessfulLaunchAction callback Fixed an issue where canceling a UnityTest while it was running would incorrectly mark it as passed instead of canceled. Added command line argument for running tests synchronously. The test search bar now handles null values correctly. The test output pane now retains its size on domain reloads. [1.1.9] - 2019-12-12 Rolled back refactoring to the test run system, as it caused issues in some corner cases. [1.1.8] - 2019-11-15 Ensured that a resumed test run is continued instantly. [1.1.7] - 2019-11-14 Fixed an issue with test runs after domain reload. [1.1.6] - 2019-11-12 Building a player for test will no longer look in unrelated assemblies for relevant attributes. [1.1.5] - 2019-10-23 Fixed a regression to synchronous runs introduced in 1.1.4. [1.1.4] - 2019-10-15 Running tests in batch mode now correctly returns error code 3 (RunError) when a timeout or a build error occurs. Fixed an issue where a test run in a player would time out, if the player takes longer than 10 minutes to run. Added command line argument and api setting for specifying custom heartbeat timeout for running on players. [1.1.3] - 2019-09-23 Fixed a regression where tests in a player would report a timeout after a test run is finished. Made it possible for the ui to change its test items when the test tree changes without script compilation. Added synchronous runs as an option to the TestRunnerApi. [1.1.2] - 2019-09-11 Fixed an issue where Run Selected would run all tests in the category, if a category filter was selected, regardless of what tests were selected. Unsupported attributes used in UnityTests now give an explicit error. Added support for the Repeat and Retry attributes in UnityTests (case 1131940). Tests with a explicit timeout higher than 10 minutes, no longer times out after running longer than 10 minutes when running from command line (case 1125991). Fixed a performance regression in the test runner api result reporting, introduced in 2018.3 (case 1109865). Fixed an issue where parameterized test fixtures would not run if selected in the test tree (case 1092244). Pressing Clear Results now also correctly clears the counters on the test list (case 1181763). Prebuild setup now handles errors logged with Debug.LogError and stops the run if any is logged (case 1115240). It now also supports LogAssert.Expect. [1.1.1] - 2019-08-07 Tests retrieved as a test list with the test runner api incorrectly showed both mode as their TestMode. Fixed a compatibility issue with running tests from rider. [1.1.0] - 2019-07-30 Introduced the TestRunnerApi for running tests programmatically from elsewhere inside the Editor. Introduced yield instructions for recompiling scripts and awaiting a domain reload in Edit Mode tests. Added a button to the Test Runner UI for clearing the results. [1.0.18] - 2019-07-15 Included new full documentation of the test framework. [1.0.17] - 2019-07-11 Fixed an issue where the Test Runner window wouldn’t frame selected items after search filter is cleared. Fixed a regression where playmode test application on the IOS platform would not quit after the tests are done. [1.0.16] - 2019-06-20 Fixed an issue where the Test Runner window popped out if it was docked, or if something else was docked next to it, when re-opened (case 1158961) Fixed a regression where the running standalone playmode tests from the ui would result in an error. [1.0.15] - 2019-06-18 Added new [TestMustExpectAllLogs] attribute, which automatically does LogAssert.NoUnexpectedReceived() at the end of affected tests. See docs for this attribute for more info on usage. Fixed a regression where no tests would be run if multiple filters are specified. E.g. selecting both a whole assembly and an individual test in the ui. Fixed an issue where performing Run Selected on a selected assembly would run all assemblies. Introduced the capability to do a split build and run, when running playmode tests on standalone devices. Fixed an error in ConditionalIgnore, if the condition were not set. [1.0.14] - 2019-05-27 Fixed issue preventing scene creation in IPrebuildSetup.Setup callback when running standalone playmode tests. Fixed an issue where test assemblies would sometimes not be ordered alphabetically. Added module references to the package for the required modules: imgui and jsonserialize. Added a ConditionalIgnore attribute to help ignoring tests only under specific conditions. Fixed a typo in the player test window (case 1148671). [1.0.13] - 2019-05-07 Fixed a regression where results from the player would no longer update correctly in the UI (case 1151147). [1.0.12] - 2019-04-16 Added specific unity release to the package information. [1.0.11] - 2019-04-10 Fixed a regression from 1.0.10 where test-started events were triggered multiple times after a domain reload. [1.0.10] - 2019-04-08 Fixed an issue where test-started events would not be fired correctly after a test performing a domain reload (case 1141530). The UI should correctly run tests inside a nested class, when that class is selected. All actions should now correctly display a prefix when reporting test result. E.g. \"TearDown :\". Errors logged with Debug.LogError in TearDowns now append the error, rather than overwriting the existing result (case 1114306). Incorrect implementations of IWrapTestMethod and IWrapSetUpTearDown now gives a meaningful error. Fixed a regression where the Test Framework would run TearDown in a base class before the inheriting class (case 1142553). Fixed a regression introduced in 1.0.9 where tests with the Explicit attribute could no longer be executed. [1.0.9] - 2019-03-27 Fixed an issue where a corrupt instance of the test runner window would block for a new being opened. Added the required modules to the list of package requirements. Fixed an issue where errors would happen if the test filter ui was clicked before the ui is done loading. Fix selecting items with duplicate names in test hierarchy of Test Runner window (case 987587). Fixed RecompileScripts instruction which we use in tests (case 1128994). Fixed an issue where using multiple filters on tests would sometimes give an incorrect result. [1.0.7] - 2019-03-12 This is the first release of Unity Package com.unity.test-framework. Migrated the test-framework from the current extension in unity."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Unity Test Framework overview What's new Edit Mode vs. Play Mode tests Getting started with UTF How to create a new test assembly How to create a test How to run a test How to run a Play Mode test as standalone Extending UTF How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests Reference Running tests from the command-line Test settings file UnityTest attribute Setup and cleanup at build time IPrebuildSetup IPostBuildCleanup Actions outside of tests Action execution order UnitySetUp and UnityTearDown OuterUnityTestAction Domain Reloads Custom attributes ConditionalIgnore attribute ParameterizedIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute Custom equality comparers ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Custom equality comparers with equals operator Test Utils Custom yield instructions IEditModeTestYieldInstruction EnterPlayMode ExitPlayMode RecompileScripts WaitForDomainReload Custom assertion LogAssert Custom constraints Is Parameterized tests MonoBehaviour tests MonoBehaviourTest<T> IMonoBehaviourTest TestRunnerApi ExecutionSettings Filter ITestRunSettings ICallbacks IErrorCallbacks Async tests Learn Unity Test Framework Overview General introduction Intro Running a test in a Unity project Arrange, act, assert Semantic test assertion Custom comparison Asserting logs Setup and teardown Play mode tests Play mode tests in a player Using the UnityTest attribute Long-running tests Scene-based tests Setup and cleanup at build time Domain reload Preserve test state Test cases Custom attributes Running tests programmatically Testing Lost Crypt Intro Setting up Running a test in LostCrypt Moving character Reach wand test Collision test Asset change test Scene validation test Performance tests Resources"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/asset-change-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/asset-change-test.html",
    "title": "6. Asset Change Test | Inventory System",
    "summary": "6. Asset Change Test Learning Objectives This exercise will teach you a popular pattern in Game Tests to verify if Assets change over time. Exercise As you noticed inside LostCrypt, when you pick up the Wand, your character equips armor. Write a test that checks that after Sara picks up the wand, armor is equipped. Create a WandTests.cs class and implement MainScene\\_CharacterReachesWandAndEquipsArmor test. Try to observe how Sara Variant or more specifically puppet_sara GameObject changes the moment you pick up the wand. Hints You can reuse code from Reach Wand Test for the logic of the character picking up the wand. Or you can try to trigger this action programmatically. Remember that if some Unity internal APIs are not accessible for your test you might need to add a new reference inside the PlayModeTests assembly definition. Solution PlayModeTests.asmdef { \"name\": \"PlayModeTests\", \"rootNamespace\": \"\", \"references\": [ \"Unity.InputSystem\", \"Unity.InputSystem.TestFramework\", \"TestInputControl\", \"UnityEngine.TestRunner\", \"Unity.2D.Animation.Runtime\" ], \"includePlatforms\": [], \"excludePlatforms\": [], \"allowUnsafeCode\": false, \"overrideReferences\": true, \"precompiledReferences\": [ \"nunit.framework.dll\" ], \"autoReferenced\": false, \"defineConstraints\": [ \"UNITY_INCLUDE_TESTS\" ], \"versionDefines\": [], \"noEngineReferences\": false } WandTests.cs using System.Collections; using NUnit.Framework; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; using UnityEngine.Experimental.U2D.Animation; public class WandTests { private Transform _characterTransform; private float _testTimeout = 25.0f; private float _wandLocation = 21.080f; [UnityTest] public IEnumerator MainScene_CharacterReachesWandAndEquipsArmor() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); // Skip first frame so Sara have a chance to appear on the screen yield return null; var puppet = GameObject.Find(\"puppet_sara\"); var spriteLibrary = puppet.GetComponent<SpriteLibrary>(); Assert.AreEqual(spriteLibrary.spriteLibraryAsset.name, \"Sara\"); var elapsedTime = 0.0f; yield return GoRight(); while (GetCurrentCharacterPosition() <= _wandLocation) { yield return null; elapsedTime += Time.deltaTime; if (elapsedTime > _testTimeout) { Assert.Fail($\"Character did not reach location position in {_testTimeout} seconds.\"); } } // Wait for Wand pickup animation to be over. yield return new WaitForSeconds(12); Assert.AreEqual(spriteLibrary.spriteLibraryAsset.name, \"Sara_var01\"); } private float GetCurrentCharacterPosition() { // Get Main character's Transform which is used to manipulate position. if (_characterTransform == null) { _characterTransform = GameObject.Find(\"Sara Variant\").transform; } return _characterTransform.position.x; } private IEnumerator GoRight() { TestInputControl.MoveLeft = false; yield return null; TestInputControl.MoveRight = true; } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/collision-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/collision-test.html",
    "title": "5. Collision Test | Inventory System",
    "summary": "5. Collision Test Learning Objectives Check for collisions and make sure that LostCrypt does not have bugs that allow your character to move outside of the map. Exercise Take a look at a game object Environment/Character Bounds - Left. You can see that it is placed at the left side of our 2D map. It is meant to protect players from exiting the map and falling into textures. Let's see if it fulfills its purpose. Add a new test MainScene\\_CharacterDoesNotFallIntoTextures in MovementTest.cs. Make your character move left and occasionally jump with some wait interval in between jumps. In test, Assert that Sara Variant game object position is within bounds of our current scene. Hints Similarly to the previous test, let's set some arbitrary amount of seconds as our timeout. Sara should stay within the bounds of the scene for the given time. You might want to use WaitForSeconds(0.5f) between jumps to emulate User behaviour better. Study the Scene and hardcode X, and Y position used for out of map check, or better - get it dynamically from Character Bounds - Left game object. Solution MovementTest.cs using System.Collections; using NUnit.Framework; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; public class MovementTest { const float _testTimeout = 20.0f; private Transform _characterTransform; [UnityTest] public IEnumerator MainScene_CharacterDoesNotFallIntoTextures() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); yield return waitForSceneLoad(); yield return GoLeft(); while (Time.timeSinceLevelLoad < _testTimeout) { yield return new WaitForSeconds(0.5f); yield return Jump(); if (GetCurrentCharacterPosition().x < -75f && GetCurrentCharacterPosition().y < -10f) { Assert.Fail(\"Character escaped the map and fell into textures! :(\"); } } } private Vector3 GetCurrentCharacterPosition() { // Get Main character's Transform which is used to manipulate position. if (_characterTransform == null) { _characterTransform = GameObject.Find(\"Sara Variant\").transform; } return _characterTransform.position; } private IEnumerator Jump() { TestInputControl.Jump = true; yield return null; TestInputControl.Jump = false; } private IEnumerator GoLeft() { TestInputControl.MoveRight = false; yield return null; TestInputControl.MoveLeft = true; } private IEnumerator waitForSceneLoad() { while (SceneManager.GetActiveScene().buildIndex > 0) { yield return null; } } } Our test fails, we have a bug in one of our Sample Unity projects. How would you approach fixing this problem? There are plenty of possibilities, go ahead and try to fix it as part of this training: Introduce new Character Bounds Box collider that will prevent the bug from happening. Rework our Sara character collision logic."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/first-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/first-test.html",
    "title": "2. Running a test in a LostCrypt | Inventory System",
    "summary": "2. Running a test in a LostCrypt Learning Objectives Set up a simple Play Mode test for LostCrypt. Exercise Go to the Assets/Scripts directory, and spend some time exploring the scripts necessary for LostCrypt to work properly. Create a new directory Assets/Tests. In the Test Runner window click Create PlayModeTest Assembly Folder and name a new folder PlayModeTests. You should end up with Assets/Tests/PlayModeTests. Open the newly created folder and click Create Test Script in current folder in the Test Runner window. Name the file SceneSetupTests.cs. Write your first test that asserts that after loading the Main scene the current time is day. Hints In order to load scenes, please refer to UnityEngine.SceneManagement documentation. Inside Scenes/Main.unity look for GameObject FX - Day. Solution SceneSetupTests.cs using System.Collections; using System.Collections.Generic; using NUnit.Framework; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; public class SceneSetupTests { [UnityTest] public IEnumerator MainScene_LoadsCorrectlyAndItsDaytime() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); yield return null; var fxDay = GameObject.Find(\"FX - Day\"); Assert.IsTrue(fxDay != null, \"should find the 'FX - Day' object in the scene\"); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/moving-character.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/moving-character.html",
    "title": "3. Moving character | Inventory System",
    "summary": "3. Moving character Learning objectives How to use the Unity InputSystem package to have a generic way of moving your character programmatically in tests. Exercise Please make sure InputSystem is installed in your Unity project. You can verify that by checking the Package Manager. Create a new class called MovementTest.cs under Assets/Tests/PlayModeTests. Attach the reference to Unity.InputSystem and Unity.InputSystem.TestFramework in your PlayModeTests assembly definition. Create a new InputControl directory under Tests: Assets/Tests/InputControl. Inside InputControl directory, create a new assembly definition: TestInputControl.asmdef. Create a new class TestInputControl.cs where you implement following properties: public static bool MoveLeft { get; set; } public static bool MoveRight { get; set; } public static bool Jump { get; set; } Go back to your assembly definition PlayModeTests and attach the reference to newly created: TestInputControl. Finally, we need to use our TestInputControl in actual LostCrypt code. Currently Unity's InputSystem does not support an easier way of programmatically doing mocks, please see this git diff to know what to change inside CharacterController2D: diff --git a/Assets/Scripts/CharacterController2D.cs b/Assets/Scripts/CharacterController2D.cs index f8a10cf2..e0a62878 100644 --- a/Assets/Scripts/CharacterController2D.cs +++ b/Assets/Scripts/CharacterController2D.cs @@ -81,15 +81,15 @@ public class CharacterController2D : MonoBehaviour // Horizontal movement float moveHorizontal = 0.0f; - if (keyboard.leftArrowKey.isPressed || keyboard.aKey.isPressed) + if (keyboard.leftArrowKey.isPressed || keyboard.aKey.isPressed || TestInputControl.MoveLeft) moveHorizontal = -1.0f; - else if (keyboard.rightArrowKey.isPressed || keyboard.dKey.isPressed) + else if (keyboard.rightArrowKey.isPressed || keyboard.dKey.isPressed || TestInputControl.MoveRight) moveHorizontal = 1.0f; movementInput = new Vector2(moveHorizontal, 0); // Jumping input - if (!isJumping && keyboard.spaceKey.wasPressedThisFrame) + if (!isJumping && (keyboard.spaceKey.wasPressedThisFrame || TestInputControl.Jump)) jumpInput = true; } Now you are ready! Go back to MovementTest.cs and write a test that does not do any assertions (just yet), but only moves the Sara character and makes it occasionally jump. Hints You might want to use WaitForSeconds in your test, to deliberately make it run longer and see actual animation happening on your screen. In case of compilation issues, please make sure you follow the right folder structure: Tests InputControl TestInputControl.asmdef TestInputControl.cs PlayModeTests MovementTest.cs PlayModeTest.asmdef Solution PlayModeTests.asmdef { \"name\": \"PlayModeTests\", \"references\": [ \"Unity.InputSystem\", \"Unity.InputSystem.TestFramework\", \"TestInputControl\" ], \"optionalUnityReferences\": [ \"TestAssemblies\" ] } MovementTest.cs using System.Collections; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; public class MovementTest { [UnityTest] public IEnumerator MainScene_CharacterIsAbleToJump() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); yield return waitForSceneLoad(); yield return GoRight(); yield return new WaitForSeconds(2); yield return Jump(); yield return new WaitForSeconds(3); yield return GoLeft(); yield return Jump(); yield return new WaitForSeconds(2); } private IEnumerator Jump() { TestInputControl.Jump = true; yield return null; TestInputControl.Jump = false; } private IEnumerator GoRight() { TestInputControl.MoveLeft = false; yield return null; TestInputControl.MoveRight = true; } private IEnumerator GoLeft() { TestInputControl.MoveRight = false; yield return null; TestInputControl.MoveLeft = true; } private IEnumerator waitForSceneLoad() { while (SceneManager.GetActiveScene().buildIndex > 0) { yield return null; } } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/performance-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/performance-tests.html",
    "title": "8. Performance Tests | Inventory System",
    "summary": "8. Performance Tests Learning Objectives One final thing we'll explore is a package that extends Unity Test Framework with Performance Tests. Exercise The Performance Testing package can be used to measure performance in our game. This is a great tool if we want to track various regressions/progressions that happen over time in our project. In this example, you'll learn how to create a test that measures game average frames. LostCrypt does not include the Performance Testing package installed by default. Install it by following these instructions. Add the package as a dependency to the project manifest. When the package is installed, add a reference to Unity.PerformanceTesting in your PlayModeTests assembly definition to access the performance testing APIs. Create a new C# class under Assets/Tests/PlayModeTests called PerformanceTests.cs. You're now ready to complete your objective. In PerformanceTests.cs create a new function called MainScene_MeasureAverageFrames(). In this function move your character to the wand position and wait until the wand pickup effect is over. During all that time, measure the frames. Bonus Try to measure the average FPS in LostCrypt. You might need to use Time.deltaTime from UnityEngine API and Measure.Custom from the Performance Testing package API. Hints The first handful of frames after loading Scene are usually unstable, let's utilize the Measure.Frames().Scope() API to measure them into a separate scope. After your test finishes, performance results can be viewed under Window > Analysis > Performance Test Report or you can even hook into results using Callback API. Solution PerformanceTests.cs using System.Collections; using Unity.PerformanceTesting; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; public class PerformanceTests { private Transform _characterTransform; private float _wandLocation = 21.080f; [UnityTest, Performance] public IEnumerator MainScene_MeasureAverageFrames() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); using (Measure.Frames().Scope(\"Frames.MainSceneOnLoad.Unstable\")) { for (var i = 0; i < 25; i++) { yield return null; } } using (Measure.Frames().Scope(\"Frames.MainSceneGameplay\")) { yield return GoRight(); while (GetCurrentCharacterPosition() <= _wandLocation) { yield return null; } StopMoving(); yield return new WaitForSeconds(15); } } private float GetCurrentCharacterPosition() { // Get Main character's Transform which is used to manipulate position. if (_characterTransform == null) { _characterTransform = GameObject.Find(\"Sara Variant\").transform; } return _characterTransform.position.x; } private IEnumerator GoRight() { TestInputControl.MoveLeft = false; yield return null; TestInputControl.MoveRight = true; } private void StopMoving() { TestInputControl.MoveRight = false; TestInputControl.MoveLeft = false; } } Bonus Solution Measure.Custom(\"FPS\", (int)(1f / Time.deltaTime));"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/reach-wand-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/reach-wand-test.html",
    "title": "4. Reach Wand Test | Inventory System",
    "summary": "4. Reach Wand Test Learning Objectives Perform Assertions on your character position and behavior. Exercise Go back to the previous MovementTest.cs file. Write a MainScene\\_CharacterReachesWand test that makes your character move right, and checks if it reaches the wand location. Hints Look for Altar and Sara Variant game objects in your scene. You are interested in measuring the X position of your Transform objects. Wand location X position is equal float of 21.080. Main Character X position is dynamic and it changes whenever it moves. Consider setting a timeout that makes the test fail if the Wand is not reached. Solution using System.Collections; using NUnit.Framework; using UnityEngine; using UnityEngine.TestTools; using UnityEngine.SceneManagement; public class MovementTest { private Transform _characterTransform; private float _testTimeout = 25.0f; private float _wandLocation = 21.080f; [UnityTest] public IEnumerator MainScene_CharacterReachesWand() { SceneManager.LoadScene(\"Assets/Scenes/Main.unity\", LoadSceneMode.Single); yield return waitForSceneLoad(); var elapsedTime = 0.0f; yield return GoRight(); while (GetCurrentCharacterPosition() <= _wandLocation) { yield return null; elapsedTime += Time.deltaTime; if (elapsedTime > _testTimeout) { Assert.Fail($\"Character did not reach location position in {_testTimeout} seconds.\"); } } } private float GetCurrentCharacterPosition() { // Get Main character's Transform which is used to manipulate position. if (_characterTransform == null) { _characterTransform = GameObject.Find(\"Sara Variant\").transform; } return _characterTransform.position.x; } private IEnumerator GoRight() { TestInputControl.MoveLeft = false; yield return null; TestInputControl.MoveRight = true; } private IEnumerator waitForSceneLoad() { while (SceneManager.GetActiveScene().buildIndex > 0) { yield return null; } } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/scene-validation-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/scene-validation-test.html",
    "title": "7. Scene Validation Test | Inventory System",
    "summary": "7. Scene Validation Test Learning Objectives Test scene for presence of Sara and Wand game object. Utilize Test Framework feature to make this test use all scenes as fixtures. Exercise Create ValidationTest.cs file with a single namespace and two classes SceneValidationTests and GameplayScenesProvider. In the Tests class create SaraAndWandArePresent test to check that \"Sara Variant\" and \"Wand\" game objects are not null. In the Fixture class GameplayScenesProvider implement IEnumerable<string> and in generator method yield all scenes from EditorBuildSettings.scenes. Use TestFixture and TestFixtureSource annotations on SceneValidationTests class. Create a new Empty Scene and attach it to EditorBuildSettings to verify if tests are created dynamically. Hints TestFixture and TestFixtureSource NUnit annotations require Test Class to be present inside Namespace. To attach a scene to EditorBuildSettings, you need to create a new Scene, and then add it to File > Build Settings. Solution ValidationTests.cs using System.Collections; using System.Collections.Generic; using NUnit.Framework; using UnityEditor; using UnityEngine; using UnityEngine.SceneManagement; using UnityEngine.TestTools; namespace ValidationTests { [TestFixture] [TestFixtureSource(typeof(GameplayScenesProvider))] public class SceneValidationTests { private readonly string _scenePath; public SceneValidationTests(string scenePath) { _scenePath = scenePath; } [OneTimeSetUp] public void LoadScene() { SceneManager.LoadScene(_scenePath); } [UnityTest] public IEnumerator SaraAndWandArePresent() { yield return waitForSceneLoad(); var wand = GameObject.Find(\"Wand\"); var sara = GameObject.Find(\"Sara Variant\"); Assert.NotNull(wand, \"Wand object exists\"); Assert.NotNull(sara, \"Sara object exists\"); } IEnumerator waitForSceneLoad() { while (!SceneManager.GetActiveScene().isLoaded) { yield return null; } } } public class GameplayScenesProvider : IEnumerable { public IEnumerator GetEnumerator() { foreach (var scene in EditorBuildSettings.scenes) { if (!scene.enabled || scene.path == null) { continue; } yield return scene.path; } } IEnumerator IEnumerable.GetEnumerator() { return GetEnumerator(); } } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/setting-up.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/setting-up.html",
    "title": "1. Setting up LostCrypt | Inventory System",
    "summary": "1. Setting up LostCrypt Learning Objectives In this exercise you'll set up a simple Unity 2D project and import a sample project (LostCrypt). Prerequisites Unity 2020.3 LTS - recommended version of Unity for this training session C# IDE (for example Rider or Visual Studio) - not necessary but highly recommended. This way you can use features like a debugger and reliable syntax autocompletion. Exercise Open Unity Hub and click New Project. Select a blank 2D (or Core2D) project. Enter a Project Name and click Create. Visit the LostCrypt asset page. Click Add to my Assets -> Open in Unity Editor. Package Manager window opens automatically. Find Lost Crypt - 2D Sample Project. Press Download and then Import. Import Unity Package window opens. Click Import to add all additional packages and assets to your newly created project. Restart Unity if needed. Now confirm that LostCrypt works correctly. From the Project tab open Scenes/Main. Enter Play Mode by clicking Play button. You should be able to move your character around. Further reading and Resources You can read more about LostCrypt in our blog post. Hints (what can go wrong) There might be some dependency problems - please make sure LostCrypt is downloaded for the suggested Unity LTS version. Make sure you have the newest project packages in your Package Manager."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/welcome.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/LostCrypt/welcome.html",
    "title": "Testing Lost Crypt | Inventory System",
    "summary": "Testing Lost Crypt Welcome to the this training material for the Unity Test Framework (UTF). The training is structured with a selection of exercises, starting with more basic topics and then expanding on that knowledge. Each section has a Learning Objectives section, which can help you pick what exercises will teach you new things. The exercises are grouped thematically and their difficulty varies. This course focus on testing an actual game. Our candidate is the LostCrypt example project. Course outline Setting up Running a test in LostCrypt Moving character Reach wand test Collision test Asset change test Scene validation test Performance tests Prerequisites Although not technically a requirement, we strongly recommend you complete the General Introduction course before attempting this one."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/arrange-act-assert.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/arrange-act-assert.html",
    "title": "2. Arrange, Act, Assert | Inventory System",
    "summary": "2. Arrange, Act, Assert Learning Objectives In this exercise, you will learn about the core unit testing principle of AAA (Arrange, Act, Assert), which will help you structure your unit test. Intro and Motivation The Arrange, Act, Assert concept is an industry standard in unit testing. It allows for a clear distinction of the code for setting up your test, carrying out the test, and evaluation. Using this can make your test more readable both for yourself and for your colleagues. In the first part of the code, we arrange all the elements needed for the test. In the middle part, we act on the object that is under test. In the final part, we assert on the result of the act part. The three parts of the code are usually separated by an empty line. An example of Arrange, Act, Assert could look like the following: [Test] public void StringWriterTest() { // Arrange var stringWriterUnderTest = new StringWriter(); stringWriterUnderTest.NewLine = \"\\\\n\"; var testStringA = \"I am testing\"; var testStringB = \"with new line\"; // Act stringWriterUnderTest.WriteLine(testStringA); stringWriterUnderTest.WriteLine(testStringB); // Assert Assert.AreEqual(\"I am testing\\\\nwith new line\\\\n\", stringWriterUnderTest.ToString()); } It is good practice to use XUnderTest as a variable name of the class that is being tested. This helps to keep the focus of the test clean. The Act part of the code should have as few lines as possible, reflecting what is actually being tested. The assert should in the optimal case only contain assert calls, but it can also be necessary to include some lines of logic to allow for the assertion. Exercise Import the sample 2_ActArrangeAssert into your Unity Editor (version 2019.2 or newer) from the Package Manager window. In this project we have a class called StringFormatter. It has two methods of interest: void Configure(string joinDelimiter) and string Join(object[] args). The goal of this exercise is to write one or more tests, testing the Join method. For example, testing that it can join with a \";\" (semicolon) delimiter. Hints Setup of the test input and the call to Configure(\";\") would go into the Arrange part of your test. It is good practice to separate the three parts of your test (arrange, act and assert) with a blank line. Solution The exercise can be solved with a test like the following: [Test] public void JoinsObjectsWithSemiColon() { // Arrange var formatterUnderTest = new StringFormatter(); formatterUnderTest.Configure(\";\"); var objects = new object[] {\"a\", \"bc\", 5, \"d\"}; // Act var result = formatterUnderTest.Join(objects); // Assert Assert.AreEqual(\"a;bc;5;d\", result); } A full project with the solution can be found in the sample 2_ActArrangeAssert_Solution. Further reading and Resources The AAA concept is a widely used standard which you can read more about in many online sources, including this blogpost."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/asserting-logs.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/asserting-logs.html",
    "title": "5. Asserting and expecting logs | Inventory System",
    "summary": "5. Asserting and expecting logs Learning objectives How to test and verify code that writes to the console log. Intro and motivation At Unity, we have many packages and modules that communicate with the user through logging messages and exceptions to the console log. This can be both for the normal workflows and for error cases. We have extended the test framework to be aware of the console log. This means that by default, any error or exception that is logged while running a test will result in that test failing. If such failures are expected, then it is possible to use LogAssert.Expect(logtype, message) to ensure that a given message is logged. This can be used to expect normal messages and warnings as well. The LogAssert.Expect can be placed both before and after the message happens. When the test is done (or next time it yields), it will fail if the expected message is not present. [Test] public void LogAssertExample() { // Expect a regular log message LogAssert.Expect(LogType.Log, \"Log message\"); // The test fails without the following expected log message Debug.Log(\"Log message\"); // An error log Debug.LogError(\"Error message\"); // Without expecting an error log, the test would fail LogAssert.Expect(LogType.Error, \"Error message\"); } The LogAssert.Expect also takes a regex as an argument, as sometimes it is not possible to know the precise string. For example, if the logged message has time duration in the string. Exercise In the sample 5_AssertingLogs there is a class called MyLoggingClass. The class has two methods with the following behavior: DoSomething(); logs the message \"Doing something\". DoSomethingElse(); logs an error \"An error happened. Code: #\" where # is a random number from 0 to 9. Write tests that verify the above behavior using LogAssert.Expect. You can experiment by seeing what happens if DoSomethingElse(); is called without the expect and what happens if you expect e.g. a message of type warning. Hints You will need to use a regular expression together with LogAssert.Expect in order to expect the error message. In Unity, there is a difference between a logged error and a logged exception. Solution A full solution to the exercise can be found in the sample 5_AssertingLogs_Solution. One possible implementation of the tests is as follows: [Test] public void DoSomethingLogsMessage() { var loggingClassUnderTest = new MyLoggingClass(); loggingClassUnderTest.DoSomething(); LogAssert.Expect(LogType.Log, \"Doing something\"); } [Test] public void DoSomethingElseLogsError() { var loggingClassUnderTest = new MyLoggingClass(); loggingClassUnderTest.DoSomethingElse(); LogAssert.Expect(LogType.Error, new Regex(\"An error happened. Code: \\\\d\")); } Further reading and resources Documentation for LogAssert"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/build-setup-cleanup.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/build-setup-cleanup.html",
    "title": "12. Setup and cleanup at build time | Inventory System",
    "summary": "12. Setup and cleanup at build time Learning objectives This section will introduce you to the hooks in the test framework for before and after the player build. Intro and motivation Sometimes it's necessary to change settings or prepare assets before a build for Play Mode tests. Similarly, it might be relevant to clean up things after the build. For this the test framework has two hookup points called PrebuildSetup and PostBuildCleanup. In the Editor, the PrebuildSetup is invoked before the build and test run and the PostBuildCleanup is invoked after the tests are completely done. This happens for both Edit Mode and Play Mode tests. When running Play Mode tests on a device, the Cleanup is already run right after the build is done, as the tests are happening in parallel on the device. The simplest way of ensuring a test has a PrebuildSetup and PostBuildCleanup is by implementing IPrebuildSetup and IPostBuildCleanup respectively in your test class. Often the setup and cleanup will be interacting with code in the UnityEditor assemblies. These are not available when running on a device, but we want our built-in setup and cleanup code to stay in the test class. For this, it's recommended to wrap the Editor-related code lines in #if UNITY_EDITOR defines. For example: public class MyTestClass : IPrebuildSetup { [Test] public void MyTest() { } public void Setup() { #if UNITY_EDITOR UnityEditor.EditorSettings.serializationMode = SerializationMode.ForceText; #endif } } Note: If the Editor code is not wrapped, then you won't see any compilation error when running in the Editor, but you will see the compilation error once you try to run the test in a player. Exercise The sample 12_BuildSetupCleanup contains a Play Mode test for verifying the content of a scene. It is essentially the Play Mode version of the test from the previous exercise. The test fails because the scene can't be found. It could be solved by adding the scene to the build settings, but it's not good practise to add a test-related scene to the build settings, as it could get included when building for non-testing purposes. Therefore the task is to create a PrebuildSetup that adds the scene to EditorBuildSettings and a PostBuildCleanup that removes it again. Test the solution by running the test both in the Editor and in a standalone player. You will need to use #if UNITY_EDITOR to make the code compile for the player. Hints The IPrebuildSetup interface requires a Setup method, so be careful that there are no [SetUp] methods already called that. Solution A full solution is available in the sample 12_BuildSetupCleanup_Solution. The full test solution can be done like this: using System.Collections; using System.Linq; using NUnit.Framework; #if UNITY_EDITOR using UnityEditor; #endif using UnityEngine; using UnityEngine.SceneManagement; using UnityEngine.TestTools; namespace Tests { public class SceneTests : IPrebuildSetup, IPostBuildCleanup { private string originalScene; private const string k_SceneName = \"Assets/MyGameScene.unity\"; public void Setup() { #if UNITY_EDITOR if (EditorBuildSettings.scenes.Any(scene => scene.path == k_SceneName)) { return; } var includedScenes = EditorBuildSettings.scenes.ToList(); includedScenes.Add(new EditorBuildSettingsScene(k_SceneName, true)); EditorBuildSettings.scenes = includedScenes.ToArray(); #endif } [UnitySetUp] public IEnumerator SetupBeforeTest() { originalScene = SceneManager.GetActiveScene().path; SceneManager.LoadScene(k_SceneName); yield return null; // Skip a frame } [Test] public void VerifyScene() { var gameObject = GameObject.Find(\"GameObjectToTestFor\"); Assert.That(gameObject, Is.Not.Null, $\"GameObjectToTestFor not found in {SceneManager.GetActiveScene().path}.\"); } [TearDown] public void TeardownAfterTest() { SceneManager.LoadScene(originalScene); } public void Cleanup() { #if UNITY_EDITOR EditorBuildSettings.scenes = EditorBuildSettings.scenes.Where(scene => scene.path != k_SceneName).ToArray(); #endif } } } Note that #if UNITY_EDITOR is also used among the using statements, to allow for a using reference to UnityEditor. Further reading and resources UTF documentation for PrebuildSetup and PostBuildCleanup."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/custom-attributes.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/custom-attributes.html",
    "title": "16. Custom attributes | Inventory System",
    "summary": "16. Custom attributes Learning objectives In this section we will look at some ways of implementing custom NUnit attributes, which can be used to alter test execution. Intro and motivation A powerful part of NUnit is that it is very extendable. One of the ways it can be extended is through custom attributes. An example is attributes that implement the IWrapTestMethod interface. This interface has a method for wrapping a TestCommand, which implements a method for executing. Normally these test commands do something, call execute on their inner command and then maybe do something again after the inner command is completed. In the following three classes an IWrapTestMethod interface is implemented and used in a test: public class MyAttribute : NUnitAttribute, IWrapTestMethod { public TestCommand Wrap(TestCommand command) { return new MyCommand(command); } } public class MyCommand : TestCommand { private TestCommand innerCommand; public MyCommand(TestCommand command) : base(command.Test) { innerCommand = command; } public override TestResult Execute(ITestExecutionContext context) { Debug.Log(\"Before\"); var result = innerCommand.Execute(context); Debug.Log(\"After\"); return result; } } public class MyTests { [Test] [MyAttribute] public void Test1() { Debug.Log(\"The test\"); } } When running MyTests.Test1 the following output is printed: Test1 (0,017s) --- Before The test After Other interfaces that custom attributes can implement are IWrapSetUpTearDown, IApplyToContext, and IApplyToTest. Exercise At Unity we have a goal that an action should never take longer than 500 ms. In the sample 16_CustomAttributes there is a class called MyClass, which has two methods. Both methods are supposed to return true. However someone has made a regression so that one of the two methods takes a long time to run. The task is to create a new custom attribute, which detects if the test takes longer than 500 ms to run. If that happens, it should fail the test with a descriptive message. Apply that to the two existing tests. Hints You can use the class System.Diagnostics.Stopwatch to time how many miliseconds have passed. Solution A full solution for the exercise is availiable at 16_CustomAttributes_Solution. The core of the solution is the execute method in the test command implementation: public override TestResult Execute(ITestExecutionContext context) { var stopWatch = new Stopwatch(); stopWatch.Start(); var result = innerCommand.Execute(context); stopWatch.Stop(); if (stopWatch.ElapsedMilliseconds > 500) { result.SetResult(ResultState.Failure, $\"Test took {stopWatch.ElapsedMilliseconds} ms. That is longer than 500ms!\"); } return result; }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/custom-comparison.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/custom-comparison.html",
    "title": "4. Custom comparison | Inventory System",
    "summary": "4. Custom comparison Learning objectives This exercise will cover the custom equality comparers included in Unity Test Framework, such as Vector3EqualityComparer. These are used to assert on e.g. Vectors. Intro and motivation We have extended the assertion capabilities of NUnit with some custom comparisons for Unity-specific objects. A good example of this is the ability to compare two Vector3 objects. An example of its use is: actual = new Vector3(0.01f, 0.01f, 0f); expected = new Vector3(0.01f, 0.01f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector3EqualityComparer.Instance)); This allows us to verify that the two vectors are identical within a given tolerence. By default the tolerance is 0.0001f. The tolerance can be changed by providing a new Vector3EqualityComparer, instead of using the default in .instance. For example you can up the tolerance to 0.01f with the following: Assert.That(actual, Is.EqualTo(expected).Using(new Vector3EqualityComparer(0.01f)); For a list of all available custom comparers, see Custom equality comparers. Exercise Similar to the project for exercise 3, the sample 4_CustomComparison contains a ValueOutputter class. Verify that the ValueOutputter returns the correct values from its methods: GetVector3() should return a Vector3 that is roughly equal to (10.333, 3, 9.666). GetFloat() should return a float that is roughly 19.333. This is the same as previous exercise, but you can try to solve this with a FloatEqualityComparer. GetQuaternion should return a Quaternion object that should be roughly equal to (10f, 0f, 7.33333f, 0f). Hints For some of the exercises, you might need to provide a custom error tolerance to the comparer. If the comparison fails, the comparers give a message about the actual and expected value, just like a normal assertion. However, because ToString on Vector3 rounds the value off before displaying it, the two values in the string message might be equal, even when their Vector3 values are not. Solution The full solution is available in the sample 4_CustomComparison_Solution. [Test] public void Vector3ReturnsCorrectValue() { var valueOutputterUnderTest = new ValueOutputter(); var vector3 = valueOutputterUnderTest.GetVector3(); var expected = new Vector3(10.333f, 3f, 9.666f); Assert.That(vector3, Is.EqualTo(expected).Using(new Vector3EqualityComparer(0.001f))); } [Test] public void FloatReturnsCorrectValue() { var valueOutputterUnderTest = new ValueOutputter(); var actualFloat = valueOutputterUnderTest.GetFloat(); Assert.That(actualFloat, Is.EqualTo(19.333f).Using(new FloatEqualityComparer(0.001f))); } [Test] public void QuaternionReturnsCorrectValue() { var valueOutputterUnderTest = new ValueOutputter(); var actualValue = valueOutputterUnderTest.GetQuaternion(); var expectedValue = new Quaternion(10f, 0f, 7.33333f, 0f); Assert.That(actualValue, Is.EqualTo(expectedValue).Using(new QuaternionEqualityComparer(0.001f))); } Further reading and resources Custom equality comparers"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/domain-reload.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/domain-reload.html",
    "title": "13. Domain reload | Inventory System",
    "summary": "13. Domain reload Learning objectives In this section, you will learn how to invoke and wait for Domain Reloads. Intro and motivation When performing actions that affect the scripts in a project, Unity performs a domain reload. Since a domain reload restarts all scripts, then it's necessary to mark any expected domain reload by yielding a WaitForDomainReload. The command stops any further code execution and then resumes after the domain reload is done. It's also possible to yield a RecompileScripts command. This does the same as WaitForDomainReload except that it performs an AssetDatabase.Reload() call. Both calls can be configured to expect whether a script compilation is expected to succeed. If a domain reload happens while a test is running without yielding one of these commands, then the test will fail with an error about an unexpected domain reload. Exercise The sample 13_DomainReload_Solution is set up with a test class called ScriptAddingTests. The test has two helper methods already implemented: CreateScript creates a C# script with a class called MyTempScript. That has a method called Verify. VerifyScript instantiates an instance of MyTempScript using reflection and returns the value from the Verify method. The expected return value is the string \"OK\". After running CreateScript Unity now has a new C# file in the project and thus needs to recompile. The task is to create a test that calls CreateScript, handles the domain reload and then verifies the output from VerifyScript. Remember that your script should also clean up after itself, by deleting the file and recompiling the script again. This is recommended to do in a TearDown or UnityTearDown, which will run even if the test fails. Important: After importing, you should move the sample test folder Tests_13 into the Assets folder for this exercise to work. Hints If RecompileScripts is unavailable to you due to it being internal, then you need to upgrade the Unity Test Framework package to version 1.1.0 or higher. If you are on a non-Windows machine you might want to change paths inside k_fileName or use C# Path.Combine for more cross-platform safe code. Solution A full solution is available in the sample 13_DomainReload_Solution. The test can be implemented as follows: internal class ScriptAddingTests { private const string k_fileName = @\"Assets\\\\Tests\\\\TempScript.cs\"; [UnityTest] public IEnumerator CreatedScriptIsVerified() { CreateScript(); yield return new RecompileScripts(); var verification = VerifyScript(); Assert.That(verification, Is.EqualTo(\"OK\")); } [UnityTearDown] public IEnumerator Teardown() { if (!File.Exists(k_fileName)) { yield break; } File.Delete(k_fileName); yield return new RecompileScripts(); } private void CreateScript() { File.WriteAllText(k_fileName, @\" public class MyTempScript { public string Verify() { return \"\"OK\"\"; } }\"); } private string VerifyScript() { Type type = Type.GetType(\"MyTempScript\", true); object instance = Activator.CreateInstance(type); var verifyMethod = type.GetMethod(\"Verify\", BindingFlags.Instance | BindingFlags.Public); var verifyResult = verifyMethod.Invoke(instance, new object[0]); return verifyResult as string; } } Further reading and resources Documentation for RecompileScripts. Documentation for WaitForDomainReload."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/long-running-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/long-running-tests.html",
    "title": "10. Long running tests | Inventory System",
    "summary": "10. Long running tests Learning objectives This exercise will cover best practices and pitfalls for tests that have a long runtime, such as tests yielding back a WaitForSeconds. Intro and motivation In Play Mode it is possible for UnityTests to return Yield instructions, such as WaitForSeconds. This is supported because in some test cases it can be valid to wait for a limited time. However, long-running tests are in general a bad practice that should be avoided when possible. If you can't avoid a long-running test, it's recommended to provide the test with [Category] and [Explicit] attributes. The [Category] attribute is used to label tests with a category name that can later be used as a filter to run a subset of tests selectively. The [Explicit] attribute ensures that the test is not run by default when running all tests. The test is only run when it is explicitly selected in the UI, or when its category is selected. [UnityTest] [Explicit, Category(\"integration\")] public IEnumerator MySlowTest() { ... } In practice, this means that if you give some long-running tests the category \"integration\", then they will only be run if the \"integration\" category is selected. This makes it possible to keep \"All tests\" running relatively fast, even on a large project. It is also possible to specify the [Explicit] and [Category] attributes on a class level, which then applies to all tests in the class and on an assembly level, which applied to all tests inside that assembly. An example with it applied to assemblies: [assembly:Explicit] [assembly:Category(\"integration\")] It is a good practice to have assembly level attributes defined in an AssemblyInfo.cs file. Exercise Import the sample 10_LongRunningTests, which is set up with a test assembly for Play Mode. The exercise is to add a new UnityTest, which yields back a WaitForSeconds command and then tag it accordingly with [Category] and [Explicit] tags. When pressing RunAll, the test should be skipped. When the Category is selected in the category drop down in the UI, then the test should not be skipped when RunAll is selected. Solution The sample 10_LongRunningTests_Solution contains the solution. The implemented test can look like this: [UnityTest] [Explicit, Category(\"integration\")] public IEnumerator ASlowTest() { yield return new WaitForSeconds(5); } Further reading and resources Nunit documentation for the Category attribute"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/overview.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/overview.html",
    "title": "Unity Test Framework learning materials | Inventory System",
    "summary": "Unity Test Framework learning materials This section contains courses to help you learn Unity Test Framework through a series of applied exercises. The courses are: The Unity Test Framework General Introduction, which gives you an opportunity to try out some of the framework's core features through general examples. Each exercise in this course is accompanied by a sample project and corresponding solution, which you can import from the Package Manager window. Testing Lost Crypt, which shows you how to use the framework to test an actual game project. We strongly recommend that you complete the General Introduction before you attempt Testing Lost Crypt."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/play-mode-tests-in-player.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/play-mode-tests-in-player.html",
    "title": "8. PlayMode tests in a Player | Inventory System",
    "summary": "8. PlayMode tests in a Player Learning objectives This section will teach you how to run Play Mode tests in a Standalone player on your machine. Intro and motivation A huge area in our quality assurance using automated testing is the ability to test on different types of platforms. This is both useful for us and our customers, allowing them to verify their application on everything from phones to consoles. The simplest setup to run on a platform is to run as standalone on your own computer. If you have the Unity standalone platform support for your OS installed, then you can run your Play Mode tests by clicking the Run all in player button. For more detailed instructions, see Run play mode tests in a standalone player. Exercise Import the sample 8_PlayModeTests_InPlayer. This project contains the solution to the previous exercise, which is just a simple Play Mode test. Execute the test in your standalone player by clicking the Run all in player button in the Play Mode tab."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/play-mode-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/play-mode-tests.html",
    "title": "7. PlayMode tests | Inventory System",
    "summary": "7. PlayMode tests Learning objectives This exercise introduces the concept of Play Mode tests and will teach you: When to use Play Mode tests. How to set up an assembly definition for PlayMode tests. How to run tests in Play Mode. Intro and motivation Managed code in Unity generally exists in two different modes: Edit Mode and Play Mode. Edit Mode is code executing inside the Editor, which includes things like our UIs and underlying logic. Play Mode is when the game or 3D application is playing, which is either when the user presses the play button in the Editor or when the code runs in a standalone player. We have distinct tests for each mode because how they run and what they can access is different in each case. Methods from a given API may only be available in one mode. Due to this distinction, tests for Edit Mode and Play Mode are in different assemblies. You can create a Play Mode test assembly by following the instructions in the Play Mode tab of the Test Runner UI. Detailed instructions are available in the Getting started section. The difference in the assembly definition between Edit Mode and Play Mode is what platforms they are enabled for. An Edit Mode test assembly is only enabled for the Editor platform. Enabling any other platforms automatically makes it a Play Mode test assembly, as tests can now run on other platforms. By default, Play Mode tests are set to run on all platforms. Exercise The sample 7_PlayModeTests contains an empty project. Import this sample and add a new assembly for Play Mode tests. Afterwards add a test which just asserts that Application.isPlaying is true. This flag will only be true when in Play Mode. Run the test. Notice that your Editor enters Play Mode (the equivalent of pressing the play button) while the test is running and exits Play Mode afterward. Solution A full solution with the test and assembly setup is available in the 7_PlayModeTests_Solution sample. Further reading and resources EditMode vs PlayMode"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/preserve-test-state.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/preserve-test-state.html",
    "title": "14. Preserve test state | Inventory System",
    "summary": "14. Preserve test state Learning objectives This section will cover how to let variables and information in your tests survive domain reloads using serialization. Intro and motivation When a domain reload happens, all scripts are reloaded. That also means that most data in members of the test class are lost. In some cases that is an issue, as you might want to retain some information during a domain reload. The solution to that is serialization. If you add a [SerializeField] attribute to the field in question, then it will retain its value. Note that there are some limitations to serialization in Unity, see Unity Serialization. Exercise The sample 14_PreserveTestState contains the solution for the previous assignment, with one exception; the file name is now a guid. This means that in order to clean up correctly, the TearDown method needs to know the filename. Currently, when running the test for the first time, the TearDown will fail because it's not given a file name. On subsequent runs of the test, it will fail due to duplicate files with the same C# script in it. The task is to fix this loss of the file name info by using serialization. Solution The solution is simple. Just add a [SerializeField] attribute to the filename field. The solution is included as sample 14_PreserveTestState_Solution."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/running-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/running-test.html",
    "title": "1. Running a test in a Unity project | Inventory System",
    "summary": "1. Running a test in a Unity project Learning objectives This exercise will teach you how to set up a simple Unity project with a test assembly and tests. It will also introduce the structure of unit tests based on NUnit. Intro and motivation At Unity, our main way of testing content is using the Unity Test Framework, which comes as a default package in the Unity Editor. Knowing how to set up a basic project with tests can help you get started on your journey. Exercise Import the sample 1_RunningTest_Project into your Unity Editor (version 2019.2 or newer) from the Package Manager window. Note: The project contains one .cs file (MyMath.cs), which is a simple math implementation. The exercise is to create unit tests for this class. Open up the Test Runner UI (Window > General > TestRunner) and set up a new EditMode test assembly alongside the MyExercise folder. Detailed instructions are available in the Getting started section. Create a new test inside the new test assembly folder (default name is Tests) either from the Test Runner UI or by right-clicking in the Project window and selecting Create > Testing > C# test script. Before we do the test, it is also necessary to link up our test assembly with the existing code assembly. Click on the test assembly you created in the Project window to see it in the Inspector (Click on the Tests folder > Tests). In the Assembly Definition References, you will see that UnityEngine.TestRunner and UnityEditor.TestRunner are already referenced, along with an assembly reference to NUnit. Click the `+` button in the Assembly Definition Reference part to add a new reference. Click on the little circle and select MyExercise and click Apply in the bottom of the inspector (you might need to scroll down). Open up the C# solution with your IDE (Visual Studio or Rider) and open up the test file you created. You can delete the method with the [UnityTest] attribute, as you won't be needing that. In the method with [Test] attribute, you can add an assert statement, to verify that MyMath.Add works correctly. E.g. using Assert.AreEqual. Rename the method to be something more descriptive. A good practice is that the method name should describe what is being tested. For example, the class name could be MyMathTests and the first test could then be AddsTwoPositiveIntegers. If you want to, you can add additional methods that test other number combinations. It is a best practice that each test should have just one check. Switch back to Unity and go to the Test Runner UI. Here you should now see a tree structure which includes your test assembly name, the class name and method name. This reflects the general structure of tests with NUnit, which is the framework that Unity Test Framework is built on top of. Each class can have multiple tests and there can be multiple test classes in a namespace / assembly. You can double click on your test name or any of its parents to run the test. You will see a green checkmark if your test code passes and a red cross if your test code failed. Note that if you do not see any tests, remember to check your console log. Any compile error would block all tests from being shown. You can now go back to your test code and add tests for the Subtract method. Note that you will likely see the tests fail, as there is a bug in our Subtract method. After you have seen your test fail with a meaningful error (e.g. Expected 2, but got 6), you can go to MyMath.cs and fix the return value to be just return a - b;. Then rerun the test to verify that you fixed the error. Hints Sometimes the UI for creating a test assembly and creating your first test file can be a bit hard to use. If the Test Runner UI does not register your assembly, try clicking on the folder in the project window or navigate to the folder with the asmdef. Solution A solution for this exercise can be found in the sample 1_RunningTest_Project_Solution. The solution contains a Tests folder with an asmdef file and and one .cs file, containing the tests. Further reading and resources Read more about Assembly Definitions in the Unity manual. You can read more about unit tests in general at Introduction To Unity Unit Testing."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/running-tests-programmatically.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/running-tests-programmatically.html",
    "title": "17. Running tests programmatically | Inventory System",
    "summary": "17. Running tests programmatically Learning objectives This section will introduce the TestRunnerApi, teaching you how to trigger a test run programmatically. Intro and motivation A recent new feature in the test framework is the addition of the TestRunnerApi. This api allows for interactions with the test framework programmatically, such as listing tests, running tests and receiving test results. For details and examples, see the TestRunnerApi documentation. Exercise The sample 17_RunningTestsProgrammatically contains a mono behavior script called MyMonoBehaviour, which has a property for whether it has been configured. The project also contains a scene with multiple game objects with MyMonoBehaviour on them. The task is to create a set of scene validation tests, which verifies that the scene MyScene.unity: The scene contains precisely 5 game objects with MyMonoBehaviour on them. All game objects with MyMonoBehaviour must have IsConfigured set to true After these tests have been created, implement a MenuItem, which can trigger the test run of the scene validation tests, using the TestRunnerApi and report the result to the console log. It is recommended to give your scene validation test a category, so it is easier to make a filter that runs those exclusively. Hints Remember to include the test mode in the filter provided to Execute Solution A full example solution for the excersise is available in the sample 17_RunningTestsProgrammatically_Solution."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/scene-based-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/scene-based-tests.html",
    "title": "11. Scene-based tests | Inventory System",
    "summary": "11. Scene-based tests Learning objectives In this exercise, you will learn how to test content that is stored in a scene. Intro and motivation A useful scenario for our customers is using the test framework for verifying the content of a scene. That could be checking for certain GameObjects and MonoBehaviors. The EditorSceneManager allows for loading and saving scenes. In combination with the test framework, this allows for the implementation of tests that verify a scene. When changing the state of the Editor in a test, such as loading a scene, it's good practice to clean up afterward. This can be done in a method with the [TearDown] attribute. Exercise Import the sample 11_SceneBasedTests, which contains a scene named MyGameScene and an assembly for Edit Mode tests. The task is to create a test that opens the scene, verifies that the scene contains a game object named GameObjectToTestFor. As cleanup, it should open a new empty scene, which is the default for Edit Mode tests. It is recommended to put that in a [TearDown], which ensures that the cleanup code is run, even if the test fails. Hints EditorSceneManager.OpenScene(\"Assets\\\\MyGameScene.unity\"); loads the scene EditorSceneManager.NewScene(NewSceneSetup.DefaultGameObjects, NewSceneMode.Single); cleans up by changing back to an empty scene. Solution A full solution is available in the sample 11_SceneBasedTests_Solution. The test implementation can look like this: public class SceneTests { [SetUp] public void Setup() { EditorSceneManager.OpenScene(\"Assets\\\\MyGameScene.unity\"); } [Test] public void VerifyScene() { var gameObject = GameObject.Find(\"GameObjectToTestFor\"); Assert.That(gameObject, Is.Not.Null); } [TearDown] public void Teardown() { EditorSceneManager.NewScene(NewSceneSetup.DefaultGameObjects, NewSceneMode.Single); } } Further reading and resources Documentation for EditorSceneManage api"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/semantic-test-assertion.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/semantic-test-assertion.html",
    "title": "3. Semantic test assertion | Inventory System",
    "summary": "3. Semantic test assertion Learning objectives This exercise introduces the Assert.That and related classes. Intro and motivation The NUnit test framework and the Unity Test Framework have a series of classes for asserting objects in a way that is closer to natural language. This makes the statements easily readable. Here are some examples on how to use the semantic assertion classes: Assert.That(myValue, Is.GreaterThan(20)); Assert.That(str, Does.Contain(\"a string\").And.Contain(\"something else\")); Here we check that the variable myValue is greater than 20 and then that the string str contains both \"a string\" and \"something else\". The semantic assertion is also known as Constraint Model. Other than It and Does there are multiple other keywords that can be used. Exercise In the 3_SemanticTestAssertion sample, there is a class called ValueOutputter, which returns values of different types. Write tests that assert on the different outputs. It should be verified that: GetInt() returns 11. GetString() returns a string that contains the words string and asserted. GetFloat() returns a value that is around 19.33. Hints Asserting on the float might require a check for the value being greater than 19.33 and less than 19.34, as the output is not rational. Solution A full solution to the exercise is available in the sample 3_SemanticTestAssertion_Solution. internal class ValueOutputterTests { [Test] public void GivesExpectedInt() { var outputterUnderTest = new ValueOutputter(); var number = outputterUnderTest.GetInt(); Assert.That(number, Is.EqualTo(11)); } [Test] public void GivesExpectedString() { var outputterUnderTest = new ValueOutputter(); var str = outputterUnderTest.GetString(); Assert.That(str, Does.Contain(\"string\").And.Contain(\"asserted\")); } [Test] public void GivesExpectedFloat() { var outputterUnderTest = new ValueOutputter(); var number = outputterUnderTest.GetFloat(); Assert.That(number, Is.GreaterThan(19.33f).And.LessThan(19.34f)); } } Further reading and resources NUnit 2 documentation for the constraint model"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/setup-teardown.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/setup-teardown.html",
    "title": "6. SetUp and TearDown | Inventory System",
    "summary": "6. SetUp and TearDown Learning objectives In this exercise, you will get practical experience in using the NUnit attributes [SetUp] and [TearDown] in order to reduce code duplication in your tests. Intro and motivation It's good practice to always let your test code clean up after itself and you also often need to set things up before running a test. If you have multiple tests, then that can easily become a lot of code duplication and if your test fails, your cleanup might not even be run, if you have not wrapped it in try and finally blocks. As a solution to this, NUnit has the [SetUp] and [TearDown] attributes. Methods with this attribute will be run before and after any of the classes respectively. If you are running multiple tests in your class at once, then the teardown and setup are run in between each of the tests. public class TestClass { [SetUp] public void MySetUp() { ... } [Test] public void MyFirstTest() { ... } [Test] public void MySecondTest() { ... } [TearDown] public void MyTearDown() { ... } } Exercise Import the sample 6_SetUpTearDown. In this project there is a class called FileCreator. It has two methods: CreateEmptyFile(fileName) - Creates an empty file in an OutputFiles directory CreateFile(string fileName, string content) - Creates a file with the given content in an OutputFiles directory The catch is that it will throw a DirectoryNotFoundException, if there is no output called OutputFiles in the current directory. You will need to create this directory inside a SetUp method and remove it again afterwards with a TearDown. Your test can then assume that it starts with an emtpy directory, which simplifies the assertion. Hints You can use Directory.CreateDirectory to create a directory. You can use Directory.Delete with the recursive flag (second argument) set to delete the directory along with all its files. Directory.GetFiles can be used to get files in a given directory. Path.Combine is a handy method for combining parts of a file path. For example the directory name and the file name. Solution The exercise can be solved with a test like the following: [SetUp] public void Setup() { Directory.CreateDirectory(FileCreator.k_Directory); } [Test] public void CreatesEmptyFile() { var fileCreatorUnderTest = new FileCreator(); var expectedFileName = \"MyEmptyFile.txt\"; fileCreatorUnderTest.CreateEmptyFile(expectedFileName); var files = Directory.GetFiles(FileCreator.k_Directory); Assert.That(files.Length, Is.EqualTo(1), \"Expected one file.\"); var expectedFilePath = Path.Combine(FileCreator.k_Directory, expectedFileName); Assert.That(files[0], Is.EqualTo(expectedFilePath)); } [Test] public void CreatesFile() { var fileCreatorUnderTest = new FileCreator(); var expectedFileName = \"MyFile.txt\"; var expectedContent = \"TheFileContent\"; fileCreatorUnderTest.CreateFile(expectedFileName, expectedContent); var files = Directory.GetFiles(FileCreator.k_Directory); Assert.That(files.Length, Is.EqualTo(1), \"Expected one file.\"); var expectedFilePath = Path.Combine(FileCreator.k_Directory, expectedFileName); Assert.That(files[0], Is.EqualTo(expectedFilePath)); var content = File.ReadAllText(expectedFilePath); Assert.That(content, Is.EqualTo(expectedContent)); } [TearDown] public void Teardown() { Directory.Delete(FileCreator.k_Directory, true); } A full project with the solution can be found in the sample 6_SetUpTearDown. Further reading and resources Nunit documentation for SetUp and TearDown"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/test-cases.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/test-cases.html",
    "title": "15. Test cases | Inventory System",
    "summary": "15. Test cases Learning objectives This section will cover [TestCase] and similar NUnit attributes and how to work with them in UnityTests. Intro and motivation NUnit has a few tools for parameterized tests, which can be used to specify test cases with variating parameters. This can drastically reduce the amount of repeated code and make the test cleaner to use. An example of a parameterized test using the [TestCase] attribute: [Test] [TestCase(49, \"a string\", true)] [TestCase(9, \"something\", false)] public void MyTest(int firstValue, string secondValue, bool expectedOutcome) { ... } This will generate two tests, each with a different input to the method body. In addition to the [TestCase] attribute, NUnit also has a [Values] attribute, which specifies a set of values on each individual input. An example of such is: [Test] public void MyTest([Values(49, 9)]int firstValue, [Values(\"a string\", \"something\")]string secondValue) { ... } When specifying multiple input parameters, they are treated as combinatorial. That means that each combination of them will be tested. For the above example, that will result in a total of 4 cases: MyTest(49, \"a string\") MyTest(49, \"something\") MyTest(9, \"a string\") MyTest(9, \"something\") This can easily explode into many combinations. The combinations might not all be valuable and would just waste time, so use this with care. For both the [TestCase] and [Values] attributes, there is a more dynamic version called [TestCaseSource] and [ValueSource] accordingly. These each take in a static method or array, returning a collection of objects. Of these 4 methods, the [ValueSource] attribute is currently the only one supported by [UnityTest]. Since this would produce combinational tests, if multiple arguments with [ValueSource] are provided, then it is recommended to make a test case struct, if multiple arguments are needed for the test. An example of such could look like this: [UnityTest] public IEnumerator AddAsyncCalculatesCorrectValue([ValueSource(nameof(TestCases))] TestCase testCase) { ... } private static IEnumerable TestCases() { yield return new TestCase {value1 = 4, value2 = \"a string\"}; yield return new TestCase {value1 = 8, value2 = \"another string\"}; } public struct TestCase { public int value1; public string value2; public override string ToString() { return $\"{value1}, {value2}\"; } } Exercise In the sample 15_TestCases a class is set up with some basic math. It has two methods: Add which takes two integers and adds them together. AddAsync also adds two integers together, but does so asynchronously, yielding back an IEnumerator The task is to add tests for the two methods. The AddAsync method first returns the result after a few frames, so that will be best suited for a [UnityTest]. Note that it is not enough to yield back the IEnumerator, as the test framework does not curently support nested yields. Instead, create a loop to move over each element until it's done. At each step of the while loop, let the test yield back null. Hints The ToString() implementation in the struct is there to provide readable info in the test runner treeview. Without it, it would just show the struct name as the test argument for every case. Solution A solution for the exercise is available in the sample 15_TestCases_Solution. Tests for both methods can be implemented as follows: [Test] [TestCase(24, 80, 104)] [TestCase(10, -15, -5)] [TestCase(int.MaxValue, 10, int.MinValue + 9)] public void AddCalculatesCorrectValue(int valueA, int valueB, int expectedResult) { var myClass = new MyClass(); var result = myClass.Add(valueA, valueB); Assert.That(result, Is.EqualTo(expectedResult)); } [UnityTest] public IEnumerator AddAsyncCalculatesCorrectValue([ValueSource(nameof(AdditionCases))] AddCase addCase) { var myClass = new MyClass(); var enumerator = myClass.AddAsync(addCase.valueA, addCase.valueB); while (enumerator.MoveNext()) { yield return null; } var result = enumerator.Current; Assert.That(result, Is.EqualTo(addCase.expectedResult)); } private static IEnumerable AdditionCases() { yield return new AddCase {valueA = 24, valueB = 80, expectedResult = 104}; yield return new AddCase {valueA = 10, valueB = -15, expectedResult = -5}; yield return new AddCase {valueA = int.MaxValue, valueB = 10, expectedResult = int.MinValue + 9}; } public struct AddCase { public int valueA; public int valueB; public int expectedResult; public override string ToString() { return $\"{valueA} + {valueB} = {expectedResult}\"; } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/unitytest-attribute.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/unitytest-attribute.html",
    "title": "9. Using the UnityTest Attribute | Inventory System",
    "summary": "9. Using the UnityTest Attribute Learning objectives This section will introduce you to the custom [UnityTest] Attribute, which allows for creating tests that run over multiple frames. Intro and motivation An important extension to the Nunit framework that we've made is introducing the [UnityTest] attribute. The attribute allows for creating tests that can yield and resume running after a certain condition. Therefore the test must have the return type of IEnumerator. You can then yield back a yield instruction or null, like so: [UnityTest] public IEnumerator MyTest() { DoSomething(); // Skip 1 frame. yield return null; DoSomethingElse(); } In the snippet above we call the DoSomething method, then skip one frame before calling the DoSomethingElse method. For more information on the yield keyword in C#, see the Microsoft documentation. Exercise In the sample 9_UnityTestAttribute you will find a Play Mode test assembly set up with one Play Mode test in it. The PlayMode test does not have a body yet, but there is a function called PrepareCube() which will set up a cube with some physics applied. The task is to initialize the cube and then verify that it has moved after one frame has passed. Solution The full solution is available in the 9_UnityTestAttribute_Solution sample. [UnityTest] public IEnumerator CubeMovesDown() { var cubeUnderTest = PrepareCube(); var initialPosition = cubeUnderTest.transform.position; yield return null; Assert.That(cubeUnderTest.transform.position, Is.Not.EqualTo(initialPosition)); } Further reading and resources UTF documentation regarding UnityTest attribute"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/welcome.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/course/welcome.html",
    "title": "Welcome | Inventory System",
    "summary": "Welcome Welcome to the Unity Test Framework general introduction course. This course consists of different exercises to help you learn fundamental Unity Test Framework concepts through practical examples. Each exercise has a Learning Objectives section to help you identify the skills you will learn. The exercises are grouped thematically, and their difficulty varies. After completing an exercise, you can check your solution against the one provided. Note that many of the exercises can be solved in several possible ways. Import samples Project files for each exercise and its accompanying solution are provided as samples with the Unity Test Framework package. To import an exercise or solution to your Unity Editor: Go to Window > Package Manager and, in the packages list view, selct Unity Test Framework. In the package details view, find the Samples section. Find the exercise or solution you want to import and click the import button. Note: You can import an exercise and its solution or multiple exercises at the same time, but since several of the exercises use the same naming pattern this will likely result in compilation errors that prevent you running tests or building your project. The recommended workflow is to import and work on one exercise at a time. If you import additional exercises or solutions for reference, you can delete them again before running your main exercise. Course outline Running a test in a Unity project Arrange, act, assert Semantic test assertion Custom comparison Asserting logs Setup and teardown Play mode tests Play mode tests in a player Using the UnityTest attribute Long-running tests Scene-based tests Setup and cleanup at build time Domain reload Preserve test state Test cases Custom attributes Running tests programmatically Introduction to the Unity Test Framework (UTF) Here you can find a video introduction to the Unity Test Framework."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/edit-mode-vs-play-mode-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/edit-mode-vs-play-mode-tests.html",
    "title": "Edit Mode vs. Play Mode tests | Inventory System",
    "summary": "Edit Mode vs. Play Mode tests Let’s clarify a bit what Play Mode and Edit Mode test means from the Unity Test Framework perspective: Edit Mode tests Edit Mode tests (also known as Editor tests) are only run in the Unity Editor and have access to the Editor code in addition to the game code. With Edit Mode tests it is possible to test any of your Editor extensions using the UnityTest attribute. For Edit Mode tests, your test code runs in the EditorApplication.update callback loop. Note: You can also control entering and exiting Play Mode from your Edit Mode test. This allow your test to make changes before entering Play Mode. Edit Mode tests should meet one of the following conditions: They should have an assembly definition with reference to nunit.framework.dll and has only the Editor as a target platform: \"includePlatforms\": [ \"Editor\" ], Legacy condition: put tests in the project’s Editor folder. Play Mode tests You can run Play Mode tests as a standalone in a Player or inside the Editor. Play Mode tests allow you to exercise your game code, as the tests run as coroutines if marked with the UnityTest attribute. Play Mode tests should correspond to the following conditions: Have an assembly definition with reference to nunit.framework.dll. Have the test scripts located in a folder with the .asmdef file. The test assembly should reference an assembly within the code that you need to test. \"references\": [ \"NewAssembly\" ], \"optionalUnityReferences\": [ \"TestAssemblies\" ], \"includePlatforms\": [], Recommendations Attributes Use the NUnit Test attribute instead of the UnityTest attribute, unless you need to yield special instructions, in Edit Mode, or if you need to skip a frame or wait for a certain amount of time in Play Mode. References It is possible for your Test Assemblies to reference the test tools in UnityEngine.TestRunner and UnityEditor.TestRunner. The latter is only available in Edit Mode. You can specify these references in the Assembly Definition References on the Assembly Definition."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extending.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extending.html",
    "title": "Extending Unity Test Framework | Inventory System",
    "summary": "Extending Unity Test Framework It is possible to extend the Unity Test Framework (UTF) in many ways, for custom workflows for your projects and for other packages to build on top of UTF. These extensions are a supplement to the ones already offered by NUnit. Some workflows for extending UTF include: How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-get-test-results.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-get-test-results.html",
    "title": "How to get test results | Inventory System",
    "summary": "How to get test results You can receive callbacks when the active test run, or individual tests, starts and finishes. You can register callbacks by invoking RegisterCallbacks on the TestRunnerApi with an instance of a class that implements ICallbacks. There are four ICallbacks methods for the start and finish of both the whole run and each level of the test tree. Example An example of how listeners can be set up: Note: Listeners receive callbacks from all test runs, regardless of the registered TestRunnerApi for that instance. public void SetupListeners() { var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RegisterCallbacks(new MyCallbacks()); } private class MyCallbacks : ICallbacks { public void RunStarted(ITestAdaptor testsToRun) { } public void RunFinished(ITestResultAdaptor result) { } public void TestStarted(ITestAdaptor test) { } public void TestFinished(ITestResultAdaptor result) { if (!result.HasChildren && result.ResultState != \"Passed\") { Debug.Log(string.Format(\"Test {0} {1}\", result.Test.Name, result.ResultState)); } } } Note: The registered callbacks are not persisted on domain reloads. So it is necessary to re-register the callback after a domain reloads, usually with InitializeOnLoad. It is possible to provide a priority as an integer as the second argument when registering a callback. This influences the invocation order of different callbacks. The default value is zero. It is also possible to provide RegisterCallbacks with a class instance that implements IErrorCallbacks that is an extended version of ICallbacks. IErrorCallbacks also has a callback method for OnError that invokes if the run fails to start, for example, due to compilation errors or if an IPrebuildSetup throws an exception."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-retrieve-test-list.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-retrieve-test-list.html",
    "title": "How to retrieve the list of tests | Inventory System",
    "summary": "How to retrieve the list of tests It is possible to use the TestRunnerApi to retrieve the test tree for a given test mode (Edit Mode or Play Mode). You can retrieve the test tree by invoking RetrieveTestList with the desired TestMode and a callback action, with an ITestAdaptor representing the test tree. Example The following example retrieves the test tree for Edit Mode tests and prints the number of total test cases: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RetrieveTestList(TestMode.EditMode, (testRoot) => { Debug.Log(string.Format(\"Tree contains {0} tests.\", testRoot.TestCaseCount)); });"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-run-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/extension-run-tests.html",
    "title": "How to run tests programmatically | Inventory System",
    "summary": "How to run tests programmatically Filters Run tests by calling Execute on the TestRunnerApi, and provide some execution settings that consists of a Filter. The Filter specifies what tests to run. Example The following is an example of how to run all Play Mode tests in a project: var testRunnerApi = ScriptableObject.CreateInstance<TestRunnerApi>(); var filter = new Filter() { testMode = TestMode.PlayMode }; testRunnerApi.Execute(new ExecutionSettings(filter)); Multiple filter values It is possible to specify a more specific filter by filling out the fields on the Filter class in more detail. Many of the fields allow for multiple values. The runner tries to match tests against at least one of the values provided and then runs any tests that match. Example In this example, the API runs tests with full names that fit either of the two names provided: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings(new Filter() { testNames = new[] {\"MyTestClass.NameOfMyTest\", \"SpecificTestFixture.NameOfAnotherTest\"} })); Multiple filter fields If using multiple different fields on the filter, then it matches against tests that fulfill all the different fields. Example In this example, it runs any test that fits either of the two test names, and that also belongs to a test assembly that fits the given name. var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings(new Filter() { assemblyNames = new [] {\"MyTestAssembly\"}, testNames = new [] {\"MyTestClass.NameOfMyTest\", \"MyTestClass.AnotherNameOfATest\"} })); Multiple constructor filters The execution settings take one or more filters in its constructor. If there is no filter provided, then it runs all Edit Mode tests by default. If there are multiple filters provided, then a test runs if it matches any of the filters. Example In this example, it runs any tests that are either in the assembly named MyTestAssembly or if the full name of the test matches either of the two provided test names: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings( new Filter() { assemblyNames = new[] {\"MyTestAssembly\"}, }, new Filter() { testNames = new[] {\"MyTestClass.NameOfMyTest\", \"MyTestClass.AnotherNameOfATest\"} } )); Note: Specifying different test modes or platforms in each Filter is not currently supported. The test mode and platform is from the first Filter only and defaults to Edit Mode, if not supplied."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/getting-started.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/getting-started.html",
    "title": "Getting started with Unity Test Framework | Inventory System",
    "summary": "Getting started with Unity Test Framework To access the Unity Test Framework (UTF) in the Unity Editor, open the Test Runner window; go to Window > General > Test Runner. To get started with UTF, follow the workflows below: How to create a new test assembly How to create a test How to run a test How to create a Play Mode test How to run a Play Mode test as standalone For further information, see the resources and reference sections."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/index.html",
    "title": "About Unity Test Framework | Inventory System",
    "summary": "About Unity Test Framework The Unity Test Framework (UTF) enables Unity users to test their code in both Edit Mode and Play Mode, and also on target platforms such as Standalone, Android, iOS, etc. This package provides a standard test framework for users of Unity and developers at Unity so that both benefit from the same features and can write tests the same way. UTF uses a Unity integration of NUnit library, which is an open-source unit testing library for .Net languages. UTF currently uses NUnit version 3.5. For more information about NUnit, see the official NUnit website and the NUnit documentation. Note: UTF is not a new concept or toolset; it is an adjusted and more descriptive naming for the toolset otherwise known as Unity Test Runner, which is now available as this package. Installing Unity Test Framework The Test Framework package is shipped with the Unity Editor and should be automatically included in any project created with Unity 2019.2 or later. If you need to install the package manually, you can do so in any of the standard ways documented in the Package Manager documentation. Note: If you're adding the package by name, the canonical name to use is com.unity.test-framework. If you're adding it from the registry, the package is listed under the display name Test Framework. Using Unity Test Framework To learn how to use the Unity Test Framework package in your project, read the manual. Technical details Requirements This version of the Unity Test Framework is compatible with the following versions of the Unity Editor: 2019.2 and later. Known limitations Unity Test Framework version 1.3.x includes the following known limitations: The UnityTest attribute does not support WSA platform. The UnityTest attribute does not support Parameterized tests (except for ValueSource). The UnityTest attribute does not support the NUnit Repeat attribute. Nested test fixture cannot run from the Editor UI. When using the NUnit Retry attribute in PlayMode tests, it throws InvalidCastException."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/manual.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/manual.html",
    "title": "Unity Test Framework manual | Inventory System",
    "summary": "Unity Test Framework manual This is the manual for the Unity Test Framework (UTF): Introduction Unity Test Framework overview Edit Mode vs. Play Mode tests Getting started Getting started with UTF Workflows: How to create a new test assembly How to create a test How to run a test How to create a Play Mode test How to run a Play Mode test in player Resources Extending UTF Extending UTF Workflows: How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests Reference Running tests from the command-line UnityTest attribute Setup and cleanup at build time IPrebuildSetup IPostBuildCleanup Actions outside of tests Action execution order UnitySetUp and UnityTearDown OuterUnityTestAction Domain Reloads Custom attributes ConditionalIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute Custom equality comparers ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Custom equality comparers with equals operator Test Utils Custom yield instructions IEditModeTestYieldInstruction EnterPlayMode ExitPlayMode Custom assertion LogAssert Custom constraints Is Parameterized tests MonoBehaviour tests MonoBehaviourTest IMonoBehaviourTest TestRunnerApi ExecutionSettings Filter ITestRunSettings ICallbacks IErrorCallbacks"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-actions-outside-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-actions-outside-tests.html",
    "title": "Actions outside of tests | Inventory System",
    "summary": "Actions outside of tests When writing tests, it is possible to avoid duplication of code by using the SetUp and TearDown methods built into NUnit. The Unity Test Framework has extended these methods with extra functionality, which can yield commands and skip frames, in the same way as UnityTest. Action execution order The actions related to a test run in the following order: Attributes implementing IApplyToContext Any attribute implementing OuterUnityTestAction has its BeforeTest invoked Tests with UnitySetUp methods in their test class Attributes implementing IWrapSetUpTearDown Any method with the [SetUp]) attribute Action attributes have their BeforeTest method invoked Attributes implementing IWrapTestMethod The test itself runs Action attributes have their AfterTest method invoked Any method with the TearDown attribute Tests with UnityTearDown methods in their test class Any OuterUnityTestAction has its AfterTest invoked The list of actions is the same for both Test and UnityTest. Execution order flow Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Domain Reloads In Edit Mode tests it is possible to yield instructions that can result in a domain reload, such as entering or exiting Play Mode (see Custom yield instructions). When a domain reload happens, all non-Unity actions (such as OneTimeSetup and Setup) are rerun before the code, which initiated the domain reload, continues. Unity actions (such as UnitySetup) are not rerun. If the Unity action is the code that initiated the domain reload, then the rest of the code in the UnitySetup method runs after the domain reload."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-async-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-async-tests.html",
    "title": "Async tests | Inventory System",
    "summary": "Async tests You can use the dotnet Task asynchronous programming model to write asynchronous tests. If you're new to asynchronous programming and its applications, see the Microsoft documentation for a comprehensive guide. See also the documentation for NUnit Test, which explains the requirements for an async test. Async code is run on the main thread and Unity Test Framework will await it by checking if the task is done on each update for Play Mode or on each EditorApplication.update outside Play Mode. Note that any failing log messages will first be evaluated after the async test has completed. This means that if you have a failing log message in an async test, it will not be reported until the test has completed. The following code snippet demonstrates an async test based on Microsoft's making breakfast example. Note that the test method is marked with the async keyword and has return type Task. We set up a list of Tasks corresponding to asynchronous methods representing parts of the breakfast making process. We use await to start these tasks in a non-blocking way, write to the log when each one completes, and write again to the log when all are completed. using System.Collections.Generic; using System.Threading.Tasks; using NUnit.Framework; using UnityEngine; public class AsyncExample { [Test] public async Task MakeBreakfast_InTheMorning_IsEdible() { var eggsTask = FryEggsAsync(2); var baconTask = FryBaconAsync(3); var toastTask = MakeToastWithButterAndJamAsync(2); var breakfastTasks = new List<Task> { eggsTask, baconTask, toastTask }; while (breakfastTasks.Count > 0) { Task finishedTask = await Task.WhenAny(breakfastTasks); if (finishedTask == eggsTask) { Debug.Log(\"eggs are ready\"); } else if (finishedTask == baconTask) { Debug.Log(\"bacon is ready\"); } else if (finishedTask == toastTask) { Debug.Log(\"toast is ready\"); } breakfastTasks.Remove(finishedTask); } Debug.Log(\"Breakfast is ready!\"); } static async Task<Toast> MakeToastWithButterAndJamAsync(int number) { var toast = await ToastBreadAsync(number); ApplyButter(toast); ApplyJam(toast); return toast; } private static Juice PourOJ() { Debug.Log(\"Pouring orange juice\"); return new Juice(); } private static void ApplyJam(Toast toast) => Debug.Log(\"Putting jam on the toast\"); private static void ApplyButter(Toast toast) => Debug.Log(\"Putting butter on the toast\"); private static async Task<Toast> ToastBreadAsync(int slices) { for (int slice = 0; slice < slices; slice++) { Debug.Log(\"Putting a slice of bread in the toaster\"); } Debug.Log(\"Start toasting...\"); await Task.Delay(3000); Debug.Log(\"Remove toast from toaster\"); return new Toast(); } private static async Task<Bacon> FryBaconAsync(int slices) { Debug.Log($\"putting {slices} slices of bacon in the pan\"); Debug.Log(\"cooking first side of bacon...\"); await Task.Delay(3000); for (int slice = 0; slice < slices; slice++) { Debug.Log(\"flipping a slice of bacon\"); } Debug.Log(\"cooking the second side of bacon...\"); await Task.Delay(3000); Debug.Log(\"Put bacon on plate\"); return new Bacon(); } private static async Task<Egg> FryEggsAsync(int howMany) { Debug.Log(\"Warming the egg pan...\"); await Task.Delay(3000); Debug.Log($\"cracking {howMany} eggs\"); Debug.Log(\"cooking the eggs ...\"); await Task.Delay(3000); Debug.Log(\"Put eggs on plate\"); return new Egg(); } private static Coffee PourCoffee() { Debug.Log(\"Pouring coffee\"); return new Coffee(); } public struct Toast { } public struct Juice { } public struct Bacon { } public struct Egg { } public struct Coffee { } } The following shows the result of running this example in the Test Runner window: Editor freezing on Assert.ThrowsAsync and workaround NUnit's assertion for asynchronous code, Assert.ThrowsAsync, blocks the calling thread until the async function you pass in completes. By default Unity runs asynchronous functions on the main thread in case they need to call the Editor API, which means Assert.ThrowsAsync can lock up the main thread and cause the Editor to freeze. To workaround this problem, you can unwrap the Assert.ThrowsAsync logic into your own try/catch blocks and assert that you caught something. For example, do this: [Test] public async Task ThisDoesNotLockTheMainThread() { bool caught = false; try { await Task.Delay(1000); throw new System.Exception(\"Hello world.\"); } catch (System.Exception x) { caught = true; } Assert.That(caught); } Instead of this: [Test] public void ThisLocksTheMainThread() { Assert.ThrowsAsync<System.Exception>(async () => { await Task.Delay(1000); throw new System.Exception(\"Hello world.\"); } ); }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-conditionalignore.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-conditionalignore.html",
    "title": "ConditionalIgnore attribute | Inventory System",
    "summary": "ConditionalIgnore attribute This attribute is an alternative to the standard Ignore attribute in NUnit. It allows for ignoring tests only under a specified condition. The condition evaluates during OnLoad, referenced by ID. Example The following example shows a method to use the ConditionalIgnore attribute to ignore a test if the Unity Editor is running macOS: using UnityEditor; using NUnit.Framework; using UnityEngine.TestTools; [InitializeOnLoad] public class OnLoad { static OnLoad() { var editorIsOSX = false; #if UNITY_EDITOR_OSX editorIsOSX = true; #endif ConditionalIgnoreAttribute.AddConditionalIgnoreMapping(\"IgnoreInMacEditor\", editorIsOSX); } } public class MyTestClass { [Test, ConditionalIgnore(\"IgnoreInMacEditor\", \"Ignored on Mac editor.\")] public void TestNeverRunningInMacEditor() { Assert.Pass(); } } Note: You can only use InitializeOnLoad in Edit Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-parameterizedignore.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-parameterizedignore.html",
    "title": "ParametrizedIgnore attribute | Inventory System",
    "summary": "ParametrizedIgnore attribute This attribute is an alternative to the standard Ignore attribute in NUnit. It allows for ignoring tests based on arguments which were passed to the test method. Example The following example shows a method to use the ParametrizedIgnore attribute to ignore only one test with specific combination of arguments, where someString is b and someInt is 10. using NUnit.Framework; using System.Collections.Generic; using UnityEngine.TestTools; public class MyTestsClass { public static IEnumerable<TestCaseData> MyTestCaseSource() { for (int i = 0; i < 5; i++) { yield return new TestCaseData(\"a\", i); yield return new TestCaseData(\"b\", i); } } [Test, TestCaseSource(\"MyTestCaseSource\")] [ParametrizedIgnore(\"b\", 3)] public void Test(string someString, int someInt) { Assert.Pass(); } } It could also be used together with Values attribute in NUnit. using NUnit.Framework; using UnityEngine.TestTools; public class MyTestsClass { [Test] [ParametrizedIgnore(\"b\", 10)] public void Test( [Values(\"a\", \"b\")] string someString, [Values(5, 10)] int someInt) { Assert.Pass(); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testmustexpectalllogs.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testmustexpectalllogs.html",
    "title": "TestMustExpectAllLogs attribute | Inventory System",
    "summary": "TestMustExpectAllLogs attribute The presence of this attribute causes the Test Runner to expect every single log. By default, the Test Runner only fails on error logs, but TestMustExpectAllLogs fails on warnings and info level messages as well. It is the same as calling the method LogAssert.NoUnexpectedReceived at the bottom of every affected test. Assembly-wide usage You can apply this attribute to test assemblies (that affects every test in the assembly), fixtures (affects every test in the fixture), or on individual test methods. It is also inherited from base fixtures. The MustExpect property (true by default) lets you enable or disable the higher level value. For example when migrating an assembly to this more strict checking method, you might attach [assembly:TestMustExpectAllLogs] to the assembly itself, but then whitelist failing fixtures and test methods with [TestMustExpectAllLogs(MustExpect=false)] until you have migrated them. This also means new tests in that assembly would have the more strict checking."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testplayerbuildmodifier.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testplayerbuildmodifier.html",
    "title": "TestPlayerBuildModifier attribute | Inventory System",
    "summary": "TestPlayerBuildModifier attribute You can use the TestPlayerBuildModifier attribute to accomplish a couple of different scenarios: Modify the Player build options for Play Mode tests It is possible to change the BuildPlayerOptions for the test Player, to achieve custom behavior when running Play Mode tests. Modifying the build options allows for changing the target location of the build as well as changing BuildOptions. To modify the BuildPlayerOptions, do the following: Implement the ITestPlayerBuildModifier Reference the implementation type in a TestPlayerBuildModifier attribute on an assembly level. Example using UnityEditor; using UnityEditor.TestTools; [assembly:TestPlayerBuildModifier(typeof(BuildModifier))] public class BuildModifier : ITestPlayerBuildModifier { public BuildPlayerOptions ModifyOptions(BuildPlayerOptions playerOptions) { if (playerOptions.target == BuildTarget.iOS) { playerOptions.options |= BuildOptions.SymlinkLibraries; // Enable symlink libraries when running on iOS } playerOptions.options |= BuildOptions.AllowDebugging; // Enable allow Debugging flag on the test Player. return playerOptions; } } Note: When building the Player, it includes all TestPlayerBuildModifier attributes across all loaded assemblies, independent of the currently used test filter. As the implementation references the UnityEditor namespace, the code is typically implemented in an Editor only assembly, as the UnityEditor namespace is not available otherwise. Split build and run It is possible to use the Unity Editor for building the Player with tests, without running the tests. This allows for running the Player on e.g. another machine. In this case, it is necessary to modify the Player to build and implement a custom handling of the test result. By using TestPlayerBuildModifier, you can alter the BuildOptions to not start the Player after the build as well as build the Player at a specific location. Combined with PostBuildCleanup, you can automatically exit the Editor on completion of the build. Example using System; using System.IO; using System.Linq; using Tests; using UnityEditor; using UnityEditor.TestTools; using UnityEngine; using UnityEngine.TestTools; [assembly:TestPlayerBuildModifier(typeof(HeadlessPlayModeSetup))] [assembly:PostBuildCleanup(typeof(HeadlessPlayModeSetup))] namespace Tests { public class HeadlessPlayModeSetup : ITestPlayerBuildModifier, IPostBuildCleanup { private static bool s_RunningPlayerTests; public BuildPlayerOptions ModifyOptions(BuildPlayerOptions playerOptions) { // Do not launch the player after the build completes. playerOptions.options &= ~BuildOptions.AutoRunPlayer; // Set the headlessBuildLocation to the output directory you desire. It does not need to be inside the project. var headlessBuildLocation = Path.GetFullPath(Path.Combine(Application.dataPath, \".//..//PlayModeTestPlayer\")); var fileName = Path.GetFileName(playerOptions.locationPathName); if (!string.IsNullOrEmpty(fileName)) { headlessBuildLocation = Path.Combine(headlessBuildLocation, fileName); } playerOptions.locationPathName = headlessBuildLocation; // Instruct the cleanup to exit the Editor if the run came from the command line. // The variable is static because the cleanup is being invoked in a new instance of the class. s_RunningPlayerTests = true; return playerOptions; } public void Cleanup() { if (s_RunningPlayerTests && IsRunningTestsFromCommandLine()) { // Exit the Editor on the next update, allowing for other PostBuildCleanup steps to run. EditorApplication.update += () => { EditorApplication.Exit(0); }; } } private static bool IsRunningTestsFromCommandLine() { var commandLineArgs = Environment.GetCommandLineArgs(); return commandLineArgs.Any(value => value == \"-runTests\"); } } } If the Editor is still running after the Play Mode tests have run, the Player tries to report the results back, using PlayerConnection, which has a reference to the IP address of the Editor machine, when built. To implement a custom way of reporting the results of the test run, let one of the assemblies in the Player include a TestRunCallback. At RunFinished, it is possible to get the full test report as XML from the NUnit test result by calling result.ToXml(true). You can save the result and then save it on the device or send it to another machine as needed."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testruncallback.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-testruncallback.html",
    "title": "TestRunCallback attribute | Inventory System",
    "summary": "TestRunCallback attribute It is possible for the test framework to invoke callbacks as the current test run progresses. To do this, there is a TestRunCallback attribute which takes the type of ITestRunCallback implementation. You can invoke the callbacks with NUnit ITest and ITestResult classes. At the RunStarted and RunFinished methods, the test and test results are for the whole test tree. These methods invoke at each node in the test tree; first with the whole test assembly, then with the test class, and last with the test method. From these callbacks, it is possible to read the partial or the full results, and it is furthermore possible to save the XML version of the result for further processing or continuous integration. Example using NUnit.Framework.Interfaces; using UnityEngine; using UnityEngine.TestRunner; [assembly:TestRunCallback(typeof(MyTestRunCallback))] public class MyTestRunCallback : ITestRunCallback { public void RunStarted(ITest testsToRun) { } public void RunFinished(ITestResult testResults) { } public void TestStarted(ITest test) { } public void TestFinished(ITestResult result) { if (!result.Test.IsSuite) { Debug.Log($\"Result of {result.Name}: {result.ResultState.Status}\"); } } } Note: The TestRunCallback does not need any references to the UnityEditor namespace and is thus able to run in standalone Players, on the Player side. Note also that TestRunCallback is part of the runtime code and should not be confused with iCallbacks which are part of the TestRunnerApi. If you want to receive callbacks for tests run programmatically through the TestRunnerApi, see iCallbacks."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-unityplatform.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-unityplatform.html",
    "title": "UnityPlatform attribute | Inventory System",
    "summary": "UnityPlatform attribute Use this attribute to define a specific set of platforms you want or do not want your test(s) to run on. You can use this attribute on the test method, test class, or test assembly level. Use the supported RuntimePlatform enumeration values to specify the platforms. You can also specify which platforms to test by passing one or more RuntimePlatform values along with or without the include or exclude properties as parameters to the Platform attribute constructor. The test(s) skips if the current target platform is: Not explicitly specified in the included platforms list In the excluded platforms list using UnityEngine; using UnityEngine.TestTools; using NUnit.Framework; [TestFixture] public class TestClass { [Test] [UnityPlatform(RuntimePlatform.WindowsPlayer)] public void TestMethod() { Assert.AreEqual(Application.platform, RuntimePlatform.WindowsPlayer); } } Properties Syntax Description RuntimePlatform[] exclude List the platforms you do not want to have your tests run on. RuntimePlatform[] include A subset of platforms you need to have your tests run on."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-unitytest.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-attribute-unitytest.html",
    "title": "UnityTest attribute | Inventory System",
    "summary": "UnityTest attribute UnityTest attribute is the main addition to the standard NUnit library for the Unity Test Framework. This type of unit test allows you to skip a frame from within a test (so background tasks can finish) or give certain commands to the Unity Editor, such as performing a domain reload or entering Play Mode from an Edit Mode test. In Play Mode, the UnityTest attribute runs as a coroutine. Whereas Edit Mode tests run in the EditorApplication.update callback loop. The UnityTest attribute is, in fact, an alternative to the NUnit Test attribute, which allows yielding instructions back to the framework. Once the instruction is complete, the test run continues. If you yield return null, you skip a frame. That might be necessary to ensure that some changes do happen on the next iteration of either the EditorApplication.update loop or the game loop. Edit Mode example The most simple example of an Edit Mode test could be the one that yields null to skip the current frame and then continues to run: [UnityTest] public IEnumerator EditorUtility_WhenExecuted_ReturnsSuccess() { var utility = RunEditorUtilityInTheBackground(); while (utility.isRunning) { yield return null; } Assert.IsTrue(utility.isSuccess); } Play Mode example In Play Mode, a test runs as a coroutine attached to a MonoBehaviour. So all the yield instructions available in coroutines, are also available in your test. From a Play Mode test you can use one of Unity’s Yield Instructions: WaitForFixedUpdate: to ensure changes expected within the next cycle of physics calculations. WaitForSeconds: if you want to pause your test coroutine for a fixed amount of time. Be careful about creating long-running tests. The simplest example is to yield to WaitForFixedUpdate: [UnityTest] public IEnumerator GameObject_WithRigidBody_WillBeAffectedByPhysics() { var go = new GameObject(); go.AddComponent<Rigidbody>(); var originalPosition = go.transform.position.y; yield return new WaitForFixedUpdate(); Assert.AreNotEqual(originalPosition, go.transform.position.y); }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-command-line.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-command-line.html",
    "title": "Running tests from the command line | Inventory System",
    "summary": "Running tests from the command line It’s pretty simple to run a test project from the command line. Here is an example in Windows: Unity.exe -runTests -batchmode -projectPath PATH_TO_YOUR_PROJECT -testResults C:\\temp\\results.xml -testPlatform PS4 Note: Use the -batchmode option when running tests on the command line to remove the need for manual user inputs. For more information, see Unity Command line arguments. Test Framework command line arguments forgetProjectPath Don't save your current Project into the Unity launcher/hub history. runTests Runs tests in the Project. testCategory A semicolon-separated list of test categories to include in the run, or a regular expression pattern to match category names. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. testCategory \"firstCategory;secondCategory\". If using both testFilter and testCategory, then only tests that match both are run. This argument supports negation using '!'. If using '!MyCategory' then no tests with the 'MyCategory' category will be included in the run. testFilter A semicolon-separated list of test names to run, or a regular expression pattern to match tests by their full name. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. testFilter \"Low;Medium\". This argument supports negation using '!'. If using the test filter '!MyNamespace.Something.MyTest', then all tests except that test will be run. It is also possible to run a specific variation of a parameterized test like so: \"ClassName\\.MethodName\\(Param1,Param2\\)\" testPlatform The platform to run tests on. Accepted values: EditMode Edit Mode tests. Equivalent to running tests from the EditMode tab of the Test Runner window. PlayMode Play Mode tests that run in the Editor. Equivalent to running tests from the PlayMode tab of the Test Runner window. Any value from the BuildTarget enum. Play Mode tests that run on a player built for the specified platform. Equivalent to using the Run all tests (<target_platform>) dropdown in the PlayMode tab of the Test Runner window. Note: If no value is specified for this argument, tests run in Edit Mode. assemblyNames A semicolon-separated list of test assemblies to include in the run. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. assemblyNames \"firstAssembly;secondAssembly\". testResults The path where Unity should save the result file. By default, Unity saves it in the Project’s root folder. Test results follow the XML format as defined by NUnit, see the NUnit documentation. There is currently no common definition for exit codes reported by individual Unity components under test. The best way to understand the source of a problem is the content of error messages and stack traces. playerHeartbeatTimeout The time, in seconds, the editor should wait for heartbeats after starting a test run on a player. This defaults to 10 minutes. runSynchronously If included, the test run will run tests synchronously, guaranteeing that all tests runs in one editor update call. Note that this is only supported for EditMode tests, and that tests which take multiple frames (i.e. [UnityTest] tests, or tests with [UnitySetUp] or [UnityTearDown] scaffolding) will be filtered out. testSettingsFile Path to a TestSettings.json file. orderedTestListFile Path to a .txt file (which can have any name as long as the format is text) which contains a list of full test names you want to run in the specified order. The tests should be seperated by new lines and if they have parameters, these should be specified as well. The following is an example of the content of such a file: Unity.Framework.Tests.OrderedTests.NoParameters Unity.Framework.Tests.OrderedTests.ParametrizedTestA(3,2) Unity.Framework.Tests.OrderedTests.ParametrizedTestB(\"Assets/file.fbx\") Unity.Framework.Tests.OrderedTests.ParametrizedTestC(System.String[],\"foo.fbx\") Unity.Framework.Tests.OrderedTests.ParametrizedTestD(1.0f) Unity.Framework.Tests.OrderedTests.ParametrizedTestE(null) Unity.Framework.Tests.OrderedTests.ParametrizedTestF(False, 1) Unity.Framework.Tests.OrderedTests.ParametrizedTestG(float.NaN) Unity.Framework.Tests.OrderedTests.ParametrizedTestH(SomeEnum) randomOrderSeed An integer different from 0 that set the seed to randomize the tests in the project, indipendetly from the fixture. # normal order Test_1 Test_2 Test_3 Test_4 # randomized with seed x Test_3 Test_1 Test_4 Test_2 # randomized with same seed x and a new test Test_3 Test_5 Test_1 Test_4 Test_2 retry An integer that sets the retry count. Failing tests will be retried up to this number of times, or until they succeed, whichever happens first. repeat An integer that set the repeat count. Successful tests will be repeated up to this number of times, or until they fail, whichever happens first."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-color.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-color.html",
    "title": "ColorEqualityComparer | Inventory System",
    "summary": "ColorEqualityComparer Use this class to compare two Color objects. ColorEqualityComparer.Instance has default calculation error value set to 0.01f. To set a test specific error value instantiate a comparer instance using the one argument constructor. Static properties Syntax Description Instance A singleton instance of the comparer with a default error value set to 0.01f. Constructors Syntax Description ColorEqualityComparer(float error) Creates an instance of the comparer with a custom error value. Public methods Syntax Description bool Equals(Color expected, Color actual); Compares the actual and expected Color objects for equality using Utils.AreFloatsEqualAbsoluteError to compare the RGB and Alpha attributes of Color. Returns true if expected and actual objects are equal otherwise, it returns false. Example [TestFixture] public class ColorEqualityTest { [Test] public void GivenColorsAreEqual_WithAllowedCalculationError() { // Using default error var firstColor = new Color(0f, 0f, 0f, 0f); var secondColor = new Color(0f, 0f, 0f, 0f); Assert.That(firstColor, Is.EqualTo(secondColor).Using(ColorEqualityComparer.Instance)); // Allowed error 10e-5f var comparer = new ColorEqualityComparer(10e-5f); firstColor = new Color(0f, 0f, 0f, 1f); secondColor = new Color(10e-6f, 0f, 0f, 1f); Assert.That(firstColor, Is.EqualTo(secondColor).Using(comparer)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-equals.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-equals.html",
    "title": "Custom equality comparers with equals operator | Inventory System",
    "summary": "Custom equality comparers with equals operator If you need to compare Vectors using the overloaded operator == (see Vector2.operator ==, Vector3.operator ==, and Vector4.operator ==) you should use the respective comparer implementations: Vector2ComparerWithEqualsOperator Vector3ComparerWithEqualsOperator Vector4ComparerWithEqualsOperator The interface is the same as for other equality comparers except the public constructor error parameter is inapplicable in this case. Example [TestFixture] public class Vector3Test { [Test] public void VerifyThat_TwoVector3ObjectsAreEqual() { var actual = new Vector3(10e-7f, 10e-7f, 10e-7f); var expected = new Vector3(0f, 0f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector3ComparerWithEqualsOperator.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-float.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-float.html",
    "title": "FloatEqualityComparer | Inventory System",
    "summary": "FloatEqualityComparer Use this class to compare two float values for equality with NUnit constraints. Use FloatEqualityComparer.Instance comparer to have the default error value set to 0.0001f. For any other error, use the one argument constructor to create a comparer. Static Properties Syntax Description Instance A singleton instance of the comparer with a default error value set to 0.0001f. Constructors Syntax Description FloatEqualityComparer(float allowedError) Creates an instance of the comparer with a custom error value. Public methods Syntax Description bool Equals(float expected, float actual); Compares the actual and expected float values for equality using Utils.AreFloatsEqual. Example [TestFixture] public class FloatsTest { [Test] public void VerifyThat_TwoFloatsAreEqual() { var comparer = new FloatEqualityComparer(10e-6f); var actual = -0.00009f; var expected = 0.00009f; Assert.That(actual, Is.EqualTo(expected).Using(comparer)); // Default relative error 0.0001f actual = 10e-8f; expected = 0f; Assert.That(actual, Is.EqualTo(expected).Using(FloatEqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-quaternion.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-quaternion.html",
    "title": "QuaternionEqualityComparer | Inventory System",
    "summary": "QuaternionEqualityComparer Use this utility to compare two Quaternion objects for equality with NUnit assertion constraints. Use the static instance QuaternionEqualityComparer.Instance to have the default calculation error value set to 0.00001f. For any other custom error value, use the one argument constructor. Static properties Syntax Description Instance A comparer instance with the default error value 0.00001f. Constructors Syntax Description QuaternionEqualityComparer(float allowedError) Creates an instance of the comparer with a custom allowed error value. Public methods Syntax Description bool Equals(Quaternion expected, Quaternion actual) Compares the actual and expected Quaternion objects for equality using the Quaternion.Dot method. Example [TestFixture] public class QuaternionTest { [Test] public void VerifyThat_TwoQuaternionsAreEqual() { var actual = new Quaternion(10f, 0f, 0f, 0f); var expected = new Quaternion(1f, 10f, 0f, 0f); var comparer = new QuaternionEqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Using default error 0.00001f actual = new Quaternion(10f, 0f, 0.1f, 0f); expected = new Quaternion(1f, 10f, 0.1f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(QuaternionEqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector2.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector2.html",
    "title": "Vector2EqualityComparer | Inventory System",
    "summary": "Vector2EqualityComparer Use this class to compare two Vector2 objects for equality with NUnit constraints. Use the static Vector2EqualityComparer.Instance to have the calculation error value set to default 0.0001f. For any other error value, instantiate a new comparer object with the one argument constructor. Static properties Syntax Description Instance A comparer instance with the default error value set to 0.0001f. Constructors Syntax Description Vector2EqualityComparer(float error) Creates an instance with a custom error value. Public methods Syntax Description Equals(Vector2 expected, Vector2 actual) Compares the actual and expected Vector2 objects for equality using the Utils.AreFloatsEqual method. Example [TestFixture] public class Vector2Test { [Test] public void VerifyThat_TwoVector2ObjectsAreEqual() { // Custom calculation error var actual = new Vector2(10e-7f, 10e-7f); var expected = new Vector2(0f, 0f); var comparer = new Vector2EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Default error 0.0001f actual = new Vector2(0.01f, 0.01f); expected = new Vector2(0.01f, 0.01f); Assert.That(actual, Is.EqualTo(expected).Using(Vector2EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector3.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector3.html",
    "title": "Vector3EqualityComparer | Inventory System",
    "summary": "Vector3EqualityComparer Use this class to compare two Vector3 objects for equality with NUnit constraints. Call Vector3EqualityComparer.Instance comparer to perform a comparison with the default calculation error value 0.0001f. To specify a different error value, use the one argument constructor to instantiate a new comparer. Static properties Syntax Description Instance A comparer instance with the default calculation error value equal to 0.0001f. Constructors Syntax Description Vector3EqualityComparer(float allowedError) Creates an instance with a custom error value. Public methods Syntax Description bool Equals(Vector3 expected, Vector3 actual) Compares the actual and expected Vector3 objects for equality using Utils.AreFloatsEqual to compare the x, y, and z attributes of Vector3. Example [TestFixture] public class Vector3Test { [Test] public void VerifyThat_TwoVector3ObjectsAreEqual() { // Custom error 10e-6f var actual = new Vector3(10e-8f, 10e-8f, 10e-8f); var expected = new Vector3(0f, 0f, 0f); var comparer = new Vector3EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Default error 0.0001f actual = new Vector3(0.01f, 0.01f, 0f); expected = new Vector3(0.01f, 0.01f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector3EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector4.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-comparer-vector4.html",
    "title": "Vector4EqualityComparer | Inventory System",
    "summary": "Vector4EqualityComparer Use this class to compare two Vector4 objects for equality with NUnit constraints. Call Vector4EqualityComparer.Instance to perform comparisons using default calculation error value 0.0001f. To set a custom test value, instantiate a new comparer using the one argument constructor. Static Properties Syntax Description Vector4EqualityComparer Instance A comparer instance with the default calculation error value set to 0.0001f. Constructors Syntax Description Vector4EqualityComparer(float allowedError) Creates an instance with a custom error value. Public methods Syntax Description bool Equals(Vector4 expected, Vector4 actual); Compares the actual and expected Vector4 objects for equality using Utils.AreFloatsEqual to compare the x, y, z, and w attributes of Vector4. Example [TestFixture] public class Vector4Test { [Test] public void VerifyThat_TwoVector4ObjectsAreEqual() { // Custom error 10e-6f var actual = new Vector4(0, 0, 1e-6f, 1e-6f); var expected = new Vector4(1e-6f, 0f, 0f, 0f); var comparer = new Vector4EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); // Default error 0.0001f actual = new Vector4(0.01f, 0.01f, 0f, 0f); expected = new Vector4(0.01f, 0.01f, 0f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector4EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-assertion.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-assertion.html",
    "title": "Custom assertion | Inventory System",
    "summary": "Custom assertion A test fails if Unity logs a message other than a regular log or warning message. Use LogAssert to check for an expected message in the log so that the test does not fail when Unity logs the message. Use LogAssert.Expect before running the code under test, as the check for expected logs runs at the end of each frame. A test also reports a failure, if an expected message does not appear, or if Unity does not log any regular log or warning messages. Example [Test] public void LogAssertExample() { // Expect a regular log message LogAssert.Expect(LogType.Log, \"Log message\"); // The test fails without the following expected log message Debug.Log(\"Log message\"); // An error log Debug.LogError(\"Error message\"); // Without expecting an error log, the test would fail LogAssert.Expect(LogType.Error, \"Error message\"); } LogAssert LogAssert lets you expect Unity log messages that would otherwise cause the test to fail. It is available under the namespace UnityEngine.TestTools, see the Scripting API for more details. Static properties Syntax Description bool ignoreFailingMessages Set this property to true to prevent unexpected error log messages from triggering an assertion. By default, it is false. Static Methods Syntax Description void Expect(LogType type, string message); void Expect(LogType type, Regex message); Verifies that a log message of a specified type appears in the log. A test won’t fail from an expected error, assertion, or exception log message. It does fail if an expected message does not appear in the log. void NoUnexpectedReceived(); Triggers an assertion when receiving any log messages and fails the test if some are unexpected messages. If multiple tests need to check for no received unexpected logs, consider using the TestMustExpectAllLogs attribute instead. Expect string message void Expect(LogType type, string message); Parameters Syntax Description LogType type A type of log to expect. It can take one of the LogType enum values. string message A string value that should equate to the expected message. Expect Regex message void Expect(LogType type, Regex message); Parameters Syntax Description LogType type A type of log to expect. It can take one of the LogType enum values. Regex message A regular expression pattern to match the expected message."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-attributes.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-attributes.html",
    "title": "Custom attributes | Inventory System",
    "summary": "Custom attributes As a part of UTF’s public API we provide the following attributes: ConditionalIgnore attribute ParametrizedIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-constraints.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-constraints.html",
    "title": "Custom constraints | Inventory System",
    "summary": "Custom constraints NUnit allows you to write test assertions in a more descriptive and human readable way using the Assert.That mechanism, where the first parameter is an object under test and the second parameter describes conditions that the object has to meet. Is We’ve extended NUnit API with a custom constraint type and declared an overlay Is class. To resolve ambiguity between the original implementation and the custom one you must explicitly declare it with a using statement or via addressing through the full type name UnityEngine.TestTools.Constraints.Is. Static Methods Syntax Description AllocatingGCMemory A constraint type that invokes the delegate you provide as the parameter of Assert.That and checks whether it causes any GC memory allocations. It passes if any GC memory is allocated and fails if not. Example using Is = UnityEngine.TestTools.Constraints.Is; class MyTestClass { [Test] public void MyTest() { Assert.That(() => { var i = new int[500]; }, Is.AllocatingGCMemory()); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-equality-comparers.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-equality-comparers.html",
    "title": "Custom equality comparers | Inventory System",
    "summary": "Custom equality comparers To enable easier verification of custom Unity type values in your tests we provide you with some custom equality comparers: ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Use these classes to compare two objects of the same type for equality within the range of a given tolerance using NUnit or custom constraints . Call Instance to apply the default calculation error value to the comparison. To set a specific error value, instantiate a new comparer object using a one argument constructor ctor(float error). Static properties Syntax Description Instance A singleton instance of the comparer with a predefined default error value. Constructors Syntax Description ctor(float error) Creates an instance of comparer with a custom error value.allowedError. The relative error to be considered while comparing two values. Public methods Syntax Description bool Equals(T expected, T actual); Compares the actual and expected objects for equality using a custom comparison mechanism. Returns true if expected and actual objects are equal, otherwise it returns false."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-yield-instructions.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-custom-yield-instructions.html",
    "title": "Custom yield instructions | Inventory System",
    "summary": "Custom yield instructions By implementing this interface below, you can define custom yield instructions in Edit Mode tests. IEditModeTestYieldInstruction In an Edit Mode test, you can use IEditModeTestYieldInstruction interface to implement your own instruction. There are also a couple of commonly used implementations available: EnterPlayMode ExitPlayMode RecompileScripts WaitForDomainReload Example [UnityTest] public IEnumerator PlayOnAwakeDisabled_DoesntPlayWhenEnteringPlayMode() { var videoPlayer = PrefabUtility.InstantiatePrefab(m_VideoPlayerPrefab.GetComponent<VideoPlayer>()) as VideoPlayer; videoPlayer.playOnAwake = false; yield return new EnterPlayMode(); var videoPlayerGO = GameObject.Find(m_VideoPlayerPrefab.name); Assert.IsFalse(videoPlayerGO.GetComponent<VideoPlayer>().isPlaying); yield return new ExitPlayMode(); Object.DestroyImmediate(GameObject.Find(m_VideoPlayerPrefab.name)); } Properties Syntax Description bool ExpectDomainReload Returns true if the instruction expects a domain reload to occur. bool ExpectedPlaymodeState Returns true if the instruction expects the Unity Editor to be in Play Mode. Methods Syntax Description IEnumerator Perform() Used to define multi-frame operations performed when instantiating a yield instruction. EnterPlayMode Implements IEditModeTestYieldInstruction. Creates a yield instruction to enter Play Mode. When creating an Editor test that uses the UnityTest attribute, use this to trigger the Editor to enter Play Mode. Throws an exception if the Editor is already in Play Mode or if there is a script compilation error. ExitPlayMode Implements IEditModeTestYieldInstruction. A new instance of the class is a yield instruction to exit Play Mode. Throws an exception if the Editor is not in Play Mode."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-execution-settings.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-execution-settings.html",
    "title": "ExecutionSettings | Inventory System",
    "summary": "ExecutionSettings The ExecutionSettings is a set of filters and other settings provided when running a set of tests from the TestRunnerApi. Constructors Syntax Description ExecutionSettings(params Filter[] filtersToExecute) Creates an instance with a given set of filters, if any. Fields Syntax Description Filter[] filters A collection of Filters to execute tests on. ITestRunSettings overloadTestRunSettings An instance of ITestRunSettings to set up before running tests on a Player. bool runSynchronously If true, the call to Execute() will run tests synchronously, guaranteeing that all tests have finished running by the time the call returns. Note that this is only supported for EditMode tests, and that tests which take multiple frames (i.e. [UnityTest] tests, or tests with [UnitySetUp] or [UnityTearDown] scaffolding) will be filtered out. 'int playerHeartbeatTimeout' The time, in seconds, the editor should wait for heartbeats after starting a test run on a player. This defaults to 10 minutes."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-filter.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-filter.html",
    "title": "Filter | Inventory System",
    "summary": "Filter The filter class provides the TestRunnerApi with a specification of what tests to run when running tests programmatically. Fields Syntax Description TestMode testMode An enum flag that specifies if Edit Mode or Play Mode tests should run. Applying both Edit Mode and Play Mode is currently not supported when running tests from the API. string[] testNames The full name of the tests to match the filter. This is usually in the format FixtureName.TestName. If the test has test arguments, then include them in parenthesis. E.g. MyTestClass2.MyTestWithMultipleValues(1). string[] groupNames The same as testNames, except that it allows for Regex. This is useful for running specific fixtures or namespaces. E.g. \"^MyNamespace\\\\.\" Runs any tests where the top namespace is MyNamespace. string[] categoryNames The name of a Category to include in the run. Any test or fixtures runs that have a Category matching the string. string[] assemblyNames The name of assemblies included in the run. That is the assembly name, without the .dll file extension. E.g., MyTestAssembly. BuildTarget? targetPlatform The BuildTarget platform to run the test on. If set to null, then the Editor is the target for the tests."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-icallbacks.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-icallbacks.html",
    "title": "ICallbacks | Inventory System",
    "summary": "ICallbacks An interface for receiving callbacks when running tests. All test runs invoke the callbacks until the next domain reload. The RunStarted method runs when the whole test run starts. Then the TestStarted method runs with information about the tests it is about to run on an assembly level. Afterward, it runs on a test fixture level and then on the individual test. If the test is a parameterized test, then it is also invoked for each parameter combination. After each part of the test tree have completed running, the corresponding TestFinished method runs with the test result. At the end of the run, the RunFinished event runs with the test result. An extended version of the callback, IErrorCallbacks, extends this ICallbacks to receive calls when a run fails due to a build error. Public methods Syntax Description void RunStarted(ITestAdaptor testsToRun) Invoked when the test run starts. The ITestAdaptor represents the tree of tests to run. void RunFinished(ITestResultAdaptor result) Invoked when the test run finishes. The ITestResultAdaptor represents the results of the set of tests that have run. void TestStarted(ITestAdaptor test) Invoked on each node of the test tree, as that part of the tree starts to run. void TestFinished(ITestResultAdaptor result) Invoked on each node of the test tree once that part of the test tree has finished running. The ITestResultAdaptor represents the results of the current node of the test tree. Example An example that sets up a listener on the API. The listener prints the number of failed tests after the run has finished: public void SetupListeners() { var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RegisterCallbacks(new MyCallbacks()); } private class MyCallbacks : ICallbacks { public void RunStarted(ITestAdaptor testsToRun) { } public void RunFinished(ITestResultAdaptor result) { Debug.Log(string.Format(\"Run finished {0} test(s) failed.\", result.FailCount)); } public void TestStarted(ITestAdaptor test) { } public void TestFinished(ITestResultAdaptor result) { } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-ierror-callbacks.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-ierror-callbacks.html",
    "title": "IErrorCallbacks | Inventory System",
    "summary": "IErrorCallbacks An extended version of the ICallbacks, which get invoked if the test run fails due to a build error or if any IPrebuildSetup has a failure. Public methods Syntax Description void OnError(string message) The error message detailing the reason for the run to fail."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-adaptor.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-adaptor.html",
    "title": "ITestAdaptor | Inventory System",
    "summary": "ITestAdaptor ITestAdaptor is a representation of a node in the test tree implemented as a wrapper around the NUnit ITest interface. Properties Syntax Description string Id The ID of the test tree node. The ID can change if you add new tests to the suite. Use UniqueName, if you want to have a more permanent point of reference. string Name The name of the test. E.g., MyTest. string FullName The full name of the test. E.g., MyNamespace.MyTestClass.MyTest. int TestCaseCount The total number of test cases in the node and all sub-nodes. bool HasChildren Whether the node has any children. bool IsSuite Whether the node is a test suite/fixture. IEnumerable<ITestAdaptor> Children The child nodes. ITestAdaptor Parent The parent node, if any. int TestCaseTimeout The test case timeout in milliseconds. Note that this value is only available on TestFinished. ITypeInfo TypeInfo The type of test class as an NUnit ITypeInfo. If the node is not a test class, then the value is null. IMethodInfo Method The Nunit IMethodInfo of the test method. If the node is not a test method, then the value is null. object[] Arguments The array of arguments that the test method/fixture will be invoked with. string[] Categories An array of the categories applied to the test or fixture. bool IsTestAssembly Whether the node represents a test assembly. RunState RunState The run state of the test node. Either NotRunnable, Runnable, Explicit, Skipped, or Ignored. string Description The description of the test. string SkipReason The skip reason. E.g., if ignoring the test. string ParentId The ID of the parent node. string ParentFullName The full name of the parent node. string UniqueName A unique generated name for the test node. E.g., Tests.dll/MyNamespace/MyTestClass/[Tests][MyNamespace.MyTestClass.MyTest]. string ParentUniqueName A unique name of the parent node. E.g., Tests.dll/MyNamespace/[Tests][MyNamespace.MyTestClass][suite]. int ChildIndex The child index of the node in its parent. TestMode TestMode The mode of the test. Either Edit Mode or Play Mode. Note: Some properties are not available when receiving the test tree as a part of a test result coming from a standalone Player, such as TypeInfo and Method."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-result-adaptor.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-result-adaptor.html",
    "title": "ITestResultAdaptor | Inventory System",
    "summary": "ITestResultAdaptor The ITestResultAdaptor is the representation of the test results for a node in the test tree implemented as a wrapper around the NUnit ITest interface. Properties Syntax Description ITestAdaptor Test The test details of the test result tree node as a TestAdaptor. string Name The name of the test node. string FullName Gets the full name of the test result string ResultState The state of the result as a string. E.g., Success, Skipped, Failure, Explicit, Cancelled. TestStatus TestStatus The status of the test as an enum. Either Inconclusive, Skipped, Passed, or Failed. double Duration Gets the elapsed time for running the test in seconds. DateTime StartTime Gets or sets the time the test started running. DateTime EndTime Gets or sets the time the test finished running. string Message Gets the message associated with a test failure or with not running the test string StackTrace Gets any stack trace associated with an error or failure. Not available in the Compact Framework 1.0. int AssertCount Gets the number of asserts that ran during the test and all its children. int FailCount Gets the number of test cases that failed when running the test and all its children. int PassCount Gets the number of test cases that passed when running the test and all its children. int SkipCount Gets the number of test cases skipped when running the test and all its children. int InconclusiveCount Gets the number of test cases that were inconclusive when running the test and all its children. bool HasChildren Indicates whether this result has any child results. Accessing HasChildren should not force the creation of the Children collection in classes implementing this interface. IEnumerable<ITestResultAdaptor> Children Gets the collection of child results. string Output Gets any text output written to this result. TNode ToXml Gets the test results as an NUnit XML node. Use this to save the results to an XML file."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-run-settings.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-itest-run-settings.html",
    "title": "ITestRunSettings | Inventory System",
    "summary": "ITestRunSettings ITestRunSettings lets you set any of the global settings right before building a Player for a test run and then reverts the settings afterward. ITestRunSettings implements IDisposable, and runs after building the Player with tests. Public methods Syntax Description void Apply() A method called before building the Player. void Dispose() A method called after building the Player or if the build failed. Example The following example sets the iOS SDK version to be the simulator SDK and resets it to the original value after the run. public class MyTestSettings : ITestRunSettings { private iOSSdkVersion originalSdkVersion; public void Apply() { originalSdkVersion = PlayerSettings.iOS.sdkVersion; PlayerSettings.iOS.sdkVersion = iOSSdkVersion.SimulatorSDK; } public void Dispose() { PlayerSettings.iOS.sdkVersion = originalSdkVersion; } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-outerunitytestaction.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-outerunitytestaction.html",
    "title": "OuterUnityTestAction | Inventory System",
    "summary": "OuterUnityTestAction OuterUnityTestAction is a wrapper outside of the tests, which allows for any tests with this attribute to run code before and after the tests. This method allows for yielding commands in the same way as UnityTest. The attribute must inherit the NUnit attribute and implement IOuterUnityTestAction. OuterUnityTestAction Example using System.Collections; using NUnit.Framework; using NUnit.Framework.Interfaces; using UnityEngine; using UnityEngine.TestTools; public class MyTestClass { [UnityTest, MyOuterActionAttribute] public IEnumerator MyTestInsidePlaymode() { Assert.IsTrue(Application.isPlaying); yield return null; } } public class MyOuterActionAttribute : NUnitAttribute, IOuterUnityTestAction { public IEnumerator BeforeTest(ITest test) { yield return new EnterPlayMode(); } public IEnumerator AfterTest(ITest test) { yield return new ExitPlayMode(); } } Execution order Unity outer test action is not rerun on domain reload but non-Unity action attributes are: Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Test actions with domain reload example using NUnit.Framework.Interfaces; public class TestActionOnSuiteAttribute : NUnitAttribute, ITestAction { public void BeforeTest(ITest test) { Debug.Log(\"TestAction OnSuite BeforeTest\"); } public void AfterTest(ITest test) { } public ActionTargets Targets { get { return ActionTargets.Suite; } } } public class TestActionOnTestAttribute : NUnitAttribute, ITestAction { public void BeforeTest(ITest test) { Debug.Log(\"TestAction OnTest BeforeTest\"); } public void AfterTest(ITest test) { Debug.Log(\"TestAction OnTest AfterTest\"); } public ActionTargets Targets { get { return ActionTargets.Test; } } } public class OuterTestAttribute : NUnitAttribute, IOuterUnityTestAction { public IEnumerator BeforeTest(ITest test) { Debug.Log(\"OuterTestAttribute BeforeTest\"); yield return null; } public IEnumerator AfterTest(ITest test) { Debug.Log(\"OuterTestAttribute AfterTest\"); yield return null; } } [TestActionOnSuite] public class ActionOrderTestBase { [Test, OuterTest, TestActionOnTest] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest, OuterTest, TestActionOnTest] public IEnumerator UnityTestWithDomainReload() { Log(\"Test part 1\"); yield return new EnterPlayMode(); //Domain reload yield return new ExitPlayMode(); Log(\"Test part 2\"); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-recompile-scripts.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-recompile-scripts.html",
    "title": "RecompileScripts | Inventory System",
    "summary": "RecompileScripts RecompileScripts is an IEditModeTestYieldInstruction that you can yield in Edit Mode tests. It lets you trigger a recompilation of scripts in the Unity Editor. Constructors Syntax Description RecompileScripts(bool expectScriptCompilation = true, bool expectScriptCompilationSuccess = true) Creates a new instance of the RecompileScripts yield instruction. The parameter expectScriptCompilation indicates if you expect a script compilation to start (defaults to true). If a script compilation does not start and expectScriptCompilation is true, then it throws an exception. Example [UnitySetUp] public IEnumerator SetUp() { using (var file = File.CreateText(\"Assets/temp/myScript.cs\")) { file.Write(\"public class ATempClass { }\"); } AssetDatabase.Refresh(); yield return new RecompileScripts(); }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-setup-and-cleanup.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-setup-and-cleanup.html",
    "title": "Setup and cleanup at build time | Inventory System",
    "summary": "Setup and cleanup at build time In some cases, it is relevant to perform changes to Unity or the file system before building the tests. In the same way, it may be necessary to clean up such changes after the test run. In response to such needs, you can incorporate the pre-build setup and post-build cleanup concepts into your tests in one of the following ways: Via implementation of IPrebuildSetup and IPostBuildCleanup interfaces by a test class. Via applying the PrebuildSetup attribute and PostBuildCleanup attribute on your test class, one of the tests or the test assembly, providing a class name that implements the corresponding interface as an argument (fx [PrebuildSetup(\"MyTestSceneSetup\")]). Execution order All setups run in a deterministic order one after another. The first to run are the setups defined with attributes. Then any test class implementing the interface runs, in alphabetical order inside their namespace, which is the same order as the tests run. Note: Cleanup runs right away for a standalone test run, but only after related tests run in the Unity Editor. PrebuildSetup and PostBuildCleanup Both PrebuildSetup and PostBuildCleanup attributes run if the respective test or test class is in the current test run. The test is included either by running all tests or setting a filter that includes the test. If multiple tests reference the same pre-built setup or post-build cleanup, then it only runs once. IPrebuildSetup Implement this interface if you want to define a set of actions to run as a pre-build step. Public methods Syntax Description void Setup() Implement this method to call actions automatically before the build process. IPostBuildCleanup Implement this interface if you want to define a set of actions to execute as a post-build step. Cleanup runs right away for a standalone test run, but only after all the tests run within the Editor. Public methods Syntax Description void Cleanup() Implement this method to specify actions that should run as a post-build cleanup step. Example [TestFixture] public class CreateSpriteTest : IPrebuildSetup { Texture2D m_Texture; Sprite m_Sprite; public void Setup() { #if UNITY_EDITOR var spritePath = \"Assets/Resources/Circle.png\"; var ti = UnityEditor.AssetImporter.GetAtPath(spritePath) as UnityEditor.TextureImporter; ti.textureCompression = UnityEditor.TextureImporterCompression.Uncompressed; ti.SaveAndReimport(); #endif } [SetUp] public void SetUpTest() { m_Texture = Resources.Load<Texture2D>(\"Circle\"); } [Test] public void WhenNullTextureIsPassed_CreateShouldReturnNullSprite() { // Check with Valid Texture. LogAssert.Expect(LogType.Log, \"Circle Sprite Created\"); Sprite.Create(m_Texture, new Rect(0, 0, m_Texture.width, m_Texture.height), new Vector2(0.5f, 0.5f)); Debug.Log(\"Circle Sprite Created\"); // Check with NULL Texture. Should return NULL Sprite. m_Sprite = Sprite.Create(null, new Rect(0, 0, m_Texture.width, m_Texture.height), new Vector2(0.5f, 0.5f)); Assert.That(m_Sprite, Is.Null, \"Sprite created with null texture should be null\"); } } Tip: Use #if UNITY_EDITOR if you want to access Editor only APIs, but the setup/cleanup is inside a Play Mode assembly."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-runner-api.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-runner-api.html",
    "title": "TestRunnerApi | Inventory System",
    "summary": "TestRunnerApi The TestRunnerApi retrieves and runs tests programmatically from code inside the project, or inside other packages. TestRunnerApi is a ScriptableObject. You can initialize the API like this: var testRunnerApi = ScriptableObject.CreateInstance<TestRunnerApi>(); Note: You can subscribe and receive test results in one instance of the API, even if the run starts from another instance. The TestRunnerApi supports the following workflows: How to run tests programmatically How to get test results How to retrieve the list of tests Public methods Syntax Description void Execute(ExecutionSettings executionSettings) Starts a test run with a given set of ExecutionSettings. void RegisterCallbacks(ICallbacks testCallbacks, int priority = 0) Sets up a given instance of ICallbacks to be invoked on test runs. void UnregisterCallbacks(ICallbacks testCallbacks) Unregisters an instance of ICallbacks to no longer receive callbacks from test runs. void RetrieveTestList(TestMode testMode, Action<ITestAdaptor> callback) Retrieve the full test tree as ITestAdaptor for a given test mode. void SaveResultToFile(ITestResultAdaptor results, string filePath) Save a given set of ITestResultAdaptor to a file at the provided file path."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-settings-file.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-settings-file.html",
    "title": "Test settings file | Inventory System",
    "summary": "Test settings file You can define options for a test run in a TestSettings.json file. You can specify the location of this file using the testSettingsFile command line argument. Here's an example of a TestSettings.json file: { \"scriptingBackend\":\"WinRTDotNET\", \"Architecture\":null, \"apiProfile\":0, \"featureFlags\": { \"requiresSplashScreen\": true } } Supported options You can define the following options in a test settings file: apiProfile The .Net compatibility level, refer to ApiCompatabilityLevel. Set to one of the following values: 1 - .Net 2.0 2 - .Net 2.0 Subset 3 - .Net 4.6 5 - .Net micro profile (used by Mono scripting backend if Stripping Level is set to Use micro mscorlib) 6 - .Net Standard 2.0 appleEnableAutomaticSigning Sets option for automatic signing of Apple devices, refer to PlayerSettings.iOS.appleEnableAutomaticSigning. appleDeveloperTeamID Sets the team ID for the apple developer account, refer to PlayerSettings.iOS.appleDeveloperTeamID. architecture Target architecture for Android, refer to AndroidArchitecture. Set to one of the following values: None = 0 ARMv7 = 1 ARM64 = 2 X86 = 4 All = 4294967295 iOSManualProvisioningProfileType Refer to PlayerSettings.iOS.iOSManualProvisioningProfileType. Set to one of the following values: 0 - Automatic 1 - Development 2 - Distribution iOSManualProvisioningProfileID iOSTargetSDK Target SDK for iOS. Set to one of the following values, which should be given as a string literal enclosed in quotes: DeviceSDK SimulatorSDK tvOSManualProvisioningProfileType Refer to PlayerSettings.iOS.tvOSManualProvisioningProfileType. Set to one of the following values: 0 - Automatic 1 - Development 2 - Distribution tvOSManualProvisioningProfileID tvOSTargetSDK Target SDK for tvOS. Set to one of the following values, which should be given as a string literal enclosed in quotes: DeviceSDK SimulatorSDK scriptingBackend Set to one of the following values, which should be given as a string literal enclosed in quotes: Mono2x IL2CPP WinRTDotNET playerGraphicsAPI Set graphics API that will be used during test execution in the player. Value can be any GraphicsDeviceType as a string literal enclosed in quotes. Value will only be set if it is supported on the target platform. webGLClientBrowserType A browser to be used when running test using WebGL platform. Accepted browser types: Safari Firefox Chrome Chromium webGLClientBrowserPath An absolute path to the browser's location on your device. If not defined, path from UNITY_AUTOMATION_DEFAULT_BROWSER_PATH enviromental variable will be used. androidBuildAppBundle A boolean setting that allows to build an Android App Bundle (AAB) instead of APK for tests. featureFlags Map of strings and boolean values which can switch Unity Test Framework features on or off. The currently supported features are: fileCleanUpCheck Throws an error message (instead of warning) if tests generate files which are not cleaned up. False (off) by default. requiresSplashScreen By default UTR disables the Made with Unity splash screen to speed up building the player and running tests. Set this flag to true to override the default and always require a splash screen to be built."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-utils.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-test-utils.html",
    "title": "Test Utils | Inventory System",
    "summary": "Test Utils This contains test utility functions for float value comparison and creating primitives. Static Methods Syntax Description bool AreFloatsEqual(float expected, float actual, float allowedRelativeError) Relative epsilon comparison of two float values for equality. allowedRelativeError is the relative error to be used in relative epsilon comparison. The relative error is the absolute error divided by the magnitude of the exact value. Returns true if the actual value is equivalent to the expected value. bool AreFloatsEqualAbsoluteError(float expected, float actual, float allowedAbsoluteError) Compares two floating point numbers for equality under the given absolute tolerance. allowedAbsoluteError is the permitted error tolerance. Returns true if the actual value is equivalent to the expected value under the given tolerance. GameObject CreatePrimitive( type) Creates a GameObject with a primitive MeshRenderer. This is an analogue to the GameObject.CreatePrimitive, but creates a primitive MeshRenderer with a fast Shader instead of the default built-in Shader, optimized for testing performance. type is the primitive type of the required GameObject. Returns a GameObject with primitive MeshRenderer and Collider. Example [TestFixture] class UtilsTests { [Test] public void CheckThat_FloatsAreEqual() { float expected = 10e-8f; float actual = 0f; float allowedRelativeError = 10e-6f; Assert.That(Utils.AreFloatsEqual(expected, actual, allowedRelativeError), Is.True); } [Test] public void CheckThat_FloatsAreAbsoluteEqual() { float expected = 0f; float actual = 10e-6f; float error = 10e-5f; Assert.That(Utils.AreFloatsEqualAbsoluteError(expected, actual, error), Is.True); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-tests-monobehaviour.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-tests-monobehaviour.html",
    "title": "MonoBehaviour tests | Inventory System",
    "summary": "MonoBehaviour tests MonoBehaviourTest is a coroutine and a helper for writing MonoBehaviour tests. Yield a MonoBehaviourTest when using the UnityTest attribute to instantiate the MonoBehaviour you wish to test and wait for it to finish running. Implement the IMonoBehaviourTest interface on the MonoBehaviour to state when the test completes. Example [UnityTest] public IEnumerator MonoBehaviourTest_Works() { yield return new MonoBehaviourTest<MyMonoBehaviourTest>(); } public class MyMonoBehaviourTest : MonoBehaviour, IMonoBehaviourTest { private int frameCount; public bool IsTestFinished { get { return frameCount > 10; } } void Update() { frameCount++; } } MonoBehaviourTest<T> This is a wrapper that allows running tests on MonoBehaviour scripts. Inherits from CustomYieldInstruction. Properties Syntax Description T component A MonoBehaviour component created for the test and attached to the test’s GameObject. GameObject gameObject A GameObject created as a container for the test component. bool keepWaiting (Inherited) Returns true if the test is not finished yet, which keeps the coroutine suspended. IMonoBehaviourTest An interface implemented by a MonoBehaviour test. Properties Syntax Description bool IsTestFinished Indicates when the test is considered finished."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-tests-parameterized.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-tests-parameterized.html",
    "title": "Parameterized tests | Inventory System",
    "summary": "Parameterized tests For data-driven testing, you may want to have your tests parameterized. You may use both the NUnit attributes TestCase and ValueSource with a unit test. Note: With UnityTest it is recommended to use ValueSource since TestCase is not supported. Example static int[] values = new int[] { 1, 5, 6 }; [UnityTest] public IEnumerator MyTestWithMultipleValues([ValueSource(\"values\")] int value) { yield return null; } Ignore based on parameters You can selectively ignore tests based on the parameters supplied to the test method by using the ParameterizedIgnoreAttribute."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-unitysetup-and-unityteardown.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-unitysetup-and-unityteardown.html",
    "title": "UnitySetUp and UnityTearDown | Inventory System",
    "summary": "UnitySetUp and UnityTearDown The UnitySetUp and UnityTearDown attributes are identical to the standard SetUp and TearDown attributes, with the exception that they allow for yielding instructions. The UnitySetUp and UnityTearDown attributes expect a return type of IEnumerator. UnitySetUp and UnityTeardown example public class SetUpTearDownExample { [UnitySetUp] public IEnumerator SetUp() { yield return new EnterPlayMode(); } [Test] public void MyTest() { Debug.Log(\"This runs inside playmode\"); } [UnityTearDown] public IEnumerator TearDown() { yield return new ExitPlayMode(); } } Execution order UnitySetUp and UnityTearDown can be used with either the Test or UnityTest test attributes. In both cases the relative execution order of Unity and non-Unity SetUp and TearDown attributes is the same. The only difference is that a UnityTest allows for yielding instructions during the test that can result in a domain reload, in which case the non-Unity SetUp methods are re-run before proceeding to the second part of the test. Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Base and Derived classes The term base in the execution order denotes a base class from which a test class inherits. UnitySetUp and UnityTearDown follow the same pattern as NUnit SetUp and TearDown attributes in determining execution order between base classes and their derivatives. SetUp methods are called on base classes first, and then on derived classes. TearDown methods are called on derived classes first, and then on the base class. See the NUnit Documentation for more details. Base and Derived class example public class BaseClass { [OneTimeSetUp] public void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp Base\"); } [SetUp] public void SetUp() { Debug.Log(\"SetUp Base\"); } [UnitySetUp] public IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup Base\"); yield return null; } [TearDown] public void TearDown() { Debug.Log(\"TearDown Base\"); } [UnityTearDown] public IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown Base\"); yield return null; } } public class DerivedClass: BaseClass { [OneTimeSetUp] public new void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp\"); } [SetUp] public new void SetUp() { Debug.Log(\"SetUp\"); } [UnitySetUp] public new IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup\"); yield return null; } [Test] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest] public IEnumerator UnityTest() { Debug.Log(\"UnityTest before yield\"); yield return null; Debug.Log(\"UnityTest after yield\"); } [TearDown] public new void TearDown() { Debug.Log(\"TearDown\"); } [UnityTearDown] public new IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown\"); yield return null; } [OneTimeTearDown] public void OneTimeTearDown() { Debug.Log(\"OneTimeTearDown\"); } } Domain reload example public class BaseClass { [OneTimeSetUp] public void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp Base\"); } [SetUp] public void SetUp() { Debug.Log(\"SetUp Base\"); } [UnitySetUp] public IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup Base\"); yield return null; } [TearDown] public void TearDown() { Debug.Log(\"TearDown Base\"); } [UnityTearDown] public IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown Base\"); yield return null; } } public class DerivedClass: BaseClass { [OneTimeSetUp] public new void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp\"); } [SetUp] public new void SetUp() { Debug.Log(\"SetUp\"); } [UnitySetUp] public new IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup\"); yield return null; } [Test] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest] public IEnumerator UnityTest() { Debug.Log(\"UnityTest before yield\"); yield return new EnterPlayMode(); //Domain reload happening yield return new ExitPlayMode(); Debug.Log(\"UnityTest after yield\"); } [TearDown] public new void TearDown() { Debug.Log(\"TearDown\"); } [UnityTearDown] public new IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown\"); yield return null; } [OneTimeTearDown] public void OneTimeTearDown() { Debug.Log(\"OneTimeTearDown\"); } }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-wait-for-domain-reload.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/reference-wait-for-domain-reload.html",
    "title": "WaitForDomainReload | Inventory System",
    "summary": "WaitForDomainReload WaitForDomainReload is an IEditModeTestYieldInstruction that you can yield in Edit Mode tests. It delays the execution of scripts until after an incoming domain reload. If the domain reload results in a script compilation failure, then it throws an exception. Constructors Syntax Description WaitForDomainReload() Create a new instance of the WaitForDomainReload yield instruction. Example [UnitySetUp] public IEnumerator SetUp() { File.Copy(\"Resources/MyDll.dll\", @\"Assets/MyDll.dll\", true); // Trigger a domain reload. AssetDatabase.Refresh(); yield return new WaitForDomainReload(); }"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/resources.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/resources.html",
    "title": "Resources | Inventory System",
    "summary": "Resources Here you can find other related resources to the Unity Test Framework: Performance Benchmarking in Unity: How to Get Started [Blog] Testing Test-Driven Development with the Unity Test Runner [Blog]"
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/whats-new.html",
    "title": "What's new in version 1.4 | Inventory System",
    "summary": "What's new in version 1.4 This page summarizes new features, improvements, and issues resolved in version 1.4 of Unity Test Framework. Added API updates In this version, we introduced several API changes: Added API for saving results Added API for canceling test runs Added overloads of LogAssert.Expect which allow users to expect a log message without specifying a severity, which will match logged messages of any severity. Ignore tests based on arguments This version introduces the ParameterizedIgnoreAttribute which allows ignoring tests based on arguments which were passed to the test method of a parameterized test. Updated Revised Test Runner UI This version includes a revised Test Runner window and several usability improvements: Added a third tab to the Test Runner window, for running in a player explicitly. This makes it easier to run a subset of tests, as well as retaining the test results from the latest player run. Moved the run and action buttons to the bottom of the window, to separate them from the filters. The stack traces are clickable, and will open the relevant file in the external editor. When searching, the parents of the matching tests are expanded, to make it easier to see the context of the matching tests. ] Fixed This version includes many bug fixes and performance improvements. For a full list of changes and updates in this version, see the Unity Test Framework package changelog."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-create-test-assembly.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-create-test-assembly.html",
    "title": "Workflow: Creating test assemblies | Inventory System",
    "summary": "Workflow: Creating test assemblies UTF looks for tests in a Test Assembly, which is any assembly that references Nunit. The Test Runner UI helps you set up test assemblies: Select the Assets folder in your Project window. Open the Test Runner window (menu: Window > General > Test Runner). In the Test Runner window, select Create a new Test Assembly Folder in the active path. Alternatively, you can go via the Assets menu: Select the Assets folder in your Project window. Create a new Test Assembly Folder (menu: Assets > Create > Testing > Test Assembly Folder). This creates a Tests folder in your project Assets with a corresponding .asmdef file with the required references. You can change the name of the new Assembly Definition and press Enter to accept it. Click on the assembly definition file to inspect it in the Inspector window. You'll see that it has references to nunit.framework.dll*,* UnityEngine.TestRunner, and UnityEditor.TestRunner assemblies. This tells UTF that this is a test assembly. The checkbox selections under Platforms determine which platforms the test assembly can run on. Assemblies created through the Test Runner target the Editor only by default. Any Platform or a specific platform other than Editor makes it possible to run any Play Mode tests in the assembly on standalone Players for the additional platforms. Note: The UnityEditor.TestRunner reference is only available for Edit Mode tests. You can repeat the steps above as many times as you like to create additional Test Assemblies. The first Test Assembly folder you create is named Tests by default and subsequent ones are named Tests 1, Tests 2, and so on. Remember that you can always rename the assemblies but each assembly name must be unique. Note: Changing the file name of the assembly definition file does not affect the value of the Name property in the file. Use the Inspector window or edit the .asmdef direclty in a text editor to make sure the name property is properly changed."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-create-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-create-test.html",
    "title": "Workflow: Creating tests | Inventory System",
    "summary": "Workflow: Creating tests To create a test through the Test Runner window: Create your Test Assembly folder and select it in the Project window. Open the Test Runner window (menu: Window > General > Test Runner). Click the Create a new Test Script in the active path button in the Test Runner window. Alternatively, use the Asset menu: In the Project window, select the new folder. Create a new test script in the folder (menu: Assets > Create > Testing > C# Test Script). This creates a NewTestScript.cs file in the Tests folder with some sample tests to get you started. Change the name of the script, if necessary, and press Enter to accept it. Now you’ll see the sample tests in the Test Runner window: Now you can open the tests in your favorite script editor. Note: Unity does not include test assemblies (NUnit, Unity Test Framework, and user script assemblies) when using the normal build pipeline, but does include them when using Run on <Platform> in the Test Runner window. Creating Play Mode tests The process for creating a Play Mode test is the same as for creating an Edit Mode test. The only relevant differences are: Play Mode tests that need to run in a standalone platform Player should be in an assembly that references the required platform."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-run-playmode-test-standalone.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-run-playmode-test-standalone.html",
    "title": "Workflow: Running Play Mode tests in a player | Inventory System",
    "summary": "Workflow: Running Play Mode tests in a player Build and run Tests in a player If you run a Play Mode test in the same way as an Editor test, it runs inside the Unity Editor. You can also run Play Mode tests on specific platforms. Select Player tab to build and run your tests on the currently active target platform. Note: Your current platform shows at the top of the Test Runner window. For example, in the image above, the bar above the search bar reads Running in StandaloneOSX, because the current platform is MacOS. The target platform is always the current Platform selected in Build Settings (menu: File > Build Settings). The test result displays in the build once the test completes: The application running on the platform reports back the test results to the Editor UI then displays the executed tests and shuts down. To make sure you receive the test results from the Player on your target platform back into the Editor that’s running the test, both should be on the same network. Note: Some platforms do not support shutting down the application with Application.Quit, so it will continue running after reporting the test results. If Unity cannot instantiate the connection, you can see the tests succeed in the running application. Running tests on platforms with arguments, in this state, does not provide XML test results. Build a player with tests You can use the dropdown selector next to the Run All button to build a player with all the tests, or a selected subset of tests, without running it. Note: In some cases the available selections are different: If the selected platform is Android or iOS and Export project is enabled in Build Settings, the selections are Export All Tests and Export Selected Tests. For more information, see Edit Mode vs Play Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-run-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/Documentation~/workflow-run-test.html",
    "title": "Workflow: Running tests | Inventory System",
    "summary": "Workflow: Running tests There are several ways to run tests in the Test Runner window: Double-click on the test or test fixture name. Use the Run All or Run Selected buttons at the bottom of the window. Right-click on any item in the test tree and choose Run in the context menu to run the test and all of its children. When you run a test the test status icon changes to show the result and a counter in the top right corner updates: Filters If you have a lot of tests, and you only want to view/run a sub-set of them, you can filter them in several ways (see image above): Type in the search box in the top left Click a test class or fixture (such as NewTestScript in the image above) Click one of the test result icon buttons in the top right Run tests within Rider It is possible to run unit tests in the Unity Test Framework directly from JetBrains Rider. For more information, see the JetBrains official documentation and their blog post Run Unity tests in Rider 2018.1. Known issues and limitations The total duration of test suites shown in the Test Runner window does not take into account the time taken to run any OneTimeSetup, UnityOneTimeSetup, OneTimeTearDown or UnityOneTimeTearDown methods, but instead shows the sum of the duration of all tests in the suite."
  },
  "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.test-framework@dfdbd02f5918/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Test Framework copyright © 2024 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog [1.8.7] - 2024-05-24 Added Released ronl-workflow-custom-marker.md Added a new workflow to the Timeline Workflows documentation: Released ronl-workflow-custom-marker.md The Create a custom Notes marker workflow demonstrates how to create a custom marker for adding notes to Timeline instances. This workflow also demonstrates how to change the default appearance of a custom marker with scripting and a Unity Style Sheet (USS). Fixed Fixed bug where using , and . (<>) to step frames in the Animation Window while the Timeline Window was linked would sometimes not work. IN-56667 When the Timeline and Animation windows are linked and the Timeline Window is active, moving the playhead in the Timeline Window will cause the animation window to repaint immediately. [1.8.6] - 2023-10-05 Changed In the Create Asset menu, the Signal and Timeline items have been moved to the Timeline submenu. Fixed Fixed issue where changing the name of a group track was not undoable (TB-218). Fixed issue where a warning would be logged in the console for TrackAsset (TB-229). Fixed performance regression when rebuilding the playable graph. Fixed a MissingReferenceException when editing a Timeline that is an instance of a prefab and a bound Animator is destroyed (TB-222) Removed warnings due to obsolete analytics API. [1.8.5] - 2023-08-24 Added Added two new workflows to the Timeline Workflows documentation: The Use markers and signals for footsteps workflow demonstrates how to use Timeline markers, Signal assets, and Signal Receiver components to play audio sources for footsteps. The Create a Sub-Timeline instance workflow demonstrates how to create a single cut-scene by nesting a Timeline instance within another Timeline instance. Fixed Fixed playback and recording when Timeline is linked with the Animation Window. [1.8.4] - 2023-06-13 Fixed Fixed issue where exceptions were thrown when different ControlTracks are referencing the same TimelineAsset (IN-21163). [1.8.3] - 2023-06-01 Changed Updated the Timeline package documentation to include previously undocumented features and new screen images. Fixed Enable Timeline Action menu entry for Delete when PlayableDirector component is disabled. (TB-177) The Text Track sample has been updated to use the com.unity.ugui package. Removed usage of deprecated API: UnityEditor.MemoryProfiler [1.8.2] - 2023-03-02 Fixed Fixed issue where previewing the Timeline would create prefab property modifications Fixed issue where ClipEditor.OnClipChanged was not invoked when changing the object assigned to a ExposedReference<UnityEngine.Object>. [1.8.1] - 2023-02-07 Changed Reduced the number of playable graph rebuilds when editing playable assets through the clip inspector. Fixed Fixed an issue where the clip inspector was not able to display custom playable asset inspectors rendered with UIToolkit. Fixed issue where modifying curves on an animation clip did not trigger an evaluation of the graph when the Timeline Window is hidden. (TB-117) Fixed an issue where the empty marker track that's automatically created when showing the markers in the Timeline Window would remain in the Timeline Asset when the markers are hidden. ([TB-120]) [1.8.0] - 2022-10-31 Added Added field on DirectorControlPlayable: pauseAction. This property controls whether the director is paused or stopped when the playable is paused. Added field on ControlPlayableAsset: directorOnClipEnd. This asset property is passed to DirectorControlPlayable.pauseAction when the DirectorControlPlayable is created. Fixed Fixed an issue where menu items related to track, marker and clip types in contextual menus would be in arbitrary order in some versions of Unity. Menu items related to types will now be sorted based on their full names, including the assembly name. [1.7.2] - 2022-09-12 Fixed Fix post-extrapolation mode change not recalculating previous clip pre-extrapolation time. ([ATL-1291]) Fixed an issue where prefab overrides would be created when keyframing a prefab instance in Timeline. ([TB-108]) Fixed an issue where a warning would be raised when using the undo history to undo multiple timeline interactions([TB-119]) Fixed an issue where in some cases a NullReferenceException would be thrown in the PlayableDirector inspector after a TimelineAsset would be unloaded in the Editor([TB-129]) Fixed an issue with the NoFoldOut attribute drawer, which was behaving incorrectly when used outside of the sample context. ([TB-132]) [1.7.1] - 2022-03-07 Fixed Fixed warnings related to meta files related to missing folders. [1.7.0] - 2022-02-21 Added Added TimelinePlaybackControls Editor API: The Playback controls API lets you drive the Timeline Window playback controls from code. From this API, you can Change the current Time/Frame Query the current Time/Frame Start/Stop playback of the currently shown Timeline Go to First or Last frame Go to previous or next frame. Use it to accelerate your workflow, or build your own workflows on top of Timeline. Changed [Requires Unity 2021.2] Fixed an issue where the last frame of a Timeline was not guaranteed to be executed when the Playable Director had Wrap Mode None. License file header changed from \"Timeline copyright © 2021 Unity Technologies ApS\" to \"Timeline copyright © 2021 Unity Technologies\" Fixed Fixed an issue where unused TrackAssets would be saved in the TimelineAsset file after removing tracks. Fixed an issue where grouped markers at time zero would sometimes disappear after clicking on them (https://issuetracker.unity3d.com/issues/timeline-markers-disappear-when-double-clicking-on-stacked-markers-at-0-frames) Fixed an issue where selecting a prefab in the project view could trigger an exception when parenting the prefab to a prefab sub-object. (1386125) Fixed an issue where duplicated or pasted tracks that were part of group tracks would lose their associated bindings (https://issuetracker.unity3d.com/issues/duplicated-track-groups-lose-their-nester-tracks-game-object-assignments) Fixed an issue where pasting a track after changing scenes would lose PlayableAsset references in clips (https://issuetracker.unity3d.com/issues/animation-tracks-copy-loses-its-properties-when-its-pasted-from-another-scene) Fixed an issue where the Timeline Window play range would not be serialized and persisted. Fixed an issue where clicking on a clip during Play Mode would evaluate the Timeline unnecessarily. (https://issuetracker.unity3d.com/issues/timeline-rebuilds-playable-graph-when-selecting-a-timeline-clip-during-play-mode) Fixed an issue where control clips would behave inconsistently if the clip was set to hold, but the PlayableDirector was set to not extrapolate. (https://issuetracker.unity3d.com/product/unity/issues/guid/1375771) Fixed issue where a warning would appear in 2022.1 regarding AnimationWindowState.SnapMode. [Requires Unity 2021.2] Fixed an issue where the last frame of a Timeline was not guaranteed to be executed when the Playable Director had Wrap Mode None. Fixed an issue where the Timeline Window's UI would not update until the user clicked in the window if the TimelineAsset's file contents were changed on disk, such as during a version control operation 1357110 [1.6.3] - 2021-10-20 Fixed Fixed an issue where the Timeline Window would not work correctly with read-only source controlled files. Fixed an issue where the a MissingReferenceException would be thrown when an IAnimationWindowPreview component previewed by Timeline would be destroyed. (https://issuetracker.unity3d.com/issues/missingreferenceexception-is-thrown-when-using-rigbuilder-inside-a-prefab) Fixed an issue where the \"Match Content\" action would not apply on all selected clips. (1368028) [1.6.2] - 2021-08-05 Fixed Fixed an issue where copy-pasting Timeline Clips that contain Generic Lists of ExposedReferences would cause a NullReferenceException (1332377) [1.6.1] - 2021-06-22 Added ClipDrawOptions.hideScaleIndicator can now be used to disable the clip scale indicator. Added an asterisk to the Timeline Window when the currently edited Timeline Asset is dirty (has unsaved changes). (1024230) Added the IInspectorChangeHandler interface to change what happens when a UI component in the inspector is modified. (1283486) (Unity 2020.2+ only) The Timeline window title displays an asterisk when there are unsaved changes. Double click now toggles the collapsed state of group tracks. A keyboard shortcut can now be mapped to expand or collapse group tracks. Added displayClipName property to ClipDrawOption. Use displayClipName to display (true) or hide (false) the clip name. New API added to TimelineEditorWindow: TimelineNavigator. Enables navigation between timelines and nested timelines through code for automation purposes. Gives access to Timeline window breadcrumbs. (Unity 2021.2+ only) Added Framelocked preview option in Timeline preferences. Added framerate display with standard framerates. TimelineAsset framerate can be set with a StandardFramerate value. (TimelineAsset.SetStandardFramerate) Changed Removed non-working PlayRange options (Loop/Hold) as both were actually mapping to Loop behaviour and always have been. Timeline settings menu has been modified to use standard framerates in framerate submenu. TimelineAsset.fps is obsolete and is replaced by TimelineAsset.frameRate. TimelineProjectSettings.assetDefaultFramerate is obsolete and is replaced by TimelineProjectSettings.defaultFramerate. Fixed Removed GC allocations in PlayableDirector.duration when a timeline asset is assigned. (1298818) Removed warnings with AnimationWindowState snap mode. (1306205) Fixed issue where the \"Navigate Right\" (default key: Right Arrow ▶) would not behave consistently. The correct order of operations should now always be, in order: expand group, select first track of group, then select first item of the track. Fixed frame display not rounding up correctly. (1333009) Fixed an issue where TimelinePlayable duration would not be initialized if the playable is not created from the PlayableDirector. (1329151) Fixed memory leak in custom playable inspectors. (1332377) Fixed exception when using the Key All Animated shortcut with no Timeline selected. (1334339) Fixed issue where a warning would appear regarding obsolete AnimationWindowState.SnapMode values. [1.5.5] - 2021-04-30 Fixed Fixed an issue in the Curves view where the color indicator was sized incorrectly on high-res displays. (1318782) Fixed a rare issue where keyframes were created for Playable Curves when switching to play mode. (1319124) Fixed an issue where clearing the Unity selection did not refresh the Timeline window. (1320260) Fixed an issue with IAnimationWindowPreview.StartPreview not getting called for sub timelines. (1322571) Fixed an issue where the curve color identifiers would overlap property names when the Timeline window was resized. (1323591) Fixed a regression where changes made to clip curves would not be processed until another modification caused a graph rebuild. Fixed compilation issue on 2020.1 due to incorrect version checks. Fixed issue where text labels were incorrectly displayed when the mouse pointer was located above a clip. [1.5.4] - 2021-03-10 Fixed Fixed issue where the horizontal scrollbar could not be moved or resized. [1.5.3] - 2021-03-05 Changed Disabled edition of Track Asset Inspector Script field as it could break Timeline Assets. Fixed Fixed issue where the timeline header track would automatically open during a drag and drop operation. (1305436) Fixed a rare issue where some broken tracks could not be removed. (1305388) Fixed rare issue where the time field could not be edited after opening a timeline. (1312198) Fixed cosmetic issue where the duration marker was drawn over the scroll bar. Fixed issue where times without a decimal separator (. or , depending on locale) would not be interpreted correctly by the time field. (1315605) Fixed issue where a selection rectangle could not be made when started inside a track. (1315840) Performing Undo/Redo will not affect Timeline window selection when the window is locked. (Selecting sub-timelines can still be undone). (1313515) Fixed an issue where text would be clipped in the track header binding. (1302401) Fixed issue where clicking in the Timeline window while there is no active timeline would throw an exception. [1.5.2] - 2021-01-08 Added During recording, there are new ways to key animated properties: A new Inspector context menu has been added (Key All Animated) that sets a key to all currently animated properties. It is possible to make a multi-selection of tracks to set a keyframe to all currently animated properties. If no track is selected, all recording tracks are keyed. If properties are selected in the curve editor, only those properties are keyed. TimelineEditor.GetWindow and TimelineEditor.GetOrCreateWindow to get the current Timeline window or create a Timeline window. TimelineEditorWindow.SetCurrentTimeline to change which timeline asset is opened in the Timeline window. TimelineEditorWindow.lock to lock or unlock the Timeline window. TrackExtensions.GetCollapsed, TrackExtensions.SetCollapsed, TrackExtensions.IsVisibleRecursive to get and change the visibility state of a track. AnimationTrackExtensions.IsRecording, AnimationTrackExtensions.SetRecording, AnimationTrackExtensions.SupportsRecording to get or change the recording state of an Animation track. Added two methods in TrackEditor to control how an object is bound to a track: IsBindingAssignableFrom and GetBindingFrom. Added Japanese translation. The Timeline window will automatically rebuild the graph when a notifications's properties are changed. The Timeline window will be automatically refreshed when a marker's properties are changed. Added TimelineEditor.GetInspectedTimeFromMasterTime and TimelineEditor.GetMasterTimeFromInspectedTime to convert time from master to inspected timeline and vice versa when using sub-timelines. Added API to improve how to get/set a TimelineClip's parent track: TimelineClip.GetParentTrack (replaces obsolete property getter) ItemsUtils.SetParentTrack (extension method thar replaces obsolete property setter) Added a new Seconds time display mode and renamed previous Seconds mode to Timecode. TimelinePreferences.timeFormat field, UnityEditor.Timeline.TimeFormat enum. Added API for the user to clip to the track area: API: Relevant member to MarkerOverlayRegion, API: MarkerOverlayRegion.trackRegion, API: MarkerOverlayRegion constructor. Added Gameplay sequence sample. This sample demonstrates how Timeline can be used to create a small in-game moment, using built-in tracks. Added Customization sample. This sample demonstrates how to create custom tracks, clips, markers and actions. Changed The binding field on a track header will change its background color when dragging a valid object on it. Timeline marker track is now selectable. TimelineClip property parentTrack is now obsolete. TimelinePreferences.timeUnitInFrames is now obsolete. Fixed Fixed a bug affecting the conversion between seconds and frames in the inspector. Fixed issue where KeyAllAnimated was available when right-clicking on markers and tracks that were not in record mode. (1270304) Fixed issue where the mouse cursor would stay stuck to a resize icon when resizing the track header. (1076031) Fixed case where an animation event at time 0 would not fire on a timeline loop. (1184106) Fixed issue where Timeline objects (ie. TrackAsset, ControlTrack, SignalAsset, etc.) would have incorrect links to the documentation pages. Available starting from Unity 2021.1. (1082941) Fixed multiple issues related to blends Fix display of blends when clips have ease-in/ease-out (1178066) Fix clip disappearing when dragging it from left to right completely inside another clip. Fix select and drag clip discarding foreground display rule of selected clip after releasing the drag. Fix fully blended clips selection not available. (1289912) Fixed issue where the clip display would flicker when moving two clips that are completely overlapped. (1085679) The Timeline window will no longer revert to editing only the asset if the user uses the Timeline selector to pick a game object and switches focus. (1291455) Create button on timeline panel no longer defaults to an invalid path. (1289923) Fixed issue where Timeline's bindings field would loses names and bindings when selecting clips. (1293941) Make Timeline's duration result displayed in the Inspector, when switching from duration mode: Based On Clips to Fixed Length, closer to the actual duration. (1156920) Copy/Paste of clips in the Timeline Window will no longer paste clips at an invalid time in mix-mode. (1289925) [1.4.5] - 2020-11-19 Fixed Fixed issue where changing a clip's extrapolation values would clear the current clip selection. (936046) Fixed multiple issues related to the curves view: Fixed curve removal not functioning with PlayableAssets (clips & tracks curves). (1231002) Fixed inconsistent icon display on curves. Fixed incorrect ordering of properties. Properties now have a object/type/property ordering. Fixed unnecessary grouping of fields. Changed context menu from Remove Properties to Remove Curves to better reflect the change in functionality between curves for GameObjects and curves for PlayableAssets. Fixed behaviour where removing a single field in a Position, Rotation or Scale group would remove the entire group. Fixed case where pausing in Playmode and switching the active director in editor could pause the director. (1263707) Material properties are now displayed by their shader name in the curves view when possible. (1115961) Fixed issue where a signal could be pasted on a track that doesn't support notifications. (1283763) Fixed issue where a clip could be paseted on an incompatible track. (1283763) Fixed errors when leaving prefab mode when a timeline is opened. (1280331) No preview will be shown when the PlayableDirector is disabled. (1286198) Fixed issue where an infinite clip's Foot Ik property was not visible in the Inspector when selecting its track. (1279824) Fixed issue where child particle systems were not controlled correctly when they are not subemitters. (1212943) Fixed inconsistent recording behaviour on audio tracks and PlayableAssets. Default values are changed when a value is not recorded, and the key added/updated when a value is already animated. (1283453) Fixed issue where the curves view for tracks and PlayableAssets would not update when changed externally (such as from the Animation window). Fixed Add Key/Remove Key context menus not being properly enabled in some cases when using tracks and PlayableAssets. Fixed simulation of subemitters when scrubbing a timeline. (1142781) Fixed choppy playback of particles with a large fixed time step. (1262234) [1.4.4] - 2020-10-09 Fixed Disable drag and drop of Signal asset on Control Track. (1222760) Fixed system locale causing issues when keying float values on custom clips. (1190877) Fixed issue where recording to a clip would place keys on the frame. (1274892) Fixed keyboard clip selection from locked tracks. (1233612) Fixed issue where the Timeline window would stay locked even when no timeline asset is shown. (1278598) Fixed issue where invoking SelectLeft or SelectRight shortcuts on a group track, the group would not collapse or expand. (1279379) Fixed Blend Curve Editor from the clip's inspector that was not responding correctly to undo and redo commands. (978673) Fixed issue where the Frame All action would not frame keys outside of clips when the curve display is collapsed. (1273725, #295) Scrolling the horizontal scrollbar of the timeline to the right edge will no longer prevent the user from dragging left again. (1127199, #301) Splitting a clip with an ease in or out value now ensures ease duration stays on correct side of split. (1279350) Fixed delay when zooming in after reaching Timeline window's maximum and then zooming back. (1214228) Prevent creation of presets with Group Tracks. (1281056) Fixed issue where markers placed on top of clips could not be selected. (1284807, #314) Fixed issue where multiple markers placed on top of each other could not be selected. (1284801, #314) [1.4.3] - 2020-08-26 Fixed Fixed incorrect selection when clicking on a clip's blend. (1178052) Fixed issue where an exception was thrown when drawing an Audio clip's waveform when that clip wasn't in the AssetDatabase. (1268868) When choosing Add Signal Emitter from Signal Asset, closing the Object Selector window will not add an empty Signal Emitter. (1261553) Fixed issue where an error would appear when editing keys in the Animation window if the Timeline window is opened. (1269829) Fixed issue where the Frame All operation would continually increase the zoom value when only empty tracks are added to the timeline (1273540). [1.4.2] - 2020-08-04 Fixed Fixed double-click not opening the AnimationWindow on clips with animated parameters. (1262950) Fixed issue where the Timeline window would rebuild its Playable Graph every time an AnimationClip would be added, changed or deserialized. (1265314, 1267055) [1.4.1] - 2020-07-15 Fixed Fixed IndexOutOfRangeException exception being thrown when editing inspector curves. (1259902) Fixed IndexOutOfRangeException exception being thrown when the New Signal dialog replaces an existing signal. (1241170) Fixed signal state being reset on paused timelines. (1257208) Fixed nested custom types not updating animation values in the inspector. (1239893) Fixed AnimationTracks SceneOffset mode incorrectly overriding root transform on tracks without root transform in editor. (1237704) The DisplayName attribute is now supported when used with TrackAssets. (1253397) Fixed NullReference exception being thrown when clicking on the Scene Preview checkbox if the Timeline window was closed. (1261543) [1.4.0] - 2020-06-26 Added Added ClipCaps.AutoScale to automatically change the speed multiplier value when the clip is trimmed in the Timeline window. Added a DeleteClip method in TrackAsset. Added dependency on Animation, Audio, Director and Particle System modules. (1229825) Added an option in TimelineAsset.EditorSettings to disable scene preview. Added base classes to define custom actions: TimelineAction TrackAction ClipAction MarkerAction Added the following attributes that can be used with action classes: ApplyDefaultUndo to automatically manage undo operations. ActiveInMode to control in which Timeline mode the action is valid. MenuEntry to add the action to the context menu. TimelineShortcut can be added to a static method to invoke the action with a shortcut. Invoker to invoke actions using Timeline's selection or context. MenuOrder contains menu priority values, to be used with MenuEntry. TimelineModes to specify in which mode an action is valid, to be used with MenuEntry. ActionContext to provide a context to invoke TimelineActions. ActionValidity to specify is an action is valid for a given context. UndoExtension to manage undo operations with common Timeline types. Changed Improved performance with ControlTracks in preview mode for cases where multiple Control Tracks are assigned to the same PlayableDirector. Improved layout and appearance of track header buttons. Reduced icons' file size without any quality loss. A track's binding will be duplicated when pasting or duplicating a track. When creating a new timeline asset, the \"Timeline\" suffix will not be added to the file name twice. ClipCaps.All now includes the new Autoscale feature. To get the previous ClipCaps.All behaviour on clips, use ClipCaps.Looping | ClipCaps.Extrapolation | ClipCaps.ClipIn | ClipCaps.SpeedMultiplier | ClipCaps.Blending Inline curve selection is now synced with the clip's selection. Selecting a curve view property will also select the corresponding curve view. Clicking and holding the Command or Control key on a curve view will deselect it if it was already selected. Improved Timeline window UI performance. Fixed Selecting clips from locked tracks is not allowed anymore when using the playhead's context menu. Inserting gaps in locked tracks is not allowed anymore. When adding an Activation track, the viewport is adjusted to show the new Activation clip. Fixed issue where trimming AnimationClips would also change the speed multiplier. [1.3.4] - 2020-06-09 Fixed Fix a Control Track bug that caused the first frame of an animation to evaluated incorrectly when scrubbing forwards and backwards. (1253485) Fixed memory leak where the most recently played timeline would not get unloaded. (1214752 and 1253974) [1.3.3] - 2020-05-29 Fixed Fixed regression where animation tracks were writing root motion when the animation clip did not contain root transform values (1249355) [1.3.2] - 2020-04-02 Fixed Fixed issue where the clip Inspector's curve preview would close when clicking on the curve. (1228127) Fixed issue where the curves view was not synced between Animation and Timeline windows. (1213937) Fixed issue where play range didn't loop when range ends on the final frame. (1215926) Fixed issue where displaying an array in the curves view generated errors. (1178251) [1.3.1] - 2020-03-13 Fixed Fixed issue where the curves view would flicker when editing multiple keys. (1217326) Fixed issue where adding a keyframe in the curves view at the end of a clip would not place the keyframe at the correct position. (1221337) [1.3.0] - 2020-02-26 Added Inline Curve Properties can be removed. Tracks can be individually resized. Changed Creating a new Timeline will no longer automatically add an Animation Track and an Animator to the target GameObject. Ease-in and ease-out values for clips are no longer restricted to 50% of the clip's duration. The resize handle for inline curves has been moved to the track header area. Reduced the minimum width of the track header area. Trimming the left edge of a clip while pressing the Shift key will change the Speed Multiplier value. Fixed Fixed humanoid characters going to default pose during initial root motion recording. (1174752) Fixed Override Tracks not masking RootTransform when an AvatarMask without the Root Node is applied. (1190600) Fixed preview of Avatar Masks on base level Animation Tracks. (1190600) [1.2.13] - 2020-02-24 Fixed Fixed Performance issue where Control Tracks would resimulate during the tail of a non-looping particle clip. (1216702) Fixed adjacent recording clips highlighting the wrong clip. (1210312) Fixed timescale drawing to only draw visible lines which avoids a hang with very large clips. (1213189) Fixed SignalReceiver.ChangeSignalAtIndex incorrectly throwing exception when multiple entries are set to null. (1210877) Fixed a memory leak with Animation Clips in Edit mode. Fixed issue where changes to a Signal Receiver component in a prefab were reverted. (1210883) Fixed avatar mask reassignment not causing immediate re-evaluation. (1219326) Fixed issues related to recursive control tracks. (1178423) Fixed issue where using the HideInMenu attribute in combination with a class inheriting from Marker would not hide the marker from the Timeline context menus. (1221054) [1.2.12] - 2020-02-21 Fixed Fixed issue where the curves view would change its framing when moving a clip. (1217353) [1.2.11] - 2020-01-22 Fixed Fixed Control Track inspector dropdown not opening. (1208943) Fixed issue where applying the Match content command on subtimeline clip with a newly created subtimeline with no duration makes the clip disappear. (1203662) Fixed issue where the opened timeline is changed to another timeline when switching focus from Unity to a different application. (1087348) Fixed issue where the keys in the inline curves view were incorrectly positioned (1205835) Changed ControlPlayableAsset.searchHierarchy (a.k.a. Control Children) now defaults to false. [1.2.10] - 2019-12-08 Fixed Fixed issue where object selectors on tracks did not show bound objects. (1202853) Fixing inspector blend graph display for animation clips. (1201474) Fixed Timeline Window lock state when restarting Unity and no timeline are selected. (1201405) [1.2.9] - 2019-12-06 Fixed Added missing high-resolution icons for Personal Skin. [1.2.8] - 2019-11-21 Fixed Fixed issue where recording couldn't be turned on for override tracks. (1199389) Fixed overlay bug when panning. (1198348) Fixed Foot IK being applied in Editor when option is disabled. (1197426) Fixed issue where the Animation Track's inline curves were not properly aligned when panning the timeline. (1198364) [1.2.7] - 2019-11-15 Fixed Fixed inline curves to display PlayableBehaviour array properties. (1178251) Fixed clip selection from playhead. (1187495) Fixed recorded clips dirtying the scene on copy/paste. (1181492) [1.2.6] - 2019-10-25 Added Added Timeline manual. [1.2.5] - 2019-10-16 Changed Added tooltips that were missing for Timeline selector and settings buttons. (1152790) Removed Undo menu entry that was added when clicking on the Inline curves button. (1187402) Fixed Fixed issue where recording couldn't be turned off when an object is deactivated. (1187174) Timelines listed in the Timeline selector will now be sorted alphabetically. (1190514) Fixed Insert Frames options from Trackhead context menu not applying to markers. (1187895) Fixed incorrect display when a large number of nested group tracks was added to a Timeline. (1157367) [1.2.4] - 2019-10-03 Changed Properties in the Inline Curve editor will now be listed in the same order as the Animation window. (1184058) Updated the appearance of the Timeline window to conform to the editor's UX redesign Improved the appearance of clip blends. Fixed Adding a PlayableDirector with no Playable Asset will no longer trigger a repaint of the Timeline Window on each frame. (1172707) Fixed issue where a clip's blend selection border was not drawn correctly when there was a previous clip. (1178173) Fixed issue where Animation Events were fired twice when the Playable Director Wrap mode is set to Loop. (1173281) Fixed issue where double-clicking on a Timeline Asset would not open it in the Timeline window. (1182159) Fixed issue where the paste shortcut would not work when copying and pasting between two different timelines. (1184967) Fixed audio stutter when going into playmode. (1167289) Fixed PreviousFrame and NextFrame controls in subtimelines with large offsets. (1175320) Fixed issue where exceptions were thrown when resetting a Signal Receiver component. (1158227) Increased font size of clip labels (1179642) [1.2.3] - 2019-10-03 Fixed Removed unnecessary directories from the package. [1.2.2] - 2019-08-20 Fixed Fixed issue where fields for custom clips were not responding to Add Key commands. (1174416) Fixed issue where a different track's bound GameObject is highlighted when clicking a track's bound GameObject box. (1141836) Fixed issue where a clip locks to the playhead's position when moving it. (1157280) [1.2.1] - 2019-08-01 Fixed Fixed appearance of a selected clip's border. Fixed non-transform properties from AnimationClips not being correctly put into preview mode when the avatar root does not contain the animator component. (1162334) Fixed an issue where the context menu for inline curves keys would not open on MacOS. (1158584) Fixed recording state being incorrect after toggling preview mode (1146551) Fixed copying clips without ExposedReferences causing the scene to dirty (1144469) [1.2.0] - 2019-07-16 Compatible with Unity 2019.3 Added Added ILayerable interface. Implementing this interface on a custom track will enable support for multiple layers, similar to the AnimationTracks override tracks. Added \"Pan\" autoscrolling option in the Timeline window. Enabled rectangle tool for inline curves. Changed Scrolling horizontally with the mouse wheel or trackpad now pans the timeline view horizontally, instead of zooming. Scrolling vertically with the mouse wheel or trackpad on the track headers or on the vertical scroll bar now pans the timeline view vertically, instead of zooming. Fixed Fixed an issue causing info text to overlap when displaying multiple lines (1150863). Fixed duration mode not reverting from \"Fixed Length\" to \"Based On Clips\" properly. (1154034) Fixed playrange markers being drawn over horizontal scrollbar (1156023) Fixed an issue where a hotkey does not autofit all when Marker is present (1158704) Fixed an issue where an exception was thrown when overwriting a Signal Asset through the Signal Emitter inspector. (1152202) Fixed Control Tracks not updating instances when source prefab change. (case 1158592) An exception will be thrown when calling TrackAsset.CreateMarker() with a marker that implements INotification if the track does not support notifications. (1150248) Fixed preview mode being reenabled when warnings change on tracks. (case 1151381) Fixed minimum clip duration to be frame aligned. (case 1156602) Fixed playhead being moved when applying undo while recording.(case 1154802) Fixed warnings about localEulerAnglesRaw when using RectTransform. (case 1151100) Fixed precision error on the duration of infinite tracks. (case 1156723) Fixed issue where two GatherProperties call were made when switching between two PlayableDirectors. (1159036) Fixed issue where inspectors for clips, tracks and markers would get incorrectly displayed when no Timeline Window is opened. (1158242, 1158283) Fixed issue with clip connectors that were incorrectly drawn when the timeline was panned or zoomed. (1141960) Fixed issue where evaluating a Playable Graph inside a Notification Receiver would cause an infinite recursion. (1149930) Fixed Trim and Move operations to ensure playable duration is updated upon completion. (1151894) Fixed options menu icon that was blurry on high-dpi screens. (1154623) Track binding field is now larger. (1153446) Fixed issue where an empty Timeline window would create new objects on each repaint. (1142894) Fixed an issue causing info text to overlap when displaying multiple lines (when trimming + time scaling, for example). (1150863) Fixed duration mode not reverting from \"Fixed Length\" to \"Based On Clips\" properly. (1154034) Prevented the PlayableGraph from being created twice when playing a timeline in play mode with the Timeline window opened. (1147247) Fixed issue where an exception was thrown when clicking on a SignalEmitter with the Timeline window in asset mode. (1146261) A timeline will now be played correctly when building a player with Mono and Managed Stripping Level set higher than Low. (1133182) The Signal Asset creation dialog will no longer throw exceptions when canceled on macOS. (1141959) Fixed issue where the Emit Signal property on a Signal Emitter would not get saved correctly. (1148709) Fixed issue where a Signal Emitter placed at the start of a timeline would be fired twice. (1149653) Fixed record button state not updating when offset modes are changed. (1142747) Cleared invalid assets from the Timeline Clipboard when going into or out of PlayMode. (1144473) Copying a Control Clip during play mode no longer throws exceptions. (1141581) Going to Play Mode while inspecting a Track Asset will no longer throw exceptions. (1141958) Resizing Timeline's window no longer affects the zoom value. (1147150) Snap relaxing now responds to Command on Mac, instead of Control. (1149144) Clips will no longer randomly disappear when showing or hiding inline curves. (1141661) The global/local time referential button will no longer be shown for a top-level timeline. (1080872) Playhead will not be drawn above the bottom scrollbar anymore. (1134016) Fixed moving a marker on an Infinite Track will keep the track in infinite mode (1141190) Fixed zooming in/out will keep the padding at the beginning of the timeline (1030689) Fixed marker UI is the same color and size on infinite track (1139370) Fixed Disable the possibility to add Markers to tracks of a Timeline that is ReadOnly (1134463) Fixed wrong context menu being shown when right-clicking a marker (1133592) Fixed creation of override track to work with multiselection (1133592) [1.1.0] - 2019-02-14 Compatible with Unity 2019.2 Added ClipEditor, TrackEditor and MarkerEditor classes users can derive from to control visual appearance of custom timeline clips, tracks and markers using the CustomTimelineEditor attribute. ClipEditor.GetSubTimelines to allow user created clips that support sub-timelines in editor TimelineEditor.selectedClip and TimelineEditor.selectedClips to set and retrieve the currently selected timeline clips IPropertyCollector.AddFromName override that takes a component. Warning icons to SignalEmitters when they do not reference an asset Ability to mute/unmute a Group Track. Mute/Unmute only selected track command added for tracks with multiple layers. Animate-able Properties on Tracks and Clips can now be edited through inline curves. Added loop override on AnimationTrack clips (1140766) ReadOnly/Source Control Lock support for Timeline Scene Changed Control Track display to show a particle system icon when particle systems are being controlled Animate-able Properties for clips are no longer edited using by \"recording\"; they are edited through the inline curves just like tracks. AudioTrack properties can now be animated through inline curves. Changed Marker show/hide to be undoable. Hide will also unselect markers. (1124661) Changed SignalReceivers show their enabled state in the inspector. (1131163) Changed Track Context Menu to show \"Add Signal Emitter\" at the top of the list of Marker commands. (1131166) Moved \"Add Signal Emitter\" and \"Add Signal Emitter From Asset\" commands out of their sub-menu. (1131166) Fixed Fixed markers being drawn outside their pane. (1124381) Fixed non-public tracks not being recognized by the Timeline Editor. (1122803) Fixed keyboard shortcuts for Frame All (default: A) and Frame Selected (default: F) to also apply horizontally (1126623) Fixed recording getting disabled when selecting a different GameObject while the Timeline Window is not locked. (1123119) Fixed time sync between Animation and Timeline windows when clips have non-default timescale or clip-in values. (930909) Fixed animation window link not releasing when deleting the timeline asset. (1127425) Fixed an exception being raised when selecting both a Track marker and a Timeline marker at the same time. (1113006) Fixed the header marker area will so it no longer opens its context menu if it's hidden. (1124351) Fixed Signal emitters to show the Signals list when created on override tracks. (1102913) Fixed a crash on IL2CPP platforms when the VideoPlayer component is not used. (1129572) Fixed Timeline Duration changes in editor not being undoable. (1109279) Fixed Match Offsets commands causing improper animation defaults to be applied. (911678) Fixed Timeline Inspectors leaving EditorGUI.showMixedValue in the wrong state. (1123895) Fixed issue where performing undo after moving items on multiple tracks would not undo some items. (1131071) Fixed cog icon in the Signal Receiver inspector being blurry. (1130320) Fixed Timeline marker track hamburger icon not being centered vertically. (1131112) Fixed detection of signal receivers when track is in a group. (1131811) Fixed exception being thrown when deleting Signal entries. (1131065) Fixed Markers blocking against Clips when moving both Clips and Markers in Ripple mode. (1102594) Fixed NullReferenceException being thrown when muting an empty marker track. (1131106) Fixed SignalEmitter Inspector losing the Receiver UI when it is locked and another object is selected. (1116041) Fixed Marker and Clip appearing to be allowed to move to another track in Ripple mode. (1131123) Fixed issue where the Signal Emitter inspector did not show the Signal Receiver UI when placed on the timeline marker track. (1131811) Fixed Replace mode not drawing clips when moved together with a Marker. (1132605) Fixed inline curves to retain their state when performing undo/redo or keying from the inspector. (1125443) Fixed an issue preventing Timeline from entering preview mode when an Audio Track is present an a full assembly reload is performed. (1132243) Fixed an issue where the Marker context menu would show a superfluous line at the bottom. (1132662) Fixed an issue preventing Timeline asset to be removed from a locked Timeline Window when a new scene is loaded. (1135073) Fixed EaseIn/Out shortcut for clips [1.0.0] - 2019-01-28 Compatible with Unity 2019.1 Added This is the first release of Timeline, as a Package Added API calls to access all AnimationClips used by Timeline. Added support in the runtime API to Animate Properties used by template-style PlayableBehaviours used as Mixers. Added Markers. Markers are abstract types that represent a single point in time. Added Signal Emitters and Signal Assets. Signal Emitters are markers that send a notification, indicated by a SignalAsset, to a GameObject indicating an event has occurred during playback of the Timeline. Added Signal Receiver Components. Signal Receivers are MonoBehaviour that listen for Signals from Timeline and respond by invoking UnityEvents. Added Signal Tracks. Signal Tracks are Timeline Tracks that are used only for Signal Emitters. Fixed Signal Receiver will no longer throw exceptions when its inspector is locked (1114526) Context menu operations will now be applied on all selected tracks (1089820) Clip edit mode clutch keys will not get stuck when holding multiple keys at the same time (1097216) Marker inspector will be disabled when the marker is collapsed (1102860) Clip inspector will no longer throw exceptions when changing values when the inspector is locked (1115984) Fixed appearance of muted tracks (1018643) Fixed multiple issues where clips and markers were selectable when located under the time ruler and the marker header track (1117925, 1102598) A marker aligned with the edge of a clip is now easier to select (1102591) Changed behaviour of the Timeline Window to apply modifications immediately during Playmode (922846, 1111908) PlayableDirector.played event is now called after entering or exiting Playmode (1088918) Undoing a paste track operation in a group will no longer corrupt the timeline (1116052) The correct context menu will now be displayed on the marker header track (1120857) Fixed an issue where a circular reference warning appeared in the Control Clip inspector even if there was no circular reference (1116520) Fixed preview mode when animation clips with root curves are used (case 1116297, case 1116007) Added option to disable foot IK on animation playable assets (case 1115652) Fixed unevaluated animation tracks causing default pose (case 1109118) Fixed drawing of Group Tracks when header is off-screen (case 876340) Fixed drag and drop of objects inside a group being inserted outside (case 1011381, case 1014774)"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Unity's Timeline Install Timeline Timeline Samples Customization Samples Gameplay Sequence Demo Timeline Workflows Create a Timeline asset and Timeline instance Record basic animation Convert an Infinite clip to an Animation clip Animate a humanoid Override upper-body animation Create a Sub-Timeline instance Use markers and signals for footsteps Create a custom Notes marker Timeline assets and instances Timeline window Timeline Preview Timeline Playback Controls Timeline Selector Timeline Options Track List Track Header Add tracks Select tracks Duplicate tracks Reorder tracks and Animation Priority Group Tracks Delete Tracks Lock and Mute Tracks Content view and Edit modes Pan and Zoom the Content view Add clips Insert clips Select clips Position clips Tile clips Duplicate clips Trim clips Split clips Reset clips Change clip play speed Set Gap Extrapolation Ease-in and ease-out clips Blend clips Match clip offsets Curves View Use the Curves View Manipulate keyframes Tangent modes and types Timeline properties in the Inspector window Timeline asset properties Track properties Activation track properties Animation track properties Audio track properties Clip properties Activation clip properties Animation clip properties Audio clip properties Control clip properties Timeline Preferences Playable Director Component Timeline Glossary"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-add.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-add.html",
    "title": "Add clips | Inventory System",
    "summary": "Add clips The Timeline window supports different methods of adding clips to tracks, depending on the type of track, where you click, where you drag, and whether a clip or track is already selected. The quickest method to add a clip is to right-click on an empty area within a track and choose the appropriate Add option from the context menu. Depending on the track, the options for adding a clip change. Context menu for adding an Activation clip. There are other ways to add clips: Select a clip option from the More (⋮) menu in the Track Header to add a clip at the location of the Timeline Playhead. Drag an animation source asset from the Project window to an empty area in the Timeline window to automatically create an Animation track and add an Animation clip. Drag an animation source asset from the Project window to an existing track in the Timeline window to add an Animation clip to the same track. Drag an audio source asset from the Project window to an empty area in the Timeline window to automatically create an Audio track and add an Audio clip. Drag a GameObject with a PlayableDirector component to create a Sub-Timeline instance. This automatically creates a Control track and adds a Control clip for the Sub-Timeline instance. Drag a Prefab from the Project window to an empty area in the Timeline window to add a Prefab instance to your Timeline instance. This automatically creates a Control track and adds a Control clip for the Prefab instance. Drag a GameObject with a Particle component to add a particle effect to your Timeline instance. This automatically creates a Control track and adds a Control clip for the duration of the Particle effect. When you add a clip, the selected Edit mode determines how the added clip interacts with surrounding and intersecting clips. For example, if you add an Animation clip at the location of the Timeline Playhead, the added clip could blend, ripple, or replace clips on the same track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-blend.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-blend.html",
    "title": "Blend clips | Inventory System",
    "summary": "Blend clips Blend two clips on the same track to create a smooth transition between two Animation clips, two Audio clips, or two Playable clips. To blend two clips, select the Mix Edit mode and position or trim one clip until it overlaps an adjacent clip. (A) The Mix Edit mode. (B) The blend area displays the transition between the outgoing clip and incoming clip. In a blend, the first clip is referred to as the outgoing clip and the second clip is referred to as the incoming clip. The area where the outgoing clip transitions to the incoming clip is referred to as the blend area. The blend area sets the duration of the transition. Although the Content view represents a blend area as a single linear curve, the transition between clips is actually comprised of two blend curves. The blend curve for the outgoing clip is referred to as the Blend Out curve. The blend curve for the incoming clip is referred to as the Blend In curve. By default, each blend curve is automatically set to an ease-in and ease-out curve. In the Inspector window, the label for the Ease In Duration or Ease Out Duration property changes to Blend In Duration or Blend Out Duration if either affects a blend. The blend duration properties cannot be edited when labelled Blend In Duration or Blend Out Duration because the duration of the blend area is only editable in the Content view. (A) The Ease Out Duration property changes to Blend Out Duration because there is a blend between this clip and the next clip. (B) Use Blend Curves to customize the transition between clips. Use the Blend Curves in the Inspector window to change the shape for either the Blend In curve, labelled In, or Blend Out curve, labelled Out. The Inspector window only lets you edit the properties of one clip at a time. You cannot simultaneously customize both blend curves used in the same blend area. To customize either the Blend Out curve or Blend In curve, use the drop-down menu to switch from Auto to Manual. With Manual selected, the Inspector window displays a preview of the blend curve. Click the Curve Preview to open the Curve Editor in the Inspector window. (A) Curve Preview. (B) Click the Curve Editor header to expand or minimize the Curve Editor. (C) Use the Curve Editor menu to minimize, maximize, or open the Curve Editor in its own Preview window. Use the Curve Editor to customize the shape of the blend curve. By default, the blend curve includes a keyframe at the beginning of the curve and a keyframe at the end of the curve. The Curve Editor provides the following different methods of modifying the blend curve: Select a shape template from the bottom of the Curve Editor. The available shape templates differ depending on whether you are modifying the Blend In curve or the Blend Out curve. Double-click a location on the blend curve to add a new keyframe. Select a keyframe and use its tangent handles to adjust the interpolation between keyframes."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-duplicate.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-duplicate.html",
    "title": "Duplicate clips | Inventory System",
    "summary": "Duplicate clips There are many ways to duplicate clips in the Content view: Select a clip or multiple clips. Right-click in the Content view and choose Duplicate from the context menu. Select a clip or multiple clips. Hold Control (MacOS: Command) and press D. Right-click an unselected clip and choose Duplicate from the context menu. Duplicating clips copies each selected clip and places the duplicates after the last clip on the same track. If you duplicate clips used in a blend or clips separated by a gap, the blend or gap is also duplicated. If you duplicate an Animation clip that uses a recorded clip as its source asset, the recorded clip is also duplicated. This duplicate only appears in your Project window after you save the Scene or Project. For example, the following images demonstrates what happens if you duplicate an Animation clip named Clip 2B that uses the recorded clip named Recorded (3). Select the Clip 2B, hold Control (MacOS: Command) and press D to duplicate A duplicate Animation clip is placed at the end of the same track. The recorded clip associated with Clip 2B is also duplicated. The new Recorded (6) recorded clip appears in the Project window after you save the Scene or Project"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-ease.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-ease.html",
    "title": "Ease-in and ease-out clips | Inventory System",
    "summary": "Ease-in and ease-out clips Ease-in and ease-out a clip to create a smooth transition between a clip and its surrounding gaps. To create an ease-in or ease-out transition, select a clip and, in the Inspector window, set either the Ease In Duration or the Ease Out Duration. Use Ease In Duration and Ease Out Duration to smoothly transition into and out of the selected clip. Ease-in and ease-out transitions create different effects, depending on the track: On an Animation track or an Animation Override track, ease-in to an Animation clip to create a smooth transition between the animation in the gap before the clip and the Animation clip. Ease-out of an Animation clip to create a smooth transition between the Animation clip and the animation in the gap after the clip. To understand which animation occurs in the gap before or after an Animation clip, consult Setting gap extrapolation. On an Audio track, ease-in to an Audio clip to fade in the volume of the audio waveform. Ease-out of an Audio clip to fade out the volume of the audio waveform specified by the Audio clip. On a Playable track, ease-in to a Playable clip to fade in its custom asset. Ease-out of a Playable clip to fade out its custom asset. Ease-in and ease-out an Animation clip to transition between its animation and its gaps Although the Content view represents each ease-in or ease-out transition as a linear curve, every transition is actually set to a gradual ease-in or ease-out curve by default. To change the shape of either the ease-in curve (labelled In) or the ease-out curve (labelled Out), use the Blend Curves in the Inspector window. Use the Blend Curves to customize ease-in or ease-out transitions To customize either the ease-in or ease-out transition, use the drop-down menu to switch from Auto to Manual. With Manual selected, the Inspector window displays a preview of the blend curve. Click the curve preview to open the Curve Editor below the Inspector window. Select Manual and click the preview to open the Curve Editor The Curve Editor is the same editor that is used to customize the shape of the blend curves when blending between clips. Note that the Blend Curves could affect the blend area used for blending between two clips. The label for the Ease In Duration or Ease Out Duration properties changes to Blend In Duration or Blend Out Duration if either effects a blend. In addition, the blend duration properties cannot be edited when they are labelled Blend In Duration or Blend Out Duration because the duration of the blend area is only editable in the Clips area. When creating an ease-in or an ease-out transition with Animation clips, the Animation clip blends between its gaps and the Animation clip. The following factors affect the values of animated properties in the gaps surrounding an Animation clip: The pre-extrapolate and post-extrapolate settings for the Animation clip and for other Animation clips on the same track. Animation clips on other Animation tracks that are bound to the same GameObject. The position or animation of the GameObject in the Scene, outside the Timeline asset."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-gap-extrap.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-gap-extrap.html",
    "title": "Set gap extrapolation | Inventory System",
    "summary": "Set gap extrapolation Gap extrapolation refers to how an Animation track approximates animation data in the gaps before and after an Animation clip. The main purpose for extrapolating animation data in the gaps between Animation clips is to avoid animation anomalies. Depending on the GameObject bound to the Animation track, these anomalies could be a GameObject jumping between two transformations, or a humanoid jumping between different poses. Each Animation clip has two gap extrapolation properties: Pre-Extrapolate, which controls how animation data is approximated in the gap before an Animation clip. Post-Extrapolate, which controls how animation data extends in the gap after an Animation clip. By default, Timeline sets both extrapolation properties to Hold. This sets the gap before the Animation clip to the animation on the first frame, and the gap after the Animation clip to the animation on the last frame. Each gap holds the animation at a certain frame. Icons before and after an Animation clip indicate the selected extrapolation modes. Icons indicate the pre-extrapolate and post-extrapolate modes When an Animation track contains a gap between two Animation clips, the Post-Extrapolate property of the left clip sets the gap extrapolation by default. If the Post-Extrapolate property of the clip to the left of a gap is set to None, the Pre-Extrapolate property of the right clip sets the gap extrapolation. Icons before and after Animation clips indicate whether the extrapolation for a gap is taken from the Post-Extrapolate property of the clip to the left or from the Pre-Extrapolate property of the clip to the right. (A) The gap extrapolation is taken from the the Post-Extrapolate property of the left clip. (B) The gap extrapolation is taken from the Pre-Extrapolate property of the right clip. To change the Pre-Extrapolate and Post-Extrapolate properties, select the Animation clip and use the Animation Extrapolation properties in the Inspector window. Use Pre-Extrapolate and Post-Extrapolate to set the extrapolation modes for the selected Animation clip The Pre-Extrapolate property is hidden when one of the following is true: The gap before the Animation clip is set by the Post-Extrapolation mode of the previous clip. There is no gap before the Animation clip. Use the Pre-Extrapolation property to set the gap extrapolation of the gap before the selected Animation clip. The following table describes each pre-extrapolation mode. Icon/Name Description None (no icon) Turns off pre-extrapolation. In the gap before the selected Animation clip, the GameObject uses its transform, pose, or state from the Scene. Select None if, for example, you want to create an ease-in between the motion of a GameObject in the Scene and an Animation clip. Consult Easing-in and Easing-out Clips. Hold (default) In the gap before the selected Animation clip, the GameObject bound to the Animation track uses the values assigned at the start of the Animation clip. Loop Turns off pre-extrapolation. In the gap before the selected Animation clip, the GameObject uses its transform, pose, or state from the Scene. Select None if, for example, you want to create an ease-in between the motion of a GameObject in the Scene and an Animation clip. Consult Easing-in and Easing-out Clips for details. Ping Pong In the gap before the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation forwards, then backwards. Use the Clip In property to offset the start of the loop. Changing the Clip In property affects the start of the loop when looping forward, and the end of the loop when looping backwards. Continue In the gap before the selected Animation clip, the GameObject bound to the Animation track either holds or loops the animation based on the settings of its source asset. For example, if the selected Animation clip uses the motion file Recorded(2) as its source asset and Recorded(2) is set to Loop, then selecting Continue loops the animation according to the Recorded(2) Loop Time settings. Use the Post-Extrapolate property to set the gap extrapolation of the gap after the selected Animation clip. The following table describes each post-extrapolation mode. Icon/Name Description None (no icon) Turns off post-extrapolation. In the gap after the selected Animation clip, the GameObject uses its transform, pose, or state from the Scene. Selecting None is useful if, for example, you want to create an ease-out between an Animation clip and the motion of a GameObject in the Scene. Consult Easing-in and Easing-out Clips for details. Hold (default) In the gap after the selected Animation clip, the GameObject bound to the Animation track uses the values assigned at the end of the Animation clip. Loop In the gap after the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation as a forward loop: from start to end. To offset the start of the loop, use the Clip In property.. Ping Pong In the gap after the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation forwards, then backwards. Use the Clip In property to offset the start of the loop. Changing the Clip In property affects the start of the loop when looping forward, and the end of the loop when looping backwards. Continue In the gap after the selected Animation clip, the GameObject bound to the Animation track either holds or loops the animation based on the settings of its source asset. For example, if the selected Animation clip uses the motion file Recorded(2) as its source asset and Recorded(2) is set to Loop, then selecting Continue loops the animation according to the Recorded(2) Loop Time settings."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-insert.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-insert.html",
    "title": "Insert clips | Inventory System",
    "summary": "Insert clips The Timeline window supports different methods of inserting clips depending on the type of track, where you click, and whether a clip or track is already selected. In the Timeline window, inserting clips refers to adding and making space for a clip without blending or replacing intersecting clips. To accurately insert a clip, select Ripple mode as the Edit mode, and position the Timeline Playhead to set the insertion point. Select Add From Animation Clip from the More (⋮) menu for the track where you want to insert the clip. Accurately insert a clip with the Ripple mode (A), the Timeline Playhead (B), and Add From Animation Clip in the More (⋮) menu (C) In the above example, the Timeline Playhead is the insertion point. You can specify the insertion point using these other methods: Right-click within a gap and add a clip with the context menu. The insertion point is where you right-click. Drag a source asset (animation or audio) to a track in the Content view. The insertion point is where you release dragging. The location of the insertion point determines where the clip is inserted and how it affects the other clips and gaps on the same track: If the insertion point intersects a clip, the inserted clip is added at the insertion point. The intersected clip, and all subsequent clips and gaps, are rippled after the inserted clip. If the insertion point is within a gap and there is enough space between the insertion point and the next clip, then the inserted clip is added to the gap. The other clips on the track are not affected. If the insertion point is within a gap and the inserted clip overlaps the next clip, the inserted clips is added at the insertion point. The next clip, and all subsequent clips and gaps, are rippled to accommodate the inserted clip. For example, inserting a clip at the Timeline Playhead, in the gap between Clip 1A and Clip 1B, ripples Clip 1B to accommodate the 72 frame Walk clip"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-match.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-match.html",
    "title": "Match clip offsets | Inventory System",
    "summary": "Match clip offsets Every Animation clip contains keyframe animation, or motion, that animates a GameObject, or character, bound to the Animation track. When you add an Animation clip to an Animation track, its animation or motion does not automatically begin where the previous clip ends. By default, each Animation clip begins at the position and rotation of the GameObject, or character, at the start of the Timeline instance. For example, three Animation clips create an animation sequence where a character walks (Walk), turns around and stops (TurnLeft), then walks to a jog (Wk-Jog). An animation sequence of three Animation clips: Walk, TurnLeft, Wk-Jog. When first added, each Animation clip starts at the position and rotation of the character at the start of the Timeline instance. The following illustration shows the end of each Animation clip. (A) The start of the Timeline instance. (B) The end of the Walk Animation clip. (C) The end of the TurnLeft Animation clip. (D) The end of the Wk-Jog Animation clip. For an animation sequence to flow seamlessly, the start position and rotation of each Animation clip must match the end position and rotation of the previous Animation clip. These position and rotation offsets are named Clip Transform Offsets and they can be set manually in the Inspector window or automatically. The following sections describe how to automatically set clip offsets by matching two or more Animation clips. Match two clips To match the clip offsets between two clips, right-click the Animation clip that you want to match. From the context menu, select either Match Offsets to Previous Clip or Match Offsets to Next Clip. Matching an Animation clip with the next clip For example, right-click the middle Animation clip, named TurnLeft, and choose Match Offsets To Next Clip to match its offsets to the next clip. This selects the clip, then matches the end of the middle clip with the start of next clip. The context menu only displays the match options available for the selected Animation clip. For example, if the first clip, Walk is selected, only the Match Offsets to Next Clip menu item is available. Match many clips To match the clip offsets of many clips, select the adjacent Animation clips that you want to match and right-click one of the selected clips. From the context menu, select either Match Offsets to Previous Clip or Match Offsets to Next Clip. Matching many clips with previous clips For example, select the TurnLeft and Wk-Jog clips. Right-click one of the selected clips and choose Match Offsets to Previous Clip. This matches the TurnLeft clip with the previous Walk clip and matches the Wk-Jog clip with the previous RunLeft clip."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-overview.html",
    "title": "Content view and Edit modes | Inventory System",
    "summary": "Content view and Edit modes Use the Content view to add, position, and manage the clips and markers on each track in the Timeline asset or Timeline instance. The selected Edit mode determines how clips and markers interact with each other when you add, position, trim, resize, or delete them. (A) Edit modes (B) Content view Clips and the Content view In the Content view, each clip has a colored accent line that identifies the type of clip: Activation clips are green. Animation clips are blue. Audio clips are orange. Control clips are turquoise. Playable clips are white. A clip with a source asset, such as an Animation clip or an Audio clip, displays arrows that indicate when the clip excludes part of its source animation, audio waveform, or other source content. For example, if an Animation clip uses only part of its full animation, white arrows indicate that keyframes exists before the start or after the end of the clip. Small arrows (red) indicate that data exists before the start or after the end of the area defined by the clip There are many ways to resize a clip and view its hidden source data: Drag the start or end of the clip to trim its start or end. Select the clip and modify its clip timing properties in the Inspector window. Right-click the clip and choose Match Content from the context menu. When you resize a clip, the selected Edit mode determines how the surrounding clips are affected. Clips and Edit modes Select an Edit mode to choose how clips are added, positioned, and trimmed in the Content view. The Edit mode is also used when you modify clip timing properties in the Inspector window. There are three Edit modes that affect most clip editing features. Edit modes are Mix mode (default and selected), Ripple mode, and Replace mode You can temporarily switch between Edit modes. This is useful if, for example, you want to temporarily use Ripple mode to offset the content of a track while you position clips. To temporarily switch between Edit modes, hold down the following keyboard keys: Hold down 1 to temporarily switch to Mix mode. Hold down 2 to temporarily switch to Ripple mode. Hold down 3 to temporarily switch to Replace mode. Mix mode Use Mix mode to add, position, and trim clips without moving or replacing adjacent clips. Mix mode creates blends between intersecting clips. Mix mode is the default Edit mode. Timeline window with Mix mode as the selected Edit mode. In Mix mode, when you hover over a clip in the Content view, the cursor changes to indicate the action that you can perform. The action depends on the part of the clip that you hover over: When you hover over the start of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the start of the clip. When you hover over the middle of a clip, the cursor changes to a position cursor. The position cursor indicates the area to drag to position the clip. When you hover over the end of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the end of the clip. In Mix mode, if you drag to trim or position a clip and it intersects another clip, the cursor changes to a white arrow that points towards the blend being created. There are three possible cursors depending on whether the blend is created at the beginning of the clip, at the end of the clip, or at both the beginning and end of the clip. The clip and the blend are also outlined in white. For example, the white arrow cursor and white outline indicates that dragging Clip 2A to the right creates a blend, at the end of the clip, between Clip 2A and Clip 2B. Ripple mode Use Ripple mode to add, position, and trim a clip while affecting the subsequent clips on the same track. Positioning or trimming clips in Ripple mode preserves the gaps between subsequent clips. Timeline window with Ripple mode as the selected Edit mode. In Ripple mode, when you hover over a clip in the Content view, the cursor changes to indicate the action that you can perform. The actions and areas are similar to Mix mode: When you hover over the start of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its start. When you hover over the middle of a clip, the cursor changes to a position cursor. The position cursor indicates the area to drag to position the clip. When you hover over the end of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its end. In Ripple mode, when you drag to trim or position a clip, the cursor switches to a yellow arrow that points towards the affected clips and gaps. A yellow line indicates the ripple point. When you drag to trim a clip, dragging left and right changes the duration of the selected clip and repositions subsequent clips and gaps after the ripple point. For example, the yellow arrow cursor indicates that dragging Clip 2A affects the clips and gaps to the right, after the ripple point. Replace mode Use Replace mode to add, position, and trim a clip while cutting or replacing intersecting clips. Timeline window with Replace mode as the selected Edit mode. In Replace mode, when you hover over a clip in the Content view, the cursor changes to indicate the action that you can perform. The actions and areas are similar to Mix mode: When you hover over the start of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its start. When you hover over the middle of a clip, the cursor changes to a position cursor. The position cursor indicates the area to drag to position the clip. When you hover over the end of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its end. In Replace mode, when you drag to position a clip, the clip becomes transparent so that you can view overlapping clips. If the clip being positioned overlaps other clips, releasing the clip cuts the underlying clip at each overlap. In Replace mode, when you drag to trim a clip and it intersects another clip, the cursor changes to a red arrow and a red replacement line indicates where clips overlap. Releasing the trim cuts the overlapping clip at the red replacement line."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-pan-zoom.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-pan-zoom.html",
    "title": "Pan and zoom the Content view | Inventory System",
    "summary": "Pan and zoom the Content view Use either the keyboard or the zoombar to pan and zoom the Content view. There are many ways to pan, zoom, or frame clips and markers in the Content view: To pan, either middle-click and drag, or hold Alt (MacOS: Option) and drag. To frame selected clips and markers, select clips then press F. To frame all clips and markers, press A. Or, press F with no clips or markers selected. To zoom horizontally, move the scroll-wheel. Or, press = to zoom-in and - to zoom-out. To zoom vertically, hold Control (MacOS: Command) and move the scroll-wheel. When you horizontally zoom the Content view, the zoombar indicates the level of zoom. The zoombar is the horizontal bar at the bottom of the Content view that zooms and pans the section of the Timeline instance or Timeline asset displayed in the Content view. The Timeline zoombar (A) Left zoombar handle (B) The zoombar thumb is the area between the two zoombar handles (C) Right zoombar handle (D) The white line indicates the location of the Timeline Playhead. Use this line to view the location of the Timeline Playhead relative to the zoom level and the part of the Timeline instance displayed in the Content view. The Timeline Playhead, and the white line, only appears for Timeline instances. There are many ways to pan and zoom with the Timeline zoombar: To pan, drag the zoombar thumb left or right. To jump to a section of the Timeline instance or Timeline asset, click an empty area of the scrollbar, on either side of the zoombar. To zoom-in or zoom-out, drag either zoombar handle. Dragging a zoombar handle also resizes the zoombar thumb."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-position.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-position.html",
    "title": "Position clips | Inventory System",
    "summary": "Position clips To position a clip, select Mix mode as the Edit mode. Select a clip and hover over it. When the cursor is a standard arrow cursor, click and drag the clip to its new position. While dragging, black lines indicate the selection of clips being positioned. The Timeline ruler displays the start time and end time of the selected clips being positioned. Select Mix mode (A). Select and drag to position a clip (B). By default, when you drag to position clips, both Snap to Frame and Edge Snap are enabled in the Content view. You can change these snap settings in the Timeline Options menu. You can also move a clip to another track of the same type. Drag the clip off of its current track and a white ghost indicates where the clip will be moved. If you drag a clip to an area where the clip cannot be placed, the ghost changes to red indicating that you cannot release the clip in that area. For example, you cannot drag a clip where there is no track. The ghost of the selection being moved is drawn in red if you attempt to move a clip to an invalid area You can position a selection of clips on the same track, or on different tracks. You are not limited to positioning one clip at a time. The same edge snapping rules and invalid area restrictions apply when positioning a selection of clips on many tracks. Position clips with the Inspector window Use the Inspector window to accurately position clips. To position a clip with the Inspector window, select a clip and use the Clip Timing properties to change its Start property. Clip Timing properties for an Animation clip The impact that changing the Start value has on adjacent clips depends on the selected Edit mode. Position clips in different Edit modes You are not restricted to positioning clips with Mix mode as the selected Edit mode. You can also position clips in Ripple mode and in Replace mode. The difference is the impact each Edit mode has on adjacent clips on the tracks where clips are being moved: Position clips in Mix mode to create blends between intersecting clips. Position clips in Ripple mode to ripple subsequent clips, respecting the gaps between clips. Position clips in Replace mode to cut or replace intersecting clips. Position clips with the Timeline Playhead You can position clips by inserting frames at the position of the Timeline Playhead. To do this, follow these steps: move the Timeline Playhead to where you want to insert frames. For example, to insert frames starting at frame 40, move the Timeline Playhead to frame 40 Right-click the Timeline Playhead on the Timeline ruler above the Content view, select Insert > Frame, and a number of frames. To insert 25 frames, right-click the Timeline Playhead and choose Insert > Frame > 25 Frames This inserts frames in the Timeline instance at the position of the Timeline Playhead. Inserting frames only repositions the clips that start after the position of the Timeline Playhead. In this example, inserting 25 frames at frame 40 affects Clip 1B, Clip 2B, and Clip 2C."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-reset.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-reset.html",
    "title": "Reset clips | Inventory System",
    "summary": "Reset clips You can reset the duration and speed of a clip. Resetting a clip does not reset the following properties: Start Ease In Duration and Ease Out Duration Animation Extrapolation settings Blend Curves To reset a clip, right-click the clip and choose Editing from the context menu. Then, select Reset Duration, Reset Speed, or Reset All. Depending on the reset option you select, resetting a clip does the following: Option: Description: Reset Duration Resets the Duration and the Clip In. Reset Speed Resets the Speed Multiplier. Reset All Resets the Duration, Clip In, and Speed Multiplier. If resetting a clip results in two clips overlapping each other, Timeline creates a blend for the overlap, regardless of the selected Edit mode."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-select.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-select.html",
    "title": "Select clips | Inventory System",
    "summary": "Select clips The Timeline window supports many different methods of selecting clips depending on where you click, where you drag, and whether a clip or track is already selected. The easiest method is to click a clip to select it. The Content view displays the selected clip with a white border, including its blends. Selecting a clip deselects all other tracks or clips. Selecting a clip also displays its properties in the Inspector window. The clip properties change depending on the type of clip and whether multiple clips are selected. Consult Setting Clip properties for details. Select many clips Hold Shift and click to select contiguous clips vertically on different tracks or horizontally on the same track. For example, to select three contiguous clips on the same track, select the first clip, then hold Shift and click the third clip. All three clips are selected. Click to select the first clip, 2A Shift-click the third clip, 2C, to select contiguous clips (2A, 2B, and 2C) on the same track Hold Control (MacOS: Command) and click to select discontiguous clips. Hold Control (MacOS: Command) and click a selected clip to deselect it. Select clips with a selection rectangle Click and drag on an empty area in the Content view to draw a selection rectangle. This selects all clips inside or that intersect the rectangle. Hold Shift and draw a selection rectangle to add clips to the current selection. Select clips with the Tab key You can also press the Tab key to select clips. The behavior of the Tab key changes depending on the current selection: If a track is selected, press Tab to select the first clip on the selected track. If many discontiguous tracks are selected, press Tab to select the first clip on the last selected track. If a clip is selected, press Tab to select its track. If there are no clips or tracks selected, press Tab to select the first clip on the first track. Select clips with arrow keys Use the arrow keys to change the selected clips. The behavior and results depend on the current selection and which modifier keys you press: If nothing is selected in the Timeline window, press the Tab, Up arrow, or Down arrow key to select the first clip on the first track. If a clip is selected, press the Left arrow key to select the previous clip. If the selected clip is the first clip on the track, the Left arrow key selects the track. If a clip is selected, press the Right arrow key to select the next clip. Press the Up arrow key to select the closest clip on the previous track. Press the Down arrow key to select the closest clip on the next track. Hold Shift and press either the Left arrow key or Right arrow key to add or remove clips from the selection of clips. Whether a clip is added to or removed from the selection of clips is relative to the first selected clip. This selection method only selects or unselects clips on the same track. When using arrow keys to change selected clips, the Content view pans to display the most recently selected clip if it outside the Content view. For example, if the selected clip is framed in the Content view and you press the Right arrow key to select the next clip that is outside the Content view, the Content view pans to display the start of the selected clip. Select clips with the Timeline Playhead You can also select clips with the Timeline Playhead. Right-click the Timeline Playhead and choose a selection option. This selects clips that either start after, start before, end after, end before, or intersect the Timeline Playhead. Clips are selected on all tracks. Right-click the Timeline Playhead and choose Select for more clip selection options"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-speed.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-speed.html",
    "title": "Change clip play speed | Inventory System",
    "summary": "Change clip play speed Change the clip play speed to accelerate or decelerate its audio, animation, or particle effect. Changing the clip play speed affects the duration of the clip. You can only change the play speed for Animation clips, Audio clips, and Control clips. To change the clip play speed, first, select the Edit mode to determine how other clips on the same track are affected: If the change in duration results in two clips that overlap each other: Select Mix mode to create a blend. Select Replace mode to cut or remove intersecting clips. Select Ripple mode to reposition the clips that start after the clip being sped up or slowed down. Ripple mode also preserves the gaps between clips. Select the clip and set the Speed Multiplier property in the Inspector window. The Speed Multiplier property displays the play speed as a multiplier of the original clip speed. Speed Multiplier in the Inspector window When the Speed Multiplier is set to 1, the clip plays at its original speed. To double the play speed, change the Speed Multiplier to 2. This changes the duration of the clip. For example, doubling the play speed of a 180 frame Animation clip changes its duration to 90 frames. A short-dashed line and multiplication factor of 2.00x indicates a clip playing at double its original speed There are other ways to change the play speed of a clip: Right-click the clip and choose Editing > Double Speed to halve the clip duration. The clip plays at twice its current speed. A short-dashed line and a multiplication factor indicates an accelerated clip. Doubling the clip speed sets the Speed Multiplier property to double its current value. Right-click the clip and choose Editing > Half Speed to double the clip duration. The clip plays at half its current speed. A long-dashed line and multiplication factor indicates a decelerated clip. Halving the clip speed sets the Speed Multiplier property to half its current value. Right-click the clip and choose Editing > Reset Speed to reset the clip to its original speed. This is the original duration of the clip. Resetting the clip speed sets the Speed Multiplier property to 1. Note: The clip play speed only recognizes positive values 0.001 and greater. You cannot set the clip play speed to a negative value. This does not, for example, play an Animation clip in reverse."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-split.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-split.html",
    "title": "Split clips | Inventory System",
    "summary": "Split clips You can split a clip into two identical clips that have different start points, end points, and durations. To split a clip: Select the clip. Position the playhead where you want to split the clip. Either right-click the clip and choose Editing > Split, or press S. Selected clips that intersect the playhead are split into separate clips. You can position, trim, and edit split clips independently. Select the clips to be split, position the playhead where you want the split to occur, and press S Selected clips are split where each clip intersects the playhead If a split clip is part of a blend, or if the split is performed within a blend, Timeline copies the blend settings to the split clips. If you split an Animation clip that uses a recorded clip as its source asset, the recorded clip is also copied. This copied recorded clip only appears in your Project window after you save the Scene or Project."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-tile.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-tile.html",
    "title": "Tile clips | Inventory System",
    "summary": "Tile clips Tile clips to remove gaps and blends between clips on the same track. Tiling clips is useful if you want each clip to begin exactly where the previous clip ends. If you select multiple clips on multiple tracks, you must select at least two clips on the same track for tiling to have an affect. To tile clips, select at least two clips on the same track. Three clips with gaps and blends are selected Right-click on one of the selected clips and choose Tile from the context menu. Timeline positions the selected clips based on the position of the first selected clip. The first selected clip does not move, and the duration of each clip remains the same. Tiling removes gaps and blends between the selected clips"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-trim.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/clip-trim.html",
    "title": "Trim clips | Inventory System",
    "summary": "Trim clips Trimming a clip cuts off a portion of the clip at its start or end. To trim a clip, select the Mix Edit mode, hover over the start or end of the clip until the trim cursor appears, then drag the trim cursor to modify the start or end of the clip. If you trim an Animation clip, an Audio clip, or a Control clip, this selects the portion of the source asset that the clip uses. For example, trim the start of an Animation clip to modify its start and offset. This selects the section of the source asset to use. Trim the end of an Animation clip to modify its duration. If an Animation clip's source asset is keyframe animation, use the Curves view to display the unused section of the source asset. (A) Curves view. (B) If the area defined by an Animation clip, Audio clip, or Control clip only uses part of its source asset, the clip displays a white arrow to indicate that unused content exists before the start or after the end of the clip. (C) The trimmed keyframe animation displays outside of the Animation clip. Trimming a clip is non-destructive. Trim the clip again to modify its start or end to include the animation, audio waveform, or other source content cut during a previous trim. You can also reset a clip to undo trims and other edits. Trim with the Inspector window You can select a clip to display its Clip properties in the Inspector window. Use the Start, End, Duration, and Clip In (offset) properties to modify a clip to exact values. Position and trim a clip by adjusting its Start, End, Duration, and Clip In properties in the Inspector window Trim with the Timeline Playhead You can trim a clip based on the location of the Timeline Playhead. To trim using the playhead, do the following: Position the playhead within the clip to be trimmed. Right-click the clip and choose either Editing > Trim Start or Editing > Trim End. Trim Start trims the start of the clip to the playhead. Trim End trims the end of the clip to the playhead. For example, move the Timeline Playhead within the clip Right-click the clip and choose Editing > Trim Start to trim the start of the clip to the playhead If you select clips on multiple tracks, Timeline only trims the selected clips that intersect the playhead. Trim to hold or loop clips If you trim the end of an Animation clip, Audio clip, or Control clip past the end of its source asset, the extra clip area either holds or loops its content. When the extra clip area loops, the entire source asset loops. Each full loop is labelled sequentially as L1, L2, L3, and so on. If the source asset is recorded keyframe animation, you can also view the looping animation curves in the Curves view. For example, an Animation clip named EndRotation is set to loop. Trimming the end of the EndRotation clip past the end of the Recorded(2) source asset loops its content. The EndRotation clip loops once, indicated by L1. Its animation curve loops and is drawn in white. Whether the extra clip area holds or loops depends on the Loop property in the Animation Clip Properties or the Audio Clip Properties. For Control clips, the properties that determine whether the extra clip area holds or loops depends on whether the clip controls a Sub-Timeline instance, Particle System, Prefab instance, or an ITimeControl Script. Special trim options for looping clips The Timeline window provides special trimming options for clips with loops. These special trim options either remove or complete the last partial loop. For example, an Animation clip is set to loop and its duration is just over twice longer than its source asset. This results in the Walk clip with one full loop and one partial loop. L1 indicates a complete loop. The clip ends in the middle of the second partial loop, L2. To extend the end of the clip and complete the partial loop, right-click the clip and choose Editing > Complete Last Loop. To trim the clip at the last complete loop, right-click the clip and choose Editing > Trim Last Loop. The result of Complete Last Loop The result of Trim Last Loop"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-keyframes.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-keyframes.html",
    "title": "Manage keyframes | Inventory System",
    "summary": "Manage keyframes This topic summarizes how to use the Curves view to add, select, step between, edit, and delete keyframes on an animation curve. The functionality described in this topic is similar to manipulating keyframes in Curves mode in the Animation window. Add keyframes The Curves view provides the following ways to add keyframes: Right-click on an animation curve and choose Add Key. This method adds a keyframe at the location of the right-click. Double-click on an animation curve. This method adds a keyframe at the location of the Double-click. Select keyframes Click to select a single keyframe. Selecting a keyframe deselects all other selected keyframes. When you select a keyframe, the Curves view displays the keyframe with its tangents. Each keyframe has either one or two tangents that you can use to change the shape of the animation curve. For more information, consult Tangent modes and types. To select contiguous keyframes along the same animation curve, click the first keyframe, then hold Shift and click the last keyframe. Click to select a single keyframe. A selected keyframe displays its tangents. Hold Shift and click a keyframe to select contiguous keyframes There are others ways to select and deselect keyframes: Hold Control (MacOS: Command) and click to select discontiguous keyframes. Hold Control (MacOS: Command) and click a selected keyframe to deselect it. Click and drag on an empty area in the Curves view to draw a selection rectangle. This selects all keyframes within the rectangle. Hold Shift while drawing a selection rectangle to add keyframes to the current selection. Hold Control (MacOS: Command) and double-click a keyframe to select all keyframes on the same animation curve. Click in an empty area in the Curves view to deselect all selected keyframes. This empty area cannot be within a selection of keyframes. Move the Timeline Playhead between keyframes After you select at least one animation curve in the Curves view, use one of the following methods to move the Timeline Playhead between keyframes: Hold Shift and Control (MacOS: Command), and press Period (.) to move the Timeline Playhead to the next keyframe. Hold Shift and Control (MacOS: Command), and press Comma (,) to move the Timeline Playhead to the previous keyframe. Edit keyframes Edit a keyframe to change its time, value, or both. The Curves view provides the following different ways to edit a keyframe: Right-click a keyframe and choose Edit from the context menu to enter specific values for time and value. Select a keyframe and press Enter to enter specific values for time and value. Select and drag a keyframe to change its time and value. Drag a keyframe vertically, then press Shift while dragging to snap the keyframe on the vertical axis. This changes the value but not the time of the keyframe. Drag a keyframe horizontally, then press Shift while dragging to snap the keyframe on the horizontal axis. This changes the time of the keyframe, but not its value. In addition to the methods described above, you can also scale, ripple, and edit the time and value of a selection of keyframes using the same methods as found in the Animation window. Consult Key manipulation in Curves mode for details. Delete keyframes The Curves view provides the following ways to delete a keyframe: Right-click a keyframe and choose Delete Key from the context menu. Select a keyframe and press Delete."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-overview.html",
    "title": "Curves view | Inventory System",
    "summary": "Curves view Use the Curves view to view and edit animation curves for audio tracks, infinite clips, and animation clips. The Curves view is similar to Curves mode in the Animation window. (A) Curves View toggle. (B) List of properties with Animation curves, referred to as the Animation Properties list. (C) Curves view. (D) Use the double-line at the bottom of the Animated Properties list to resize the Curves view vertically. Curves view with Animation clips Use the Curves view to view and perform basic edits to animation curves in Infinite clips and Animation clips. These edits include adding keyframes, modifying keyframes, adjusting tangents, and changing the interpolation between keyframes. To view animation curves for an Infinite clip or Animation clip, enable the Curves View toggle in the Track Header. If you enable the Curves View toggle for an Animation track without selecting an Animation clip, the Curves view displays the animation curves for the first Animation clip. The Curves View toggle (A) displays or hides the Curves view for the selected Animation clip (B) View and edit in the Animation window The Curves View toggle does not appear for Animation tracks with imported animation. To view and edit keyframe animation for imported Animation clips, right-click an Animation clip and choose Edit in Animation Window from the context menu. You can also double-click the Animation clip. When the Animation window appears, it is linked to the Timeline window. When in linked mode, the Animation window displays the Linked button and the name of the Animation clip being viewed or edited. Animation window linked to the Timeline window, indicated by the Linked button and Animation clip name. The clip in this example is (Read-Only) which means that it can be viewed but not edited. Click the Linked button to stop viewing or editing the Animation clip, and to release the Animation window from linked mode. You can also close the Animation window to release it from linked mode. Curves view with Audio tracks For Audio tracks, the Curves view displays the animation curves for the animatable properties of an Audio track. You can animate the following Audio track properties: Spatial Blend Stereo Pan Volume Each animatable property is calculated based on its keyframe values, the values for each Audio clip, the values for each Audio source, or a combination of each. Consult Audio track properties for more information on each animatable property. The Curves View toggle (A) displays or hides the animatable properties of an Audio track (B) When you animate the properties for an Audio track, it is recommended that you select the Audio track, lock the Timeline window, and lock the Inspector window. With both the Timeline window and Inspector window locked, you can add and edit keyframe values with the Audio Track properties in the Inspector window. Use the Timeline Playhead, Playhead Controls, or keyboard shortcuts to navigate between keyframes."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-tangents.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-tangents.html",
    "title": "Tangent modes and types | Inventory System",
    "summary": "Tangent modes and types This topic describes keyframe tangents, tangent modes, tangent types, and weighted tangents. Many of the features described in this topic are similar to editing tangents in the Editing Curves topic in the Animation window. Keyframe tangents Use keyframe tangents to modify the shape of the animation curve between keyframes. Each keyframe has one or two tangents depending on the location of the keyframe on its animation curve. (A) The first keyframe has a single right tangent that controls the shape of the animation curve after the keyframe. (B) Most keyframes have two tangents where the left tangent controls the shape of the animation curve before the keyframe, and the right tangent controls the shape after the keyframe. (C) The last keyframe has a single left tangent that controls the shape of the animation curve before the last keyframe. By default, left and right tangents are joined. Rotating a joined tangent handle rotates both tangents which changes the shape of the animation curve both before and after the keyframe. You can break joined tangents to modify the left and right tangent handles independently. In addition, each keyframe has a tangent mode and a tangent type that controls tangents and the shape of the animation curve. Tangent modes The term tangent mode refers to the algorithm that automatically adjusts tangent handles when you modify the time or value of a keyframe. To display the tangent mode for a keyframe, right-click the keyframe. A context menu displays the selected tangent mode with a checkmark. In some cases, a keyframe can have more than one tangent mode. For example, keyframe tangents can be both Free Smooth and Flat. Tangent mode Description Clamped Auto This is the default tangent mode. In this mode, the Curves view automatically adjusts the rotation of each tangent handle to ensure that the animation curve smoothly passes through the keyframe. For example, if you drag a keyframe to modify its time or value, the Clamped Auto tangent mode automatically adjusts the rotation of each tangent handle. When in Clamped Auto mode, if you rotate a keyframe tangent handle, its tangent mode changes to Free Smooth. Auto Do not select this tangent mode. This is a legacy tangent mode that is only included for backward compatibility with projects prior to Unity 5.5. If you have a keyframe set to this tangent mode, you should change it to another tangent mode. Free Smooth Joins broken tangent handles. Selecting this tangent mode may rotate the tangent handles as they are joined. This tangent mode does not use an algorithm to automatically adjust tangent handles. For example, if you drag a keyframe set to the Free Smooth tangent mode, the rotation of the each tangent handles are not adjusted. Flat Use this tangent mode to join tangent handles and flatten them horizontally. This tangent mode is linked to the Free Smooth tangent mode. For example, if you change the tangent mode from Clamped Auto to Flat, the keyframe is set to both the Free Smooth and Flat tangent modes. Broken Select this mode to break joined tangent handles. When tangent handles are broken, you can control the left and right tangent handles independently. In some cases, both the Free Smooth and Broken tangent modes may be selected. The tangent mode is automatically selected in the following cases: If you select the tangent type for the Left Tangent, Right Tangent, or Both Tangents of a keyframe, the tangent mode changes to either Free Smooth or Broken. If you rotate the left or right tangent handle of a keyframe, the tangents are broken and the tangent mode changes to Broken. Tangent types Select a tangent type to have greater control over the shape and slope of the animation curve before and after a keyframe. The term tangent type refers to the interpolation algorithm that determines the shape of an animation curve between keyframes. The term interpolation refers to the estimation of values between two known points. To set the tangent type of a keyframe tangent, do the following: Right-click a keyframe. A context menu appears. Select a tangent type from the Left Tangent, Right Tangent, or Both Tangents sub-menu. Tangent type Description Free Select this tangent type to freely rotate the left tangent handle (Left Tangent), right tangent handle (Right Tangent), or both tangent handles (Both Tangents). When you select Free this breaks joined tangent handles and sets the tangent mode to Broken. Linear Select this tangent type to draw a straight line to the keyframe (Left Tangent), away from the keyframe (Right Tangent), or both to and away from the keyframe (Both Tangents). When you select this tangent type, the tangent is hidden. Selecting this tangent type also breaks joined tangent handles and sets the tangent mode to Broken. Constant Select this tangent type to keep a constant value from the last keyframe to this keyframe (Left Tangent), from this keyframe to the next keyframe (Right Tangent), or both (Both Tangents). When you select this tangent type, the tangent is hidden. Selecting this tangent type also breaks joined tangent handles and sets the tangent mode to Broken. Weighted Select this tangent type to use a weighted tangent to modify the shape and slope of the animation curve before the keyframe (Left Tangent), after the keyframe (Right Tangent), or both before and after the keyframe (Both Tangents). Consult weighted tangents for more information. Weighted tangents Use weighted tangents to modify the shape and slope of an animation curve. You can modify the length of a weighted tangent which modifies the slope of its animation curve. This provides greater control over the animation when compared to the default tangent. By default, tangents are non-weighted: you can only rotate a non-weighted tangent to modify the shape of its animation curve. You cannot modify the slope of the animation curve because the tangent is set to a fixed length. (A) Keyframe with default non-weighted tangents. The length of the tangent cannot be changed. (B) Keyframe with weighted tangents. Its tangent handles are drawn as outlines. In this example, the left and right tangents are set to different lengths. To change a non-weighted tangent to a weighted tangent, do the following: Right-click a keyframe. A context menu appears. Select Weighted as the tangent type for the Left Tangent, Right Tangent, or Both Tangents sub-menu."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-using.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/curves-using.html",
    "title": "Use the Curves view | Inventory System",
    "summary": "Use the Curves view This topic summarizes how to use the Curves view to navigate, display, and hide animation curves. The functionality described in this topic is similar to Curves mode in the Animation window. Navigate the Curves view Use one of the following methods to pan, zoom, resize, or frame the animation curves and keyframes in the Curves view: To pan, middle-click and drag, or hold Alt (MacOS: Option) and drag. To zoom vertically, move the scroll-wheel, or hold Alt (MacOS: Option), right-click and drag. To zoom horizontally, hold Control (MacOS: Command) and zoom vertically. To resize the Curves view, drag the double line separating the Curves view from the next track in the Track list. To frame only selected animation curves or selected keyframes, press F. To frame all animation curves or keyframes, press A. You can also use the Zoombar to pan, zoom, and resize the Content view. Display and hide animation curves For the selected Animation clip, the Curves view includes a hierarchical list of the properties with animation curves. Expand, collapse, select, and deselect the properties in this list to filter which animation curves appear in the Curves view. For example, to display only the X-axis animation curves for the position of a GameObject, do the following: Click the Triangle beside the Position parent property to display its child properties. Select the Position.x property. Press F to frame the animation curve for the Position.x property. Curves view that displays the animation curve of the Position.x property There are many ways to expand, collapse, select, and deselect animation curves: Click the foldout (triangle) of a parent property to expand and collapse its list of child properties. Hold Shift and click to select contiguous properties. Hold Control (MacOS: Command) and click to select discontiguous properties. Hold Control (MacOS: Command) and click a selected property to deselect it."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/index.html",
    "title": "Unity's Timeline | Inventory System",
    "summary": "Unity's Timeline Use Unity's Timeline to create cinematic content, gameplay sequences, audio sequences, and complex particle effects. Each cut-scene, cinematic, or gameplay sequence that you create with Unity's Timeline consists of a Timeline asset and a Timeline instance. The Timeline window creates and modifies Timeline assets and Timeline instances simultaneously. The Timeline assets and instances topic provides details on the relationship between the Timeline window, Timeline assets, and Timeline instances. The Timeline Workflows section provides basic steps on how to create Timeline assets and Timeline instances, record basic animation, animate humanoids, use Animation Override tracks, Sub-Timelines, and other Timeline features. The Timeline Samples section provides a description of the samples included in the Timeline package."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-act.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-act.html",
    "title": "Activation clip properties | Inventory System",
    "summary": "Activation clip properties Use the Inspector window to change the properties of an Activation clip. These properties includes its name and Clip Timing. Inspector window when selecting an Activation clip in the Timeline window Display Name The name of the Activation clip displayed in the Timeline window. By default, each Activation clip is named Active. Clip Timing properties Use the Clip Timing properties to change the position and duration of the Activation clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds to modify a Clip Timing property, all decimal values are accepted. When specifying frames, only integer values are accepted. For example, if you attempt to enter 12.5 in a frames (f) field, it is set to 12 frames. Depending on the selected Edit mode, changing the Start, End, or Duration may ripple or replace Activation clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-anim.html",
    "title": "Animation clip properties | Inventory System",
    "summary": "Animation clip properties Use the Inspector window to change the properties of an Animation clip. An Animation clip has two sets of properties: Common properties Animation Playable Asset properties Common properties The common properties of an Animation clip include its display name, clip timing, extrapolation, and blend curves. Inspector window when selecting an Animation clip in the Timeline window Display Name The name of the Animation clip displayed in the Timeline window. Clip Timing properties Use the Clip Timing properties to position, change the duration, change the ease-in and ease-out duration, choose the extrapolation mode, and adjust the play speed of the Animation clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Edit mode, changing the Start, End, or Duration may blend, ripple, or replace Animation clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start changes the position of the clip on its track in the Timeline asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Ease In Duration or Blend In Duration Sets the number of seconds or frames that it takes for the clip to ease in. Consult Easing-in and Easing-out Clips. If the beginning of the clip overlaps and blends with another clip, the name of this property changes to Blend In Duration and it displays the duration of the blend between clips. The Blend In Duration can only be edited in the Content view. Consult Blending clips. Ease Out Duration or Blend Out Duration Sets the number of seconds or frames that it takes for the clip to ease out. Consult Easing-in and Easing-out Clips. If the end of the clip overlaps and blends with another clip, the name of this property changes to Blend Out Duration and it displays the duration of the blend between clips. The Blend Out Duration can only be edited in the Content view. Clip In Sets the offset for when the source asset starts playing. For example, to play the last 10 seconds of a 30 second Animation clip, set Clip In to 20 seconds. Speed Multiplier A multiplier on the playback speed of the clip. This value must be greater than 0. Changing this value changes the duration of the clip. You cannot use this property to reverse playback. Consult Changing Clip Play Speed. Animation Extrapolation Use the Animation Extrapolation properties to set the gap extrapolation before and after an Animation clip. The term gap extrapolation refers to how an Animation track approximates or extends animation data in the gaps before, between, and after the Animation clips on a track. Property Description Pre-Extrapolate Controls how animation data is approximated in the gap before an Animation clip. The Pre-Extrapolate property affects the easing-in of an Animation clip. Post-Extrapolate Controls how animation data extends in the gap after an Animation clip. The Post-Extrapolate property affects the easing-out of an Animation clip. Consult Setting the gap extrapolation for more information on each gap extrapolation mode and how they affect other Animation clips on the same Animation track. Blend Curves Use the Blend Curves to customize the transition between the outgoing and incoming Animation clips. Consult Blending clips for details on how to blend clips and customize blend curves. When easing-in or easing-out clips, use the Blend Curves to customize the curve that eases-in or eases-out an Animation clip. Consult Easing-in and Easing-out clips for details. Animation Playable Asset properties Use the Inspector window to change the Playable Asset properties of an Animation clip. These properties include properties for selecting the source asset used by the Animation clip, controls for manually applying position and rotation clip offsets, and options for overriding default clip matching. To view the Playable Asset properties for an Animation clip, expand Animation Playable Asset. Inspector window with the Animation Playable Asset properties expanded Animation Clip Use the Animation Clip to choose the source asset used by the Animation clip on the Animation track. The source asset is either a recorded Infinite clip or an external motion clip. Clip Transform Offsets Use the Clip Transform Offsets area to manually apply position and rotation offsets to the selected Animation clip. The tools and properties underneath the Clip Transform Offsets provide two methods of manually applying offsets based on the selected source: Property: Description: Move tool Displays a Move Gizmo in the Scene view. Use the Move Gizmo to manually position the clip offset for the selected Animation clip. Using the Move Gizmo changes the Position coordinates. Rotate tool Displays a Rotate Gizmo in the Scene view. Use the Rotate Gizmo to manually rotate the clip offset for the selected Animation clip. Using the Rotate Gizmo changes the Rotation coordinates. Position Manually sets the clip offset in X, Y, and Z coordinates. By default, the Position coordinates are set to zero and are relative to the track offsets. Rotation Manually sets the clip rotation offset around the X, Y, and Z axes. By default, the Rotation axes are set to zero and are relative to the track offsets. You can also automatically match the clip offsets based on the end of the previous Animation clip, or the start of the next Animation clip. The transforms that are matched depends on the Offset Match Fields. Offsets Match Fields Use Offsets Match Fields to choose which transforms to match when matching clip offsets. By default, Use Defaults is enabled and uses the default matching options set for the Animation track. Disable Use Defaults to override the track matching options and choose which transformations to match when performing a Match Offsets to Previous Clip or Match Offsets to Next Clip for the selected Animation clip. When you disable Offsets Match Fields, a series of additional checkboxes appear. Use these additional checkboxes to enable or disable matching per coordinate, for both position and rotation. Remove Start Offset Enable Remove Start Offset to make the Animation clip begin at position zero and rotation zero. The rest of the position and rotation keyframes in the Animation clip follow from zero. Enabling Remove Start Offset makes it easier to match the Animation clip with the previous Animation clip. Disable Remove Start Offset to keep the starting position and rotation. The Animation clip starts from its original position and rotation. Foot IK Enable Foot IK if the Animation clip is animating a humanoid and you want to use inverse kinematics for foot solving. Inverse kinematics attempts to remedy foot sliding by solving and influencing foot placement from the foot to the hip of the humanoid. Disable Foot IK if the Animation clip is animating a non-humanoid object such as a moving platform or a quadruped character with a non-human bone structure. Loop Use the Loop property to set how Timeline handles the extra clip area when an Animation clip is longer than its source asset. For example, if you trim the end of an Animation clip past the end of its source asset, the extra clip area either holds or loops its content. Value: Description: Use Source Asset Sets the Animation clip to loop or hold based on the Loop Time property of its source asset. If the source asset is imported from an FBX file, the Loop Time property is set in the Animation tab. If the source asset is recorded keyframe animation, the Loop Time property displays when you select the Recorded clip saved under the Timeline Asset in the Project window. On Loops the extra clip area, ignoring the Loop Time property of the source asset. When the extra clip area loops, the entire source asset loops. Each full loop is labelled sequentially as L1, L2, L3, and so on. Off Sets the extra clip area to hold, ignoring the Loop Time property of the source asset. When the extra clip area holds, the last value of the source asset is held until the end of the extra clip area. The label Hold displays in the extra clip area."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-audio.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-audio.html",
    "title": "Audio clip properties | Inventory System",
    "summary": "Audio clip properties Use the Inspector window to change the properties of an Audio clip. An Audio clip has two sets of properties: Common properties Audio Playable Asset properties Common properties The common properties of an Audio clip include its display name, clip timing, and blend curves. Inspector window when selecting an Audio clip in the Timeline window Display Name The name of the Audio clip displayed in the Timeline window. This is not the name of the audio file that Unity uses for the waveform. For information on audio file properties, consult Audio Playable Asset properties. Clip Timing properties Use the Clip Timing properties to position, change the duration, change the ease-in and ease-out duration, and adjust the play speed of the Audio clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Edit mode, changing the Start, End, or Duration may blend, ripple, or replace Audio clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start property changes the position of the clip on its track in the Timeline asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Ease In Duration or Blend In Duration Sets the number of seconds or frames that it takes for the Audio clip to ease in (fade in). If the beginning of the clip overlaps and blends with another clip, the name of this property changes to Blend In Duration and it displays the duration of the crossfade between Audio clips. The Blend In Duration can only be edited in the Content view. Consult Blending clips. Ease Out Duration or Blend Out Duration Sets the number of seconds or frames that it takes for the Audio clip to ease out (fade out). If the end of the clip overlaps and blends with another Audio clip, the name of this property changes to Blend Out Duration and it displays the duration of the crossfade between Audio clips. The Blend Out Duration can only be edited in the Content view. Clip In Sets the offset for when the source waveform starts playing. Use Clip In to skip silence at the beginning of a source waveform. For example, if the source waveform has 2 seconds of silence before the theme music begins, set Clip In to 2 seconds to skip the silence. Speed Multiplier A multiplier that effects the playback speed of the Audio clip. This value must be greater than 0. Changing this value changes the duration of the Audio clip. You cannot use this property to play an Audio clip backwards. Blend Curves Use the Blend Curves to customize the fade-in and fade-out between the outgoing and incoming Audio clips. Consult Blending clips for details on how to blend clips and customize blend curves. When easing-in or easing-out Audio clips, use the Blend Curves to customize the curve that fades-in or fades-out an Audio clip. Consult Easing-in and Easing-out clips for details. Audio Playable Asset properties Use the Audio Playable Asset properties to select the Audio file used by the Audio clip, set whether the Audio clip loops, and to adjust its volume. Inspector window when selecting an Audio clip in the Timeline window Property Description Clip This is the name of the audio file associated with the Audio clip. Loop Sets how Timeline handles the extra clip area when the Audio clip is longer than its source audio file (specified by Clip). Enable Loop to loop from the start of the source audio file. Each full loop is labelled sequentially as L1, L2, L3, and so on. Disable Loop to play the audio file once. The label Hold displays in the extra clip area. Volume The volume for the Audio clip. The value is a number between 0 and 1 (default). When changed from its default value, the volume for the Audio clip is calculated based on the Audio track volume, this volume value, and the volume of the [Audio Source] bound to the Audio track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-control.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip-control.html",
    "title": "Control clip properties | Inventory System",
    "summary": "Control clip properties Use the Inspector window to change the properties of a Control clip. A Control clip has two sets of properties: Common properties Control Playable Asset properties About Control clips A Control clip is a special clip that controls a Sub-Timeline instance, a Particle System, a Prefab instance, or a ITimeControl Script. What a Control clip controls depends on how you create the Control clip: If you create a Control clip from a GameObject with a Playable Director component associated with a Timeline asset, then the Control clip controls a Sub-Timeline instance. If the GameObject parents other GameObjects associated with many Timeline assets, then the Control clip controls multiple Timeline instances. If you create a Control clip from a GameObject with a Particle System component, then the Control clip controls a Particle System. If you create a Control clip from a GameObject linked to a Prefab, then the Control clip controls a Prefab instance. If you create a Control clip from a GameObject with a script that implements the ITimeControl interface, then the Control clip controls an ITimeControl Script. Common properties The common properties of a Control clip include its name and Clip Timing properties. Not all common properties apply to all types of Control clips. Inspector window when selecting a Control clip in the Timeline window Display Name The name of the Control clip displayed in the Timeline window. Clip Timing properties Use the Clip Timing properties to position and change the duration of the Control clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Edit mode, changing the Start, End, or Duration of a Control clip may insert or replace clips on the same track. You cannot create a blend between Control clips. Property: Description: Start The frame or time (in seconds) when the Control clip starts. Changing the Start changes the position of the Control clip on its track in the Timeline asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the Control clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Clip In Sets the offset of when the Control clip starts playing. The Clip In property only affects Particle Systems and Sub-Timeline instances. Speed Multiplier A speed multiplier that affects the playback speed of the Control clip. This value must be greater than 0. The Speed Multiplier property only affects Particle Systems and Sub-Timeline instances. Control Playable Asset properties Use the Inspector window to change the playable asset properties of a Control clip. To view the playable asset properties for a Control clip, select a Control clip in the Timeline window and expand Control Playable Asset in the Inspector window. Inspector window with the Control Playable Asset properties for the selected Control clip Source Game Object Use Source Game Object to select the GameObject with the Particle System, Sub-Timeline instance, or ITimeControl Script for the selected Control clip. Changing the Source Game Object changes what the Control clip controls. Prefab Use Prefab to select a Prefab to instantiate when the Timeline instance plays in Play mode. When a Prefab is selected, the label of the Source Game Object property changes to Parent Object. When in Play mode, the Prefab is instantiated as a child of the Parent Object. Although the Prefab is instantiated at the start of the Timeline instance, the Prefab is only activated during the Control clip. When the Control clip ends, the Prefab instance is deactivated. Control Activation Enable Control Activation to activate the Source Game Object while the Control clip plays. Disable this property to activate the Source Game Object during the entire Timeline instance. The Control Activation property only affects Control clips that control a Sub-Timeline instance or a Particle System. Post Playback When Control Activation is enabled, use the Post Playback property to set the activation state for the Sub-Timeline instance when the main Timeline stops playing. The Post Playback property only affects Sub-Timeline instances. Post-Playback State Description Active Activates the Source Game Object after the Sub-Timeline instance finishes playing. Inactive Deactivates the Source Game Object after the Sub-Timeline instance finishes playing. Revert Reverts the Source Game Object to its activation state before the Sub-Timeline instance began playing. Advanced properties Use the Advanced properties to select additional functionality based on whether the Control clip controls a Playable Director, Particle System, or ITimeControl Script. The Advanced properties do not apply to all Control clips. Property Description Control Playable Directors Enable this property if the Source Game Object is attached to a Playable Director and you want the Control clip to control the Sub-Timeline instance associated with this Playable Director. On Clip End Use this property in conjunction with Control Playable Directors to set the state of the controlled Playable Director at the end of a clip. Stop Director stops the Playable Director and destroys the Playable Director graph at the end of a clip, releasing allocated resources. Pause Director pauses the Playable Director and reuses the Playable Director graph, preserving allocated resources. Select Pause Director to improve performance when a Control track has multiple clips using the same Sub-Timeline instance. Control Particle Systems Enable this property when the Control clip includes a Particle System. Set the value of the Random Seed property to create a unique, repeatable effect. Control ITimeControl Enable this property to control ITimeControl scripts on the Source GameObject. To use this feature, the Source GameObject must have a script that implements the ITimeControl interface. Control Children Enable this property if the Source Game Object has a child GameObject with either a Playable Director, Particle System, or ITimeControl Script, and you want the Control clip to control this child component. For example, if the Source Game Object is a GameObject that parents another GameObject with a Particle System, enable this property to make the Control clip control the Particle system on the child GameObject."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-clip.html",
    "title": "Clip properties | Inventory System",
    "summary": "Clip properties Use the Inspector window to change the name of a clip and other properties, such as its timing and blend properties. The available properties depend on the type of clip selected. For example, select an Activation clip to change its name and set its Clip Timing. Inspector window when selecting an Activation clip in the Timeline window Not all clips have properties. See the following topics for clips with properties: Activation clip properties Animation clip properties Audio clip properties Control clip properties"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-overview.html",
    "title": "Timeline properties in the Inspector window | Inventory System",
    "summary": "Timeline properties in the Inspector window This section describes the properties that display in the Inspector window when you select Timeline assets, tracks, clips, markers, or other Timeline-related items. The displayed properties also depend on whether you select a single item or multiple items. Not all selected items have properties. Single selection If you select a single Timeline asset, track, clip, or marker, the Inspector window displays the properties for the selected item. For example, if you select an Animation clip in the Timeline window, the Inspector window displays the properties for the selected Animation clip. Inspector window when selecting an Animation clip in the Timeline window The following topics provide more information on the properties that display when you select a Timeline asset, track, clip, or marker: Timeline Asset Properties Track Properties Clip Properties Marker and Signal properties Multiple selection If you select multiple Timeline assets, tracks, clips, or markers, the Inspector window lists the properties that apply to the selection as a group followed by properties common to all selected items. Inspector window when selecting multiple clips, from multiple tracks, in the Timeline window For example, if you select an Audio clip on one track and an Animation clip on another track, the Inspector window includes Multiple Clip Timing properties and Clip Timing properties: Use the Multiple Clip Timing properties to change the Start or End of the selection as a group. For example, if you change the Start to frame 30, the selection of clips start at frame 30. This moves the start of the first clip to frame 30 and the remaining selected clips are placed relative to the first clip, respecting gaps between selected clips. Use the Clip Timing properties to change the common properties for each selected clip. If the selected clips have different values for the same property, the value is represented with a dash (\"-\"). If you change the dash to a value, it sets the value for all selected clips. For example, if you change the Ease In Duration from a dash to 10 frames, the ease-in of each selected clip changes to 10 frames. If your selection does not have common properties, the Inspector window prompts you to narrow the selection. For example, if you select an Animation track and an Audio clip in the Timeline window, you are prompted to narrow the selection: The message in the Inspector window when the selection does not have common properties"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-tl-asset.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-tl-asset.html",
    "title": "Timeline asset properties | Inventory System",
    "summary": "Timeline asset properties Use the Inspector window to set the frame rate, the duration mode, and a fixed length for the selected Timeline asset. Select a Timeline asset from the Project window to view its properties. Inspector window when you select a Timeline asset in the Project window Property Description Frame Rate Sets the reference frame rate for the Timeline asset and its Timeline instances. Change the frame rate to align clips at precise frames. Note that the Frame Rate is only visual and has no effect on play speed, keyframes, tracks, or clips. To set the Frame Rate, either select a standard frame rate from the drop-down menu or enter a non-standard frame rate in the adjacent field. Timeline supports frame rates from 1e-6 to 1000. For Timeline instances associated with the Timeline asset, you can set the Frame Rate in the Timeline Options. Duration Mode Choose whether the duration of the Timeline asset extends to the end of the last clip or ends at a specific time or frame. Based On Clips Sets the length of the Timeline asset based on the end of the last clip. Fixed Length Sets the length of the Timeline asset to a specific number of seconds or frames. Duration Displays the length of the Timeline asset in seconds and frames when the Duration Mode is set to Based on Clips. Sets the length of the Timeline asset to a specific number of seconds or frames when the Duration Mode is set to Fixed Length. Scene Preview Enable to preview the affect of the Timeline instance on the Scene. It is recommended to always enable Scene Preview. Disable Scene Preview to apply the changes from the Timeline instance to the Scene. Since disabling Scene Preview can be destructive, a warning appears in the Inspector window and a warning icon appears on the Timeline Preview toggle."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-act.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-act.html",
    "title": "Activation track properties | Inventory System",
    "summary": "Activation track properties Use the Inspector window to change the name of an Activation track and set the state of its bound GameObject when the Timeline asset finishes playing. Inspector window when selecting an Activation track in the Timeline window Property Description Display Name The name of the Activation track displayed in the Timeline window and Playable Director component. The Display Name applies to the Timeline asset and all of its Timeline instances. It is set to Activation Track by default. Post-playback state Sets the activation state for the bound GameObject when the Timeline asset stops playing. The Post-playback state applies to the Timeline asset and all of its Timeline instances. Active Activates the bound GameObject when the Timeline asset finishes playing. Inactive Deactivates the bound GameObject when the Timeline asset finishes playing. Revert Reverts the bound GameObject to its activation state before the Timeline asset began playing. For example, if the Timeline asset finishes playing with the GameObject set to inactive, and the GameObject was active before the Timeline asset began playing, then the GameObject reverts to active. Leave As Is Sets the activation state of the bound GameObject to the state the Timeline asset is at when it finishes playing. For example, if the Timeline asset finishes playing with the GameObject set to inactive, the GameObject remains inactive."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-anim.html",
    "title": "Animation track properties | Inventory System",
    "summary": "Animation track properties Use the Inspector window to change the name of an Animation track, set how track offsets are applied, use an avatar mask, and set which transforms are modified by default when you match clip offsets. Inspector window when selecting an Animation track in the Timeline window Property Description Display Name The name of the Animation track displayed in the Timeline window and in the Playable Director component. The Display Name applies to the Timeline asset and all of its Timeline instances. The Display Name is set to Animation Track by default. Track Offsets Applies a position and rotation offset to the start of each Animation clip on the selected Animation track. The position and rotation offset starts from a specific position and rotation or from the position and rotation relative to a state machine or another Timeline instance. Apply Transform Offsets Starts the animation in each Animation clip from a specific position and rotation offset. Use the Move and Rotate tools, and the Position and Rotation fields, to set the starting position and rotation. Apply Scene Offsets Starts the animated GameObject from its current position and rotation in the Scene. Use this mode to build a Timeline instance that transitions to and from a state machine or to and from another Timeline instance. Auto (deprecated) If you load a Scene or Project that was built before 2018.3, Track Offsets is automatically set to Auto. This is a special offset for backwards compatibility. If you select Auto, a warning states that this mode should not be selected because it will be deprecated. You should choose one of the other Track Offsets. The Auto offset also disables animation recording. Move tool Enable the Move tool displays the Move Gizmo in the Scene view. Use the Move Gizmo to visually position the transform offset. Positioning the Move Gizmo changes the Position properties. The Move tool only appears when Track Offsets is set to Apply Transform Offsets. Rotate tool Enable the Rotate tool displays the Rotate Gizmo in the Scene view. Use the Rotate Gizmo to visually rotate the track offset. Rotating the Rotate Gizmo changes the Rotation properties. The Rotate tool only appears when Track Offsets is set to Apply Transform Offsets. Position Sets the track position offset in X, Y, and Z coordinates. The Position fields only appears when Track Offsets is set to Apply Transform Offsets. Rotation Sets the track rotation offset in X, Y, and Z coordinates. The Rotation fields appear when Track Offsets is set to Apply Transform Offsets. Apply Avatar Mask Enables Avatar masking. When enabled, Timeline applies the animation of all Animation clips on the track based on the selected Avatar Mask. Avatar Mask Selects the Avatar Mask applied to all Animation clips on the Animation track. An Avatar Mask defines which humanoid body parts are animated by Animation clips on the selected Animation track. The body parts that are masked are animated by other Animation tracks in the Timeline asset. For example, you can use an Avatar Mask to combine the lower-body animation on an Animation track with the upper body animation on an Override Animation track. Default Offset Match Fields Expand to display a series of checkboxes that choose which transforms are matched when matching clip offsets between Animation clips. The Default Offset Match Fields set the default matching options for all Animation clips on the same track. Use the Animation Playable Asset properties to override these defaults for each Animation clip."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-audio.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk-audio.html",
    "title": "Audio track properties | Inventory System",
    "summary": "Audio track properties Use the Inspector window to change the name of an Audio track, and set its Volume, Stereo Pan, and Spatial Blend. You can also animation the Audio track properties in the Curves view. Inspector window when selecting an Animation track in the Timeline window Property Description Display Name The name of the Audio track displayed in the Timeline window and in the Playable Director component. The Display Name applies to the Timeline asset and all of its Timeline instances. The Display Name is set to Audio Track by default. Volume The volume for the Audio track. The value is a number between 0 and 1 (default). When changed from its default value, the volume for each Audio clip on the Audio track is calculated based on this volume value, the Audio clip volume, and the volume of the Audio Source bound to the Audio track. Stereo Pan The pan value for the Audio track. This property is only valid for Mono or Stereo Audio clips. The pan value is a number between -1 and 1, where fully panned left is -1 and fully panned right is 1. By default, panning is set to 0 which is centered. For Mono Audio clips, the default value is either panned fully left or fully right. When changed from its default, the final pan is calculated based on this pan value and the pan of the Audio Source bound to the Audio track. Spatial Blend Sets how much the 3D engine has an effect on the Audio track. The Spatial Blend value is a number between 0 and 1, where 0 means that the Audio track is fully 2D: the audio uses its original audio channel mapping and is not affected by the 3D engine. When set to fully 3D, all audio channels are mixed down to a mono channel and attenuated based on distance and direction. By default, Spatial Blend is set to 0 (fully 2D). When changed from its default, the Spatial Blend for the Audio track and its clips are calculated based on this property and the Spatial Blend of the Audio Source bound to the Audio track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/insp-trk.html",
    "title": "Track properties | Inventory System",
    "summary": "Track properties Use the Inspector window to change the name of a track and its properties. The available properties depend on the type of track selected. For example, select an Animation track to set how track offsets are applied, use an avatar mask, and select which transforms are modified when matching offsets between Animation clips. Inspector window when selecting an Animation track in the Timeline window Not all tracks have properties. See the following topics for tracks with properties: Activation Track properties Animation Track properties Audio Track properties"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/install.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/install.html",
    "title": "Install Timeline | Inventory System",
    "summary": "Install Timeline Timeline is a Package. It is automatically installed with the Unity Editor. You can update and reinstall the Timeline package with the Packages window in the Unity Editor. Consult the Packages window documentation for more information. The Timeline package also contains sample projects that demonstrate many Timeline features. For information on how to install samples, consult the Timeline Samples section. Requirements This version of Timeline is compatible with the following versions of the Unity Editor: 2019.4 and later"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/playable-director.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/playable-director.html",
    "title": "Playable Director component | Inventory System",
    "summary": "Playable Director component The Playable Director component stores the link between a Timeline instance and a Timeline asset. The Playable Director component controls when the Timeline instance plays, how the Timeline instance updates its clock, and what happens when the Timeline instance finishes playing. Playable Director component added to the GameObject named Ground. The GameObject is associated with the GroundCTL Timeline asset. The Playable Director component also displays the list of tracks from the associated Timeline asset (Playable property) that animate GameObjects in the Scene. The link between Timeline asset tracks and GameObjects in the Scene is referred to as binding or Track binding. For more on binding and the relationship between Timeline assets and Timeline instances, consult the Timeline assets and instances topic. Property Description Playable Associates a Timeline asset with a GameObject in the Scene. When you make this association, you create a Timeline instance for the selected Timeline asset. Update Method Sets the clock source that the Timeline instance uses to update its timing. DSP Select for sample accurate audio scheduling. When selected, the Timeline instance uses the same clock source that processes audio. DSP stands for digital signal processing. Game Time Select to use the same clock source as the game clock. This clock source is affected by time scaling. Unscaled Game Time Select to use the same clock source as the game clock, but without being affected by time scaling. Manual Select to not use a clock source and to manually set the clock time through scripting. Play on Awake Whether the Timeline instance is played when gameplay is initiated. By default, a Timeline instance is set to begin as soon as the Scene begins playback. To disable the default behavior, disable Play on Awake. Wrap Mode The behavior when the Timeline instance ends playback. Hold Plays the Timeline instance once and holds on the last frame until playback is interrupted. Loop Plays the Timeline instance repeatedly until playback is interrupted. None Plays the Timeline instance once. Initial Time The time (in seconds) at which the Timeline instance begins playing. The Initial Time adds a delay in seconds before the Timeline instance actually begins. For example, when Play On Awake is enabled and Initial Time is set to five seconds, if you click Play in the Unity Toolbar, Play mode starts and the Timeline instance begins five seconds later. Current Time Displays the progression of time according to the Timeline instance in the Timeline window. Use the Current Time field when the Timeline window is hidden. The Current Time field appears in the Playable Director component when in Timeline Playback mode or when Unity is in Game Mode. The Current Time field matches the Playhead Location field. Bindings Displays the link between GameObjects in the Scene with tracks from the associated Timeline asset (Playable). The Bindings area is split into two columns: The first column lists the tracks from the Timeline asset. Each track is identified by an icon and its track type. Select a track to reveal its Timeline asset in the Project window. The second column lists the GameObject linked (or bound) to each track. Select a GameObject to reveal its location in the Hierarchy view. The Bindings area does not list Track groups, Track sub-groups, or tracks that are not linked to GameObjects."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-custom-samples.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-custom-samples.html",
    "title": "Customization Samples | Inventory System",
    "summary": "Customization Samples The Customization Samples sample includes track groups, tracks, clips, markers, signals, and actions that demonstrate how to extend and customize Unity's Timeline. To import the Customization Samples scene and open its Timeline instance, do the following: Import the Customization Samples sample into your project. In the Project window, go to Assets/Samples/Timeline/<version>/Customization Samples/Demo/Scenes, where <version> is your installed Timeline package version. Double-click the scene named Timeline_CustomTracks. To open the Timeline instance, in the Hierarchy window, select the Timeline GameObject. The Timeline instance named CustomTracks displays in the Timeline window. If the Timeline window is not open, go to Window > Sequencing > Timeline. CustomTracks Timeline instance associated with the Timeline GameObject This sample uses the CustomTracks Timeline instance to demonstrate different custom markers, tracks, scripts, and menu items. These customizations play as a single sequence with captions from the custom Text track and annotations from custom annotation markers. The main customizations in this Timeline instance are as follows: Annotation marker: This custom marker annotates the custom tracks, text, video, and animation clips. These markers are placed on the Markers track, on custom tracks, and on animation tracks. Time dilation track: This custom track creates a time dilation effect that slows down animation for emphasis. Video track: This custom track plays video clips. Text track: This custom track uses the TextMeshPro component describe the other custom tracks with captions. Tween track: This custom track provides a track that can be used for simple transform movements. Annotation marker This custom marker annotates the custom tracks, text, video, and animation clips. These markers are placed on the Markers track, on custom tracks, and on animation tracks. The custom Annotation marker uses scripts to override the default Timeline marker behavior and USS (Unity style sheets) to default marker appearance. There are also custom scripts for adding menu items that add annotation markers and copy text from the clipboard. Time Dilation Track The Time Dilation Track provides track and clip scripts that adjust Unity's Time.timeScale global. The most common usage for modifying this global is to create a time warp effect where the animation slows down for emphasize. This is referred to as a bullet time effect. This sample demonstrates how to: Create a custom TrackMixer PlayableBehaviour that performs custom blending of clip values. Set and restore Unity global values in a PlayableBehaviour. Support blending and extrapolation on custom clips. Animate custom clip data using the Curves view with a PlayableBehaviour template. Usage Select the Add (+) menu and choose Timeline.Samples > Time Dilation Track to add a new Time Dilation Track. Add clips to the track, and use the Inspector window to set timescale values for the clip. You can also use the Curves view in the Timeline window to animate the timescale. Blend clips to create transitions. Video Track sample The Video Track sample provides a track that plays video clips. This sample demonstrates how to: Use blending, speed, and clip-in with custom clips. Use many ClipEditors to customize clip drawing. Use a mixer PlayableBehaviour to perform look-ahead operations. Manage the UnityEngine.Object lifetime (VideoPlayer) with a PlayableBehaviour. Use ExposedReferences to reference scene components from a PlayableAsset. Usage Drag an imported video from the Project window into a Timeline instance to create a video track and video clip. The video clip provides several playback options including selecting which camera renders the video and which audio source plays the audio. If a camera is not specified, the video clip uses the main camera. If an audio source is not specified, the audio plays directly. The video playback options are set per clip in the Inspector window. To view these options, select the video clip and expand Video Playable Asset. Known Issues The video track supports ease-in and ease-out, but blending between videos is not supported and may give unexpected results. Editing a Timeline instance with video clips may cause the blended result to flicker or change unexpectedly. Looping a Timeline instance with video clips could de-synchronize the video. Text Track The Text track requires the TextMeshPro package. The Text track provides track and clip scripts that display subtitles or other similar types of messages. This sample demonstrates how to: Register custom properties in a custom track. Perform custom clip blending with a mixer (PlayableBehaviour). Animate custom clip properties in the Curves view through a PlayableBehaviour template. Use a ClipEditor to react to changes in a clip. Transform Tween track sample The Transform Tween Track provides a track for simple transform movements between two points. This track demonstrates how to: Create a custom clip, custom track, and mixer. Use the PlayableGraph API to transform a GameObject. Customize a clip with a ClipEditor. Usage Use the Transform Tween track for simple transform movements. All translation happens in a straight line but you can control the speed with an animation curve. The Tween track binds to the scene Transform you want to move. Property Description Start Location A GameObject in the scene that the playable uses as a starting reference. This reference is the starting position, rotation, or both. If the Start Location is set to null, the Transform uses its own position, rotation, or both when the playable starts. End Location A GameObject in the scene that the playable uses as an ending reference. This reference is the ending position, rotation, or both. If the End Location is set to null, the Transform uses its own position, rotation, or both when the playable finishes. Tween Position Whether the position of the Transform changes. Tween Rotation Whether the rotation of the Transform changes."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-gameplay-demo.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-gameplay-demo.html",
    "title": "Gameplay Sequence Demo | Inventory System",
    "summary": "Gameplay Sequence Demo The Gameplay Sequence Demo sample demonstrates how to use Unity's Timeline to create a complex cut-scene. To import the Gameplay Sequence Demo scene and open its Timeline instance, do the following: Import the Gameplay Sequence Demo sample into your project. In the Project window, go to Assets/Samples/Timeline/<version>/Gameplay Sequence Demo/Scenes, where <version> is your installed Timeline package version. Double-click the scene named GameplaySequence. To open the Timeline instance, in the Hierarchy window, select the Timeline GameObject. The Timeline instance named GameplaySequence displays in the Timeline window. If the Timeline window is not open, go to Window > Sequencing > Timeline. GameplaySequence Timeline instance associated with the Timeline GameObject The GameplaySequence Timeline instance uses the Markers track and multiple Activation, Animation, Audio, and Control tracks organized into the following Track groups: Building Track group: Contains tracks for spawning the buildings and controlling particle effects related to the spawned buildings. Lights Track group: Contains tracks that animate two of the lights in the cut-scene: Sun Light and the Point Light. Cameras Track group: Contains tracks that creates camera movement and camera switch between two camera GameObjects: Main Camera and Follow Camera. Characters Track group: Contains tracks that animate the activate the main Player character and the secondary Character2 character. Audio Track group: Contains multiple audio tracks that play sounds associated with characters, environment, and other effects. Props Track group: Contains multiple tracks that animate and activate the Table and Can GameObjects. The Props Track group uses the Can Sub-Timeline instance to animate the Can GameObject bouncing and falling off the table. Markers track In the GameplaySequence Timeline instance, the Markers track includes a single runtime Signal Emitter at frame 1200. This Signal Emitter emits a signal to play an audio clip at the end of the cut-scene. The Signal Receiver is attached to the Timeline GameObject. It receives the signal and plays an audio clip of the Player character jogging. This Signal Receiver only receives the signal at runtime and will not play the audio clip while previewing the GameplaySequence Timeline instance in the Timeline window. The purpose of playing this audio clip is to provide an audio transition from the cut-scene to gameplay when the cut-scene has ended. Building Track group The Building Track group expanded The Building Track group contains the following tracks: Track Description Building Spawn Control track This track contains a Control clip that spawns the building prefab. Building Particles Control track This track uses two Control clips to add background effects. The ElectricalSparks clip provides electrical sparks inside the building. The SandSwirlsEffect clip provides the swirling sand effect outside the building. Lights Track group The Lights Track group expanded The Lights Track group contains the following tracks: Track Description Sun Light Animation track This track animates the passage of time from night, to sunrise, and then to day. This effect is achieved by animating the rotation of the light GameObject bound to the Sun Light track. Point light Animation track This track animates a flickering light within the Building model. The flickering light effect is achieved by animating the Intensity property of the light GameObject bound to the Point Light track. The animation for each light track is created with keyframe animation on infinite clips. To view the keyframe animation, for either track, do one of the following: Enable the Curves View toggle in the Track Header. The keyframe animation displays in the Curves View. Double-click the infinite clip. The keyframe animation displays in the Animation window. Cameras Track group The Cameras Track group expanded The Cameras Track group contains the following tracks: Track Description Main Camera Animation track This track animates the camera movement of the Main Camera camera GameObject. The camera movement is created with keyframe animation on an infinite clip. To view this keyframe animation, either enable the Curves View toggle in the Track Header or double-click the infinite clip to open the Animation window. Player Shots Animation Override track This track is a child of the Main Camera Animation track. The clips on this track override the position and rotation of the Main Camera camera which provides a camera shot of the main Player character. Character2 Shots Animation Override track This track is a child of the Main Camera Animation track. The clips on this track override the position and rotation of the Main Camera camera. Follow Camera Activation track This track activates the Follow Camera GameObject. When active, the view from the Follow Camera camera overrides the Main Camera track and its Animation Override tracks. To create this follow camera and camera shot, in the scene, the Follow Camera is parented by the Player Character so that the Follow Camera camera moves with the Player Character. A local position and rotation offset is added to the Follow Camera GameObject so that the camera shot is from over the left shoulder of the Player Character. Characters Track group The Characters Track group expanded The Characters Track group contains the following tracks: Track Description Player Animation track This track animates the Player character. This is the main character in the cut-scene. The Animation clip on this track takes control of the Player character, collides Player with the Character2 character, bumps Player into a table which causes a can to fall and bounce on the floor, then returns control of the Player character to the jog Animator state. If you attempt to preview this animation in the Timeline window, the Player character is shown in a T-Stance pose before and after the Animation clip because the jog Animator state is only available during runtime. To preview the Player character with the looping jog animation, click Play in the Game View. Character2 Activation track This track activates the Character2 character. The Character2 character is the secondary character in the cut-scene. Character2 Animation track This track contains many Animation clips that blend together to create the parkour animation sequence for the Character2 character. This track also includes animation clips for the collision between characters and Character2 gesturing towards the main Player character. Audio Track group The Audio Track group expanded The Audio Track group contains the following tracks: Track Description Player Audio track This track plays the jog Audio clip which contains the jogging and breathing sounds associated with the main Gameplay character. This Audio track also plays the bump Audio clip when the two characters collide. Sun Light Audio track This track plays the crickets Audio clip during the night portion of the Gameplay sequence. The Sun Light Audio track also has pan and volume track animation. To view this track animation, enable the Curves View toggle for the Sun Light Audio Track Header. Point Light Audio track This track plays the neon_light Audio clips as Character2 moves, jumps, and runs through the Building model. The neon-light Audio clip is for the flickering Point light effect. Character2 Audio track This track contains the jump and breath audio clips as the Character2 character parkours through the Building model. The Character2 Audio track also plays a bump Audio clip when the two characters collide. Props Track group The Props Track group expanded The Props Track group contains the following tracks: Track Description Table Activation track This track activates the Table GameObject. StaticCan Activation track This track activates a static copy of the Can GameObject. The StaticCan GameObject is hidden when the table is bumped and the Can Sub-Timeline animation begins. TableBase Animation track This track contains an Infinite clip that animates the table bump. The table bump also animates the StaticCan GameObject because the StaticCan is parented by the TableBase. This movement causes the can to fall off the table. Can Sub-Timeline Control track This track includes a Control clip that contains the Can Sub-Timeline instance. The Can Sub-Timeline contains an Animation track for the can rolling off the table and bouncing on the ground, an Audio track for the sound effects of the bouncing can, and a Control track for the liquid particles splashing out of the can as it bounces. To view the Can Sub-Timeline and its additional three tracks, double-click the Control clip."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/samp-overview.html",
    "title": "Timeline Samples | Inventory System",
    "summary": "Timeline Samples The Timeline package includes sample projects that demonstrate how to use and customize tracks, clips, markers, and menu items. Timeline package for version 1.8.2 listing the available Timeline sample projects. Sample projects were first added to the Timeline package in version 1.5. To import a sample project: Expand the Timeline entry in the Package Manager window. Select the currently installed Timeline package. Either expand Samples or select the Samples tab to display the list of available Timeline sample projects. Click Import beside the sample you want to import. If you have already imported the sample, click Reimport to reimport the sample into your project. When you reimport a sample, any changes that you have made to the sample, its assets, scenes, and files are overwritten with the original sample. The Package Manager window imports or reimports sample files to the Assets/Samples/Timeline/<version> in the Project window, where <version> is the installed Timeline package version. Depending on the sample, the location of its assets, scenes, and files may differ. Consult the dedicated topic on each Timeline sample for more information. The Timeline package includes the following Timeline samples: Sample Description Customization Samples This sample project includes a Timeline instance with different custom tracks that demonstrate time dilation, video, text, tweening, and character animation. This sample also includes a custom marker that annotates clips and tracks, and track groups. Use the examples in this sample project as a basis for your own Timeline track customizations. Gameplay Sequence Demo This sample project includes a Timeline instance with multiple Track groups, tracks, animated characters, effects, and camera switches that demonstrate how to use Unity's Timeline to create a cut-scene. This cut-scene features a jogging character (Player) who collides with another character (Character2). The Character2 character then bumps into a table which causes a can to fall and bounce on the floor. The Character2 character gestures towards the Player character who continues jogging as the cut-scene ends."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-glossary.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-glossary.html",
    "title": "Timeline glossary | Inventory System",
    "summary": "Timeline glossary This topic provides an alphabetical list of the terminology used throughout the Timeline documentation. animatable property: A property belonging to a GameObject, or belonging to a component added to a GameObject, that can have a different value over time. animation: The result of adding two keyframes with different values, at two different times, for the same animatable property. The basic definition is a value that changes over time. animation curve: The curve drawn between keyframes set for the same animatable property, at different times. The position of the tangents and the selected interpolation mode for each keyframe determines the shape of the animation curve. binding or Track binding: Refers to the link between Timeline asset tracks and the GameObjects in the scene. When you link a GameObject to a track, the track animates the GameObject. Bindings are stored as part of the Timeline instance. blend and blend area: The area where two Animation clips, Audio clips, or Control clips overlap. The overlap creates a transition that is referred to as a blend. The duration of the overlap is referred to as the blend area. The blend area sets the duration of the transition. Blend In curve: In a blend between two Animation clips, Audio clips, or Control clips, there are two blend curves. The blend curve for the incoming clip is referred to as the Blend In curve. Blend Out curve: In a blend between two Animation clips, Audio clips, or Control clips, there are two blend curves. The blend curve for the out-going clip is referred to as the Blend Out curve. clip: A generic term that refers to any clip within the Content view of the Timeline window. Content view: The area in the Timeline window where you add, position, and manipulate clips and markers. Curves view: The area in the Timeline window that displays the animation curves for Infinite clips, or for Animation clips that have been converted from Infinite clips. The Curves view also displays animation curves for Audio Track properties. The Curves view is similar to Curves mode in the Animation window. gap extrapolation: How an Animation track approximates animation data in the gaps before and after an Animation clip. field: A generic term that describes an editable box where the user clicks and types-in a value. incoming clip: The second clip in a blend between two clips. The first clip, the out-going clip, transitions to the second clip, the incoming clip. Infinite clip: A special animation clip that contains basic keyframe animation recorded directly to an Animation track within the Timeline window. An Infinite clip cannot be positioned, trimmed, or split because it does not have a defined duration: it spans the entirety of an Animation track. interpolation: The estimation of values between keyframes that determine the shape of an animation curve. interpolation mode: The interpolation algorithm that draws the animation curve between keyframes. The interpolation mode also joins or breaks left and right tangents. Interpolation mode is also referred to as tangent mode and tangent type. keyframe: The value of an animatable property set at a specific point in time. Setting at least two keyframes for the same property creates an animation. marker: A generic term that refers to any marker within the Content view of the Timeline window. out-going clip: The first clip in a blend between two clips. The first clip, the out-going clip, transitions to the second clip, the incoming clip. Playhead Location field: The field that expresses the location of the Timeline Playhead in frames, timecode, or seconds depending on the Timeline Settings. property: A generic term for the editable fields, toggles, checkboxes, or menus that comprise a component. An editable field is also referred to as a field. tangent: One of two handles that control the shape of the animation curve before and after a keyframe. Tangents appear when a keyframe is selected in the Curves view. tangent mode or tangent type: The selected interpolation mode used by the left tangent, right tangent, or both tangents. Timeline or Unity's Timeline: Generic terms that refer to all features, windows, editors, and components related to creating, modifying, or reusing cut-scenes, cinematic, and gameplay sequences. Timeline asset: Refers to the tracks, clips, and recorded keyframe animation that comprise a cut-scene, cinematic, gameplay sequence, or other effect created with the Timeline window. A Timeline asset does not include bindings to the GameObjects animated by the Timeline asset. The bindings to scene GameObjects are stored in the Timeline instance. A Timeline asset is project-based. Timeline instance: Refers to the link between a Timeline asset and the GameObjects that the Timeline asset animates in the scene. You create a Timeline instance by associating a Timeline asset to a GameObject through a Playable Director component. A Timeline instance is scene-based. Timeline Playback Controls: The row of buttons, toggles, and fields in the Timeline window that controls playback of the Timeline instance. The Timeline Playback Controls affect the location of the Timeline Playhead. Timeline Playback mode: The mode that previews the Timeline instance in the Timeline window. Timeline Playback mode does not support audio playback. Timeline Playback mode is a simulation of Play mode in the Unity. Timeline Playhead: The white marker and line that indicates the exact point in time being previewed in the Timeline window. Timeline Selector: The name of the menu in the Timeline window that selects the Timeline instance to be previewed or modified. Timeline window: The official name of the window where you create, modify, and preview a Timeline instance. Modifications to a Timeline instance also affect the Timeline asset. track: A generic term that refers to any track within the Track list of the Timeline window. Track group: A container in the Track list for organizing a collection of tracks. Track sub-group: A Track group nested within another Track group. A Track group can have multiple nested sub-groups. Track list: The area in the Timeline window where you add, group, and modify tracks. Each track is represented by a Track Header."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-options.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-options.html",
    "title": "Timeline Options | Inventory System",
    "summary": "Timeline Options Use the Timeline Options to choose Timeline asset settings such as the unit of measurement, the duration mode, whether to display markers, and the Timeline frame rate. You can also access the Timeline Preferences. Click the gear icon in the Timeline window to view the Timeline Options menu The items in the Timeline Options menu apply to the selected Timeline asset and affect its Timeline instances. Consult the Timeline assets and instances topic for more information on the relationship between Timeline assets and Timeline instances. Preferences page Select to open the Preferences window and access the Timeline Preferences. The Timeline Preferences are settings that apply to the Timeline window regardless of the selected Timeline asset or Timeline instance. Consult Timeline Preferences for more information. Frames, Timecode, or Seconds Select either Frames, Timecode or Seconds to set the selected Timeline asset to display time in that format. Timecode displays the time in seconds with sub-second values displayed in frames. Duration Mode Use the Duration Mode to set whether the duration of the Timeline asset extends to the end of the last clip (Based On Clips), or ends at a specific time or frame (Fixed Length). Timeline asset Duration Mode set to Fixed Length (A) Length of Timeline asset. (B) Blue marker that indicates the end of the Timeline asset. When the Duration Mode is set to Fixed Length, use one of the following methods to change the length of the Timeline asset: Select the Timeline asset in the Project window and use the Inspector window to set the Duration in seconds or frames. In the Timeline window, drag the blue marker on the timeline. The blue marker indicates the end of the Timeline asset. A blue line indicates the duration of the Timeline asset. Show markers Use the Show markers option to expand or collapse the Timeline marker track. This option toggles the Timeline Markers toggle in the Track list. Use the Timeline marker track, and other dedicated marker tracks, to add and manage markers and signals. Frame Rate Select one of the standard frame rates under Frame Rate to set the unit of measurement for the Timeline ruler. Change the Frame Rate to align clips at precise frames but changing the Frame Rate is only visual and has no effect on play speed, keyframes, tracks, or clips. Timeline supports custom frame rates from 1e-6 to 1000. To set a custom frame rate, you must use the Frame Rate property in the Timeline asset settings. When the Timeline asset is set to a custom frame rate, Custom is automatically selected for the Timeline instance. The Custom menu item displays the custom frame rate in parentheses."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-overview.html",
    "title": "Timeline assets and instances | Inventory System",
    "summary": "Timeline assets and instances Use the Timeline window to create cut-scenes, cinematics, and gameplay sequences by visually arranging tracks and clips linked to GameObjects in your Scene. A cinematic sequence in the Timeline window. For each cut-scene, cinematic, or gameplay sequence, the Timeline window saves the following: Timeline asset: Stores the tracks, clips, and recorded animations without links to the specific GameObjects being animated. The Timeline asset is saved to the Project. Timeline instance: Stores links to the specific GameObjects being animated or affected by the Timeline asset. These links, referred to as bindings, are saved to the Scene. Timeline asset The Timeline window saves track and clip definitions as a Timeline asset. If you record keyframe animation while creating your cinematic, cut-scene, or gameplay sequence, the Timeline window saves the recorded clips as children of the Timeline asset. The Timeline asset saves tracks and clips (A). Timeline window saves recorded clips (B) as children of the Timeline asset. Timeline instance To animate a GameObject in your Scene with a Timeline asset, you must create a Timeline instance. A Timeline instance associates a Timeline asset with the GameObject in the Scene through a Playable Director component. When you select a GameObject in a Scene that has a Playable Director component, the Timeline instance displays in the Timeline window. The bindings display in the Timeline window and in the Playable Director component (Inspector window). The Playable Director component displays the Timeline asset (A) with its bound GameObjects (B). The Timeline window displays the same bindings (B) in the Track list. The Timeline window provides an automated method of creating a Timeline instance while creating a Timeline asset. Reusing Timeline assets Because Timeline assets and Timeline instances are separate, you can reuse the same Timeline asset with many Timeline instances. For example, you could create a Timeline asset named VictoryTL with the animation, music, and particle effects that play when the main game character (Player) wins. To reuse the VictoryTL Timeline asset to animate another game character (Enemy) in the same Scene, you can create another Timeline instance for the secondary game character. The Player GameObject (red) is attached to the VictoryTL Timeline asset The Enemy GameObject (green) is also attached to the VictoryTL Timeline asset Because you are reusing the Timeline asset, any modification to the Timeline asset in the Timeline window results in changes to all Timeline instances associated with this asset. For example, in the previous example, if you delete the Audio track while modifying the Player Timeline instance, the Timeline window removes this track from the VictoryTL Timeline asset. This removes the Audio track from all instances associated with the VictoryTL Timeline asset, including the Enemy Timeline instance."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-play-ctrls.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-play-ctrls.html",
    "title": "Timeline Playback Controls | Inventory System",
    "summary": "Timeline Playback Controls To play the Timeline instance and to control the location of the Timeline Playhead, use the Timeline Playback Controls and the Playhead Location field. Timeline Playback Controls and the Playhead Location field Timeline Start To move the Timeline Playhead to the start of the Timeline instance, click the Timeline Start button, or hold Shift and press Comma (,). Previous Frame To move the Timeline Playhead to the previous frame, click the Previous Frame button, or press Comma (,). Timeline Play To preview the Timeline instance in Timeline Playback mode, click the Timeline Play button, or press the Spacebar. Timeline Playback mode does the following: Begins playback at the current location of the Timeline Playhead and continues to the end of the Timeline instance. If the Play Range toggle is enabled, playback is restricted to a specified time range. The Timeline Playhead moves along the Timeline instance. The Playhead Location field displays the position of the Timeline Playhead in either frames, timecode, or seconds, depending on the Timeline settings. To pause playback, click the Timeline Play button again, or press the Spacebar. When playback reaches the end of the Timeline instance, the Wrap Mode determines whether playback should hold, loop, or do nothing. The Wrap Mode property is in the Playable Director component. Timeline Playback mode provides a preview of the Timeline instance while in the Timeline window. Timeline Playback mode is only a simulation of Play mode in the Game View. The Timeline Playback mode does not support audio playback. To preview a Timeline instance with audio, enable the Play on Awake option in the Playable Director component and preview gameplay in Play mode. Next Frame To move the Timeline Playhead to the next frame, click the Next Frame button, or press Period (.). Timeline End To move the Timeline Playhead to the end of the Timeline instance, click the Timeline End button, or hold Shift and press Period (.). Play Range Enable the Play Range toggle to continuously loop playback within a specific range. You can only set a play range when previewing a Timeline instance within the Timeline window. Unity ignores the play range in Play mode. Play Range enabled with loop points and highlighted area defining range (A) Play Range enabled (B) The Timeline ruler highlights the play range and indicates its start and end with loop points. To modify the play range, drag either border of the play range. Timeline Playhead and Playhead Location field The Timeline Playhead indicates the exact point in time being previewed in the Timeline window. The Playhead Location field expresses the location of the Timeline Playhead in frames, timecode, or seconds. Use the Playhead Location field to move the Timeline Playhead (A) Playhead Location field (B) Timeline Playhead (C) Timeline Playhead on the Zoombar Use the Zoombar to navigate, scroll, and zoom the Content view. A white line indicates the location of the Timeline Playhead in relation to the entire Timeline instance. To jump the Timeline Playhead to a specific time, click the Timeline ruler. You can also enter the time value in the Playhead Location field and press Enter. This value is converted to frames, timecode, or seconds based on the Timeline Options. For example, if the Timeline ruler is expressed as seconds with a frame rate of 30 frames per second, entering 180 in the Playhead Location field converts the value to seconds and moves the Timeline Playhead to 6:00. Use the Timeline Options to set the time format and choose the frame rate."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-preferences.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-preferences.html",
    "title": "Timeline Preferences | Inventory System",
    "summary": "Timeline Preferences Use the Timeline Preferences to choose the Timeline window settings such as the unit of measurement, whether to display audio waveforms, and edge snap settings. The Timeline Preferences are found in the Preferences window. The Timeline Preferences are settings that apply to the Timeline window regardless of the selected Timeline asset or Timeline instance. To open the Timeline Preferences, from the Timeline window, click the Gear button and choose Preferences Page from the Timeline Options menu. The Preferences window opens with Timeline selected. Time Unit Select either Frames, Timecode, or Seconds to set the Timeline window to display time in that format. Timecode displays the time in seconds with sub-second values displayed in frames. Playback Scrolling Mode Use Playback Scrolling Mode to set whether the Content view follows the Timeline Playhead when in Timeline Playback mode. Mode Description None The Content view does not follow the Timeline Playhead. Pan The Content view pans as the Timeline Playhead reaches the edge of the viewable area. Smooth The Content view scrolls while keeping the Timeline Playhead at the center of the Content view and smoothly scrolls the Content view. Show Audio Waveforms Enable Show Audio Waveforms to draw the waveforms for all audio clips on all audio tracks. For example, use an audio waveform as a guide when manually positioning an Audio clip of footsteps with the Animation clip of a humanoid walking. Disable Show Audio Waveform to hide audio waveforms. Show Audio Waveforms is enabled by default. Allow Audio Scrubbing Enable Allow Audio Scrubbing to play audio while dragging the Timeline Playhead. Disable Allow Audio Scrubbing to stop playing audio while dragging the Timeline Playhead. When disabled, Timeline only plays audio when in Timeline Playback mode. Snap to Frame Enable Snap to Frame to manipulate clips, preview Timeline instances, and to drag and position the Timeline Playhead using frames. Disable Snap to Frame to position clips between frames. Snap to Frame is enabled by default. For example, when Snap to Frame is disabled and you drag the Timeline Playhead, it moves the playhead between frames. The format of the Playhead Location field is different depending on whether the Time Unit is set to Frames, Timecode or Seconds: When the Time Unit is set to Frames, the Playhead Location displays frames and subframes. For example, 8 frames and 34 subframes displays as 8.34. When the Time Unit is set to Timecode, the Playhead Location displays seconds, frames, and subframes. For example, 6 seconds, 17 frames, and 59 subframes displays as 6:17 [.59]. When the Time Unit is set to Seconds, the Playhead Location displays seconds. For example, 6.5 seconds displays as 6:50. Manipulating clips, previewing Timeline instances, and positioning the playhead at the subframes level is useful when attempting to synchronize animation and effects with audio. Many high-end audio processing software products create audio waveforms with subframe accuracy. Edge Snap Enable the Edge Snap option to snap clips when you position, trim, and create blends. When enabled, the start or end of a clip snaps when it is dragged within 10 pixels of the following: The Timeline Playhead. The start or end of a clip on the same track or other tracks. The start or end of the Timeline instance itself. The start guide or end guide is redrawn in white to indicate when the clip snaps to the edge of another clip or the Timeline Playhead. Disable Edge Snap to create more accurate blends, ease-ins, or ease-outs and when it is not important to have clips snap to the Timeline Playhead, the start and end of other clips, or the start and end of the Timeline instance itself. Edge Snap is enabled by default. Playback Locked To Frame Enable Playback Locked To Frame to enable frame accurate previewing during playback."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-preview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-preview.html",
    "title": "Timeline Preview toggle | Inventory System",
    "summary": "Timeline Preview toggle The Timeline Preview toggle enables or disables previewing the impact that the selected Timeline instance has on your Scene. The Timeline Preview is toggled on by default. When Preview is toggled off, the following occurs: Timeline preview is disabled when using the Timeline Playback Controls. To preview your Scene, you must use Play Mode. Recording is disabled for all recordable tracks. Play range is disabled in the Timeline Playback Controls and Timeline window. The Stop() method is not called on the PlayableDirector when you switch between different TimelineAsset objects in the TimelineWindow class. When the Scene Preview option is disabled in the Timeline asset Properties, the Preview toggle is unavailable and displays a warning icon. Preview is unavailable (A) because Scene Preview is disabled When you disable the Scene Preview option, if your Timeline instance transforms or modifies GameObjects, these changes are saved to the Scene which could result in unintended changes to scene data. You should only disable the Scene Preview option if you have manually coded a scene data management system that saves, restores, and protects scene data. Enable the Scene Preview option to preview the affect of the Timeline instance on the Scene. When Scene Preview is enabled, the Timeline window also automatically manages and protects the scene and its scene data. It is recommended to always enable the Scene Preview option."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-selector-instance.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-selector-instance.html",
    "title": "Timeline Selector | Inventory System",
    "summary": "Timeline Selector Use the Timeline Selector to select which Timeline instance to view, modify, or preview in the Timeline window. To select a Timeline instance, click the Timeline Selector and choose from the list of Timeline instances in the current Scene. (A) Timeline Selector and menu of Timeline instances. The menu indicates the selected Timeline instance with a checkmark. (B) Timeline title. Each menu item and the Timeline title displays the name of the Timeline asset and its associated GameObject in the current Scene. For example, the Timeline asset named GroundATL is associated with the Ground GameObject. In this case, the Timeline title displays GroundATL (Ground). Sub-Timeline instances When you are editing a Sub-Timeline instance, the Timeline title displays a breadcrumb list of Timeline and Sub-Timeline instances. The Local or Global button indicates whether the Timeline ruler displays local time or global time. (A) Local or Global button. (B) Sub-Timeline instance. Switching between Local and Global time Use the Local or Global button to change the Timeline ruler from global time to local time and back. This option only appears when you are editing a Sub-Timeline instance. Local displays the Timeline ruler relative to the Sub-Timeline Click Local to switch the Timeline ruler to Global time. Global time is relative to the Sub-Timeline's Control clip in the main Timeline instance. For example, if the Control clip is placed at frame 70 on the main Timeline, then the Timeline ruler starts at frame 70 when editing the Sub-Timeline. Global displays the Timeline ruler relative to the main Timeline Click Global to switch the Timeline ruler to Local time. Local time is relative to the Sub-Timeline. This means that the Timeline ruler starts at zero when editing the Sub-Timeline."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-window.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/tl-window.html",
    "title": "Timeline window | Inventory System",
    "summary": "Timeline window Use the Timeline window to visually arrange tracks, clips, and markers to create cut-scenes, cinematics, and gameplay sequences. The Timeline window provides dedicated areas for controlling playback, selecting a Timeline instance, setting Timeline options, managing tracks, adding markers, and managing clips. (A) The Timeline Preview and Timeline Playback Controls. (B) Timeline Selector and instance. (C) Timeline options. (D) The Track List includes the Add (+) menu, the Edit modes, the Timeline Markers toggle, and a Track Header for each track. (E) The Content view includes the Timeline Playhead, Timeline Ruler, and the Zoombar. Accessing the Timeline window To access the Timeline window, go to Window > Sequencing > Timeline. What the Timeline window displays depends on what you select in the Project window, the Hierarchy window, or the Scene view. For example, if you select a GameObject that is associated with a Timeline asset, the Timeline window displays the tracks and clips from the Timeline asset and the GameObject bindings from the Timeline instance. Selecting a GameObject associated with a Timeline asset displays its tracks and clips, and the bindings from the Timeline instance If you haven’t selected a GameObject, the Timeline window informs you that the first step for creating a Timeline asset and a Timeline instance is to select a GameObject. With no GameObject selected, the Timeline window provides instructions If a GameObject is selected and it is not associated with a Timeline asset, the Timeline window provides the option to create a new Timeline asset. This option also adds a Playable Director component to the selected GameObject and creates a Timeline instance. Click Create to create a Timeline asset, a Timeline instance, and add a Playable Director component to the selected GameObject To use the Timeline window to view a previously created Timeline asset, select the Timeline asset in the Project window and open the Timeline window. The Timeline window displays the tracks and clips associated with the Timeline asset, but without the track bindings to GameObjects in the Scene. In addition, the Timeline Playback Controls are disabled and there is no Timeline Playhead. Timeline asset selected in the Project window displays its tracks and clips, but with no track bindings. The Timeline Playback Controls are disabled. The Timeline window saves the track bindings to GameObjects in the Scene with the Timeline instance, not the Timeline asset. Consult the Timeline assets and instances topic for details on the relationship between the Project, Scene, Timeline assets, and Timeline instances. Create Sub-Timelines To create a Sub-Timeline, drag a GameObject associated with a Timeline instance into another Timeline instance. The Timeline instance you are dragging into becomes the parent or main Timeline instance. The Timeline instance associated with the GameObject becomes a Sub-Timeline instance. Drag a GameObject linked to a Timeline instance (BoardTL) into another Timeline instance (NestTL) to create a Sub-Timeline instance as a Control clip on a Control track Edit Sub-Timelines To edit a Sub-Timeline instance, double-click the Control clip that contains the Sub-Timeline instance. The Timeline window switches to the Sub-Timeline instance, indicated by the Timeline title which is the name and GameObject of the parent Timeline instance, followed by the name and GameObject of the Sub-Timeline instance. The Timeline title indicates that you are editing a Sub-Timeline instance When viewing a Sub-Timeline, use the Local or Global button to change the Timeline ruler from local time to global time. The Local or Global button is documented in the Timeline Selector topic since it is related to selecting the Timeline instance."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-add.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-add.html",
    "title": "Add tracks | Inventory System",
    "summary": "Add tracks The Timeline window supports many different methods of adding tracks to the Track list. Depending on the method you choose, the Timeline window may also add track bindings to the Track header, clips to tracks, and components to GameObjects. The simplest method to add a track is to click the Add (+) menu and choose the track to add. You can also right-click an empty area of the Track list to add a track. Add (+) menu Timeline supports adding the following tracks: Activation: Use this track to control when its bound GameObject is active. When you select an Activation track, its track properties appear in the Inspector window. Animation: Use this track to animate GameObjects and humanoids. When you select an Animation track, its track properties appear in the Inspector window. Audio: Use this track to play Audio clips. When you select an Audio track, its track properties appear in the Inspector window. You can also animate Audio track properties with the Curves view. Control: Use this track to schedule a Sub-Timeline or to control a particle system, a prefab, or a script that uses ITimeControl. The Control track itself has no track properties. Instead, a Control track depends on its Control clips. It is recommended to add a Control track by dragging a GameObject into the Content view. Consult About Control clips for more on Control clips and Control tracks. Playable: Use this track to add Playable clips. Each Playable clip is bound to a script that uses the Playables API to create custom animation tools, effects, or gameplay mechanisms. Note that the script must inherit from PlayableAsset to be detected automatically and create a Playable Track. Consult the Tween Track sample for an example of how to create a custom Playable track. Signal: Use this track to schedule Signal Emitters that send signals to its bound GameObject. The bound GameObject must have a Signal Receiver component with a reaction to successfully receive signals and perform a reaction. The Signal track itself has no track properties. Dragging into the Track list Drag a GameObject into an empty area in the Track list and choose the type of track to add from the context menu. Depending on the type of track selected, the Timeline window performs different actions: Select Animation Track and the Timeline window binds the GameObject to the Animation track. If the GameObject doesn't already have an Animator component, the Timeline window creates an Animator component for the GameObject. Select Activation Track and the Timeline window binds the GameObject to the Activation track. There are some limitations when creating an Activation track when dragging a GameObject. For example, the main GameObject with the Playable Director component should not be bound to an Activation track. Because this is the same GameObject that links the Timeline asset to the Scene, activating and disabling the GameObject affects the length of Timeline instance. Select Audio Track and the Timeline window adds an Audio Source component to the GameObject and binds this Audio Source component to the Audio track. Select Signal Track and the Timeline window binds the GameObject to the Signal track. If the GameObject doesn't already have a Signal Receiver component, the Timeline window adds a Signal Receiver component to the GameObject."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-delete.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-delete.html",
    "title": "Delete tracks | Inventory System",
    "summary": "Delete tracks Delete a track to remove its track header, clips, blends, and properties. This is a destructive action that modifies a Timeline asset and affects all Timeline instances based on the Timeline asset. There are many ways to delete a track: Select a track and press the Delete key (MacOS: hold Command and press Delete). In the Track Header, select Delete from the More (⋮) menu. Right-click a track and choose Delete from the context menu. Deleting an Animation track also deletes the recorded Infinite clips for Animation clips that were converted from Infinite clips. The Project window may still display recorded Infinite clips as children of a Timeline asset because it is not updated until you save the Scene or Project. You cannot delete a locked track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-duplicate.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-duplicate.html",
    "title": "Duplicate tracks | Inventory System",
    "summary": "Duplicate tracks Duplicating a track copies its binding, clips, blends, and Inspector properties. Result of duplicating the last track bound to DefaultMale There are many ways to duplicate tracks: Select a track. Right-click an empty area in the Track list and choose Duplicate from the context menu. Select a track. Hold Control (MacOS: Command) and press D. Select a track. Hold Control (MacOS: Command) and press C, for copy, then press V, for paste. Right-click a track and either select Duplicate from the context menu or hold Control (MacOS: Command) and press D."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-groups.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-groups.html",
    "title": "Group tracks | Inventory System",
    "summary": "Group tracks Use Track groups to organize tracks into groups when you are working with many tracks. For example, a Timeline instance has two Animation tracks that animate pieces to set up a game board. You can group these two tracks into a Track group named MovingPieces. A Track group with two Animation tracks (A) Use the foldout (triangle) to collapse or expand the Track group. (B) Track group name. (C) Use the Lock and Mute toggles to lock or mute the tracks in the Track group. (D) Use the Add (+) button to add tracks or sub-groups directly to the Track group. (E) Track headers for the tracks within a Track group are indented. To add a Track group, select the Add (+) menu and choose Track Group. You can also right-click an empty area of the Track list and choose Track Group from the context menu. When you add a Track group, it is added to the bottom of the Track list. Timeline instance with a Track group added to the bottom of the Track list To rename a Track group, click its name. Type the new name for the Track group and press Return. You can also rename a Track group in the Inspector window. To move tracks into a Track group, select one or more tracks and drag over the Track group. When you drag a selection of tracks, the name of the last selected track displays beside the cursor. To drop the tracks before a specific track in a Track group, drag until a white insert line indicates the destination. This is the same as reordering tracks outside a Track group. If you release when the Track group is highlighted, the tracks are moved to the top of the Track group. Collapsing and expanding Track groups To collapse the tracks in a Track group, click the foldout (triangle) beside the name of the Track group. The tracks are collapsed from view in the Timeline window, but are not muted. To expand the tracks in a Track group, click the foldout (triangle) again. When a track group is collapsed, a ghost track visually represents the tracks in the Track group. You can also press the Left arrow key to collapse the tracks in a Track group while the Track group is selected. Press the Right Arrow key to expand the tracks in a Track group. If you press the Right Arrow key with a Track group already selected, the selection switches to the first selectable clip on the first track in the Track group. Locking and muting Track groups Lock a Track group to prevent editing its sub-groups, tracks, and clips. Mute a Track group to hide the effect its sub-groups, tracks, and clips have on your scene. A Track group can be both locked and muted. A locked Track group has the message Locked with its Lock toggle enabled. A muted Track group has the message Muted with its Mute toggle enabled. There are many ways to lock and unlock a Track group: Enable the Lock toggle in the Track group. Select a Track group and press L. You can select and lock or unlock multiple Track groups and tracks at a time. Right-click a selected Track group and choose Lock or Unlock from the context menu. There are many ways to mute a Track group: Enable the Mute button in the Track header. Select a track and press M. You can select and mute or unmute multiple Track groups and tracks at a time. Right-click a selected Track group and choose Mute or Unmute from the context menu. Tracks in a Track group maintain their individual locked and muted states when you lock a Track group. This means that if you lock or mute a track and then lock or mute its Track group, when you unlock or unmute the Track group, the track remains locked or muted. For example, the MovingPieces Track group has its first track locked and its second track unlocked. If you lock the Track group, both the first and second track are locked. If you unlock the Track group, the first track remains locked and the second track is unlocked because the first track was locked before the Track group was locked. MovingPieces Track group is unlocked but its first track remains locked because it was locked before the Track group was locked. Adding Track sub-groups A Track group can have any number of Track sub-groups. There are many ways to add a Track sub-group: Select a Track group, click the Add (+) menu in the Track list, and choose Track Sub-Group. Click the Add (+) button beside the Track group name, and choose Track Sub-Group. You can also use this menu to add tracks directly to a Track group or a Track sub-group. Click the Add (+) button to add tracks and sub-groups directly to the Track group. Tracks and sub-groups are added to the bottom of the Track group."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-header.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-header.html",
    "title": "Track header | Inventory System",
    "summary": "Track header When a Timeline asset is selected, use the Track Header to rename a track, display the Curves view for an Audio track, or lock and mute a track. When a GameObject with a Timeline instance is selected, use the Track Header to set the track binding or rename a track, enable an Avatar mask, display the Curves view, record keyframe animation, display Track markers, or lock and mute a track. Track Header for an Animation track when a GameObject with a Timeline instance is selected (A) The colored accent and icon provides track information and indicates track errors or warnings. (B) The Track name or its binding (C) Use the Avatar Mask, Curves View, and Record toggle to enable masking between Animation tracks, display and edit animation curves for Animation clips or Audio tracks, and to record basic animation. (D) Enable the Track Markers toggle to expand the size of markers on the track and to make the markers selectable. Disable the Track Markers toggle to collapse markers and make them unselectable. (E) Use the Lock and Mute toggles to lock and mute tracks. (F) More (⋮) menu Colored accent and icon Each Track header has a colored accent that identifies the track type and its clips: Activation tracks are green. Use Activation tracks to add Activation clips which set when the bound GameObject is active. The GameObject is bound to the Activation track. Animation tracks are blue. Use Animation tracks to add Animation clips that animate the bound GameObject. Use an Animation track and its Animation clips to record basic animation or animate a humanoid. Audio tracks are orange. Use Audio tracks to add Audio clips for playing background music or sound effects. Each Audio clip is bound to an audio waveform. The audio source, that plays each waveform, is bound to the Audio track. Control tracks are turquoise. Use Control tracks to add Control clips which are special clips that control a Sub-Timeline instance, Particle System, Prefab instance, or ITimeControl Script. How the Control clip is created determines what it controls. Playable tracks are white. Use Playable tracks to add Playable clips. Each Playable clip is bound to a script that uses the Playables API to create custom animation tools, effects or gameplay mechanisms. Each Track header is also identified by an icon. If a track has a binding error, its bound GameObject is disabled, or another track related error occurs, then this icon switches to an error or warning icon. Hovering over this icon displays an error or warning message. For example, if an Animation track is bound to a disabled GameObject, the icon switches to an alert icon. An alert icon indicates that the RedCube bound GameObject is disabled. Hover over the icon to view an explanation of the warning. Track name or binding When a Timeline instance is selected, depending on the type of track, the Track header displays either the track name or the track binding. To rename a track that has a track name, click the track name, type the new name and press Return. You can also rename tracks in the Inspector window when setting track properties. To select or change a track binding, click the picker (circle) to choose from the list of GameObjects in your Scene. This list only includes GameObjects that have an Animator component. To view the GameObject that is bound to a track, click the track binding and the linked GameObject is indicated in the Hierarchy view. Track bindings are saved to the Playable Director component associated with the GameObject that is linked to the Timeline asset. For more information on the relationship between Timeline assets and Timeline instances, consult the Timeline assets and instances topic."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-list-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-list-overview.html",
    "title": "Track list | Inventory System",
    "summary": "Track list Use the Track list to add, select, duplicate, delete, lock, mute, and reorder the tracks of a Timeline asset or Timeline instance. (A) Use the Add (+) button to add tracks and Track Groups. (B) Select an Edit mode to choose how clips and markers interact with each other when you add, position, trim, or resize them in the Content view. (C) Use the Timeline Markers toggle to expand and collapse the Timeline marker track. Use the Timeline marker track, and other dedicated marker tracks, to add and manage markers and signals. (D) The Track list displays a Track header for each track in the Timeline instance or Timeline Asset. The options available for each Track Header depends on the type of track. The remainder of this section includes topics on how to add, select, duplicate, reorder, group, delete, lock, and mute tracks."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-lock-mute.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-lock-mute.html",
    "title": "Lock and mute tracks | Inventory System",
    "summary": "Lock and mute tracks Lock a track to prevent editing the track or its contents. Mute a track to hide the effect its signals and clips have on your scene. A track can be both locked and muted. For example, you can lock an Animation track when you have finished creating a cut-scene and you want to avoid inadvertently modifying its Animation clips. You can mute an Audio track if you want to stop its audio from playing while you edit other tracks and clips in your Timeline instance. A muted track and a locked track (A) An enabled Lock toggle identifies a locked track. (B) A locked track has the message Locked. You cannot select, edit, or delete a locked track or its contents. (C) An enabled Mute toggle identifies a muted track. (D) A muted track has the message Muted. You can select, edit, and delete a muted track and its contents. There are many ways to lock or unlock a track: Enable the Lock toggle in the Track header. Select a track and press L. You can select and lock or unlock multiple tracks at a time. Right-click a selected track and choose Lock or Unlock from the context menu. There are many ways to mute or unmute a track: Enable the Mute toggle in the Track header. Select a track and press M. You can select and mute or unmute multiple tracks at a time. Right-click a selected track and choose Mute or Unmute from the context menu."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-reorder.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-reorder.html",
    "title": "Reorder tracks and animation priority | Inventory System",
    "summary": "Reorder tracks and animation priority To reorder tracks, select one or more tracks and drag until a white insert line appears between tracks in the Track list. The white insert line indicates the destination of the tracks you are dragging. The name of the last selected track displays beside the cursor. The white insert line (A) indicates the destination of the track named Storm (B) Animation Priority In the Timeline window, the animation priority is from the first track to the last track, where the last track has priority. When you reorder tracks, it is important to understand the animation priority. For example, a Timeline instance has four Animation tracks, where the second and fourth Animation tracks animate the same GameObject. The fourth track overrides the animation on the preceding tracks. The second track and fourth track animate the same GameObject (GreenCube). The fourth track has priority and overrides the second track. The example above uses Animation tracks but animation priority applies to any track that uses the same GameObject and Animator as another track. For example, a Control track has a Control clip with a Sub-Timeline. This Sub-Timeline includes an Animation track that animates the same GameObject as an Animation track on the main Timeline. According to the animation priority, whichever track is last in the main Timeline takes priority. Reordering Animation Override tracks The first to last animation priority is why an Animation Override track is added after the Animation track being overridden: because the Animation Override track overrides the animation on the preceding track. An Animation Override track is bound to the same GameObject as its parent Animation track. If you reorder an Animation Override track without selecting its parent Animation track, the binding of the Animation Override track is set to none and the track becomes an Animation track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-select.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/trk-select.html",
    "title": "Select tracks | Inventory System",
    "summary": "Select tracks To select a single track, click its Track header in the Track list. You can also click an empty area in the Content view. When you select a track, Timeline highlights its Track header and Content view. Selecting a track deselects all other tracks or clips. Selecting a track also shows its properties in the Inspector window. The track properties change depending on the type of track and how many tracks you select. To select contiguous tracks, select the first track and then hold Shift and click the last track in the series. For example, to select three contiguous tracks, click the first track, then hold Shift and click the third track. All three tracks are selected. Click to select the first track Hold Shift and click to select contiguous tracks Hold Control (MacOS: Command) and click to select discontiguous tracks. Hold Control (MacOS: Command) and click to deselect a selected track. There are many other ways to select tracks: Hold Shift and press the Up arrow key or Down arrow key to add and remove tracks from the selection. To deselect all tracks or clips, click on an empty area in either the Track list or Content view. When a clip is selected on a track, press Tab to select the track. Use the arrow keys to change the selected track. The Up and Down arrow keys select the previous or next track. The Right arrow key selects the first clip on the track. If a Track group is selected, the Left arrow and Right arrow keys collapse and expand the Track group."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-anim-human.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-anim-human.html",
    "title": "Animate a humanoid | Inventory System",
    "summary": "Animate a humanoid This workflow demonstrates how to use a Timeline instance to animate a humanoid model so that it turns left and begins to walk. Although this workflow uses a humanoid, you can use this animation method for any GameObject. This workflow uses the humanoid model named DefaultMale and animation source assets from the Gameplay Sequence sample for its examples. Consult Timeline Samples for information on the samples available from the Timeline package and how to import these samples into your projects. This workflow starts with a Timeline instance that has an empty Animation track bound to the DefaultMale humanoid model. The DefaultMale humanoid model linked to a Timeline instance (HumanTL) with an empty Animation track bound to the same model While animating the humanoid model, this workflow demonstrates how to do the following: Add and position Animation clips. Match clip offsets. Create blends between clips. Manually adjust clip offsets to reduce foot sliding. Add and position Animation clips From your Project, drag an animation source asset into the Animation track to add a new Animation clip. Dragging a source asset adds an Animation clip on the same track. The duration of the Animation clip matches the source asset. To position, resize, or trim the Animation clip in the Content view, select Mix mode as the Edit mode. There are three Edit modes that affect the editing behavior of the Timeline window. When the Timeline window is in Mix mode, you can drag to position, trim, and blend clips. You can also select an Animation clip to modify its Animation clip properties, including its Start, End, and Duration, in the Inspector window. The Mix mode (red) is the selected Edit mode. The TurnLeft clip is positioned to start at frame 0. Add a second Animation clip. This workflow adds a walk clip (Walk), positions the clip so it starts immediately after the first clip, and it resizes the second clip to include one loop. Animation track with the TurnLeft and Walk Animation clips Play the Timeline instance. In this example, the DefaultMale animation jumps between each Animation clip because its position and rotation at the end of each clip does not match the position and rotation at the start of the next Animation clip. The DefaultMale jumps between the TurnLeft Animation clip, which ends at frame 105 (A), and the Walk Animation clip, ghost model which starts at frame 106 (B) Match clip offsets To fix animation jumping between clips, match the offset of each Animation clip. The Timeline window provides different methods for matching offsets. This workflow demonstrates how to match an Animation clip with the previous clip. In this workflow, to match the TurnLeft clip with the previous clip, follow these steps: Select the TurnLeft clip. Right-click the selected clip and choose Match Offsets to Previous Clip from the context menu. The position and rotation of the humanoid at the start of the second Animation clip (Walk) matches the position and rotation of the humanoid at the end of the first Animation clip. The ghosted DefaultMale at the start of the Walk Animation clip, which starts at frame 106 (B), matches the position and rotation of the DefaultMale at the end of the TurnLeft Animation clip, which ends at frame 105 (A) Play the Timeline instance again. Although the position and rotation of the humanoid matches, there is still a jump between the two Animation clips because the humanoid is in different poses: At the end of the TurnLeft Animation clip, the feet are on the ground and the arms are slightly raised. At the start of the Walk Animation clip, the left leg is off the ground and the arms are in a relaxed position. To remove the jump and to transition between these two poses, you can create a blend. Create blends between clips Create a blend to seamlessly mix between two different animations or poses. The Timeline window includes many different ways to create a blend between Animation clips. To create a blend, move an Animation clip until it overlaps another Animation clip. You might need to adjust the size of the Animation clips, the Blend Area, the Clip In value, and the shape of each Blend Curve to create a smoother transition between the two poses. For example, in the transition between the TurnLeft clip and the Walk clip, the Walk clip was repositioned to start at frame 83. The rest of the clip properties are unchanged from their default values. Overlap two clips to create a smooth transition between two Animation clips As the TurnLeft clip transitions to the Walk clip, the blend removes the obvious jump between poses. The transition between most body parts appears natural, however in this case, the blend between the different positions of the foot results in an unnatural slide. Reduce foot sliding To reduce foot sliding, manually adjust the offset of an Animation clip so that the position of the foot changes less drastically. To manually adjust the offset, follow these steps: Select the Animation clip in the Timeline window and, in the Inspector window, expand Animation Playable Asset. The Animation Playable Asset properties include the Clip Transform Offsets In this example, the X Position. Z Position, and Y Rotation of the Clip Transform Offsets for the Walk Animation clip is not zero because a Match Offsets to Previous Clip was performed earlier in this workflow. Match to a previous clip sets these values to match the root of the humanoid at the end of the previous Animation clip. With the Animation clip selected, use one of the following methods: In the Inspector window, under Clip Transform Offsets, change the value of the appropriate Position property. In the Inspector window, under Clip Transform Offsets, enable the Move tool. The Move Gizmo appears in the Scene view at the root of the Animation clip. In the Scene view, drag the Move Gizmo. Enable the Move tool (A) to view the Move Gizmo (B)"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-anim-override.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-anim-override.html",
    "title": "Override upper-body animation | Inventory System",
    "summary": "Override upper-body animation This workflow demonstrates how to use an Animation Override track and an Avatar Mask to replace the upper-body animation of an Animation track. For example, you can use this technique to animate a humanoid to walk while celebrating a victory. This workflow uses the humanoid model named DefaultMale and animation source assets from the Gameplay Sequence sample for its examples. Consult Timeline Samples for information on the samples available from the Timeline package and how to import these samples into your projects. This workflow starts with a Timeline instance that has an Animation track bound to the DefaultMale humanoid model. The Animation track has a single Animation clip that starts at frame 0 and loops twice for a duration of 216 frames. The DefaultMale humanoid model linked to a Timeline instance (OverrideTL) with an Animation track bound to the same model (DefaultMale) with a Walk Animation clip that loops twice. In this workflow, to add an Animation Override track and override the upper-body animation, follow these steps: In the Track Header for the Animation track, click the More (⋮) menu and choose Add Override Track. An Animation Override track, named Override 0, is linked to the selected Animation track. Notice that the Animation Override track is not bound to a GameObject. Because the Animation Override track is linked to the Animation track above, the Override track is bound to the same GameObject: the DefaultMale humanoid. Animation track with an Animation Override track. The More (⋮) menu icon is indicated in red. From your Project, drag an animation source asset with upper-body animation into the Override track. This workflow uses the Vct_Dnc_anim1 animation source asset from the Gameplay Sequence sample. Position and resize the clip to choose the upper-body animation to combine with the Walk clip. The Animation clip on the Override track should also match the size of Walk clip. The Animation Override track contains a trimmed part of the full Vct_Dnc_anim1 animation source asset (frames 630 to 846). This clip was also positioned and resized to match the Animation clip (Walk) on the parent Animation track. Play the Timeline instance. The victory dance clip, Vct_Dnc_anim1, completely overrides the Walk clip. To combine the lower-body animation from one Animation clip with the upper-body animation from the Animation Override clip, you must specify an Avatar Mask for the Animation Override track. To specify an Avatar Mask, select the Override track to view its track properties in the Inspector window. The track properties for an Animation Override track are the same as an Animation track In the Inspector window, specify an Avatar Mask that masks the lower body animation for the Avatar Mask property. If you do not have an Avatar Mask that masks the lower body, consult Avatar Mask window for information on how to create one. Once you have specified a lower body Avatar Mask, select the mask and enable the Apply Avatar Mask checkbox. An Avatar Mask toggle appears beside the Override track name. In the track header, the enabled Avatar Mask indicates that the Animation Override track uses an Avatar Mask. Play the Timeline instance. In this example, the DefaultMale humanoid uses upper-body animation from the Vct_Dnc_anim1 clip and the lower body animation from the Walk clip. To temporarily disable the Avatar Mask, toggle the Avatar Mask toggle off. This is the same as disabling the Apply Avatar Mask checkbox in the Inspector window."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-convert-infinite.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-convert-infinite.html",
    "title": "Convert an Infinite clip | Inventory System",
    "summary": "Convert an Infinite clip When you record animation to an Animation track in the Timeline window, it creates an Infinite clip. An Infinite clip cannot be positioned, trimmed, or split because it does not have a defined duration. An Infinite clip appears as a dope sheet. To position, trim, split, or perform other clip manipulations on an Infinite clip, you must first convert it to an Animation clip. Once you convert an Infinite clip to an Animation clip, you cannot convert it back to an Infinite clip. To convert an Infinite clip to an Animation clip, in the Track Header of the track with the Infinite clip, click the More (⋮) menu and choose Convert to Clip Track. Each Track Header has a Track menu You can also right-click the track and choose Convert to Clip Track from the context menu. The More (⋮) menu and context menu are similar. An infinite clip after it has been converted to an Animation clip"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-create-instance.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-create-instance.html",
    "title": "Create a Timeline asset and Timeline instance | Inventory System",
    "summary": "Create a Timeline asset and Timeline instance To use a Timeline asset in your Scene, you must associate the Timeline asset with a GameObject using a Playable Director component. Associating a Timeline asset with a Playable Director component creates a Timeline instance and allows you to specify which objects in the Scene are animated by the Timeline asset. Timeline window with Create The Timeline window automatically creates a Timeline instance while creating a new Timeline asset. The Timeline window also adds the necessary components. To create a new Timeline asset and Timeline instance, follow these steps: In your Scene, select the GameObject that you want to use as the focus of your cinematic or other gameplay-based sequence. Open the Timeline window (menu: Window > Sequencing > Timeline). If the GameObject does not have a Playable Director component attached to a Timeline asset, a message in the Timeline window prompts you to click Create. Click Create. A dialog box prompts you for the name and location of the Timeline asset you are creating. You can also specify tags to identify the Timeline asset. Click Save. The Timeline window saves a new Timeline asset to the Assets directory of your Project. If you did not change the name and location of the Timeline asset you are creating, the Timeline window creates a name based on the selected GameObject with the Timeline suffix. For example, selecting the GameObject called RedSphere names the Asset RedSphereTimeline. Timeline asset named RedSphereTimeline created for the RedSphere GameObject and opened in the Timeline window Timeline also adds a Playable Director component to the selected GameObject, and sets the Playable property to the Timeline asset. The link between the GameObject and the Timeline asset is a Timeline instance. Playable Director component added to the GameObject named RedSphere"
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-custom-marker.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-custom-marker.html",
    "title": "Create a custom marker | Inventory System",
    "summary": "Create a custom marker This workflow demonstrates how to create a custom marker that you can use to add notes to your Timeline instance. This workflow also demonstrates how to change the default appearance of a custom marker with scripting and a Unity Style Sheet (USS). If you are unfamiliar with markers and signals, it is recommended that you follow the markers and signals workflow before this workflow. The custom marker created in this workflow is a simplified version of the custom Annotation marker found in the Customization Samples sample. Consult Timeline Samples for information on the available Timeline samples and how to import them into your projects. To demonstrate how to create a custom marker, this workflow is divided into the following main tasks: Set up the Timeline instance. Add folders for scripts and files. Create a Notes marker with custom properties. Add a line overlay. Customize the marker's appearance with USS. Add a marker overlay. Override the default tooltip. Check your scripts. Add more features. Set up the Timeline instance The examples in this workflow use the Timeline instance named NotesTL which has a single Animation track bound to the DefaultMale model. The content of this Animation track is the result of following the Animate a humanoid workflow. The NotesTL Timeline instance before creating a custom marker It is not necessary to create the same Timeline instance shown in this workflow. You can use any Timeline instance to follow this workflow. Add folders for scripts and files In a Unity project, you store scripts, images, and other supporting files in the Assets folder. You can keep the Assets folder organized by adding additional folders and sub-folders. To ensure that some scripts, images, and assets are recognized by the Unity Editor, some folders must have specific names, be placed in a specific folder structure, or both. To organize the Assets folder and create a recognized folder structure, follow these steps: In the Project view, right-click the Assets folder and choose Create > Folder from the context menu. Name this new folder Notes. This folder will store the scripts, assets, and images for overriding the default marker behavior and appearance. In the Notes folder, add a new folder and name it Editor. This folder will store a custom script that overrides the default marker behavior and creates a custom editor. This folder must be named Editor. In the Editor folder, add a new folder and name it Stylesheets. In the Stylesheets folder, add two new folders. Name one folder Extensions and the other Resources. The Extensions folder will store a Unity Style Sheet. This file must be in the path Editor/Stylesheets/Extensions to be recognized. The Resources folder will store the image resource files used by the Unity Style Sheet. Resource images must be in the path Editor/Stylesheets/Resources to be recognized. Project window with the Notes folder and its paths expanded. Create a Notes marker with custom properties To create a custom Notes marker with custom properties, you must write a script with a class that inherits from the Marker class. To do this, follow these steps: In the Project window, right-click the Notes folder and choose Create > C# Script from the context menu. This adds a NewBehaviourScript file to the Notes folder. Rename the file NotesMarker.cs. For Unity to recognize this script, the file name must match the class name. Select the NotesMarker file in the Notes folder and choose Open in the Inspector window. The NotesMarker script opens for editing in your External Script Editor. In your script editor, replace the contents of the NotesMarker file with the following: using System.ComponentModel; using UnityEngine; using UnityEngine.Timeline; public class NotesMarker : Marker { public string title = \"empty\"; public Color color = new Color(1.0f, 1.0f, 1.0f, 0.5f); public bool showLineOverlay = false; [TextArea(10, 15)] public string note; } Save the script and switch to the Unity Editor. When you save a script and switch to the Unity Editor, it recompiles the script and checks for errors or warnings. If found, errors and warnings are written to the Console window. To view the Console window, select Window > General > Console. When the script is corrected and recompiled, you can add the Notes marker to your Timeline instance. For example, to add the custom Notes marker to the expanded Timeline Marker track, right-click on the Marker track and select Add Notes Marker from the context menu. Notes marker added to the Marker track. The Notes marker has the same appearance as the default marker. The added marker is selected and its custom properties display in the Inspector window. Modifying the custom properties does not affect the selected marker. Except for the Time property, the Notes marker properties are not connected to the selected marker For example, if you enable Show Line Overlay, a line overlay is not drawn. If you change the Color property, the color of the selected Notes marker does not change. More scripting is necessary before modifying a custom property in the Inspector window affects the selected Notes marker. Add a line overlay For the custom properties in the Inspector window to affect the selected Notes marker, you must write a script with a class that inherits from the MarkerEditor class. The MarkerEditor class is similar to a custom Inspector. You override methods in the MarkerEditor class to perform actions such as drawing a colored line overlay. To do this, follow these steps: In the Project window, right-click the Editor folder and choose Create > C# Script from the context menu. Name the script NotesMarkerEditor.cs. Select the NotesMarkerEditor file in the Editor folder and choose Open in the Inspector window to open this file for editing. In the script editor, replace the contents of the NotesMarkerEditor.cs file with the following code snippet: using System; using UnityEditor; using UnityEditor.Timeline; using UnityEngine; using UnityEngine.Timeline; // Editor used by the Timeline window to customize the appearance of a NotesMarker [CustomTimelineEditor(typeof(NotesMarker))] public class NotesMarkerEditor : MarkerEditor { // Set a constant for the transparency of overlays const float k_OverlayAlpha = 0.5f; // Override this method to draw a vertical line over the Timeline window's contents. public override void DrawOverlay(IMarker marker, MarkerUIStates uiState, MarkerOverlayRegion region) { // Check if marker is not NotesMarker. Set notes as local variable. if (marker is not NotesMarker notes) { return; // If not, return without drawing an overlay } // If NotesMarker, check if Show Line Overlay property is true if (notes.showLineOverlay) { DrawLineOverlay(notes.color, region); // if Show Line Overlay is true, call function to draw vertical line } } static void DrawLineOverlay(Color color, MarkerOverlayRegion region) { // Calculate a rectangle that uses the full timeline region's height and marker width Rect overlayLineRect = new Rect(region.markerRegion.x, region.timelineRegion.y, region.markerRegion.width, region.timelineRegion.height); // Set the color with an extra alpha value adjustment, then draw the rectangle Color overlayLineColor = new Color(color.r, color.g, color.b, color.a * k_OverlayAlpha); EditorGUI.DrawRect(overlayLineRect, overlayLineColor); } } In the NotesMarkerEditor script, the CustomTimelineEditor attribute associates NotesMarker with the NotesMarkerEditor. The NotesMarkerEditor script overrides the DrawOverlay method. This overridden method checks the type of marker. If the marker is not a NotesMarker, the method returns without drawing an overlay. If the marker is a NotesMarker and the notes.showLineOverlay property is true, the DrawOverlay method calls the DrawLineOverlay method. The DrawLineOverlay method draws a colored line overlay based on the notes.color property and MarkerOverlayRegion. This region includes two sub-regions that you can use to calculate the rectangle for the line overlay: markerRegion: The region of the marker. You can use this rectangle to draw directly on the marker itself. timelineRegion: The region of the Content view in the Timeline window. The height of the Timeline window is derived from region.timelineRegion.y. Save the script, switch to the Unity Editor, and correct any errors or warnings. Errors and warnings are written to the Console window. To view the Console window, select Window > General > Console. In the Timeline window, select the Notes marker on frame 30. In the Inspector window, enable Show Line Overlay and modify the Color property to change the color overlay from white to red. Notes marker at frame 30 is drawn with a red line overlay. Customize the marker's appearance with USS When you create a custom marker, it uses the same images as the default Signal Emitter marker. This makes it difficult to visually distinguish a custom marker from a default marker. In this workflow, the Notes marker uses the same images as the default Signal Emitter marker. To change the appearance of the Notes marker, you can use a Unity Stylesheet (USS). Before creating the USS file, you should have an image for each state of the Notes marker. This workflow uses three states: collapsed, expanded, and selected. The following table provides an image for each Notes marker state: Image/State Description collapsed The notes_collapsed.png image displays when the Notes marker is collapsed. expanded The notes_expanded.png image displays when the Notes marker is expanded but not selected. selected The notes_selected.png image displays when the Notes marker is expanded and selected. To modify the Notes marker to use these images, follow these steps: Copy the three images from the table above to the Assets/Notes/Editor/Stylesheets/Resources folder. These images must be located in the Resources folder to be recognized by the USS file. In the Project window, right-click the Extensions folder in the Assets/Notes/Editor/Stylesheets path and choose Create > UI Toolkit > Style Sheet from the context menu. A NewUSSFile.uss is created in the Extensions folder. Rename the NewUSSFile file as common. This USS file must be named common.uss and must be saved in the Editor/Stylesheets/Extensions path for it to be recognized by Unity. Select the common USS file in the Extensions folder and choose Open in the Inspector window. The common.uss file opens for editing in your External Script Editor. In the script editor, replace the contents of the common.uss file with the following: /* Custom USS stylesheet. */ /* NotesMarker uses this style and image when marker is collapsed.*/ .NotesStyle { width:16px; height:16px; background-image: resource(\"notes_collapsed\"); } /* NotesMarker uses this style and image when the marker is selected.*/ .NotesStyle:hover:focus:checked { background-image: resource(\"notes_selected\"); } /* NotesMarker uses this style and image when the marker is not selected.*/ .NotesStyle:checked { background-image: resource(\"notes_expanded\"); } USS styles support pseudo-states, which are similar to pseudo-classes in CSS. Timeline markers use pseudo-states to set its image depending on whether the marker is collapsed, expanded, or selected: Collapsed: no pseudo-state Expanded: checked pseudo-state Selected: combination hover:focus:checked pseudo-states The common.uss file defines USS styles for both the light and dark Editor Theme. If you want to define specific styles for the Unity light and dark themes, in the same folder as the common.uss file, add the light.uss and dark.uss style sheets. The styles defined in these USS files will override styles in the common.uss file. To associate the Notes marker with the custom NotesStyle style, add the CustomStyle attribute to the NotesMaker script. Add the attribute to the script before the class definition: ... [CustomStyle(\"NotesStyle\")] public class NotesMarker : Marker { ... } Save the NotesMarker script, switch to the Unity Editor, and correct any errors or warnings. Errors and warnings are written to the Console window. To view the Console window, select Window > General > Console. When the script is corrected and recompiled, the appearance of each Notes marker changes depending on whether the marker is selected, not selected, or collapsed: (A) The Notes marker at frame 30 is selected. (B) The Notes marker at frame 60 is not selected. (C) The Notes markers at frames 90 and 150, on the Animation track, are collapsed. Add a marker overlay At this point in the workflow, the Notes marker uses custom images and uses the Color property when the Show Line Overlay property is enabled. The Color property is not used when the Show Line Overlay is disabled. To use the Color property to add color to the Notes marker in all states, expand the conditional statement for the Show Line Overlay property to include a draw marker overlay method. This method draws an overlay for the size of the Notes marker. To do this, follow these steps: Select the NotesMarkerEditor script in the Assets/Notes/Editor folder and choose Open in the Inspector window. This script opens for editing in your External Script Editor. In the NotesMarkerEditor script, expand the if statement to include an else statement which calls a new function named DrawMarkerOverlay: // If NotesMarker, check if Show Line Overlay is true if (notes.showLineOverlay) { DrawLineOverlay(notes.color, region); // if Show Line Overlay is true, draw vertical line } else // If NotesMarker and Show Line Overlay is false, draw marker overlay { DrawMarkerOverlay(notes.color, region, uiState); } If the marker is a NotesMarker and the notes.showLineOverlay property is false, the DrawOverlay method calls the DrawMarkerOverlay function. The DrawMarkerOverlay function is similar to DrawLineOverlay except an additional parameter is included to check the UI state of the Notes marker. In the NotesMarkerEditor script, after the DrawLineOverlay function, add the new DrawMarkerOverlay function: static void DrawMarkerOverlay(Color color, MarkerOverlayRegion region, MarkerUIStates state) { // By default, set the height to the markerRegion's height float markerHeight = region.markerRegion.height; // If marker is collapsed, set the height to 2/3 the markerRegion's height if (state.HasFlag(MarkerUIStates.Collapsed)) { markerHeight = region.markerRegion.height / 1.5f; } // Calculate a rectangle that uses the marker region and variable markerHeight Rect overlayMarkerRect = new Rect(region.markerRegion.x, region.markerRegion.y, region.markerRegion.width, markerHeight); Color overlayMarkerColor = new Color(color.r, color.g, color.b, color.a * k_OverlayAlpha); EditorGUI.DrawRect(overlayMarkerRect, overlayMarkerColor); } The DrawMarkerOverlay function draws a colored rectangle based on the notes.color property and the MarkerOverlayRegion. The function uses the markerRegion region and the UI state to calculate the size of the overlay. For example, if the Notes marker is collapsed (state.HasFlag(MarkerUIStates.Collapsed)) then the rectangle is set to two-thirds the height of the marker region. This matches the height of the notes_collapsed.png file. When the Notes marker is not collapsed, the marker overlay uses the full height of the Notes marker. Save the NotesMarkerEditor script, switch to the Unity Editor, and correct any errors or warnings. Errors and warnings are written to the Console window. To view the Console window, select Window > General > Console. After the script is corrected and recompiled, each Notes marker is drawn using its Color property. For example, if (A) The Notes marker at frame 30 is red. (B) The Notes marker at frame 60 is green. (C) The Notes markers at frames 90 and 150, on the Animation track, are collapsed and blue. Override the default tooltip A tooltip is a brief two or three sentence description that displays when you hover the cursor over an interface element such as a property name, a button, or an option. If you hover the cursor over the default Timeline marker, the tooltip displays the name of its Signal asset. Because the custom Notes marker does not emit a signal, when you hover over the Notes marker, nothing displays. You can override the MarkerDrawOptions function in the NotesMarkerEditor script to use the tooltip to display the title of the Notes marker. To do this, follow these steps: In the Project window, select the NotesMarkerEditor script in the Assets/Notes/Editor folder and choose Open in the Inspector window. The script opens for editing in your External Script Editor. Override the GetMarkerOptions method by inserting the following code snippet after the const float k_OverlayAlpha = 0.5f assignment: // Use MarkerDrawOptions to override the marker's tooltip if the marker is of type NotesMarker. public override MarkerDrawOptions GetMarkerOptions(IMarker marker) { // Check if marker is not NotesMarker and assign it to notes if (marker is not NotesMarker notes) { return base.GetMarkerOptions(marker); // If not, return with no tooltip override } return new MarkerDrawOptions { tooltip = notes.title }; // If NotesMarker, replace tooltip with contents of notes.title } The GetMarkerOptions method provides information about the marker through the MarkerEditor class. Save the NotesMarkerEditor script, switch to the Unity Editor, and correct any errors or warnings. Errors and warnings are written to the Console window. To view the Console window, select Window > General > Console. After the script is corrected and recompiled, when you hover over a Notes marker, the title of the Notes marker displays as a tooltip. By default, each Notes marker tooltip displays \"empty\". You can change the default title in the NotesMarker script. The tooltip also displays for collapsed Notes markers. Check your scripts This topic provides the complete scripts that you created and modified during this workflow. Use these listings to ensure that you have entered and edited the following scripts correctly: NotesMarker script. NotesMarkerEditor script. Use these listings to ensure that your NotesMarker script The complete NotesMarker.cs script: using System.ComponentModel; using UnityEngine; using UnityEngine.Timeline; [CustomStyle(\"NotesStyle\")] public class NotesMarker : Marker { public string title = \"empty\"; public Color color = new Color(1.0f, 1.0f, 1.0f, 0.5f); public bool showLineOverlay = false; [TextArea(10, 15)] public string note; } NotesMarkerEditor script The complete NotesMarkerEditor.cs file: using System; using UnityEditor; using UnityEditor.Timeline; using UnityEngine; using UnityEngine.Timeline; // Editor used by the Timeline window to customize the appearance of a NotesMarker [CustomTimelineEditor(typeof(NotesMarker))] public class NotesMarkerEditor : MarkerEditor { // Set a constant for the transparency of overlays const float k_OverlayAlpha = 0.5f; // Use MarkerDrawOptions to override the marker's tooltip if the marker is of type NotesMarker. public override MarkerDrawOptions GetMarkerOptions(IMarker marker) { // Check if marker is not NotesMarker and assign it to notes if (marker is not NotesMarker notes) { return base.GetMarkerOptions(marker); // If not, return with no tooltip override } return new MarkerDrawOptions { tooltip = notes.title }; // If NotesMarker, replace tooltip with contents of notes.title } // Override this method to draw a vertical line over the Timeline window's contents. public override void DrawOverlay(IMarker marker, MarkerUIStates uiState, MarkerOverlayRegion region) { // Check if marker is not NotesMarker. Set notes as local variable. if (marker is not NotesMarker notes) { return; // If not, return without drawing an overlay } // If NotesMarker, check if Show Line Overlay property is true if (notes.showLineOverlay) { DrawLineOverlay(notes.color, region); // if Show Line Overlay is true, call function to draw vertical line } else // If NotesMarker and Show Line Overlay is false, draw marker overlay { DrawMarkerOverlay(notes.color, region, uiState); } } static void DrawLineOverlay(Color color, MarkerOverlayRegion region) { // Calculate a rectangle that uses the full timeline region's height and marker width Rect overlayLineRect = new Rect(region.markerRegion.x, region.timelineRegion.y, region.markerRegion.width, region.timelineRegion.height); // Set the color with an extra alpha value adjustment, then draw the rectangle Color overlayLineColor = new Color(color.r, color.g, color.b, color.a * k_OverlayAlpha); EditorGUI.DrawRect(overlayLineRect, overlayLineColor); } static void DrawMarkerOverlay(Color color, MarkerOverlayRegion region, MarkerUIStates state) { // By default, set the height to the markerRegion's height float markerHeight = region.markerRegion.height; // If marker is collapsed, set the height to 2/3 the markerRegion's height if (state.HasFlag(MarkerUIStates.Collapsed)) { markerHeight = region.markerRegion.height / 1.5f; } // Calculate a rectangle that uses the marker region and variable markerHeight Rect overlayMarkerRect = new Rect(region.markerRegion.x, region.markerRegion.y, region.markerRegion.width, markerHeight); Color overlayMarkerColor = new Color(color.r, color.g, color.b, color.a * k_OverlayAlpha); EditorGUI.DrawRect(overlayMarkerRect, overlayMarkerColor); } } Add more features The Notes marker is complete but you can continue adding features. Here are some suggestions: In the add a marker overlay step, you draw a colored overlay for the Notes marker. This changes the background color of the Notes marker but does not draw the image using color. To do this, you could load each marker image as a 2D texture and draw these images with the marker's color. Consult the custom Annotation marker sample for more on how to load 2D textures and draw them with a specific color. In the customize the marker's appearance with USS step, you use the common.uss file to define USS styles for both the light and dark Editor Theme. To define specific styles for the light and dark themes, you can create USS files named light.uss and dark.uss. These files, if present at the same path as common.uss, overrides styles with the same name and pseudo-states."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-overview.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-overview.html",
    "title": "Timeline workflows | Inventory System",
    "summary": "Timeline workflows Use the Timeline window to create Timeline assets and Timeline instances that you can then use to record animation, schedule animation, nest Timeline instances to create cinematic content, place markers that emit signals, and customize Timeline with custom tracks, clips, and markers. To successfully perform these tasks requires following steps in a particular order. Each workflow in this section demonstrate how to perform specific tasks. Workflow Demonstrates Create a Timeline asset and Timeline instance How to create a Timeline asset and a Timeline instance, and how to associate a Timeline instance with a GameObject. This is the first step when using Timeline to create a cut-scene or gameplay animation. Record basic animation How to record keyframe animation directly to a Timeline instance using an Animation track and an Infinite clip. Convert an Infinite clip How to convert an Infinite clip to an Animation clip. Animate a humanoid How to animate a humanoid model to follow two Animation clips. This workflow also demonstrates how to blend clips, match clips, and how to manually reduce foot sliding. Override an animation with an Avatar Mask How to use an Animation Override track and an Avatar Mask to replace only the upper-body animation in an Animation track. Create a Sub-Timeline instance How to create and use a Sub-Timeline instance to combine two Timeline instances into a single cut-scene. Use markers and signals for footsteps How to add Timeline markers, signal emitters, and signal receivers to play one of two audio sources when a character's foot contacts the floor. Create a custom Notes marker How to create a custom marker that you can use to add notes to your Timeline instances. This workflow also demonstrates how to change the default appearance of a custom marker with scripting and a Unity Style Sheet (USS)."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-record-anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-record-anim.html",
    "title": "Record basic animation | Inventory System",
    "summary": "Record basic animation This workflow demonstrates how to record animation directly to a Timeline instance. Before you can record animation, you must add an empty Animation track for the GameObject that you want to animate. You must also ensure that the GameObject you want to animate has an Animator component. To create an Animation track for a GameObject and add an Animator component to the GameObject, drag the GameObject into an empty area in the Track list and choose Add Animation Track from the context menu. Drag a GameObject into the Track list and choose Add Animation Track The Timeline window creates an empty Animation track bound to the GameObject. The Timeline window adds the Animator component to the GameObject. In the Track header for the Animation track, click the Record button to enable Record mode. Click the Record button on an empty track to enable Record mode When a track is in Record mode, the clip area of the track is drawn in red and the Record button blinks on and off. When you record directly to an empty Animation track, you create an Infinite clip. An Infinite clip is a clip that contains basic keyframe animation recorded through the Timeline window. Timeline window in Record mode When in Record mode, any modification to an animatable property of the GameObject adds a keyframe at the location of the Timeline Playhead. To start creating an animation, move the Timeline Playhead to the location of the first keyframe, and do one of the following: In the Inspector window, change the value of the animatable property of the GameObject. This adds a keyframe for the property with its changed value. The keyframe appears in the Infinite clip. In the Scene view, either move, rotate, or scale the GameObject. This automatically adds a keyframe for the properties you change. A diamond appears in the Infinite clip. The red background indicates that Timeline is in record mode Added keyframes resemble diamonds in the Infinite clip. This Infinite clip has two keyframes. Move the playhead to a different location and change the animatable properties of the GameObject. At each location, the Timeline window adds a diamond to the Infinite clip for any changed properties and adds a keyframe to its associated animation curves. While in Record mode, you can right-click the name of an animatable property to perform other keying operations such as adding a keyframe without changing its value, updating the value of a keyframe, jumping to the next or previous keyframe, and removing a keyframe. For example, to add a keyframe for the position of a GameObject without changing its value, right-click Position and choose Add Key from the context menu. Right-click the name of an animatable property to perform keying operations on the Animation curves for the property When you finish your animation, click the blinking Record button to disable Record mode. An Infinite clip appears as a dope sheet in the Timeline window. You cannot edit the keyframes in this view. Use the Curves view to edit keyframes. You can also double-click the Infinite clip and edit the keyframes with the Animation window. An Infinite clip appears as a dope sheet Save the Scene or Project to save the Timeline asset and the Infinite clip. The Timeline window saves the keyframe animation from the Infinite clip as a source asset. The source asset is named Recorded and saved as a child of the Timeline asset in the Project. For every additional recorded Infinite clip, the Timeline window numbers each clip sequentially, starting at (1). For example, a Timeline asset named BoardTL has three recorded Infinite clips: Recorded, Recorded (1), and Recorded (2). If you delete a Timeline asset, its recorded clips are also removed. Recorded clips are saved under the Timeline asset in the Project An Infinite clip cannot be positioned, trimmed, or split in the Content view because it does not have a defined size: it spans the entirety of an Animation track. To perform clip actions on an Infinite clip you must convert it to a Clip track."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-signals.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-signals.html",
    "title": "Use markers and signals for footsteps | Inventory System",
    "summary": "Use markers and signals for footsteps This workflow demonstrates how to use Timeline markers, Signal assets, and Signal Receiver components to play audio sources for footsteps. This workflow uses the humanoid model named DefaultMale and animation source assets from the Gameplay Sequence sample for its walk and walk to jog cycles. Consult Timeline Samples for information on the samples available from the Timeline package and how to import these samples into your projects. To demonstrate how to use markers and signals, this workflow is divided into the following main tasks: Set up the Timeline instance. Add files, assets, and components. Decide where to add markers. Add a marker and signal for the first left footstep. Add a marker and signal for the first right footstep. Add markers and signals for remaining footsteps. Preview and adjust each marker. Set up the Timeline instance To follow along with this workflow, create a Timeline instance with a single track that animates a character with a walk cycle or any animation where the character's feet occasionally contact the floor. You can also use the result of the Animate a humanoid workflow. The Timeline instance in this workflow, named SignalsTL, has a single Animation track bound to the DefaultMale model. The Animation track starts with a walk cycle and blends into a walk to jog cycle. The Timeline instance is associated with an empty GameObject named Timeline. This workflow uses a Timeline instance (SignalsTL) with the DefaultMale model walking then jogging Add files, assets, and components Before adding markers and signals, depending on what you want your Timeline instance to interact with, you may need to add additional files, assets, and components to your project. For example, this workflow plays one of two different audio sources depending on which foot of the DefaultMale character contacts the floor. Before adding markers and signals to play footsteps, you must do the following: Add audio files to your project. Add an audio source to the LeftFoot to play the left footstep audio file. Add an audio source to the RightFoot to play the right footstep audio file. Add Audio files to your project This workflow uses the audio files named footsteps1.wav and footsteps2.wav. These are freeware footstep sounds downloaded from a royalty free website. Before you can use audio files in your project, you must add them to the Assets folder. You can do this using one of the following methods: Use your operating system to copy or move the audio files to the Assets folder within your Project folder. Drag the file from your operating system onto the Assets folder in the Project window. In the Project window, select the Assets folder then right-click and choose Import New Asset from the context menu. Use the Import dialog that displays to select which files to move to the Assets folder. To keep your assets organized, it is recommended that you create additional folders within your Assets folder for each type of asset, file, or resource. For example, you could create a folder named Audio to store your audio files. Unity recognizes assets and files in child folders within the Assets folder. The audio files footsteps1.wav and footsteps2.wav are copied or moved to the Audio folder within the Assets folder Add an Audio Source for the left footstep After you add audio files to your project, add an Audio Source component to play the audio file for the LeftFoot. In the Scene Hierarchy, navigate and choose LeftFoot in the DefaultMale character hierarchy. LeftFoot selected in the DefaultMale hierarchy With LeftFoot selected, in the Inspector window, click Add Component. From the list of components, select Audio > Audio Source. In the AudioClip field, select the picker (circle) and choose the audio file to play when the LeftFoot touches the floor. In the Audio Source component for LeftFoot, disable Play On Awake so that the Audio Source does not automatically play when switching to Play mode in the Game view. Audio Source for LeftFoot with the audio file selected and Play On Awake disabled Add an Audio Source for the right footstep After the LeftFoot has an Audio Source component, follow the same steps but for the RightFoot. In the Scene Hierarchy, navigate and choose RightFoot in the DefaultMale character hierarchy. RightFoot selected in the DefaultMale hierarchy With RightFoot selected, in the Inspector window, click Add Component. From the list of components, select Audio > Audio Source. In the AudioClip field, select the picker (circle) and choose the audio file to play when the RightFoot touches the floor. In the Audio Source component for RightFoot, disable Play On Awake so that the Audio Source does not automatically play when switching to Play mode in the Game view. Audio Source for RightFoot with the audio file selected and Play On Awake disabled Decide where to add markers After audio files are imported and Audio Source components are created, the next step is to add Timeline markers that play these audio sources at specific points in time. In the Timeline window, you can add Timeline markers to any track associated with a GameObject. The most appropriate track to add Timeline markers depends on what you want these markers to interact with. In this workflow, you want these Timeline markers to play the audio sources that have been added to the LeftFoot and RightFoot GameObjects. These GameObjects are in the DefaultMale hierarchy. For this reason, you should add Timeline markers to the Animation track bound to the DefaultMale hierarchy. Add a marker and signal for the first left footstep In this step, you add a marker, set its properties, and create a Signal Asset for the first left footstep on the DefaultMale Animation track. You will also add a Signal Receiver component to the DefaultMale GameObject. Move the Timeline Playhead to where the DefaultMale character's left foot first touches the floor. The Playhead Location field displays the time in frames. In this workflow, the left foot first touches the floor at frame 27. On the Track Header for the DefaultMale Animation track, click the More menu (⋮) and choose Add Signal Emitter. This adds a Timeline marker to the Animation track, at the location of the Timeline Playhead. When you add a Timeline marker, you choose the Signal Emitter type for the Timeline marker being added. By default, the Signal Emitter type is the only available type of emitter. When you add a Timeline marker, it is automatically selected and its properties display in the Inspector window. If the Inspector window does not display the Timeline marker properties, click the Timeline marker to select it. Inspector window with the Create Signal and Add Signal Receiver buttons In the Timeline window, notice that this Timeline marker is drawn with a warning icon. This indicates that the Timeline marker is not yet linked to a Signal Asset. Timeline marker added to the DefaultMale Animation track with a warning icon To remove the warning icon, you can either create a new Signal Asset or associate the marker with an existing Signal Asset. In this workflow, since you have yet to create a Signal Asset for the left foot, do one of the following: If your project contains no Signal assets, the Inspector window prompts you to click the Create Signal button. If your project contains at least one Signal Asset, choose Create Signal from the Emit Signal dropdown menu. A dialog box prompts you for the name and location of the Signal asset you are creating. You can also specify tags to identify the Signal asset. Name the Signal Asset, choose a location, and click Save. A Signal Asset defines the relationship between the Timeline Marker and the Signal Receiver. You can reuse a Signal Asset multiple times for many different Timeline Markers. This workflow names the Signal Asset LeftFootSignal.Signal to differentiate it from the Signal Asset for the right foot and to distinguish it from the LeftFoot GameObject. This workflow also saves Signal Assets to the folder named Signals, within the Assets folder. The Signals folder is optional. It is used to organize the assets in the Assets folder. Click Add Signal Receiver to create and define a Signal Receiver component. The Signal Receiver component is added to the GameObject bound to the track with the selected Timeline marker. In this workflow, the Signal Receiver component is added to the DefaultMale GameObject. With the Timeline marker selected, the Inspector window displays the same properties as the Signal Receiver component except for the Receiver Component on property. The table in the Signal Receiver properties include a Signal column and a Reaction column. The Signal column lists the signals that the Signal Receiver receives. The Reaction column defines the actions that are performed when a signal is received. blah (A) The GameObject with this Signal Receiver component (B) Reaction type (C) Destination function (D) Reaction destination In the Reaction column, select Editor and Runtime as the Reaction type. This ensures that the Signal Receiver reacts to the emitted signal during Timeline preview, Editor Play mode, and during Runtime. Below the reaction type, select the GameObject that receives the signal. Since this Signal Receiver is meant to play the footstep Audio Source associated with the LeftFoot, select LeftFoot as the Reaction destination instead of DefaultMale. To define the reaction, click No Function and select Audio Source > Play() to play the footstep sound from the Audio Source component. Defining the reaction chooses which method is called and from which component. The available methods depends on the components added to the GameObject that receives the signal. In this workflow, the Play() method does not accept parameters. If you select a method that accepts parameters, the parameters would be listed beneath the select component and function. Lastly, make sure Retroactive and Emit Once are disabled. These properties are disabled by default. Add a marker and signal for first right footstep In this step, you add a marker, set its properties, and define a Signal Asset for the first right footstep. These steps are simplified because they are similar to adding a marker and signal for the first left footstep. Move the Timeline Playhead to where the DefaultMale character's right foot first touches the floor. In this workflow, the right foot first touches the floor at frame 64. On the Track Header for the DefaultMale Animation track, click the More menu (⋮) and choose Add Signal Emitter. This adds a Timeline marker to the Animation track, at the location of the Timeline Playhead. When you add a Timeline marker, it is automatically selected and its properties display in the Inspector window. If the Inspector window does not display the Timeline marker properties, click the Timeline marker to select it. In the Inspector window, make sure Retroactive and Emit Once are disabled. These properties are disabled by default. In the Inspector window, to remove the warning icon from the Timeline marker and create a new Signal Asset, choose Create Signal from the Emit Signal dropdown menu. A dialog box prompts you for the name and location of the Signal asset you are creating. You can also specify tags to identify the Signal asset. Name the Signal Asset RightFootSignal.Signal to differentiate it from the Signal Asset for the left foot and to distinguish it from the RightFoot GameObject. Choose a location and click Save. This workflow saves Signal Assets to the folder named Signals, within the Assets folder. The Signals folder is optional. It is used to organize the assets in the Assets folder. When the RightFootSignal.Signal is saved, a new row is added to the table in Signal Receiver properties. You don't have to add a new Signal Receiver component because this component was added to the DefaultMale GameObject when you created the first signal for the left foot. In the Reaction column for the RightFootSignal row, select Editor and Runtime as the Reaction type and select the RightFoot GameObject as the Reaction destination. Click No Function and select Audio Source > Play() to play the footstep sound from the Audio Source component. Inspector window for the first right footstep Timeline marker Add markers and signals for additional footsteps In this step, for the additional footsteps, you reuse each created Signal Asset based on which foot touches the floor. This is similar to adding a marker and signal in the previous steps. The difference is that the Signal Assets for playing either footstep sound has already been created. Instead of creating new Signal Assets, you will reuse previous assets. Move the Timeline Playhead until the character's next foot touches the floor. In this workflow, this occurs at frame 100. On the Track Header for the DefaultMale Animation track, click the More (⋮) menu and choose Add Signal Emitter from Signal Asset. An Object Picker window displays prompting you to select a Signal Asset. Because the LeftFoot touches the floor, select the LeftFootSignal Signal Asset and close the Object Picker window. This adds a new Timeline marker of the Signal Emitter type to the DefaultMale Animation track. The new Timeline marker is selected and its properties display in the Inspector window. Inspector window for the second left footstep Timeline marker which reuses the LeftFootSignal Asset Repeat these steps for each remaining frame where either the LeftFoot or RightFoot of the DefaultMale character contacts the floor. The SignalsTL Timeline instance with markers for each foot contact For example, in this workflow, after adding Timeline markers for the first two foot steps, there are four additional frames where either foot of the DefaultMale character contacts the floor: LeftFoot at frame 100 (set above) RightFoot at frame 137 LeftFoot at frame 164 RightFoot at frame 188 Play and adjust each marker After you add a marker for every occurrence where the LeftFoot or RightFoot of the DefaultMale character touches the floor, click the Play button in the Timeline Playback Controls to preview the result. As each foot touches the floor, you might need to adjust the location of each Timeline marker to ensure that the footstep sound corresponds with each footstep."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-subtimeline.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/Documentation~/wf-subtimeline.html",
    "title": "Create a Sub-Timeline instance | Inventory System",
    "summary": "Create a Sub-Timeline instance This workflow demonstrates how to create a single cut-scene by nesting a Timeline instance within another Timeline instance. This workflow uses the Gameplay Sequence sample. Consult Timeline Samples for information on the samples available from the Timeline package and how to import these samples into your projects. To demonstrate how to combine two Timeline instances, this workflow is divided into the following main tasks: Set up the main Timeline instance. Add a Control track and create a Sub-Timeline instance. Adjust the Control clip. Play the result. Set up the main Timeline instance This workflow demonstrates how to combine two Timeline instances to create a single cut-scene. By default, in the Gameplay Sequence Demo scene, the CanSubTimeline Sub-Timeline instance is already combined with the GameplaySequence Timeline instance. Before demonstrating how to combine two Timeline instances, remove the Sub-Timeline instance. To do this, follow these steps: Load the GameplaySequence scene and open the GameplaySequence Timeline instance in the Timeline window. Consult Gameplay Sequence Demo for the steps on how to load the GameplaySequence scene and display the GameplaySequence Timeline instance. In the Timeline window, expand the Props Track group. The Props Track group contains tracks that activate and animate the Table and Can GameObjects. The Props Track group also contains the Can Sub-Timeline Control track that nests the CanSubTimeline Timeline instance. This Timeline instance animates the Can GameObject as it bounces and falls off the table. The Props Track group expanded in the Timeline window with the Can Sub-Timeline track selected Since this workflow demonstrates how to combine two Timeline instances, you should remove the nested CanSubTimeline Timeline instance. To remove the nested CanSubTimeline Timeline instance, delete the Can Sub-Timeline Control track. To delete the Can Sub-Timeline Control track, select the More (⋮) menu from its Track Header and choose Delete. This is one way to delete a track from a Timeline instance. The Timeline window includes other ways to delete a track. Add a Control track and create a Sub-Timeline instance To nest the CanSubTimeline Timeline instance within the GameplaySequence Timeline instance, do the following: In the scene, select the GameObject associated with the Timeline instance that will be the main Timeline instance. In this workflow, the GameplaySequence is the main Timeline instance. It is associated with the Timeline GameObject. Select the Timeline GameObject to display the GameplaySequence Timeline instance in the Timeline window When the Timeline window displays the GameplaySequence Timeline instance, enable the Lock icon. When locked, the Timeline window does not change when you select GameObjects. This makes it easier to set up or modify a Timeline instance. Add a Control track to the Props Track group. To do this, click the Add (+) button beside the Prop Track group name, and choose Control Track. The Add button (A) beside the Prop Track group name. A new Control Track is added at the end of the Prop Track. You may have to scroll the Timeline window to view the new Control track. A Control track is a special track for adding a Particle System, a Prefab instance, a ITimeControl Script, or a nested Timeline instance. In the Scene Hierarchy, find the GameObject that is associated with the Timeline instance to be nested. In this workflow, you want to nest the CanSubTimeline Timeline instance which is associated with the CanSubTimeline GameObject. This GameObject is within the Table hierarchy. The CanSubTimeline is associated with CanSubTimeline GameObject Select and drag the CanSubTimeline GameObject into the Control track that you added to the Props Track group. The Timeline window places a Control clip where you release the CanSubTimeline GameObject. The Control clip is set to the same size as the CanSubTimeline Timeline instance. When a Timeline instance is nested within another Timeline instance, the nested instance is referred to as a Sub-Timeline instance. (A) Control track with a Control clip. (B) Downward arrow in the Control clip indicates that the Control clip contains a Sub-Timeline instance. To view and Sub-Timeline instance, double-click its Control clip. The Local or Global button indicates whether the Timeline ruler displays the time local to the Sub-Timeline instance or the time global to the main Timeline instance. When you edit a Sub-Timeline instance, the Timeline title displays a breadcrumb list of Timeline and Sub-Timeline instances. There can be many nested Sub-Timeline instances. (A) Local or Global button. (B) Sub-Timeline instance with breadcrumb list or nested Sub-Timeline instances. You cannot change the duration of the Sub-Timeline instance. You must return to the main Timeline instance and change the duration of the Control clip to change the duration of the Sub-Timeline instance. Click the name of the main Timeline instance, in the breadcrumb list beside the Timeline selector, to return to the main Timeline instance. Adjust the Control clip After you create a Sub-Timeline instance, you may have to reposition its Control clip to ensure a smooth transition between the animation in the main Timeline instance and the Sub-Timeline instance. For example, in this workflow, when the character bumps into the table, the TableBase Animation track animates the table before the Sub-Timeline takes control and animates the can. To ensure a smooth transition between these two animations, the Control clip must be repositioned to when the table begins to move. To do this, follow these steps: In the Timeline instance, select the Control clip for the Can Sub-Timeline. The properties for the CanSubTimeline Control clip display in the Inspector window Set the Start for the Control clip to frame 833. This is the last frame when the StaticCan Activation clip is active. This is also the frame when the TableBase keyframe animation begins. Play the result To properly preview the entire cut-scene, including the Player character with the looping jog animation, click Play in the Game View. If you attempt to preview this animation in the Timeline window, the Player character is shown in a T-Stance for most of the cut-scene because the jog Animator state is only available during runtime."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Timeline copyright © 2023 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.timeline@c58b4ee65782/README.html": {
    "href": "Library/PackageCache/com.unity.timeline@c58b4ee65782/README.html",
    "title": "About Timeline | Inventory System",
    "summary": "Code Coverage Status About Timeline Use Unity’s Timeline to create cinematic content, game-play sequences, audio sequences, and complex particle effects. Installing Timeline To install this package, follow the instructions in the Package Manager documentation. Using Timeline The Timeline Manual can be found here Technical details Requirements This version of Timeline is compatible with the following versions of the Unity Editor: 2019.3 and later (recommended)"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog [2.0.0] - 2023-03-08 Merge of the com.unity.textmeshpro package. [1.0.0] - 2019-01-08 This is the first release of Unity UI as a built in package."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/EventSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/EventSystem.html",
    "title": "Event System | Inventory System",
    "summary": "Event System The Event System is a way of sending events to objects in the application based on input, be it keyboard, mouse, touch, or custom input. The Event System consists of a few components that work together to send events. When you add an Event System component to a GameObject you will notice that it does not have much functionality exposed, this is because the Event System itself is designed as a manager and facilitator of communication between Event System modules. The primary roles of the Event System are as follows: Manage which GameObject is considered selected Manage which Input Module is in use Manage Raycasting (if required) Updating all Input Modules as required Input Modules An Input Module is where the main logic of how you want the Event System to behave lives, they are used for: Handling Input Managing event state Sending events to scene objects. Only one Input Module can be active in the Event System at a time, and they must be components on the same GameObject as the Event System component. If you want to write a custom Input Module, send events supported by existing UI components in Unity. To extend and write your own events, see the Messaging System documentation. Raycasters Raycasters are used for figuring out what the pointer is over. It is common for Input Modules to use the Raycasters configured in the Scene to calculate what the pointing device is over. There are 3 provided Raycasters that exist by default: Graphic Raycaster - Used for UI elements Physics 2D Raycaster - Used for 2D physics elements Physics Raycaster - Used for 3D physics elements If you have a 2d / 3d Raycaster configured in your Scene, it is easy to make non-UI elements receive messages from the Input Module. Simply attach a script that implements one of the event interfaces. For examples of this, see the IPointerEnterHandler and IPointerClickHandler Scripting Reference pages."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/EventSystemReference.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/EventSystemReference.html",
    "title": "Event System Reference | Inventory System",
    "summary": "Event System Reference This section provides details about the following parts of the event system: Event System Manager Graphic Raycaster Physics Raycaster Physics2D Raycaster Standalone Input Module Touch Input Module Event Trigger"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-ShaderGraph.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-ShaderGraph.html",
    "title": "Create Custom UI Effects With Shader Graph | Inventory System",
    "summary": "Create Custom UI Effects With Shader Graph Shader Graph can help you create customized UI effects, including animated backgrounds and unique UI elements. With Shader Graph, you can transform Image elements from static to dynamic and easily define your own button state appearances. Shader Graph can also provide you with more control over the appearance of your UI and help you optimize performance and texture memory. Here are some examples of what you can achieve with Shader Graph in Unity UI: Create custom backgrounds for your user interfaces that subtly swirl, flow, or drift. Define visual button states, such as mouse hover and mouse press, or unfocused with just a single grayscale image. Design animated HUD elements that indicate the passage of time. The Basics To create a Shader Graph shader for a Canvas UI element, use one of the following methods: Modify an existing Shader Graph: Open the Shader Graph in the Shader Editor. In Graph Settings, select the HDRP Target. If there isn't one, go to Active Targets > Plus, and select HDRP. In the Material drop-down, select Canvas. Create a new Shader Graph. Go to Assets > Create > Shader Graph > HDRP, and select Canvas Shader Graph. Create animated backgrounds Follow these steps to create a simple animated background for a user interface. Add two Sample Texture 2D nodes to the graph and set them to use a tiling clouds texture. We will scroll these in different directions speeds. For each of the Sample Texture 2D nodes, add a Tiling and Offset node and connect it to the UV input port of the Sample Texture 2D node. We will use the Offset input ports to add the scrolling. For each of the Tiling and Offset nodes, create a multiply node and connect it to the Offset input port. For the first Multiply node, create a Vector 2 node connected to the A input port and set it to 0.2 and 0.13. For the second Multiply node, create a Vector 2 node connected to the B input port and set it to -0.1 and 0.23. These values control the scrolling directions. Create a Time node and multiply the Time output value by 0.3. This value is used to adjust the speed of the effect. Connect the ouput port of the Time multiply node to the other two multiply nodes. Now our textures are scrolling. Create a new Blend node and use it to blend the outputs of the two Sample Texture 2D nodes. This will combine the contributions of both textures together. Add a Lerp node and wire the output of the Blend node to the T input of the Lerp. This uses the texture contributions as a mask for blending. To blend the two colors using the animated mask, create two Color nodes and connect them to the A and B inputs of the Lerp. Set the colors according to your preference. Finally, connect the output of the Lerp to the Base Color input on the Fragment Context Block. You now have an animated background shader. You can customize it by changing the colors, changing the texture being used, or controlling the speed. Apply the shader to a Canvas element Follow the steps below to apply the shader you created to a Canvas UI element. Right-click your Shader Graph asset in the Project window and select Create > Material. Give your material a name. Ensure that your scene has a Canvas element. If it doesn't, right-click in the Hierarchy panel and select UI > Canvas. Add a new Image element to your Canvas. Right-click the Canvas element and select UI > Image. Select the Image element in the Hierarchy panel. In the Inspector window, select Browse on the Material slot. Select the Material asset you created in step 1. Now your Canvas element is using the shader you created. Pass custom data into the shader It's possible to retrieve custom data in a Shader Graph shader, such as the width and height dimensions of Canvas Image elements. You can easily achieve this using a script by following the steps below: Follow the steps in Apply The Shader To A Canvas Element to create a material and apply it to a Canvas Image element. To access the Blackboard window, open the Shader Graph asset and then select Blackboard on the top right. In the Blackboard window, click + on the top right to add a new Blackboard parameter. Select the data type that matches the type of data you want to bring in. In this example, add a Vector 2 parameter. Name the new parameter \"Size\". You can then drag the Size parameter into the graph and use it based on your needs. Create the following script to connect the Canvas Image's Width and Height values to the shader's Size parameter: using UnityEngine; using UnityEngine.UI; [RequireComponent(typeof(Graphic))] [ExecuteAlways] public class ImageSize : MonoBehaviour { private Image m_myCanvasImage; private void Start() { m_myCanvasImage = GetComponent<Image>(); } #if UNITY_EDITOR void OnValidate() { UpdateMaterial(); } #endif private void FixedUpdate() { UpdateMaterial(); } void UpdateMaterial() { if (m_myCanvasImage != null && m_myCanvasImage.material != null) { var imageRect = m_myCanvasImage.rectTransform.rect; var widthHeight = new Vector2(x: imageRect.width, y: imageRect.height); m_myCanvasImage.material.SetVector(name: \"_Size\", widthHeight); } } } Save the script as ImageSize.cs and add it to your project. Select the Image element in the Hierarchy panel of your scene. In the Inspector window, select Add Component and then choose Scripts > Image Size. The Image element's Width and Height values from the Rect Transform are passed into the Material's Size parameter. You can now use them in the shader."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UICreateFromScripting.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UICreateFromScripting.html",
    "title": "Creating UI elements from scripting | Inventory System",
    "summary": "Creating UI elements from scripting If you are creating a dynamic UI where UI elements appear, disappear, or change based on user actions or other actions in the game, you may need to make a script that instantiates new UI elements based on custom logic. Creating a prefab of the UI element In order to be able to easily instantiate UI elements dynamically, the first step is to create a prefab for the type of UI element that you want to be able to instantiate. Set up the UI element the way you want it to look in the Scene, and then drag the element into the Project View to make it into a prefab. For example, a prefab for a button could be a Game Object with a Image component and a Button component, and a child Game Object with a Text component. Your setup might be different depending on your needs. You might wonder why we don't have a API methods to create the various types of controls, including visuals and everything. The reason is that there are an infinite number of way e.g. a button could be setup. Does it use an image, text, or both? Maybe even multiple images? What is the text font, color, font size, and alignment? What sprite or sprites should the image use? By letting you make a prefab and instantiate that, you can set it up exactly the way you want. And if you later want to change the look and feel of your UI you can just change the prefab and then it will be reflected in your UI, including the dynamically created UI. Instantiating the UI element Prefabs of UI elements are instantiated as normal using the Instantiate method. When setting the parent of the instantiated UI element, it's recommended to do it using the Transform.SetParent method with the worldPositionStays parameter set to false. Positioning the UI element A UI Element is normally positioned using its Rect Transform. If the UI Element is a child of a Layout Group it will be automatically positioned and the positioning step can be skipped. When positioning a Rect Transform it's useful to first determine it has or should have any stretching behavior or not. Stretching behavior happens when the anchorMin and anchorMax properties are not identical. For a non-stretching Rect Transform, the position is set most easily by setting the anchoredPosition and the sizeDelta properties. The anchoredPosition specifies the position of the pivot relative to the anchors. The sizeDelta is just the same as the size when there's no stretching. For a stretching Rect Transform, it can be simpler to set the position using the offsetMin and offsetMax properties. The offsetMin property specifies the corner of the lower left corner of the rect relative to the lower left anchor. The offsetMax property specifies the corner of the upper right corner of the rect relative to the upper right anchor. Customizing the UI Element If you are instantiating multiple UI elements dynamically, it's unlikely that you'll want them all to look the same and do the same. Whether it's buttons in a menu, items in an inventory, or something else, you'll likely want the individual items to have different text or images and to do different things when interacted with. This is done by getting the various components and changing their properties. See the scripting reference for the Image and Text components, and for how to work with UnityEvents from scripting."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIFitContentSize.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIFitContentSize.html",
    "title": "Making UI elements fit the size of their content | Inventory System",
    "summary": "Making UI elements fit the size of their content Normally when positioning a UI element with its Rect Transform, its position and size is specified manually (optionally including behavior to stretch with the parent Rect Transform). However, sometimes you may want the rectangle to be automatically sized to fit the content of the UI element. This can be done by adding a component called Content Size Fitter. Fit to size of Text In order to make a Rect Transform with a Text component on it fit the text content, add a Content Size Fitter component to the same Game Object which has the Text component. Then set both the Horizontal Fit and Vertical Fit dropdowns to the Preferred setting. How does it work? What happens here is that the Text component functions as a Layout Element that can provide information about how big its minimum and preferred size is. In a manual layout this information is not used. A Content Size Fitter is a type of Layout Controller, which listens to layout information provided by Layout Elements and control the size of the Rect Transform according to this. Remember the pivot When UI elements are automatically resized to fit their content, you should pay extra attention to the pivot of the Rect Transform. The pivot will stay in place when the element is resized, so by setting the pivot position you can control in which direction the element will expand or shrink. For example, if the pivot is in the center, then the element will expand equally in all directions, and if the pivot is in the upper left corner, then the element will expand to the right and down. Fit to size of UI element with child Text If you have a UI element, such as a Button, that has a background image and a child Game Object with a Text component on it, you probably want the whole UI element to fit the size of the text - maybe with some padding. In order to do this, first add a Horizontal Layout Group to the UI element, then add a Content Size Fitter too. Set the Horizontal Fit, the Vertical Fit, or both to the Preferred setting. You can add and tweak padding using the padding property in the Horizontal Layout Group. Why use a Horizontal Layout Group? Well, it could have been a Vertical Layout Group as well - as long as there is only a single child, they produce the same result. How does it work? The Horizontal (or Vertical) Layout Group functions both as a Layout Controller and as a Layout Element. First it listens to the layout information provided by the children in the group - in this case the child Text. Then it determines how large the group must be (at minimum, and preferably) in order to be able to contain all the children, and it functions as a Layout Element that provides this information about its minimum and preferred size. The Content Size Fitter listens to layout information provided by any Layout Element on the same Game Object - in this case provided by the Horizontal (or Vertical) Layout Group. Depending on its settings, it then controls the size of the Rect Transform based on this information. Once the size of the Rect Transform has been set, the Horizontal (or Vertical) Layout Group makes sure to position and size its children according to the available space. See the page about the Horizontal Layout Group for more information about how it controls the positions and sizes of its children. Make children of a Layout Group fit their respective sizes If you have a Layout Group (horizontal or vertical) and want each of the UI elements in the group to fit their respective content, what do you do? You can't put a Content Size Fitter on each child. The reason is that the Content Size Fitter wants control over its own Rect Transform, but the parent Layout Group also wants control over the child Rect Transform. This creates a conflict and the result is undefined behavior. However, it isn't necessary either. The parent Layout Group can already make each child fit the size of the content. What you need to do is to disable the Child Force Expand toggles on the Layout Group. If the children are themselves Layout Groups too, you may need to disable the Child Force Expand toggles on those too. Once the children no longer expand with flexible width, their alignment can be specified in the Layout Group using the Child Alignment setting. What if you want some of the children to expand to fill additional available space, but not the other children? You can easily control this by adding a Layout Element component to the children you want to expand and enabling the Flexible Width or Flexible Height properties on those Layout Elements. The parent Layout Group should still have the Child Force Expand toggles disabled, otherwise all the children will expand flexibly. How does it work? A Game Object can have multiple components that each provide layout information about minimum, preferred and flexible sizes. A priority system determines which values take effect over others. The Layout Element component has a higher priority than the Text, Image, and Layout Group components, so it can be used to override any layout information values they provide. When the Layout Group listens to the layout information provided by the children, it will take the overridden flexible sizes into account. Then, when controlling the sizes of the children, it will not make them any bigger than their preferred sizes. However, if the Layout Group has the Child Force Expand option enabled, it will always make the flexible sizes of all the children be at least 1. More information This page has explained solutions to a few common use cases. For a more in depth explanation of the auto layout system, see the UI Auto Layout page."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIMultiResolution.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIMultiResolution.html",
    "title": "Designing UI for Multiple Resolutions | Inventory System",
    "summary": "Designing UI for Multiple Resolutions Modern games and applications often need to support a wide variety of different screen resolutions and particularly UI layouts need to be able to adapt to that. The UI System in Unity includes a variety of tools for this purpose that can be combined in various ways. In this how-to we're going to use a simple case study and look at and compare the different tools in the context of that. In our case study we have three buttons in the corners of the screen as shown below, and the goal is to adapt this layout to various resolutions. For this how-to we're going to consider four screen resolutions: Phone HD in portrait (640 x 960) and landscape (960 x 640) and Phone SD in portrait (320 x 480) and landscape (480 x 320). The layout is initially setup in the Phone HD Portrait resolution. Using anchors to adapt to different aspect ratios UI elements are by default anchored to the center of the parent rectangle. This means that they keep a constant offset from the center. If the resolution is changed to a landscape aspect ratio with this setup, the buttons may not even be inside the rectangle of the screen anymore. One way to keep the buttons inside the screen is to change the layout such that the locations of the buttons are tied to their respective corners of the screen. The anchors of the top left button can be set to the upper left corner using the Anchors Preset drop down in the Inspector, or by dragging the triangular anchor handles in the Scene View. It's best to do this while the current screen resolution set in the Game View is the one the layout is initially designed for, where the button placement looks correct. (See the UI Basic Layout page for more information on anchors.) Similarly, the anchors for the lower left and lower right buttons can be set to the lower left corner and lower right corner, respectively. Once the buttons have been anchored to their respective corners, they stick to them when changing the resolution to a different aspect ratio. When the screen size is changed to a larger or smaller resolution, the buttons will also remain anchored to their respective corners. However, since they keep their original size as specified in pixels, they may take up a larger or smaller proportion of the screen. This may or may not be desirable, depending on how you would like your layout to behave on screens of different resolutions. In this how-to, we know that the smaller resolutions of Phone SD Portrait and Landscape don't correspond to screens that are physically smaller, but rather just screens with a lower pixel density. On these lower-density screens the buttons shouldn't appear larger than on the high-density screens - they should instead appear with the same size. This means that the buttons should become smaller by the same percentage as the screen is smaller. In other words, the scale of the buttons should follow the screen size. This is where the Canvas Scaler component can help. Scaling with Screen Size The Canvas Scaler component can be added to a root Canvas - a Game Object with a Canvas component on it, which all the UI elements are children of. It is also added by default when creating a new Canvas through the GameObject menu. In the Canvas Scaler component, you can set its UI Scale Mode to Scale With Screen Size. With this scale mode you can specify a resolution to use as reference. If the current screen resolution is smaller or larger than this reference resolution, the scale factor of the Canvas is set accordingly, so all the UI elements are scaled up or down together with the screen resolution. In our case, we set the Canvas Scaler to be the Phone HD portrait resolution of 640 x 960. Now, when setting the screen resolution to the Phone SD portrait resolution of 320 x 480, the entire layout is scaled down so it appears proportionally the same as in full resolution. Everything is scaled down: The button sizes, their distances to the edges of the screen, the button graphics, and the text elements. This means that the layout will appear the same in the Phone SD portrait resolution as in Phone HD portrait; only with a lower pixel density. One thing to be aware of: After adding a Canvas Scaler component, it's important to also check how the layout looks at other aspect ratios. By setting the resolution back to Phone HD landscape, we can see that the buttons now appear bigger than they should (and used to). The reason for the larger buttons in landscape aspect ratio comes down to how the Canvas Scaler setting works. By default it compares the width or the current resolution with the width of the Canvas Scaler and the result is used as the scale factor to scale everything with. Since the current landscape resolution of 960 x 640 has a 1.5 times larger width than the portrait Canvas Scaler of 640 x 960, the layout is scaled up by 1.5. The component has a property called Match which can be 0 (Width), 1 (Height) or a value in between. By default it's set to 0, which compares the current screen width with the Canvas Scaler width as described. If the Match property is set to 0.5 instead, it will compare both the current width to the reference width and the current height to the reference height, and choose a scale factor that's in between the two. Since in this case the landscape resolution is 1.5 times wider but also 1.5 times shorter, those two factor even out and produce a final scale factor of 1, which means the buttons keep their original size. At this point the layout supports all the four screen resolutions using a combination of appropriate anchoring and the Canvas Scaler component on the Canvas. See the Canvas Scaler reference page for more information on different ways to scale UI elements in relation to different screen sizes."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIScreenTransition.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIScreenTransition.html",
    "title": "Creating Screen Transitions | Inventory System",
    "summary": "Creating Screen Transitions The need to transition between multiple UI screens is fairly common. In this page we will explore a simple way to create and manage those transitions using animation and State Machines to drive and control each screen. Overview The high-level idea is that each of our screens will have an Animator Controller with two states (Open and Closed) and a boolean Parameter (Open). To transition between screens you will only need to close the currently open Screen and open the desired one. To make this process easier we will create a small Class ScreenManager that will keep track and take care of closing any already open Screen for us. The button that triggers the transition will only have to ask the ScreenManager to open the desired screen. Thinking about Navigation If you plan to support controller/keyboard navigation of UI elements, then it's important to have a few things in mind. It's important to avoid having Selectable elements outside the screen since that would enable players to select offscreen elements, we can do that by deactivating any off-screen hierarchy. We also need to make sure when a new screen is shown we set a element from it as selected, otherwise the player would not be able to navigate to the new screen. We will take care of all that in the ScreenManager class below. Setting up the Animator Controller Let's take a look at the most common and minimal setup for the Animation Controller to do a Screen transition. The controller will need a boolean parameter (Open) and two states (Open and Closed), each state should have an animation with only one keyframe, this way we let the State Machine do the transition blending for us. Now we need to create the transition between both states, let's start with the transition from Open to Closed and let's set the condition properly, we want to go from Open to Closed when the parameter Open is set to false. Now we create the transition from Closed to Open and set the condition to go from Closed to Open when the parameter Open is true. Managing the screens With all the above set up, the only thing missing is for us to set the parameter Open to true on the screens Animator we want to transition to and Open to false on the currently open screens Animator. To do that, we will create a small script: using UnityEngine; using UnityEngine.UI; using UnityEngine.EventSystems; using System.Collections; using System.Collections.Generic; public class ScreenManager : MonoBehaviour { //Screen to open automatically at the start of the Scene public Animator initiallyOpen; //Currently Open Screen private Animator m_Open; //Hash of the parameter we use to control the transitions. private int m_OpenParameterId; //The GameObject Selected before we opened the current Screen. //Used when closing a Screen, so we can go back to the button that opened it. private GameObject m_PreviouslySelected; //Animator State and Transition names we need to check against. const string k_OpenTransitionName = \"Open\"; const string k_ClosedStateName = \"Closed\"; public void OnEnable() { //We cache the Hash to the \"Open\" Parameter, so we can feed to Animator.SetBool. m_OpenParameterId = Animator.StringToHash (k_OpenTransitionName); //If set, open the initial Screen now. if (initiallyOpen == null) return; OpenPanel(initiallyOpen); } //Closes the currently open panel and opens the provided one. //It also takes care of handling the navigation, setting the new Selected element. public void OpenPanel (Animator anim) { if (m_Open == anim) return; //Activate the new Screen hierarchy so we can animate it. anim.gameObject.SetActive(true); //Save the currently selected button that was used to open this Screen. (CloseCurrent will modify it) var newPreviouslySelected = EventSystem.current.currentSelectedGameObject; //Move the Screen to front. anim.transform.SetAsLastSibling(); CloseCurrent(); m_PreviouslySelected = newPreviouslySelected; //Set the new Screen as then open one. m_Open = anim; //Start the open animation m_Open.SetBool(m_OpenParameterId, true); //Set an element in the new screen as the new Selected one. GameObject go = FindFirstEnabledSelectable(anim.gameObject); SetSelected(go); } //Finds the first Selectable element in the providade hierarchy. static GameObject FindFirstEnabledSelectable (GameObject gameObject) { GameObject go = null; var selectables = gameObject.GetComponentsInChildren<Selectable> (true); foreach (var selectable in selectables) { if (selectable.IsActive () && selectable.IsInteractable ()) { go = selectable.gameObject; break; } } return go; } //Closes the currently open Screen //It also takes care of navigation. //Reverting selection to the Selectable used before opening the current screen. public void CloseCurrent() { if (m_Open == null) return; //Start the close animation. m_Open.SetBool(m_OpenParameterId, false); //Reverting selection to the Selectable used before opening the current screen. SetSelected(m_PreviouslySelected); //Start Coroutine to disable the hierarchy when closing animation finishes. StartCoroutine(DisablePanelDeleyed(m_Open)); //No screen open. m_Open = null; } //Coroutine that will detect when the Closing animation is finished and it will deactivate the //hierarchy. IEnumerator DisablePanelDeleyed(Animator anim) { bool closedStateReached = false; bool wantToClose = true; while (!closedStateReached && wantToClose) { if (!anim.IsInTransition(0)) closedStateReached = anim.GetCurrentAnimatorStateInfo(0).IsName(k_ClosedStateName); wantToClose = !anim.GetBool(m_OpenParameterId); yield return new WaitForEndOfFrame(); } if (wantToClose) anim.gameObject.SetActive(false); } //Make the provided GameObject selected //When using the mouse/touch we actually want to set it as the previously selected and //set nothing as selected for now. private void SetSelected(GameObject go) { //Select the GameObject. EventSystem.current.SetSelectedGameObject(go); //If we are using the keyboard right now, that's all we need to do. var standaloneInputModule = EventSystem.current.currentInputModule as StandaloneInputModule; if (standaloneInputModule != null) return; //Since we are using a pointer device, we don't want anything selected. //But if the user switches to the keyboard, we want to start the navigation from the provided game object. //So here we set the current Selected to null, so the provided gameObject becomes the Last Selected in the EventSystem. EventSystem.current.SetSelectedGameObject(null); } } Let's hook up this script, we do this by creating a new GameObject, we can rename it \"ScreenManager\" for instance, and add the component above to it. You can assign an initial screen to it, this screen will be open at the start of your scene. Now for the final part, let's make the UI buttons work. Select the button that should trigger the screen transition and add a new action under the On Click () list in the Inspector. Drag the ScreenManager GameObject we just created to the ObjectField, on the dropdown select ScreenManager->OpenPanel (Animator) and drag and drop the panel you want to open when the user clicks the button to the las ObjectField. Notes This technique only requires each screen to have an AnimatorController with an Open parameter and a Closed state to work - it doesn't matter how your screen or State Machine are constructed. This technique also works well with nested screens, meaning you only need one ScreenManager for each nested level. The State Machine we set up above has the default state of Closed, so all of the screens that use this controller start as closed. The ScreenManager provides an initiallyOpen property so you can specify which screen is shown first."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIWorldSpace.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/HOWTO-UIWorldSpace.html",
    "title": "Creating a World Space UI | Inventory System",
    "summary": "Creating a World Space UI The UI system makes it easy to create UI that is positioned in the world among other 2D or 3D objects in the Scene. Start by creating a UI element (such as an Image) if you don't already have one in your scene by using GameObject > UI > Image. This will also create a Canvas for you. Set the Canvas to World Space Select your Canvas and change the Render Mode to World Space. Now your Canvas is already positioned in the World and can be seen by all cameras if they are pointed at it, but it is probably huge compared to other objects in your Scene. We'll get back to that. Decide on a resolution First you need to decide what the resolution of the Canvas should be. If it was an image, what should the pixel resolution of the image be? Something like 800x600 might be a good starting point. You enter the resolution in the Width and Height values of the Rect Transform of the Canvas. It's probably a good idea to set the position to 0,0 at the same time. Specify the size of the Canvas in the world Now you should consider how big the Canvas should be in the world. You can use the Scale tool to simply scale it down until it has a size that looks good, or you can decide how big it should be in meters. If you want it to have a specific width in meters, you can can calculate the needed scale by using meter_size / canvas_width. For example, if you want it to be 2 meters wide and the Canvas width is 800, you would have 2 / 800 = 0.0025. You then set the Scale property of the Rect Transform on the Canvas to 0.0025 for both X, Y, and Z in order to ensure that it's uniformly scaled. Another way to think of it is that you are controlling the size of one pixel in the Canvas. If the Canvas is scaled by 0.0025, then that is also the size in the world of each pixel in the Canvas. Position the Canvas Unlike a Canvas set to Screen Space, a World Space Canvas can be freely positioned and rotated in the Scene. You can put a Canvas on any wall, floor, ceiling, or slanted surface (or hanging freely in the air of course). Just use the normal Translate and Rotate tools in the toolbar. Create the UI Now you can begin setting up your UI elements and layouts the same way you would with a Screen Space Canvas."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/InputModules.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/InputModules.html",
    "title": "Input Modules | Inventory System",
    "summary": "Input Modules An Input Module is where the main logic of an event system can be configured and customized. Out of the box there are two provided Input Modules, one designed for Standalone, and one designed for Touch input. Each module receives and dispatches events as you would expect on the given configuration. Input modules are where the 'business logic' of the Event System take place. When the Event System is enabled it looks at what Input Modules are attached and passes update handling to the specific module. Input modules are designed to be extended or modified based on the input systems that you wish to support. Their purpose is to map hardware specific input (such as touch, joystick, mouse, motion controller) into events that are sent via the messaging system. The built in Input Modules are designed to support common game configurations such as touch input, controller input, keyboard input, and mouse input. They send a variety of events to controls in the application, if you implement the specific interfaces on your MonoBehaviours. All of the UI components implement the interfaces that make sense for the given component."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/MessagingSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/MessagingSystem.html",
    "title": "Messaging System | Inventory System",
    "summary": "Messaging System The new UI system uses a messaging system designed to replace SendMessage. The system is pure C# and aims to address some of the issues present with SendMessage. The system works using custom interfaces that can be implemented on a MonoBehaviour to indicate that the component is capable of receiving a callback from the messaging system. When the call is made a target GameObject is specified; the call will be issued on all components of the GameObject that implement the specified interface that the call is to be issued against. The messaging system allows for custom user data to be passed, as well as how far through the GameObject hierarchy the event should propagate; that is should it just execute for the specified GameObject, or should it also execute on children and parents. In addition to this the messaging framework provides helper functions to search for and find GameObjects that implement a given messaging interface. The messaging system is generic and designed for use not just by the UI system but also by general game code. It is relatively trivial to add custom messaging events and they will work using the same framework that the UI system uses for all event handling. Defining A Custom Message If you wish to define a custom message it is relatively simple. In the UnityEngine.EventSystems namespace there is a base interface called 'IEventSystemHandler'. Anything that extends from this can be considered as a target for receiving events via the messaging system. public interface ICustomMessageTarget : IEventSystemHandler { // functions that can be called via the messaging system void Message1(); void Message2(); } Once this interface is defined then it can be implemented by a MonoBehaviour. When implemented it defines the functions that will be executed if the given message is issued against this MonoBehaviours GameObject. public class CustomMessageTarget : MonoBehaviour, ICustomMessageTarget { public void Message1() { Debug.Log (\"Message 1 received\"); } public void Message2() { Debug.Log (\"Message 2 received\"); } } Now that a script exists that can receive the message we need to issue the message. Normally this would be in response to some loosely coupled event that occurs. For example, in the UI system we issue events for such things as PointerEnter and PointerExit, as well as a variety of other things that can happen in response to user input into the application. To send a message a static helper class exists to do this. As arguments it requires a target object for the message, some user specific data, and a functor that maps to the specific function in the message interface you wish to target. ExecuteEvents.Execute<ICustomMessageTarget>(target, null, (x,y)=>x.Message1()); This code will execute the function Message1 on any components on the GameObject target that implement the ICustomMessageTarget interface. The scripting documentation for the ExecuteEvents class covers other forms of the Execute functions, such as Executing in children or in parents."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/ProfilerUI.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/ProfilerUI.html",
    "title": "UI and UI Details Profiler | Inventory System",
    "summary": "UI and UI Details Profiler The UI and UI Details Profiler modules provide information on how much time and resources Unity spends laying out and rendering the user interface within your application. You can use this module to understand how Unity handles UI batching for your application, including why and how it batches objects. You can also use this module to find out which part of the UI is responsible for slow performance, or to preview the UI while you scrub the timeline. To open the Profiler window, go to Window > Analysis > Profiler. For more information on how to use the Profiler window, refer to The Profiler window. Chart categories The UI and UI Details Profiler modules’ charts are divided into five categories. To change the order of the categories in the chart, you can drag and drop them in the chart’s legend. You can also click a category’s colored legend to toggle its display. Chart Description UI Profiler module Layout How much time Unity has spent performing the layout pass for the UI. This includes calculations done by HorizontalLayoutGroup, VerticalLayoutGroup, and GridLayoutGroup. Render How much time the UI has spent doing its portion of rendering. This is either the cost of rendering directly to the graphics device or rendering to the main render queue. UI Details Profile module Batches Displays the total number of draw calls that are batched together. Vertices The total number of vertices that are used to render a section of UI. Markers Displays event markers. Unity records markers when the user interacts with the UI (for example, a button click, or a slider value change) and then draws them as vertical lines and labels on the chart. Module details pane When you select the UI or the UI Details Profiler module, the module details pane at the bottom of the Profiler window displays more details on the UI in your application. You can use it to inspect the profiling information about the UI objects in your application. The pane is divided into the following columns: Column Description Object A list of UI canvases your application used during the period profiled. Double click on a row to highlight the matching object in the Scene. Self Batch Count How many batches Unity generated for the canvas. Cumulative Batch Count How many batches Unity generated for the canvas and all of its nested canvases Self Vertex Count How many vertices this canvas is rendering. Cumulative Vertex Count How many vertices this canvas and nested canvases are rendering Batch Breaking Reason Why Unity split the batch. Sometimes Unity might not be able to batch objects together. Common reasons include: Not Coplanar With Canvas, where the batching needs the object’s rect transform to be coplanar (unrotated) with the canvas. CanvasInjectionIndex, where a CanvasGroup component is present and forces a new batch, such as when it displays the drop down list of a combo box on top of the rest. Different Material Instance, Rect clipping, Texture, or A8TextureUsage, where Unity can only batch together objects with identical materials, masking, textures, and texture alpha channel usage. GameObject Count How many GameObjects are part of this batch GameObjects The list of GameObjects in the batch. When you select a UI object from the list, a preview of it appears on the right hand side of the pane. Above the preview there are the following options in the toolbar: Detach: Select this button to open the UI canvas in a separate window. To reattach the window, close it. Preview background: Use the dropdown to change the color of the preview background. You can choose from Checkerboard, Black, or White. This is useful if your UI has a particularly light or dark color scheme. Preview type: Use the dropdown to select from Standard, Overdraw, or Composite Overdraw. Additional resources Profiler window introduction Profiling your application"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/Raycasters.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/Raycasters.html",
    "title": "Raycasters | Inventory System",
    "summary": "Raycasters A Raycaster is a component that determines what objects are under a specific screen space position, such as the location of a mouse click or a touch. It works by projecting a ray from the screen into the scene and identifying objects that intersect with that ray. Raycasters are essential for detecting user interactions with UI elements, 2D objects, or 3D objects. Different types of Raycasters are used for different types of objects: Graphic Raycaster: Detects UI elements on a Canvas. Physics 2D Raycaster: Detects 2D physics elements. Physics Raycaster: Detects 3D physics elements. The Event System uses Raycasters to determine where to send input events. When a Raycaster is present and enabled in the scene, the Event System uses it to determine which object is closest to the screen at a given screen space position. If multiple Raycasters are active, the system will cast against all of them and sort the results by distance."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/StyledText.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/StyledText.html",
    "title": "Rich Text | Inventory System",
    "summary": "Rich Text The text for UI elements and text meshes can incorporate multiple font styles and sizes. Rich text is supported both for the UI System and the legacy GUI system. The Text, GUIStyle, GUIText and TextMesh classes have a Rich Text setting which instructs Unity to look for markup tags within the text. The Debug.Log function can also use these markup tags to enhance error reports from code. The tags are not displayed but indicate style changes to be applied to the text. Markup format The markup system is inspired by HTML but isn't intended to be strictly compatible with standard HTML. The basic idea is that a section of text can be enclosed inside a pair of matching tags:- We are <b>not</b> amused. As the example shows, the tags are just pieces of text inside the \"angle bracket\" characters, < and >. You place the opening tag at the beginning of the section. The text inside the tag denotes its name (which in this case is just b). You place another tag at the end of the section. This is the closing tag. It has the same name as the opening tag, but the name is prefixed with a slash / character. Every opening tag must have a corresponding closing tag. If you don't close an opening tag, it is rendered as regular text. The tags are not displayed to the user directly but are interpreted as instructions for styling the text they enclose. The b tag used in the example above applies boldface to the word \"not\", so the text appears ons creen as:- We are not amused A marked up section of text (including the tags that enclose it) is referred to as an element. Nested elements It is possible to apply more than one style to a section of text by \"nesting\" one element inside another We are <b><i>definitely not</i></b> amused The <i> tag applies italic style, so this would be presented onscreen as We are definitely not amused Note the ordering of the closing tags, which is in reverse to that of the opening tags. The reason for this is perhaps clearer when you consider that the inner tags need not span the whole text of the outermost element We are <b>absolutely <i>definitely</i> not</b> amused which gives We are absolutely definitely not amused Tag parameters Some tags have a simple all-or-nothing effect on the text but others might allow for variations. For example, the color tag needs to know which color to apply. Information like this is added to tags by the use of parameters:- We are <color=green>green</color> with envy Which produces this result: Note that the ending tag doesn't include the parameter value. Optionally, the value can be surrounded by quotation marks but this isn't required. Tag parameters cannot include blank spaces. For example: We are <color = green>green</color> with envy does not work because of the spaces to either side of the = character. Supported tags The following list describes all the styling tags supported by Unity. Tag Description Example Notes b Renders the text in boldface. We are <b>not</b> amused. i Renders the text in italics. We are <i>usually</i> not amused. size Sets the size of the text according to the parameter value, given in pixels. We are <size=50>largely</size> unaffected. Although this tag is available for Debug.Log, you will find that the line spacing in the window bar and Console looks strange if the size is set too large. color Sets the color of the text according to the parameter value. The color can be specified in the traditional HTML format. #rrggbbaa ...where the letters correspond to pairs of hexadecimal digits denoting the red, green, blue and alpha (transparency) values for the color. For example, cyan at full opacity would be specified by color=#00ffffff... You can specify hexadecimal values in uppercase or lowercase; #FF0000 is equivalent to #ff0000. We are <color=#ff0000ff>colorfully</color> amused Another option is to use the name of the color. This is easier to understand but naturally, the range of colors is limited and full opacity is always assumed. <color=cyan>some text</color> The available color names are given in the table below. material This is only useful for text meshes and renders a section of text with a material specified by the parameter. The value is an index into the text mesh's array of materials as shown by the inspector. We are <material=2>texturally</material> amused quad This is only useful for text meshes and renders an image inline with the text. It takes parameters that specify the material to use for the image, the image height in pixels, and a further four that denote a rectangular area of the image to display. Unlike the other tags, quad does not surround a piece of text and so there is no ending tag - the slash character is placed at the end of the initial tag to indicate that it is \"self-closing\". <quad material=1 size=20 x=0.1 y=0.1 width=0.5 height=0.5> This selects the material at position in the renderer's material array and sets the height of the image to 20 pixels. The rectangular area of image starts at given by the x, y, width and height values, which are all given as a fraction of the unscaled width and height of the texture. Supported colors The following table lists colors for which you can use a name instead of a hexadecimal tag in the <color> rich text tag. Color name Hex value Swatch aqua (same as cyan) #00ffffff black #000000ff blue #0000ffff brown #a52a2aff cyan (same as aqua) #00ffffff darkblue #0000a0ff fuchsia (same as magenta) #ff00ffff green #008000ff grey #808080ff lightblue #add8e6ff lime #00ff00ff magenta (same as fuchsia) #ff00ffff maroon #800000ff navy #000080ff olive #808000ff orange #ffa500ff purple #800080ff red #ff0000ff silver #c0c0c0ff teal #008080ff white #ffffffff yellow #ffff00ff Editor GUI Rich text is disabled by default in the editor GUI system but it can be enabled explicitly using a custom GUIStyle. The richText property should be set to true and the style passed to the GUI function in question: GUIStyle style = new GUIStyle (); style.richText = true; GUILayout.Label(\"<size=30>Some <color=yellow>RICH</color> text</size>\",style);"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/SupportedEvents.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/SupportedEvents.html",
    "title": "Supported Events | Inventory System",
    "summary": "Supported Events The Event System supports a number of events, and they can be customized further in user custom user written Input Modules. The events that are supported by the Standalone Input Module and Touch Input Module are provided by interface and can be implemented on a MonoBehaviour by implementing the interface. If you have a valid Event System configured the events will be called at the correct time. IPointerEnterHandler - OnPointerEnter - Called when a pointer enters the object IPointerExitHandler - OnPointerExit - Called when a pointer exits the object IPointerDownHandler - OnPointerDown - Called when a pointer is pressed on the object IPointerUpHandler- OnPointerUp - Called when a pointer is released (called on the GameObject that the pointer is clicking) IPointerClickHandler - OnPointerClick - Called when a pointer is pressed and released on the same object IInitializePotentialDragHandler - OnInitializePotentialDrag - Called when a drag target is found, can be used to initialize values IBeginDragHandler - OnBeginDrag - Called on the drag object when dragging is about to begin IDragHandler - OnDrag - Called on the drag object when a drag is happening IEndDragHandler - OnEndDrag - Called on the drag object when a drag finishes IDropHandler - OnDrop - Called on the object where a drag finishes IScrollHandler - OnScroll - Called when a mouse wheel scrolls IUpdateSelectedHandler - OnUpdateSelected - Called on the selected object each tick ISelectHandler - OnSelect - Called when the object becomes the selected object IDeselectHandler - OnDeselect - Called on the selected object becomes deselected IMoveHandler - OnMove - Called when a move event occurs (left, right, up, down) ISubmitHandler - OnSubmit - Called when the submit button is pressed ICancelHandler - OnCancel - Called when the cancel button is pressed"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "Unity UI Unity UI: Unity User Interface Canvas Basic Layout Visual Components Interaction Components Animation Integration Auto Layout Rich Text Events MessagingSystem InputModules SupportedEvents Raycasters Reference Rect Transform Canvas Components Canvas Canvas Scaler Canvas Group Canvas Renderer Visual Components Text Image Raw Image Mask RectMask2D UI Effect Components Shadow Outline Position as UV1 Interaction Components Selectable Base Class Transition Options Navigation Options Button Toggle Toggle Group Slider Scrollbar Dropdown Input Field Scroll Rect Auto Layout Layout Element Content Size Fitter Aspect Ratio Fitter Horizontal Layout Group Vertical Layout Group Grid Layout Group Events Event System Manager Graphic Raycaster Panel Event Handler Panel Raycaster Physics Raycaster Physics 2D Raycaster Standalone Input Module Touch Input Module Event Trigger UI How Tos Designing UI for Multiple Resolutions Making UI elements fit the size of their content Creating a World Space UI Creating UI elements from scripting Creating Screen Transitions Creating Custom UI Effects With Shader Graph UI and UI Details Profiler TextMesh Pro Creating text UI Text GameObjects 3D Text GameObjects Font Assets Font Asset Properties Font Asset Creator Line Metrics Signed Distance Fields Dynamic Fonts The Fallback Chain Color emojis Rich Text Tags Supported Tags"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorEmojis.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorEmojis.html",
    "title": "Color emojis | Inventory System",
    "summary": "Color emojis You can include color glyphs and emojis in text. To do so, import a font file that has color emojis in it and set it as the fallback emojis text assets. Set up color emojis Create a color font asset and add it to the TMP Settings Fallback. Note this is the same as the Project Settings/TextMeshPro/Settings as depicted in the image. In your project, import a font file that has color emojis in it. Right-click in the Asset folder, and then select Create > TextMeshPro > FontAsset > Color. This ensures that you create the font asset with the right shader (Sprite) and the right atlas rendering mode (Color). Open the TMP Settings asset or alternatively via the Edit > ProjectSettings > TextMesh Pro > Settings. Add the emoji font asset to the Fallback Emoji Text Assets section. Alternatively, assigning a color font asset to the text object will work fine provided that the Emoji Fallback Support option in the Extra Settings of the text component is disabled. Include emojis in text To include emojis in text, do the following: Include emojis in text through their Unicode. For example, enter \\U00001f60 to represent a smile. Use OS Virtual Keyboard. Copy the emojis from an external Text Editing tool and paste them in your text field. To find more information about the Unicode Emojis Standard, see this link. Control Emoji Fallback Search The \"Emoji Fallback Support\" option controls where we search for characters defined in the Unicode Standards as Emojis. When this option is enabled (default), the \"Fallback Emoji Text Assets\" list will be search first for any characters defined as Emojis. When this option is disabled, the Primary font asset assigned to the text component will be searched first. Basically, this option overrides the character search to prioritize searching thru the \"Fallback Emoji Text Assets\" list first when the character is an emoji. This option is also useful when a font contains black-and-white emojis as it allows the user to control if the emojis contained in the primary will be used or those from the \"Fallback Emoji Text Assets\" list. To update the Emoji Fallback Support: Select the Text (TMP) field in the hierarchy. In the Inspector window, under the Extra Settings foldout of the Text (TMP) field, select the Emoji Fallback Support toggle. Limitations The color emojis feature has the following limitations: It doesn't support some OpenType font features, such as chain context and single substitution. It doesn't support Apple fonts that use the AAT format. It's a predecessor to OpenType. It doesn't support SVG color glyphs. Dynamic OS FontAsset has limited support on some iOS devices. The Apple Color Emoji font file found on OSX and several iOS devices works fine. However, the Apple Color Emoji-160px found on newer iOS devices is not support as the emoji's are encoded in JPEG format which is not supported by FreeType. Prior to Unity 2023.1, adding a UTF-32 through the inspector sends an error. The emojis won't display in the inspector."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradients.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradients.html",
    "title": "Color Gradients | Inventory System",
    "summary": "Color Gradients You can apply gradients of up to four colors to TextMesh Pro GameObjects. When you add a gradient, TextMesh Pro applies it to each character in the text individually. It stores gradient colors as in each character sprite's vertex colors. TextMesh Pro text with a four-color gradient Because each character sprite consists of two triangles, gradients tend to have a dominant direction. This is most obvious in diagonal gradients. For example, the dominant direction in gradient below favors the red and black colors in the bottom-left and top-right corners When you reverse the gradient colors, so both the top-right and bottom-left corners are yellow, the dominant color changes. TextMesh Pro multiplies gradient colors with the text's main vertex color (Main Settings > Vertex Color in the TextMesh Pro Inspector). If the main vertex color is white you see only the gradient colors. If it’s black you don’t see the gradient colors at all. Applying a Gradient To apply a gradient to a TextMesh Pro GameObject, edit the Gradient properties in the Inspector. Note To apply a gradient to only a portion of the text, use the gradient rich text tag. To apply a gradient to multiple text objects, use a gradient preset. To apply a color gradient to a TextMesh Pro GameObject: Enable the Main Settings > Color Gradient property. Set Main Settings > Color Gradient > Color Mode to the type of gradient you want to apply. Use the Main Settings > Color Gradient > Colors settings to choose colors for the gradient. For each color you can: Click the color swatch to open a Color Picker. Use the eyedropper to pick a color from anywhere on your screen. Enter the color’s hexadecimal value directly in the text field."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradientsPresets.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradientsPresets.html",
    "title": "Gradient Presets | Inventory System",
    "summary": "Gradient Presets Use gradient presets to reuse the same color gradients across text objects. A gradient preset overrides the text’s local gradient type and colors. You have to store Gradient presets in a specific folder so TextMesh Pro can find them and include them in builds. You can change the folder from the TextMesh Pro settings. Creating gradient presets To create a gradient preset, choose Assets > Create > TextMesh Pro > Color Gradient from the menu. This adds a new TextMesh Pro Color Gradient Asset to the Scene, and opens it in the Inspector. You can then select a gradient type from the Color Mode dropdown, and set the gradient Colors. Applying gradient presets You apply a gradient preset to text from the TextMesh Pro Inspector. To apply a gradient preset: Enable the Main Settings > Color Gradient property. Open the Object Picker (circle icon) for Main Settings > Color Preset, and choose choose a preset When you apply a gradient preset, the Inspector overrides the text's gradient type and colors with the values from the preset. Caution If you modify the gradient settings in the TextMesh Pro Inspector after you apply a preset, it affects the preset itself. Changes affect every object that uses the same preset. Removing gradient presets To remove a gradient preset, open the Object Picker (circle icon) for Main Settings > Color Preset, and choose None. When you remove the preset, the text reverts to its local gradient properties."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradientsTypes.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ColorGradientsTypes.html",
    "title": "Color Gradient Types | Inventory System",
    "summary": "Color Gradient Types You can apply the following types of gradients to text. Single: A single color that is TextMesh Pro multiplies with the text object's vertex color. Horizontal: A two-color side-to-side gradient. Vertical: A two-color up-and-down gradient. Four Corner: A four-color gradient. Each color radiates from one corner. The TexMesh Pro color gradient settings The number of colors available in the Colors settings depends on the type of gradient you choose. Each swatch corresponds to the color's origin on a character sprite. The image above shows a the settings for a four color gradient. Each color originates in the corresponding corner of the sprite (top-left, top-right, bottom-left, bottom-right). IT produces the following gradient: Single Color The Single gradient type applies a single color. Horizontal Gradients The Horizontal gradient type applies two colors, and produces a side to side transition between them on each character. Vertical Gradients The Vertical gradient type consists of two colors, and produces an up and down transition between the two on each character. Four Corner Gradients The Four Corner gradient type applies four colors. Each one radiates out from its assigned corner of each character. This is the most versatile gradient type. By varying some colors and keeping others identical, you can create different kinds of gradients. For example: Give three corners one color and the fourth a different color. Give pairs of adjacent corners the same color to create horizontal or vertical gradients. Give pairs of diagonally opposite corners the same color to create diagonal gradients. Create horizontal and vertical 3-color gradients with a dominant color at one end and a transition between two colors at the other. Give two diagonally opposite corners same color and give the other two corners different colors to create a diagonal stripe 3-color gradient."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/CustomStyles.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/CustomStyles.html",
    "title": "Styles | Inventory System",
    "summary": "Styles Use styles to apply additional formatting to some or all of the text in a TextMesh Pro object. A style is a combination of opening and closing rich text tags, and can also include leading and trailing characters. To define styles, use a TextMesh Pro style sheet. To apply styles to your text, use the <style> rich text tag in the text editor. Custom styles example Say you want headings in your text to be big, red, and bold with an asterisk to either side and a line break at the end. That requires several tags for each heading, which makes the formatting cumbersome to maintain, and the text more difficult to read in the editor. <font-weight=700><size=2em><color=#FF0000>*Heading*</color></size></font-weight><br> It's easier to put all of the markup in a style. The example below shows a style called H1. Once you create the style you can format all of your headings with a single <style> tag. <style=\"H1\">Heading</style> Not only does that make the text easier to read in the editor, you can now update all of the headings in your text just by changing the style."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/DebugTool.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/DebugTool.html",
    "title": "Debugging TextMesh Pro text | Inventory System",
    "summary": "Debugging TextMesh Pro text Use the Text Info Debug Tool to display diagnostic information about a TextMesh Pro GameObject in the Scene view and the Inspector. For example, you can display lines that indicate font metrics such as the line height, or the offset for superscript and subscript text. This can help you diagnose problems with fonts you import. The TextMesh Pro debug tool set to show character bounding boxes and font metrics [NOTE!] The debug tool is part of the TextMesh Pro Examples & Extras package. You can install the package from the menu (select Window > TextMesh Pro > Import TMP Examples and Extras) or the TextMesh Pro settings. To use the debug tool: Open a TextMesh Pro GameObject in the Inspector. Add a TMP_TextInfoDebugTool component. From the TMP_Text Info Debug Tool section, turn debug settings on and off. You can see the results in the Scene view. Text Info Debug Tool properties Property: Function: Show Characters Displays each character's bounding box, as well as reference lines for font metrics, in the Scene view. Show Words Displays the bounding box for each word in the Scene view. Show Links Displays the bounding box for each link in the Scene view. Show Lines Displays the bounding box for line of text word in the Scene view. Show Mesh Bounds Displays the bounding box for the entire block of text in the Scene view. Show Text Bounds Displays the boundary of the area that text can occupy, as defined by the font metrics, in the Scene view. Object Stats Shows statistics about the TextMesh Pro GameObject, such as the number of characters, words, lines, and spaces. Text Component Links to the TextMesh Pro GameObject's Text component. Transform Links to the TextMesh Pro GameObject's RectTransform component."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Debugging.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Debugging.html",
    "title": "Debugging TextMesh Pro text | Inventory System",
    "summary": "Debugging TextMesh Pro text"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssets.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssets.html",
    "title": "Font Assets | Inventory System",
    "summary": "Font Assets To use different fonts with TextMesh Pro, you need to create font assets. TextMesh Pro has its own font Asset format that is distinct from, but related to, Unity's regular font Asset format. You create TextMesh Pro font assets from Unity font assets. Every TextMesh Pro font Asset has two sub-Assets: Font atlas: a black and white or grayscale texture file that contains all of the characters included in the font Asset. Example of a font atlas Font material: a material that controls the appearance of TextMesh Pro text using one of the TextMesh Pro shaders. Font assets must be in a specific folder so TextMesh Pro can find them and include them in builds. To change the default folder for font assets, got to the TextMesh Pro settings and set the Default Font Asset > Path option. Creating Font Assets To create a TextMesh Pro font Asset, use the TexMesh Pro Font Asset Creator. You can also create an empty TextMesh Pro font Asset from the Unity main menu. An empty font asset does not contain any characters by default, you must add them later. To create an empty TextMesh Pro font asset, select a Unity font Asset and then select Asset > Create > TextMeshPro > Font Asset from the menu. Types of font atlas Font Assets can have the following types of font atlas: Distance Field: This type of atlas contains signed distance field (SDF) information. This is the recommended Font Asset type for most applications because SDF atlases produce text that is smooth when transformed. Smooth/Hinted Smooth: This type of atlas is an antialiased bitmap texture. A Hinted smooth atlas aligns glyph pixels with texture pixels to produce a smoother result. Smooth atlases work well for static text that is viewed head on, in situations where there is a good correspondence between texture pixels and screen pixels. Transforming text generated from a smooth atlas blurs the text edges. Raster/Raster Hinted: Raster atlases are un-smoothed bitmap textures. They almost always produce text with jagged, pixellated edges. The Hinted rater atlases align glyph pixels with texture pixels to produce a smoother result. Get Font Features This option determines if OpenType font features should be retrieved from the source font file as new characters and glyphs are added to the font asset. Disabling this option will prevent extracting font features. To update the Get Font Features option on a FontAsset: Select the FontAsset In the FontAsset inspector, navigate to the Generation Settings section. Select Get Font Features. Reset The Reset context menu option clears all tables which includes the Character and Glyph tables along with all font features tables such as the Ligature, Glyph Adjustment, Mark to Base, Mark to Mark tables. This option also clears the font asset's atlas texture and resets it back to size zero. To reset a FontAsset: Select the FontAsset Expand the top right menu in the FontAsset Inspector. Select Reset. Clear Dynamic Data The Clear Dynamic Data context menu option clears the character and glyph tables as well as the font asset's atlas texture which is also resized back to size zero. This option preserves all font feature table data such as Ligatures, Glyph Adjustment, Mark to Base, Mark to Mark, etc. To clear a FontAsset: Select the FontAsset Expand the top right menu in the FontAsset Inspector. Select Clear Dynamic Data. This preserves the custom ligatures, kernings, and diacritical marks you added to the font asset when clearing the atlas. Clear Dynamic Data on Build The \"Clear Dynamic Data on Build\" option works like the \"Clear Dynamic Data\" context menu option but also clears data when building the project or closing the Editor. When enabled, this option resizes the texture to 0 (empty) during the build process. For dynamic FontAssets, it resets the glyph atlas, character table, and glyph table to their initial states. This feature helps reduce build size by minimizing the FontAsset's data footprint. To update the Clear Dynamic Data on Build option: Select the FontAsset In the FontAsset inspector, navigate to the Generation Settings section. Select Clear Dynamic Data on Build."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsCreator.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsCreator.html",
    "title": "| Inventory System",
    "summary": "Font Asset Creator The Font Asset Creator converts Unity font assets into TextMesh Pro font assets. You can use it to create both Signed Distance Field (SDF) fonts and bitmap fonts. When you create a new font Asset, TextMesh Pro generates the Asset itself, as well as the atlas texture and material for the font. After you create a TextMesh Pro font Asset, you can delete the Unity font Asset you used as a source, although you may want to keep it in the Scene in case you need to regenerate the TextMesh Pro font Asset. Creating a font Asset Before you start, make sure that you've already imported the font (usually a TrueType .ttf file) you want to use into the project. For more information about importing fonts into Unity, see the documentation on Fonts in the Unity manual. To create a TextMesh Pro font Asset: From the menu, choose: Window > TextMesh Pro > Font Asset Creator to open the Font Asset Creator. Choose a Source Font File. This the Unity font Asset that you want to convert into a TextMesh Pro font Asset. Adjust the Font Settings as needed, then click Generate Font Atlas to create the atlas texture The atlas, and information about the font Asset appear in the texture preview area. IMAGE Continue adjusting the settings and regenerating the atlas until you're satisfied with the result. Click Save or Save as... to save the font Asset to your project. You must save the Asset to a Resources folder to make it accessible to TextMesh Pro. Font Asset Creator Settings: Property: Function: Source Font File Select a font from which to generate a Text Mesh Pro font Asset. This font is not included in project builds, unless you use it elsewhere in the project, or put it in a Resources folder. You can use one of the default TextMesh Pro font assets, or import your own. Sampling Point Size Set the font size, in points, used to generate the font texture. Auto Sizing Use the largest point size possible while still fitting all characters on the texture. This is the usual setting for SDF fonts. Custom Size Use a custom point size. Enter the desired size in the text box. Use this setting to achieve pixel-accurate control over bitmap-only fonts. Padding Specify the space, in pixels, between characters in the font texture. Padding provides the space required to render character separately, and to generate the SDF gradient (See the documentation on Font Assets for details). The larger the padding, the smoother the transition, which allows for higher-quality rendering and larger effects, like thick outlines. A padding of 5 is often fine for a 512x512 texture. Packing Method Specify how to fit the characters into the font texture. Optimum Finds the largest possible automatic font size that still fits all characters in the texture. Use this setting to generate the final font texture. Fast Computes character packing more quickly, but may use a smaller font size than Optimum mode. Use this setting when testing out font Asset creation settings. Atlas Resolution Set the size width and height of the font texture, in pixels. A resolution of 512 x 512 is fine for most fonts, as long as you are only including ASCII characters. Fonts with more characters may require larger resolutions, or multiple atlases. When using an SDF font, a higher resolution produces finer gradients, and therefore higher quality text. Character Set The characters in a font file aren't included in the font Asset automatically. You have to specify which ones you need. You can select a predefined character set, provide a list of characters to include, or include all of the characters in an existing font Asset or text Asset. ASCII Includes the visible characters in the ASCII character set. Extended ASCII Includes the visible characters in the extended ASCII character set. ASCII Lowercase Includes only visible lower-case characters from the ASCII character set. ASCII Uppercase Includes only visible upper-case characters from the ASCII character set. Numbers + Symbols Includes only the visible numbers and symbols from the ASCII character set. Custom Range Includes a range of characters that you define. Enter a sequence of decimal values, or ranges of values, to specify which characters to include. Use a hyphen to separate the first and last values of a range. Use commas to separate values and ranges (for example 32-126,160,8230). You can also choose an existing font Asset to include the characters in that Asset. Unicode Range (Hex) Includes a range of characters that you define. Enter a sequence of unicode hexadecimal values, or ranges of values, to specify which characters to include. Use a hyphen to separate the first and last values of a range. Use commas to separate values and ranges (for example 20-7E,A0,2026). You can also choose an existing font Asset to include the characters in that Asset. Custom Characters Includes a range of characters that you define. Enter a sequence of characters to specify which characters to include. Enter characters one after the other, with no spaces or delimiting characters in between (for example abc123*#%). You can also choose an existing font Asset to include the characters in that Asset. Characters from File Includes all the characters in a text Asset that you specify. Use this option when you want to save your character set. Font Style Apply basic font styling when creating a bitmap-only font Asset. For SDF fonts, you configure the styling in the shader rather than the font Asset. Normal Generates characters with no styling. Bold, Italic, Bold_Italic Generates the font Asset with bold characters, italicized characters, or both. With these settings, you can set a strength value that applied to bolding and italicization Outline Generates the font Asset with outline characters. Bold_Sim Generates the font Asset with a simulated bold. Render Mode Specify the render mode to use when outputting the font atlas. SMOOTH Renders the atlas to an antialiased bitmap. RASTER Renders the atlas to a non-antialiased bitmap. SMOOTH_HINTED Renders the atlas to an antialiased bitmap, and aligns character pixels with texture pixels for a crisper result. RASTER_HINTED Renders the atlas to a non-antialiased bitmap and aligns character pixels with texture pixels for a crisper result. SDF Renders the atlas using a slower, but more accurate SDF generation mode, and no oversampling. SDFAA Renders the atlas using a faster, but less accurate SDF generation mode. It produces font atlases that are sufficient for most situations. SDFAA_HINTED Renders the atlas using a faster, but less accurate SDF generation mode, and aligns character pixels with texture pixels for a crisper result.. It produces font atlases that are sufficient for most situations SDF8 Renders the atlas using a slower, but more accurate SDF generation mode, and 8x oversampling. SDF16 Renders the atlas using a slower, but more accurate SDF generation mode, and 16x oversampling. SDF32 Renders the atlas using a slower, but more accurate SDF generation mode, and 32x oversampling. Use this setting for fonts with complex or small characters. Get Kerning Pairs Enable this option to copy the kerning data from the font. Kerning data is used to adjust the spacing between specific character pairs to produce a more visually pleasing result. Note: It isn't always possible to import kerning data. Some fonts store kerning pairs in their glyph positioning (GPOS) table, which is not supported by FreeType, the font engine used by TextMesh Pro. Other fonts do not store kerning pairs at all. Generate Font Atlas Generate the font atlas texture. Save Save the current font atlas. Save As Save the current font atlas as a new font Asset. Tips for creating font assets Characters in the font texture need some padding between them so they can be rendered separately. This padding is specified in pixels. Padding also creates room for the SDF gradient. The larger the padding, the smoother the transition, which allows for higher-quality rendering and larger effects, like thick outlines. A padding of 5 is often fine for a 512x512 texture. For most fonts, a 512x512 texture resolution is fine when including all ASCII characters. When you need to support thousands of character, you will have to use large textures. But even at maximum resolution, you might not be able to fit everything. In that case, you can split the characters by creating multiple font assets. Put the most often used characters in a main font Asset, and the others in a fallback font assets."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsDynamicFonts.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsDynamicFonts.html",
    "title": "Dynamic fonts assets | Inventory System",
    "summary": "Dynamic fonts assets Normally when you generate a font Asset using the Font Asset Creator, you choose which characters to include, and bake them into a Font Atlas texture. Dynamic font assets work the other way around. Instead of baking characters into an atlas in advance, you start with an empty atlas to which characters are added automatically as you use them. This makes dynamic fonts assets more flexible, but that flexibility comes at a cost. Dynamic fonts require more computational resources than static fonts. Dynamic font assets maintain a link to the original font file used to create them. That means: During development, you must keep the font file in the project. You cannot delete it as you can the source fonts of static font assets. Source fonts of any dynamic font assets in your game are included in builds, which can increase build size. This has several uses, for example: Use dynamic fonts during development to capture characters you forgot to include in your baked font assets. Use dynamic fonts in runtime when you don't know in advance which characters the user will enter in a text field. Creating a dynamic font Asset Empty font assets are dynamic by default. To create one: From Unity's main menu, choose Assets > Create > TextMeshPro > Font Asset or press Ctrl/Cmd + Shift + F12. To make an existing font Asset dynamic: Select Asset and open it in the Inspector. Set the Generation Settings > Atlas Population Mode property to Dynamic. Resetting a dynamic font Asset You reset TextMesh Pro dynamic font assets, the same way you reset other components: by choosing Reset from the gear icon menu or context menu in the Inspector. [IMAGE] However, instead of resetting all of the Asset's properties to their default values, the command affects only: The Font Atlas The Character Table The Glyph Table The Glyph Adjustment Table (kerning) These are reset to include only the characters/glyphs used by TextMesh Pro text objects that use the font Asset. If the Asset is currently unused, TextMesh Pro resizes the atlas texture to 0 x 0 pixels. NOTE: Resetting a static font Asset leaves the atlas texture as-is, but empties the character-, glyph-, and glyph adjustment tables."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsFallback.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsFallback.html",
    "title": "Fallback font assets | Inventory System",
    "summary": "Fallback font assets A font atlas, and by extension a font Asset, can only contain a certain number of glyphs. The exact number depends on the font, the size of the atlas texture, and the settings you use when generating the atlas. The fallback font system allows you to specify other font assets to search when TextMesh Pro can't find a glyph in a text object's font Asset. This is useful in a variety of situations, including: Working with languages that have very large alphabets (Chinese, Korean, and Japanese, for example). Use fallback fonts to distribute an alphabet across several assets. Designing for mobile devices, where an imposed maximum texture size prevents you from fitting an entire set of glyphs in a single atlas of sufficient quality. Including special characters from other alphabets in your text. Local and general fallback font assets Every font Asset can have its own list of fallback font assets. You set these in the font Asset properties. You can also set general fallback font assets that apply to every TextMesh Pro font Asset in your project. You set these in the TextMesh Pro settings. The fallback chain In addition to a text object's fallback fonts, TextMesh Pro searches several other assets for missing glyphs. Together, these assets form the fallback chain. The table below lists the assets in the fallback chain in the order in which they are searched. Position: Asset: Defined in: Notes: 1 TextMesh Pro object's primary Font Asset Text object properties 2 Primary font assets Fallback Font Assets Font Asset properties TexMesh Pro searches these assets in the order they're listed in the font Asset properties. The search is recursive, and includes each fallback Asset's fallback assets. 3 Text object's Sprite Asset Text object properties When searching sprite assets, TextMesh Pro looks for sprites with an assigned unicode value that matches the missing character's unicode value. 4 General Fallback Font Assets TextMesh Pro settings TexMesh Pro searches these assets in the order they're listed in the font Asset properties. The search is recursive, and includes each fallback Asset's fallback assets. 5 Default Sprite Asset TextMesh Pro settings When searching sprite assets, TextMesh Pro looks for sprites with an assigned unicode value that matches the missing character's unicode value. 6 Default Font Asset TextMesh Pro settings 7 Missing glyphs character TextMesh Pro settings The fallback chain search is designed to detect circular references so each Asset in the chain is only searched once."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsLineMetrics.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsLineMetrics.html",
    "title": "Line metrics. | Inventory System",
    "summary": "Line metrics. TextMesh Pro sets line metrics automatically when you generate a font Asset. If the generated values produce strange or incorrect results, you can tweak the line metrics settings to fine-tune the font. Most line metric values are relative to the Baseline, which is the horizontal line that characters sit on. Values for above-the-baseline metrics, such as the Ascender height, are greater that the Baseline value. Values for below-the-baseline metrics, such as the Descender height, are less than Baseline value. Metric: Function: Line Height The distance between the tops of consecutive lines. If you set the line height to a value greater than the combined size of the Ascender and Descender, it creates a gap between lines. If you set a line height to a value less than the combined size of the ascender and descender results in potential overlap between characters on different lines. Ascender The ascender height, which specifies how far characters can extend above the baseline. It corresponds to the top of a line. Cap Height The height of capital letters from the baseline. Baseline The baseline height. The baseline is the horizontal line that characters sit on. Descender The descender height, which specifies how far characters can extend below the baseline. Underline Offset The position of underlines relative to the baseline. Strikethrough Offset The position of strikethrough lines relative to the baseline. Superscript/ Subscript Offset Adjust the baseline for superscript and subscript text. Super/ Subscript Size The scale of superscript and subscript text relative to the normal font size. Padding The amount of padding between characters in the font atlas texture. TextMesh Pro sets this value when you generate the font Asset. It is not editable. Width/Height The font atlas texture's width and height, in pixels. TextMesh Pro sets these values when you generate the font Asset. They are not editable."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsProperties.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsProperties.html",
    "title": "Font Asset Properties | Inventory System",
    "summary": "Font Asset Properties Properties Properties are divided into the following sections: A Face Info B Generation Settings C Atlas & Material D Font Weights E Fallback Font Assets F Character Table G Glyph Table H Glyph Adjustment Table Face Info The Face Info properties control the font's line metrics. They also include read-only properties that the Font Asset Creator generates when you create the Asset. Line metrics Property: Function: Update Texture Atlas Open the Font Asset Creator pre-configured to modify and regenerate this font Asset. Family Name The name of the font used to create this font Asset. TextMesh Pro sets this value when you generate the font Asset. You cannot change it manually. Style Name The style of the font used to create this font Asset. For example, Regular, Bold, Italic, and so on. TextMesh Pro sets this value when you generate the font Asset. You cannot change it manually. Point Size The font size in points. TextMesh Pro bakes this value into the atlas texture when you generate the font Asset. You cannot change it manually. Scale Scales the font by this amount. For example, a value of 1.5 scales glyphs to 150% of their normal size. Line Height Controls the distance between the tops of consecutive lines. If you set a line height greater than the sum of the Ascent Line and Descent Line values, it creates in a gap between lines. If you set a line height greater than the sum of the Ascent Line and Descent Line values, characters on different lines might overlap. Ascent Line Controls the maximum distance that glyphs can extend above the baseline. It corresponds to the top of a line. Cap Line Controls the distance between the base line and the tops of uppercase glyphs. Mean Line Controls the maximum height for non-ascending lowercase glyphs (for example. \"a\" and \"c\", but not \"b\" and \"d,\" which have ascenders). The tops of rounded glyphs sometimes extend a slightly above the mean line. Baseline Controls the height of the baseline. The baseline is the horizontal line that characters sit on. Descent Line Controls the maximum distance that glyphs can extend below the baseline. Underline Offset Controls the position of underlines relative to the baseline. Underline Thickness Controls the thickness of underlines. Strikethrough Offset Controls the position of strikethrough lines relative to the baseline. Superscript Offset Offsets superscript text from the baseline. Superscript Size Scales superscript text relative to the normal font size. Subscript Offset Offsets subscript text from the baseline. Subscript Size Scales subscript text relative to the normal font size. Tab Width Specifies the width of a TAB character. Generation Settings The Font Asset Creator generates these values when you generate the Font Asset. Note When the Atlas Population Mode is set to Dynamic, you can change the atlas size without regenerating the atlas. Property: Function: Source Font File Atlas Population Mode Dynamic Static Atlas Render Mode SMOOTH Renders the atlas to an antialiased bitmap. RASTER Renders the atlas to a non-antialiased bitmap. SMOOTH_HINTED Renders the atlas to an antialiased bitmap, and aligns character pixels with texture pixels for a crisper result. RASTER_HINTED Renders the atlas to a non-antialiased bitmap and aligns character pixels with texture pixels for a crisper result. SDF Renders the atlas using a slower, but more accurate SDF generation mode, and no oversampling. SDFAA Renders the atlas using a faster, but less accurate SDF generation mode. It produces font atlases that are sufficient for most situations. SDFAA_HINTED Renders the atlas using a faster, but less accurate SDF generation mode, and aligns character pixels with texture pixels for a crisper result.. It produces font atlases that are sufficient for most situations SDF8 Renders the atlas using a slower, but more accurate SDF generation mode, and 8x oversampling. SDF16 Renders the atlas using a slower, but more accurate SDF generation mode, and 16x oversampling. SDF32 Renders the atlas using a slower, but more accurate SDF generation mode, and 32x oversampling. Use this setting for fonts with complex or small characters. Sampling Point Size The size, in points, of characters in the font texture. Padding The amount of padding between characters in the font atlas texture. This value is set when you generate the font Asset, and is not editable. Atlas Width/Height The width and height the font atlas texture. Choose for each dimension, choose one of the available values from the drop-down menu. Multi Atlas Textures Atlas & Material This section lists the sub-assets that the Font Asset Creator creates when you generate the Asset. Do not edit these directly. Property: Function: Font Atlas The font texture atlas created when you generated the font Asset. Font Material The font material created when you generated the font Asset. Font Weights The Font Weights options control the appearance of bold and italicized text. There are two ways of doing this: Create different bold and italic variants of the font Asset, and add them to the Font Table. You can specify regular and italic fonts for weights ranging from 100 (Thin) to 900 (Black). Define \"fake\" bolding and italicization by setting the Font Weight > Italic Style and Bold Weight properties. These settings tell TextMesh Pro how to adjust characters in the current font Asset when you bold or italicize text. Property: Function: Font Table Specify font assets to use for the following font variants. 100 - Thin 200 - Extra-Light 300 - Light 400 - Regular (italic only) 500 - Medium 600 - Semi-Bold 700 - Bold 800 - Heavy 900 - Black * 400 - Regular > Regular Typeface is the current font Asset. You cannot change it. If you don't specify font assets, TextMesh Pro \"fakes\" bolding and italicization according to the rest of the the Font Weights settings. Using \"faked\" font weights limits you to regular and italic versions of normal and bold text (equivalent to weights of 400 and 700 respectively). Normal Weight Set the regular font weight to use when no font Asset is available. Bold Weight Set the bold font weight assumed when no font Asset is available. Spacing Offset Add space between characters when using the normal text style. Bold Spacing Add space between characters when using the fake bold text style (meaning you haven’t specified a Bold font Asset). Italic Style If you don’t specify a font Asset for 400 - Regular > Italic Style variant, TextMeshPro slanting the character sprites in the Normal Style font Asset by an amount defined in the Italic Style setting. Set this value to control the Tab Multiple Set the tab size. This value is multiplied by the width of the font's space character to calculate the tab size used. Fallback Font Assets Each font Asset contains a limited number of characters. When you use a character that the current Font Asset does not contain, TextMesh Pro searches the fallback font list until it finds a font Asset that includes it. The text object then uses that font to render the character. You can use this feature to distribute fonts over multiple textures, or use different fonts for specific characters. Be aware that searching the list for missing characters requires extra computing resources, and that using additional fonts requires additional draw calls. For more information about how fallback fonts work, see The Fallback font chain. Property: Function: Fallback Font Asset list Manage the fallback fonts for this font Asset. Click + and - to add and remove font slots. Click the circle icon next to a font to open an Object Picker where you can choose a font Asset. Drag the handles on the left side of any font Asset to reorder the list. Character Table Glyph Table The glyph table contains information about each of the glyphs in the Font Asset. You can adjust the attributes of individual glyphs, which is useful when you need to correct problems that can occur when TextMesh Pro imports font data. Property: Function: Glyph Search Search the character list by character, ASCII value, or Hex value. Search results are ordered by ASCII value, lowest to highest. Previous Page/Next Page Long character lists are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Glyph Properties Displays a single glyph’s properties. Each glyph has its own entry. Click an entry to make it active. You can then edit the glyph, copy it, or remove it from the list. Ascii Displays the character’s ASCII decimal value. Hex Displays the character’s Unicode Hex value. Char Displays the character. X, Y, W, H Define the rectangular area the character occupies in the font atlas. OX, OY Control the placement of the character's sprite, defined at its top-left corner relative to its origin on the baseline. ADV Specify how far to advance along the baseline before placing the next character. SF Change this scaling factor value to adjust the size of the character. Copy to Duplicate this glyph. To make a copy, enter an unused Unicode (Hex) ID in the text field and click Copy to. Remove Remove this glyph from the list. Glyph Adjustment Table The glyph adjustment table controls spacing between specific pairs of characters. Some fonts include kerning information, which is imported automatically. You can add kerning pairs for fonts that don’t include them. Property: Function: Adjustment Pair Search Search the adjustment table by character or ASCII value. Search results include entries where either the left or right character matches the search string. Search results are ordered by the ASCII value of the left character, lowest to highest. Previous Page/Next Page Long adjustment tables are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Glyph Properties Displays a single glyph’s properties. Each glyph has its own entry. Click an entry to make it active. You can then edit the glyph, copy it, or remove it from the list. Char (left and right) Display the left and right characters for the kerning pair. When you add anew kerning pair, you can specify the left and right characters to use by typing them in these fields. ID (left and right) Display the left and right characters’ ASCII decimal values. When you add anew kerning pair, you can specify the left and right characters to use by typing their ASCII values in these fields. OX, OY For each character in the kerning pair, set the horizontal (X) and vertical (Y) offset relative to the character's initial position. AX For each character in the kerning pair, specify how far to advance along the baseline before placing the next character. Practically speaking, the left AX value controls the distance between the characters in the kerning pair, while the right AX value controls the distance between the kerning pair and the next character. Add New Kerning Pair Add a new entry to the Glyph Adjustment Table. You cannot duplicate an existing entry."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsSDF.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/FontAssetsSDF.html",
    "title": "| Inventory System",
    "summary": "About SDF fonts TextMesh Pro takes advantage of Signed Distance Field (SDF) rendering to generate font assets that look crisp when you transform and magnify them, and support effects such as outlines and drop shadows. Unlike black and white bitmap font textures, SDF font assets contain contour distance information. In font atlases, this information looks like grayscale gradients running from the middle of each glyph to a point past its edge. The gradient's mid-point corresponds to the edge of the glyph. The images below show bitmap and SDF font assets and the rendered text they produce. Notice that the bitmap fonts produce text whose edges are more or less jagged/blurry, depending on how far the text is from the camera, and how it is transformed/distorted. The SDF font, on the other hand produces text with completely smooth edges regardless of the distance from the camera. A bitmap font, atlas texture and rendered result A smoothed bitmap, atlas texture and rendered result An SDF font, atlas texture and rendered result"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichText.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichText.html",
    "title": "Rich Text | Inventory System",
    "summary": "Rich Text Rich text tags alter the appearance and layout of text by supplementing or overriding TextMesh Pro GameObject properties. For example, you can use rich text tags to change the color or alignment of some, or all of your text without modifying its properties or material. To use rich text tags: Enter any supported rich text tags in the TextMeshPro Text input field, inline with the text you want to display. To disable rich text for a TextMesh Pro object: Open the TextMesh Pro GameObject in the Inspector, and disable the Text Mesh Pro > Extra Settings > Rich Text property. Rich Text Tags Rich text tags are similar to HTML or XML tags, but have less strict syntax. A simple tag consists of only the tag name, and looks like this: <tag> For example, the <b> tag makes text bold, while the <u> tag underlines it. Tag attributes and values Some tags have additional values or attributes, and look like this: <tag=\"value\"> or <tag attribute=\"value\"> For example <color=”red”> makes text red. Red is the color tag’s value. Similarly <sprite index=3> inserts the fourth sprite from the default Sprite Asset. index is an attribute of the sprite tag, and its value is 3. A tag, including its attributes, can be up to 128 characters long. The table below lists possible attribute/value types. Attribute/value type: Example Decimals 0.5 Percentages 25% Pixel values 5px Font units 1.5em Hex color values #FFFFFF (RGB) #FFFFFFFF (RGBA) #FF (A) Names Both <link=”ID”> and <link=ID> are valid. Tag scope and nested tags Tags have a scope that defines how much of the text they affect. Most of the time, a tag added to a given point in the text affects all of the text from that point forward. For example, adding the tag <color=\"red\"> at the beginning of the text affects the entire text block: <color=\"red\">This text is red Successive color tags Adding the same tag in the middle of the text block affects only the text between the tag and the end of the block : This text turns<color=\"red\"> red Successive color tags If you use the same tag more than once in a text block, the last tag supersedes all previous tags of the same type. <color=\"red\">This text goes from red<color=\"green\"> to green Successive color tags You can also limit the scope of most tags using a closing tag. Closing tags contain only a forward slash and the tag name, like this: </tag> Tags can also be nested so one tag’s scope is within another tag’s scope. For example: <color=red>This text is <color=green>mostly </color>red. Successive color tags The first <color> tag’s scope is the entire text block. The the second <color> tag has a closing tag that limits its scope to one word. When you nest tags, you don't have to close their scopes in the same order that you started them. Rich-text tags and right-to-left text TextMesh Pro's right-to-left editor does not distinguish between regular text and rich text tags. Rich text tags that you enter in the right-to-left editor do not work unless you type them right-to-left as well. The easiest way to apply rich text tags to right-to-left text is to type the text in the right-to-left editor, and then apply the tags in the regular editor."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextAlignment.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextAlignment.html",
    "title": "Text Alignment | Inventory System",
    "summary": "Text Alignment Each text object has an overall alignment, but you can override this with <align> tags. All horizontal alignment options are available except for Geometry Center. Normally you put these tags at the start of a paragraph. Successive alignment scopes don't stack. If you put multiple alignment tags on the same line, the last one overrides the others. The closing </align> tag reverts back to the object's overall alignment. Example: <align=\"left\"><b>Left-aligned</b> <align=\"center\"><b>Center-aligned</b> <align=\"right\"><b>Right-aligned</b> <align=\"justified\"><b>Justified:</b> stretched to fill the display area (except for the last line) <align=\"flush\"><b>Flush:</b> stretched to fill the display area (including the last line) Text Alignment"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextBoldItalic.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextBoldItalic.html",
    "title": "Bold and Italic | Inventory System",
    "summary": "Bold and Italic You can apply bold and italic styling to your text with the <b> and <i> tags respectively. The font Asset defines how bold and italicized text looks when rendered. The closing </b> and </i> tags revert to the text's normal appearance. Example: The <i>quick brown fox</i> jumps over the <b>lazy dog</b>. Bold and italic."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextCharacterSpacing.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextCharacterSpacing.html",
    "title": "Character Spacing | Inventory System",
    "summary": "Character Spacing The <cspace> tag allows you to adjust character spacing, either absolute or relative to the original font Asset. You can use pixels or font units. Postive adjustments push the characters apart, negative adjustments pull them together. The closing </cspace> tag reverts back to the font's normal spacing. Example: <cspace=1em>Spacing</cspace> is just as important as <cspace=-0.5em>timing. Character spacing"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextColor.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextColor.html",
    "title": "Text Color | Inventory System",
    "summary": "Text Color There are two ways to change text color with color tags: Use named colors, as in <color=\"colorName\"> The following color names are supported: black, blue, green, orange, purple, red, white, and yellow. Use hexadecimal values, as in <color=#FFFFFF> or <color=#FFFFFFFF> if you also want to define the alpha value. If you apply successive <color> tags in the same text, the last one takes precedence over the others until you either add another <color>tage or use a closing </color> tag to end the current color's scope. Example: <color=\"red\">Red <color=#005500>Dark Green <#0000FF>Blue <color=#FF000088>Semitransparent Red Successive color tags <color=\"red\">Red, <color=\"blue\">Blue,</color> and red again. Closing color tag"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextFont.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextFont.html",
    "title": "Font | Inventory System",
    "summary": "Font You can switch to a different font using <font=\"fontAssetName\">. The font you specify replaces the default font until you insert a closing <font> tag. Font tags can be nested. You can also use the material attribute to switch between different materials for a single font. You must place the font and material assets in the directory that is specified in the TextMesh Settings > Default Font Asset > Path field. The default path is Assets/TextMesh Pro/Resources/Fonts & Materials. If you don't have it in your project, select Window > TextMeshPro > Import TMP Essential Resources to add it. For more information, refer to Importing required resources into projects. To revert to the default font: Close all open font tags using </font> tag Use another <font> tag and set the font Asset name to default Example: Would you like <font=\"Impact SDF\">a different font?</font> or just <font=\"NotoSans\" material=\"NotoSans Outline\">a different material? Mixing fonts and materials"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextFontWeight.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextFontWeight.html",
    "title": "Font weight | Inventory System",
    "summary": "Font weight Use the <font-weight> tag to switch between the font weights available for the current Font Asset. You specify the weight using its numeric value, for example 400 for normal, 700 for bold, and so on. You can only apply font weights defined in the Font Asset properties. If you have not defined any font weights, you can still use values of 400 and 700 to apply the multipliers set in the Normal Weight and Bold Weight properties. The closing </font-weight> tag reverts to the original font specified for the TextMesh Pro object. Example: <font-weight=\"100\">Thin</font-weight> <font-weight=\"200\">Extra-Light</font-weight> <font-weight=\"300\">Light</font-weight> <font-weight=\"400\">Regular</font-weight> <font-weight=\"500\">Medium</font-weight> <font-weight=\"600\">Semi-Bold</font-weight> <font-weight=\"700\">Bold</font-weight> <font-weight=\"800\">Heavy</font-weight> <font-weight=\"900\">Black</font-weight> Font weights"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextGradient.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextGradient.html",
    "title": "Gradient | Inventory System",
    "summary": "Gradient The <gradient> tag applies a pre-defined gradient preset to text. For more information about creating gradient presets, see the documentation on Gradient Presets. The closing </gradient> tag reverts to the TextMesh pro object's original color. Example: Apply<b> <gradient=\"Yellow to Orange - Vertical\">any <gradient=\"Light to Dark Green - Vertical\">gradient <gradient=\"Blue to Purple - Vertical\">preset</gradient> </b>to your text Successive gradient tags ended with a closing </gradient> Note: When you apply a gradient using this tag, it's multiplied by the TextMesh Pro object's current vertex colors. This <gradient=\"Light to Dark Green - Vertical\">Light to Dark Green gradient</gradient> is tinted by the red vertex color Applying a green gradient to red text To apply the pure gradient to a selection of text, you can use a <color> tag to \"reset\" the color to white before applying the gradient. This <color=#FFFFFFFF><gradient=\"Light to Dark Green - Vertical\">Light to Dark Green gradient</gradient></color> is no longer tinted by the red vertex color \"Resetting\" the text's vertex color before applying a gradient"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextIndentation.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextIndentation.html",
    "title": "Indentation | Inventory System",
    "summary": "Indentation The <indent> tag controls the horizontal caret position the same way the <pos> tag does, but the effect persists across lines. Use this tag to create text patterns, such as bullet points, that work with word-wrapping. You specify indentation in pixels, font units, or percentages. Example: 1. <indent=15%>It is useful for things like bullet points.</indent> 2. <indent=15%>It is handy. Using indentation to make a list."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLetterCase.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLetterCase.html",
    "title": "Lowercase, Uppercase, and Smallcaps | Inventory System",
    "summary": "Lowercase, Uppercase, and Smallcaps The <lowercase>, <uppercase>, <allcaps> and <smallcaps> tags alter the capitalization of your text before rendering. The text in the Text field remains as you entered it. The <lowercase> and <uppercase> tags work as you would expect, converting to all capitals or no capitals before rendering. The <allcaps> tag is functionally identical to <uppercase>. The <smallcaps> tag works like <uppercase>, but also reduces the size of all characters that you entered in lowercase. Example: <lowercase>Alice and Bob watched TV.</lowercase> <uppercase>Alice and Bob watched TV.</uppercase> <allcaps>Alice and Bob watched TV.</allcaps> <smallcaps>Alice and Bob watched TV.</smallcaps> Modifying capitalization."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineBreak.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineBreak.html",
    "title": "Line Break | Inventory System",
    "summary": "Line Break Use the <br> tag to force a line break in text. Example: Add line breaks wherever you want Add line breaks <br>wherever <br>you <br>want Adding line breaks"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineHeight.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineHeight.html",
    "title": "Line Height | Inventory System",
    "summary": "Line Height Use the <line-height> tag to manually control line height. The line-height controls how far down from the current line the next line starts. It does not change the current line. Smaller values pull lines closer together. Larger values push them farther apart. You can specify the line height in pixels, font units, or percentages. Adjustments you make using this tag are relative to the line-height specified in the Font Asset. The </line-height> closing tag reverts to this height. Example: Line height at 100% <line-height=50%>Line height at 50% <line-height=100%>Rather cozy. <line-height=150%>Line height at 150% Such distance! Different line heights"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineIndentation.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLineIndentation.html",
    "title": "Line Indentation | Inventory System",
    "summary": "Line Indentation The <line-indent> tag inserts horizontal space directly after it, and before the start of each new line. It only affects manual line breaks (including line breaks created with the <br> tag, not word-wrapped lines. You can specify the indentation in pixels, font units, or percentages. The </line-indent> closing tag ends the indentation of lines. Example: <line-indent=15%>This is the first line of this text example. This is the second line of the same text. Indent every new line, with one tag"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLink.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextLink.html",
    "title": "Text Link | Inventory System",
    "summary": "Text Link You can use <link=\"ID\">my link</link> to add link metadata to a text segment. The link ID should be unique to allow you to retrieve its ID and link text content when the user interacts with your text. You do not have to give each link a unique ID. You can reuse IDs when it makes sense, for example when linking to the same data multiple times. The linkInfo array contains each ID only once. While this link enables user interaction, it does not change the appearance of the linked text. You have to use other tags for that."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMargins.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMargins.html",
    "title": "Margin | Inventory System",
    "summary": "Margin You can increase the horizontal margins of the text with the <margin> tag. If you only want to adjust the left or right margin, you can use the <margin-left> or <margin-right> tag. You can specify the margins in pixels, font units, and percentages. Negative values have no effect. Adjustments you make using this tag are relative to the margins specified in the TexMesh Pro object. The </margin> closing tag reverts to this value. Example: Our margins used to be very wide. <margin=5em>But those days are long gone. Adjusting margins"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMark.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMark.html",
    "title": "Mark | Inventory System",
    "summary": "Mark The <mark> tag adds an overlay on top of the text. You can use it to highlight portions of your text. Because markings are overlaid on the text, you have to give them a semitransparent color for the text to show through. You can do this by specifying the color using a hex value that includes Alpha. You cannot combine marks. Each tag affects the text between itself and the next <mark> tag or a closing </mark> tag. Example: Text <mark=#ffff00aa>can be marked with</mark> an overlay. Marked text"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMonospace.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextMonospace.html",
    "title": "Monospacing | Inventory System",
    "summary": "Monospacing You can override a font's character spacing and turn it into a monospace font with the <mspace> tag. This gives all characters the same amount of horizontal space. You can specify the character width in pixels or font units. The </mspace> closing tag clears all monospace overrides. Example: Any font can become <mspace=2.75em>monospace, if you really want it. Treating a font as monospace"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextNoBreak.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextNoBreak.html",
    "title": "No Break | Inventory System",
    "summary": "No Break Use the <nobr> tag to keep specific words together, and not be separated by word wrapping. The closing </nobr> tag reverts to the default behavior of allowing words to break where the line wraps. If you apply the <nobr> tag to a segment of text that is too big to fit on one line, the segment will break wherever the line wraps. Example: You don't want <nobr>I M P O R T A N T</nobr> things to be broken up. The important parts stay together"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextNoParse.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextNoParse.html",
    "title": "Noparse | Inventory System",
    "summary": "Noparse The <noparse> tag creates a scope that TextMesh Pro does not parse. This is useful for rendering text that TextMesh Pro normally interprets as a rich text tag, without disabling rich text tags. Example: Use <noparse><b></noparse> for <b>bold</b> text. Prevent parsing of some tags"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextOpacity.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextOpacity.html",
    "title": "Text Opacity (Alpha) | Inventory System",
    "summary": "Text Opacity (Alpha) Use the <alpha> tag to change text opacity. It works with hexadecimal values. Example: <alpha=#FF>FF <alpha=#CC>CC <alpha=#AA>AA <alpha=#88>88 <alpha=#66>66 <alpha=#44>44 <alpha=#22>22 <alpha=#00>00 Successive <alpha> tags"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextPageBreak.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextPageBreak.html",
    "title": "Page Break | Inventory System",
    "summary": "Page Break You can use the <page> tag to insert page breaks in your text. This cuts the text into separate blocks. For page breaks to work, you must set the TextMesh Pro object's Overflow mode to Page."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextPos.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextPos.html",
    "title": "Horizontal Position | Inventory System",
    "summary": "Horizontal Position The <pos> tag gives you direct control over the horizontal caret position. This works best with horizontal alignment. The <pos> tag's position in the line has no effect on the caret position. This tag is best used with left alignment. You can specify the horizontal position in pixels, font units, or percentages. Example: at <pos=75%>75% at <pos=25%>25% at <pos=50%>50% at 0% Setting caret positions"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextRotate.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextRotate.html",
    "title": "Rotate | Inventory System",
    "summary": "Rotate Use the <rotate> tag to rotate each character about its center. Specify the amount of rotation in degrees. Positive values rotate characters counter-clockwise. Negative values rotate them clockwise. Rotation affects the spacing between characters, and may cause characters to overlap in some cases. Use the <cspace> tag to correct character spacing as needed. Example: Rotate text <rotate=\"-10\">counter-clockwise</rotate> or <rotate=\"10\">clockwise</rotate> Text rotated counter-clockwise (left) and clockwise (right) Rotate text <rotate=\"45\">counter-clockwise</rotate> More rotation makes it more likely that characters overlap Rotate text <cspace=\"15\"><rotate=\"45\">counter-clockwise</rotate></cspace> The <cspace> tag adjusts character spacing, and can help correct overlap caused by rotation"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSize.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSize.html",
    "title": "Font Size | Inventory System",
    "summary": "Font Size Use the <size> tag to adjust the font size of your text. You can specify the new size in pixels (px), font units (em), or percentages (%). Pixel adjustments can be absolute (5px, 10px, and so on) or relative (+1 or -1, for example). Relative sizes are based on the original font size, so they're not cumulative. Font unit adjustments are always relative to the original font size. For example, <size=1em> sets the font size to the original size, <size=2em> doubles the size, and <size=0.5em> halves it. Example: <size=100%>Echo <size=80%>Echo <size=60%>Echo <size=40%>Echo <size=20%>Echo Adjusting font size"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSpace.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSpace.html",
    "title": "Horizontal Space | Inventory System",
    "summary": "Horizontal Space The <space> tag inserts a horizontal offset, as if you inserted multiple spaces. You can specify the offset in pixels or font units. When the <space> tag touches adjacent text, it appends or prepends the offset to that text, which affects how the text wraps. If you do not want the offset to wrap independently of adjacent text, make sure to add a space character on either side of the <space> tag. Example: Give me some <space=5em> space. Adding some space"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSprite.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSprite.html",
    "title": "Sprite | Inventory System",
    "summary": "Sprite The <sprite> tag inserts images from a Sprite Asset into your text. Sprite assets must be located in the folder specified in the TextMesh Pro settings. You can access sprites from the default sprite assets by index <sprite index=1> or by name <sprite name=\"spriteName\">. When accessing a sprite from the default Asset by index, you can also use the index shorthand, <sprite=1>, To use sprites from a different Asset, specify the Asset before accessing the sprites by index <sprite=\"assetName\" index=1> or by name <sprite=\"assetName\" name=\"spriteName\">. Adding the tint=1 attribute to the tag tints the sprite with the TextMesh Pro object's Vertex Color. You can choose a different color by adding a color attribute to the tag (color=#FFFFFF). Example: Sprites! <sprite=0> More sprites! <sprite index=3> And even more! <sprite name=\"Default Sprite Asset_4\" color=#55FF55FF> Inserting sprites from the default sprite asset"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextStrikethroughUnderline.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextStrikethroughUnderline.html",
    "title": "Strikethrough and Underline | Inventory System",
    "summary": "Strikethrough and Underline You can add additional lines that run along your text. The <underline> tag draws the line slightly below the baseline to underline the text. The vertical offset is defined in the Font Asset. The <strikethrough> tag places the line slightly above the baseline so it crosses out the text. Example: The <s>quick brown</s> fox jumps over <u>the lazy dog</u>. Strikethrough and underline"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextStyle.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextStyle.html",
    "title": "Style | Inventory System",
    "summary": "Style Apply custom styles using the <style> tag. For more information about creating custom styles, see the documentation on Style Sheets. The opening <style> tag must contain the style name. The closing </style> tag, which simply closes the last style opened. Example: <style=\"Title\">Styles</style> You can create your own. Applying a custom style"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSubSuper.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSubSuper.html",
    "title": "Subscript and Superscript | Inventory System",
    "summary": "Subscript and Superscript Use the <sub> and <sup> tags to render text as superscript or subscript. This is often used in scientific notation and ordinal numbering (1st, 2nd, etc.). Set the offset and size for sub- and superscript in the Font Asset. Example: We have 1m<sup>3</sup> of H<sub>2</sub>O. Subscript and superscript"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSupportedTags.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextSupportedTags.html",
    "title": "Supported Rich Text Tags | Inventory System",
    "summary": "Supported Rich Text Tags The following table is a quick reference of supported rich text tags. For details, see the main pages for specific tags. Tag: Description: Notes: <align> Changes the text's horizontal alignment. <allcaps> Converts text to uppercase before rendering. Functionally identical to <uppercase>. <alpha> Changes text opacity. <b> Renders text in boldface. <br> Forces a line break in text. <color> Changes text color or color and opacity. <cspace> Changes spacing between characters. <font> Changes text font and, optionally, material. <font-weight> Changes the text's font weight to any of the weights defined in the font Asset. <gradient> Applies a gradient preset to text. <i> Renders text in italics. <indent> Indents all text between the tag and the next hard line break. <line-height> Modifies the line height relative to the default line height specified in the font Asset. <line-indent> Indents the first line after every hard line break. New lines created by word-wrapping are not indented. <link> Specifies a link ID for a text segment. <lowercase> Converts text to lowercase before rendering. <margin> Gives the text horizontal margins. You can set margins for both sides together or each side individually <mark> Highlights the text with a colored overlay. The overlay must be translucent (alpha less than 1) for the text to show through. <mspace> Renders the text as monospace. <nobr> Keeps a segment of text together. <noparse> Prevents parsing of text that TextMesh Pro would normally interpret as rich text tags. <page> Adds a page break to the text. The text's Overflow mode must be set to Page for page breaks to work. <pos> Sets the horizontal caret position on the current line. <rotate> Rotates each character about its center. <s> Renders a line across the text. <size> Adjusts the font size for a specified portion of the text. <smallcaps> Converts text to uppercase before rendering. <space> Adds a horizontal offset between itself and the rest of the text. <sprite> Adds a sprite to the text. By default, TextMesh Pro looks in the default sprite assets, but you can use tag attributes to retrieve sprites from other assets. <strikethrough> Draws a line slightly above the baseline so it crosses out the text. <style> Applies a custom style to the text. <sub> Converts the text to subscript. <sup> Converts the test to superscript. <u> Draws a line slightly below the baseline to underline the text. <uppercase> Converts text to uppercase before rendering. Functionally identical to <allcaps>. <voffset> Gives the baseline a vertical offset. <width> Changes the horizontal size of text area."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextVOffset.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextVOffset.html",
    "title": "Vertical Offset | Inventory System",
    "summary": "Vertical Offset Use the <voffset> tag to offset the text baseline vertically. This adjusts the line height accordingly to accommodate the text's offset position. You can compensate for that adjustment by manually adjusting the line height. Specify the offset in pixels or font units. The offset is always relative to the original baseline. The </voffset> closing tag resets the baseline back to its original position. Example: Up <voffset=1em>up <voffset=2em>UP</voffset> and <voffset=-0.5em>down</voffset> we go again. Vertical offset"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextWidth.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/RichTextWidth.html",
    "title": "Text Width | Inventory System",
    "summary": "Text Width Use the <width> tag adjust the horizontal size of text area. The change takes effect on the current line, after the tag. Typically, you place the tag at the start of a paragraph. If you add more than one ,width> tag to a line, the last one takes precedence over the others. You can specify the width in either pixels, font units, or percentages. The adjusted width cannot exceed the TextMesh Pro object's original width. The closing </width> tag reverts to the original width. Example: I remember when we had lots of space for text. <width=60%>But those days are long gone. Adjusting text area width"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Settings.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Settings.html",
    "title": "Settings | Inventory System",
    "summary": "Settings TextMesh Pro’s project-wide settings are stored in a special Asset named TMP Settings. This Asset must be stored in a Resources folder. By default it’s in the Assets/TextMesh Pro folder. To edit the settings, either select the Asset in the Project View or open the Project Settings window and choose TextMesh Pro from the category list. TextMesh Pro Settings The Settings are divided into the following groups: Group: Function: A Default Font Asset: Set the default font for text objects. B Fallback Font Assets: Choose font assets to search when TexMesh Pro can’t find a character in a text object’s main font Asset. C Fallback Material Settings: Set style options for characters retrieved from fallback fonts. D Dynamic Font System Settings: Set options for handling missing characters. E Text Container Default Settings: Control the size of the text container for new text objects. F Text Component Default Settings: Set the basic text formatting options for new text objects. G Default Sprite Asset: Choose a default Sprite Asset to use for for rich text sprite tags that do not specify an Asset, and set other sprite-related options. H Default Style Sheet: Choose a default style sheet. I Color Gradient Presets: Choose a location to store color gradient presets. J Line Breaking for Asian Languages: Define leading and following characters in order to get proper line breaking when using Asian fonts. Default Font Asset Property: Function: Default Font Asset Specify the default font used when you create a new text object. Path Specify where to store font assets. The Path must point to a subfolder of a Resources folder. Fallback Font Assets When a text object contains a character that is not in its font Asset, TextMesh Pro searches these font assets for the glyph. If the object’s font assets has a local fallback font list, TextMesh Pro searches the fonts in that list first. Property: Function: Fallback Font Assets List Manage the global fallback font assets. Click + and - to add and remove font slots. Click the circle icon next to a font to choose a font Asset using the Object Picker. Drag the handles on the left side of any font Asset to reorder the list. Fallback Material Settings Property: Function: Match Material Presets Enable this setting to make glyphs from the fallback font match the style of the main font. When TextMesh Pro uses a glyph from a fallback font, it creates a material with the same settings as the main font’s material. This looks best when the main font and the fallback font are similar. Dynamic Font System Settings These are project-wide settings for handling missing glyphs. Property: Function: Get Font Features at Runtime Replacement Specify the ID of the character to use when TextMesh Pro cannot find a missing glyph in any of the fallback fonts. The default value of 0 produces the outline of a square. Disable Warnings Enable this setting to prevent Unity from logging a warning for every missing glyph. Text Container Default Settings These settings define the default size for text containers in new text objects. Property: Function: TextMeshPro Set the default size of text containers for new TextMesh Pro 3D GameObjects, in Unity units. TextMeshPro UI Set the default size of text containers for new TextMesh Pro UI GameObjects, in Unity units. Enable Raycast Target Enable this option to make TextMesh Pro GameObjects targets for raycasting by default. When you disable this option, the UI ignores TextMesh Pro GameObjects by default when determining what the cursor interacts with. Auto Size Text Container Enable this option to automatically size text containers to fit the text when creating new TextMesh Pro UI GameObjects. Text Component Default Settings These settings define default values for new text objects. After adding a text object to the Scene, you can adjust these settings in the object's TextMesh Pro Inspector. Property: Function: Default Font Size Set the default font size, in points. Text Auto Size Ratios Set the default Min to Max size ratio TextMesh Pro uses when it sets font size automatically. Word Wrapping Enable this option to turn word wrapping on for all new text objects. Kerning Enable this option to toggle kerning on for all new text objects. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the results aren't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites. Tint All Sprites By default, sprites aren't affected by the text's vertex colors. Enable Tint All Sprites changes this. Parse Escape Sequence Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Default Sprite Asset Property: Function: Default Sprite Asset Choose the Sprite Asset for TextMesh Pro GameObjects to use by default. IOS Emoji Support Toggle support for iOS emoji. Path Specify where to store Sprite Assets. The Path must point to a subfolder of a Resources folder. Default Style Sheet Property: Function: Default Style Sheet You can choose a single style sheet Asset, which is used by all text objects in the project. Color Gradient Presets Property: Function: Path Specify where to store Sprite Assets. The Path must point to a subfolder of a Resources folder. Line Breaking for Asian Languages To obtain correct line-breaking behavior for Asian languages, you must specify which characters behave as leading and following characters. This is done via two text assets. Property: Function: Leading Characters Specify the text file that contains the list of leading characters. Following Characters Specify the text file that contains the list of following characters."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Shaders.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Shaders.html",
    "title": "Shaders | Inventory System",
    "summary": "Shaders TextMesh Pro has been designed to take advantage of signed distance field (SDF) rendering and includes a collection of shaders for this purpose. There are also bitmap-only shaders, in case you don't want to use SDF rendering. All shaders have a desktop and a mobile version. The mobile versions are less demanding and suitable for mobile devices, but support fewer effects. All shaders can be found in the shader menu under TextMeshPro and TextMeshPro / Mobile. SDF Shaders There are three variants of the SDF shader, known as Distance Field, Distance Field (Surface), and Distance Field Overlay. The regular and overlay shaders are unlit, so they don't interact with the Scene lighting. They can support locally simulated lighting effects instead. The surface shader versions do interact with the Scene lighting. They use Unity's surface shader framework and are quite flexible, but also more demanding on the GPU. They are not physically based shaders. SDF shaders can use the distance data to generate special effects, like outlines, underlays, and bevels. These effects often increase the visual size of the text. When taken to their extremes, you might see artifacts appear around the edges of character sprites. If this happens, scale down the effects. For example, a soft dilated underlay with large offsets might take things too far. The artifacts occur because data from adjacent characters in the font atlas will bleed into the current character. You can increase the padding when importing a font to give the effects more space."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmap.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmap.html",
    "title": "Bitmap Shader | Inventory System",
    "summary": "Bitmap Shader The Bitmap shader is designed to use bitmap-only fonts. It treats the font atlas like a regular texture, displaying it directly, and does not support any text effects. Bitmap-textured text becomes blocky when you zoom in on it. Properties Face: Controls the text's overall appearance. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face Description Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. Stencil ID The reference value. For more information, refer to the ref parameter in ShaderLab command: Stencil. Stencil Comp A comparison operation. For more information, refer to the comparisonOperation parameter in ShaderLab command: Stencil."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmapCustomAtlas.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmapCustomAtlas.html",
    "title": "Bitmap Custom Atlas Shader | Inventory System",
    "summary": "Bitmap Custom Atlas Shader The Bitmap shader is designed to use bitmap-only fonts. It treats the font atlas like a regular texture, displaying it directly, and does not support any text effects. Bitmap-textured text becomes blocky when you zoom in on it. Properties Face: Controls the text's overall appearance. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face Description Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. Stencil ID The reference value. For more information, refer to the ref parameter in ShaderLab command: Stencil. Stencil Comp A comparison operation. For more information, refer to the comparisonOperation parameter in ShaderLab command: Stencil."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmapMobile.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersBitmapMobile.html",
    "title": "Bitmap Mobile Shader | Inventory System",
    "summary": "Bitmap Mobile Shader The mobile Bitmap shader is designed to use bitmap-only fonts. It treats the font atlas like a regular texture, displaying it directly, and does not support any text effects. Bitmap-textured text becomes blocky when you zoom in on it. Unlike the regular Bitmap shader, the mobile Bitmap shader does not support textures for the text face. Properties Face: Controls the text's overall appearance. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Diffuse Power Increase this value to multiply the text Color, which brightens the text. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceField.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceField.html",
    "title": "Distance Field / Distance Field Overlay Shaders | Inventory System",
    "summary": "Distance Field / Distance Field Overlay Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Lighting: Simulates local directional lighting on the text. Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed X/Y Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Lighting The Distance Field shader does not react to Scene lighting. Instead, it uses the settings in this group to simulate local directional lighting, and light effects. If you want your text to react to Scene lighting, use the Distance Field Surface shader. The Lighting properties are grouped into the following sections Bevel: Local Lighting: Bump Map: Environment Map: Bevel A bevel adds the illusion of depth to your text. It works like a normal map, except that the shader calculates the bevel using the font’s signed distance field. Bevels are prone to showing artifacts, especially when they are too pronounced. These artifacts are more obvious on some materials than on others. Sometimes, artifacts that are more obvious on a simple material are hardly noticeable on a more complex material. Although bevels work best with text that has an outline, you can apply them to text with no outline. In that case, you must set a positive Width, and should set a negative Offset to ensure that the whole bevel is visible. Property: Description Type Choose the type of bevel to apply Outer Bevel Produces raised lettering with sloped sides. The bevel starts at the outside of the outline and increases in height until it reaches the inside of the outline. Inner Bevel Produces text with a raised outline. The bevel starts at the outside of the outline, increases in height until it reaches the middle of the outline, and decreases in height until it reaches the inside of the outline. Amount Adjust the steepness of the bevel. This setting defines the apparent difference in height between low and high regions of the bevel. Offset Offset the bevel from its usual position so it no longer matches the outline. Different offsets produce very different bevels. This is especially useful when you apply a bevel to text with no outline. Width Adjust the bevel size. Set a value of 0 to make the bevel fill the full thickness of the outline. Set a positive value to make the bevel extend beyond both sides of the outline. Set a negative value to shrink the bevel toward the middle of the outline. Roundness Increase this value to smooth out more angular regions of the bevel. The effect is often quite subtle. Clamp Set this value to limit the maximum height of the bevel. Higher values mean the bevel reaches its maximum height sooner. Clamped outer bevels end before reaching the inside edge of the outline. Clamped inner bevels have a larger flat region in the middle of the outline. Local Lighting These settings control simulated local directional lighting. They work in combination with the Bevel, Bump Map, and Environment Map settings. Property: Description Light Angle Adjust the angle, in radians, of the simulated local light illuminating the text. The default angle is approximately π (pi) radians, which positions the light above the text. Specular Color Set the tint for specular highlights. These are the highlights you see when the text directly reflects the simulated local light source. Specular Power Adjust the appearance of specular highlights. Larger values produce larger and brighter highlights. Reflectivity Power Adjust the how much the Environment Map contributes to the final color of the text. The higher the value, the more the text appears to reflect the environment map texture and color. Diffuse Shadow Adjust the overall shadow level. Higher values produce stronger shadowing, and consequently fewer apparent light effects on the text. Ambient Shadow Adjust the ambient light level. Settings lower than 1 darken the text color based on the slope of the text. This is a subtle effect that is only noticeable with strong bevels or normal maps. Bump Map You can use a normal map as a bump map to add bumpiness to the text. The bump map affects both the text face and outline, but you can control how strongly it affects each one individually. If your text has both a bevel and a bump map, the two mix together. Property: Description Texture Select a normal map texture to use as a bump map. Face Control how much the bump map affects the text face. A value of 0 shows no effect while a value of 1 shows the full effect of the bump map. Outline Control how much the bump map affects the text outline. A value of 0 shows nothing while a value of 1 shows the full effect of the bump map. Environment Map You can use an environment map to add a reflection effect to your text face or outline, or for special image effects. The environment texture must be a cubemap. You can provide a static cubemap or create one at run time via a script. Property: Description Face Color Choose a color to use to tint reflections on the text face. This color is multiplied with the environment map before the reflectivity effect is applied to the text face. When this color is set to black, the environment map has no effect on the text face. When this color is set to white, the environment map is at full strength on the text face. Outline Color Choose a color to use to tint reflections on the text outline. This color is multiplied with the environment map before the reflectivity effect is applied to the text outline. When this color is set to black, the environment map has no effect on the text outline. When this color is set to white, the environment map is at full strength on the text outline. Texture Choose a cubemap texture to use as an environment map. Rotation Rotate the environment map to control which parts of the texture are visible in the reflection. You can animate the rotation to create a sense of movement. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Mask Mask Off Mask Hard Mask Soft Mask Bounds Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Match Bounds Renderer Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldMaskingMobile.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldMaskingMobile.html",
    "title": "Distance Field Masking Mobile Shader | Inventory System",
    "summary": "Distance Field Masking Mobile Shader The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Debug Settings The debug section contains options for defining and controlling masking. It also exposes some of the shader’s internal properties, which can be helpful for troubleshooting. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Mask Texture Choose a texture file to use as a mask. Black and white images work best. By default, black regions of the image mask the text, while white areas reveal it. Inverse Mask Invert the mask so that white regions of the image mask the text, while black areas reveal it. Edge Color Tint the edge of the mask with a specific color. The softer the edge, the larger the tinted region. Edge Softness Make the edges of the mask softer or harder. A value of 0.5 applies the mask as-is. Higher values soften the edges. Lower values make them sharper. Wipe Position Control the extent to which the text is masked. A value of 0.5 masks the text exactly as defined by the Mask Texture. A value of 0 fully exposes the text (no masking at all). A value of 1 hides the text (all of the text is masked). Softness X/Softness Y Apply soft masking to the text in either axis. Increase the X value to add soft masking to the left and right sides of the text. Increase the Y value to add soft masking at the top and bottom. This masking is added to any masking defined by the Mask Texture. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldMobile.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldMobile.html",
    "title": "Distance Field / Distance Field Overlay Mobile Shaders | Inventory System",
    "summary": "Distance Field / Distance Field Overlay Mobile Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldSurface.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldSurface.html",
    "title": "Distance Field (Surface) Shader | Inventory System",
    "summary": "Distance Field (Surface) Shader The Distance Field (Surface) surface shader is similar to the Distance Field shader, but rather than simulating local directional lighting, it interacts with Scene lighting. It is not a physically based shader. This shader uses Unity's surface shader framework, which makes it quite flexible, but also more demanding on the GPU. Properties Face: Controls the appearance of the text face. Outline: Controls the appearance of the text outline. Bevel: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. SurfaceLighting: Controls the appearance of locally simulated lighting on the text. Bump Map: Adds bumpiness to the text face and/or outline using a normal map texture. Environment Map: Adds a reflection effect to the text face and/or outline using a normal map texture Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face You edit Distance Field Surface shader properties in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Gloss Adjust the glossiness of the text face. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specular highlights. Outline Description Property: Description Color Adjust the color for the text outline. Tthe outline is not visible unless you set a Thickness value greater than 0. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Gloss Adjust the glossiness of the text outline. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specualr highlights. Bevel A bevel adds the illusion of depth to your text. It works like a normal map, except that the shader calculates the bevel sing the font’s signed distance field. Bevels are prone to showing artifacts, especially when they are too pronounced. These artifacts are more or less obvious, depending on the material you use. Sometimes, artifacts that are more obvious on a simple material are hardly noticeable on a more complex material. Although bevels work best with text that has an outline, you can apply them to text without an outline as well. Property: Description Type Choose the type of bevel to apply Outer Bevel Produces raised lettering with sloped sides. The bevel starts at the outside of the outline and increases in height until it reaches the inside of the outline. Inner Bevel Produces text with a raised outline. The bevel starts at the outside of the outline, increases in height until it reaches the middle of the outline, and decreases in height until it reaches the inside of the outline. Amount Adjust the steepness of the bevel. This setting defines the apparent difference in height between low and high regions of the bevel. Offset Offset the bevel from its usual position so it no longer matches the outline. Different offsets produce very different bevels. This is especially useful when you apply a bevel to text with no outline. Width Adjust the bevel size. Set a value of 0 to make the bevel fill the full thickness of the outline. Set a positive value to make the bevel extend beyond both sides of the outline. Set a negative value to shrink the bevel toward the middle of the outline. If you are setting a bevel for text with no outline, you must set a positive Width. You should also set a negative Offset to ensure that the whole bevel is visible. Roundness Increase this value to smooth out more angular regions of the bevel. The effect is often quite subtle. Clamp Set this value to limit the maximum height of the bevel. Higher values mean the bevel reaches its maximum height sooner. Clamped outer bevels end before reaching the inside edge of the outline. Clamped inner bevels have a larger flat region in the middle of the outline. Surface Lighting These settings control simulated local directional lighting. They work in combination with the Bevel, Bump Map, and Environment Map settings. Property: Description Specular Color Set the tint for specular highlights. These are the highlights you see when the text directly reflects the simulated local light source. Bump Map You can use a normal map as a bump map to add bumpiness to the text. The bump map affects both the text face and outline, but you can control how strongly it affects each one individually. If your text has both a bevel and a bump map, the two mix together. Property: Description Texture Select a normal map texture to use as a bump map. Face Control how much the bump map affects the text face. A value of 0 shows no effect while a value of 1 shows the full effect of the bump map. Outline Control how much the bump map affects the text outline. A value of 0 shows nothing while a value of 1 shows the full effect of the bump map. Environment Map An environment map can be used to add a reflection effect to your text face or outline. You can either use it for reflections of a static Scene or for special image effects. The mobile shaders do not support this.The environment texture is a cubemap. You can either provide a static cubemap or create one at run time via a script. Property: Description Face Color Choose a color to use to tint reflections on the text face. This color is multiplied with the environment map before the reflectivity effect is applied to the text face. When this color is set to black, the environment map has no effect on the text face. When this color is set to white, the environment map is at full strength on the text face. Outline Color Choose a color to use to tint reflections on the text outline. This color is multiplied with the environment map before the reflectivity effect is applied to the text outline. When this color is set to black, the environment map has no effect on the text outline. When this color is set to white, the environment map is at full strength on the text outline. Texture Choose a cubemap texture to use as an environment map. Rotation Rotate the environment map to control which parts of the texture are visible in the reflection. You can animate the rotation to create a sense of movement. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldSurfaceMobile.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/ShadersDistanceFieldSurfaceMobile.html",
    "title": "Distance Field (Surface) Mobile Shader | Inventory System",
    "summary": "Distance Field (Surface) Mobile Shader The Distance Field (Surface) surface shader is similar to the Distance Field shader, but rather than simulating local directional lighting, it interacts with Scene lighting. It is not a physically based shader. This shader uses Unity's surface shader framework, which makes it quite flexible, but also more demanding on the GPU. Properties Face: Controls the appearance of the text face. Outline: Controls the appearance of the text outline. Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face You edit Distance Field Surface shader properties in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Gloss Adjust the glossiness of the text face. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specular highlights. Outline Description Property: Description Color Adjust the color for the text outline. Tthe outline is not visible unless you set a Thickness value greater than 0. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Gloss Adjust the glossiness of the text outline. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specualr highlights. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Sprites.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/Sprites.html",
    "title": "Sprites | Inventory System",
    "summary": "Sprites TextMesh Pro allows you to include sprites in your text via rich text tags. To use sprites in your Scene, you need a Sprite Asset. You create sprite assets from atlas textures that each contain a given set of sprites. A sprite atlas texture You can use as many sprite atlases and assets as you like, but keep in mind that using multiple atlases per text object results in multiple draw calls for that object, which consumes more system resources. As a rule, try to stick to one atlas per object. Note: Sprites are regular bitmap textures, so make sure that their resolution is high enough to display correctly on your target platforms. Using Sprite Assets To use a sprite Asset in your project, put it in a Resources/Sprites folder. This allows TextMesh Pro to find it. Once you've added/created your sprite assets, you can set one as the default source for sprites in the project. You set the default sprite Asset in the TextMesh Pro Settings. You can also choose sprite assets to use with specific text objects. Edit a TexMesh Pro 3D or TextmeshPro UI Asset to specify a sprite Asset to use with the font. Creating a Sprite Asset You create sprite assets from atlas textures. Although sprite assets and their source textures are separate entities, you must keep the source textures in the project after creating the sprite assets. Select the texture you want to use for the Sprite Asset. In the Inspector, change the following Texture Importer properties. Set the Texture Type to Sprite (2D and UI). Set the Sprite Mode to Multiple. Open the Sprite Editor from the Inspector, or choose Window > 2D > Sprite Editor from the menu, and use it to divide the texture into individual sprites. With the texture still selected, choose Asset > Create > TextMesh Pro > Sprite Asset from the menu to create a new sprite Asset. After creating the sprite Asset, you can revert the atlas texture's Texture Type to its original setting. Sprite Asset Properties The Sprite Asset properties are divided into the following groups: Sprite Info: Provides references to the sprite Asset's material and source texture. Fallback Sprite Assets: Provides references to the sprite Asset's material and source texture. Sprite List: Provides references to the sprite Asset's material and source texture. Sprite Info Property: Function: Sprite Atlas A reference to the sprite Asset's source texture. Default Material A reference to the sprite Asset's material, which it uses to render sprites. Fallback Sprite Assets When TextMesh Pro can't find a glyph in this sprite assets, it searches the fallback sprite assets that you specify here. Property: Function: Fallback Sprite Asset List Manage the fallback sprite assets. Click + and - to add and remove font slots. Click the circle icon next to a font to choose a font Asset using the Object Picker. Drag the handles on the left side of any font Asset to reorder the list. Sprite List Property: Function: Sprite Search Search the sprite list by ID or Name. Search results are ordered by ID, lowest to highest. Previous Page / Next Page Long sprite lists are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Sprite Properties Manage the sprites in this Asset. Click a sprite to make it active. Click Up or Down to move the sprite up or down in the list. Enter an ID in the text field and click Goto to move the sprite to that position in then list. Note: Moving a sprite updates its ID and the IDs of all preceding sprites accordingly. Click + to add a copy of the sprite to the list. Click - to remove the sprite from the list. ID A unique ID for the sprite, based on its portion in the list. You can use this value in rich text tags tags to add this sprite to text. Reordering the list updates the IDs of any affected sprites Unicode Name A unique name for the sprite. You can change this value, but it must be unique in the list You can use this value in rich text tags to add this sprite to text. X, Y, W, H The rectangular area the character occupies in the sprite atlas. OX, OY Control the placement of the sprite, defined at its top-left corner relative to its origin on the baseline. Adv. Specify how far to advance along the baseline before placing the next sprite. SF Change this scaling factor value to adjust the size of the sprite. Global Offsets & Scale Use these settings to override the following values for all sprites in the Asset: OX, OY, ADV., and SF."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/StyleSheets.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/StyleSheets.html",
    "title": "Style Sheets | Inventory System",
    "summary": "Style Sheets Use style sheets to create custom text styles that you can apply to text using the <style> rich text tag. A custom style can include opening and closing rich text tags, as well as leading and trailing text. For example, you might want headings in your text to be big, red, bold, with an asterisk to either side and a line break at the end. Instead of typing this for every heading: <font-weight=700><size=2em><color=#FF0000>*Heading*</color></size></font-weight><br> You can create a style, called H1 that includes all of that formatting: You can then format all of your headings with a single <style> tag: <style=\"H1\">Heading</style> The default style sheet The default style sheet is the style sheet that every TextMesh Pro object in your TextMesh Pro ships with a default style sheet stored in the TextMesh Pro > Resources > Style Sheets folder, but you can set any style sheet to be the default. To change the default style sheet, set the Default Style Sheet > Default Style Sheet option in the TextMesh Pro settings. Per-object style sheets Creating custom style sheets To create a new style sheet, choose Assets > Create > TextMesh Pro > Style Sheet from the menu. This adds a new TextMesh Pro style sheet to the Project. Open it in the Inspector to add custom styles."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObject3DText.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObject3DText.html",
    "title": "3D Text GameObjects | Inventory System",
    "summary": "3D Text GameObjects By default, a TextMesh Pro 3D Text GameObject has the following components: Rect Transform: Controls the GameObject's position and size. For more information, see the Rect Transform documentation in the Unity Manual. Note Note: If you want to use the Rect Transform component's anchoring system, the TextMesh Pro component's parent GameObject must also have a Rect Transform component. Mesh Renderer: Renders the GameObject. For more information, see the Mesh Renderer documentation in the Unity Manual. TextMesh Pro UGUI (Script): Contains the text to display, and the properties that control its appearance and behavior. These properties are described below. Material: A Unity material that uses one of the TextMesh Pro shaders to further control the text's appearance. For more information see the Shaders section. Properties Overview Text input A Text: Where you enter the text to display, along with any rich text markup. Main settings B Font: Specifies the font to use, as well as basic font attributes (size, style, and so on). C Color: Defines the base color or color gradient for the text D Spacing: Controls spacing between characters, words, lines and, paragraphs. E Alignment: Controls horizontal and vertical text alignment. F Wrapping and Overflow: Controls word wrapping and defines what happens when text doesn't fit inside its display area. G UV Mapping: Controls how textures are mapped to the face and outline of the text. H Extra Settings: Additional options for controlling the appearance and behavior of text. Text Input The text section is where you enter the text to display, and optionally customize it using rich text markup. Property: Function: Text The input field for text to display. Enable RTL Editor Enable this option to display text right-to-left instead of left-to-right. The Inspector displays an additional input field where you can view the reversed text and edit it directly. The text is reversed before it is displayed on screen or rendered. Main Settings The Main Settings section contains the properties needed to define the basic appearance of text. You can further customize the look of text by changing or editing its material. Font The fonts settings panel is where you choose a font for your text, and customize the font style. Property: Function: Font Asset Choose a font Asset for the TextMesh Pro GameObject to use. TextMesh Pro ships with several font assets, and you can create others from standard font files such as truetype (ttf) fonts. Note: You can set the default font Asset for new text objects in the TextMesh Pro settings. Material Preset Choose a material for your font. Each font Asset has a default material, but you can also create customized materials for it. This preset list includes all materials whose names contain the font Asset's name, and use the corresponding font atlas texture. Font Style Enable standard text styling options. You can use these options in any combination, except for the casing options (lowercase, uppercase, and small caps), which are mutually exclusive. B Bold the text. The appearance of bold text is defined in the font Asset properties. I Italicize the text. The appearance of italicized text is defined in the font Asset properties. U Underline the text. This renders an extra line below the baseline. S Add a strikethrough line to the text. This renders an extra line above the baseline. ab Convert the text to lowercase before rendering. This does not change text casing in the Text field. AB Convert the text to uppercase before rendering. This does not change text casing in the Text field. SC Use small caps. The text is displayed in all uppercase, but letters you actually entered in uppercase are larger. Font Size Specify the text display size, in points. Auto Size Enable this option to set the font size automatically, based on the Auto Size Options. When this option is enabled, TextMesh Pro lays out the text multiple times to find a good fit. This is a resource intensive process, so avoid auto-sizing dynamic text that changes frequently. Tip: For static text, you can enable Auto Size, note the calculated font size (displayed in the Font Size field), then disable Auto Size and apply the calculated size manually. Auto Size Options Define the basic rules for auto-sizing text. Min Specify the smallest acceptable font size, in points. Max Specify the largest acceptable font size, in points. WD% Specify the maximum acceptable amount to reduce character width when sizing the text. TextMesh Pro squeezes characters to make them taller. This is usually only acceptable for digits. Line Adjust the line height. This is useful for fitting a larger font into a given space. Color TextMesh Pro uses vertex colors to tint the text. You can apply a uniform color as well a gradient of up to four colors. Property: Function: Vertex Color Choose the main color for the text. Any colors and textures defined in the TextMesh Pro GameObject or its material ar multiplied with this color. Color Gradient Enable this option to apply a color gradient to each character sprite. You can then set the gradient’s type and colors, or apply a color gradient preset. Gradient colors are multiplied with the Vertex Color. If Vertex Color is set to white you see only the gradient colors. If it’s set to black you don’t see the gradient colors at all. Color Preset Choose a color gradient preset. When you apply a preset its Color Mode and Colors replace the text's local properties in the Inspector. Editing these properties modifies the preset, which affects every TextMesh Pro GameObject that uses it. Set this property to None to revert to the text’s local gradient properties. Color Mode Choose the type of color gradient to apply. TextMesh Pro applies gradients to each character individually. Single A uniform color that modifies the base Vertex Color. Horizontal Gradient A two-color gradient with each color emanating from one side of the character. Vertical Gradient A two-color gradient with one color emanating from the top of the character, and the other from the bottom. Four Corners Gradient A four-color gradient with each color emanating from a different corner of the character. Colors Choose each gradient color. The number of available colors depends on the type of gradient, and the color fields are arranged to match the position of each color in the gradient (left and right, top and bottom, 2 rows of 2 for four-corner gradients). You can set the color in any of the following ways: Swatch: Click to open a color picker. Eyedropper: Click to choose a color from any part of the screen. Hex Value: Enter the RGBA hex value directly. Override Tags Enable this option to ignore any rich text tags that change text color. Spacing These options control spacing between characters, words, lines and, paragraphs. You can use them to fine-tune the text for individual TextMesh Pro GameObjects, without adjusting their font assets. To control spacing within a single TextMesh Pro GameObject, use rich text tags. Property: Function: Character Set the spacing between characters for this TextMesh Pro GameObject. Word Set the spacing between words for this TextMesh Pro GameObject. Line Set the spacing between lines for this TextMesh Pro GameObject. Paragraph Set the spacing between paragraphs for this TextMesh Pro GameObject. Paragraphs are defined by explicit line breaks. Alignment The horizontal and vertical alignment options control how text is placed in the display area. Property: Function: [Horizontal Alignment Options] Left, Center, Right Position the text horizontally in the display area, without changing the text itself. Justified, Flush Stretch the text to fill the width of the display area by increasing the distance between words and characters. The Wrap Mix option controls the balance between word and character spacing. Justified mode does not stretch the last lines of paragraphs, while Flush mode does. Geometry Center Centers the text based on the mesh rather than the text metrics. The difference is not always noticeable, but in some cases this mode yields better looking results than regular Center alignment. [Vertical Alignment Options] Top, Middle, Bottom Position the text vertically in the display area, without changing the text itself. Baseline Position the text so the baseline of the line is aligned with the middle of the display area. This is useful when working with a single line of text. Midline Use this as an alternative to Middle alignnment. This option determine vertical placement using the bounds of the text mesh, rather than line metrics. This is useful in tight spaces when ascenders and descenders might otherwise extend too far. Capline Position the text so the middle of the first the line is aligned with the middle of the display area. Wrap Mix (W <-> C) Adjust the balance between extra word spacing and extra character spacing when horizontal alignment is set to Justified or Flush. Wrapping and Overflow Wrapping splits lines of text to ensure that they don't get wider than the display area. Lines are normally wrapped at word boundaries, but words that are longer than an entire line are split as well. Overflow controls what happens when the text doesn't fit inside the display area. Some overflow options supersede wrapping. For example, if Overflow is set to truncate, the text is truncated when it reaches the edge of the display area, irrespective of whether Wrapping is enabled. Property: Function: Wrapping Enable or Disable word wrapping. Overflow Specify what happens when the text doesn't fit inside the display area. Overflow Extends the text beyond the bounds of the display area, but still wraps it if Wrapping is enabled. Ellipsis Cuts off the text and inserts an ellipsis (…) to indicate that some of the text is omitted. Masking Like Overflow, but the shader hides everything outside of the display area. Truncate Cuts off the text when it no longer fits. Scroll Rect A legacy mode that’s similar to Masking. This option is available strictly for compatibility with older TextMesh Pro projects. For new projects, use Masking mode instead. Page Cuts the text into several pages that each fit inside the display area. You can choose which page to display. You can also use rich text to manually insert page breaks. Note: The vertical alignment options work on a per-page basis. Linked Extends the text into another TextMesh Pro GameObject that you select. This is useful for creating multi-column text. UV Mapping Some TextMesh Pro shaders allow you to apply one or more image textures to text. These options control how those textures stretch to fit the text. You can also edit shader-specific texturing options in the shaders themselves. The available options depend on the shader you use. When texturing text, make sure that your texture assets have their Wrap Mode set to Repeat. Otherwise the texture is likely to be heavily distorted when applied to the text. See the Render Texture documentation in the Unity Manual for more information. Property: Function: Horizontal Mapping Specify how textures map to text horizontally when you use a shader that supports textures. Character Stretches the texture horizontally across each character's sprite. Line Stretches the texture horizontally across the entire width of each line. Paragraph Stretches the texture horizontally across the entire text. Match Aspect Scales the texture horizontally so it maintains its aspect ratio, and is not deformed. When you use this horizontal mapping mode, the Vertical Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Vertical Mapping Specify how textures map to text vertically when you use a shader that supports textures. Character Stretches the texture vertically across each character's sprite. Line Stretches the texture vertically across the entire width of each line. Paragraph Stretches the texture vertically across the entire text. Match Aspect Scales the texture vertically so it maintains its aspect ratio, and is not deformed. When you use this vertical mapping mode, the Horizontal Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Line Offset When Horizontal Mapping is set to Line, Paragraph, or Match Aspect, set this value to add a horizontal texture offset to each successive line. This value is added to the Offset X value you specify in the shader. Extra Settings This section contains assorted options for further controlling the appearance and behavior of text. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. Set negative values to make the text extend beyond the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Sorting Layer Order in Layer Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Othographic Mode Enable this option when creating camera-aligned text with an orthographic camera. It prevents the TextMesh Pro shader from using perspective correction. Rich Text Enable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as plain text. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the results isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObjectUIText.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObjectUIText.html",
    "title": "UI Text GameObjects | Inventory System",
    "summary": "UI Text GameObjects By default, a TextMesh Pro UI Text GameObject has the following components: Rect Transform: Controls the GameObject's position and size on the canvas. For more information, see the Rect Transform documentation in the Unity Manual. Canvas Renderer: Renders the GameObject on the canvas. For more information, see the Canvas Renderer documentation in the Unity Manual. TextMesh Pro UGUI (Script): Contains the text to display, and the properties that control its appearance and behavior. These properties are described below. Material: A Unity material that uses one of the TextMesh Pro shaders to further control the text's appearance. For more information see the Shaders section. Properties Overview Text input A Text: Where you enter the text to display, along with any rich text markup. Main settings B Font: Specifies the font to use, as well as basic font attributes (size, style, and so on). C Color: Defines the base color or color gradient for the text D Spacing: Controls spacing between characters, words, lines and, paragraphs. E Alignment: Controls horizontal and vertical text alignment. F Wrapping and Overflow: Controls word wrapping and defines what happens when text doesn't fit inside its display area. G UV Mapping: Controls how textures are mapped to the face and outline of the text. H Extra Settings: Additional options for controlling the appearance and behavior of text. Text Input The text section is where you enter the text to display, and optionally customize it using rich text markup. Property: Function: Text The input field for text to display. Enable RTL Editor Enable this option to display text right-to-left instead of left-to-right. The Inspector displays an additional input field where you can view the reversed text and edit it directly. The text is reversed before it is displayed on screen or rendered. Main Settings The Main Settings section contains the properties needed to define the basic appearance of text. You can further customize the look of text by changing or editing its material. Font The fonts settings panel is where you choose a font for your text, and customize the font style. Property: Function: Font Asset Choose a font Asset for the TextMesh Pro GameObject to use. TextMesh Pro ships with several font assets, and you can create others from standard font files such as truetype (ttf) fonts. Note: You can set the default font Asset for new text objects in the TextMesh Pro settings. Material Preset Choose a material for your font. Each font Asset has a default material, but you can also create customized materials for it. This preset list includes all materials whose names contain the font Asset's name, and use the corresponding font atlas texture. Font Style Enable standard text styling options. You can use these options in any combination, except for the casing options (lowercase, uppercase, and small caps), which are mutually exclusive. B Bold the text. The appearance of bold text is defined in the font Asset properties. I Italicize the text. The appearance of italicized text is defined in the font Asset properties. U Underline the text. This renders an extra line below the baseline. S Add a strikethrough line to the text. This renders an extra line above the baseline. ab Convert the text to lowercase before rendering. This does not change text casing in the Text field. AB Convert the text to uppercase before rendering. This does not change text casing in the Text field. SC Use small caps. The text is displayed in all uppercase, but letters you actually entered in uppercase are larger. Font Size Specify the text display size, in points. Auto Size Enable this option to set the font size automatically, based on the Auto Size Options. When this option is enabled, TextMesh Pro lays out the text multiple times to find a good fit. This is a resource intensive process, so avoid auto-sizing dynamic text that changes frequently. Tip: For static text, you can enable Auto Size, note the calculated font size (displayed in the Font Size field), then disable Auto Size and apply the calculated size manually. Auto Size Options Define the basic rules for auto-sizing text. Min Specify the smallest acceptable font size, in points. Max Specify the largest acceptable font size, in points. WD% Specify the maximum acceptable amount to reduce character width when sizing the text. TextMesh Pro squeezes characters to make them taller. This is usually only acceptable for digits. Line Adjust the line height. This is useful for fitting a larger font into a given space. Color TextMesh Pro uses vertex colors to tint the text. You can apply a uniform color as well a gradient of up to four colors. Property: Function: Vertex Color Choose the main color for the text. Any colors and textures defined in the TextMesh Pro GameObject or its material ar multiplied with this color. Color Gradient Enable this option to apply a color gradient to each character sprite. You can then set the gradient’s type and colors, or apply a color gradient preset. Gradient colors are multiplied with the Vertex Color. If Vertex Color is set to white you see only the gradient colors. If it’s set to black you don’t see the gradient colors at all. Color Preset Choose a color gradient preset. When you apply a preset its Color Mode and Colors replace the text's local properties in the Inspector. Editing these properties modifies the preset, which affects every TextMesh Pro GameObject that uses it. Set this property to None to revert to the text’s local gradient properties. Color Mode Choose the type of color gradient to apply. TextMesh Pro applies gradients to each character individually. Single A uniform color that modifies the base Vertex Color. Horizontal Gradient A two-color gradient with each color emanating from one side of the character. Vertical Gradient A two-color gradient with one color emanating from the top of the character, and the other from the bottom. Four Corners Gradient A four-color gradient with each color emanating from a different corner of the character. Colors Choose each gradient color. The number of available colors depends on the type of gradient, and the color fields are arranged to match the position of each color in the gradient (left and right, top and bottom, 2 rows of 2 for four-corner gradients). You can set the color in any of the following ways: Swatch: Click to open a color picker. Eyedropper: Click to choose a color from any part of the screen. Hex Value: Enter the RGBA hex value directly. Override Tags Enable this option to ignore any rich text tags that change text color. Spacing These options control spacing between characters, words, lines and, paragraphs. You can use them to fine-tune the text for individual TextMesh Pro GameObjects, without adjusting their font assets. To control spacing within a single TextMesh Pro GameObject, use rich text tags. Property: Function: Character Set the spacing between characters for this TextMesh Pro GameObject. Word Set the spacing between words for this TextMesh Pro GameObject. Line Set the spacing between lines for this TextMesh Pro GameObject. Paragraph Set the spacing between paragraphs for this TextMesh Pro GameObject. Paragraphs are defined by explicit line breaks. Alignment The horizontal and vertical alignment options control how text is placed in the display area. Property: Function: [Horizontal Alignment Options] Left, Center, Right Position the text horizontally in the display area, without changing the text itself. Justified, Flush Stretch the text to fill the width of the display area by increasing the distance between words and characters. The Wrap Mix option controls the balance between word and character spacing. Justified mode does not stretch the last lines of paragraphs, while Flush mode does. Geometry Center Centers the text based on the mesh rather than the text metrics. The difference is not always noticeable, but in some cases this mode yields better looking results than regular Center alignment. [Vertical Alignment Options] Top, Middle, Bottom Position the text vertically in the display area, without changing the text itself. Baseline Position the text so the baseline of the line is aligned with the middle of the display area. This is useful when working with a single line of text. Midline Use this as an alternative to Middle alignnment. This option determine vertical placement using the bounds of the text mesh, rather than line metrics. This is useful in tight spaces when ascenders and descenders might otherwise extend too far. Capline Position the text so the middle of the first the line is aligned with the middle of the display area. Wrap Mix (W <-> C) Adjust the balance between extra word spacing and extra character spacing when horizontal alignment is set to Justified or Flush. Wrapping and Overflow Wrapping splits lines of text to ensure that they don't get wider than the display area. Lines are normally wrapped at word boundaries, but words that are longer than an entire line are split as well. Overflow controls what happens when the text doesn't fit inside the display area. Some overflow options supersede wrapping. For example, if Overflow is set to truncate, the text is truncated when it reaches the edge of the display area, irrespective of whether Wrapping is enabled. Property: Function: Wrapping Enable or Disable word wrapping. Overflow Specify what happens when the text doesn't fit inside the display area. Overflow Extends the text beyond the bounds of the display area, but still wraps it if Wrapping is enabled. Ellipsis Cuts off the text and inserts an ellipsis (…) to indicate that some of the text is omitted. Masking Like Overflow, but the shader hides everything outside of the display area. Truncate Cuts off the text when it no longer fits. Scroll Rect A legacy mode that’s similar to Masking. This option is available strictly for compatibility with older TextMesh Pro projects. For new projects, use Masking mode instead. Page Cuts the text into several pages that each fit inside the display area. You can choose which page to display. You can also use rich text to manually insert page breaks. Note: The vertical alignment options work on a per-page basis. Linked Extends the text into another TextMesh Pro GameObject that you select. This is useful for creating multi-column text. UV Mapping Some TextMesh Pro shaders allow you to apply one or more image textures to text. These options control how those textures stretch to fit the text. You can also edit shader-specific texturing options in the shaders themselves. The available options depend on the shader you use. When texturing text, make sure that your texture assets have their Wrap Mode set to Repeat. Otherwise the texture is likely to be heavily distorted when applied to the text. See the Render Texture documentation in the Unity Manual for more information. Property: Function: Horizontal Mapping Specify how textures map to text horizontally when you use a shader that supports textures. Character Stretches the texture horizontally across each character's sprite. Line Stretches the texture horizontally across the entire width of each line. Paragraph Stretches the texture horizontally across the entire text. Match Aspect Scales the texture horizontally so it maintains its aspect ratio, and is not deformed. When you use this horizontal mapping mode, the Vertical Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Vertical Mapping Specify how textures map to text vertically when you use a shader that supports textures. Character Stretches the texture vertically across each character's sprite. Line Stretches the texture vertically across the entire width of each line. Paragraph Stretches the texture vertically across the entire text. Match Aspect Scales the texture vertically so it maintains its aspect ratio, and is not deformed. When you use this vertical mapping mode, the Horizontal Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Line Offset When Horizontal Mapping is set to Line, Paragraph, or Match Aspect, set this value to add a horizontal texture offset to each successive line. This value is added to the Offset X value you specify in the shader. Extra Settings This section contains options for further controlling how text looks and behaves. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. Negative values make the text extend beyond the boundaries of the text container. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Rich Text Disable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as regular text. Raycast Target Enable this option to make this TextMesh Pro GameObject a raycast target. Disabling this option causes the UI to ignores this TextMesh Pro GameObject when determining what the cursor interacts with. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. Kerning is defined in the GameObject's Font Asset. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the result isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObjects.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TMPObjects.html",
    "title": "Creating text | Inventory System",
    "summary": "Creating text To create text, add TextMesh Pro GameObjects to a Scenes. There are two types of TextMesh Pro GameObject: TextMesh Pro UI Text GameObjects use Unity's UI system, and are designed for use on a Canvas. TextMesh Pro 3D Text GameObjects behave like regular 3D GameObjects in the Scene. TextMesh Pro UI Text GameObjects TextMesh Pro UI text objects use Unity's UI system. When you create one, it is placed on a Canvas in the Scene. If the Scene does not have a canvas, Unity creates one automatically when you create the TexMesh Pro UI text GameObject. To create a new TextMesh Pro UI Text GameObject: From the menu, choose GameObject > UI > TextMesh Pro - Text. In the TextMesh Pro (UGUI) Inspector, enter your text. Adjust the UI text properties as needed. Other TextMesh Pro UI GameObjects In addition to the UI text GameObject, you can create TextMesh Pro Dropdown and Input Field components from the GameObject > UI menu. These components are nearly identical to regular Unity UI components, but have a few key differences: The TextMesh Pro Dropdown GameObject uses TextMesh Pro font assets instead of regular Unity font assets. For more information about Unity dropdowns, see the Dropdown documentation in the Unity manual. The TextMesh Pro Input Field GameObject uses uses TextMesh Pro font assets instead of regular Unity font assets, and has more options for defining the input field. For more information about Unity input fields, see the Input Field documentation in the Unity manual. TextMesh Pro 3D Text GameObjects TextMesh Pro 3D text objects are nearly identical to their UI counterparts, but rather than being positioned on a Canvas, they behave like regular 3D objects in the Scene. To create a new TextMesh Pro 3D Text GameObject: From the menu, choose GameObject > 3D GameObject > TextMesh Pro - Text. In the TextMesh Pro Inspector, enter your text. Adjust the 3D text properties as needed. OpenType FontFeature Font Features define the typographic capabilities of a font asset. These features define potential substitutions or positional adjustments of glyphs. The following are the currently supported Font Features: Ligatures: Defines the substitution of multiple glyphs by a single glyph, such as 'fi' or 'ffl'. This features is identified as \"liga\". Kerning: Defines positional adjustments between two glyphs relative to each other. This features is identified as \"kern\". Diacritical Marks: Defines positional adjustments between Base glyphs and Mark glyphs. The Mark-to-Base feature \"mark\" defines the positional adjustments of Mark glyphs relative to Base glyphs. The Mark-to-Mark feature \"mkmk\" defines the positional adjustments of Mark glyphs relative to Base Mark glyphs. You can enable or disable the Font Features through the Font Features field in the Text component's Extra Settings section shown in the image below:"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TextMeshPro.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/TextMeshPro.html",
    "title": "TextMesh Pro User Guide | Inventory System",
    "summary": "TextMesh Pro User Guide Overview This User Guide was designed to provide first time users of TextMesh Pro with a basic overview of the features and functionality of the tool. Installation The TextMesh Pro UPM package is already included with the Unity Editor and as such does not require installation. TextMesh Pro \"TMP\" does however require adding resources to your project which are essential for using TextMesh Pro. To import the \"TMP Essential Resources\", please use the \"Window -> TextMeshPro -> Import TMP Essential Resources\" menu option. These resources will be added at the root of your project in the \"TextMesh Pro\" folder. The TextMesh Pro package also includes additional resources and examples that will make discovering and learning about TextMesh Pro's powerful features easier. It is strongly recommended that first time users import these additional resources. To import the \"TMP Examples & Extras\", please use the \"Window -> TextMeshPro -> Import TMP Examples & Extras\" menu option. These resources will also be added in the same \"TextMesh Pro\" folder inside your project. Quick Start There are two TextMesh Pro components available. The first TMP text component is of type <TextMeshPro> and designed to work with the MeshRenderer. This component is an ideal replacement for the legacy TextMesh component. To add a new <TextMeshPro> text object, go to: �GameObject->3D Object->TextMeshPro Text�. The second TMP text component is of type <TextMeshProUGUI> and designed to work with the CanvasRenderer and Canvas system. This component is an ideal replacement for the UI.Text component. To add a new <TextMeshProUGUI> text object, go to: �GameObject->UI->TextMeshPro Text�. You may also wish to watch this Getting Started short video which covers this topic. We strongly recommend that you also watch the Font Asset Creation video as well as the Working with Material Presets as these two topics is also key to working and getting the most out of TextMesh Pro. As mentionned in the Installation section of this guide, it is recommended that you import the \"TMP Examples & Extras\" and take the time to explore each of the examples as they provide a great overview of the functionality of the tool and the many text layout and rich text tags available in TextMesh Pro. Support & API Documentation Should you have questions or require assistance, please visit the Unity UI & TextMesh Pro section of the Unity forum as well as the TextMesh Pro User Forum where you will find additional information, Video Tutorials and FAQ. In the event you are unable to find the information you seek, always feel free to post on the Unity UI & TextMesh Pro section user forum. Online Documentation is also available on TextMesh Pro including Rich Text tags, Shaders, Scripting API and more."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/exportdoc.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/exportdoc.html",
    "title": "TextMesh Pro Documentation | Inventory System",
    "summary": "TextMesh Pro Documentation TextMesh Pro is a set of Unity tools for 2D and 3D text. [IMAGE] TextMesh Pro provides better control over text formatting and layout than to Unity's UI Text & Text Mesh systems. It includes features such as: Character, word, line and paragraph spacing. Kerning. Justified text. Links. More than thirty rich text tags. Support for multiple fonts. Support for sprites. Custom styles. Advanced text rendering using custom shaders. Getting started The TextMesh Pro package is included in the Unity Editor. You do not need to install it. You can switch to other versions of TextMesh Pro from the Packages Window. To use TextMesh Pro, you must import the TMP Essential Resources package (see the next section). You can also import the TMP Examples & Extras package to help you learn TextMesh Pro. Importing required resources into projects To use TextMesh Pro in your projects, you need to import the TMP Essential Resources. From the menu, select Window > TextMeshPro > Import TMP Essential Resources This adds the essential resources to the TextMesh Pro folder in the Project. Importing examples and additional resources TextMesh Pro also includes additional resources and examples to help you learn about various features. You can import these into your projects as well. From the menu, select Window > TextMeshPro > Import TMP Examples & Extras This adds the examples and additional resources to the TextMesh Pro > Examples & Extras folder in the Project. Installing the TMP Examples & Extras is not mandatory, but is strongly recommended for first-time TextMesh Pro users. NEW FILE: TMPObjects.md Creating text To create text, add TextMesh Pro GameObjects to a Scenes. There are two types of TextMesh Pro GameObject: TextMesh Pro UI Text GameObjects use Unity's UI system, and are designed for use on a Canvas. TextMesh Pro 3D Text GameObjects behave like regular 3D GameObjects in the Scene. TextMesh Pro UI Text GameObjects TextMesh Pro UI text objects use Unity's UI system. When you create one, it is placed on a Canvas in the Scene. If the Scene does not have a canvas, Unity creates one automatically when you create the TexMesh Pro UI text GameObject. To create a new TextMesh Pro UI Text GameObject: From the menu, choose GameObject > UI > TextMesh Pro - Text. In the TextMesh Pro (UGUI) Inspector, enter your text. Adjust the UI text properties as needed. Other TextMesh Pro UI GameObjects In addition to the UI text GameObject, you can create TextMesh Pro Dropdown and Input Field components from the GameObject > UI menu. These components are nearly identical to regular Unity UI components, but have a few key differences: The TextMesh Pro Dropdown GameObject uses TextMesh Pro font assets instead of regular Unity font assets. For more information about Unity dropdowns, see the Dropdown documentation in the Unity manual. The TextMesh Pro Input Field GameObject uses uses TextMesh Pro font assets instead of regular Unity font assets, and has more options for defining the input field. For more information about Unity input fields, see the Input Field documentation in the Unity manual. TextMesh Pro 3D Text GameObjects TextMesh Pro 3D text objects are nearly identical to their UI counterparts, but rather than being positioned on a Canvas, they behave like regular 3D objects in the Scene. To create a new TextMesh Pro 3D Text GameObject: From the menu, choose GameObject > 3D GameObject > TextMesh Pro - Text. In the TextMesh Pro Inspector, enter your text. Adjust the 3D text properties as needed. NEW FILE: TMPObjectUIText.md UI Text GameObjects By default, a TextMesh Pro UI Text GameObject has the following components: Rect Transform: Controls the GameObject's position and size on the canvas. For more information, see the Rect Transform documentation in the Unity Manual. Canvas Renderer: Renders the GameObject on the canvas. For more information, see the Canvas Renderer documentation in the Unity Manual. TextMesh Pro UGUI (Script): Contains the text to display, and the properties that control its appearance and behavior. These properties are described below. Material: A Unity material that uses one of the TextMesh Pro shaders to further control the text's appearance. For more information see the Shaders section. Properties Overview Text input A Text: Where you enter the text to display, along with any rich text markup. Main settings B Font: Specifies the font to use, as well as basic font attributes (size, style, and so on). C Color: Defines the base color or color gradient for the text D Spacing: Controls spacing between characters, words, lines and, paragraphs. E Alignment: Controls horizontal and vertical text alignment. F Wrapping and Overflow: Controls word wrapping and defines what happens when text doesn't fit inside its display area. G UV Mapping: Controls how textures are mapped to the face and outline of the text. H Extra Settings: Additional options for controlling the appearance and behavior of text. Text Input The text section is where you enter the text to display, and optionally customize it using rich text markup. Property: Function: Text The input field for text to display. Enable RTL Editor Enable this option to display text right-to-left instead of left-to-right. The Inspector displays an additional input field where you can view the reversed text and edit it directly. The text is reversed before it is displayed on screen or rendered. Main Settings The Main Settings section contains the properties needed to define the basic appearance of text. You can further customize the look of text by changing or editing its material. Font The fonts settings panel is where you choose a font for your text, and customize the font style. Property: Function: Font Asset Choose a font Asset for the TextMesh Pro GameObject to use. TextMesh Pro ships with several font assets, and you can create others from standard font files such as truetype (ttf) fonts. Note: You can set the default font Asset for new text objects in the TextMesh Pro settings. Material Preset Choose a material for your font. Each font Asset has a default material, but you can also create customized materials for it. This preset list includes all materials whose names contain the font Asset's name, and use the corresponding font atlas texture. Font Style Enable standard text styling options. You can use these options in any combination, except for the casing options (lowercase, uppercase, and small caps), which are mutually exclusive. B Bold the text. The appearance of bold text is defined in the font Asset properties. I Italicize the text. The appearance of italicized text is defined in the font Asset properties. U Underline the text. This renders an extra line below the baseline. S Add a strikethrough line to the text. This renders an extra line above the baseline. ab Convert the text to lowercase before rendering. This does not change text casing in the Text field. AB Convert the text to uppercase before rendering. This does not change text casing in the Text field. SC Use small caps. The text is displayed in all uppercase, but letters you actually entered in uppercase are larger. Font Size Specify the text display size, in points. Auto Size Enable this option to set the font size automatically, based on the Auto Size Options. When this option is enabled, TextMesh Pro lays out the text multiple times to find a good fit. This is a resource intensive process, so avoid auto-sizing dynamic text that changes frequently. Tip: For static text, you can enable Auto Size, note the calculated font size (displayed in the Font Size field), then disable Auto Size and apply the calculated size manually. Auto Size Options Define the basic rules for auto-sizing text. Min Specify the smallest acceptable font size, in points. Max Specify the largest acceptable font size, in points. WD% Specify the maximum acceptable amount to reduce character width when sizing the text. TextMesh Pro squeezes characters to make them taller. This is usually only acceptable for digits. Line Adjust the line height. This is useful for fitting a larger font into a given space. Color TextMesh Pro uses vertex colors to tint the text. You can apply a uniform color as well a gradient of up to four colors. Property: Function: Vertex Color Choose the main color for the text. Any colors and textures defined in the TextMesh Pro GameObject or its material ar multiplied with this color. Color Gradient Enable this option to apply a color gradient to each character sprite. You can then set the gradient’s type and colors, or apply a color gradient preset. Gradient colors are multiplied with the Vertex Color. If Vertex Color is set to white you see only the gradient colors. If it’s set to black you don’t see the gradient colors at all. Color Preset Choose a color gradient preset. When you apply a preset its Color Mode and Colors replace the text's local properties in the Inspector. Editing these properties modifies the preset, which affects every TextMesh Pro GameObject that uses it. Set this property to None to revert to the text’s local gradient properties. Color Mode Choose the type of color gradient to apply. TextMesh Pro applies gradients to each character individually. Single A uniform color that modifies the base Vertex Color. Horizontal Gradient A two-color gradient with each color emanating from one side of the character. Vertical Gradient A two-color gradient with one color emanating from the top of the character, and the other from the bottom. Four Corners Gradient A four-color gradient with each color emanating from a different corner of the character. Colors Choose each gradient color. The number of available colors depends on the type of gradient, and the color fields are arranged to match the position of each color in the gradient (left and right, top and bottom, 2 rows of 2 for four-corner gradients). You can set the color in any of the following ways: Swatch: Click to open a color picker. Eyedropper: Click to choose a color from any part of the screen. Hex Value: Enter the RGBA hex value directly. Override Tags Enable this option to ignore any rich text tags that change text color. Spacing These options control spacing between characters, words, lines and, paragraphs. You can use them to fine-tune the text for individual TextMesh Pro GameObjects, without adjusting their font assets. To control spacing within a single TextMesh Pro GameObject, use rich text tags. Property: Function: Character Set the spacing between characters for this TextMesh Pro GameObject. Word Set the spacing between words for this TextMesh Pro GameObject. Line Set the spacing between lines for this TextMesh Pro GameObject. Paragraph Set the spacing between paragraphs for this TextMesh Pro GameObject. Paragraphs are defined by explicit line breaks. Alignment The horizontal and vertical alignment options control how text is placed in the display area. Property: Function: [Horizontal Alignment Options] Left, Center, Right Position the text horizontally in the display area, without changing the text itself. Justified, Flush Stretch the text to fill the width of the display area by increasing the distance between words and characters. The Wrap Mix option controls the balance between word and character spacing. Justified mode does not stretch the last lines of paragraphs, while Flush mode does. Geometry Center Centers the text based on the mesh rather than the text metrics. The difference is not always noticeable, but in some cases this mode yields better looking results than regular Center alignment. [Vertical Alignment Options] Top, Middle, Bottom Position the text vertically in the display area, without changing the text itself. Baseline Position the text so the baseline of the line is aligned with the middle of the display area. This is useful when working with a single line of text. Midline Use this as an alternative to Middle alignnment. This option determine vertical placement using the bounds of the text mesh, rather than line metrics. This is useful in tight spaces when ascenders and descenders might otherwise extend too far. Capline Position the text so the middle of the first the line is aligned with the middle of the display area. Wrap Mix (W <-> C) Adjust the balance between extra word spacing and extra character spacing when horizontal alignment is set to Justified or Flush. Wrapping and Overflow Wrapping splits lines of text to ensure that they don't get wider than the display area. Lines are normally wrapped at word boundaries, but words that are longer than an entire line are split as well. Overflow controls what happens when the text doesn't fit inside the display area. Some overflow options supersede wrapping. For example, if Overflow is set to truncate, the text is truncated when it reaches the edge of the display area, irrespective of whether Wrapping is enabled. Property: Function: Wrapping Enable or Disable word wrapping. Overflow Specify what happens when the text doesn't fit inside the display area. Overflow Extends the text beyond the bounds of the display area, but still wraps it if Wrapping is enabled. Ellipsis Cuts off the text and inserts an ellipsis (…) to indicate that some of the text is omitted. Masking Like Overflow, but the shader hides everything outside of the display area. Truncate Cuts off the text when it no longer fits. Scroll Rect A legacy mode that’s similar to Masking. This option is available strictly for compatibility with older TextMesh Pro projects. For new projects, use Masking mode instead. Page Cuts the text into several pages that each fit inside the display area. You can choose which page to display. You can also use rich text to manually insert page breaks. Note: The vertical alignment options work on a per-page basis. Linked Extends the text into another TextMesh Pro GameObject that you select. This is useful for creating multi-column text. UV Mapping Some TextMesh Pro shaders allow you to apply one or more image textures to text. These options control how those textures stretch to fit the text. You can also edit shader-specific texturing options in the shaders themselves. The available options depend on the shader you use. When texturing text, make sure that your texture assets have their Wrap Mode set to Repeat. Otherwise the texture is likely to be heavily distorted when applied to the text. See the Render Texture documentation in the Unity Manual for more information. Property: Function: Horizontal Mapping Specify how textures map to text horizontally when you use a shader that supports textures. Character Stretches the texture horizontally across each character's sprite. Line Stretches the texture horizontally across the entire width of each line. Paragraph Stretches the texture horizontally across the entire text. Match Aspect Scales the texture horizontally so it maintains its aspect ratio, and is not deformed. When you use this horizontal mapping mode, the Vertical Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Vertical Mapping Specify how textures map to text vertically when you use a shader that supports textures. Character Stretches the texture vertically across each character's sprite. Line Stretches the texture vertically across the entire width of each line. Paragraph Stretches the texture vertically across the entire text. Match Aspect Scales the texture vertically so it maintains its aspect ratio, and is not deformed. When you use this vertical mapping mode, the Horizontal Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Line Offset When Horizontal Mapping is set to Line, Paragraph, or Match Aspect, set this value to add a horizontal texture offset to each successive line. This value is added to the Offset X value you specify in the shader. Extra Settings This section contains options for further controlling how text looks and behaves. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. Negative values make the text extend beyond the boundaries of the text container. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Rich Text Disable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as regular text. Raycast Target Enable this option to make this TextMesh Pro GameObject a raycast target. Disabling this option causes the UI to ignores this TextMesh Pro GameObject when determining what the cursor interacts with. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. Kerning is defined in the GameObject's Font Asset. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the result isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites. NEW FILE: TMPObject3DText.md 3D Text GameObjects By default, a TextMesh Pro 3D Text GameObject has the following components: Rect Transform: Controls the GameObject's position and size. For more information, see the Rect Transform documentation in the Unity Manual. Note Note: If you want to use the Rect Transform component's anchoring system, the TextMesh Pro component's parent GameObject must also have a Rect Transform component. Mesh Renderer: Renders the GameObject. For more information, see the Mesh Renderer documentation in the Unity Manual. TextMesh Pro UGUI (Script): Contains the text to display, and the properties that control its appearance and behavior. These properties are described below. Material: A Unity material that uses one of the TextMesh Pro shaders to further control the text's appearance. For more information see the Shaders section. Properties Overview Text input A Text: Where you enter the text to display, along with any rich text markup. Main settings B Font: Specifies the font to use, as well as basic font attributes (size, style, and so on). C Color: Defines the base color or color gradient for the text D Spacing: Controls spacing between characters, words, lines and, paragraphs. E Alignment: Controls horizontal and vertical text alignment. F Wrapping and Overflow: Controls word wrapping and defines what happens when text doesn't fit inside its display area. G UV Mapping: Controls how textures are mapped to the face and outline of the text. H Extra Settings: Additional options for controlling the appearance and behavior of text. Text Input The text section is where you enter the text to display, and optionally customize it using rich text markup. Property: Function: Text The input field for text to display. Enable RTL Editor Enable this option to display text right-to-left instead of left-to-right. The Inspector displays an additional input field where you can view the reversed text and edit it directly. The text is reversed before it is displayed on screen or rendered. Main Settings The Main Settings section contains the properties needed to define the basic appearance of text. You can further customize the look of text by changing or editing its material. Font The fonts settings panel is where you choose a font for your text, and customize the font style. Property: Function: Font Asset Choose a font Asset for the TextMesh Pro GameObject to use. TextMesh Pro ships with several font assets, and you can create others from standard font files such as truetype (ttf) fonts. Note: You can set the default font Asset for new text objects in the TextMesh Pro settings. Material Preset Choose a material for your font. Each font Asset has a default material, but you can also create customized materials for it. This preset list includes all materials whose names contain the font Asset's name, and use the corresponding font atlas texture. Font Style Enable standard text styling options. You can use these options in any combination, except for the casing options (lowercase, uppercase, and small caps), which are mutually exclusive. B Bold the text. The appearance of bold text is defined in the font Asset properties. I Italicize the text. The appearance of italicized text is defined in the font Asset properties. U Underline the text. This renders an extra line below the baseline. S Add a strikethrough line to the text. This renders an extra line above the baseline. ab Convert the text to lowercase before rendering. This does not change text casing in the Text field. AB Convert the text to uppercase before rendering. This does not change text casing in the Text field. SC Use small caps. The text is displayed in all uppercase, but letters you actually entered in uppercase are larger. Font Size Specify the text display size, in points. Auto Size Enable this option to set the font size automatically, based on the Auto Size Options. When this option is enabled, TextMesh Pro lays out the text multiple times to find a good fit. This is a resource intensive process, so avoid auto-sizing dynamic text that changes frequently. Tip: For static text, you can enable Auto Size, note the calculated font size (displayed in the Font Size field), then disable Auto Size and apply the calculated size manually. Auto Size Options Define the basic rules for auto-sizing text. Min Specify the smallest acceptable font size, in points. Max Specify the largest acceptable font size, in points. WD% Specify the maximum acceptable amount to reduce character width when sizing the text. TextMesh Pro squeezes characters to make them taller. This is usually only acceptable for digits. Line Adjust the line height. This is useful for fitting a larger font into a given space. Color TextMesh Pro uses vertex colors to tint the text. You can apply a uniform color as well a gradient of up to four colors. Property: Function: Vertex Color Choose the main color for the text. Any colors and textures defined in the TextMesh Pro GameObject or its material ar multiplied with this color. Color Gradient Enable this option to apply a color gradient to each character sprite. You can then set the gradient’s type and colors, or apply a color gradient preset. Gradient colors are multiplied with the Vertex Color. If Vertex Color is set to white you see only the gradient colors. If it’s set to black you don’t see the gradient colors at all. Color Preset Choose a color gradient preset. When you apply a preset its Color Mode and Colors replace the text's local properties in the Inspector. Editing these properties modifies the preset, which affects every TextMesh Pro GameObject that uses it. Set this property to None to revert to the text’s local gradient properties. Color Mode Choose the type of color gradient to apply. TextMesh Pro applies gradients to each character individually. Single A uniform color that modifies the base Vertex Color. Horizontal Gradient A two-color gradient with each color emanating from one side of the character. Vertical Gradient A two-color gradient with one color emanating from the top of the character, and the other from the bottom. Four Corners Gradient A four-color gradient with each color emanating from a different corner of the character. Colors Choose each gradient color. The number of available colors depends on the type of gradient, and the color fields are arranged to match the position of each color in the gradient (left and right, top and bottom, 2 rows of 2 for four-corner gradients). You can set the color in any of the following ways: Swatch: Click to open a color picker. Eyedropper: Click to choose a color from any part of the screen. Hex Value: Enter the RGBA hex value directly. Override Tags Enable this option to ignore any rich text tags that change text color. Spacing These options control spacing between characters, words, lines and, paragraphs. You can use them to fine-tune the text for individual TextMesh Pro GameObjects, without adjusting their font assets. To control spacing within a single TextMesh Pro GameObject, use rich text tags. Property: Function: Character Set the spacing between characters for this TextMesh Pro GameObject. Word Set the spacing between words for this TextMesh Pro GameObject. Line Set the spacing between lines for this TextMesh Pro GameObject. Paragraph Set the spacing between paragraphs for this TextMesh Pro GameObject. Paragraphs are defined by explicit line breaks. Alignment The horizontal and vertical alignment options control how text is placed in the display area. Property: Function: [Horizontal Alignment Options] Left, Center, Right Position the text horizontally in the display area, without changing the text itself. Justified, Flush Stretch the text to fill the width of the display area by increasing the distance between words and characters. The Wrap Mix option controls the balance between word and character spacing. Justified mode does not stretch the last lines of paragraphs, while Flush mode does. Geometry Center Centers the text based on the mesh rather than the text metrics. The difference is not always noticeable, but in some cases this mode yields better looking results than regular Center alignment. [Vertical Alignment Options] Top, Middle, Bottom Position the text vertically in the display area, without changing the text itself. Baseline Position the text so the baseline of the line is aligned with the middle of the display area. This is useful when working with a single line of text. Midline Use this as an alternative to Middle alignnment. This option determine vertical placement using the bounds of the text mesh, rather than line metrics. This is useful in tight spaces when ascenders and descenders might otherwise extend too far. Capline Position the text so the middle of the first the line is aligned with the middle of the display area. Wrap Mix (W <-> C) Adjust the balance between extra word spacing and extra character spacing when horizontal alignment is set to Justified or Flush. Wrapping and Overflow Wrapping splits lines of text to ensure that they don't get wider than the display area. Lines are normally wrapped at word boundaries, but words that are longer than an entire line are split as well. Overflow controls what happens when the text doesn't fit inside the display area. Some overflow options supersede wrapping. For example, if Overflow is set to truncate, the text is truncated when it reaches the edge of the display area, irrespective of whether Wrapping is enabled. Property: Function: Wrapping Enable or Disable word wrapping. Overflow Specify what happens when the text doesn't fit inside the display area. Overflow Extends the text beyond the bounds of the display area, but still wraps it if Wrapping is enabled. Ellipsis Cuts off the text and inserts an ellipsis (…) to indicate that some of the text is omitted. Masking Like Overflow, but the shader hides everything outside of the display area. Truncate Cuts off the text when it no longer fits. Scroll Rect A legacy mode that’s similar to Masking. This option is available strictly for compatibility with older TextMesh Pro projects. For new projects, use Masking mode instead. Page Cuts the text into several pages that each fit inside the display area. You can choose which page to display. You can also use rich text to manually insert page breaks. Note: The vertical alignment options work on a per-page basis. Linked Extends the text into another TextMesh Pro GameObject that you select. This is useful for creating multi-column text. UV Mapping Some TextMesh Pro shaders allow you to apply one or more image textures to text. These options control how those textures stretch to fit the text. You can also edit shader-specific texturing options in the shaders themselves. The available options depend on the shader you use. When texturing text, make sure that your texture assets have their Wrap Mode set to Repeat. Otherwise the texture is likely to be heavily distorted when applied to the text. See the Render Texture documentation in the Unity Manual for more information. Property: Function: Horizontal Mapping Specify how textures map to text horizontally when you use a shader that supports textures. Character Stretches the texture horizontally across each character's sprite. Line Stretches the texture horizontally across the entire width of each line. Paragraph Stretches the texture horizontally across the entire text. Match Aspect Scales the texture horizontally so it maintains its aspect ratio, and is not deformed. When you use this horizontal mapping mode, the Vertical Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Vertical Mapping Specify how textures map to text vertically when you use a shader that supports textures. Character Stretches the texture vertically across each character's sprite. Line Stretches the texture vertically across the entire width of each line. Paragraph Stretches the texture vertically across the entire text. Match Aspect Scales the texture vertically so it maintains its aspect ratio, and is not deformed. When you use this vertical mapping mode, the Horizontal Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Line Offset When Horizontal Mapping is set to Line, Paragraph, or Match Aspect, set this value to add a horizontal texture offset to each successive line. This value is added to the Offset X value you specify in the shader. Extra Settings This section contains assorted options for further controlling the appearance and behavior of text. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. Set negative values to make the text extend beyond the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Sorting Layer Order in Layer Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Othographic Mode Enable this option when creating camera-aligned text with an orthographic camera. It prevents the TextMesh Pro shader from using perspective correction. Rich Text Enable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as plain text. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the results isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites. NEW FILE: FontAssets.md Font Assets To use different fonts with TextMesh Pro, you need to create font assets. TextMesh Pro has its own font Asset format that is distinct from, but related to, Unity's regular font Asset format. You create TextMesh Pro font assets from Unity font assets. Every TextMesh Pro font Asset has two sub-assets: Font atlas: a black and white or grayscale texture file that contains all of the characters included in the font Asset. Example of a font atlas Font material: a material that controls the appearance of TextMesh Pro text using one of the TextMesh Pro shaders. Font assets must be stored in a specific folder, defined in the Default Font Asset > Path option of the TextMesh Pro settings.This ensures that TextMesh Pro can find them and that they are included in builds. Creating Font Assets There are two ways to create a TextMesh Pro font Asset: Select a Unity font Asset and choose Asset > Create > TextMeshPro > Font Asset from Unity's main menu or press Ctrl/Cmd + Shift + F12. This creates an empty, font Asset, meaning its font atlas does not yet include any characters. Using the TexMesh Pro Font Asset Creator, a tool for creating and updating TextMesh Pro font assets. Types of font atlas When you generate a font Asset you can choose what type of font atlas texture to render from the Font Settings > Render Mode dropdown in the Font Asset Creator. Distance Field: Use these options to render font atlases containing signed distance field (SDF) information. This is the recommended mode for most applications because SDF atlases produce text that is smooth when transformed. Smooth/Hinted Smooth: These options render antialiased bitmap textures. The Hinted version aligns glyph pixels with texture pixels to produce a smoother result. This mode works well for static text that will be viewed head on, with a good correspondence between texture pixels and screen pixels. Transforming the text produces blurry edges. Raster/Raster Hinted: These options render un-smoothed bitmap textures. These will almost always produce text with jagged, pixellated edges. The Hinted version aligns glyph pixels with texture pixels to produce a smoother result. NEW FILE: FontAssetsProperties.md Font Asset Properties Properties Properties are divided into the following sections: Face Info: Generation Settings: Atlas & Material: Font Weights: Fallback Font Assets: Glyph Table: Glyph Adjustment Table: Face Info The Face Info properties allow you to control the font's line metrics. They also include a few read-only properties that are generated when you create the font Asset. Line metrics Property: Function: Update Texture Atlas Open the Font Asset Creator pre-configured to modify and regenerate this font Asset. Family Name The name of the font used to create this font Asset. TextMesh Pro sets this value when you generate the font Asset. You cannot change it manually. Style Name The style of the font used to create this font Asset. For example, Regular, Bold, Italic, and so on. TextMesh Pro sets this value when you generate the font Asset. You cannot change it manually. Point Size The font size in points. TextMesh Pro bakes this value into the atlas texture when you generate the font Asset. You cannot change it manually. Scale Scales the font by this amount. For example, a value of 1.5 scales glyphs to 150% of their normal size. Line Height Controls the distance between the tops of consecutive lines. If you set a line height greater than the sum of the Ascent Line and Descent Line values, it creates in a gap between lines. If you set a line height greater than the sum of the Ascent Line and Descent Line values, characters on different lines might overlap. Ascent Line Controls the maximum distance that glyphs can extend above the baseline. It corresponds to the top of a line. Cap Line Controls the distance between the base line and the tops of uppercase glyphs. Mean Line Controls the maximum height for non-ascending lowercase glyphs (for example. \"a\" and \"c\", but not \"b\" and \"d,\" which have ascenders). The tops of rounded glyphs sometimes extend a slightly above the mean line. Baseline Controls the height of the baseline. The baseline is the horizontal line that characters sit on. Descent Line Controls the maximum distance that glyphs can extend below the baseline. Underline Offset Controls the position of underlines relative to the baseline. Underline Thickness Controls the thickness of underlines. Strikethrough Offset Controls the position of strikethrough lines relative to the baseline. Superscript Offset Offsets superscript text from the baseline. Superscript Size Scales superscript text relative to the normal font size. Subscript Offset Offsets subscript text from the baseline. Subscript Size Scales subscript text relative to the normal font size. Tab Width Specifies the width of a TAB character. Generation Settings These values are set when you generate the font Asset. When the Atlas Population Mode is set to Dynamic, you can change the atlas size without regenerating the atlas. Property: Function: Source Font File Atlas Population Mode Dynamic Static Atlas Render Mode SMOOTH Renders the atlas to an antialiased bitmap. RASTER Renders the atlas to a non-antialiased bitmap. SMOOTH_HINTED Renders the atlas to an antialiased bitmap, and aligns character pixels with texture pixels for a crisper result. RASTER_HINTED Renders the atlas to a non-antialiased bitmap and aligns character pixels with texture pixels for a crisper result. SDF Renders the atlas using a slower, but more accurate SDF generation mode, and no oversampling. SDFAA Renders the atlas using a faster, but less accurate SDF generation mode. It produces font atlases that are sufficient for most situations. SDFAA_HINTED Renders the atlas using a faster, but less accurate SDF generation mode, and aligns character pixels with texture pixels for a crisper result.. It produces font atlases that are sufficient for most situations SDF8 Renders the atlas using a slower, but more accurate SDF generation mode, and 8x oversampling. SDF16 Renders the atlas using a slower, but more accurate SDF generation mode, and 16x oversampling. SDF32 Renders the atlas using a slower, but more accurate SDF generation mode, and 32x oversampling. Use this setting for fonts with complex or small characters. Sampling Point Size The size, in points, of characters in the font texture. Padding The amount of padding between characters in the font atlas texture. This value is set when you generate the font Asset, and is not editable. Atlas Width/Height The width and height the font atlas texture. Choose for each dimension, choose one of the available values from the drop-down menu. Atlas & Material This section lists the sub-assets created when you generated the font Asset. You should not edit these directly. Property: Function: Font Atlas The font texture atlas created when you generated the font Asset. Font Material The font material created when you generated the font Asset. Font Weights The Font Weights options allow you to control the appearance of bold and italicized text. There are two ways of doing this: Create different bold and italic variants of the font Asset, and add them to the Font Table. You can specify regular and italic fonts for weights ranging from 100 (Thin) to 900 (Black). Define \"fake\" bolding and italicization by setting the Font Weight > Italic Style and Bold Weight properties. These settings tell TextMesh Pro how to treat the current font Asset when you bold or italicize text. Property: Function: Font Table Specify font assets to use for the following font variants. 100 - Thin 200 - Extra-Light 300 - Light 400 - Regular (italic only) 500 - Medium 600 - Semi-Bold 700 - Bold 800 - Heavy 900 - Black * 400 - Regular > Regular Typeface is the current font Asset. You cannot change it. If you don't specify font assets, TextMesh Pro \"fakes\" bolding and italicization according to the rest of the the Font Weights settings. Practically speaking, this limits you to regular and italic versions of normal and bold text (equivalent to weights of 400 and 700 respectively). Italic Style Choose a font Asset to use for italic style. Regular Typeface The regular font Asset that you created using the Font Asset Creator. You cannot change this Asset. Italic Style Choose a font Asset to use for italic style. If you don’t specify a font Asset, TextMesh Pro “fakes” italics slanting the character sprites in the Normal Style font Asset by an amount defined in the Italic Style setting. 400 - Regular Regular Typeface The regular font Asset that you created using the Font Asset Creator. You cannot change this Asset. Italic Style Choose a font Asset to use for italic style. If you don’t specify a font Asset, TextMesh Pro “fakes” italics slanting the character sprites in the Normal Style font Asset by an amount defined in the Italic Style setting. 700 - Bold Regular Typeface Choose a font Asset to use for bold style. If you don’t specify a font Asset, TextMesh Pro bolds character sprites in the Normal Style font Asset according to the Bold Weight setting. Italic Style Choose a font Asset to use for bold italicized style. If you don’t specify a font Asset, TextMesh pro bolds and slants the character sprites in the Normal Style font Asset according to the Bold Weight and Italic Style settings respectively. Normal Weight Set the regular font weight to use when no font Asset is available. Bold Weight Set the bold font weight assumed when no font Asset is available. Spacing Offset Add space between characters when using the normal text style. Bold Spacing Add space between characters when using the fake bold text style (meaning you haven’t specified a Bold font Asset). Italic Style If you don’t specify a font Asset for 400 - Regular > Italic Style variant, TextMeshPro slanting the character sprites in the Normal Style font Asset by an amount defined in the Italic Style setting. Set this value to control the Tab Multiple Set the tab size. This value is multiplied by the width of the font's space character to calculate the tab size used. Fallback Font Assets Each font Asset contains a limited number of characters. When the font you’re using is missing a glyph, TextMesh Pro searches the fallback font list until it finds a font Asset that includes it. The text object then uses that font to render the character. You can use this feature to distribute fonts over multiple textures, or use different fonts for specific characters. However, keep in mind that searching the list for missing characters requires extra computing resources, and that using additional fonts requires additional draw calls. Property: Function: Fallback Font Asset list Manage the fallback fonts for this font Asset. Click + and - to add and remove font slots. Click the circle icon next to a font to open an Object Picker where you can choose a font Asset. Drag the handles on the left side of any font Asset to reorder the list. Glyph Table Property: Function: Glyph Search Search the character list by character, ASCII value, or Hex value. Search results are ordered by ASCII value, lowest to highest. Previous Page/Next Page Long character lists are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Glyph Properties Displays a single glyph’s properties. Each glyph has its own entry. Click an entry to make it active. You can then edit the glyph, copy it, or remove it from the list. Ascii Displays the character’s ASCII decimal value. Hex Displays the character’s Unicode Hex value. Char Displays the character. X, Y, W, H Define the rectangular area the character occupies in the font atlas. OX, OY Control the placement of the character's sprite, defined at its top-left corner relative to its origin on the baseline. ADV Specify how far to advance along the baseline before placing the next character. SF Change this scaling factor value to adjust the size of the character. Copy to Duplicate this glyph. To make a copy, enter an unused Unicode (Hex) ID in the text field and click Copy to. Remove Remove this glyph from the list. Glyph Adjustment Table The glyph adjustment table controls spacing between specific pairs of characters. Some fonts include kerning information, which is imported automatically. You can add kerning paris for fonts that don’t include them. Property: Function: Adjustment Pair Search Search the adjustment table by character or ASCII value. Search results include entries where either the left or right character matches the search string. Search results are ordered by the ASCII value of the left character, lowest to highest. Previous Page/Next Page Long adjustment tables are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Glyph Properties Displays a single glyph’s properties. Each glyph has its own entry. Click an entry to make it active. You can then edit the glyph, copy it, or remove it from the list. Char (left and right) Display the left and right characters for the kerning pair. When you add anew kerning pair, you can specify the left and right characters to use by typing them in these fields. ID (left and right) Display the left and right characters’ ASCII decimal values. When you add anew kerning pair, you can specify the left and right characters to use by typing their ASCII values in these fields. OX, OY For each character in the kerning pair, set the horizontal (X) and vertical (Y) offset relative to the character's initial position. AX For each character in the kerning pair, specify how far to advance along the baseline before placing the next character. Practically speaking, the left AX value controls the distance between the characters in the kerning pair, while the right AX value controls the distance between the kerning pair and the next character. Add New Kerning Pair Add a new entry to the Glyph Adjustment Table. You cannot duplicate an existing entry. NEW FILE: FontAssetsCreator.md Font Asset Creator The Font Asset Creator converts Unity font assets into TextMesh Pro font assets. You can use it to create both Signed Distance Field (SDF) fonts and bitmap fonts. When you create a new font Asset, TextMesh Pro generates the Asset itself, as well as the atlas texture and material for the font. After you create a TextMesh Pro font Asset, you can delete the Unity font Asset you used as a source, although you may want to keep it in the Scene in case you need to regenerate the TextMesh Pro font Asset. Creating a font Asset Before you start, make sure that you've already imported the font (usually a TrueType .ttf file) you want to use into the project. For more information about importing fonts into Unity, see the documentation on Fonts in the Unity manual. To create a TextMesh Pro font Asset: From the menu, choose: Window > TextMesh Pro > Font Asset Creator to open the Font Asset Creator. Choose a Source Font File. This the Unity font Asset that you want to convert into a TextMesh Pro font Asset. Adjust the Font Settings as needed, then click Generate Font Atlas to create the atlas texture The atlas, and information about the font Asset appear in the texture preview area. IMAGE Continue adjusting the settings and regenerating the atlas until you're satisfied with the result. Click Save or Save as... to save the font Asset to your project. You must save the Asset to a Resources folder to make it accessible to TextMesh Pro. Font Asset Creator Settings: Property: Function: Source Font File Select a font from which to generate a Text Mesh Pro font Asset. This font is not included in project builds, unless you use it elsewhere in the project, or put it in a Resources folder. You can use one of the default TextMesh Pro font assets, or import your own. Sampling Point Size Set the font size, in points, used to generate the font texture. Auto Sizing Use the largest point size possible while still fitting all characters on the texture. This is the usual setting for SDF fonts. Custom Size Use a custom point size. Enter the desired size in the text box. Use this setting to achieve pixel-accurate control over bitmap-only fonts. Padding Specify the space, in pixels, between characters in the font texture. Padding provides the space required to render character separately, and to generate the SDF gradient (See the documentation on Font Assets for details). The larger the padding, the smoother the transition, which allows for higher-quality rendering and larger effects, like thick outlines. A padding of 5 is often fine for a 512x512 texture. Packing Method Specify how to fit the characters into the font texture. Optimum Finds the largest possible automatic font size that still fits all characters in the texture. Use this setting to generate the final font texture. Fast Computes character packing more quickly, but may use a smaller font size than Optimum mode. Use this setting when testing out font Asset creation settings. Atlas Resolution Set the size width and height of the font texture, in pixels. A resolution of 512 x 512 is fine for most fonts, as long as you are only including ASCII characters. Fonts with more characters may require larger resolutions, or multiple atlases. When using an SDF font, a higher resolution produces finer gradients, and therefore higher quality text. Character Set The characters in a font file aren't included in the font Asset automatically. You have to specify which ones you need. You can select a predefined character set, provide a list of characters to include, or include all of the characters in an existing font Asset or text Asset. ASCII Includes the visible characters in the ASCII character set. Extended ASCII Includes the visible characters in the extended ASCII character set. ASCII Lowercase Includes only visible lower-case characters from the ASCII character set. ASCII Uppercase Includes only visible upper-case characters from the ASCII character set. Numbers + Symbols Includes only the visible numbers and symbols from the ASCII character set. Custom Range Includes a range of characters that you define. Enter a sequence of decimal values, or ranges of values, to specify which characters to include. Use a hyphen to separate the first and last values of a range. Use commas to separate values and ranges (for example 32-126,160,8230). You can also choose an existing font Asset to include the characters in that Asset. Unicode Range (Hex) Includes a range of characters that you define. Enter a sequence of unicode hexadecimal values, or ranges of values, to specify which characters to include. Use a hyphen to separate the first and last values of a range. Use commas to separate values and ranges (for example 20-7E,A0,2026). You can also choose an existing font Asset to include the characters in that Asset. Custom Characters Includes a range of characters that you define. Enter a sequence of characters to specify which characters to include. Enter characters one after the other, with no spaces or delimiting characters in between (for example abc123*#%). You can also choose an existing font Asset to include the characters in that Asset. Characters from File Includes all the characters in a text Asset that you specify. Use this option when you want to save your character set. Font Style Apply basic font styling when creating a bitmap-only font Asset. For SDF fonts, you configure the styling in the shader rather than the font Asset. Normal Generates characters with no styling. Bold, Italic, Bold_Italic Generates the font Asset with bold characters, italicized characters, or both. With these settings, you can set a strength value that applied to bolding and italicization Outline Generates the font Asset with outline characters. Bold_Sim Generates the font Asset with a simulated bold. Render Mode Specify the render mode to use when outputting the font atlas. SMOOTH Renders the atlas to an antialiased bitmap. RASTER Renders the atlas to a non-antialiased bitmap. SMOOTH_HINTED Renders the atlas to an antialiased bitmap, and aligns character pixels with texture pixels for a crisper result. RASTER_HINTED Renders the atlas to a non-antialiased bitmap and aligns character pixels with texture pixels for a crisper result. SDF Renders the atlas using a slower, but more accurate SDF generation mode, and no oversampling. SDFAA Renders the atlas using a faster, but less accurate SDF generation mode. It produces font atlases that are sufficient for most situations. SDFAA_HINTED Renders the atlas using a faster, but less accurate SDF generation mode, and aligns character pixels with texture pixels for a crisper result.. It produces font atlases that are sufficient for most situations SDF8 Renders the atlas using a slower, but more accurate SDF generation mode, and 8x oversampling. SDF16 Renders the atlas using a slower, but more accurate SDF generation mode, and 16x oversampling. SDF32 Renders the atlas using a slower, but more accurate SDF generation mode, and 32x oversampling. Use this setting for fonts with complex or small characters. Get Kerning Pairs Enable this option to copy the kerning data from the font. Kerning data is used to adjust the spacing between specific character pairs to produce a more visually pleasing result. Note: It isn't always possible to import kerning data. Some fonts store kerning pairs in their glyph positioning (GPOS) table, which is not supported by FreeType, the font engine used by TextMesh Pro. Other fonts do not store kerning pairs at all. Generate Font Atlas Generate the font atlas texture. Save Save the current font atlas. Save As Save the current font atlas as a new font Asset. Tips for creating font assets Characters in the font texture need some padding between them so they can be rendered separately. This padding is specified in pixels. Padding also creates room for the SDF gradient. The larger the padding, the smoother the transition, which allows for higher-quality rendering and larger effects, like thick outlines. A padding of 5 is often fine for a 512x512 texture. For most fonts, a 512x512 texture resolution is fine when including all ASCII characters. When you need to support thousands of character, you will have to use large textures. But even at maximum resolution, you might not be able to fit everything. In that case, you can split the characters by creating multiple font assets. Put the most often used characters in a main font Asset, and the others in a fallback font assets. NEW FILE: FontAssetsLineMetrics.md Line metrics. TextMesh Pro sets line metrics automatically when you generate a font Asset. If the generated values produce strange or incorrect results, you can tweak the line metrics settings to fine-tune the font. Most line metric values are relative to the Baseline, which is the horizontal line that characters sit on. Values for above-the-baseline metrics, such as the Ascender height, are greater that the Baseline value. Values for below-the-baseline metrics, such as the Descender height, are less than Baseline value. Metric: Function: Line Height The distance between the tops of consecutive lines. If you set the line height to a value greater than the combined size of the Ascender and Descender, it creates a gap between lines. If you set a line height to a value less than the combined size of the ascender and descender results in potential overlap between characters on different lines. Ascender The ascender height, which specifies how far characters can extend above the baseline. It corresponds to the top of a line. Cap Height The height of capital letters from the baseline. Baseline The baseline height. The baseline is the horizontal line that characters sit on. Descender The descender height, which specifies how far characters can extend below the baseline. Underline Offset The position of underlines relative to the baseline. Strikethrough Offset The position of strikethrough lines relative to the baseline. Superscript/ Subscript Offset Adjust the baseline for superscript and subscript text. Super/ Subscript Size The scale of superscript and subscript text relative to the normal font size. Padding The amount of padding between characters in the font atlas texture. TextMesh Pro sets this value when you generate the font Asset. It is not editable. Width/Height The font atlas texture's width and height, in pixels. TextMesh Pro sets these values when you generate the font Asset. They are not editable. NEW FILE: FontAssetsSDF.md About SDF fonts TextMesh Pro takes advantage of Signed Distance Field (SDF) rendering to generate font assets that look crisp when transformed, magnified, and so on, and support effects like outlines and drop shadows. Unlike black and white bitmap font textures, SDF font assets contain contour distance information. In font atlases, this information looks like grayscale gradients running from the middle of each glyph to a point past its edge, with the mid-point of the gradient corresponding to the edge of the glyph. The images below show bitmap and SDF font assets and the rendered text they produce. Notice that the bitmap fonts produce text whose edges are more or less jagged/blurry, depending on how far the text is from the camera, and how it is transformed/distorted. The SDF font, on the other hand produces text with completely smooth edges. A bitmap font, atlas texture and rendered result A smoothed bitmap, atlas texture and rendered result An SDF font, atlas texture and rendered result NEW FILE: FontAssetsDynamicFonts.md Dynamic fonts assets Normally when you generate a font Asset using the Font Asset Creator, you choose which characters to include, and bake them into a Font Atlas texture. Dynamic font assets work the other way around. Instead of baking characters into an atlas in advance, you start with an empty atlas to which characters are added automatically as you use them. This makes dynamic fonts assets more flexible, but that flexibility comes at a cost. Dynamic fonts require more computational resources than static fonts. Dynamic font assets maintain a link to the original font file used to created them. That means: During development, you must keep the font file in the project. You cannot delete it as you can the source fonts of static font assets. Source fonts of any dynamic font assets in your game are included in builds, which can increase build size. This has several uses, for example: Use dynamic fonts during development to capture characters you forgot to include in your baked font assets. At runtime, use Working with dynamic font assets Creating a dynamic font Asset Empty font assets are dynamic by default. To create one: From Unity's main menu, choose Assets > Create > TextMeshPro > Font Asset or press Ctrl/Cmd + Shift + F12. To make an existing font Asset dynamic: Select Asset and open it in the Inspector. Set the Generation Settings > Atlas Population Mode property to Dynamic. Modifying dynamic font Asset settings Resetting a dynamic font Asset You reset TextMesh Pro dynamic font assets, the same way you reset other components: by choosing Reset from the gear icon menu or context menu in the Inspector. [IMAGE] However, instead of resetting all of the Asset's properties to their default values, the command affects only: The Font Atlas The Character Table The Glyph Table The Glyph Adjustment Table (kerning) These are reset to include only the characters/glyphs used by TextMesh Pro text objects that use the font Asset. If the Asset is currently unused, TextMesh Pro resizes the atlas texture to 0 x 0 pixels. NOTE: Resetting a static font Asset leaves the atlas texture as-is, but empties the character-, glyph-, and glyph adjustment tables. Updating/Baking a dynamic font Asset NEW FILE: FontAssetsFallback.md Fallback font assets A font atlas, and by extension a font Asset, can only contain a certain number of glyphs. The exact number depends on the font, the size of the atlas texture, and the settings you use when generating the atlas. The fallback font system allows you to specify other font assets to search when TextMesh Pro can't find a glyph in a text object's font Asset. This is useful in a variety of situations, including: Working with languages that have very large alphabets (Chinese, Korean, and Japanese, for example). Use fallback fonts to distribute an alphabet across several assets. Designing for mobile devices, where an imposed maximum texture size prevents you from fitting an entire set of glyphs in a single atlas of sufficient quality. Including special characters from other alphabets in your text. Local and general fallback font assets Every font Asset can have its own list of fallback font assets. You set these in the font Asset properties. You can also set general fallback font assets that apply to every TextMesh Pro font Asset in your project. You set these in the TextMesh Pro settings. The fallback chain In addition to a text object's fallback fonts, TextMesh Pro searches several other assets for missing glyphs. Together, these assets form the fallback chain. The table below lists the assets in the fallback chain in the order in which they are searched. Position: Asset: Defined in: Notes: 1 TextMesh Pro object's primary Font Asset Text object properties 2 Primary font assets Fallback Font Assets Font Asset properties TexMesh Pro searches these assets in the order they're listed in the font Asset properties. The search is recursive, and includes each fallback Asset's fallback assets. 3 Text object's Sprite Asset Text object properties When searching sprite assets, TextMesh Pro looks for sprites with an assigned unicode value that matches the missing character's unicode value. 4 General Fallback Font Assets TextMesh Pro settings TexMesh Pro searches these assets in the order they're listed in the font Asset properties. The search is recursive, and includes each fallback Asset's fallback assets. 5 Default Sprite Asset TextMesh Pro settings When searching sprite assets, TextMesh Pro looks for sprites with an assigned unicode value that matches the missing character's unicode value. 6 Default Font Asset TextMesh Pro settings 7 Missing glyphs character TextMesh Pro settings The fallback chain search is designed to detect circular references so each Asset in the chain is only searched once. NEW FILE: RichText.md Rich Text Rich text tags alter the appearance and layout of text by supplementing or overriding TextMesh Pro GameObject properties. For example, you can use rich text tags to change the color or alignment of some, or all of your text without modifying its properties or material. To use rich text tags: Enter any supported rich text tags in the TextMeshPro Text input field, inline with the text you want to display. To disable rich text for a TextMesh Pro object: Open the TextMesh Pro GameObject in the Inspector, and disable the Text Mesh Pro > Extra Settings > Rich Text property. Rich Text Tags Rich text tags are similar to HTML or XML tags, but have less strict syntax. A simple tag consists of only the tag name, and looks like this: <tag> For example, the <b> tag makes text bold, while the <u> tag underlines it. Tag attributes and values Some tags have additional values or attributes, and look like this: <tag=\"value\"> or <tag attribute=\"value\"> For example <color=”red”> makes text red. Red is the color tag’s value. Similarly <sprite index=3> inserts the fourth sprite from the default Sprite Asset. index is an attribute of the sprite tag, and its value is 3. A tag, including its attributes, can be up to 128 characters long. The table below lists possible attribute/value types. Attribute/value type: Example Decimals 0.5 Percentages 25% Pixel values 5px Font units 1.5em Hex color values #FFFFFF (RGB) #FFFFFFFF (RGBA) #FF (A) Names Both <link=”ID”> and <link=ID> are valid. Tag scope and nested tags Tags have a scope that defines how much of the text they affect. Most of the time, a tag added to a given point in the text affects all of the text from that point forward. For example, adding the tag <color=\"red\"> at the beginning of the text affects the entire text block: <color=\"red\">This text is red Successive color tags Adding the same tag in the middle of the text block affects only the text between the tag and the end of the block : This text turns<color=\"red\"> red Successive color tags If you use the same tag more than once in a text block, the last tag supersedes all previous tags of the same type. <color=\"red\">This text goes from red<color=\"green\"> to green Successive color tags You can also limit the scope of most tags using a closing tag. Closing tags contain only a forward slash and the tag name, like this: </tag> Tags can also be nested so one tag’s scope is within another tag’s scope. For example: <color=red>This text is <color=green>mostly </color>red. Successive color tags The first <color> tag’s scope is the entire text block. The the second <color> tag has a closing tag that limits its scope to one word. When you nest tags, you don't have to close their scopes in the same order that you started them. Rich-text tags and right-to-left text TextMesh Pro's right-to-left editor does not distinguish between regular text and rich text tags. Rich text tags that you enter in the right-to-left editor do not work unless you type them right-to-left as well. The easiest way to apply rich text tags to right-to-left text is to type the text in the right-to-left editor, and then apply the tags in the regular editor. NEW FILE: RichTextSupportedTags.md Supported Rich Text Tags The following table is a quick reference of supported rich text tags. For details, see the main pages for specific tags. Tag: Description: Notes: <align> Changes the text's horizontal alignment. <allcaps> Converts text to uppercase before rendering. Functionally identical to <uppercase>. <alpha> Changes text opacity. <b> Renders text in boldface. <br> Forces a line break in text. <color> Changes text color or color and opacity. <cspace> Changes spacing between characters. <font> Changes text font and, optionally, material. <font-weight> Changes the text's font weight to any of the weights defined in the font Asset. <gradient> Applies a gradient preset to text. <i> Renders text in italics. <indent> Indents all text between the tag and the next hard line break. <line-height> Modifies the line height relative to the default line height specified in the font Asset. <line-indent> Indents the first line after every hard line break. New lines created by word-wrapping are not indented. <link> Specifies a link ID for a text segment. <lowercase> Converts text to lowercase before rendering. <margin> Gives the text horizontal margins. You can set margins for both sides together or each side individually <mark> Highlights the text with a colored overlay. The overlay must be translucent (alpha less than 1) for the text to show through. <mspace> Renders the text as monospace. <nobr> Keeps a segment of text together. <noparse> Prevents parsing of text that TextMesh Pro would normally interpret as rich text tags. <page> Adds a page break to the text. The text's Overflow mode must be set to Page for page breaks to work. <pos> Sets the horizontal caret position on the current line. <rotate> Rotates each character about its center. <s> Renders a line across the text. <size> Adjusts the font size for a specified portion of the text. <smallcaps> Converts text to uppercase before rendering. <space> Adds a horizontal offset between itself and the rest of the text. <sprite> Adds a sprite to the text. By default, TextMesh Pro looks in the default sprite assets, but you can use tag attributes to retrieve sprites from other assets. <strikethrough> Draws a line slightly above the baseline so it crosses out the text. <style> Applies a custom style to the text. <sub> Converts the text to subscript. <sup> Converts the test to superscript. <u> Draws a line slightly below the baseline to underline the text. <uppercase> Converts text to uppercase before rendering. Functionally identical to <allcaps>. <voffset> Gives the baseline a vertical offset. <width> Changes the horizontal size of text area. NEW FILE: RichTextAlignment.md Text Alignment Each text object has an overall alignment, but you can override this with <align> tags. All horizontal alignment options are available except for Geometry Center. Normally you put these tags at the start of a paragraph. Successive alignment scopes don't stack. If you put multiple alignment tags on the same line, the last one overrides the others. The closing </align> tag reverts back to the object's overall alignment. Example: <align=\"left\"><b>Left-aligned</b> <align=\"center\"><b>Center-aligned</b> <align=\"right\"><b>Right-aligned</b> <align=\"justified\"><b>Justified:</b> stretched to fill the display area (except for the last line) <align=\"flush\"><b>Flush:</b> stretched to fill the display area (including the last line) Text Alignment NEW FILE: RichTextLetterCase.md Lowercase, Uppercase, and Smallcaps The <lowercase>, <uppercase>, <allcaps> and <smallcaps> tags alter the capitalization of your text before rendering. The text in the Text field remains as you entered it. The <lowercase> and <uppercase> tags work as you would expect, converting to all capitals or no capitals before rendering. The <allcaps> tag is functionally identical to <uppercase>. The <smallcaps> tag works like <uppercase>, but also reduces the size of all characters that you entered in lowercase. Example: <lowercase>Alice and Bob watched TV.</lowercase> <uppercase>Alice and Bob watched TV.</uppercase> <allcaps>Alice and Bob watched TV.</allcaps> <smallcaps>Alice and Bob watched TV.</smallcaps> Modifying capitalization. NEW FILE: RichTextOpacity.md Text Opacity (Alpha) Use the <alpha> tag to change text opacity. It works with hexadecimal values. Example: <alpha=#FF>FF <alpha=#CC>CC <alpha=#AA>AA <alpha=#88>88 <alpha=#66>66 <alpha=#44>44 <alpha=#22>22 <alpha=#00>00 Successive <alpha> tags NEW FILE: RichTextBoldItalic.md Bold and Italic You can apply bold and italic styling to your text with the <b> and <i> tags respectively. The font Asset defines how bold and italicized text looks when rendered. The closing </b> and </i> tags revert to the text's normal appearance. Example: The <i>quick brown fox</i> jumps over the <b>lazy dog</b>. Bold and italic. NEW FILE: RichTextColor.md Text Color There are two ways to change text color with color tags: Use named colors, as in <color=\"colorName\"> The following color names are supported: black, blue, green, orange, purple, red, white, and yellow. Use hexadecimal values, as in <color=#FFFFFF> or <color=#FFFFFFFF> if you also want to define the alpha value. If you apply successive <color> tags in the same text, the last one takes precedence over the others until you either add another <color>tage or use a closing </color> tag to end the current color's scope. Example: <color=\"red\">Red <color=#005500>Dark Green <#0000FF>Blue <color=#FF000088>Semitransparent Red Successive color tags <color=\"red\">Red, <color=\"blue\">Blue,</color> and red again. Closing color tag NEW FILE: RichTextCharacterSpacing.md Character Spacing The <cspace> tag allows you to adjust character spacing, either absolute or relative to the original font Asset. You can use pixels or font units. Postive adjustments push the characters apart, negative adjustments pull them together. The closing </cspace> tag reverts back to the font's normal spacing. Example: <cspace=1em>Spacing</cspace> is just as important as <cspace=-0.5em>timing. Character spacing NEW FILE: RichTextFont.md Font You can switch to a different font using <font=\"fontAssetName\">. The font you specify replaces the default font until you insert a closing <font> tag. Font tags can be nested. You can also use the material attribute to switch between different materials for a single font. Font and material assets must be placed in specified in the TextMesh Pro settings Asset. To revert to the default font: Close all open font tags using </font> tag Use another <font> tag and set the font Asset name to default Example: Would you like <font=\"Impact SDF\">a different font?</font> or just <font=\"NotoSans\" material=\"NotoSans Outline\">a different material? Mixing fonts and materials NEW FILE: RichTextFontWeight.md Font weight Use the <font-weight> tag to switch between the font weights available for the current Font Asset. You specify the weight using its numeric value, for example 400 for normal, 700 for bold, and so on. You can only apply font weights defined in the Font Asset properties. If you have not defined any font weights, you can still use values of 400 and 700 to apply the multipliers set in the Normal Weight and Bold Weight properties. The closing </font-weight> tag reverts to the original font specified for the TextMesh Pro object. Example: <font-weight=\"100\">Thin</font-weight> <font-weight=\"200\">Extra-Light</font-weight> <font-weight=\"300\">Light</font-weight> <font-weight=\"400\">Regular</font-weight> <font-weight=\"500\">Medium</font-weight> <font-weight=\"600\">Semi-Bold</font-weight> <font-weight=\"700\">Bold</font-weight> <font-weight=\"800\">Heavy</font-weight> <font-weight=\"900\">Black</font-weight> Font weights NEW FILE: RichTextGradient.md Gradient The <gradient> tag applies a pre-defined gradient preset to text. For more information about creating gradient presets, see the documentation on Gradient Presets. The closing </gradient> tag reverts to the TextMesh pro object's original color. Example: Apply<b> <gradient=\"Yellow to Orange - Vertical\">any <gradient=\"Light to Dark Green - Vertical\">gradient <gradient=\"Blue to Purple - Vertical\">preset</gradient> </b>to your text Successive gradient tags ended with a closing </gradient> Note: When you apply a gradient using this tag, it's multiplied by the TextMesh Pro object's current vertex colors. This <gradient=\"Light to Dark Green - Vertical\">Light to Dark Green gradient</gradient> is tinted by the red vertex color Applying a green gradient to red text To apply the pure gradient to a selection of text, you can use a <color> tag to \"reset\" the color to white before applying the gradient. This <color=#FFFFFFFF><gradient=\"Light to Dark Green - Vertical\">Light to Dark Green gradient</gradient></color> is no longer tinted by the red vertex color \"Resetting\" the text's vertex color before applying a gradient NEW FILE: RichTextBoldItalic.md Bold and Italic You can apply bold and italic styling to your text with the <b> and <i> tags respectively. The font Asset defines how bold and italicized text looks when rendered. The closing </b> and </i> tags revert to the text's normal appearance. Example: The <i>quick brown fox</i> jumps over the <b>lazy dog</b>. Bold and italic. NEW FILE: RichTextIndentation.md Indentation The <indent> tag controls the horizontal caret position the same way the <pos> tag does, but the effect persists across lines. Use this tag to create text patterns, such as bullet points, that work with word-wrapping. You specify indentation in pixels, font units, or percentages. Example: 1. <indent=15%>It is useful for things like bullet points.</indent> 2. <indent=15%>It is handy. Using indentation to make a list. NEW FILE: RichTextLineHeight.md Line Height Use the <line-height> tag to manually control line height. The line-height controls how far down from the current line the next line starts. It does not change the current line. Smaller values pull lines closer together. Larger values push them farther apart. You can specify the line height in pixels, font units, or percentages. Adjustments you make using this tag are relative to the line-height specified in the Font Asset. The </line-height> closing tag reverts to this height. Example: Line height at 100% <line-height=50%>Line height at 50% <line-height=100%>Rather cozy. <line-height=150%>Line height at 150% Such distance! Different line heights NEW FILE: RichTextLineIndentation.md Line Indentation The <line-indent> tag inserts horizontal space directly after it, and before the start of each new line. It only affects manual line breaks (including line breaks created with the <br> tag, not word-wrapped lines. You can specify the indentation in pixels, font units, or percentages. The </line-indent> closing tag ends the indentation of lines. Example: <line-indent=15%>This is the first line of this text example. This is the second line of the same text. Indent every new line, with one tag NEW FILE: RichTextLink.md Text Link You can use <link=\"ID\">my link</link> to add link metadata to a text segment. The link ID should be unique to allow you to retrieve its ID and link text content when the user interacts with your text. You do not have to give each link a unique ID. You can reuse IDs when it makes sense, for example when linking to the same data multiple times. The linkInfo array contains each ID only once. While this link enables user interaction, it does not change the appearance of the linked text. You have to use other tags for that. NEW FILE: RichTextLetterCase.md Lowercase, Uppercase, and Smallcaps The <lowercase>, <uppercase>, <allcaps> and <smallcaps> tags alter the capitalization of your text before rendering. The text in the Text field remains as you entered it. The <lowercase> and <uppercase> tags work as you would expect, converting to all capitals or no capitals before rendering. The <allcaps> tag is functionally identical to <uppercase>. The <smallcaps> tag works like <uppercase>, but also reduces the size of all characters that you entered in lowercase. Example: <lowercase>Alice and Bob watched TV.</lowercase> <uppercase>Alice and Bob watched TV.</uppercase> <allcaps>Alice and Bob watched TV.</allcaps> <smallcaps>Alice and Bob watched TV.</smallcaps> Modifying capitalization. NEW FILE: RichTextMargins.md Margin You can increase the horizontal margins of the text with the <margin> tag. If you only want to adjust the left or right margin, you can use the <margin-left> or <margin-right> tag. You can specify the margins in pixels, font units, and percentages. Negative values have no effect. Adjustments you make using this tag are relative to the margins specified in the TexMesh Pro object. The </margin> closing tag reverts to this value. Example: Our margins used to be very wide. <margin=5em>But those days are long gone. Adjusting margins NEW FILE: RichTextMark.md Mark The <mark> tag adds an overlay on top of the text. You can use it to highlight portions of your text. Because markings are overlaid on the text, you have to give them a semitransparent color for the text to show through. You can do this by specifying the color using a hex value that includes Alpha. You cannot combine marks. Each tag affects the text between itself and the next <mark> tag or a closing </mark> tag. Example: Text <mark=#ffff00aa>can be marked with</mark> an overlay. Marked text NEW FILE: RichTextMonospace.md Monospacing You can override a font's character spacing and turn it into a monospace font with the <mspace> tag. This gives all characters the same amount of horizontal space. You can specify the character width in pixels or font units. The </mspace> closing tag clears all monospace overrides. Example: Any font can become <mspace=2.75em>monospace, if you really want it. Treating a font as monospace NEW FILE: RichTextNoBreak.md No Break Use the <nobr> tag to keep specific words together, and not be separated by word wrapping. The closing </nobr> tag reverts to the default behavior of allowing words to break where the line wraps. If you apply the <nobr> tag to a segment of text that is too big to fit on one line, the segment will break wherever the line wraps. Example: You don't want <nobr>I M P O R T A N T</nobr> things to be broken up. The important parts stay together NEW FILE: RichTextNoParse.md Noparse The <noparse> tag creates a scope that TextMesh Pro does not parse. This is useful for rendering text that TextMesh Pro normally interprets as a rich text tag, without disabling rich text tags. Example: Use <noparse><b></noparse> for <b>bold</b> text. Prevent parsing of some tags NEW FILE: RichTextPageBreak.md Page Break You can use the <page> tag to insert page breaks in your text. This cuts the text into separate blocks. For page breaks to work, you must set the TextMesh Pro object's Overflow mode to Page. NEW FILE: RichTextPos.md Horizontal Position The <pos> tag gives you direct control over the horizontal caret position. This works best with horizontal alignment. The <pos> tag's position in the line has no effect on the caret position. This tag is best used with left alignment. You can specify the horizontal position in pixels, font units, or percentages. Example: at <pos=75%>75% at <pos=25%>25% at <pos=50%>50% at 0% Setting caret positions NEW FILE: RichTextRotate.md Rotate Use the <rotate> tag to rotate each character about its center. Specify the amount of rotation in degrees. Positive values rotate characters counter-clockwise. Negative values rotate them clockwise. Rotation affects the spacing between characters, and may cause characters to overlap in some cases. Use the <cspace> tag to correct character spacing as needed. Example: Rotate text <rotate=\"-10\">counter-clockwise</rotate> or <rotate=\"10\">clockwise</rotate> Text rotated counter-clockwise (left) and clockwise (right) Rotate text <rotate=\"45\">counter-clockwise</rotate> More rotation makes it more likely that characters overlap Rotate text <cspace=\"15\"><rotate=\"45\">counter-clockwise</rotate></cspace> The <cspace> tag adjusts character spacing, and can help correct overlap caused by rotation NEW FILE: RichTextStrikethroughUnderline.md Strikethrough and Underline You can add additional lines that run along your text. The <underline> tag draws the line slightly below the baseline to underline the text. The vertical offset is defined in the Font Asset. The <strikethrough> tag places the line slightly above the baseline so it crosses out the text. Example: The <s>quick brown</s> fox jumps over <u>the lazy dog</u>. Strikethrough and underline NEW FILE: RichTextSize.md Font Size Use the <size> tag to adjust the font size of your text. You can specify the new size in pixels, font units, or percentage. Pixel adjustments can be absolute (5px, 10px, and so on) or relative (+1 or -1, for example). Relative sizes are based on the original font size, so they're not cumulative. Example: <size=100%>Echo <size=80%>Echo <size=60%>Echo <size=40%>Echo <size=20%>Echo Adjusting font size NEW FILE: RichTextLetterCase.md Lowercase, Uppercase, and Smallcaps The <lowercase>, <uppercase>, <allcaps> and <smallcaps> tags alter the capitalization of your text before rendering. The text in the Text field remains as you entered it. The <lowercase> and <uppercase> tags work as you would expect, converting to all capitals or no capitals before rendering. The <allcaps> tag is functionally identical to <uppercase>. The <smallcaps> tag works like <uppercase>, but also reduces the size of all characters that you entered in lowercase. Example: <lowercase>Alice and Bob watched TV.</lowercase> <uppercase>Alice and Bob watched TV.</uppercase> <allcaps>Alice and Bob watched TV.</allcaps> <smallcaps>Alice and Bob watched TV.</smallcaps> Modifying capitalization. NEW FILE: RichTextSpace.md Horizontal Space The <space> tag inserts a horizontal offset, as if you inserted multiple spaces. You can specify the offset in pixels or font units. When the <space> tag touches adjacent text, it appends or prepends the offset to that text, which affects how the text wraps. If you do not want the offset to wrap independently of adjacent text, make sure to add a space character on either side of the <space> tag. Example: Give me some <space=5em> space. Adding some space NEW FILE: RichTextSprite.md Sprite The <sprite> tag inserts images from a Sprite Asset into your text. Sprite assets must be located in the folder specified in the TextMesh Pro settings. You can access sprites from the default sprite assets by index <sprite index=1> or by name <sprite name=\"spriteName\">. When accessing a sprite from the default Asset by index, you can also use the index shorthand, <sprite=1>, To use sprites from a different Asset, specify the Asset before accessing the sprites by index <sprite=\"assetName\" index=1> or by name <sprite=\"assetName\" name=\"spriteName\">. Adding the tint=1 attribute to the tag tints the sprite with the TextMesh Pro object's Vertex Color. You can choose a different color by adding a color attribute to the tag (color=#FFFFFF). Example: Sprites! <sprite=0> More sprites! <sprite index=3> And even more! <sprite name=\"Default Sprite Asset_4\" color=#55FF55FF> Inserting sprites from the default sprite asset NEW FILE: RichTextStyle.md Style Apply custom styles using the <style> tag. For more information about creating custom styles, see the documentation on Style Sheets. The opening <style> tag must contain the style name. The closing </style> tag, which simply closes the last style opened. Example: <style=\"Title\">Styles</style> You can create your own. Applying a custom style NEW FILE: RichTextSubSuper.md Subscript and Superscript Use the <sub> and <sup> tags to render text as superscript or subscript. This is often used in scientific notation and ordinal numbering (1st, 2nd, etc.). Set the offset and size for sub- and superscript in the Font Asset. Example: We have 1m<sup>3</sup> of H<sub>2</sub>O. Subscript and superscript NEW FILE: RichTextSubSuper.md Subscript and Superscript Use the <sub> and <sup> tags to render text as superscript or subscript. This is often used in scientific notation and ordinal numbering (1st, 2nd, etc.). Set the offset and size for sub- and superscript in the Font Asset. Example: We have 1m<sup>3</sup> of H<sub>2</sub>O. Subscript and superscript NEW FILE: RichTextStrikethroughUnderline.md Strikethrough and Underline You can add additional lines that run along your text. The <underline> tag draws the line slightly below the baseline to underline the text. The vertical offset is defined in the Font Asset. The <strikethrough> tag places the line slightly above the baseline so it crosses out the text. Example: The <s>quick brown</s> fox jumps over <u>the lazy dog</u>. Strikethrough and underline NEW FILE: RichTextLetterCase.md Lowercase, Uppercase, and Smallcaps The <lowercase>, <uppercase>, <allcaps> and <smallcaps> tags alter the capitalization of your text before rendering. The text in the Text field remains as you entered it. The <lowercase> and <uppercase> tags work as you would expect, converting to all capitals or no capitals before rendering. The <allcaps> tag is functionally identical to <uppercase>. The <smallcaps> tag works like <uppercase>, but also reduces the size of all characters that you entered in lowercase. Example: <lowercase>Alice and Bob watched TV.</lowercase> <uppercase>Alice and Bob watched TV.</uppercase> <allcaps>Alice and Bob watched TV.</allcaps> <smallcaps>Alice and Bob watched TV.</smallcaps> Modifying capitalization. NEW FILE: RichTextVOffset.md Vertical Offset Use the <voffset> tag to offset the text baseline vertically. This adjusts the line height accordingly to accommodate the text's offset position. You can compensate for that adjustment by manually adjusting the line height. Specify the offset in pixels or font units. The offset is always relative to the original baseline. The </voffset> closing tag resets the baseline back to its original position. Example: Up <voffset=1em>up <voffset=2em>UP</voffset> and <voffset=-0.5em>down</voffset> we go again. Vertical offset NEW FILE: RichTextWidth.md Text Width Use the <width> tag adjust the horizontal size of text area. The change takes effect on the current line, after the tag. Typically, you place the tag at the start of a paragraph. If you add more than one ,width> tag to a line, the last one takes precedence over the others. You can specify the width in either pixels, font units, or percentages. The adjusted width cannot exceed the TextMesh Pro object's original width. The closing </width> tag reverts to the original width. Example: I remember when we had lots of space for text. <width=60%>But those days are long gone. Adjusting text area width NEW FILE: StyleSheets.md Style Sheets Use style sheets to create custom text styles that you can apply to text using the <style> rich text tag. A custom style can include opening and closing rich text tags, as well as leading and trailing text. For example, you might want headings in your text to be big, red, bold, with an asterisk to either side and a line break at the end. Instead of typing this for every heading: <font-weight=700><size=2em><color=#FF0000>*Heading*</color></size></font-weight><br> You can create a style, called H1 that includes all of that formatting: You can then format all of your headings with a single <style> tag: <style=\"H1\">Heading</style> The default style sheet The default style sheet is the style sheet that every TextMesh Pro object in your TextMesh Pro ships with a default style sheet stored in the TextMesh Pro > Resources > Style Sheets folder, but you can set any style sheet to be the default. To change the default style sheet, set the Default Style Sheet > Default Style Sheet option in the TextMesh Pro settings. Per-object style sheets Creating custom style sheets To create a new style sheet, choose Assets > Create > TextMesh Pro > Style Sheet from the menu. This adds a new TextMesh Pro style sheet to the Project. Open it in the Inspector to add custom styles. NEW FILE: Sprites.md Sprites TextMesh Pro allows you to include sprites in your text via rich text tags. To use sprites in your Scene, you need a Sprite Asset. You create sprite assets from atlas textures that each contain a given set of sprites. A sprite atlas texture You can use as many sprite atlases and assets as you like, but keep in mind that using multiple atlases per text object results in multiple draw calls for that object, which consumes more system resources. As a rule, try to stick to one atlas per object. Note: Sprites are regular bitmap textures, so make sure that their resolution is high enough to display correctly on your target platforms. Using Sprite Assets To use a sprite Asset in your project, put it in a Resources/Sprites folder. This allows TextMesh Pro to find it. Once you've added/created your sprite assets, you can set one as the default source for sprites in the project. You set the default sprite Asset in the TextMesh Pro Settings. You can also choose sprite assets to use with specific text objects. Edit a TexMesh Pro 3D or TextmeshPro UI Asset to specify a sprite Asset to use with the font. Creating a Sprite Asset You create sprite assets from atlas textures. Although sprite assets and their source textures are separate entities, you must keep the source textures in the project after creating the sprite assets. Select the texture you want to use for the Sprite Asset. In the Inspector, change the following Texture Importer properties. Set the Texture Type to Sprite (2D and UI). Set the Sprite Mode to Multiple. Open the Sprite Editor from the Inspector, or choose Window > 2D > Sprite Editor from the menu, and use it to divide the texture into individual sprites. With the texture still selected, choose Asset > Create > TextMesh Pro > Sprite Asset from the menu to create a new sprite Asset. After creating the sprite Asset, you can revert the atlas texture's Texture Type to its original setting. Sprite Asset Properties The Sprite Asset properties are divided into the following groups: Sprite Info: Provides references to the sprite Asset's material and source texture. Fallback Sprite Assets: Provides references to the sprite Asset's material and source texture. Sprite List: Provides references to the sprite Asset's material and source texture. Sprite Info Property: Function: Sprite Atlas A reference to the sprite Asset's source texture. Default Material A reference to the sprite Asset's material, which it uses to render sprites. Fallback Sprite Assets When TextMesh Pro can't find a glyph in this sprite assets, it searches the fallback sprite assets that you specify here. Property: Function: Fallback Sprite Asset List Manage the fallback sprite assets. Click + and - to add and remove font slots. Click the circle icon next to a font to choose a font Asset using the Object Picker. Drag the handles on the left side of any font Asset to reorder the list. Sprite List Property: Function: Sprite Search Search the sprite list by ID or Name. Search results are ordered by ID, lowest to highest. Previous Page / Next Page Long sprite lists are split into pages, which you can navigate using these buttons (also located at the bottom of the section). Sprite Properties Manage the sprites in this Asset. Click a sprite to make it active. Click Up or Down to move the sprite up or down in the list. Enter an ID in the text field and click Goto to move the sprite to that position in then list. Note: Moving a sprite updates its ID and the IDs of all preceding sprites accordingly. Click + to add a copy of the sprite to the list. Click - to remove the sprite from the list. ID A unique ID for the sprite, based on its portion in the list. You can use this value in rich text tags tags to add this sprite to text. Reordering the list updates the IDs of any affected sprites Unicode Name A unique name for the sprite. You can change this value, but it must be unique in the list You can use this value in rich text tags to add this sprite to text. X, Y, W, H The rectangular area the character occupies in the sprite atlas. OX, OY Control the placement of the sprite, defined at its top-left corner relative to its origin on the baseline. Adv. Specify how far to advance along the baseline before placing the next sprite. SF Change this scaling factor value to adjust the size of the sprite. Global Offsets & Scale Use these settings to override the following values for all sprites in the Asset: OX, OY, ADV., and SF. NEW FILE: ColorGradients.md Color Gradients You can apply gradients of up to four colors to TextMesh Pro GameObjects. When you add a gradient, TextMesh Pro applies it to each character in the text individually. It stores gradient colors as in each character sprite's vertex colors. TextMesh Pro text with a four-color gradient Because each character sprite consists of two triangles, gradients tend to have a dominant direction. This is most obvious in diagonal gradients. For example, the dominant direction in gradient below favors the red and black colors in the bottom-left and top-right corners When you reverse the gradient colors, so both the top-right and bottom-left corners are yellow, the dominant color changes. TextMesh Pro multiplies gradient colors with the text's main vertex color (Main Settings > Vertex Color in the TextMesh Pro Inspector). If the main vertex color is white you see only the gradient colors. If it’s black you don’t see the gradient colors at all. Applying a Gradient To apply a gradient to a TextMesh Pro GameObject, edit the Gradient properties in the Inspector. Note To apply a gradient to only a portion of the text, use the gradient rich text tag. To apply a gradient to multiple text objects, use a gradient preset. To apply a color gradient to a TextMesh Pro GameObject: Enable the Main Settings > Color Gradient property. Set Main Settings > Color Gradient > Color Mode to the type of gradient you want to apply. Use the Main Settings > Color Gradient > Colors settings to choose colors for the gradient. For each color you can: Click the color swatch to open a Color Picker. Use the eyedropper to pick a color from anywhere on your screen. Enter the color’s hexadecimal value directly in the text field. NEW FILE: ColorGradientsTypes.md Color Gradient Types You can apply the following types of gradients to text. Single: A single color that is TextMesh Pro multiplies with the text object's vertex color. Horizontal: A two-color side-to-side gradient. Vertical: A two-color up-and-down gradient. Four Corner: A four-color gradient. Each color radiates from one corner. The TexMesh Pro color gradient settings The number of colors available in the Colors settings depends on the type of gradient you choose. Each swatch corresponds to the color's origin on a character sprite. The image above shows a the settings for a four color gradient. Each color originates in the corresponding corner of the sprite (top-left, top-right, bottom-left, bottom-right). IT produces the following gradient: Single Color The Single gradient type applies a single color. Horizontal Gradients The Horizontal gradient type applies two colors, and produces a side to side transition between them on each character. Vertical Gradients The Vertical gradient type consists of two colors, and produces an up and down transition between the two on each character. Four Corner Gradients The Four Corner gradient type applies four colors. Each one radiates out from its assigned corner of each character. This is the most versatile gradient type. By varying some colors and keeping others identical, you can create different kinds of gradients. For example: Give three corners one color and the fourth a different color. Give pairs of adjacent corners the same color to create horizontal or vertical gradients. Give pairs of diagonally opposite corners the same color to create diagonal gradients. Create horizontal and vertical 3-color gradients with a dominant color at one end and a transition between two colors at the other. Give two diagonally opposite corners same color and give the other two corners different colors to create a diagonal stripe 3-color gradient. NEW FILE: ColorGradientsPresets.md Gradient Presets Use gradient presets to reuse the same color gradients across text objects. A gradient preset overrides the text’s local gradient type and colors. You have to store Gradient presets in a specific folder so TextMesh Pro can find them and include them in builds. You can change the folder from the TextMesh Pro settings. Creating gradient presets To create a gradient preset, choose Assets > Create > TextMesh Pro > Color Gradient from the menu. This adds a new TextMesh Pro Color Gradient Asset to the Scene, and opens it in the Inspector. You can then select a gradient type from the Color Mode dropdown, and set the gradient Colors. Applying gradient presets You apply a gradient preset to text from the TextMesh Pro Inspector. To apply a gradient preset: Enable the Main Settings > Color Gradient property. Open the Object Picker (circle icon) for Main Settings > Color Preset, and choose choose a preset When you apply a gradient preset, the Inspector overrides the text's gradient type and colors with the values from the preset. Caution If you modify the gradient settings in the TextMesh Pro Inspector after you apply a preset, it affects the preset itself. Changes affect every object that uses the same preset. Removing gradient presets To remove a gradient preset, open the Object Picker (circle icon) for Main Settings > Color Preset, and choose None. When you remove the preset, the text reverts to its local gradient properties. NEW FILE: Shaders.md Shaders TextMesh Pro has been designed to take advantage of signed distance field (SDF) rendering and includes a collection of shaders for this purpose. There are also bitmap-only shaders, in case you don't want to use SDF rendering. All shaders have a desktop and a mobile version. The mobile versions are less demanding and suitable for mobile devices, but support fewer effects. All shaders can be found in the shader menu under TextMeshPro and TextMeshPro / Mobile. SDF Shaders There are three variants of the SDF shader, known as Distance Field, Distance Field (Surface), and Distance Field Overlay. The regular and overlay shaders are unlit, so they don't interact with the Scene lighting. They can support locally simulated lighting effects instead. The surface shader versions do interact with the Scene lighting. They use Unity's surface shader framework and are quite flexible, but also more demanding on the GPU. They are not physically based shaders. SDF shaders can use the distance data to generate special effects, like outlines, underlays, and bevels. These effects often increase the visual size of the text. When taken to their extremes, you might see artifacts appear around the edges of character sprites. If this happens, scale down the effects. For example, a soft dilated underlay with large offsets might take things too far. The artifacts occur because data from adjacent characters in the font atlas will bleed into the current character. You can increase the padding when importing a font to give the effects more space. NEW FILE: ShadersDistanceField.md Distance Field / Distance Field Overlay Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Lighting: Simulates local directional lighting on the text. Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed X/Y Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Lighting The Distance Field shader does not react to Scene lighting. Instead, it uses the settings in this group to simulate local directional lighting, and light effects. If you want your text to react to Scene lighting, use the Distance Field Surface shader. The Lighting properties are grouped into the following sections Bevel: Local Lighting: Bump Map: Environment Map: Bevel A bevel adds the illusion of depth to your text. It works like a normal map, except that the shader calculates the bevel using the font’s signed distance field. Bevels are prone to showing artifacts, especially when they are too pronounced. These artifacts are more obvious on some materials than on others. Sometimes, artifacts that are more obvious on a simple material are hardly noticeable on a more complex material. Although bevels work best with text that has an outline, you can apply them to text with no outline. In that case, you must set a positive Width, and should set a negative Offset to ensure that the whole bevel is visible. Property: Description Type Choose the type of bevel to apply Outer Bevel Produces raised lettering with sloped sides. The bevel starts at the outside of the outline and increases in height until it reaches the inside of the outline. Inner Bevel Produces text with a raised outline. The bevel starts at the outside of the outline, increases in height until it reaches the middle of the outline, and decreases in height until it reaches the inside of the outline. Amount Adjust the steepness of the bevel. This setting defines the apparent difference in height between low and high regions of the bevel. Offset Offset the bevel from its usual position so it no longer matches the outline. Different offsets produce very different bevels. This is especially useful when you apply a bevel to text with no outline. Width Adjust the bevel size. Set a value of 0 to make the bevel fill the full thickness of the outline. Set a positive value to make the bevel extend beyond both sides of the outline. Set a negative value to shrink the bevel toward the middle of the outline. Roundness Increase this value to smooth out more angular regions of the bevel. The effect is often quite subtle. Clamp Set this value to limit the maximum height of the bevel. Higher values mean the bevel reaches its maximum height sooner. Clamped outer bevels end before reaching the inside edge of the outline. Clamped inner bevels have a larger flat region in the middle of the outline. Local Lighting These settings control simulated local directional lighting. They work in combination with the Bevel, Bump Map, and Environment Map settings. Property: Description Light Angle Adjust the angle, in radians, of the simulated local light illuminating the text. The default angle is approximately π (pi) radians, which positions the light above the text. Specular Color Set the tint for specular highlights. These are the highlights you see when the text directly reflects the simulated local light source. Specular Power Adjust the appearance of specular highlights. Larger values produce larger and brighter highlights. Reflectivity Power Adjust the how much the Environment Map contributes to the final color of the text. The higher the value, the more the text appears to reflect the environment map texture and color. Diffuse Shadow Adjust the overall shadow level. Higher values produce stronger shadowing, and consequently fewer apparent light effects on the text. Ambient Shadow Adjust the ambient light level. Settings lower than 1 darken the text color based on the slope of the text. This is a subtle effect that is only noticeable with strong bevels or normal maps. Bump Map You can use a normal map as a bump map to add bumpiness to the text. The bump map affects both the text face and outline, but you can control how strongly it affects each one individually. If your text has both a bevel and a bump map, the two mix together. Property: Description Texture Select a normal map texture to use as a bump map. Face Control how much the bump map affects the text face. A value of 0 shows no effect while a value of 1 shows the full effect of the bump map. Outline Control how much the bump map affects the text outline. A value of 0 shows nothing while a value of 1 shows the full effect of the bump map. Environment Map You can use an environment map to add a reflection effect to your text face or outline, or for special image effects. The environment texture must be a cubemap. You can provide a static cubemap or create one at run time via a script. Property: Description Face Color Choose a color to use to tint reflections on the text face. This color is multiplied with the environment map before the reflectivity effect is applied to the text face. When this color is set to black, the environment map has no effect on the text face. When this color is set to white, the environment map is at full strength on the text face. Outline Color Choose a color to use to tint reflections on the text outline. This color is multiplied with the environment map before the reflectivity effect is applied to the text outline. When this color is set to black, the environment map has no effect on the text outline. When this color is set to white, the environment map is at full strength on the text outline. Texture Choose a cubemap texture to use as an environment map. Rotation Rotate the environment map to control which parts of the texture are visible in the reflection. You can animate the rotation to create a sense of movement. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Mask Mask Off Mask Hard Mask Soft Mask Bounds Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Match Bounds Renderer Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. NEW FILE: ShadersDistanceField.md Distance Field / Distance Field Overlay Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Lighting: Simulates local directional lighting on the text. Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed X/Y Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Lighting The Distance Field shader does not react to Scene lighting. Instead, it uses the settings in this group to simulate local directional lighting, and light effects. If you want your text to react to Scene lighting, use the Distance Field Surface shader. The Lighting properties are grouped into the following sections Bevel: Local Lighting: Bump Map: Environment Map: Bevel A bevel adds the illusion of depth to your text. It works like a normal map, except that the shader calculates the bevel using the font’s signed distance field. Bevels are prone to showing artifacts, especially when they are too pronounced. These artifacts are more obvious on some materials than on others. Sometimes, artifacts that are more obvious on a simple material are hardly noticeable on a more complex material. Although bevels work best with text that has an outline, you can apply them to text with no outline. In that case, you must set a positive Width, and should set a negative Offset to ensure that the whole bevel is visible. Property: Description Type Choose the type of bevel to apply Outer Bevel Produces raised lettering with sloped sides. The bevel starts at the outside of the outline and increases in height until it reaches the inside of the outline. Inner Bevel Produces text with a raised outline. The bevel starts at the outside of the outline, increases in height until it reaches the middle of the outline, and decreases in height until it reaches the inside of the outline. Amount Adjust the steepness of the bevel. This setting defines the apparent difference in height between low and high regions of the bevel. Offset Offset the bevel from its usual position so it no longer matches the outline. Different offsets produce very different bevels. This is especially useful when you apply a bevel to text with no outline. Width Adjust the bevel size. Set a value of 0 to make the bevel fill the full thickness of the outline. Set a positive value to make the bevel extend beyond both sides of the outline. Set a negative value to shrink the bevel toward the middle of the outline. Roundness Increase this value to smooth out more angular regions of the bevel. The effect is often quite subtle. Clamp Set this value to limit the maximum height of the bevel. Higher values mean the bevel reaches its maximum height sooner. Clamped outer bevels end before reaching the inside edge of the outline. Clamped inner bevels have a larger flat region in the middle of the outline. Local Lighting These settings control simulated local directional lighting. They work in combination with the Bevel, Bump Map, and Environment Map settings. Property: Description Light Angle Adjust the angle, in radians, of the simulated local light illuminating the text. The default angle is approximately π (pi) radians, which positions the light above the text. Specular Color Set the tint for specular highlights. These are the highlights you see when the text directly reflects the simulated local light source. Specular Power Adjust the appearance of specular highlights. Larger values produce larger and brighter highlights. Reflectivity Power Adjust the how much the Environment Map contributes to the final color of the text. The higher the value, the more the text appears to reflect the environment map texture and color. Diffuse Shadow Adjust the overall shadow level. Higher values produce stronger shadowing, and consequently fewer apparent light effects on the text. Ambient Shadow Adjust the ambient light level. Settings lower than 1 darken the text color based on the slope of the text. This is a subtle effect that is only noticeable with strong bevels or normal maps. Bump Map You can use a normal map as a bump map to add bumpiness to the text. The bump map affects both the text face and outline, but you can control how strongly it affects each one individually. If your text has both a bevel and a bump map, the two mix together. Property: Description Texture Select a normal map texture to use as a bump map. Face Control how much the bump map affects the text face. A value of 0 shows no effect while a value of 1 shows the full effect of the bump map. Outline Control how much the bump map affects the text outline. A value of 0 shows nothing while a value of 1 shows the full effect of the bump map. Environment Map You can use an environment map to add a reflection effect to your text face or outline, or for special image effects. The environment texture must be a cubemap. You can provide a static cubemap or create one at run time via a script. Property: Description Face Color Choose a color to use to tint reflections on the text face. This color is multiplied with the environment map before the reflectivity effect is applied to the text face. When this color is set to black, the environment map has no effect on the text face. When this color is set to white, the environment map is at full strength on the text face. Outline Color Choose a color to use to tint reflections on the text outline. This color is multiplied with the environment map before the reflectivity effect is applied to the text outline. When this color is set to black, the environment map has no effect on the text outline. When this color is set to white, the environment map is at full strength on the text outline. Texture Choose a cubemap texture to use as an environment map. Rotation Rotate the environment map to control which parts of the texture are visible in the reflection. You can animate the rotation to create a sense of movement. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Mask Mask Off Mask Hard Mask Soft Mask Bounds Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Match Bounds Renderer Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. NEW FILE: ShadersDistanceFieldSurface.md Distance Field (Surface) Shader The Distance Field (Surface) surface shader is similar to the Distance Field shader, but rather than simulating local directional lighting, it interacts with Scene lighting. It is not a physically based shader. This shader uses Unity's surface shader framework, which makes it quite flexible, but also more demanding on the GPU. Properties Face: Controls the appearance of the text face. Outline: Controls the appearance of the text outline. Bevel: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. SurfaceLighting: Controls the appearance of locally simulated lighting on the text. Bump Map: Adds bumpiness to the text face and/or outline using a normal map texture. Environment Map: Adds a reflection effect to the text face and/or outline using a normal map texture Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face You edit Distance Field Surface shader properties in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Gloss Adjust the glossiness of the text face. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specular highlights. Outline Description Property: Description Color Adjust the color for the text outline. Tthe outline is not visible unless you set a Thickness value greater than 0. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Gloss Adjust the glossiness of the text outline. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specualr highlights. Bevel A bevel adds the illusion of depth to your text. It works like a normal map, except that the shader calculates the bevel sing the font’s signed distance field. Bevels are prone to showing artifacts, especially when they are too pronounced. These artifacts are more or less obvious, depending on the material you use. Sometimes, artifacts that are more obvious on a simple material are hardly noticeable on a more complex material. Although bevels work best with text that has an outline, you can apply them to text without an outline as well. Property: Description Type Choose the type of bevel to apply Outer Bevel Produces raised lettering with sloped sides. The bevel starts at the outside of the outline and increases in height until it reaches the inside of the outline. Inner Bevel Produces text with a raised outline. The bevel starts at the outside of the outline, increases in height until it reaches the middle of the outline, and decreases in height until it reaches the inside of the outline. Amount Adjust the steepness of the bevel. This setting defines the apparent difference in height between low and high regions of the bevel. Offset Offset the bevel from its usual position so it no longer matches the outline. Different offsets produce very different bevels. This is especially useful when you apply a bevel to text with no outline. Width Adjust the bevel size. Set a value of 0 to make the bevel fill the full thickness of the outline. Set a positive value to make the bevel extend beyond both sides of the outline. Set a negative value to shrink the bevel toward the middle of the outline. If you are setting a bevel for text with no outline, you must set a positive Width. You should also set a negative Offset to ensure that the whole bevel is visible. Roundness Increase this value to smooth out more angular regions of the bevel. The effect is often quite subtle. Clamp Set this value to limit the maximum height of the bevel. Higher values mean the bevel reaches its maximum height sooner. Clamped outer bevels end before reaching the inside edge of the outline. Clamped inner bevels have a larger flat region in the middle of the outline. Surface Lighting These settings control simulated local directional lighting. They work in combination with the Bevel, Bump Map, and Environment Map settings. Property: Description Specular Color Set the tint for specular highlights. These are the highlights you see when the text directly reflects the simulated local light source. Bump Map You can use a normal map as a bump map to add bumpiness to the text. The bump map affects both the text face and outline, but you can control how strongly it affects each one individually. If your text has both a bevel and a bump map, the two mix together. Property: Description Texture Select a normal map texture to use as a bump map. Face Control how much the bump map affects the text face. A value of 0 shows no effect while a value of 1 shows the full effect of the bump map. Outline Control how much the bump map affects the text outline. A value of 0 shows nothing while a value of 1 shows the full effect of the bump map. Environment Map An environment map can be used to add a reflection effect to your text face or outline. You can either use it for reflections of a static Scene or for special image effects. The mobile shaders do not support this.The environment texture is a cubemap. You can either provide a static cubemap or create one at run time via a script. Property: Description Face Color Choose a color to use to tint reflections on the text face. This color is multiplied with the environment map before the reflectivity effect is applied to the text face. When this color is set to black, the environment map has no effect on the text face. When this color is set to white, the environment map is at full strength on the text face. Outline Color Choose a color to use to tint reflections on the text outline. This color is multiplied with the environment map before the reflectivity effect is applied to the text outline. When this color is set to black, the environment map has no effect on the text outline. When this color is set to white, the environment map is at full strength on the text outline. Texture Choose a cubemap texture to use as an environment map. Rotation Rotate the environment map to control which parts of the texture are visible in the reflection. You can animate the rotation to create a sense of movement. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. NEW FILE: ShadersDistanceFieldMobile.md Distance Field / Distance Field Overlay Mobile Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. NEW FILE: ShadersDistanceFieldMaskingMobile.md Distance Field Masking Mobile Shader The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Debug Settings The debug section contains options for defining and controlling masking. It also exposes some of the shader’s internal properties, which can be helpful for troubleshooting. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Mask Texture Choose a texture file to use as a mask. Black and white images work best. By default, black regions of the image mask the text, while white areas reveal it. Inverse Mask Invert the mask so that white regions of the image mask the text, while black areas reveal it. Edge Color Tint the edge of the mask with a specific color. The softer the edge, the larger the tinted region. Edge Softness Make the edges of the mask softer or harder. A value of 0.5 applies the mask as-is. Higher values soften the edges. Lower values make them sharper. Wipe Position Control the extent to which the text is masked. A value of 0.5 masks the text exactly as defined by the Mask Texture. A value of 0 fully exposes the text (no masking at all). A value of 1 hides the text (all of the text is masked). Softness X/Softness Y Apply soft masking to the text in either axis. Increase the X value to add soft masking to the left and right sides of the text. Increase the Y value to add soft masking at the top and bottom. This masking is added to any masking defined by the Mask Texture. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. NEW FILE: ShadersDistanceFieldMobile.md Distance Field / Distance Field Overlay Mobile Shaders The Distance Field and Distance Field Overlay shaders are two nearly-identical variants of the TextMesh Pro signed distance field (SDF)shader. The difference between the two is that the Distance Field Overlay variant always renders the TextMesh Pro object on top of everything else in the Scene, while the Distance Field variant renders the Scene normally—objects in front of the TextMesh Pro object are rendered on top of the text. Both of these variants are unlit, meaning they do not interact with Scene lighting. Instead, they can simulate local directional lighting effects. Properties The Distance Field and Distance Field Overlay shaders have identical properties, which you can edit in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Face: Controls the text's overall appearance. Outline: Adds a colored and/or textured outline to the text. Underlay: Adds a second rendering of the text underneath the original rendering, for example to add a drop shadow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face The Face properties control the overall appearance of the text. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Outline The outline properties allow you to add an outline to the text and control its appearance. The outline is not visible unless you set a Thickness value greater than 0. Property: Description Color Adjust the color for the text outline. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Underlay Underlay adds an additional rendering of the text underneath the original rendering. You can use it to add a drop-shadow effect. Property: Description Underlay Type Choose the type of underlay to render. None No underlay. Normal Renders the underlay underneath the original text. This creates a standard drop-shadow style effect. Inner Inverts the underlay and masks it with the original text so it is only visible inside the outline of the original letters. This creates the type of drop shadow you would see through a cutout of the text. To see an Inner underlay, you must make the text face transparent by setting its Alpha to 0. Color Set the color of the underlay text. The default is a semi-transparent black. Offset X/Offset Y Offset the underlay text horizontally and vertically from the original text. For example, if you’re using the underlay to create a drop shadow, you can position it to suggest a specific lighting direction. Dilate Adjust the position of the underlay text contour in the font's distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Softness Adjust the softness of the underlay text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. When using the underlay to create a drop-shadow, you can use this setting to make the shadows harder or softer. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. NEW FILE: ShadersDistanceFieldSurfaceMobile.md Distance Field (Surface) Mobile Shader The Distance Field (Surface) surface shader is similar to the Distance Field shader, but rather than simulating local directional lighting, it interacts with Scene lighting. It is not a physically based shader. This shader uses Unity's surface shader framework, which makes it quite flexible, but also more demanding on the GPU. Properties Face: Controls the appearance of the text face. Outline: Controls the appearance of the text outline. Glow: Adds a smooth outline to the text in order to simulate glow. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face You edit Distance Field Surface shader properties in the TextMesh Pro object Inspector. Properties are divided into several sections, some of which you must enable in order to activate the property group. Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Speed Animate the face texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Softness Adjust the softness of the text edges. A value of 0 produces crisp, anti-aliased edges. Values greater than 0 produce increasingly soft/blurry edges. This setting applies to both the text face and the outline. Dilate Adjust the position of the text contour in the font distance field. A value of 0 places the contour halfway, which corresponds to the contour of the original font. Negative values thin the characters, while positive values thicken them. Gloss Adjust the glossiness of the text face. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specular highlights. Outline Description Property: Description Color Adjust the color for the text outline. Tthe outline is not visible unless you set a Thickness value greater than 0. Texture Apply a texture to the text outline. The texture is multiplied with the outline Color to produce the final outline color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text outline. Tiling Offset Speed Animate the outline texture by setting a value greater than 0. The resulting animation is a scrolling effect as the texture’s UV coordinates change over time. Note: To see this effect in the Scene view, you must enable Animated Materials from the Effects menu in the Scene view control bar. Thickness Adjust the thickness of the outline. The higher the value, the thicker the line. The outline is drawn on the text contour, with half its thickness inside the contour and half of it outside the contour. You can pull it farther in or push it farther out by adjusting the Face > Dilate property. Gloss Adjust the glossiness of the text outline. Glossiness determines the appearance of specular highlights when light hits the text. Higher values produce smaller specualr highlights. Glow The Glow effect adds a smooth outline on top of other text effects, which is typically used to suggest a glow. The effect is additive, so it is more noticeable on dark backgrounds. When the glow extends beyond the text boundary, the surface shader shades it as if it were part of the solid text, meaning that it gets simulated lighting effects such as specular highlights. Property: Description Color Set the tint and strength of the glow effect by adjusting the Color and Alpha values respectively. Offset Adjust the center of the glow effect. A value of 0 places the center of the glow effect right on the text contour. Positive values move the center out from the contour. Negative values move it in toward the center of the text. Inner Control how far the glow effect extends inward from the its start point (text contour + Offset). Outer Control how far the glow effect extends outward from the text contour (text contour + Offset). Power Control how the glow effect falls off from its center to its edges. A value of 1 produces a strong, bright glow effect with a sharp linear falloff. Lower values produce a glow effect with a quick drop in intensity followed by a more gradual falloff. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Gradient Scale Represents the spread / range of the font’s signed distance field. This determines the effective range of material properties such as Outline > Width and Underlay > Offset X/Y. This value is equal to Padding +1, with Padding being the Padding value set when the font Asset was created. Note: This value is displayed for debugging purposes. You should not edit it manually. Texture Width/Texture Height Displays the texture atlas width and height specified in the Atlas Resolution settings when the font Asset was created. Scale X/Scale X Set multipliers for the SDF scale. When set to 0, characters are rendered as blocks. Negative values soften the characters, while positive values make them appear sharper. Perspective Filter When using a perspective camera, adjust this setting to make text look softer when viewed at sharp angles. The default setting of 0.875 is adequate in most cases. When using orthographic cameras, set this to 0. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. NEW FILE: ShadersBitmap.md Bitmap Shader The Bitmap shader is designed to use bitmap-only fonts. It treats the font atlas like a regular texture, displaying it directly, and does not support any text effects. Bitmap-textured text becomes blocky when you zoom in on it. Properties Face: Controls the text's overall appearance. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face Description Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. Stencil ID Stencil Comp NEW FILE: ShadersBitmapCustomAtlas.md Bitmap Custom Atlas Shader The Bitmap shader is designed to use bitmap-only fonts. It treats the font atlas like a regular texture, displaying it directly, and does not support any text effects. Bitmap-textured text becomes blocky when you zoom in on it. Properties Face: Controls the text's overall appearance. Debug Settings: Exposes internal shader properties that are sometimes useful for troubleshooting. Face Description Property: Description Color Adjust the face color of the text. The value you set here is multiplied with the vertex Colors you set in the TextMeshPro component. Set this to white to use the original vertex colors. Set this to black to cancel out the vertex colors. Similarly, setting the Alpha to 1 uses the original vertex-color alpha, while setting it to 0 removes any alpha set in the original vertex colors. Texture Apply a texture to the text face. The texture is multiplied with the face Color and the vertex colors in the TextMesh Pro component to produce the final face color. The Horizontal Mapping and Vertical Mapping properties in the TextMesh Pro component determine how TextMesh Pro fits the texture to the text face. Tiling X/Y Increase these values to repeat the texture across the text surface, in accordance with the TextMesh Pro object's Horizontal Mapping and Vertical Mapping properties. Offset X/Y Adjust these values to change the texture's relative position, horizontally or vertically, on the text surface. Debug Settings The debug section exposes some of the shader’s internal properties. They can be helpful for troubleshooting problems you encounter with the shader. Property: Description Font Atlas Points to the atlas texture used by the font Asset. Padding Offset X/Offset Y Offset the vertex positions of each character in X and Y. You can change these values using a script to create simulated crawl or scrolling FX. Softness X/Softness Y When Mask is set to Soft, set these to adjust the softness of the edge of the text. Clip Rect Clip Rect defines the Left (L), Bottom (B), Right (R) and Top (T) world space coordinates of the masking rectangle. This is normally set automatically by the 2D RectMask. However when using a normal TextMeshPro component, this allows you to set / control the masking region. Stencil ID Stencil Comp NEW FILE: Shaders.md Shaders TextMesh Pro has been designed to take advantage of signed distance field (SDF) rendering and includes a collection of shaders for this purpose. There are also bitmap-only shaders, in case you don't want to use SDF rendering. All shaders have a desktop and a mobile version. The mobile versions are less demanding and suitable for mobile devices, but support fewer effects. All shaders can be found in the shader menu under TextMeshPro and TextMeshPro / Mobile. SDF Shaders There are three variants of the SDF shader, known as Distance Field, Distance Field (Surface), and Distance Field Overlay. The regular and overlay shaders are unlit, so they don't interact with the Scene lighting. They can support locally simulated lighting effects instead. The surface shader versions do interact with the Scene lighting. They use Unity's surface shader framework and are quite flexible, but also more demanding on the GPU. They are not physically based shaders. SDF shaders can use the distance data to generate special effects, like outlines, underlays, and bevels. These effects often increase the visual size of the text. When taken to their extremes, you might see artifacts appear around the edges of character sprites. If this happens, scale down the effects. For example, a soft dilated underlay with large offsets might take things too far. The artifacts occur because data from adjacent characters in the font atlas will bleed into the current character. You can increase the padding when importing a font to give the effects more space. Bitmap Shaders NEW FILE: ShadersSprite.md Sprite Shader Properties Property: Function: Sprite Texture Tiling X/Y Offset X/Y Tint Stencil Comparison Stencil ID Stencil Operation Stencil Write Mask Stencil Read Mask Color Mask Clip Rect Use Alpha Clip Render Queue From Shader Geometry Alpha Test Transparent Double Sided Global Illumination NEW FILE: Settings.md Settings TextMesh Pro’s project-wide settings are stored in a special Asset named TMP Settings. This Asset must be stored in a Resources folder. By default it’s in the Assets/TextMesh Pro folder. To edit the settings, either select the Asset in the Project View or open the Project Settings window and choose TextMesh Pro from the category list. TextMesh Pro Settings The Settings are divided into the following groups: Group: Function: A Default Font Asset: Set the default font for text objects. B Fallback Font Assets: Choose font assets to search when TexMesh Pro can’t find a character in a text object’s main font Asset. C Fallback Material Settings: Set style options for characters retrieved from fallback fonts. D Dynamic Font System Settings: Set options for handling missing characters. E Text Container Default Settings: Control the size of the text container for new text objects. F Text Component Default Settings: Set the basic text formatting options for new text objects. G Default Sprite Asset: Choose a default Sprite Asset to use for for rich text sprite tags that do not specify an Asset, and set other sprite-related options. H Default Style Sheet: Choose a default style sheet. I Color Gradient Presets: Choose a location to store color gradient presets. J Line Breaking for Asian Languages: Define leading and following characters in order to get proper line breaking when using Asian fonts. Default Font Asset Property: Function: Default Font Asset Specify the default font used when you create a new text object. Path Specify where to store font assets. The Path must point to a subfolder of a Resources folder. Fallback Font Assets When a text object contains a character that is not in its font Asset, TextMesh Pro searches these font assets for the glyph. If the object’s font assets has a local fallback font list, TextMesh Pro searches the fonts in that list first. Property: Function: Fallback Font Assets List Manage the global fallback font assets. Click + and - to add and remove font slots. Click the circle icon next to a font to choose a font Asset using the Object Picker. Drag the handles on the left side of any font Asset to reorder the list. Fallback Material Settings Property: Function: Match Material Presets Enable this setting to make glyphs from the fallback font match the style of the main font. When TextMesh Pro uses a glyph from a fallback font, it creates a material with the same settings as the main font’s material. This looks best when the main font and the fallback font are similar. Dynamic Font System Settings These are project-wide settings for handling missing glyphs. Property: Function: Get Font Features at Runtime Replacement Specify the ID of the character to use when TextMesh Pro cannot find a missing glyph in any of the fallback fonts. The default value of 0 produces the outline of a square. Disable Warnings Enable this setting to prevent Unity from logging a warning for every missing glyph. Text Container Default Settings These settings define the default size for text containers in new text objects. Property: Function: TextMeshPro Set the default size of text containers for new TextMesh Pro 3D GameObjects, in Unity units. TextMeshPro UI Set the default size of text containers for new TextMesh Pro UI GameObjects, in Unity units. Enable Raycast Target Enable this option to make TextMesh Pro GameObjects targets for raycasting by default. When you disable this option, the UI ignores TextMesh Pro GameObjects by default when determining what the cursor interacts with. Auto Size Text Container Enable this option to automatically size text containers to fit the text when creating new TextMesh Pro UI GameObjects. Text Component Default Settings These settings define default values for new text objects. After adding a text object to the Scene, you can adjust these settings in the object's TextMesh Pro Inspector. Property: Function: Default Font Size Set the default font size, in points. Text Auto Size Ratios Set the default Min to Max size ratio TextMesh Pro uses when it sets font size automatically. Word Wrapping Enable this option to turn word wrapping on for all new text objects. Kerning Enable this option to toggle kerning on for all new text objects. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the results aren't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites. Tint All Sprites By default, sprites aren't affected by the text's vertex colors. Enable Tint All Sprites changes this. Parse Escape Sequence Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Default Sprite Asset Property: Function: Default Sprite Asset Choose the Sprite Asset for TextMesh Pro GameObjects to use by default. IOS Emoji Support Toggle support for iOS emoji. Path Specify where to store Sprite Assets. The Path must point to a subfolder of a Resources folder. Default Style Sheet Property: Function: Default Style Sheet You can choose a single style sheet Asset, which is used by all text objects in the project. Color Gradient Presets Property: Function: Path Line Breaking for Asian Languages To obtain correct line-breaking behavior for Asian languages, you must specify which characters behave as leading and following characters. This is done via two text assets. Property: Function: Leading Characters Specify the text file that contains the list of leading characters. Following Characters Specify the text file that contains the list of following characters."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-rich-text-tags.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-rich-text-tags.html",
    "title": "| Inventory System",
    "summary": "Tag: Description: Notes: <align> Changes the text's horizontal alignment. <allcaps> Converts text to uppercase before rendering. Functionally identical to <uppercase>. <alpha> Changes text opacity. <b> Renders text in boldface. <br> Forces a line break in text. <color> Changes text color or color and opacity. <cspace> Changes spacing between characters. <font> Changes text font and, optionally, material. <font-weight> Changes the text's font weight to any of the weights defined in the font Asset. <gradient> Applies a gradient preset to text. <i> Renders text in italics. <indent> Indents all text between the tag and the next hard line break. <line-height> Modifies the line height relative to the default line height specified in the font Asset. <line-indent> Indents the first line after every hard line break. New lines created by word-wrapping are not indented. <link> Specifies a link ID for a text segment. <lowercase> Converts text to lowercase before rendering. <margin> Gives the text horizontal margins. You can set margins for both sides together or each side individually <mark> Highlights the text with a colored overlay. The overlay must be translucent (alpha less than 1) for the text to show through. <mspace> Renders the text as monospace. <nobr> Keeps a segment of text together. <noparse> Prevents parsing of text that TextMesh Pro would normally interpret as rich text tags. <page> Adds a page break to the text. The text's Overflow mode must be set to Page for page breaks to work. <pos> Sets the horizontal caret position on the current line. <rotate> Rotates each character about its center. <s> Renders a line across the text. <size> Adjusts the font size for a specified portion of the text. <smallcaps> Converts text to uppercase before rendering. <space> Adds a horizontal offset between itself and the rest of the text. <sprite> Adds a sprite to the text. By default, TextMesh Pro looks in the default sprite assets, but you can use tag attributes to retrieve sprites from other assets. <strikethrough> Draws a line slightly above the baseline so it crosses out the text. <style> Applies a custom style to the text. <sub> Converts the text to subscript. <sup> Converts the test to superscript. <u> Draws a line slightly below the baseline to underline the text. <uppercase> Converts text to uppercase before rendering. Functionally identical to <allcaps>. <voffset> Gives the baseline a vertical offset. <width> Changes the horizontal size of text area."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-alignment.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-alignment.html",
    "title": "| Inventory System",
    "summary": "Alignment The horizontal and vertical alignment options control how text is placed in the display area. Property: Function: [Horizontal Alignment Options] Left, Center, Right Position the text horizontally in the display area, without changing the text itself. Justified, Flush Stretch the text to fill the width of the display area by increasing the distance between words and characters. The Wrap Mix option controls the balance between word and character spacing. Justified mode does not stretch the last lines of paragraphs, while Flush mode does. Geometry Center Centers the text based on the mesh rather than the text metrics. The difference is not always noticeable, but in some cases this mode yields better looking results than regular Center alignment. [Vertical Alignment Options] Top, Middle, Bottom Position the text vertically in the display area, without changing the text itself. Baseline Position the text so the baseline of the line is aligned with the middle of the display area. This is useful when working with a single line of text. Midline Use this as an alternative to Middle alignnment. This option determine vertical placement using the bounds of the text mesh, rather than line metrics. This is useful in tight spaces when ascenders and descenders might otherwise extend too far. Capline Position the text so the middle of the first the line is aligned with the middle of the display area. Wrap Mix (W <-> C) Adjust the balance between extra word spacing and extra character spacing when horizontal alignment is set to Justified or Flush."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-color.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-color.html",
    "title": "| Inventory System",
    "summary": "Color TextMesh Pro uses vertex colors to tint the text. You can apply a uniform color as well a gradient of up to four colors. Property: Function: Vertex Color Choose the main color for the text. Any colors and textures defined in the TextMesh Pro GameObject or its material ar multiplied with this color. Color Gradient Enable this option to apply a color gradient to each character sprite. You can then set the gradient’s type and colors, or apply a color gradient preset. Gradient colors are multiplied with the Vertex Color. If Vertex Color is set to white you see only the gradient colors. If it’s set to black you don’t see the gradient colors at all. Color Preset Choose a color gradient preset. When you apply a preset its Color Mode and Colors replace the text's local properties in the Inspector. Editing these properties modifies the preset, which affects every TextMesh Pro GameObject that uses it. Set this property to None to revert to the text’s local gradient properties. Color Mode Choose the type of color gradient to apply. TextMesh Pro applies gradients to each character individually. Single A uniform color that modifies the base Vertex Color. Horizontal Gradient A two-color gradient with each color emanating from one side of the character. Vertical Gradient A two-color gradient with one color emanating from the top of the character, and the other from the bottom. Four Corners Gradient A four-color gradient with each color emanating from a different corner of the character. Colors Choose each gradient color. The number of available colors depends on the type of gradient, and the color fields are arranged to match the position of each color in the gradient (left and right, top and bottom, 2 rows of 2 for four-corner gradients). You can set the color in any of the following ways: Swatch: Click to open a color picker. Eyedropper: Click to choose a color from any part of the screen. Hex Value: Enter the RGBA hex value directly. Override Tags Enable this option to ignore any rich text tags that change text color."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-extra-settings-3d.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-extra-settings-3d.html",
    "title": "| Inventory System",
    "summary": "Extra Settings This section contains assorted options for further controlling the appearance and behavior of text. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. Set negative values to make the text extend beyond the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Sorting Layer Order in Layer Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Othographic Mode Enable this option when creating camera-aligned text with an orthographic camera. It prevents the TextMesh Pro shader from using perspective correction. Rich Text Enable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as plain text. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the results isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-extra-settings-ui.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-extra-settings-ui.html",
    "title": "| Inventory System",
    "summary": "Extra Settings This section contains options for further controlling how text looks and behaves. Property: Function: Margins Set positive values to increase the distance between the text and the boundaries of the text container. You set the Left, Top, Right, and Bottom margins separately. Negative values make the text extend beyond the boundaries of the text container. You can also adjust the margins by dragging the handles of the text container Widget (yellow rectangle) in the Scene view. Geometry Sorting Each character is contained in a quad. Geometry Sorting controls how TextMesh Pro sorts these quads. This determines which character appears on top when two quads overlap. Normal TextMesh Pro draws quads in the order that they appear in the mesh. When two quads overlap, the \"later\" quad appears on top of the \"earlier\" one. Reverse TextMesh Pro draws quads in reverse order. When two quads overlap, the \"earlier\" quad appears on top of the \"later\" one. Rich Text Disable this option to turn off rich text support for the TextMesh Pro GameObject. When rich text support is disabled, tags are not parsed and are rendered as regular text. Raycast Target Enable this option to make this TextMesh Pro GameObject a raycast target. Disabling this option causes the UI to ignores this TextMesh Pro GameObject when determining what the cursor interacts with. Parse Escape Characters Enable this option to make TextMesh Pro interpret backslash-escaped characters as special characters. For example \\n is interpreted as a newline, \\t as a tab, and so on. Note: This applies to rendered text. In code, escaped characters are already parsed by the compiler. Visible Descender Use this option when using a script to slowly reveal text. Enable it to reveal the text at the bottom and move up as new lines are revealed. Disable it to reveal the text from top to bottom. To set up this type of text reveal, you must also set the vertical alignment to Bottom. Sprite Asset Kerning Enable this option to toggle kerning on for this TextMesh Pro GameObject. Kerning is defined in the GameObject's Font Asset. If new objects use a font with no kerning data, enabling this setting has no effect. Extra Padding Enable this option to add extra padding to character sprites. TextMesh Pro creates sprites to fit the visible text, but the result isn't always perfect. This setting reduces the chances that glyphs are cut off at the boundaries of their sprites."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-font.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-font.html",
    "title": "| Inventory System",
    "summary": "Font The fonts settings panel is where you choose a font for your text, and customize the font style. Property: Function: Font Asset Choose a font Asset for the TextMesh Pro GameObject to use. TextMesh Pro ships with several font assets, and you can create others from standard font files such as truetype (ttf) fonts. Note: You can set the default font Asset for new text objects in the TextMesh Pro settings. Material Preset Choose a material for your font. Each font Asset has a default material, but you can also create customized materials for it. This preset list includes all materials whose names contain the font Asset's name, and use the corresponding font atlas texture. Font Style Enable standard text styling options. You can use these options in any combination, except for the casing options (lowercase, uppercase, and small caps), which are mutually exclusive. B Bold the text. The appearance of bold text is defined in the font Asset properties. I Italicize the text. The appearance of italicized text is defined in the font Asset properties. U Underline the text. This renders an extra line below the baseline. S Add a strikethrough line to the text. This renders an extra line above the baseline. ab Convert the text to lowercase before rendering. This does not change text casing in the Text field. AB Convert the text to uppercase before rendering. This does not change text casing in the Text field. SC Use small caps. The text is displayed in all uppercase, but letters you actually entered in uppercase are larger. Font Size Specify the text display size, in points. Auto Size Enable this option to set the font size automatically, based on the Auto Size Options. When this option is enabled, TextMesh Pro lays out the text multiple times to find a good fit. This is a resource intensive process, so avoid auto-sizing dynamic text that changes frequently. Tip: For static text, you can enable Auto Size, note the calculated font size (displayed in the Font Size field), then disable Auto Size and apply the calculated size manually. Auto Size Options Define the basic rules for auto-sizing text. Min Specify the smallest acceptable font size, in points. Max Specify the largest acceptable font size, in points. WD% Specify the maximum acceptable amount to reduce character width when sizing the text. TextMesh Pro squeezes characters to make them taller. This is usually only acceptable for digits. Line Adjust the line height. This is useful for fitting a larger font into a given space."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-legend.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-legend.html",
    "title": "| Inventory System",
    "summary": "Text input A Text: Where you enter the text to display, along with any rich text markup. Main settings B Font: Specifies the font to use, as well as basic font attributes (size, style, and so on). C Color: Defines the base color or color gradient for the text D Spacing: Controls spacing between characters, words, lines and, paragraphs. E Alignment: Controls horizontal and vertical text alignment. F Wrapping and Overflow: Controls word wrapping and defines what happens when text doesn't fit inside its display area. G UV Mapping: Controls how textures are mapped to the face and outline of the text. H Extra Settings: Additional options for controlling the appearance and behavior of text."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-main-settings.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-main-settings.html",
    "title": "| Inventory System",
    "summary": "Main Settings The Main Settings section contains the properties needed to define the basic appearance of text. You can further customize the look of text by changing or editing its material."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-spacing.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-spacing.html",
    "title": "| Inventory System",
    "summary": "Spacing These options control spacing between characters, words, lines and, paragraphs. You can use them to fine-tune the text for individual TextMesh Pro GameObjects, without adjusting their font assets. To control spacing within a single TextMesh Pro GameObject, use rich text tags. Property: Function: Character Set the spacing between characters for this TextMesh Pro GameObject. Word Set the spacing between words for this TextMesh Pro GameObject. Line Set the spacing between lines for this TextMesh Pro GameObject. Paragraph Set the spacing between paragraphs for this TextMesh Pro GameObject. Paragraphs are defined by explicit line breaks."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-text.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-text.html",
    "title": "| Inventory System",
    "summary": "Text Input The text section is where you enter the text to display, and optionally customize it using rich text markup. Property: Function: Text The input field for text to display. Enable RTL Editor Enable this option to display text right-to-left instead of left-to-right. The Inspector displays an additional input field where you can view the reversed text and edit it directly. The text is reversed before it is displayed on screen or rendered."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-uv-mapping.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-uv-mapping.html",
    "title": "| Inventory System",
    "summary": "UV Mapping Some TextMesh Pro shaders allow you to apply one or more image textures to text. These options control how those textures stretch to fit the text. You can also edit shader-specific texturing options in the shaders themselves. The available options depend on the shader you use. When texturing text, make sure that your texture assets have their Wrap Mode set to Repeat. Otherwise the texture is likely to be heavily distorted when applied to the text. See the Render Texture documentation in the Unity Manual for more information. Property: Function: Horizontal Mapping Specify how textures map to text horizontally when you use a shader that supports textures. Character Stretches the texture horizontally across each character's sprite. Line Stretches the texture horizontally across the entire width of each line. Paragraph Stretches the texture horizontally across the entire text. Match Aspect Scales the texture horizontally so it maintains its aspect ratio, and is not deformed. When you use this horizontal mapping mode, the Vertical Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Vertical Mapping Specify how textures map to text vertically when you use a shader that supports textures. Character Stretches the texture vertically across each character's sprite. Line Stretches the texture vertically across the entire width of each line. Paragraph Stretches the texture vertically across the entire text. Match Aspect Scales the texture vertically so it maintains its aspect ratio, and is not deformed. When you use this vertical mapping mode, the Horizontal Mapping setting determines how the texture is mapped to the text, and must be set to something other than Match Aspect. Line Offset When Horizontal Mapping is set to Line, Paragraph, or Match Aspect, set this value to add a horizontal texture offset to each successive line. This value is added to the Offset X value you specify in the shader."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-wrapping.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/include-tmpobject-wrapping.html",
    "title": "| Inventory System",
    "summary": "Wrapping and Overflow Wrapping splits lines of text to ensure that they don't get wider than the display area. Lines are normally wrapped at word boundaries, but words that are longer than an entire line are split as well. Overflow controls what happens when the text doesn't fit inside the display area. Some overflow options supersede wrapping. For example, if Overflow is set to truncate, the text is truncated when it reaches the edge of the display area, irrespective of whether Wrapping is enabled. Property: Function: Wrapping Enable or Disable word wrapping. Overflow Specify what happens when the text doesn't fit inside the display area. Overflow Extends the text beyond the bounds of the display area, but still wraps it if Wrapping is enabled. Ellipsis Cuts off the text and inserts an ellipsis (…) to indicate that some of the text is omitted. Masking Like Overflow, but the shader hides everything outside of the display area. Truncate Cuts off the text when it no longer fits. Scroll Rect A legacy mode that’s similar to Masking. This option is available strictly for compatibility with older TextMesh Pro projects. For new projects, use Masking mode instead. Page Cuts the text into several pages that each fit inside the display area. You can choose which page to display. You can also use rich text to manually insert page breaks. Note: The vertical alignment options work on a per-page basis. Linked Extends the text into another TextMesh Pro GameObject that you select. This is useful for creating multi-column text."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/index.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/TextMeshPro/index.html",
    "title": "TextMesh Pro Documentation | Inventory System",
    "summary": "TextMesh Pro Documentation TextMesh Pro is a set of Unity tools for 2D and 3D text. TextMesh Pro provides better control over text formatting and layout than to Unity's UI Text & Text Mesh systems. It includes features such as: Character, word, line, and paragraph spacing. Kerning. Justified text. Links. More than thirty rich text tags. Support for multiple fonts. Support for sprites. Custom styles. Advanced text rendering using custom shaders. Getting started The TextMesh Pro package is included in the Unity Editor. You do not need to install it. To use TextMesh Pro, you must import the TMP Essential Resources package (see the next section). You can also import the TMP Examples & Extras package to help you learn TextMesh Pro. Importing required resources into projects To use TextMesh Pro in your projects, you need to import the TMP Essential Resources. From the menu, select Window > TextMeshPro > Import TMP Essential Resources This adds the essential resources to the TextMesh Pro folder in the Project. Importing examples and additional resources TextMesh Pro also includes additional resources and examples to help you learn about various features. You can import these into your projects as well. From the menu, select Window > TextMeshPro > Import TMP Examples & Extras This adds the examples and additional resources to the TextMesh Pro > Examples & Extras folder in the Project. Installing the TMP Examples & Extras is not mandatory, but is strongly recommended for first-time TextMesh Pro users."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIAnimationIntegration.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIAnimationIntegration.html",
    "title": "Animation Integration | Inventory System",
    "summary": "Animation Integration Animation allows for each transition between control states to be fully animated using Unity's animation system. This is the most powerful of the transition modes due to the number of properties that can be animated simultaneously. To use the Animation transition mode, an Animator Component needs to be attached to the controller element. This can be done automatically by clicking \"Auto Generate Animation\". This also generates an Animator Controller with states already set up, which will need to be saved. The new Animator controller is ready to use straight away. Unlike most Animator Controllers, this controller also stores the animations for the controller's transitions and these can be customised, if desired. For example, if a Button element with an Animator controller attached is selected, the animations for each of the button's states can be edited by opening the Animation window (Window>Animation). There is an Animation Clip pop-up menu to select the desired clip. Choose from \"Normal\", \"Highlighted\", \"Pressed\" and \"Disabled\". The Normal State is set by the values on button element itself and can be left empty. On all other states, the most common configuration is a single keyframe at the start of the timeline. The transition animation between states will be handled by the Animator. As an example, the width of the button in the Highlighted State could be changed by selecting the Highlighted state from the Animation Clip pop up menu and with the playhead at the start of the time line: Select the record Button Change the width of the Button in the inspector Exit the record mode. Change to play mode to see how the button grows when highlighted. Any number of properties can have their parameters set in this one keyframe. Several buttons can share the same behaviour by sharing Animator Controllers. The UI Animation transition mode is not compatible with Unity's legacy animation system. You should only use the Animator Component."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIAutoLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIAutoLayout.html",
    "title": "Auto Layout | Inventory System",
    "summary": "Auto Layout The Rect Transform layout system is flexible enough to handle a lot of different types of layouts and it also allows placing elements in a complete freeform fashion. However, sometimes something a bit more structured can be needed. The auto layout system provides ways to place elements in nested layout groups such as horizontal groups, vertical groups, or grids. It also allows elements to automatically be sized according to the contained content. For example a button can be dynamically resized to exactly fit its text content plus some padding. The auto layout system is a system built on top of the basic Rect Transform layout system. It can optionally be used on some or all elements. Understanding Layout Elements The auto layout system is based on a concept of layout elements and layout controllers. A layout element is an Game Object with a Rect Transform and optionally other components as well. The layout element has certain knowledge about which size it should have. Layout elements don't directly set their own size, but other components that function as layout controllers can use the information they provide in order to calculate a size to use for them. A layout element has properties that defines its own: Minimum width Minimum height Preferred width Preferred height Flexible width Flexible height Examples of layout controller components that use the information provided by layout elements are Content Size Fitter and the various Layout Group components. The basic principles for how layout elements in a layout group are sized is as follows: First minimum sizes are allocated. If there is sufficient available space, preferred sizes are allocated. If there is additional available space, flexible size is allocated. Any Game Object with a Rect Transform on it can function as a layout element. They will by default have minimum, preferred, and flexible sizes of 0. Certain components will change these layout properties when added to the Game Object. The Image and Text components are two examples of components that provide layout element properties. They change the preferred width and height to match the sprite or text content. Layout Element Component If you want to override the minimum, preferred, or flexible size, you can do that by adding a Layout Element component to the Game Object. The Layout Element component lets you override the values for one or more of the layout properties. Enable the checkbox for a property you want to override and then specify the value you want to override with. See the reference page for Layout Element for more information. Understanding Layout Controllers Layout controllers are components that control the sizes and possibly positions of one or more layout elements, meaning Game Objects with Rect Transforms on. A layout controller may control its own layout element (the same Game Object it is on itself) or it may control child layout elements. A component that functions as a layout controller may also itself function as a layout element at the same time. Content Size Fitter The Content Size Fitter functions as a layout controller that controls the size of its own layout element. The simplest way to see the auto layout system in action is to add a Content Size Fitter component to a Game Object with a Text component. If you set either the Horizontal Fit or Vertical Fit to Preferred, the Rect Transform will adjust its width and/or height to fit the Text content. See the reference page for Content Size Fitter for more information. Aspect Ratio Fitter The Aspect Ratio Fitter functions as a layout controller that controls the size of its own layout element. It can adjust the height to fit the width or vice versa, or it can make the element fit inside its parent or envelope its parent. The Aspect Ratio Fitter does not take layout information into account such as minimum size and preferred size. See the reference page for Aspect Ratio Fitter for more information. Layout Groups A layout group functions as a layout controller that controls the sizes and positions of its child layout elements. For example, a Horizontal Layout Group places its children next to each other, and a Grid Layout Group places its children in a grid. A layout group doesn't control its own size. Instead it functions as a layout element itself which may be controlled by other layout controllers or be set manually. Whatever size a layout group is allocated, it will in most cases try to allocate an appropriate amount of space for each of its child layout elements based on the minimum, preferred, and flexible sizes they reported. Layout groups can also be nested arbitrarily this way. See the reference pages for Horizontal Layout Group, Vertical Layout Group and Grid Layout Group for more information. Driven Rect Transform properties Since a layout controller in the auto layout system can automatically control the sizes and placement of certain UI elements, those sizes and positions should not be manually edited at the same time through the Inspector or Scene View. Such changed values would just get reset by the layout controller on the next layout calculation anyway. The Rect Transform has a concept of driven properties to address this. For example, a Content Size Fitter which has the Horizontal Fit property set to Minimum or Preferred will drive the width of the Rect Transform on the same Game Object. The width will appear as read-only and a small info box at the top of the Rect Transform will inform that one or more properties are driven by Conten Size Fitter. The driven Rect Transforms properties have other reasons beside preventing manual editing. A layout can be changed just by changing the resolution or size of the Game View. This in turn can change the size or placement of layout elements, which changes the values of driven properties. But it wouldn't be desirable that the Scene is marked as having unsaved changes just because the Game View was resized. To prevent this, the values of driven properties are not saved as part of the Scene and changes to them do not mark the scene as changed. Technical Details The auto layout system comes with certain components built-in, but it is also possible to create new components that controls layouts in custom ways. This is done by having a component implement specific interfaces which are recognized by the auto layout system. Layout Interfaces A component is treated as a layout element by the auto layout system if it implements the interface ILayoutElement. A component is expected to drive the Rect Transforms of its children if it implements the interface ILayoutGroup. A component is expected to drive its own RectTransform if it implements the interface ILayoutSelfController. Layout Calculations The auto layout system evaluates and executes layouts in the following order: The minimum, preferred, and flexible widths of layout elements are calculated by calling CalculateLayoutInputHorizontal on ILayoutElement components. This is performed in bottom-up order, where children are calculated before their parents, such that the parents may take the information in their children into account in their own calculations. The effective widths of layout elements are calculated and set by calling SetLayoutHorizontal on ILayoutController components. This is performed in top-down order, where children are calculated after their parents, since allocation of child widths needs to be based on the full width available in the parent. After this step the Rect Transforms of the layout elements have their new widths. The minimum, preferred, and flexible heights of layout elements are calculated by calling CalculateLayoutInputVertical on ILayoutElement components. This is performed in bottom-up order, where children are calculated before their parents, such that the parents may take the information in their children into account in their own calculations. The effective heights of layout elements are calculated and set by calling SetLayoutVertical on ILayoutController components. This is performed in top-down order, where children are calculated after their parents, since allocation of child heights needs to be based on the full height available in the parent. After this step the Rect Transforms of the layout elements have their new heights. As can be seen from the above, the auto layout system evaluates widths first and then evaluates heights afterwards. Thus, calculated heights may depend on widths, but calculated widths can never depend on heights. Triggering Layout Rebuild When a property on a component changes which can cause the current layout to no longer be valid, a layout recalculation is needed. This can be triggered using the call: LayoutRebuilder.MarkLayoutForRebuild (transform as RectTransform); The rebuild will not happen immediately, but at the end of the current frame, just before rendering happens. The reason it is not immediate is that this would cause layouts to be potentially rebuild many times during the same frame, which would be bad for performance. Guidelines for when a rebuild should be triggered: In setters for properties that can change the layout. In these callbacks: OnEnable OnDisable OnRectTransformDimensionsChange OnValidate (only needed in the editor, not at runtime) OnDidApplyAnimationProperties"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIBasicLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIBasicLayout.html",
    "title": "Basic Layout | Inventory System",
    "summary": "Basic Layout In this section we'll look at how you can position UI elements relative to the Canvas and each other. If you want to test yourself while reading, you can create an Image using the menu GameObject -> UI -> Image. The Rect Tool Every UI element is represented as a rectangle for layout purposes. This rectangle can be manipulated in the Scene View using the Rect Tool in the toolbar. The Rect Tool is used both for Unity's 2D features and for UI, and in fact can be used even for 3D objects as well. The Rect Tool can be used to move, resize and rotate UI elements. Once you have selected a UI element, you can move it by clicking anywhere inside the rectangle and dragging. You can resize it by clicking on the edges or corners and dragging. The element can be rotated by hovering the cursor slightly away from the corners until the mouse cursor looks like a rotation symbol. You can then click and drag in either direction to rotate. Just like the other tools, the Rect Tool uses the current pivot mode and space, set in the toolbar. When working with UI it's usually a good idea to keep those set to Pivot and Local. Rect Transform The Rect Transform is a new transform component that is used for all UI elements instead of the regular Transform component. Rect Transforms have position, rotation, and scale just like regular Transforms, but it also has a width and height, used to specify the dimensions of the rectangle. Resizing Versus Scaling When the Rect Tool is used to change the size of an object, normally for Sprites in the 2D system and for 3D objects it will change the local scale of the object. However, when it's used on an object with a Rect Transform on it, it will instead change the width and the height, keeping the local scale unchanged. This resizing will not affect font sizes, border on sliced images, and so on. Pivot Rotations, size, and scale modifications occur around the pivot so the position of the pivot affects the outcome of a rotation, resizing, or scaling. When the toolbar Pivot button is set to Pivot mode, the pivot of a Rect Transform can be moved in the Scene View. Anchors Rect Transforms include a layout concept called anchors. Anchors are shown as four small triangular handles in the Scene View and anchor information is also shown in the Inspector. If the parent of a Rect Transform is also a Rect Transform, the child Rect Transform can be anchored to the parent Rect Transform in various ways. For example, the child can be anchored to the center of the parent, or to one of the corners. The anchoring also allows the child to stretch together with the width or height of the parent. Each corner of the rectangle has a fixed offset to its corresponding anchor, i.e. the top left corner of the rectangle has a fixed offset to the top left anchor, etc. This way the different corners of the rectangle can be anchored to different points in the parent rectangle. The positions of the anchors are defined in fractions (or percentages) of the parent rectangle width and height. 0.0 (0%) corresponds to the left or bottom side, 0.5 (50%) to the middle, and 1.0 (100%) to the right or top side. But anchors are not limited to the sides and middle; they can be anchored to any point within the parent rectangle. You can drag each of the anchors individually, or if they are together, you can drag them together by clicking in the middle in between them and dragging. If you hold down Shift key while dragging an anchor, the corresponding corner of the rectangle will move together with the anchor. A useful feature of the anchor handles is that they automatically snap to the anchors of sibling rectangles to allow for precise positioning. Anchor presets In the Inspector, the Anchor Preset button can be found in the upper left corner of the Rect Transform component. Clicking the button brings up the Anchor Presets dropdown. From here you can quickly select from some of the most common anchoring options. You can anchor the UI element to the sides or middle of the parent, or stretch together with the parent size. The horizontal and vertical anchoring is independent. The Anchor Presets buttons displays the currently selected preset option if there is one. If the anchors on either the horizontal or vertical axis are set to different positions than any of the presets, the custom options is shown. Anchor and position fields in the Inspector You can click the Anchors expansion arrow to reveal the anchor number fields if they are not already visible. Anchor Min corresponds to the lower left anchor handle in the Scene View, and Anchor Max corresponds to the upper right handle. The position fields of rectangle are shown differently depending on whether the anchors are together (which produces a fixed width and height) or separated (which causes the rectangle to stretch together with the parent rectangle). When all the anchor handles are together the fields displayed are Pos X, Pos Y, Width and Height. The Pos X and Pos Y values indicate the position of the pivot relative to the anchors. When the anchors are separated the fields can change partially or completely to Left, Right, Top and Bottom. These fields define the padding inside the rectangle defined by the anchors. The Left and Right fields are used if the anchors are separated horizontally and the Top and Bottom fields are used if they are separated vertically. Note that changing the values in the anchor or pivot fields will normally counter-adjust the positioning values in order to make the rectangle stay in place. In cases where this is not desired, enable Raw edit mode by clicking the R button in the Inspector. This causes the anchor and pivot value to be able to be changed without any other values changing as a result. This will likely cause the rectangle to be visually moved or resized, since its position and size is dependent on the anchor and pivot values."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UICanvas.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UICanvas.html",
    "title": "Canvas | Inventory System",
    "summary": "Canvas The Canvas is the area that all UI elements should be inside. The Canvas is a Game Object with a Canvas component on it, and all UI elements must be children of such a Canvas. Creating a new UI element, such as an Image using the menu GameObject > UI > Image, automatically creates a Canvas, if there isn't already a Canvas in the scene. The UI element is created as a child to this Canvas. The Canvas area is shown as a rectangle in the Scene View. This makes it easy to position UI elements without needing to have the Game View visible at all times. Canvas uses the EventSystem object to help the Messaging System. Draw order of elements UI elements in the Canvas are drawn in the same order they appear in the Hierarchy. The first child is drawn first, the second child next, and so on. If two UI elements overlap, the later one will appear on top of the earlier one. To change which element appear on top of other elements, simply reorder the elements in the Hierarchy by dragging them. The order can also be controlled from scripting by using these methods on the Transform component: SetAsFirstSibling, SetAsLastSibling, and SetSiblingIndex. Render Modes The Canvas has a Render Mode setting which can be used to make it render in screen space or world space. Screen Space - Overlay This render mode places UI elements on the screen rendered on top of the scene. If the screen is resized or changes resolution, the Canvas will automatically change size to match this. Screen Space - Camera This is similar to Screen Space - Overlay, but in this render mode the Canvas is placed a given distance in front of a specified Camera. The UI elements are rendered by this camera, which means that the Camera settings affect the appearance of the UI. If the Camera is set to Perspective, the UI elements will be rendered with perspective, and the amount of perspective distortion can be controlled by the Camera Field of View. If the screen is resized, changes resolution, or the camera frustum changes, the Canvas will automatically change size to match as well. World Space In this render mode, the Canvas will behave as any other object in the scene. The size of the Canvas can be set manually using its Rect Transform, and UI elements will render in front of or behind other objects in the scene based on 3D placement. This is useful for UIs that are meant to be a part of the world. This is also known as a \"diegetic interface\"."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIHowTos.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIHowTos.html",
    "title": "UI How Tos | Inventory System",
    "summary": "UI How Tos In this section, you can learn about solutions to common UI tasks. Topic Description Designing UI for Multiple Resolutions Learn how to design UI that adapts to different screen resolutions. Making UI elements fit the size of their content Learn how to make UI elements fit the size of their content. Creating a World Space UI Learn how to create a World Space UI. Creating UI elements from scripting Learn how to create UI elements from scripting. Creating Screen Transitions Learn how to create screen transitions. Creating Custom UI Effects With Shader Graph Learn how to create custom UI effects with Shader Graph."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIInteractionComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIInteractionComponents.html",
    "title": "Interaction Components | Inventory System",
    "summary": "Interaction Components This section covers components in the UI system that handles interaction, such as mouse or touch events and interaction using a keyboard or controller. The interaction components are not visible on their own, and must be combined with one or more visual components in order to work correctly. Common Functionality Most of the interaction components have some things in common. They are selectables, which means they have shared built-in functionality for visualising transitions between states (normal, highlighted, pressed, disabled), and for navigation to other selectables using keyboard or controller. This shared functionality is described on the Selectable page. The interaction components have at least one UnityEvent that is invoked when user interacts with the component in specific way. The UI system catches and logs any exceptions that propagate out of code attached to UnityEvent. Button A Button has an OnClick UnityEvent to define what it will do when clicked. See the Button page for details on using the Button component. Toggle A Toggle has an Is On checkbox that determines whether the Toggle is currently on or off. This value is flipped when the user clicks the Toggle, and a visual checkmark can be turned on or off accordingly. It also has an OnValueChanged UnityEvent to define what it will do when the value is changed. See the Toggle page for details on using the Toggle component. Toggle Group A Toggle Group can be used to group a set of Toggles that are mutually exclusive. Toggles that belong to the same group are constrained so that only one of them can be selected at a time - selecting one of them automatically deselects all the others. See the Toggle Group page for details on using the Toggle Group component. Slider A Slider has a decimal number Value that the user can drag between a minimum and maximum value. It can be either horizontal or vertical. It also has a OnValueChanged UnityEvent to define what it will do when the value is changed. See the Slider page for details on using the Slider component. Scrollbar A Scrollbar has a decimal number Value between 0 and 1. When the user drags the scrollbar, the value changes accordingly. Scrollbars are often used together with a Scroll Rect and a Mask to create a scroll view. The Scrollbar has a Size value between 0 and 1 that determines how big the handle is as a fraction of the entire scrollbar length. This is often controlled from another component to indicate how big a proportion of the content in a scroll view is visible. The Scroll Rect component can automatically do this. The Scrollbar can be either horizontal or vertical. It also has a OnValueChanged UnityEvent to define what it will do when the value is changed. See the Scrollbar page for details on using the Scrollbar component. Dropdown A Dropdown has a list of options to choose from. A text string and optionally an image can be specified for each option, and can be set either in the Inspector or dynamically from code. It has a OnValueChanged UnityEvent to define what it will do when the currently chosen option is changed. See the Dropdown page for details on using the Dropdown component. Input Field An Input Field is used to make the text of a Text Element editable by the user. It has a UnityEvent to define what it will do when the text content is changed, and an another to define what it will do when the user has finished editing it. See the Input Field page for details on using the Input Field component. Scroll Rect (Scroll View) A Scroll Rect can be used when content that takes up a lot of space needs to be displayed in a small area. The Scroll Rect provides functionality to scroll over this content. Usually a Scroll Rect is combined with a Mask in order to create a scroll view, where only the scrollable content inside the Scroll Rect is visible. It can also additionally be combined with one or two Scrollbars that can be dragged to scroll horizontally or vertically. See the Scroll Rect page for details on using the Scroll Rect component."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIReference.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIReference.html",
    "title": "UI Reference | Inventory System",
    "summary": "UI Reference This section goes into more depth about Unity’s UI features. Topic Description Rect Transform Learn about the Rect Transform component. Canvas Components Learn about the Canvas component and its related components. Visual Components Learn about the visual components of Unity UI. Interaction Components Learn about the interaction components of Unity UI. Auto Layout Learn about the auto layout components of Unity UI. Events Learn about the event system components of Unity UI."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIVisualComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/UIVisualComponents.html",
    "title": "Visual Components | Inventory System",
    "summary": "Visual Components With the introduction of the UI system, new Components have been added that will help you create GUI specific functionality. This section will cover the basics of the new Components that can be created. Text The Text component, which is also known as a Label, has a Text area for entering the text that will be displayed. It is possible to set the font, font style, font size and whether or not the text has rich text capability. There are options to set the alignment of the text, settings for horizontal and vertical overflow which control what happens if the text is larger than the width or height of the rectangle, and a Best Fit option that makes the text resize to fit the available space. Image An Image has a Rect Transform component and an Image component. A sprite can be applied to the Image component under the Target Graphic field, and its colour can be set in the Color field. A material can also be applied to the Image component. The Image Type field defines how the applied sprite will appear, the options are: Simple - Scales the whole sprite equally. Sliced - Utilises the 3x3 sprite division so that resizing does not distort corners and only the center part is stretched. Tiled - Similar to Sliced, but tiles (repeats) the center part rather than stretching it. For sprites with no borders at all, the entire sprite is tiled. Filled - Shows the sprite in the same way as Simple does except that it fills in the sprite from an origin in a defined direction, method and amount. The option to Set Native Size, which is shown when Simple or Filled is selected, resets the image to the original sprite size. Images can be imported as UI sprites by selecting Sprite( 2D / UI) from the 'Texture Type' settings. Sprites have extra import settings compared to the old GUI sprites, the biggest difference is the addition of the sprite editor. The sprite editor provides the option of 9-slicing the image, this splits the image into 9 areas so that if the sprite is resized the corners are not stretched or distorted. Raw Image The Image component takes a sprite but Raw Image takes a texture (no borders etc). Raw Image should only be used if necessary otherwise Image will be suitable in the majority of cases. Mask A Mask is not a visible UI control but rather a way to modify the appearance of a control’s child elements. The mask restricts (ie, “masks”) the child elements to the shape of the parent. So, if the child is larger than the parent then only the part of the child that fits within the parent will be visible. Effects Visual components can also have various simple effects applied, such as a simple drop shadow or outline. See the UI Effects reference page for more information."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/api_index.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/api_index.html",
    "title": "Scripting API reference for Unity UI and TextMesh Pro | Inventory System",
    "summary": "Scripting API reference for Unity UI and TextMesh Pro This section of the documentation provides detailed information about the Unity UI scripting API. To effectively use this information, you should be familiar with the basic concepts and practices of scripting in Unity, as explained in the Scripting section of our manual. The scripting reference is organized by classes, which are described along with their methods, properties, and other relevant information. APIs are grouped by their respective namespaces and can be selected from the sidebar on the left."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-Canvas.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-Canvas.html",
    "title": "Canvas | Inventory System",
    "summary": "Canvas The Canvas component represents the abstract space in which the UI is laid out and rendered. All UI elements must be children of a GameObject that has a Canvas component attached. When you create a UI element object from the menu (GameObject > Create UI), a Canvas object will be created automatically if there isn't one in the scene already. Properties Property: Function: Render Mode The way the UI is rendered to the screen or as an object in 3D space (see below). The options are Screen Space - Overlay, Screen Space - Camera and World Space. Pixel Perfect (Screen Space modes only) Should the UI be rendered without antialiasing for precision? Render Camera (Screen Space - Camera mode only) The camera to which the UI should be rendered (see below). Plane Distance (Screen Space - Camera mode only) The distance at which the UI plane should be placed in front of the camera. Event Camera (World Space mode only) The camera that will be used to process UI events. Receives Events Are UI events processed by this Canvas? Details A single Canvas for all UI elements is sufficient but multiple Canvases in the scene is possible. It is also possible use nested Canvases, where one Canvas is placed as a child of another for optimization purposes. A nested Canvas uses the same Render Mode as its parent. Traditionally, UIs are rendered as if they were simple graphic designs drawn directly on the screen. That is to say, they have no concept of a 3D space being viewed by a camera. Unity supports this kind of screen space rendering but also allows UIs to rendered as objects in the scene, depending on the value of the Render Mode property. The modes available are Screen Space - Overlay, Screen Space - Camera and World Space. Screen Space - Overlay In this mode, the Canvas is scaled to fit the screen and then rendered directly without reference to the scene or a camera (the UI will be rendered even if there is no camera in the scene at all). If the screen's size or resolution are changed then the UI will automatically rescale to fit. The UI will be drawn over any other graphics such as the camera view. Note: The Screen Space - Overlay canvas needs to be stored at the top level of the hierarchy. If this is not used then the UI may disappear from the view. This is a built-in limitation. Keep the Screen Space - Overlay canvas at the top level of the hierarchy to get expected results. Screen Space - Camera In this mode, the Canvas is rendered as if it were drawn on a plane object some distance in front of a given camera. The onscreen size of the UI does not vary with the distance since it is always rescaled to fit exactly within the camera frustum. If the screen's size or resolution or the camera frustum are changed then the UI will automatically rescale to fit. Any 3D objects in the scene that are closer to the camera than the UI plane will be rendered in front of the UI, while objects behind the plane will be obscured. World Space This mode renders the UI as if it were a plane object in the scene. Unlike Screen Space - Camera mode, however, the plane need not face the camera and can be oriented however you like. The size of the Canvas can be set using its Rect Transform but its onscreen size will depend on the viewing angle and distance of the camera. Other scene objects can pass behind, through or in front of the Canvas. Hints Read more about setting up a World Space Canvas on the Creating a World Space UI page. For information about making your Canvas and UI scale to different resolutions or aspect ratios, see the Designing UI for Multiple Resolutions page as well as the Canvas Scaler page."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-CanvasGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-CanvasGroup.html",
    "title": "Canvas Group | Inventory System",
    "summary": "Canvas Group Canvas Group is a component that allows you to control the visibility, interactability, and alpha transparency of UI elements within a Canvas. It provides a way to easily manage the properties of multiple UI elements together. Typical uses of Canvas Group: Fading UI: Attach a Canvas Group to a window's GameObject and control its Alpha property to fade the entire window in or out. Disabling Interaction: Make a group of UI controls non-interactable by adding a Canvas Group to their parent GameObject and setting the Interactable property to false. Ignoring Raycasts: Prevent certain UI elements from blocking mouse events by placing a Canvas Group on the element or its parent and setting Block Raycasts to false. Properties The following table describes the properties of the Canvas Group component: Property: Function: Alpha The opacity of the UI elements in this group. The value is between 0 and 1 where 0 is fully transparent and 1 is fully opaque. Note that elements retain their own transparency as well, so the Canvas Group alpha and the alpha values of the individual UI elements are multiplied with each other. Interactable Determines if this component will accept input. When it is set to false interaction is disabled. Block Raycasts Will this component act as a collider for Raycasts? You will need to call the RayCast function on the graphic raycaster attached to the Canvas. This does not apply to Physics.Raycast. Ignore Parent Groups Will this group also be affected by the settings in Canvas Group components further up in the GameObject hierarchy, or will it ignore those and hence override them?"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-CanvasRenderer.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-CanvasRenderer.html",
    "title": "Canvas Renderer | Inventory System",
    "summary": "Canvas Renderer The Canvas Renderer component renders a graphical UI object contained within a Canvas. Properties The Canvas Renderer has no properties exposed in the inspector. Details The standard UI objects available from the menu (GameObject > Create UI) all have Canvas Renderers attached wherever they are required but you may need to add this component manually for custom UI objects. Although there are no properties exposed in the inspector, a few properties and function can be accessed from scripts - see the CanvasRenderer page in the Script Reference for full details."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-RectTransform.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/class-RectTransform.html",
    "title": "Rect Transform | Inventory System",
    "summary": "Rect Transform The Rect Transform component is the 2D layout counterpart of the Transform component. Where Transform represents a single point, Rect Transform represent a rectangle that a UI element can be placed inside. If the parent of a Rect Transform is also a Rect Transform, the child Rect Transform can also specify how it should be positioned and sized relative to the parent rectangle. Properties Property: Function: Pos (X, Y, Z) Position of the rectangle's pivot point relative to the anchors. The pivot point is the location around which the rectangle rotates. Width/Height Width and height of the rectangle. Left, Top, Right, Bottom Positions of the rectangle's edges relative to their anchors. This can be thought of as padding inside the rectangle defined by the anchors. Shown in place of Pos and Width/Height when the anchors are separated (see below). To access these options click the square Anchor Presets box at the top left of the RectTransform component. Anchors The anchor points for the lower left corner and the upper right corner of the rectangle. Min The anchor point for the lower left corner of the rectangle defined as a fraction of the size of the parent rectangle. 0,0 corresponds to anchoring to the lower left corner of the parent, while 1,1 corresponds to anchoring to the upper right corner of the parent. Max The anchor point for the upper right corner of the rectangle defined as a fraction of the size of the parent rectangle. 0,0 corresponds to anchoring to the lower left corner of the parent, while 1,1 corresponds to anchoring to the upper right corner of the parent. Pivot Location of the pivot point around which the rectangle rotates, defined as a fraction of the size of the rectangle itself. 0,0 corresponds to the lower left corner while 1,1 corresponds to the upper right corner. Rotation Angle of rotation (in degrees) of the object around its pivot point along the X, Y and Z axis. Scale Scale factor applied to the object in the X, Y and Z dimensions. Blueprint Mode Edit RectTransforms as if they were not rotated and scaled. This enabled snapping too. Raw Edit Mode When enabled, editing pivot and anchor values will not counter adjust the position and size of the rectangle in order to make it stay in one place. Details Note that some RectTransform calculations are performed at the end of a frame, just before calculating UI vertices, in order to ensure that they are up to date with all the latest changes performed throughout the frame. This means that they haven't yet been calculated for the first time in the Start callback and first Update callback. You can work around this by creating a Start() callback and adding Canvas.ForceUpdateCanvases() method to it. This will force Canvas to be updated not at the end of the frame, but when that method is called. See the Basic Layout page for a full introduction and overview of how to use the Rect Transform."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-CanvasComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-CanvasComponents.html",
    "title": "Canvas Components | Inventory System",
    "summary": "Canvas Components All UI Components are placed within a Canvas. Canvas Canvas Scaler Canvas Group Canvas Renderer"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIAutoLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIAutoLayout.html",
    "title": "Auto Layout | Inventory System",
    "summary": "Auto Layout The auto layout system provides ways to place elements in nested layout groups such as horizontal groups, vertical groups, or grids. It also allows elements to automatically be sized according to the contained content. Topic Description Layout Element Controls the minimum, preferred, and flexible sizes of a layout element. Content Size Fitter Controls the size of its own layout element. Aspect Ratio Fitter Sizes the RectTransform to maintain a specific aspect ratio. Horizontal Layout Group Arranges child elements in a horizontal row. Vertical Layout Group Arranges child elements in a vertical column. Grid Layout Group Arranges child elements in a grid."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIEffects.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIEffects.html",
    "title": "UI Effect Components | Inventory System",
    "summary": "UI Effect Components The effects components allow adding simple effects to Text and Image graphics, such as shadow and outline. Shadow Outline Position as UV1"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIInteraction.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIInteraction.html",
    "title": "Interaction Components | Inventory System",
    "summary": "Interaction Components The interaction components in the UI system handle interaction, such as mouse or touch events and interaction using a keyboard or controller. Selectable Base Class Button Toggle Toggle Group Slider Scrollbar Scroll Rect InputField"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIVisual.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/comp-UIVisual.html",
    "title": "Visual Components | Inventory System",
    "summary": "Visual Components The visual components allow for ease of creation and GUI specific functionality. Text Image Raw Image Mask"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/index.html",
    "title": "Unity UI (uGUI) | Inventory System",
    "summary": "Unity UI (uGUI) Unity UI (uGUI) is a GameObject-based UI system that you can use to develop user interfaces for games and applications. It uses Components and the Game view to arrange, position, and style user interfaces. Topic Description Canvas The Canvas is an area where you can place UI elements. Basic Layout Position elements like text and images on a canvas. Visual Components Learn how to add text and images to a canvas. Interaction Components Set up user interactions with elements on a canvas. Animation Integration Animate elements like buttons when highlighted and clicked. Auto Layout Change the size of layouts automatically. Rich Text Use rich text in UI elements. Events The Event System sends events to objects in the application based on input. Reference Comprehensive guide to understanding of uGUI features. UI How Tos Solutions to common UI tasks. UI and UI Details Profiler Use the UI and UI Details Profiler modules to understand how Unity handles UI batching for your application. Note You can't use uGUI to create or change user interfaces of the Unity Editor. Additional Resources Comparison of UI systems in Unity"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-AspectRatioFitter.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-AspectRatioFitter.html",
    "title": "Aspect Ratio Fitter | Inventory System",
    "summary": "Aspect Ratio Fitter Properties Property: Function: Aspect Mode How the rectangle is resized to enforce the aspect ratio. None Do not make the rect fit the aspect ratio. Width Controls Height The height is automatically adjusted based on the width. Height Controls Width The width is automatically adjusted based on the height. Fit In Parent The width, height, position, and anchors are automatically adjusted to make the rect fit inside the rect of the parent while keeping the aspect ratio. The may be some space inside the parent rect which is not covered by this rect. Envelope Parent The width, height, position, and anchors are automatically adjusted to make the rect cover the entire area of the parent while keeping the aspect ratio. This rect may extend further out than the parent rect. Aspect Ratio The aspect ratio to enforce. This is the width divided by the height. Description The Aspect Ratio Fitter functions as a layout controller that controls the size of its own layout element. It can adjust the height to fit the width or vice versa, or it can make the element fit inside its parent or envelope its parent. The Aspect Ratio Fitter does not take layout information into account such as minimum size and preferred size. It's worth keeping in mind that when a Rect Transform is resized - whether by an Aspect Ratio Fitter or something else - the resizing is around the pivot. This means that the pivot can be used to control the alignment of the rectangle. For example, a pivot placed at the top center will make the rectangle grow evenly to both sides, and only grow downwards while the top edge remain at its position."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Button.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Button.html",
    "title": "Button | Inventory System",
    "summary": "Button The Button control responds to a click from the user and is used to initiate or confirm an action. Familiar examples include the Submit and Cancel buttons used on web forms. Properties Property: Function: Interactable Enable Interactable if you want this button to accept input. See API documentation on Interactable for more details. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Events Property: Function: On Click A UnityEvent that Unity invokes when a user clicks the button and releases it. Details The button is designed to initiate an action when the user clicks and releases it. If the mouse is moved off the button control before the click is released, the action does not take place. The button has a single event called On Click that responds when the user completes a click. Typical use cases include: Confirming a decision (eg, starting gameplay or saving a game) Moving to a sub-menu in a GUI Cancelling an action in progress (eg, downloading a new scene)"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-CanvasScaler.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-CanvasScaler.html",
    "title": "Canvas Scaler | Inventory System",
    "summary": "Canvas Scaler The Canvas Scaler component is used for controlling the overall scale and pixel density of UI elements in the Canvas. This scaling affects everything under the Canvas, including font sizes and image borders. Properties Property: Function: UI Scale Mode Determines how UI elements in the Canvas are scaled. Constant Pixel Size Makes UI elements retain the same size in pixels regardless of screen size. Scale With Screen Size Makes UI elements bigger the bigger the screen is. Constant Physical Size Makes UI elements retain the same physical size regardless of screen size and resolution. Settings for Constant Pixel Size: Property: Function: Scale Factor Scales all UI elements in the Canvas by this factor. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the UI. Settings for Scale With Screen Size: Property: Function: Reference Resolution The resolution the UI layout is designed for. If the screen resolution is larger, the UI will be scaled up, and if it's smaller, the UI will be scaled down. Screen Match Mode A mode used to scale the canvas area if the aspect ratio of the current resolution doesn't fit the reference resolution. Match Width or Height Scale the canvas area with the width as reference, the height as reference, or something in between. Expand Expand the canvas area either horizontally or vertically, so the size of the canvas will never be smaller than the reference. Shrink Crop the canvas area either horizontally or vertically, so the size of the canvas will never be larger than the reference. Match Determines if the scaling is using the width or height as reference, or a mix in between. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the UI. Settings for Constant Physical Size: Property: Function: Physical Unit The physical unit to specify positions and sizes in. Fallback Screen DPI The DPI to assume if the screen DPI is not known. Default Sprite DPI The pixels per inch to use for sprites that have a 'Pixels Per Unit' setting that matches the 'Reference Pixels Per Unit' setting. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then its DPI will match the 'Default Sprite DPI' setting. Settings for World Space Canvas (shown when Canvas component is set to World Space): Property: Function: Dynamic Pixels Per Unit The amount of pixels per unit to use for dynamically created bitmaps in the UI, such as Text. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the world. If the 'Reference Pixels Per Unit' is set to 1, then the 'Pixels Per Unit' setting in the sprite will be used as-is. Details For a Canvas set to 'Screen Space - Overlay' or 'Screen Space - Camera', the Canvas Scaler UI Scale Mode can be set to Constant Pixel Size, Scale With Screen Size, or Constant Physical Size. Constant Pixel Size Using the Constant Pixel Size mode, positions and sizes of UI elements are specified in pixels on the screen. This is also the default functionality of the Canvas when no Canvas Scaler is attached. However, With the Scale Factor setting in the Canvas Scaler, a constant scaling can be applied to all UI elements in the Canvas. Scale With Screen Size Using the Scale With Screen Size mode, positions and sizes can be specified according to the pixels of a specified reference resolution. If the current screen resolution is larger than the reference resolution, the Canvas will keep having only the resolution of the reference resolution, but will scale up in order to fit the screen. If the current screen resolution is smaller than the reference resolution, the Canvas will similarly be scaled down to fit. If the current screen resolution has a different aspect ratio than the reference resolution, scaling each axis individually to fit the screen would result in non-uniform scaling, which is generally undesirable. Instead of this, the ReferenceResolution component will make the Canvas resolution deviate from the reference resolution in order to respect the aspect ratio of the screen. It is possible to control how this deviation should behave using the Screen Match Mode setting. Constant Physical Size Using the Constant Physical Size mode, positions and sizes of UI elements are specified in physical units, such as millimeters, points, or picas. This mode relies on the device reporting its screen DPI correctly. You can specify a fallback DPI to use for devices that do not report a DPI. World Space For a Canvas set to 'World Space' the Canvas Scaler can be used to control the pixel density of UI elements in the Canvas. Hints See the page Designing UI for Multiple Resolutions for a step by step explanation of how Rect Transform anchoring and Canvas Scaler can be used in conjunction to make UI layouts that adapt to different resolutions and aspect ratios."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ContentSizeFitter.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ContentSizeFitter.html",
    "title": "Content Size Fitter | Inventory System",
    "summary": "Content Size Fitter Properties Property: Function: Horizontal Fit How the width is controlled. Unconstrained Do not drive the width based on the layout element. Min Size Drive the width based on the minimum width of the layout element. Preferred Size Drive the width based on the preferred width of the layout element. Vertical Fit How the height is controlled. Unconstrained Do not drive the height based on the layout element. Min Size Drive the height based on the minimum height of the layout element. Preferred Size Drive the height based on the preferred height of the layout element. Description The Content Size Fitter functions as a layout controller that controls the size of its own layout element. The size is determined by the minimum or preferred sizes provided by layout element components on the Game Object. Such layout elements can be Image or Text components, layout groups, or a Layout Element component. It's worth keeping in mind that when a Rect Transform is resized - whether by a Content Size Fitter or something else - the resizing is around the pivot. This means that the direction of the resizing can be controlled using the pivot. For example, when the pivot is in the center, the Content Size Fitter will expand the Rect Transform out equally in all directions. And when the pivot is in the upper left corner, the Content Size Fitter will expand the Rect Transform down and to the right."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Dropdown.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Dropdown.html",
    "title": "Dropdown | Inventory System",
    "summary": "Dropdown The Dropdown can be used to let the user choose a single option from a list of options. The control shows the currently chosen option. Once clicked, it opens up the list of options so a new option can be chosen. Upon choosing a new option, the list of closed again, and the control shows the new selected option. The list is also closed if the user clicks on the control itself, or anywhere else inside the Canvas. Properties Property: Function: Interactable Will this component will accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Template The Rect Transform of the template for the dropdown list. See instructions below. Caption Text The Text component to hold the text of the currently selected option. (Optional) Caption Image The Image component to hold the image of the currently selected option. (Optional) Item Text The Text component to hold the text of the item. (Optional) Item Image The Image component to hold the image of the item. (Optional) Value The index of the currently selected option. 0 is the first option, 1 is the second, and so on. Options The list of possible options. A text string and an image can be specified for each option. Events Property: Function: On Value Changed A UnityEvent that is invoked when a user has clicked one of the options in the dropdown list. Details The list of options is specified in the Inspector or can be assigned from code. For each option a text string can be specified, and optionally an image as well, if the Dropdown is setup to support it. The button has a single event called On Value Changed that responds when the user completes a click on one of the options in the list. It supports sending an integer number value that is the index of the selected option. 0 is the first option, 1 is the second, and so on. The template system The Dropdown control is designed to have a child GameObject which serves as a template for the dropdown list that is shown when clicking the dropdown control. The template GameObject is inactive by default, but can be made active while editing the template to better see what's going on. A reference to the template object must be specified in the Template property of the Dropdown component. The template must have a single item in it with a Toggle component on. When the actual dropdown list is created upon clicking the dropdown control, this item is duplicated multiple times, with one copy used for each option in the list. The parent of the item is automatically resized so it can fit all the items inside. The template can be setup in many different ways. The setup used by the GameObject > UI > Dropdown menu item includes a scroll view, such that if there are too many options to show at once, a scrollbar will appear and the user can scroll through the options. This is however not a mandatory part of the template setup. (See the ScrollRect page for more information about setup of Scroll Views.) Setup of text and image support The dropdown supports one text content and one image content for each option. Both text and image is optional. They can only be used if the Dropdown is setup to support it. The dropdown supports text for each option when the Caption Text and Item Text properties are both setup. These are setup by default when using the GameObject > UI > Dropdown menu item. The Caption Text is the Text component to hold the text for the currently selected option. It is typically a child to the Dropdown GameObject. The Item Text is the Text component to hold the text for each option. It is typically a child to the Item GameObject. The dropdown supports an image for each option when the Caption Image and Item Image properties are both setup. These are not setup by default. The Caption Image is the Image component to hold the image for the currently selected option. It is typically a child to the Dropdown GameObject. The Item Image is the Image component to hold the image for each option. It is typically a child to the Item GameObject. The actual text and images used for the dropdowns are specified in the Options property of the Dropdown component, or can be set from code. Placement of the dropdown list The placement of the dropdown list in relation to the dropdown control is determined by the anchoring and pivot of the Rect Transform of the Template. By default, the list will appear below the control. This is achieved by anchoring the template to the bottom of the control. The pivot of the template also needs to be at the top, so that as the template is expanded to accommodate a variable number of option items, it only expands downwards. The Dropdown control has simple logic to prevent that the dropdown is displayed outside the bounds of the Canvas, since this would make it impossible to select certain options. If the dropdown at its default position is not fully within the Canvas rectangle, its position in relation to the control is reversed. For example, a list that is shown below the control by default will be shown above it instead. This logic is quite simple and has certain limitations. The dropdown template needs to be no larger than half the Canvas size minus the size of the dropdown control, otherwise there may not be room for the list at either position if the dropdown control is placed in the middle of the Canvas."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-EventSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-EventSystem.html",
    "title": "Event System Manager | Inventory System",
    "summary": "Event System Manager This subsystem is responsible for controlling all the other elements that make up eventing. It coordinates which Input Module is currently active, which GameObject is currently considered 'selected', and a host of other high level Event System concepts. Each 'Update' the Event System receives the call, looks through its Input Modules and figures out which is the Input Module that should be used for this tick. It then delegates the processing to the modules. Properties Property: Function: First Selected The GameObject that was selected first. Send Navigation Events Should the EventSystem allow navigation events (move / submit / cancel). Drag Threshold The soft area for dragging in pixels. Beneath the Properties table is the \"Add Default Input Modules\" button."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-EventTrigger.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-EventTrigger.html",
    "title": "Event Trigger | Inventory System",
    "summary": "Event Trigger The Event Trigger receives events from the Event System and calls registered functions for each event. The Event Trigger can be used to specify functions you wish to be called for each Event System event. You can assign multiple functions to a single event and whenever the Event Trigger receives that event it will call those functions. Note that attaching an Event Trigger component to a GameObject will make that object intercept all events, and no event bubbling will occur from this object! Events Each of the Supported Events can optionally be included in the Event Trigger by clicking the Add New Event Type button."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-GraphicRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-GraphicRaycaster.html",
    "title": "Graphic Raycaster | Inventory System",
    "summary": "Graphic Raycaster The Graphic Raycaster is used to raycast against a Canvas. The Raycaster looks at all Graphics on the canvas and determines if any of them have been hit. The Graphic Raycaster can be configured to ignore backfacing Graphics as well as be blocked by 2D or 3D objects that exist in front of it. A manual priority can also be applied if you want processing of this element to be forced to the front or back of the Raycasting. Properties Property: Function: Ignore Reversed Graphics Should graphics facing away from the raycaster be considered? Blocking Objects Type of objects that are checked to determine if they block graphic raycasts. Blocking Mask Type of objects specified through LayerMask that are checked to determine if they block graphic raycasts."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-GridLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-GridLayoutGroup.html",
    "title": "Grid Layout Group | Inventory System",
    "summary": "Grid Layout Group The Grid Layout Group component places its child layout elements in a grid. Properties Property: Function: Padding The padding inside the edges of the layout group. Cell Size The size to use for each layout element in the group. Spacing The spacing between the layout elements. Start Corner The corner where the first element is located. Start Axis Which primary axis to place elements along. Horizontal will fill an entire row before a new row is started. Vertical will fill an entire column before a new column is started. Child Alignment The alignment to use for the layout elements if they don't fill out all the available space. Constraint Constraint the grid to a fixed number of rows or columns to aid the auto layout system. Description Unlike other layout groups, the Grid Layout Group ignores the minimum, preferred, and flexible size properties of its contained layout elements and instead assigns a fixed size to all of them which is defined with the Cell Size property of the Grid Layout Group itself. Grid Layout Group and auto layout There are special considerations to be aware of when using the Grid Layout Group as part of an auto layout setup, such as using it with a Content Size Fitter. The auto layout system calculates the horizontal and vertical sizes independently. This can be at odds with the Grid Layout Group, where the number of rows depends on the number of columns and vice versa. For any given number of cells, there are different combinations of row count and column count that can make the grid fit its content. In order to aid the layout system, you can specify that you intent the table to have a fixed number of columns or rows by using the Constraint property. Here are suggested ways of using the Layout System with a Content Size Fitter: Flexible width and fixed height To setup a grid with a flexible width and fixed height, where the grid expands horizontally as more elements are added, you can set these properties as follows: Grid Layout Group Constraint: Fixed Row Count Content Size Fitter Horizontal Fit: Preferred Size Content Size Fitter Vertical Fit: Preferred Size or Unconstrained If unconstrained Vertical Fit is used, it's up to you to give the grid a height that is big enough to fit the specified row count of cells. Fixed width and flexible height To setup a grid with a fixed width and flexible height, where the grid expands vertically as more elements are added, you can set these properties as follows: Grid Layout Group Constraint: Fixed Column Count Content Size Fitter Horizontal Fit: Preferred Size or Unconstrained Content Size Fitter Vertical Fit: Preferred Size If unconstrained Horizontal Fit is used, it's up to you to give the grid a width that is big enough to fit the specified column count of cells. Both flexible width and height If you want a grid with both a flexible width and height you can do that, but you will have no control over the specific number of rows and columns. The grid will attempt to make the row and column count approximately the same. You can set these properties as follows: Grid Layout Group Constraint: Flexible Content Size Fitter Horizontal Fit: Preferred Size Content Size Fitter Vertical Fit: Preferred Size"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-HorizontalLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-HorizontalLayoutGroup.html",
    "title": "Horizontal Layout Group | Inventory System",
    "summary": "Horizontal Layout Group The Horizontal Layout Group component places its child layout elements next to each other, side by side. Their widths are determined by their respective minimum, preferred, and flexible widths according to the following model: The minimum widths of all the child layout elements are added together and the spacing between them is added as well. The result is the mimimum width of the Horizontal Layout Group. The preferred widths of all the child layout elements are added together and the spacing between them is added as well. The result is the preferred width of the Horizontal Layout Group. If the Horizontal Layout Group is at its minimum width or smaller, all the child layout elements will also have their minimum width. The closer the Horizontal Layout group is to its preferred width, the closer each child layout element will also get to their preferred width. If the Horizontal Layout Group is wider than its preferred width, it will distribute the extra available space proportionally to the child layout elements according to their respective flexible widths. For more information about minimum, preferred, and flexible width, see the documentation on Auto Layout. Properties Property: Function: Padding The padding inside the edges of the layout group. Spacing The spacing between the layout elements. Child Alignment The alignment to use for the child layout elements if they don't fill out all the available space. Control Child Size Whether the Layout Group controls the width and height of its child layout elements. Use Child Scale Whether the Layout Group considers the scale of its child layout elements when sizing and laying out elements. Width and Height correspond to the Scale > X and Scale > Y values in each child layout element's Rect Transform component. You cannot animate the Scale values using the Animator Controller Child Force Expand Whether to force the child layout elements to expand to fill additional available space."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Image.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Image.html",
    "title": "Image | Inventory System",
    "summary": "Image The Image control displays a non-interactive image to the user. You can use this for purposes such as decorations or icons, and you can change the image from a script to reflect changes in other controls. The control is similar to the Raw Image control, but offers more options for animating the image and accurately filling the control rectangle. However, the Image control requires its Texture to be a Sprite, while the Raw Image can accept any Texture. Properties Property: Function: Source Image The Texture that represents the image to display (which must be imported as a Sprite). Color The color to apply to the image. Material The Material to use for rendering the image. Raycast Target Enable Raycast Target if you want Unity to consider the image a target for raycasting. Preserve Aspect Ensure the image retains its existing dimension. Set Native Size Set the dimensions of the image box to the original pixel size of the Texture. You must import the image to display as a Sprite to work with the Image control."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-InputField.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-InputField.html",
    "title": "Input Field | Inventory System",
    "summary": "Input Field An Input Field is a way to make the text of a Text Control editable. Like the other interaction controls, it's not a visible UI element in itself and must be combined with one or more visual UI elements in order to be visible. Properties Property: Function: Interactable A boolean that determines if the Input Field can be interacted with or not. Transition Transitions are used to set how the input field transitions when Normal, Highlighted, Pressed or Disabled. Navigation Properties that determine the sequence of controls. See Navigation Options. TextComponent A reference to the Text element used as the contents of the Input Field Text Starting Value. The initial text placed in the field before editing begins. Character Limit The value of the maximum number of characters that can be entered into the input field. Content Type Define the type(s) of characters that your input field accepts Standard Any character can be entered. Autocorrected The autocorrection determines whether the input tracks unknown words and suggests a more suitable replacement candidate to the user, replacing the typed text automatically unless the user explicitly overrides the action. Integer Number Allow only whole numbers to be entered. Decimal Number Allow only numbers and a single decimal point to be entered. Alphanumeric Allow both letters and numbers. Symbols cannot be entered. Name Automatically capitalizes the first letter of each word. Note that the user can circumvent the capitalization rules using the Delete key. Email Address Allows you to enter an Alphanumeric string consisting of a maximum of one @ sign. periods/baseline dots cannot be entered next to each other. Password* Conceals the characters inputed with an asterisk. Allows symbols. Pin Conceals the characters inputed with an asterisk. Only allows only whole numbers to be entered. Custom Allows you to customise the Line Type, Input Type, Keyboard Type and Character Validation. Line Type Defines how text is formatted inside the text field. Single Line Only allows text to be on a single line. Multi Line Submit Allows text to use multiple lines. Only uses a new line when needed. Multi Line Newline Allows text to use multiple lines. User can use a newline by pressing the return key. Placeholder This is an optional ‘empty’ Graphic to show that the Input Field is empty of text. Note that this ‘empty' graphic still displays even when the Input Field is selected (that is; when there is focus on it). eg; \"Enter text...\". Caret Blink Rate Defines the blink rate for the mark placed on the line to indicate a proposed insertion of text. Selection Color The background color of the selected portion of text. Hide Mobile Input Hides the native input field attached to the onscreen keyboard on mobile devices. Note that this only works on iOS and Android devices. Events Property: Function: On Value Change A UnityEvent that is invoked when the text content of the Input Field changes. The event can send the current text content as a string type dynamic argument. End Edit A UnityEvent that is invoked when the user finishes editing the text content either by submitting or by clicking somewhere that removes the focus from the Input Field. The event can send the current text content as a string type dynamic argument. Details The Input Field script can be added to any existing Text control object from the menu (Component > UI > Input Field). Having done this, you should also drag the object to the Input Field's Text property to enable editing. The Text property of the Text control itself will change as the user types and the value can be retrieved from a script after editing. Note that Rich Text is intentionally not supported for editable Text controls; the field will apply any Rich Text markup instantly when typed but the markup essentially \"disappears\" and there is no subsequent way to change or remove the styling. Hints To obtain the text of the Input Field, use the text property on the InputField component itself, not the text property of the Text component that displays the text. The text property of the Text component may be cropped or may consist of asterisks for passwords. Limitations On iOS when an external keyboard is connected, the onscreen keyboard will be hidden by the OS but the caret will not appear in the InputField. This is due to a lack of external keyboard support on iOS 13 and older."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-LayoutElement.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-LayoutElement.html",
    "title": "Layout Element | Inventory System",
    "summary": "Layout Element If you want to override the minimum, preferred, or flexible size of a layout element, you can do that by adding a Layout Element component to the GameObject. A layout controller allocates width or height to a layout element in the following order: First, the layout controller allocates the minimum size properties (Min Width, Min Height). If there is sufficient available space, the layout controller allocates the preferred size properties (Preferred Width, Preferred Height). If there is additional available space, the layout controller allocates the flexible size properties (Flexible Width, Flexible Height). For more information about minimum, preferred, and flexible size, see documentation on Auto Layout. Properties When you enable a width or height property, a value field appears next to it. Use this value field to enter the exact value for the width or height. Min and Preferred sizes are in regular units, while the Flexible sizes are in relative units. Property: Function: Ignore Layout When enabled, the layout system ignores this layout element. Min Width The minimum width this layout element should have. Min Height The minimum height this layout element should have. Preferred Width The preferred width this layout element should have before additional available width is allocated. Preferred Height The preferred height this layout element should have before additional available height is allocated. Flexible Width The relative amount of additional available width this layout element should fill out relative to its siblings. Flexible Height The relative amount of additional available height this layout element should fill out relative to its siblings. Layout Priority The layout priority for this component. If a GameObject has more than one component with layout properties (for example, an Image component and a LayoutElement component), the layout system uses the property values from the component with the highest Layout Priority. If the components have the same Layout Priority, the layout system uses the highest value for each property, regardless of which component it comes from. Description The Layout Element component lets you override the values for one or more of the layout properties. Enable the checkbox for a property you want to override and then specify the value you want to override with. Minimum and preferred sizes are defined in regular units, while the flexible sizes are defined in relative units. If any layout element has flexible size greater than zero, it means that all the available space will be filled out. The relative flexible size values of the siblings determines how big a proportion of the available space each sibling fills out. Most commonly, flexible width and height is set to just 0 or 1. Specifying both a preferred size and a flexible size can make sense in certain cases. Flexible sizes are only allocated after all preferred sizes have been fully allocated. Thus, a layout element which has a flexible size specified but no preferred size will keep its minimum size until other layout elements have grown to their full preferred size, and only then begin to grow based on additional available space. By also specifying a flexible size, this can be avoided and the element can grow to its preferred size in tandem with the other layout elements that have preferred sizes, and then grow further once all flexible sizes have been allocated."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Mask.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Mask.html",
    "title": "Mask | Inventory System",
    "summary": "Mask A Mask is not a visible UI control but rather a way to modify the appearance of a control's child elements. The mask restricts (ie, \"masks\") the child elements to the shape of the parent. So, if the child is larger than the parent then only the part of the child that fits within the parent will be visible. Properties Property: Function: Show Graphic Should the graphic of the masking (parent) object be drawn with alpha over the child object? Description A common use of a Mask is to show a small section of a large Image, using say a Panel object (menu: GameObject > Create UI > Panel) as a \"frame\". You can achieve this by firstly making the Image a child of the Panel object. You should position the Image so that the area that should be visible is directly behind the Panel area. Then, add a Mask component to the Panel. The areas of the child Image outside the panel will become invisible since they are masked by the shape of the Panel. If the image is then moved around then only the part revealed by the Panel will be visible. The movement could be controlled by Scrollbars to create a scrollable viewer for a map, say. Implementation Masking is implemented using the stencil buffer of the GPU. *The first Mask element writes a 1 to the stencil buffer *All elements below the mask check when rendering, and only render to areas where there is a 1 in the stencil buffer *Nested Masks will write incremental bit masks into the buffer, this means that renderable children need to have the logical & of the stencil values to be rendered."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Outline.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Outline.html",
    "title": "Outline | Inventory System",
    "summary": "Outline The Outline component adds a simple outline effect to graphic components such as Text or Image. It must be on the same GameObject as the graphic component. Properties Property: Function: Effect Color The color of the outline. Effect Distance The distance of the outline effect horizontally and vertically. Use Graphic Alpha Multiplies the color of the graphic onto the color of the effect."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PanelEventHandler.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PanelEventHandler.html",
    "title": "Panel Event Handler | Inventory System",
    "summary": "Panel Event Handler Use this class to handle input and send events to UI Toolkit runtime panels. For additional information about using input and event systems with UI Toolkit, refer to FAQ for event and input system. Properties Property: Function: panel The panel that this component relates to. If the panel is null, this component has no effect. It will automatically be set to null automatically if the panel is disposed of from an external source."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PanelRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PanelRaycaster.html",
    "title": "Panel Raycaster | Inventory System",
    "summary": "Panel Raycaster A derived Raycaster to raycast against UI Toolkit panel instances at runtime. During the Start method of the EventSystem, a PanelRaycaster is automatically added to the scene for each active UI Document in the scene. To disable this behavior, call EventSystem.SetUITookitEventSystemOverride before the Start method executes. You can use the Sort Order of the Panel Settings asset referenced by each document to configure the priority of the raycast between multiple documents. You can also use the PanelRaycaster in combination with a GraphicRaycaster. In that case, the Sort Order of documents is compared to the Sort Order of Canvases to determine overall priority. For additional information about using input and event systems with UI Toolkit, refer to FAQ for event and input system. Properties Property: Function: panel The panel that this component relates to. If the panel is null, this component has no effect. It will automatically be set to null automatically if the panel is disposed of from an external source."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Physics2DRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Physics2DRaycaster.html",
    "title": "Physics 2D Raycaster | Inventory System",
    "summary": "Physics 2D Raycaster The 2D Raycaster raycasts against 2D objects in the scene. This allows messages to be sent to 2D physics objects that implement event interfaces. The Camera GameObject needs to be used and will be added to the GameObject if the Physics 3D Raycaster is not added to the Camera GameObject. For more Raycaster information see Raycasters. Properties Property: Function: Event Camera The camera that will generate rays for this raycaster. Priority Priority of the caster relative to other casters. Sort Order Priority Priority of the raycaster based upon sort order. Render Order Priority Priority of the raycaster based upon render order."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PhysicsRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PhysicsRaycaster.html",
    "title": "Physics Raycaster | Inventory System",
    "summary": "Physics Raycaster The Raycaster raycasts against 3D objects in the scene. This allows messages to be sent to 3D physics objects that implement event interfaces. Properties Property: Function: Depth Get the depth of the configured camera. Event Camera Get the camera that is used for this module. Event Mask Logical and of Camera mask and eventMask. Final Event Mask Logical and of Camera mask and eventMask."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PositionAsUV1.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-PositionAsUV1.html",
    "title": "Position as UV1 | Inventory System",
    "summary": "Position as UV1 This adds a simple Position as UV1 effect to text and image graphics. Properties Property: Function: Script"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-RawImage.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-RawImage.html",
    "title": "Raw Image | Inventory System",
    "summary": "Raw Image The Raw Image control displays a non-interactive image to the user. You can use this for purposes such as decorations or icons, and you can change the image from a script to reflect changes in other controls. The control is similar to the Image control, but offers more options for animating the image and accurately filling the control rectangle. However, the Image control requires its Texture to be a Sprite, while the Raw Image can accept any Texture. Properties Property: Function: Texture The texture that represents the image to display. Color The color to apply to the image. Material The Material to use for rendering the image. Raycast Target Enable Raycast Target if you want Unity to consider the image a target for raycasting. UV Rectangle The image's offset and size within the control rectangle, given in normalized coordinates (range 0.0 to 1.0). The edges of the image are stretched to fill the space around the UV rectangle. Details Since the Raw Image does not require a sprite texture, you can use it to display any texture available to the Unity player. For example, you might show an image downloaded from a URL using the WWW class or a texture from an object in a game. The UV Rectangle properties allow you to display a small section of a larger image. The X and Y coordinates specify which part of the image is aligned with the bottom left corner of the control. For example, an X coordinate of 0.25 will cut off the leftmost quarter of the image. The W and H (ie, width and height) properties indicate the width and height of the section of image that will be scaled to fit the control rectangle. For example, a width and height of 0.5 will scale a quarter of the image area up to the control rectangle. By changing these properties, you can zoom and scale the image as desired (see also the Scrollbar control)."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-RectMask2D.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-RectMask2D.html",
    "title": "RectMask2D | Inventory System",
    "summary": "RectMask2D A RectMask2D is a masking control similar to the Mask control. The mask restricts the child elements to the rectangle of the parent element. Unlike the standard Mask control it has some limitations, but it also has a number of performance benefits. Description A common use of a RectMask2D is to show small sections of a larger area. Using the RectMask2D to frame this area. The limitations of RectMask2D control are: It only works in 2D space It will not properly mask elements that are not coplanar The advantages of RectMask2D are: It does not use the stencil buffer No extra draw calls No material changes Fast performance"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ScrollRect.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ScrollRect.html",
    "title": "Scroll Rect | Inventory System",
    "summary": "Scroll Rect A Scroll Rect can be used when content that takes up a lot of space needs to be displayed in a small area. The Scroll Rect provides functionality to scroll over this content. Usually a Scroll Rect is combined with a Mask in order to create a scroll view, where only the scrollable content inside the Scroll Rect is visible. It can also additionally be combined with one or two Scrollbars that can be dragged to scroll horizontally or vertically. Properties Property: Function: Content This is a reference to the Rect Transform of the UI element to be scrolled, for example a large image. Horizontal Enables horizontal scrolling Vertical Enables vertical scrolling Movement Type Unrestricted, Elastic or Clamped. Use Elastic or Clamped to force the content to remain within the bounds of the Scroll Rect. Elastic mode bounces the content when it reaches the edge of the Scroll Rect Elasticity This is the amount of bounce used in the elasticity mode. Inertia When Inertia is set the content will continue to move when the pointer is released after a drag. When Inertia is not set the content will only move when dragged. Deceleration Rate When Inertia is set the deceleration rate determines how quickly the contents stop moving. A rate of 0 will stop the movement immediately. A value of 1 means the movement will never slow down. Scroll Sensitivity The sensitivity to scroll wheel and track pad scroll events. Viewport Reference to the viewport Rect Transform that is the parent of the content Rect Transform. Horizontal Scrollbar Optional reference to a horizontal scrollbar element. Visibility Whether the scrollbar should automatically be hidden when it isn't needed, and optionally expand the viewport as well. Spacing The space between the scrollbar and the viewport. Vertical Scrollbar Optional reference to a vertical scrollbar element. Visibility Whether the scrollbar should automatically be hidden when it isn't needed, and optionally expand the viewport as well. Spacing The space between the scrollbar and the viewport. Events Property: Function: On Value Changed A UnityEvent that is invoked when the scroll position of the Scroll Rect changes. The event can send the current scroll position as a Vector2 type dynamic argument. Details The important elements in a scroll view are the viewport, the scrolling content, and optionally one or two scrollbars. The root GameObject has the Scroll Rect component. The viewport has a Mask component. The viewport can either be the root GameObject, or a separate GameObject that's a child to the root. If auto-hiding scrollbars are used, it must be a child. The viewport Rect Transform needs to be referenced in the Viewport property of the Scroll Rect. All the scrolling content must be children of a single content GameObject that is a child to the viewport. The content Rect Transform needs to be referenced in the Content property of the Scroll Rect. The scrollbars - if used - are children to the root GameObject. See the Scrollbar page for more details on the setup of a scrollbar and see the section Scrollbar setup below for information about setup of scrollbars with a scroll view. This image shows a setup where the viewport is a child to the scroll view root. This is the default used when using the GameObject > UI > Scroll View menu option. To scroll content, the input must be received from inside the bounds of the ScrollRect, not on the content itself. Take care when using Unrestricted scrolling movement as it is possible to lose control of the content in an irretrievable way. When using Elastic or Constrained movement it is best to position the content so that it starts within the bounds of the ScrollRect, or undesirable behaviour may occur as the RectTransform tries to bring the content back within its bounds. Scrollbar setup Optionally, the Scroll Rect can be linked to a horizontal and/or a vertical Scrollbar. These are typically placed in the hierarchy as siblings to the viewport, and when present, should be dragged into the Horizontal Scrollbar and Vertical Scrollbar properties of the Scroll Rect, respectively. Note that the Direction property on such a horizontal Scrollbar should be set to Left To Right, and on the vertical Scrollbar to Bottom To Top. The scrollbars can optionally have auto-hiding behaviour that hides the scrollbars if the content doesn't need to scroll because it isn't larger than the viewport. Note that the auto-hiding only ever happens in Play Mode. In Edit Mode the scrollbars are always shown. This prevents marking the scene as dirty when it shouldn't be, and also help authoring content with proportions that there's room for even when the scrollbars are shown. If one or both scrollbars have their visibility behaviour set to Auto Hide And Expand View, the viewport is automatically expanded when the scrollbars are hidden in order to take up the extra room where the scrollbars would otherwise have been. With this setup, the position and size of the view is driven by the Scroll Rect, and the width of the horizontal scrollbar as well as the height of the vertical scrollbar is driven as well. With this setup the viewport as well as the scrollbars must be children to the Scroll Rect root GameObject. Hints The pivot and anchors of the content RectTransform can be used to determine how the content is aligned inside the scroll view if the content grows or shrinks. If the content should stay aligned with the top, set the anchors to the top of the parent, and set the pivot to the top position. See the page Making UI elements fit the size of their content for information about how to make the content Rect Transform automatically resize to fit the content."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Scrollbar.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Scrollbar.html",
    "title": "Scrollbar | Inventory System",
    "summary": "Scrollbar The Scrollbar control allows the user to scroll an image or other view that is too large to see completely. Note that the similar Slider control is used for selecting numeric values rather than scrolling. Familiar examples include the vertical Scrollbar at the side of a text editor and the vertical and horizontal pair of bars for viewing a section of a large image or map. Properties Property: Function: Interactable Will this component accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Fill Rect The graphic used for the background area of the control. Handle Rect The graphic used for the sliding \"handle\" part of the control Direction The direction in which the Scrollbar's value will increase when the handle is dragged. The options are Left To Right, Right To Left, Bottom To Top and Top To Bottom. Value Initial position value of the Scrollbar, in the range 0.0 to 1.0. Size Fractional size of the handle within the Scrollbar, in the range 0.0 to 1.0. Number Of Steps The number of distinct scroll positions allowed by the Scrollbar. Events Property: Function: On Value Changed A UnityEvent that is invoked when the current value of the Scrollbar changes. The event can send the value as a float type dynamic argument. Details The value of a Scrollbar is determined by the position of the handle along its length with the value being reported as a fraction between the extreme ends. For example, the default left-to-right bar has a value of 0.0 at the left end, 1.0 at the right end and 0.5 indicates the halfway point. A scrollbar can be oriented vertically by choosing Top To Bottom or Bottom To Top for the Direction property. A significant difference between the Scrollbar and the similar Slider control is that the Scrollbar's handle can change in size to represent the distance of scrolling available; when the view can scroll only a short way, the handle will fill up most of the bar and only allow a slight shift either direction. The Scrollbar has a single event called On Value Changed that responds as the user drags the handle. The current value is passed to the event function as a float parameter. Typical use cases for a scrollbar include: Scrolling a piece of text vertically. Scrolling a timeline horizontally. Used as a pair, scrolling a large image both horizontally and vertically to view a zoomed section. The size of the handle changes to indicate the degree of zooming and therefore the available distance for scrolling."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Selectable.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Selectable.html",
    "title": "Selectable Base Class | Inventory System",
    "summary": "Selectable Base Class The Selectable Class is the base class for all the interaction components and it handles the items that are in common. Property: Function: Interactable This determines if this component will accept input. When it is set to false interaction is disabled and the transition state will be set to the disabled state. Transition Within a selectable component there are several Transition Options depending on what state the selectable is currently in. The different states are: normal, highlighted, pressed and disabled. Navigation There are also a number of Navigation Options to control how keyboard navigation of the controls is implemented."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-SelectableNavigation.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-SelectableNavigation.html",
    "title": "Navigation Options | Inventory System",
    "summary": "Navigation Options Property: Function: Navigation The Navigation options refers to how the navigation of UI elements in play mode will be controlled. None No keyboard navigation. Also ensures that it does not receive focus from clicking/tapping on it. Horizontal Navigates Horizontally. Vertical Navigates Vertically. Automatic Automatic Navigation. Explicit In this mode you can explicitly specify where the control navigates to for different arrow keys. Visualize Selecting Visualize gives you a visual representation of the navigation you have set up in the scene window. See below. In the above visualization mode, the arrows indicate how the change of focus is set up for the collection of controls as a group. That means - for each individual UI control - you can see which UI control will get focus next, if the user presses an arrow key when the given control has focus. So in the example shown above, If the \"button\" has focus and the user presses the right arrow key, the first (left-hand) vertical slider will then become focused. Note that the vertical sliders can't be focused-away-from using up or down keys, because they control the value of the slider. The same is true of the horizontal sliders and the left/right arrow keys."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-SelectableTransition.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-SelectableTransition.html",
    "title": "Transition Options | Inventory System",
    "summary": "Transition Options Within a selectable component there are several transition options depending on what state the selectable is currently in. The different states are: normal, highlighted, pressed and disabled. Transition Options: Function: None This option is for the button to have no state effects at all. Color Tint Changes the colour of the button depending on what state it is in. It is possible to select the colour for each individual state. It is also possible to set the Fade Duration between the different states. The higher the number is, the slower the fade between colors will be. Sprite Swap Allows different sprites to display depending on what state the button is currently in, the sprites can be customised. Animation Allows animations to occur depending on the state of the button, an animator component must exist in order to use animation transition. It’s important to make sure root motion is disabled. To create an animation controller click on generate animation (or create your own) and make sure that an animation controller has been added to the animator component of the button. Each Transition option (except None) provides additional options for controlling the transitions. We'll go into details with those in each of the sections below. Color Tint Property: Function: Target Graphic The graphic used for the interaction component. Normal Color The normal color of the control Highlighted Color The color of the control when it is highlighted Pressed Color The color of the control when it is pressed Disabled Color The color of the control when it is disabled Color Multiplier This multiplies the tint color for each transition by its value. With this you can create colors greater than 1 to brighten the colors (or alpha channel) on graphic elements whose base color is less than white (or less then full alpha). Fade Duration The time taken, in seconds, to fade from one state to another Sprite Swap Property: Function: Target Graphic The normal sprite to use Highlighted Sprite Sprite to use when the control is highlighted Pressed Sprite Sprite to use when the control is pressed Disabled Sprite Sprite to use when the control is disabled Animation Property: Function: Normal Trigger The normal animation trigger to use Highlighted Trigger Trigger to use when the control is highlighted Pressed Trigger Trigger to use when the control is pressed Disabled Trigger Trigger to use when the control is disabled"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Shadow.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Shadow.html",
    "title": "Shadow | Inventory System",
    "summary": "Shadow The Shadow component adds a simple outline effect to graphic components such as Text or Image. It must be on the same GameObject as the graphic component. Properties Property: Function: Effect Color The color of the shadow. Effect Distance The offset of the shadow expressed as a vector. Use Graphic Alpha Multiplies the color of the graphic onto the color of the effect."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Slider.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Slider.html",
    "title": "Slider | Inventory System",
    "summary": "Slider The Slider control allows the user to select a numeric value from a predetermined range by dragging the mouse. Note that the similar ScrollBar control is used for scrolling rather than selecting numeric values. Familiar examples include difficulty settings in games and brightness settings in image editors. Properties Property: Function: Interactable Will this component accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Fill Rect The graphic used for the fill area of the control. Handle Rect The graphic used for the sliding \"handle\" part of the control Direction The direction in which the slider's value will increase when the handle is dragged. The options are Left To Right, Right To Left, Bottom To Top and Top To Bottom. Min Value The value of the slider when the handle is at its extreme lower end (determined by the Direction property). Max Value The value of the slider when the handle is at its extreme upper end (determined by the Direction property). Whole Numbers Should the slider be constrained to integer values? Value Current numeric value of the slider. If the value is set in the inspector it will be used as the initial value, but this will change at runtime when the value changes. Events Property: Function: On Value Changed A UnityEvent that is invoked when the current value of the Slider has changed. The event can send the current value as a float type dynamic argument. The value is passed as a float type regardless of whether the Whole Numbers property is enabled. Details The value of a Slider is determined by the position of the handle along its length. The value increases from the Min Value up to the Max Value in proportion to the distance the handle is dragged. The default behaviour is for the slider to increase from left to right but it is also possible to reverse this behavior using the Direction property. You can also set the slider to increase vertically by selecting Bottom To Top or Top To Bottom for the Direction property. The slider has a single event called On Value Changed that responds as the user drags the handle. The current numeric value of the slider is passed to the function as a float parameter. Typical use cases include: Choosing a level of difficulty in a game, brightness of a light, etc. Setting a distance, size, time or angle."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-StandaloneInputModule.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-StandaloneInputModule.html",
    "title": "Standalone Input Module | Inventory System",
    "summary": "Standalone Input Module The module is designed to work as you would expect a controller / mouse input to work. Events for button presses, dragging, and similar are sent in response to input. The module sends pointer events to components as a mouse / input device is moved around, and uses the Graphics Raycaster and Physics Raycaster to calculate which element is currently pointed at by a given pointer device. You can configure these raycasters to detect or ignore parts of your Scene, to suit your requirements. The module sends move events and submit / cancel events in response to Input tracked via the Input window. This works for both keyboard and controller input. The tracked axis and keys can be configured in the module's inspector. Properties Property: Function: Horizontal Axis Type the desired manager name for the horizontal axis button. Vertical Axis Type the desired manager name for the vertical axis. Submit Button Type the desired manager name for the Submit button. Cancel Button Type the desired manager name for the Cancel button. Input Actions Per Second Number of keyboard/controller inputs allowed per second. Repeat Delay Delay in seconds before the input actions per second repeat rate takes effect. Force Module Active Enable this property to force this Standalone Input Module to be active. Details The module uses: Vertical / Horizontal axis for keyboard and controller navigation Submit / Cancel button for sending submit and cancel events Has a timeout between events to only allow a maximum number of events a second. The flow for the module is as follows Send a Move event to the selected object if a valid axis from the Input window is entered Send a submit or cancel event to the selected object if a submit or cancel button is pressed Process Mouse input If it is a new press Send PointerEnter event (sent to every object up the hierarchy that can handle it) Send PointerPress event Cache the drag handler (first element in the hierarchy that can handle it) Send BeginDrag event to the drag handler Set the 'Pressed' object as Selected in the event system If this is a continuing press Process movement Send DragEvent to the cached drag handler Handle PointerEnter and PointerExit events if touch moves between objects If this is a release Send PointerUp event to the object that received the PointerPress If the current hover object is the same as the PointerPress object send a PointerClick event Send a Drop event if there was a drag handler cached Send a EndDrag event to the cached drag handler Process scroll wheel events"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Text.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Text.html",
    "title": "Text | Inventory System",
    "summary": "Text The Text control displays a non-interactive piece of text to the user. This can be used to provide captions or labels for other GUI controls or to display instructions or other text. Properties Property: Function: Text The text displayed by the control. Character Font The Font used to display the text. Font Style The style applied to the text. The options are Normal, Bold, Italic and Bold And Italic. Font Size The size of the displayed text. Line Spacing The vertical separation between lines of text. Rich Text Should markup elements in the text be interpreted as Rich Text styling? Paragraph Alignment The horizontal and vertical alignment of the text. Align by Geometry Use the extents of glyph geometry to perform horizontal alignment rather than glyph metrics. Horizontal Overflow The method used to handle the situation where the text is too wide to fit in the rectangle. The options are Wrap and Overflow. Vertical Overflow The method used to handle the situation where wrapped text is too tall to fit in the rectangle. The options are Truncate and Overflow. Best Fit Should Unity ignore the size properties and simply try to fit the text to the control's rectangle? Color The color used to render the text. Material The Material used to render the text. A default text element looks like this: Details Some controls (such as Buttons and Toggles) have textual descriptions built-in. For controls that have no implicit text (such as Sliders), you can indicate the purpose using a label created with a Text control. Text is also useful for lists of instructions, story text, conversations and legal disclaimers. The Text control offers the usual parameters for font size, style, etc, and text alignment. When the Rich Text option is enabled, markup elements within the text will be treated as styling information, so you can have just a single word or short section in boldface or in a different color, say (see the page about Rich Text for details of the markup scheme). Hints See the Effects page for how to apply a simple shadow or outline effect to the text."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Toggle.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-Toggle.html",
    "title": "Toggle | Inventory System",
    "summary": "Toggle The Toggle control is a checkbox that allows the user to switch an option on or off. Properties Property: Function: Interactable Will this component will accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Is On Is the toggle switched on from the beginning? Toggle Transition The way the toggle reacts graphically when its value is changed. The options are None (ie, the checkmark simply appears or disappears) and Fade (ie, the checkmark fades in or out). Graphic The image used for the checkmark. Group The Toggle Group (if any) that this Toggle belongs to. Events Property: Function: On Value Changed A UnityEvent that is invoked when the Toggle is clicked. The event can send the current state as a bool type dynamic argument. Details The Toggle control allows the user to switch an option on or off. You can also combine several toggles into a Toggle Group in cases where only one of a set of options should be on at once. The Toggle has a single event called On Value Changed that responds when the user changes the current value. The new value is passed to the event function as a boolean parameter. Typical use cases for Toggles include: Switching an option on or off (eg, playing music during a game). Letting the user confirm they have read a legal disclaimer. Choosing one of a set of options (eg, a day of the week) when used in a Toggle Group. Note that the Toggle is a parent that provides a clickable area to children. If the Toggle has no children (or they are disabled) then it is not clickable."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ToggleGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-ToggleGroup.html",
    "title": "Toggle Group | Inventory System",
    "summary": "Toggle Group A Toggle Group is not a visible UI control but rather a way to modify the behavior of a set of Toggles. Toggles that belong to the same group are constrained so that only one of them can switched on at a time - pressing one of them to switch it on automatically switches the others off. Properties Property: Function: Allow Switch Off Is it allowed that no toggle is switched on? If this setting is enabled, pressing the toggle that is currently switched on will switch it off, so that no toggle is switched on. If this setting is disabled, pressing the toggle that is currently switched on will not change its state. Description The Toggle Group is setup by dragging the Toggle Group object to the Group property of each of the Toggles in the group. Toggle Groups are useful anywhere the user must make a choice from a mutually exclusive set of options. Common examples include selecting player character types, speed settings (slow, medium, fast, etc), preset colors and days of the week. You can have more than one Toggle Group object in the scene at a time, so you can create several separate groups if necessary. Unlike other UI elements, an object with a Toggle Group component does not need to be a child of a Canvas object, although the Toggles themselves still do. Note that the Toggle Group will not enforce its constraint right away if multiple toggles in the group are switched on when the scene is loaded or when the group is instantiated. Only when a new toggle is swicthed on are the others switched off. This means it's up to you to ensure that only one toggle is switched on from the beginning."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-TouchInputModule.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-TouchInputModule.html",
    "title": "Touch Input Module | Inventory System",
    "summary": "Touch Input Module Note: TouchInputModule is obsolete. Touch input is now handled in StandaloneInputModule. This module is designed to work with touch devices. It sends pointer events for touching and dragging in response to user input. The module supports multitouch. The module uses the scene configured Raycasters to calculate what element is currently being touched over. A raycast is issued for each current touch. Properties Property: Function: Force Module Active Forces this module to be active. Details The flow for the module is as follows: For each touch event If it is a new press Send PointerEnter event (sent to every object up the hierarchy that can handle it) Send PointerPress event Cache the drag handler (first element in the hierarchy that can handle it) Send BeginDrag event to the drag handler Set the 'Pressed' object as Selected in the event system If this is a continuing press Process movement Send DragEvent to the cached drag handler Handle PointerEnter and PointerExit events if touch moves between objects If this is a release Send PointerUp event to the object that received the PointerPress If the current hover object is the same as the PointerPress object send a PointerClick event Send a Drop event if there was a drag handler cached Send a EndDrag event to the cached drag handler"
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-VerticalLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/script-VerticalLayoutGroup.html",
    "title": "Vertical Layout Group | Inventory System",
    "summary": "Vertical Layout Group The Vertical Layout Group component places its child layout elements on top of each other. Their heights are determined by their respective minimum, preferred, and flexible heights according to the following model: The minimum heights of all the child layout elements are added together and the spacing between them is added as well. The result is the mimimum height of the Vertical Layout Group. The preferred heights of all the child layout elements are added together and the spacing between them is added as well. The result is the preferred height of the Vertical Layout Group. If the Vertical Layout Group is at its minimum height or smaller, all the child layout elements will also have their minimum height. The closer the Vertical Layout group is to its preferred height, the closer each child layout element will also get to their preferred height. If the Vertical Layout Group is taller than its preferred height, it will distribute the extra available space proportionally to the child layout elements according to their respective flexible heights. For more information about minimum, preferred, and flexible height, see the documentation on Auto Layout. Properties Property: Function: Padding The padding inside the edges of the layout group. Spacing The spacing between the layout elements. Child Alignment The alignment to use for the child layout elements if they don't fill out all the available space. Control Child Size Whether the Layout Group controls the width and height of its child layout elements. Use Child Scale Whether the Layout Group considers the scale of its child layout elements when sizing and laying out elements. Width and Height correspond to the Scale > X and Scale > Y values in each child layout element's Rect Transform component. You cannot animate the Scale values using the Animator Controller Child Force Expand Whether to force the child layout elements to expand to fill additional available space."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/ugui.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/Documentation~/ugui.html",
    "title": "About Unity UI | Inventory System",
    "summary": "About Unity UI Unity UI is a UI toolkit for developing user interfaces for games and applications. It is a GameObject-based UI system that uses Components and the Game View to arrange, position, and style user interfaces. You cannot use Unity UI to create or change user interfaces within the Unity Editor. Installing Unity UI Unity UI is a core package. A version of it is included in each Unity release. To remove this package, or reinstall it after removal, follow the instructions in the Package Manager documentation. Getting documentation User documentation The Unity UI user documentation is in the Unity Manual. It provides a basic overview of the available components, and a few how-tos. API documentation You can find Class descriptions and API compatibility information in the Scripting API section of this documentation. Getting support For questions and assistance, visit the Unity UI section of the Unity Forum."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/LICENSE.html",
    "title": "| Inventory System",
    "summary": "Unity UI Copyright © 2015-2020 Unity Technologies ApS (\"Unity\") Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). _Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/README.html": {
    "href": "Library/PackageCache/com.unity.ugui@a0f5d16b3c82/README.html",
    "title": "Unity UI | Inventory System",
    "summary": "Unity UI The Unity UI package allows you to create in-game user interfaces fast and intuitively. Prerequisites Unity 2019.2 This package is in development, and requires Unity 2019.2. Getting Started The Unity UI user manual can be found here."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/CHANGELOG.html",
    "title": "Changelog | Inventory System",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog [1.9.7] - 2025-05-22 Fixed Fixed a warning \"Unable to load Unity.Android.Gradle's referenced assembly NiceIO\" when scanning assemblies. UVSB-2594 Fixed error when trying to load fuzzy finder on multi screen setup on Mac. UVSB-2419 Fixed the AOTSafeMode project setting appearing in the Editor Preferences window. It is now shown in the Project Settings tab for Visual Scripting. UVSB-2590 Fixed possible crash on VisionOS. UVSB-2565 Changed The AOTSafeMode project setting has been marked as not visible, it will no longer be included when calling ConfigurationPanel.GetSearchKeywords. UVSB-2590 [1.9.6] - 2025-03-05 Fixed Fixed the output path for Property Providers generated from User Editor code. UVSB-2550 Fixed a minor spelling issue in the Project Settings section UVSB-2523 Fixed an unexpected MissingComponentException thrown when using GetOrAddComponent UVSB-2575 Fixed scenes not reopening after a Build when more than one Scene was opened and Visual Scripting with variables is used. UVSB-2561 Fixed values of LocalizedAudioClip type being shown as None after selecting another game object and returning back UVSB-2528 Fixed a compilation issue that happened when a project had another version of NCalc already installed. UVSB-2583 Fixed an 'AudioMixerController' is inaccessible due to its protection level' error thrown when generating the AotStubs. UVSB-2577 Fixed compilation error when AotStubs references Unity.NetworkManager.__rpc_func_table and Unity.NetworkManager.__rpc_name_table fields UVSB-2563 Changed Improved the warning message when a library fails to load while scanning for Editor assemblies. [1.9.5] - 2024-10-24 Fixed Fixed \"NullReferenceException\" error when returning to the State Graph from the Script Graph. UVSB-1905 Fixed compilation error when a graph contains a reference to a method with an \"in\" parameter. UVSB-2544 Added missing truncate function to Formula node UVSB-2526 Fixed an error when creating a Script Graph asset in an empty project Changed Updated deprecated EditorAnalytics APIs to new ones [1.9.4] - 2024-04-08 Fixed Fixed sqlite dll changes not being recognized correctly by the 2022.3 Unity Editor [1.9.3] - 2024-03-19 Fixed Fixed errors related to the sqlite dll when using the Windows ARM64 Editor Favorites are now kept when entering play mode UVSB-2519 Fixed continuous input when using an OnInputSystemEventVector2 node with OnHold UVSB-2518 [1.9.2] - 2023-10-30 Fixed Fixed a bug where the second player input device controlled all objects when using InputSystem event nodes UVSB-2499 Documentation links have been fixed for Visual Scripting MonoBehaviours UVSB-2475 UVSB-2496 Changed AnimationEvent and NamedAnimationEvent Nodes icon changed in favor of the AnimationClip icon instead of the Animation Component icon. [1.9.1] - 2023-08-15 Fixed Reverted a breaking change where LudiqScriptableObject._data was marked as private Reverted a breaking change related to IGraphEventListener [1.9.0] - 2023-08-01 Fixed Fixed code for custom nodes being stripped in AOT builds when Managed Stripping Level is set to High UVSB-2439 Fixed OnInputSystemEvent doesn't trigger until Input Vector variates from 0.5 UVSB-2435 Fixed assembly disappearing from Node Library after domain reload. UVSB-2459 Fixed custom inspectors not being generated UVSB-2466 Fixed error when trying to load exceptions for TryCatch node dropdown UVSB-2463 Fixed infinite amount of GameObjects created in Prefab mode when performing a null check of a scene variable in editor with an OnDrawGizmos event UVSB-2453 Removed corrupt mdb which caused the ScriptUpdater to fail UVSB-2360 Fixed Gradient graph variables resetting when entering PlayMode UVSB-2334 Fixed Memory leak after destroying object UVSB-2427 Fixed migration deserialization bug introduced in 1.8.0 UVSB-2492 Added Added a warning icon next to assemblies in Project Settings that reference Editor assemblies UVSB-2382 Changed Script Graph Asset string data is unloaded after deserialization UVSB-2366 AOT Prebuild should take less memory and be faster (Added an optimization to AssetUtility.GetAllAssetsOfType<T>) UVSB-2417 [1.8.0] - 2022-11-03 Fixed Fixed graphs being corrupted on deserialization if containing a node whose type cannot be found. UVSB-2332 For nodes that support a default parameter for each of their inputs, detect and fix parameter renames UVSB-1885 Fixed the problem that was preventing link.xml creation when building for Mono backend UVSB-2348 Moved Events/MessageListeners files to a Listeners folder to avoid to exceed some OS path limit Fixed Grandient.mode serialization. Fix available for Unity 2021.3.9f1 or newer UVSB-2356 Fixed Visual Scripting settings now only save to disk when modified Fixed sub graphs being shown with broken connections on first load as of Unity 2021.2 UVSB-2345 Fixed documentation links for Script Graph and State Graphs assets UVSB-2422 Added Added confirmation popup when resetting project settings and editor preferences. UVSB-2353 Added confirmation popup when resetting assemblies/types in project settings. Added Sticky Note for ScriptGraph and StateGraph. Nodes may now have a button which triggers a custom action in their inspector description. Nodes whose type cannot be found are now temporarily converted to dummy nodes until either their original type is defined again or the user replaces them. Support for parameter renaming in code used by API nodes Changed AOTStubs are now generated for all nodes regardless of whether they represent a runtime or editor member UVS-2381 Increased zoom out distance in graphs. [1.7.8] - 2022-02-22 Fixed Handle ReflectionTypeLoadException for TypeUtility to remove warning BOLT-1900 Fixed drag inconsistency in Graph Variables BOLT-2113 Fixed exception after creating a graph from the Welcome Window on Linux BOLT-1828 Fixed the Cooldown node not becoming \"Ready\" when the \"Reset\" port is triggered Fixed exception thrown after changing Hierarchy selection after removing Saved variable BOLT-1919 Fixed old Bolt saved variables not loading when using a build created using a newer version of Visual Scripting BOLT-2052 Fixed a performance issue when using lots of Get/Set Scene variable nodes in an open graph Fixed zooming out in the Graph to be relative to the mouse cursor BOLT-1667 Fixed a compilation error when migrating from Visual Scripting 1.7.6 to 1.7.7 with InputSystem-1.1.1 or below installed. Fixed a performance issue when using lots of Get/Set Scene variable nodes in an open graph Fixed default inspectors for nodes not appearing in the correct position after a connected node is deleted BOLT-1457 Fixed Scene variables drag and drop in graph having wrong scope BOLT-2247 OnDestroy events are now properly triggered in script graphs BOLT-1783 Changed Small optimization of load times involving generic types. Renamed ContinuousNumberDrawer.cs.cs to ContinuousNumberDrawer.cs BOLT-2288 Added TextMeshPro assembly is now added by default in Project Settings/Visual Scripting/Node Library Added highlight to new VS graph drop down items BOLT-2205 Added margins to the UI for project settings and editor preferences [1.7.7] - 2021-11-23 Fixed Fix an NullException error that occurs when creating a Variable right after project initialization. Fix Visual scripting naming in Project Settings and listener. Scene is marked as dirty when a graph is created on a new or exiting GameObject BOLT-1860 Fix Flow Variables missing icon Improved node regeneration speed Fix null texture error when switching platform after a build failure Fix null texture error when entering play mode Fix Linux build failing when run from command line Fix Editor Assemblies not detected correctly at Codebase initialization Fix Wait nodes naming inconsistency BOLT-1886 Fix constant being stripped in IL2CPP builds BOLT-1638 TryConvert now returns true when the conversion was successful BOLT-2105 Fix Input system by using correct Input API BOLT-2078 [1.7.6] - 2021-11-05 Fixed Fixed a regression where AOT Stubs were not being generated correctly, causing AOT builds to fail when run. [1.7.5] - 2021-08-30 Changed Removed unused Preferences Renamed preference \"Update Units Automatically\" to \"Update Nodes Automatically\" Reduced domain reload performance cost of visual scripting to 1ms or less when not actively used by a project Fixed Fixed an issue where uncaught exceptions were thrown in Debug builds of the Windows editor Fixed the missing arrow when the \"Transition End Arrow\" is on. BOLT-1535 Fixed wrong graph is showed after creating script graph form selected object in \"Welcome Screen\" Fixed duplicate variable error. BOLT-1569 Fixed 'ReadOnlySpan<>' does not exist in the namespace 'System'\" error with AOT build. BOLT-1648 Fixed jitter when the fuzzy window is on the bottom of the screen and the user scrolls BOLT-1530 Fixed missing AOT prebuild step when building an IL2CPP project in batchmode BOLT-1649 Restored a public icon set API in UnitPortDescription.cs that was by mistake Fixed il2cpp crash caused by a recursion of the machine states in itself when AOTstubs is generating.BOLT-1656 [1.7.3] - 2021-06-30 Changed Removed unused Preferences Renamed preference \"Update Units Automatically\" to \"Update Nodes Automatically\" Fixed Fixed an issue where uncaught exceptions were thrown in Debug builds of the Windows editor Fixed custom units not appearing in the finder [1.7.2] - 2021-05-17 Changed NotEquals node in non-scalar mode is now consistent with Equals Fixed Fixed long values not preserved in literal nodes. Fixed root icons in breadcrumbs in the graph editor window. BOLT-1290 Fixed graph nodes icons Fixed project settings will not show when looking for graphs Fixed exception when user double clicks on a graph Raise warnings at edit time when a MouseEvent node is used when targeting handheld devices instead of build time. [1.7.1] - 2021-05-07 Removed For performance reasons, the BackgroundWorker attribute is now obsolete and won't have any effect. Use BackgroundWorker.Schedule() directly Changed Renamed the VSSettingsProvider assembly to Unity.VisualScripting.SettingsProvider.Editor Variables Saver GameObject no longer appears until a variable is created or changed. BOLT-1343 Renamed Singleton GameObjects created by Visual Scripting to use \"VisualScripting ---\" names. All internal plugin and product versions have been normalized to use the package version. NotEquals node in non-scalar mode is now consistent with Equals SuperUnits have been renamed into Subgraphs No longer have a hard dependency on any of the following built-in modules: ai, animation, particlesystem, physics, physics2d ScriptMachine is now displayed as \"Script Machine\" instead of \"Flow Machine\" in the Gizmo window. Update, Start, Fixed Update and Late Update nodes have been renamed into On Update, On Start, On Fixed Update and On Late Update. Moved project settings from Assets directory to the ProjectSettings directory in Unity projects Renamed control schemes to Default/Alternate The UI references to 'Unit' were changed to 'Node' without any change to the underlying types Nodes from Timeline, Cinemachine and InputSystem packages are now automatically included, with their assemblies part of the default assemblyOptions. Progress bar titles for initial node generation have been tweaked to better indicate that it is a one-time process Various optimizations to reduce the duration of domain reloads Added Added workflows to create new graphs directly from the Graph Window SetScriptGraph node SetStateGraph node Support for RenamedFrom attribute on enum members GetStateGraphs node GetScriptGraphs node GetScriptGraph node GetStateGraph node HasStateGraph node HasScriptGraph node Fixed Fixed the problem were on Linux the fuzzy window would remains above all others. BOLT-1197 There is no more crash when the user navigates quickly between fuzzy finder levels on Linux BOLT-1197 Fixed variable type turns to null when clicked outside of the graph Fixed rearranging variables, if type is not set, it sets to the type that is bellow it Lots of miscellaneous migration fixes and quality of life changes Fixed unexpected error when exceptions are thrown by flow graph units and caught by the TryCatch unit BOLT-1392 [1.6.1] - 2021-03-30 Fixed Fixed bug caused by Editor API transitioning from private to public [1.6.0] - 2021-03-23 Changed Updated graph migration process [1.5.2] - 2021-03-05 Changed User interface updated Names in different UI elements made to be more consistent with new naming schemes [1.5.1] - 2021-02-23 Added Warn the user when an Input System Package event is referencing an action of the wrong type for that event A warning is raised when adding more than one Input unit in a SuperUnit \"Open\" inspector button and double clicking a graph in the project browser now opens the visual scripting editor A warning is raised when the step's default value of the For unit is set to 0. Fixed Fixed \"Restore to Defaults\" buttons in the Project Settings window Fixed ThreadAbortException when entering Play Mode while searching in the Fuzzy Finder Fixed Visual Scripting Preferences being searchable BOLT-1218 Fixed ScalarAdd unit migration from 1.4.13 to 1.4.14 and above Fixed Open the graph window no longer causes Unity UI to stop processing mouse clicks\" BOLT-1159, Fixed Fuzzy finder no longer blinks when trying to add a node BOLT-1157, Fixed Fuzzy search no longer drops keyboard inputs and respond slowly BOLT-1214, Fixed Fuzzy finder search window no longer remains above all other windows BOLT-1197\" Fixed Dropdown icon is not clipped with TextField under \"Get Variable\" Fixed Scale groups when zoom is not at 1x Fixed graph getting corrupted when adding \"Get Action Map\" unit Fixed node description being sometimes clipped Fixed warnings overflow in the console when deleting and adding a boolean variable in the blackboard Fixed warnings when entering play mode when the \"Script Changes While Playing\" is set to Recompile And Continue Playing Fixed resize cursor rect on group when graph window is zoomed Fixed VisualScripting.Generated folder is removed when removing the VisualScripting package. Fixed error when executing \"Fix Missing Scripts\" in a HDRP project Visual Scripting Preferences spacing has been adjusted to avoid overlaps Fixed rendering of inactive ObjectFields Fixed sidebar (graph inspector/blackboard) resize when a vertical scrollbar is needed Fixed variable type reset to Enum when changing from Enum to GameObject when both Blackbaord and Variables inspector are displayed Help button in the visual scripting Assets and Behaviours inspector now link to the package documentation. FlowMachine type is now back in usable types. Fixed GraphPointerException occurs when nesting graph within itself BOLT-1257 Fixed RenamedFrom attribute does not function correctly on array references to a renamed type BOLT-1149 Fixed error message when custom inspectors are generated Fixed missing succession for Cooldown. Output of Cooldown completed is treated as unentered. BOLT-725 Fixed infinite loop when setting the For unit's step's default value to 0. Instead, the unit won't be executed and the exit output will be triggered directly. Fixed Object Variables tabs not updated when creating a Prefab Fixed console errors when deleting a Prefab with a Visual Script Fixed console errors when editing nested graphs during Play Mode Fixed console errors when opening the standalone profiler window [1.5.1-pre.5] - 2021-01-20 Changed Removed code referring to an unused SceneManagement.PrefabStage API [1.5.1-pre.3] - 2020-12-07 Added Added Visual Scripting as built-in package as of Unity 2021.1 Added New Input System Support. You can import the Input System package, activate the back-end and regenerate units to use. Added AOT Pre-Compile to automatically run when building AOT platforms Improved UI for deprecated built-in nodes Added automatic unit generation the first time the graph window is opened Changed Switched to delivering source instead of pre-built .NET 3/4 assemblies Updated Documentation Renamed assemblies to match Unity.VisualScripting naming scheme (Ex: Bolt.Core -> Unity.VisualScripting.Core) Merged Ludiq.Core and Ludiq.Graphs into Unity.VisualScripting.Core Moved Setup Wizard contents from pop-up on Editor startup to Player Settings. You can change the default settings from \"Player Settings > Visual Scripting\" Renamed \"Assembly Options\" to \"Node Library\" Renamed \"Flow Graph\" to \"Script Graph\" Renamed \"Flow Machine\" to \"Script Machine\" Renamed \"Macro\" graphs to \"Graph\" in machine source configuration and \"GraphAsset\" in Assets Renamed \"Control Input/Output\" to \"Trigger Input/Output\" Renamed \"Value Input/Output\" to \"Data Input/Output\" Updated built-in nodes. The Fuzzy Finder still accepts earlier version names of nodes. Renamed \"Branch\" node to \"If\" Renamed \"Self\" node to \"This\" Deprecated the previous Add unit. The Sum unit has been renamed to Add. Updated Window Naming Changed \"Variables\" window to \"Blackboard\" Changed \"Graph\" window to \"Script Graph\" and \"State Graph\" Updated Bolt Preferences Renamed Bolt Preferences to \"Visual Scripting\" Removed BoltEx Moved settings previously accessed from \"Window > Bolt\" to preferences Renamed Control Schemes from \"Unity/Unreal\" to \"Default/Alternate\" (Neither control scheme currently matches their respective editors' controls and will be updated in a future release) Consolidated Graph editor, Blackboard and Graph Inspector into a single window Updated Third-Party Notices Plugin version information has been removed from the Visual Scripting settings window. This information can be retrieved from the Package Manager. Fixed Corrected UGUI event management to trickle down correctly when the hierarchy contains a Unity Message Listener BOLT-2 Fixed backup failures with large projects BOLT-10 Fixed \"Null Reference\" when opening the Graph Window for the first time BOLT-996 Fixed IL2CPP build crash on startup BOLT-1036 Fixed IL2CPP issue around converting certain managed types BOLT-8 Fixed deserialization issues when undoing graphs with Wait nodes BOLT-679 Fixed \"SelectOnEnum\" node behavior enums containing non-unique values e.g. \"RuntimePlatform\" BOLT-688"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/TableOfContents.html",
    "title": "| Inventory System",
    "summary": "About Visual Scripting *Configure project settings *[Add or remove available nodes](vs-add-remove-node-library.md) *[Add or remove types](vs-add-remove-type-options.md) *[Create or restore a backup](vs-create-restore-backups.md) *Choose a control scheme *Configure your preferences *Update Visual Scripting *Version control systems *Use Visual Scripting with Unity Cloud Build Basic concepts in Visual Scripting *The interface *Nodes *Graphs *[Subgraphs and State Units](vs-nesting-subgraphs-state-units.md) *[Transitions](vs-transitions.md) *Script Machines and State Machines *Object types *[Custom types](vs-custom-types.md) *Variables Develop application logic with Script Graphs *Create a new graph file *[Create a new blank graph with the Project window](vs-create-graph-project-window.md) *[Create a new unassigned graph with the empty graph creation flow](vs-create-graph-unassigned-flow.md) *[Create and assign a graph to an existing GameObject](vs-create-graph-assign-existing-gameobject.md) *[Create and assign a graph to a new GameObject](vs-create-graph-assign-new-gameobject.md) *[Create a graph on a Script Machine or State Machine](vs-create-graph-on-machine.md) *Attach a graph file to a Script Machine or State Machine *Open a graph file *[Add a node to a Script Graph](vs-add-node-to-graph.md) *[Connect nodes in a Script Graph](vs-creating-connections.md) *[Create and add a variable to a Script Graph](vs-add-variable-graph.md) *[Create node groups](vs-groups.md) *[Add comments to a graph](vs-sticky-notes.md) *Add a Subgraph to a Script Graph *[Add a Trigger or Data port to a Script Graph](vs-nesting-add-triggers-data-graph.md) *Add a State Unit to a Script Graph *Custom Events *[Add a Custom Event node](vs-add-custom-event-node.md) *[Add a Trigger Custom Event node](vs-add-custom-event-node-trigger.md) *Capture user input in an application *[Capture input using the Input Manager](vs-capturing-player-inputs-old.md) *[Add and configure a Player Input component](vs-capture-player-input-add-component.md) *[Capture input using the Input System package](vs-capturing-player-inputs-new.md) *Use relations to debug *[Predictive and live debugging](vs-debugging.md) *[Working with debug messages](vs-debug-messages.md) *Live edit *[Live edit during runtime](vs-live-edit-runtime.md) Develop logic transitions with state graphs *Create a new state *Create a transition between states Advanced customization and development *Refactor a C# script with Visual Scripting *[Add the RenamedFrom attribute to a C# script](vs-refactor-add-attribute.md) *Custom C# nodes *[Create a new simple Custom C# node](vs-create-custom-node-empty.md) *[Add ports to your Custom C# node](vs-create-custom-node-add-ports.md) *[Add logic to your Custom C# node](vs-create-custom-node-add-logic.md) *[Add relations to your Custom C# node](vs-create-custom-node-add-relations.md) *[Add documentation to your Custom C# node](vs-create-custom-node-add-docs.md) *[Custom C# node attributes reference](vs-create-custom-node-attributes-reference.md) *Create a Custom Scripting Event node *[Create a Custom Scripting Event Sender node](vs-create-own-custom-event-send-node.md) *[Trigger a Custom Scripting Event from a C# script](vs-create-own-custom-event-node-trigger-code.md) *[Listen to a Custom Scripting Event from a C# script](vs-create-own-custom-event-listen-code.md) *Use a custom type *[Add the Inspectable attribute to a custom type](vs-add-inspectable-attribute-custom-types.md) *[Create a custom PropertyDrawer for a custom type](vs-create-custom-drawer.md) Node reference *This node *Control node *Time node *Events *[Event nodes](vs-events-reference.md) *[Input Event nodes](vs-input-nodes.md) *[On Input System Event Button](vs-nodes-events-input-system-button.md) *[On Input System Event Float](vs-nodes-events-input-system-float.md) *[On Input System Event Vector 2](vs-nodes-events-input-system-vector2.md) *[On Button Input](vs-nodes-events-on-button-input.md) *[On Keyboard Input](vs-nodes-events-on-keyboard-input.md) *[On Mouse Down](vs-nodes-events-on-mouse-down.md) *[On Mouse Drag](vs-nodes-events-on-mouse-drag.md) *[On Mouse Enter](vs-nodes-events-on-mouse-enter.md) *[On Mouse Exit](vs-nodes-events-on-mouse-exit.md) *[On Mouse Input](vs-nodes-events-on-mouse-input.md) *[On Mouse Over](vs-nodes-events-on-mouse-over.md) *[On Mouse Up As Button](vs-nodes-events-on-mouse-up-button.md) *[On Mouse Up](vs-nodes-events-on-mouse-up.md) *Variable node *Nulls node *Formula node *Nesting *[Input node](vs-nesting-input-node.md) *[Output node](vs-nesting-output-node.md) *[State Unit node](vs-nesting-state-unit-node.md) *[Subgraph node](vs-nesting-subgraph-node.md) *Script graph nodes *State graph nodes Developer's guide Known Issues"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/index.html",
    "title": "About Visual Scripting | Inventory System",
    "summary": "About Visual Scripting Use Visual Scripting to create logic for games or applications without hand-coded C# scripts. Visual Scripting uses visual, node-based graphs, which both programmers and non-programmers use to design final logic or create prototypes. Visual Scripting also has an API that programmers can use for more advanced tasks, or to create custom nodes for other team members. Visual Scripting nodes can represent functions, operators, and variables. Connect these nodes from their ports with edges to design your logic visually. Installation Starting from Unity 2021 LTS onward, Visual Scripting is installed as a package in all new projects. For more information on packages, see the Packages section in the Unity User Manual. For earlier versions of Unity, Visual Scripting was available on the Asset Store, but that option has been deprecated. Configure Visual Scripting Note To use Visual Scripting in a project for the first time, you must initialize it from the Editor's Project Settings window. To get started with Visual Scripting, configure your project settings and configure your preferences. Choose a control scheme Learn about the common keyboard shortcuts and choose the control scheme that suits your needs. Update Visual Scripting Learn how to update Visual Scripting and create and restore backups. System requirements Visual Scripting has no external dependencies."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-ff-add-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-ff-add-node.html",
    "title": "ff-add-node | Inventory System",
    "summary": "Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-open-graph-w-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-open-graph-w-node.html",
    "title": "open-graph-w-node | Inventory System",
    "summary": "Open a Script Graph where you've already added your node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-tasks-note-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-c-nodes/vs-tasks-note-end.html",
    "title": "vs-tasks-note-end | Inventory System",
    "summary": "The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-events/vs-right-click-project.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-events/vs-right-click-project.html",
    "title": "right-click-project | Inventory System",
    "summary": "Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-events/vs-tasks-note-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/custom-events/vs-tasks-note-end.html",
    "title": "tasks-note-end | Inventory System",
    "summary": "The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-desc-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-desc-end.html",
    "title": "nodes-desc-end | Inventory System",
    "summary": "It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-input-output-trigger.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-input-output-trigger.html",
    "title": "nodes-input-output-trigger | Inventory System",
    "summary": "Trigger Output Trigger The control output port. Make a connection to specify what Visual Scripting should do after the configured Input event occurs in your application."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-note-manual.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-manager/nodes-note-manual.html",
    "title": "nodes-note-manual | Inventory System",
    "summary": "node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-action-change.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-action-change.html",
    "title": "nodes-input-action-change | Inventory System",
    "summary": "Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-system-output-trigger-port.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-system-output-trigger-port.html",
    "title": "nodes-input-system-output-trigger-port | Inventory System",
    "summary": "Trigger Output Trigger The control output port. Make a connection to specify what Visual Scripting does after the configured Player Input event, such as a button press, occurs in the application."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-system-ports.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-input-system-ports.html",
    "title": "nodes-input-system-ports | Inventory System",
    "summary": "Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-note-package.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/input-system/nodes-note-package.html",
    "title": "nodes-note-package | Inventory System",
    "summary": "is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-additional-settings.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-additional-settings.html",
    "title": "nodes-additional-settings | Inventory System",
    "summary": "node has additional settings. Access these settings from the Graph Inspector:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-controls.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-controls.html",
    "title": "nodes-controls | Inventory System",
    "summary": "node has the following controls:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-coroutine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-coroutine.html",
    "title": "nodes-coroutine | Inventory System",
    "summary": "Coroutine Toggle Enable Coroutine if you want Visual Scripting to run this node and any of its connected nodes as a coroutine. Coroutine nodes don't execute all their code in a single frame, so they can spread an effect over several frames. Coroutines can also help optimize your code. For more information on coroutines, see the Unity User Manual section on Coroutines."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-inputs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-inputs.html",
    "title": "nodes-inputs | Inventory System",
    "summary": "node has the following input ports:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-outputs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-outputs.html",
    "title": "nodes-outputs | Inventory System",
    "summary": "node has the following output ports:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-related.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-related.html",
    "title": "nodes-related | Inventory System",
    "summary": "The following nodes are related or similar to the"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-control.html",
    "title": "nodes-single-control | Inventory System",
    "summary": "node has one control:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-input.html",
    "title": "nodes-single-input | Inventory System",
    "summary": "node has one input port:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-output.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/nodes-single-output.html",
    "title": "nodes-single-output | Inventory System",
    "summary": "node has one output port:"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-blackboard-tip.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-blackboard-tip.html",
    "title": "blackboard-tip | Inventory System",
    "summary": "Tip If the Blackboard isn't visible in the Graph window, select Blackboard () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-create-c-script-project.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-create-c-script-project.html",
    "title": "create-c-script | Inventory System",
    "summary": "Go to Create > C# Script."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-graph-inspector-tip-html.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-graph-inspector-tip-html.html",
    "title": "graph-inspector-tip-html | Inventory System",
    "summary": "TIP If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-graph-inspector-tip.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-graph-inspector-tip.html",
    "title": "graph-inspector-tip | Inventory System",
    "summary": "Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-existing-external-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-existing-external-code.html",
    "title": "open-existing-external-code | Inventory System",
    "summary": "Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-fuzzy-finder.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-fuzzy-finder.html",
    "title": "open-fuzzy-finder | Inventory System",
    "summary": "Right-click anywhere in the Graph Editor to open the fuzzy finder."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-graph-inspector.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-graph-inspector.html",
    "title": "open-graph-inspector | Inventory System",
    "summary": "Select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-graph.html",
    "title": "open-graph | Inventory System",
    "summary": "Open a graph file in the Graph window."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-hierarchy-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-hierarchy-window.html",
    "title": "open-hierarchy-window | Inventory System",
    "summary": "Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-inspector-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-inspector-window.html",
    "title": "open-inspector-window | Inventory System",
    "summary": "With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-new-external-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-new-external-code.html",
    "title": "open-new-external-code | Inventory System",
    "summary": "Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-project-settings.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-project-settings.html",
    "title": "open-project-settings | Inventory System",
    "summary": "Go to Edit > Project Settings."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-project-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-project-window.html",
    "title": "open-project-window | Inventory System",
    "summary": "Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-state-menu.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-open-state-menu.html",
    "title": "open-state-menu | Inventory System",
    "summary": "With a State Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the context menu."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-regen-node-library.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-regen-node-library.html",
    "title": "regen-node-library | Inventory System",
    "summary": "Follow the process described in Configure project settings to regenerate your Node Library."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-return-unity.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-return-unity.html",
    "title": "return-unity | Inventory System",
    "summary": "Return to the Unity Editor."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-save-script.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-save-script.html",
    "title": "save-script | Inventory System",
    "summary": "Save your script file."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-visual-scripting-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-visual-scripting-window.html",
    "title": "visual-scripting-window | Inventory System",
    "summary": "Go to Window > Visual Scripting > Visual Scripting Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-with-graph-open-ff.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/snippets/vs-with-graph-open-ff.html",
    "title": "with-graph-open-ff | Inventory System",
    "summary": "With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-custom-event-node-trigger.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-custom-event-node-trigger.html",
    "title": "Add a Custom Event Trigger node | Inventory System",
    "summary": "Add a Custom Event Trigger node You can use a Custom Event Trigger node to trigger a matching Custom Event node in your application. For more information on custom Events, see Custom Events. Note Before you add a Custom Event Trigger node, you must add and configure a Custom Event node in a Script Graph. For more information, see Add a Custom Event node. To add a Custom Event Trigger node to a Script Graph: Open the Script Graph where you want to add a Custom Event Trigger node. This can be the same graph or a different graph from where you added a Custom Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events. Select the Custom Event Trigger node to add it to the graph. In the Name input port's field, enter the name of the Custom Event node you want to trigger, exactly as it appears on the Custom Event node, through one of the following methods: Enter the name in the field next to the Name input port. Attach a node that outputs the name as a string value to the Name input port. In the GameObject field, indicated by the GameObject icon on the node, specify the GameObject that you want to trigger your Event. This doesn't have to be the same GameObject as the Custom Event node. Do one of the following: Select the object picker (circle icon) and select the GameObject. Attach a node to the field's data input port that outputs the GameObject. Leave the field as the default value of This to use the GameObject from your currently open Script Graph's Script Machine. In the Arguments field, enter the number from your Custom Event node's Arguments field. Note All arguments on a Custom Event Trigger node must receive input values, even if the Custom Event node doesn't use those arguments. Otherwise, Visual Scripting displays an error in the Graph Inspector for the Custom Event Trigger node. Next steps You can add more nodes and connect them to create the trigger logic for your Custom Event node in the graph. You can also create a Custom Scripting Event node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-custom-event-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-custom-event-node.html",
    "title": "Add a Custom Event node | Inventory System",
    "summary": "Add a Custom Event node You can add a Custom Event node to a Script Graph to trigger specific logic after an Event occurs. For more information about custom Events, see Custom Events. Note To use a Custom Event node, you must configure the node with the following instructions, then add a Custom Event Trigger node to your graph. For more information on how to add a Custom Event Trigger node, see Add a Custom Event Trigger node To add a Custom Event node to a Script Graph: Open the Script Graph where you want to add a Custom Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events. Select the Custom Event node to add it to your graph. In the GameObject field, indicated by the GameObject icon on the node, choose the GameObject where you want to create the Event. Do one of the following: Select the object picker (circle icon), and select a GameObject. Attach a node to the field's data input port that outputs a GameObject. Leave the field as the default value of This to use the GameObject where you attached your Script Graph to a Script Machine. In the Arguments field, enter the number of arguments you want the custom Event to receive and pass to other nodes in your graph. The default value is 0. If you enter a number greater than 0, Visual Scripting adds the corresponding number of Output ports to the Custom Event node. Note Visual Scripting labels your first argument as Arg. 0. Enter a unique name for the custom Event through one of the following methods: Enter a name in the field next to the Name input port. Attach a node that outputs a string value to the Name input port. In the following example, a custom Event called On Damage returns a single argument when it's triggered in a Script Graph. Next steps After you add a Custom Event node to your graph, add more nodes to your graph or connect nodes to specify what happens after your Event triggers. Then, add a Custom Event Trigger node to specify when to trigger the custom Event in your graph. To create more complex logic for your custom Event, you can also create a Custom Scripting Event node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-inspectable-attribute-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-inspectable-attribute-custom-types.html",
    "title": "Add the Inspectable attribute to a custom type | Inventory System",
    "summary": "Add the Inspectable attribute to a custom type If you have access to the source code for a custom type, add the [Inspectable] attribute to its fields and classes. The [Inspectable] attribute makes these fields and classes accessible to the Inspector window in the Unity Editor. You don't need to create a custom PropertyDrawer as Unity generates a basic UI for the custom type. For more information about how to use custom types in Visual Scripting, see Use a custom type or Custom types To add the [Inspectable] attribute to the source code for a custom type: Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, on a line above your public class definition, add the [Inspectable] attribute. On a line above the properties you want to have available in the Unity Inspector, add the [Inspectable] attribute. Follow the process described in Configure project settings to regenerate your Node Library. The following is an example of a public class, with fields name and amount that are accessible and can be modified through Unity's Inspector window. ```csharp using System; using UnityEngine; using Unity.VisualScripting; [Inspectable] public class MyClass { [Inspectable] public string name; [Inspectable] public int amount; public string dontShowThis; } ```"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-node-to-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-node-to-graph.html",
    "title": "Add a node to a Script Graph | Inventory System",
    "summary": "Add a node to a Script Graph All logic in a Script Graph starts with a node. Tip Depending on the method you used to create your Script Graph, you might already have two Event nodes in your graph: Start and Update. For more information on these nodes, see Events node. To add a node to a Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. In the fuzzy finder, enter a search term into the Search bar or select a category from the list to find related nodes. Categories have an arrow (>) at the end of their entry in the fuzzy finder. Select an entry in the fuzzy finder to add that node to your Script Graph. Visual Scripting adds the node to your Script Graph at the location where you opened the fuzzy finder. Next steps After you've added a node to a graph, you can add additional nodes and connect nodes in a Script Graph to create logic for your application. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-remove-node-library.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-remove-node-library.html",
    "title": "Add or remove available nodes | Inventory System",
    "summary": "Add or remove available nodes Visual Scripting has a set of default assemblies and generated nodes for Unity features. Add more assemblies through the Visual Scripting Node Library in your Project Settings. Assemblies are special files that contain the code for the feature you want to use. Visual Scripting can generate nodes from assemblies in packages and third-party assets. To use a new package or third-party asset in Visual Scripting, you must import it into Unity. For more information on how to add packages to Unity, see Adding and removing in the Unity User Manual. For more information on how to add third-party assets to Unity, see Importing assets in the User Manual. Add assemblies and nodes to the Node Library To add a new assembly and its nodes to the Node Library: Go to Edit > Project Settings. Select Visual Scripting. Expand Node Library. At the end of the assemblies list, select Add (+). In the new assembly entry, select (No Assembly) to open the Assembly menu. Select an available assembly from the Assembly menu. Visual Scripting adds the assembly and its nodes to the Node Library. To use the nodes in your project, add their types to your Type Options and regenerate the Node Library. Remove assemblies and nodes from the Node Library To remove an assembly and its nodes from your Node Library: Go to Edit > Project Settings. Select Visual Scripting. Expand Node Library. In the assemblies list, locate the entry for the assembly you want to remove. Select Remove (-). Visual Scripting removes the assembly and its nodes from the Node Library. To remove the nodes from the fuzzy finder and your project, regenerate the Node Library. You might also want to remove their types from your Type Options."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-remove-type-options.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-remove-type-options.html",
    "title": "Add or remove types | Inventory System",
    "summary": "Add or remove types Type Options specify which node inputs and outputs Visual Scripting supports. After you add a new assembly, you must add types specific to those nodes to your Type Options. Add types to make the nodes and their types accessible in the fuzzy finder and the Blackboard. You can't use a node that has an input or output type that isn't listed in your Type Options. Add a type to your Type Options To add a new type to your Type Options list: Go to Edit > Project Settings. Select Visual Scripting. Expand Type Options. At the end of the types list, select Add (+). In the new type entry, select (No Type) to open the Type menu. Select an available type from the Type menu. Visual Scripting adds the new type to your Type Options. To use nodes with the type in your project, regenerate your Node Library. Remove a type from your Type Options To remove a type from your Type Options list: Go to Edit > Project Settings. Select Visual Scripting. Expand Type Options. In the types list, locate the entry for the type you want to remove. Select Remove (-). Visual Scripting removes the type from your Type Options. To make sure that your change appears in your project, regenerate your Node Library."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-subgraph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-subgraph.html",
    "title": "Add a Subgraph to a Script Graph | Inventory System",
    "summary": "Add a Subgraph to a Script Graph A Subgraph is a Script Graph nested inside of another Script Graph. A Subgraph appears as a single node inside the parent Script Graph. You can add a Subgraph to a Script Graph in two ways: create an entirely new Script Graph, or add an existing Script Graph file. Add a new Subgraph to a Script Graph To add a new blank Subgraph to an existing Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder.. Go to Nesting and select Subgraph. In the Graph Inspector, choose the Source for your Subgraph: Embed: The Subgraph only exists on the Subgraph node. You can only modify the Subgraph from the node in its parent graph. Graph: The Subgraph exists in a separate file. You can modify the Subgraph outside of its parent graph and reuse the graph in other areas of your application. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. If you chose Graph, select New, enter a name for your graph file, and choose where you want to save it. Select Save. Add an existing Script Graph as a Subgraph To add an existing graph file as a Subgraph in a Script Graph: Note You can't nest a Script Graph as a Subgraph in its own graph file. With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder.. Go to Nesting and select Subgraph. In the Graph Inspector, set your Source to Graph. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. In the Graph field, select the object picker (circle icon) and choose a compatible Script Graph from your project. You can also click and drag a Script Graph file from your Project window and drop it into the Graph field. Tip For a faster way to add a Script Graph as a Subgraph, click and drag the Script Graph from your Project window into the Graph Editor to automatically create a Subgraph node. Next steps To open your new Subgraph for editing, select Edit Graph. Once you've added a Subgraph to your Script Graph, define its Input and Output Triggers and Input and Output Data. For more information, see Add a Trigger or Data port to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-triggers-data-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-triggers-data-graph.html",
    "title": "Add a Trigger or Data port to a Script Graph | Inventory System",
    "summary": "Add a Trigger or Data port to a Script Graph When you use a Script Graph as a Subgraph, you can pass data and logic to it from its parent graph. Add and define ports on your graph to determine which logic and data you can pass to it. To add a Trigger Input, Trigger Output, Data Input, or Data Output port to a Script Graph: If you haven't already, open the Script Graph you want to edit in the Graph window. With no nodes selected, in the Graph Inspector, select Add (+) under the port type you want to add to your Script Graph: Trigger Inputs, Trigger Outputs, Data Inputs, or Data Outputs. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. In the Key field, enter a unique key name for your port. This name can't be the same as any existing ports on your currently selected Script Graph. (Optional) In the Label field, enter any text you want to appear as a label for the port on a Subgraph, Input, or Output node for your current Script Graph. Otherwise, Visual Scripting uses the value in the Key field as a label. (Optional) In the Summary field, enter any text that you want to appear as a brief summary of the port in the Graph Inspector when you select a Subgraph, Input, or Output node for your current Script Graph. (Optional) Select Hide Label to hide the label for the port on any Subgraph, Input, or Output node for your current Script Graph. (Data Inputs and Data Outputs Only) Select the Type list to open the Type menu and select a type for the data your port should accept. (Data Inputs Only) Select Has Default Value to enable the Default Value field and specify a default value for your Script Graph's Data Input, if your graph doesn't receive another input while it runs. Next steps You can now specify triggers and data for your Script Graph when you use it as a Subgraph in another Script Graph. For more information on each port type, see Subgraph inputs and outputs. For more information on adding a Script Graph as a Subgraph, see Add a Subgraph to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-variable-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-add-variable-graph.html",
    "title": "Create and add a variable to a Script Graph | Inventory System",
    "summary": "Create and add a variable to a Script Graph You can create and add a variable to a Script Graph in one of two ways: use the Graph window's Blackboard, or add a node to a graph. Note You can't add a Flow variable to a graph from the Blackboard. For more information on Flow variables, see Variables. Create and add a new variable through the Blackboard To create a new variable in the Blackboard and add it to a graph: With a graph open in the Graph window, open the Blackboard. In the Blackboard, select the scope for the variable you want to add: Graph, Object, Scene, App, or Saved. For more information on variable scopes and when you can use each scope in your graph, see Variables. In the (New Variable Name) field, enter a name for the new variable. Do one of the following: Press Enter. Select the Add Variable (+) button. In the Type list, select the data type for your variable. For more information on types, see Object types. In the Value field, enter or modify the default value for your variable. To add the node to your graph, click and drag from the Handle (=) on the variable's definition in the Blackboard into the Graph Editor. Visual Scripting adds a new Get Variable node for your variable to your graph. Create and add a new variable through the Graph Editor To create a Flow variable or another new variable directly in a graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Select the Variables category. Select the scope for the variable you want to add: Flow, Graph, Object, Scene, Application, or Saved. For more information on variable scopes and when you can use each scope in a graph, see Variables. Select the Set <Scope> Variable node, where <Scope> is the scope you selected in the previous step. Visual Scripting adds a new Set Variable node to the graph. In the Name field, enter a name for the new variable. (Object variables only) In the GameObject field, indicated by a GameObject icon on the node, specify the GameObject where you want to create the variable. Do one of the following: Select the object picker (circle icon) and select a GameObject. Attach a node to the field's data input port that outputs a GameObject. Leave the field as the default value of This to use the GameObject where you attached the Script Graph to a Script Machine. To set a default value for your variable, connect another node that outputs the value you want to the Set Variable node's data input port. Next steps After you've added a variable to your graph, you can add nodes, create node groups, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-advanced-topics-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-advanced-topics-intro.html",
    "title": "Advanced customization and development | Inventory System",
    "summary": "Advanced customization and development Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. You can customize and extend the basic functionality of Visual Scripting using C# code. Create a Script Graph node With a C# script, you can create your own Custom C# node and add more functionality to your Visual Scripting graphs. Create a custom event node You can trigger logic in your application with a custom event node. Add custom types to Visual Scripting Add your own custom classes and types in Visual Scripting to store information more efficiently."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-aot.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-aot.html",
    "title": "Use Visual Scripting with Unity Cloud Build | Inventory System",
    "summary": "Use Visual Scripting with Unity Cloud Build At build time, Unity removes any code that isn't used by a project to reduce build size. This can cause problems with Visual Scripting because Unity can remove code that's necessary for Script Graphs to run in a project. For versions 1.7.x, Visual Scripting generates an AotStubs.cs file, which stores the Unity APIs that graphs use. With the AotStubs.cs file, Unity doesn't remove any Unity APIs used in a graph from a build. You can generate this file when you create a build of a project. Builds through Unity Cloud Build can fail because Cloud Build prevents domain reload between the prebuild and build phases of the project. Without a domain reload, the build doesn't include the generated AotStubs.cs file. For more information about domain reload, see Domain Reloading in the Unity User Manual. To build a Visual Scripting project with Cloud Build, do the following: Build the project locally for your desired platform. For more information on how to build a project, see the relevant section for each platform in Platform development in the User Manual. After the build, do one of the following: Open the project files in the system file explorer. Open the Project window in the Unity Editor. In the project files, go to Assets > Unity.VisualScripting.Generated > VisualScripting.Core. Locate the AotStubs.cs file. Add the AotStubs.cs file to your source control system. Your Cloud Build settings might automatically trigger a new build of the project after you commit the AotStubs.cs file. For more information about version control systems and Cloud Build, see Unity Cloud Build in the User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-attach-graph-machine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-attach-graph-machine.html",
    "title": "Attach a graph file to a Script Machine or State Machine | Inventory System",
    "summary": "Attach a graph file to a Script Machine or State Machine To use a Script Graph or State Graph file in your project, you must attach it to a Script Machine or State Machine. A Script Machine or State Machine is a component. Components attach to GameObjects, and help define their behavior. For more information on components and GameObjects, see Using components or GameObjects in the Unity User Manual. Add a Script Machine or State Machine component to a GameObject Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject where you'd like to add a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the GameObject's Inspector window, select Add Component. The Components menu opens. Do one of the following: To add a Script Machine or State Machine, in the Components menu, go to Visual Scripting and select Script Machine or State Machine. Use the search bar to find the Script Machine or State Machine component. The new Script Machine or State Machine component appears in the Inspector window for the GameObject: Attach a graph file to the Script Machine or State Machine In the Inspector window, locate your Script Machine or State Machine component. Set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible graph file from your project. Click and drag a file from your Project window and drop it into the Graph field. For more information on how to create Script or State Graphs, see Create a new graph file. Next steps After you attach a graph to a Script Machine or State Machine, you can open the graph and edit. For more information, see Open a graph file."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-basic-concepts.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-basic-concepts.html",
    "title": "Basic concepts in Visual Scripting | Inventory System",
    "summary": "Basic concepts in Visual Scripting Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. In this section, you can find information about basic concepts in Visual Scripting. These concepts will help you create logic for your application. The interface The Visual Scripting interface starts with the Graph window. For more information, see The interface. Nodes Nodes are the most basic part of creating scripts in Visual Scripting. For more information, see Nodes. Graphs and Machines Graphs contain the visual representations of logic in your application. To use a graph, you attach it to a Script Machine or State Machine on a GameObject. For more information about graphs, see Graphs. For more information about Script Machines and State Machines, see Script Machines and State Machines. Variables Variables act as a container for a piece of information that might change as your application runs. For more information, see Variables. Object types Variables, data, and objects in Visual Scripting all have a specific type. For more information, see Object types."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capture-player-input-add-component.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capture-player-input-add-component.html",
    "title": "Add and configure a Player Input component | Inventory System",
    "summary": "Add and configure a Player Input component To use the Input System package with Visual Scripting, add a Player Input component to the same GameObject as the Script Graph and create an Input Actions asset. You must add the Player Input component and create the Input Actions asset before you create the Script Graph. Note If the Input System package isn't installed in your project, follow the Input System documentation's Installation guide to install the package. Go to Window > Package Manager to check your installed packages. To add a Player Input component to a GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject that you want to move with the Script Graph. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. The Components menu opens. In the Components menu, do one of the following: Go to Input. In the Search bar, enter Player Input. Select the Player Input component to add it to the GameObject. Add an Input Actions asset to the Player Input component. Do one of the following: Create a new Input Actions asset. Use an existing Input Actions asset. Create a new Input Actions asset Select Create Actions. Choose a location in your project to save the Input Actions asset. Select Save. Use an existing Input Actions asset Do one of the following: Click the Actions field's object picker (circle icon) and in the SelectInputActionAsset window, select the asset. Click and drag a file from your Project window and drop it into the Actions field. Next steps To configure the available options on a Player Input component, see GameObject components for input in the Input System package documentation. To configure an Input Actions asset, see Input Action Assets in the Input System package documentation. To create a simple Script Graph to capture input with Visual Scripting, see Capture input with the Input System package. Additional resources Capture user input in an application Capture input with the Input System package Input event nodes"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capture-player-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capture-player-input.html",
    "title": "Capture user input in an application | Inventory System",
    "summary": "Capture user input in an application You can capture input from a user's input device to make your application interactive. Visual Scripting can use either the Input Manager or the Input System package to capture input data in a Script Graph. Use the Input System package The Input System package captures input in Unity applications. It uses any input device and replaces Unity's Input Manager. To install the Input System package, see the Installation guide in the Input System package documentation. To check if the Input System package is installed, go to Window > Package Manager. For more information on the Package Manager and managing packages in projects, see the Packages section in the Unity User Manual. Input System package prerequisites To use the Input System package in a project, do the following: Install the package. For more information, see the Packages section in the User Manual. Regenerate your Node Library to include the Input System package nodes. For more information, Configure project settings. In your Player Project Settings, set Active Input Handling to Input System Package (New) or Both. For more information on this setting, see Standalone Player settings in the User Manual. Create an Input System settings asset. Go to Edit > Project Settings and select Input System Package, then select Create Settings Asset. For more information on the available input settings, see Input Settings in the Input System package documentation. Create a GameObject with a PlayerInput component and an Input Actions asset. For more information, see Add and configure a PlayerInput component. After you've configured your project, create a graph to Capture input with the Input System package. Use the Input Manager The Input Manager is Unity's built-in system for input. Change the Input Manager's settings to change how a project receives input. Go to Edit > Project Settings and select Input Manager. For more information on the available settings, see the Input Manager documentation in the User Manual. Input Manager prerequisites To use the Input Manager in a project, in your Player Project Settings, set Active Input Handling to Input Manager (Old) or Both. For more information on this setting, see Standalone Player settings in the User Manual. After you’ve configured your Player Project Settings, create a graph to Capture input with the Input Manager. Additional resources Add and configure a Player Input component Capture input with the Input System package Capture input with the Input Manager Input event nodes"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capturing-player-inputs-new.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capturing-player-inputs-new.html",
    "title": "Capture input with the Input System package | Inventory System",
    "summary": "Capture input with the Input System package Important If you don't complete the prerequisite configuration for your project, you can't use the Input System package with Visual Scripting. For more information, see Input System package prerequisites. To use the Input System package with Visual Scripting to capture input in your project: Open or create a Script Graph attached to the GameObject that you want your users to move. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Events > Input or search for On Input System Event. Select an Input System Event node. In this example, select the On Input System Event Vector 2 node to add it to the graph. Set the On Input System Event Vector 2 node's Input Action Change Type control to On Hold: In the Input Action list on the On Input System Event Vector 2 node, select an Input Action to trigger the node. In this example, select Move. Note By default, Visual Scripting displays all Input Actions from the Input Action asset attached to your current GameObject's Player Input component. Right-click anywhere in the Graph Editor to open the fuzzy finder. Tip If a context menu appears when you right-click, select Add Node to open the fuzzy finder. Go to Codebase > Unity Engine > Vector 3 or search for Vector 3 Get X. Select Get X to add the Vector 3 Get X node to the graph. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Codebase > Unity Engine > Vector 3 or search for Vector 3 Get Z. Select Get Z to add the Vector 3 Get Z node to the graph. Select the Vector 2 Value output port on the On Input System Event Vector 2 node. Make a connection to the Target input port on the Vector 3 Get X node: Select the Vector 2 Value output port. Make a connection to the Target port on the Vector 3 Get Z node. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Codebase > Unity Engine > Transform or search for Translate. Select Transform: Translate (X, Y, Z) to add the Translate node to the graph. Select the Value: Float output port on the Vector 3 Get X node. Make a connection to the X float input port on the Translate node. Select the Value: Float output port on the Vector 3 Get X node. Make a connection to the Z float input port on the Translate node. The finished graph looks similar to the following image: To enter Play mode, select Play from the Unity Editor's Toolbar. While in the Game view, press a key defined under the Input Actions asset for Move in the Player Action Map. The GameObject moves along the X or Z axis in the Game view, based on the key pressed and the Input Actions asset. For more information on how to define Input Actions, see Input Action Assets in the Input System package documentation. Additional resources Capture user input in an application Add and configure a Player Input component On Input System Event Button node On Input System Event Float node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capturing-player-inputs-old.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-capturing-player-inputs-old.html",
    "title": "Capture input with the Input Manager | Inventory System",
    "summary": "Capture input with the Input Manager Note You must configure your Project Settings to use the Input Manager with Visual Scripting. For more information, see Input Manager prerequisites. To create a basic Script Graph that uses the Input Manager to capture input: Open or create a Script Graph attached to the GameObject that you want your users to move. If there isn't an On Update or similar Event node in your graph: [!include[vs-open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Events > Lifecycle, or enter On Update in the search field. Select the On Update Event node to add it to the graph. [!include[vs-open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] TIP If you right-click and the context menu appears, select Add Node to open the fuzzy finder. Go to Codebase > Unity Engine > Input, or enter Get Axis in the search field. Select Get Axis (Axis Name) to add the Get Axis node to the graph. Repeat Steps 3 through 5 to create a second Get Axis (Axis Name) node. On the first Get Axis node, in the Axis Name input field, enter Horizontal. On the second Get Axis node, in the Axis Name input field, enter Vertical. NOTE If an Axis Name doesn't match the name in the Input Manager's Project Settings, Visual Scripting displays an error in the Graph Inspector. When you enter Play mode, the Unity Editor also displays an error in the Console window. [!include[vs-open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Codebase > Unity Engine > Transform or search for Translate. Select Translate (X, Y, Z) to add a Translate node to the graph. Select the Result float output port on the Horizontal Get Axis node. Make a connection to the X input port on the Translate node. Select the Result float output port on the Vertical Get Axis node. Make a connection to the Z input port on the Translate node. The finished graph looks similar to the following image: To enter Play mode, select Play from the Unity Editor's Toolbar. While in the Game view, press a key mapped as a Negative Button or Positive Button from the Input Manager's virtual axes. The GameObject moves along the X or Z axis in the Game view, based on the key pressed and the Input Manager Project Settings. Additional resources Capture user input in an application Capture input with the Input System package On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up As Button node On Mouse Up node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-configuration.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-configuration.html",
    "title": "Configure project settings | Inventory System",
    "summary": "Configure project settings Note To use Visual Scripting in a project for the first time, you must initialize it from the Editor's Project Settings window. Use the Project Settings window with Visual Scripting to manage backups, node assemblies, type options, and regenerate your Node Library. To open your Project Settings: Go to Edit > Project Settings. Select Visual Scripting. You can find the following configuration options in your Visual Scripting Project Settings. To use Visual Scripting in a project for the first time, you must regenerate your Node Library, as described in the table below. Option Description Initialize Visual Scripting You must select Initialize Visual Scripting the first time you use Visual Scripting in a project. Initialize Visual Scripting to parse all assemblies and types for the Visual Scripting Node Library. After you initialize Visual Scripting, regenerate your Node Library. See Regenerate Nodes, below. Type Options Use the Type Options list to add or remove types for your node inputs and outputs. After you add or remove a type, you must regenerate your Node Library. See Regenerate Nodes, below. For more information on how to add or remove types, see Add or remove types. Node Library Use the Node Library list to add or remove nodes and their assemblies in Visual Scripting. You must add any new types to your Type Options after you add new nodes to Visual Scripting. You must also regenerate your Node Library after you add or remove nodes. See Regenerate Nodes, below. For more information on how to add or remove nodes from your Node Library, see Add or remove available nodes. Regenerate Nodes Regenerate your Node Library to make all nodes available for use in a project. To use Visual Scripting for the first time in a project, you must Initialize Visual Scripting and regenerate your Node Library. To regenerate your Node Library: Select Regenerate Nodes. Select OK. NOTE You must regenerate your Node Library in the following circumstances: Before you use Visual Scripting in your project for the first time. After you add or remove nodes from your Node Library. After you add or remove types from your Type Options. After you change the inputs or outputs for a Custom C# node. Generate To generate required property provider scripts for custom drawers, select Generate. These scripts are necessary for Unity to use custom drawers for custom classes and script variables inside Visual Scripting. To assign a default value to a custom variable type through the Unity Editor’s Inspector, you must either have access to the source code for the class, or provide a custom PropertyDrawer. For more information, see Custom types. Create Backup To create a new backup of your Visual Scripting graphs and settings, select Create Backup. For more information about backups, see Create or restore a backup. Restore Backup To open the folder where Visual Scripting stores your backups, select Restore Backup. For more information about backups, see Create or restore a backup. Fix Missing Scripts To correct any issues that might occur after migration from the Unity Asset Store version of Visual Scripting to the package version, select Fix Missing Scripts. This resolves any missing references to Visual Scripting Script Graphs and State Graphs in Script Machine or State Machine components. Note If your settings don't apply after you make a change, report a bug through the Unity Editor."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-control-schemes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-control-schemes.html",
    "title": "Choose a control scheme | Inventory System",
    "summary": "Choose a control scheme You can choose from two different control schemes in Visual Scripting. Each control scheme changes how you can interact with your graphs in the Graph Editor: Action Default Control Scheme Alternate Control Scheme Pan Middle-click and drag Middle-click and drag Pan Vertically Scroll N/A Zoom In/Zoom Out Ctrl+Scroll (macOS: Cmd+Scroll) Scroll Frame Selected Home Home Frame All Home Home Create Selection Click and drag Click and drag Select All Ctrl+A (macOS: Cmd+A) Ctrl+A (macOS: Cmd+A) Open Context Menu Right-click Ctrl+click (macOS) Ctrl+E (macOS: Cmd+E) Right-click Ctrl + click (MacOS) Ctrl+E (macOS: Cmd+E) Create Node Group Ctrl+click and drag (macOS: Cmd+click and drag) Ctrl+click and drag (macOS: Cmd+click and drag) Copy Selected Ctrl+C (macOS: Cmd+C) Ctrl+C (macOS: Cmd+C) Paste Selection Ctrl+V (macOS: Cmd+V) Ctrl+V (macOS: Cmd+V) Cut Selected Ctrl+X (macOS: Cmd+X) Ctrl+X (macOS: Cmd+X) Duplicate Selected Ctrl+D (macOS: Cmd+D) Ctrl+D (macOS: Cmd+D) Delete Selected Del Del Maximize Graph Window Shift+Space Double-click Shift+Space Double-click Move Group Without Child Nodes Alt+click and drag the group's Title bar Ctrl+click and drag the group's Title bar (macOS: Cmd+click and drag) Move Node on One Axis Shift+click and drag vertically or horizontally Shift+click and drag vertically or horizontally Pan Pan to move the viewable area in the Graph Editor to any part of your graph. Pan Vertically With the Default control scheme, pan the view in the Graph Editor vertically with the scroll wheel on your mouse. Zoom In/Zoom Out Change the zoom level in the Graph window to control how much of your graph is visible in the Graph Editor. You can also set your zoom level with the toolbar in the Graph window. For more information, see The interface. Frame Selected After you select a node or another item in your graph, press Home to center your selected item in the Graph Editor. Frame All With no nodes or items selected, press Home to center your entire graph in the Graph Editor. Your zoom level automatically adjusts to accommodate the size of your graph. Create Selection Click and drag to create a selection box around any nodes or items in your graph that you want to select. When you have multiple items selected, click and drag a single item to move the entire selection. Select All Press Ctrl+A (macOS: Cmd+A) to select all items in your current graph. Open Context Menu You can open the context menu to perform certain actions on State Graphs or manipulate a selection in a Script Graph. You can create new states and add transitions. Create Node Group Create a group of nodes to keep related sections of your graph together, or move multiple nodes at a time. For more information on node groups, see Create node groups. Copy Selected Copy your current selection to move it to another graph, or another location on your current graph. Paste Selection Paste the contents of a copied or cut selection into your graph. Cut Selected Cut your current selection to move it to another graph, or another location on your current graph. Duplicate Selected Duplicate a selection to instantly create a copy of your current selection to use elsewhere in your current graph. Delete Selected Delete your current selection to remove it from your graph. Maximize Graph Window After you dock the Graph window in the Unity Editor, press Shift+Space or double-click maximize your Graph window and take up the entire Editor window. Move Group Without Child Nodes You can move a group in your graph without any of the nodes contained inside that group. Move Node on One Axis Shift+click to move a node in only one direction at a time in the Graph Editor. The node can move either vertically or horizontally."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-control.html",
    "title": "Control nodes | Inventory System",
    "summary": "Control nodes Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Control nodes branch, loop and merge the flow. Branching Branching nodes split the control flow based on a value. If The common if node uses a boolean condition. Consider them as an \"if the condition is true, do something, otherwise, do something else.\" Switch Branch on the value of an enum, a string, or an integer. These nodes are called Switch nodes. To switch on an enum, decide on the type of the enum. The branch output ports appears. To switch on a string or number, create each branch option in the graph inspector. The node is updated with each output port. For strings, optionally choose to ignore the case of the selector. Note A Default port is always added. It is the path that the control flow should take if the input selector does not correspond to any other option. Select Select nodes are the opposite of switch nodes. You can select a single value from a set of options based on a selector. For example, a Select On Integer node that chooses a color based on a player number. Note In the above example predictive debugging warns of a crash if playerNo is not within 1, 2, 3, or 4, because the Default port is not connected. Looping Loops repeats logic for a certain number of iterations before moving on. The logic to be repeated is called the body of the loop. After the loop is over, the exit port is called. Note The body of every loop is called synchronously, not over the course of multiple frames. Co-routine-like behaviours are achieved by listening to the update event manually. While Loop The while loop is the simplest form of loop. It repeats its body while its condition remains true. Only when the condition becomes false does the loop terminate. For example, the following graph generates a new random name until the result isn't contained in the names application variable. Warning Do not create an infinite loop. If the condition is always true, the editor hangs. As loop bodies are synchronous, not parallel, there are few uses for while loops in visual scripting. For Each Loop For Each iterates over every element of a collection. It outputs the current index and item that is being looped over. For example, the following graph outputs four messages to the console: I love my cat I love my dog I love my bird I love my fish To access the key and value from dictionaries in the loop, check the Dictionary box. For Loop For is a numeric loop and requires three integers: a start index, an end index, and a step. The loop starts at the first index, then increments towards the last index via increments of the step. It outputs the current index. For example, this graph counts to ten by skipping odd numbers because of its step. In other words, its output is 0, 2, 4, 6, then 8. The For loop can also be very useful when combined with the Get List Item and Count Items nodes. For example, the following graph is very similar to the last graph as the output to the console is \"I like {animal}s\". Instead of using the For Each node that outputs each item, the graph outputs each item manually by its index in the list. This graph outputs the following messages: I like cats I like dogs I like birds I like horses Break Loop A loop can finish early by using the Break Loop node. As soon as this node is entered, the exit port of the loop is called, no matter how many more iterations remain. For example, even though this for loop is supposed to count to 10, it stops at 5 because of the break. Its output is 0, 1, 2, 3, then 4. Exception Handling Try Catch The Try Catch node handles Exceptions that occur. It prevents your game from crashing in case you suspect some code might fail. Anything that gets executed in the Try branch is considered \"safe\": the script continues from the Catch branch instead if it fails. The Exception port captures information about the failure when that happens. A common way of handling this is to log a warning with the exception message. Note By default, this node catches all exceptions. Be specific in your handling by changing the exception type in the dropdown. The Finally branch is optional. It is always called after Try or Catch, regardless of whether the operation succeeded or not. It is usually used to dispose or destroy any resources that must be freed. This port can be disconnected if there is no need to destroy any resources. Throw The Throw node allows you to raise your own exceptions that stop the flow. These are caught with Try Catch. It is good practice to \"fail early\" by throwing as soon as something unexpected happens. It helps catch bugs early in the chain, instead of letting them trickle down and have unexpected side effects that are hard to debug. For example, to ensure damage is positive before applying it: If the Custom checkbox is selected, you can pass a custom Exception object that contains more data than a simple message. Most often, this is not required. By default, the thrown exception is of type System.Exception. Toggles Toggle nodes are similar in principle to light-switches: they can be turned on and off to impact either the script or values. Think of them as \"gates\" that can be opened and closed. Toggle Flow The Toggle Flow node gates the flow of control. When on, the flow passes through; when off, the flow does not. There are many inputs and outputs that allow fine grained control over the logic. In the previous example, Toggle is used to show how the same event (a keypress) turns the toggle on and off. Instead you can use On and Off with two different events to get the same results. On the output side, the Is On boolean port indicates the toggle status, that is turned on or off. The control outputs are triggered according to the table below: Port Triggered When On Flow enters the toggle via the unmarked input while it is on. Off Flow enters the toggle via the unmarked input while it is off. Turned On The toggle gets turned on, either via the On or Toggle inputs. Turned Off The toggle gets turned off, either via the Off or Toggle inputs. Toggle Value The Toggle Value node selects between two different input values depending on whether it is on or off. Its ports work exactly like the Toggle Flow node. Another way of implementing the same logic as the previous example: clicking Space toggles the object to move up. This time a value of 1 or 0 is provided as the vertical velocity. Note Turn on relations in the toolbar as a means to visualize the flow between the toggle ports. Once The Once node executes different logic the first time it is traversed from any subsequent times. It can be reset by entering the Reset port. Cache The Cache node saves the result of an expensive operating and reuses it instead of fetching it again each time you need it. For example, using this graph, the formula is calculated twice: By using the Cache node, the result is saved and calculated only once, optimizing performance. Note It is important to note that caching only lasts within the scope of the current flow. The value of the cache is not shared or available from another event."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-drawer.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-drawer.html",
    "title": "Create a custom PropertyDrawer for a custom type | Inventory System",
    "summary": "Create a custom PropertyDrawer for a custom type If you want to use a custom type from a custom class in Visual Scripting, and you don't have access to its source code, you must create a custom PropertyDrawer. You can't assign a value to a custom type inside the Editor or initialize the value for a variable with a custom type if it doesn't have a PropertyDrawer. Note The class for your custom type must have the [Serializable] tag in its source code to create a custom PropertyDrawer. To create a custom PropertyDrawer: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Go to Create > C# Script. Enter a name, such as CounterDrawer, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. Remove the Start and Update functions and their comments from the script file. Above the line that defines your new public class, add a [CustomPropertyDrawer] attribute. In the parameters for the [CustomPropertyDrawer] attribute, specify a type of parameter with the name of the type you want to assign to this PropertyDrawer, exactly as it appears in Unity. Change the MonoBehaviour class at the end of your public class definition to PropertyDrawer. Note After you create a custom PropertyDrawer, you must generate the required property provider scripts from your Visual Scripting Project Settings. For more information, see Configure project settings. The following is an example of a finished PropertyDrawer script: using UnityEditor; using UnityEngine; [CustomPropertyDrawer(type of(<Counter>))] public class CounterDrawer : PropertyDrawer { // Draw the property inside the given rect public override void OnGUI(Rect position, SerializedProperty property, GUIContent label) { // Using BeginProperty / EndProperty on the parent property means that // prefab override logic works on the entire property. EditorGUI.BeginProperty(position, label, property); // Draw label position = EditorGUI.PrefixLabel(position, GUIUtility.GetControlID(FocusType.Passive), label); // Don't indent child fields var indent = EditorGUI.indentLevel; EditorGUI.indentLevel = 0; // Calculate rects var amountRect = new Rect(position.x, position.y, 30, position.height); var unitRect = new Rect(position.x + 35, position.y, 50, position.height); var nameRect = new Rect(position.x + 90, position.y, position.width - 90, position.height); // Draw fields - passs GUIContent.none to each so they are drawn without labels EditorGUI.PropertyField(amountRect, property.FindPropertyRelative(\"amount\"), GUIContent.none); EditorGUI.PropertyField(unitRect, property.FindPropertyRelative(\"unit\"), GUIContent.none); EditorGUI.PropertyField(nameRect, property.FindPropertyRelative(\"name\"), GUIContent.none); // Set indent back to what it was EditorGUI.indentLevel = indent; EditorGUI.EndProperty(); } } To create the rest of your custom PropertyDrawer, you must decide what fields you must display, and how you want them to display in the Editor's interface. For example, you might want to use the UIElements module to create your PropertyDrawer, or decide to use Unity's IMGUI module. For more information on how to create and design a custom PropertyDrawer, see the PropertyDrawer class in the main Unity Scripting API and its related methods."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-docs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-docs.html",
    "title": "Add documentation to a Custom C# node | Inventory System",
    "summary": "Add documentation to a Custom C# node You can also add Graph Inspector documentation to a Custom C# node. Visual Scripting displays the documentation in the Graph Inspector when you select a node in a Script Graph. The documentation isn't required to use the node, but can help your users understand the purpose and usage of a node. To add documentation to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Note If you already have an Editor folder in your project, you can skip Steps 2-3. Right-click your Assets folder or select Add (+), then select Folder. Name the folder Editor. Do one of the following: Right-click your Editor folder in the Project window's folder list. Right-click anywhere in the Project window's preview pane with your Editor folder selected. Go to Create > C# Script. Enter a name, such as MyNodeDescriptor for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using System; using Unity.VisualScripting; using UnityEngine; [Descriptor(typeof(MyNode))] public class MyNodeDescriptor : UnitDescriptor<MyNode> { public MyNodeDescriptor(MyNode unit) : base(unit) {} protected override void DefinedPort(IUnitPort port, UnitPortDescription description) { base.DefinedPort(port, description); switch (port.key) { case \"inputTrigger\": description.summary = \"Trigger the concatenation of two strings, myValueA and myValueB, and return the result string on the Result port.\"; break; case \"myValueA\": description.summary = \"First string value.\"; break; case \"myValueB\": description.summary = \"Second string value.\"; break; case \"outputTrigger\": description.summary = \"Execute the next action in the Script Graph after concatenating myValueA and myValueB.\"; break; case \"result\": description.summary = \"The result string obtained from concatenating myValueA and myValueB.\"; break; } } } You can modify the script to suit the specifics of your own node. Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. Select the node and open the Graph Inspector to view your documentation. Next steps After you add documentation to a node, you can choose to further customize the node with node class and port attributes."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-logic.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-logic.html",
    "title": "Add logic to a Custom C# node | Inventory System",
    "summary": "Add logic to a Custom C# node Note To add logic to a node, you must create a Custom C# node and add ports. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you create a Custom C# node and add ports, you can add logic to a node. Add logic to tell Visual Scripting what the node does with any data it receives from its ports. To add logic to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, add any logic for the node within the lambda expression that handles the assignment of the inputTrigger. For example, you can take the values of the two string input ports added in the previous example and concatenate them, as shown in the following code: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { //The lambda to execute our node action when the inputTrigger port is triggered. inputTrigger = ControlInput(\"inputTrigger\", (flow) => { //Making the resultValue equal to the input value from myValueA concatenating it with myValueB. resultValue = flow.GetValue<string>(myValueA) + flow.GetValue<string>(myValueB) + \"!!!\"; return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); result = ValueOutput<string>(\"result\", (flow) => resultValue); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. Next steps After you add logic to a node, add relations to ensure that the node displays correctly in Visual Scripting."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-ports.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-ports.html",
    "title": "Add ports to a Custom C# node | Inventory System",
    "summary": "Add ports to a Custom C# node Note To add ports to your node, you must create the C# file for the node. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you create a Custom C# node, add ports to allow the node to send and receive data or trigger other nodes in a Script Graph. To add ports to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. Add control ports In your external editor, under the class definition for the node, add two public variables: one with a ControlInput type and one with a ControlOutput type. In the Definition method for the node, use the variables to define the control ports, as shown below: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] // No need to serialize ports. public ControlInput inputTrigger; //Adding the ControlInput port variable [DoNotSerialize] // No need to serialize ports. public ControlOutput outputTrigger;//Adding the ControlOutput port variable. protected override void Definition() { //Making the ControlInput port visible, setting its key and running the anonymous action method to pass the flow to the outputTrigger port. inputTrigger = ControlInput(\"inputTrigger\", (flow) => { return outputTrigger; }); //Making the ControlOutput port visible and setting its key. outputTrigger = ControlOutput(\"outputTrigger\"); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. If you used the previous code sample, Visual Scripting adds input and output control ports to the node. Add value ports In your external editor, under the class definition for the node, add any number of variables with either a Generic or specific type value: Generic: The port can receive or output any data type. Corresponds to Unity's Object type. Specific Type Value: The port can only receive or output a specific data type. For example, string, float, or integer. For more information on types in Visual Scripting, see Object types. In the Definition method for the node, use the variables to define the value ports. In the example below, there are two input ports with a type value of string, and one string output port: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] // No need to serialize ports public ValueInput myValueA; // Adding the ValueInput variable for myValueA [DoNotSerialize] // No need to serialize ports public ValueInput myValueB; // Adding the ValueInput variable for myValueB [DoNotSerialize] // No need to serialize ports public ValueOutput result; // Adding the ValueOutput variable for result private string resultValue; // Adding the string variable for the processed result value protected override void Definition() { inputTrigger = ControlInput(\"inputTrigger\", (flow) => { return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); //Making the myValueA input value port visible, setting the port label name to myValueA and setting its default value to Hello. myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); //Making the myValueB input value port visible, setting the port label name to myValueB and setting its default value to an empty string. myValueB = ValueInput<string>(\"myValueB\", string.Empty); //Making the result output value port visible, setting the port label name to result and setting its default value to the resultValue variable. result = ValueOutput<string>(\"result\", (flow) => { return resultValue; }); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. If you used the previous code sample, Visual Scripting adds two input ports, My Value A and My Value B, and one output port, Result to the node. Next steps After you add ports to a node, add logic to tell the node what to do with the data it receives."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-relations.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-add-relations.html",
    "title": "Add relations to a Custom C# node | Inventory System",
    "summary": "Add relations to a Custom C# node Note To add logic to a node, you must create a Custom C# node and add ports. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you add ports and add logic to a node, relations help Visual Scripting correctly display a Custom C# node in a Script Graph. To add relations to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, add relations in the format $RelationType$($Port1$, $Port2$), where $RelationType$ is the relation type you want to assign between the ports you specify as $Port1$ or $Port2$. For example, to assign relations to the previous example node: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { inputTrigger = ControlInput(\"inputTrigger\", (flow) => { resultValue = flow.GetValue<string>(myValueA) + flow.GetValue<string>(myValueB) + \"!!!\"; return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); result = ValueOutput<string>(\"result\", (flow) => resultValue); Requirement(myValueA, inputTrigger); //Specifies that we need the myValueA value to be set before the node can run. Requirement(myValueB, inputTrigger); //Specifies that we need the myValueB value to be set before the node can run. Succession(inputTrigger, outputTrigger); //Specifies that the input trigger port's input exits at the output trigger port. Not setting your succession also dims connected nodes, but the execution still completes. Assignment(inputTrigger,result);//Specifies that data is written to the result string output when the inputTrigger is triggered. } } For more information on relation types, see Custom C# nodes. Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. In the Graph toolbar, enable Relations. Visual Scripting displays the relations you assigned to the Custom C# node. If you used the previous code sample, the node's relations might look like the following image: Next steps After you add relations to a node, you can choose to add documentation or customize the node with attributes."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-attributes-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-attributes-reference.html",
    "title": "Custom C# node attributes reference | Inventory System",
    "summary": "Custom C# node attributes reference You can add attributes to a node class and port variable definitions to customize the look of a Custom C# node. Node class attributes You can customize the titles that appear on a node, where it appears in the fuzzy finder, and its icon. Node class attributes must be placed above the node class definition in a node's C# script. Visual Scripting has 5 node class attributes: UnitTitle UnitShortTitle UnitSubtitle UnitCategory TypeIcon Usually, Visual Scripting automatically applies any changes you make to a node's class attributes after you save the C# file. UnitTitle You can specify a [UnitTitle] to display a different title than the node's class name on the node when it appears in a Script Graph, and when you view details about the node in the Graph Inspector: using System; using Unity.VisualScripting; using UnityEngine; [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitTitle] attribute overrides the node's class name. UnitShortTitle You can specify a [UnitShortTitle] to display a different title on the node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitShortTitle] only appears on the node in a Script Graph. The [UnitTitle] or node class name still displays in the Graph Inspector. UnitSubtitle You can add a [UnitSubtitle] to add a line of text below the [UnitTitle], [UnitShortTitle], or node class name when a node appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitSubtitle(\"It's a subtitle!\")] [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitSubtitle] doesn't appear in the Graph Inspector. UnitCategory You can specify a [UnitCategory] to tell Visual Scripting where to place the node in the fuzzy finder: using System; using Unity.VisualScripting; using UnityEngine; [UnitCategory(\"FirstLevel/SecondLevel\")] public class MyNodeAfter : Unit { ... } } Replace FirstLevel with the name of the top-level category in the fuzzy finder where you want Visual Scripting to place the node. Replace SecondLevel with the name of a subcategory. Visual Scripting creates the categories if they don't already exist in the fuzzy finder. Note You must regenerate your Node Library for changes made to a node's [UnitCategory] to take effect. TypeIcon You can use the [TypeIcon] attribute to change the icon that appears on a node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [TypeIcon(typeof(ToggleValue))] public class MyNodeAfter : Unit { ... } } The icon for the node changes in the Graph Inspector, too. Note You can't point to your own custom icons from this attribute. You must use an icon from the Visual Scripting icons library, which includes all Unity types. Port attributes Custom nodes have one mandatory port attribute and one optional port attribute: DoNotSerialize and PortLabelHidden, respectively. Port attributes must be placed above your variable declarations for each port variable in the node. Visual Scripting automatically applies any changes you make to a node's port attributes after you save the script file. DoNotSerialize [DoNotSerialize] is a mandatory attribute for all ports on custom nodes. Add this attribute to avoid serialization of data that shouldn't be serialized: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] [UnitCategory(\"My Nodes\")] [UnitSubtitle(\"It's a subtitle!\")] [TypeIcon(typeof(Color))] public class MyNodeAfter : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { ... } } PortLabelHidden You can add the [PortLabelHidden] attribute to hide the name label for any port on a node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] [UnitCategory(\"My Nodes\")] [UnitSubtitle(\"It's a subtitle!\")] [TypeIcon(typeof(Color))] public class MyNodeAfter : Unit { [DoNotSerialize] [PortLabelHidden] public ControlInput inputTrigger; [DoNotSerialize] [PortLabelHidden] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { ... } } The port's label is still visible in the Graph Inspector. Use the same name in a port's variable definition and the port's key in the Definition method for the node's class, as shown: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { ... [DoNotSerialize, PortLabelHidden] public ValueInput myValueA; [DoNotSerialize, PortLabelHidden] public ValueInput myValueB; ... protected override void Definition() { ... myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); ... } }"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-empty.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node-empty.html",
    "title": "Create a new simple Custom C# node | Inventory System",
    "summary": "Create a new simple Custom C# node You can create a Custom C# node to run your own custom logic in a Script Graph. For more information on Custom C# nodes, see Custom C# nodes. To create a new simple Custom C# node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list, or anywhere in the Project window's preview pane, and go to Create > C# Script. Enter a name, such as MyNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { protected override void Definition() //The method to set what our node will be doing. { } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. Note If you don't regenerate your Node Library, the node won't appear in Visual Scripting's fuzzy finder. Open a Script Graph where you want to add your new node. Right-click anywhere in the Graph Editor to open the fuzzy finder. The node appears as My Node at the end of the fuzzy finder list. Select the node to add it to your graph. Next steps After you create the basic start to a node and add it to Visual Scripting's fuzzy finder, add ports so your node can send and receive data."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-custom-node.html",
    "title": "Custom C# nodes | Inventory System",
    "summary": "Custom C# nodes You can create your own Custom C# node with a C# script. Use your node in Script Graphs to run your own custom logic, and provide the script file to other users to let them use it in their own Visual Scripting projects. You can create nodes that change the flow of logic in your graph, nodes that manipulate data, or both. You can also create nodes for custom events. To create a Custom C# node, you must: Create a C# script. Add ports. Add logic. Add relations. Create the initial C# script All custom nodes start with a C# file. After you create a C# file, you must regenerate your Node Library through your project settings. This allows Visual Scripting to recognize your Custom C# node and add it to the fuzzy finder for use in your project's graphs. After you regenerate your Node Library the first time, you only need to regenerate your Node Library again if you change the location of a node in the fuzzy finder. You can change the location through the [UnitCategory] attribute. For more information on how to create your initial C# script, see Create a new simple Custom C# node. Add ports Add ports to a node to specify what triggers Visual Scripting to run logic in a node, and decide what data it sends or receives. For more information on ports and nodes, see Nodes. Port types Visual Scripting has four different port types that you can add to a node: ControlInput: Provides a connection to a previous node, which tells Visual Scripting when to start the logic in a node. ControlOutput: Provides a connection to another node, which tells Visual Scripting when to run the logic for the next connected node in a Script Graph. ValueInput: Provides a connection that allows you to pass data into a node for use in its logic. ValueOutput: Provides a connection that allows you to pass data out of a node for use in other nodes. You can add any number of ports to a node. You can also choose what data type the ValueInput or ValueOutput ports send and receive: Generic: The port can receive or output any data type. Corresponds to Unity's Object type. Type Value: The port can only receive or output a specific data type. For example, string, float, or integer. For more information on types in Visual Scripting, see Object types. For more information on how to add ports to your node, see Add ports to your Custom C# node. Add logic Add logic to a node to specify what it does when it runs in a Script Graph. If there isn't any internal logic written for a node, the node can't trigger another node, or modify any of the data it receives from other nodes in a Script Graph. For more information on how to add logic to a node, see Add logic to a Custom C# node. Add relations Relations help define how a node and its Play mode animations appear in Visual Scripting. Without relations, Visual Scripting doesn't know how to animate or display a node in the Graph Editor. Relation types You can add three types of relations to a node to help correctly display its internal flow of logic: Assignment: Assignment relations are usually between a control input port and a data output port. Set an Assignment relation to tell Visual Scripting that a specific port needs to run before the node sends data to a data output port. Succession: Succession relations are usually between a control input port and a control output port. Set a Succession relation to tell Visual Scripting that a control input port exits at a control output port. Requirement: Requirement relations are usually between a control input port and a data port or ports. Set a Requirement relation to let Visual Scripting know that a specific data port or ports must have a value before the node can run any logic. Note If you don't set any Succession relations in a node, and Dim is enabled in the Graph toolbar, Visual Scripting dims your Custom C# node and any of its connected nodes in the Graph Editor during Play mode. For more information on how to add relations to a node, see Add relations to a node. Optional steps and customization After you've added relations, you can choose to add documentation for a node. Visual Scripting displays documentation in the Graph Inspector when a user selects a node in a Script Graph. Add documentation to help other users understand the purpose of each part of a node. You can also choose to customize a node with node attributes. You can add specific node class attributes to customize the entire node, or add port attributes to only customize specific ports. The attribute type determines the location where you must place the attribute in the node's C# file. Node class attributes must be placed above a node class definition, while port attributes must be placed above the variable definition for each port."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-assign-existing-gameobject.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-assign-existing-gameobject.html",
    "title": "Create and assign a graph to an existing GameObject | Inventory System",
    "summary": "Create and assign a graph to an existing GameObject You can use the empty graph creation flow to create a new graph file and assign it to an existing GameObject in your project. For more information on other ways to create a graph file, see Create a new graph file. Create a Script Graph To create a new Script Graph and assign it to an existing GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new Script Graph. Select on selected game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. Create a State Graph To create a new State Graph and assign it to an existing GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new State Graph. Select on selected game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-assign-new-gameobject.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-assign-new-gameobject.html",
    "title": "Create and assign a graph to a new GameObject | Inventory System",
    "summary": "Create and assign a graph to a new GameObject You can use the empty graph creation flow to create a new graph file and assign it to a new GameObject. Visual Scripting automatically creates a new GameObject with the required components for the new graph file. For more information on other ways to create a graph file, see Create a new graph file. To create a new graph and assign it to a new GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new Script Graph. Select on new game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. Note The GameObject you create with this method has the same name as the graph file. After you have named and saved the graph file, the GameObject appears in the Hierarchy. The new graph file automatically opens in a new window. Create a State Graph To create a new State Graph and assign it to a new GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new State Graph. Select on new game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. Note The GameObject you create with this method has the same name as the graph file. After you have named and saved the graph file, the GameObject appears in the Hierarchy. The new graph file automatically opens in a new window. Next steps After you create your new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-on-machine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-on-machine.html",
    "title": "Create a graph on a Script Machine or State Machine | Inventory System",
    "summary": "Create a graph on a Script Machine or State Machine You can create a new graph file directly from a Script Machine or State Machine component on a GameObject. For more information on how to create a Script Machine or State Machine, see Attach a graph file to a Script Machine or State Machine. Create a new graph file from a Script Machine or State Machine To create a new graph file from an existing Script Machine or State Machine: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject that has a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the Inspector window, on your Script Machine or State Machine component, set the Source set to Graph. Select New. Enter a name for your new graph file. Choose a location for the file in your project. Select Save. Create a new embedded graph on a Script Machine or State Machine You can create an embedded graph on a Script Machine or State Machine component instead of an external graph file: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject that has a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the Inspector window, on your Script Machine or State Machine component, set the Source to Embed. (Optional) In the (Title) field, enter a descriptive title for the embedded graph. (Optional) In the (Summary) field, enter a brief summary of what the embedded graph does. (Optional) To open the new embedded graph and edit, select Edit Graph. Note Unity recommends you create a graph file rather than an embedded graph. In some situations, an embedded graph works best. For more information on how to choose the correct graph type, see Source types for Script Machines and State Machines. Next steps After you attach a graph to a Script Machine or State Machine, you can open the graph and edit. For more information, see Open a graph file."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-project-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-project-window.html",
    "title": "Create a new blank graph with the Project window | Inventory System",
    "summary": "Create a new blank graph with the Project window You can create a new blank graph through the Project window in the Unity Editor. Your graph contains no starter nodes, and isn't connected to any existing components in your project. For more information on other ways to create a new graph file, see Create a new graph file. To create a new blank graph: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list, or anywhere in the Project window's preview pane, and go to Create > Visual Scripting. Do one of the following: To create a new Script Graph, select Script Graph. To create a new State Graph, select State Graph. Enter a name for the new graph. Press Enter. When you open the new graph file, the graph might look similar to the following example. Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-unassigned-flow.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph-unassigned-flow.html",
    "title": "Create a new unassigned graph with the empty graph creation flow | Inventory System",
    "summary": "Create a new unassigned graph with the empty graph creation flow You can use the empty graph creation flow to create a new unassigned graph for use in your project. Note To use the graph file, you must attach it to a Script Machine or State Machine. For more information on other ways to create a graph file, see Create a new graph file. To create a new unassigned graph: Go to Window > Visual Scripting > Visual Scripting Graph. In the new Visual Scripting window, select one of the following options: To create a new Script Graph, select Create new Script Graph. To create a new State Graph, select Create new State Graph. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. The new graph file should look similar to the following image: Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-graph.html",
    "title": "Create a new graph file | Inventory System",
    "summary": "Create a new graph file To create a new Visual Scripting graph file, you can use the Unity Editor's Project window, Visual Scripting's empty graph creation flow, or create a graph from a Script Machine or State Machine component. Use the Project window If you create a graph with the Project window, the graph is blank. It contains no starter nodes, and isn't attached to any existing components in your project. For more information on the Unity Editor's Project window, see The Project window in the Unity User Manual. Use the empty graph creation flow If you use the empty graph creation flow, you have a few options for how to create your graph: You can choose to create an unassigned graph. The graph isn't assigned to a GameObject. You can choose to create a graph and assign it to an existing GameObject. Visual Scripting creates the required components on the GameObject for you to use your graph in your project. You can choose to create a graph and assign it to a new GameObject. Visual Scripting creates a new GameObject with the required components for you to use your graph in your project. For more information about GameObjects, see GameObjects in the User Manual. Any graph you create with the empty graph creation flow contains one or two initial nodes to help you get started with your graph. Tip To keep your project organized, place your Visual Scripting graphs in a Graphs folder inside your project's Assets folder. Use a Script Machine or State Machine You can also create a blank graph file directly on the Script Machine or State Machine component where you want to use it. For more information, see Create a graph on a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-listen-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-listen-code.html",
    "title": "Listen to a Custom Scripting Event from a C# script | Inventory System",
    "summary": "Listen to a Custom Scripting Event from a C# script You can use a C# script to listen for or receive a Custom Scripting Event from a Script Graph. You can use an Event receiver script to execute additional logic in your application. Note Before you can create a listener for a Custom Scripting Event node, you must create a Custom Scripting Event node and its trigger. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node and Create a Custom Scripting Event Sender node. To receive a Custom Scripting Event from a Script Graph: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as EventReceiver, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class EventReceiver : MonoBehaviour { void Start() { EventBus.Register<int>(EventNames.MyCustomEvent, i => { Debug.Log(\"RECEIVED \" + i); }); } } Save your script file. Return to the Unity Editor. Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. Do one of the following in the Hierarchy window: Select an existing GameObject where you want to attach the new script. Select Add New (+) and in the menu, select a new GameObject to add to your scene from any of the available options. You can also right-click anywhere in the Hierarchy window and select the same options in the context menu. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. In the Component menu, enter the name of the script file. Select it to add it to the GameObject. Select Play from the Unity Editor's Toolbar to enter Play mode. If you have a Custom Scripting Event Sender node or a C# script to trigger your Event, you can trigger your Custom Scripting Event. The EventReceiver script logs the following message to the console every time the Event is triggered, as shown in the following image."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-node-trigger-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-node-trigger-code.html",
    "title": "Trigger a Custom Scripting Event from a C# script | Inventory System",
    "summary": "Trigger a Custom Scripting Event from a C# script You can send or trigger a Custom Scripting Event node in a Script Graph with a C# script instead of a Custom Scripting Event Sender node. For more information on how to create a Custom Scripting Event Sender node, see Create a Custom Scripting Event Sender node. Note Before you can trigger a Custom Scripting Event node, you must create your Custom Scripting Event node. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node. To trigger an Event from a C# script: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as CodeTriggerCustomEvent, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class CodeTriggerCustomEvent : MonoBehaviour { void Update() { if (Input.anyKeyDown) { //Trigger the previously created Custom Scripting Event MyCustomEvent with the integer value 2. EventBus.Trigger(EventNames.MyCustomEvent, 2); } } } Save your script file. Return to the Unity Editor. Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. Do one of the following in the Hierarchy window: Select an existing GameObject where you want to attach the new script. Select Add New (+) and in the menu, select a new GameObject to add to your scene from any of the available options. You can also right-click anywhere in the Hierarchy window and select the same options in the context menu. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. In the Component menu, enter the name of the script file. Select it to add it to the GameObject. Select Play from the Unity Editor's Toolbar to enter Play mode. Press any key on keyboard in the Game view. Visual Scripting triggers your Event in any Script Graph in the current scene that contains the Custom Scripting Event node. Next steps After you create the script, you can create a script to listen to your Event. You can also create an Event Sender node to trigger the Event from another Script Graph or location in the same Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-node.html",
    "title": "Create a Custom Scripting Event node | Inventory System",
    "summary": "Create a Custom Scripting Event node You can create a Custom Scripting Event node with a C# script. With C#, you can customize all aspects of your Custom Scripting Event, unlike a Visual Scripting custom Event. For more information on the different types of custom Events, see Custom Events. To create a Custom Scripting Event node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as MyEventNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using Unity.VisualScripting; using UnityEngine; //Register a string name for your Custom Scripting Event to hook it to an Event. You can save this class in a separate file and add multiple Events to it as public static strings. public static class EventNames { public static string MyCustomEvent = \"MyCustomEvent\"; } [UnitTitle(\"On my Custom Event\")]//The Custom Scripting Event node to receive the Event. Add \"On\" to the node title as an Event naming convention. [UnitCategory(\"Events\\\\MyEvents\")]//Set the path to find the node in the fuzzy finder as Events > My Events. public class MyCustomEvent : EventUnit<int> { [DoNotSerialize]// No need to serialize ports. public ValueOutput result { get; private set; }// The Event output data to return when the Event is triggered. protected override bool register => true; // Add an EventHook with the name of the Event to the list of Visual Scripting Events. public override EventHook GetHook(GraphReference reference) { return new EventHook(EventNames.MyCustomEvent); } protected override void Definition() { base.Definition(); // Setting the value on our port. result = ValueOutput<int>(nameof(result)); } // Setting the value on our port. protected override void AssignArguments(Flow flow, int data) { flow.SetValue(result, data); } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. Open a Script Graph where you want to add your new node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events > My Events. Select your On My Custom Event node to add it to the graph. Note If you change the UnitTitle or UnitCategory attributes for the node in your code, the node appears in the location in the fuzzy finder with the name that you specify. After you regenerate your Node Library, the Custom Scripting Event node appears in the fuzzy finder. If you didn't change the [UnitCategory] or [UnitTitle] from the sample code, then the fuzzy finder displays the node under Events > MyEvents, as the On my Custom Event node. For more information on the fuzzy finder, see The interface. Next steps After you create your Custom Scripting Event node, you can create a Custom Scripting Event Sender node to trigger your Event from another Script Graph or location in the same Script Graph. You can also create a script to trigger your Event from code or create a script to listen to your Event."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-send-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-own-custom-event-send-node.html",
    "title": "Create a Custom Scripting Event Sender node | Inventory System",
    "summary": "Create a Custom Scripting Event Sender node Note Before you create a Custom Scripting Event Sender node, you must create a Custom Scripting Event node. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node. After you create a Custom Scripting Event node, you can create a Custom Scripting Event Sender node to trigger the Event from any other Script Graph in the same scene, or the same Script Graph. You can also choose to create a separate script to trigger the Event from code. For more information, see Trigger a Custom Scripting Event from a C# script. Create a node and add it to the fuzzy finder To create a Custom Scripting Event Sender node and add it to the fuzzy finder: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as SendMyEventNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using Unity.VisualScripting; using UnityEngine; //Custom node to send the Event [UnitTitle(\"Send My Custom Event\")] [UnitCategory(\"Events\\\\MyEvents\")]//Setting the path to find the node in the fuzzy finder as Events > My Events. public class SendMyEvent : Unit { [DoNotSerialize]// Mandatory attribute, to make sure we don’t serialize data that should never be serialized. [PortLabelHidden]// Hide the port label, as we normally hide the label for default Input and Output triggers. public ControlInput inputTrigger { get; private set; } [DoNotSerialize] public ValueInput myValue; [DoNotSerialize] [PortLabelHidden]// Hide the port label, as we normally hide the label for default Input and Output triggers. public ControlOutput outputTrigger { get; private set; } protected override void Definition() { inputTrigger = ControlInput(nameof(inputTrigger), Trigger); myValue = ValueInput<int>(nameof(myValue),1); outputTrigger = ControlOutput(nameof(outputTrigger)); Succession(inputTrigger, outputTrigger); } //Send the Event MyCustomEvent with the integer value from the ValueInput port myValueA. private ControlOutput Trigger(Flow flow) { EventBus.Trigger(EventNames.MyCustomEvent, flow.GetValue<int>(myValue)); return outputTrigger; } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. After you regenerate your Node Library, the Custom Scripting Event Sender node appears in the fuzzy finder. If you didn't change the [UnitCategory] or [UnitTitle] from the sample code, then the fuzzy finder displays the node under Events > MyEvents, as the Send My Custom Event node. For more information on the fuzzy finder, see The interface. Trigger your Custom Scripting Event node You might use your Send My Custom Event node to trigger your Event based on keyboard input: Open a Script Graph where you want to add the new node. This can be the same or a different Script Graph from the one that contains your Custom Scripting Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events > Input. Select the On Keyboard Input node to add it to the graph. Right-click again in the Graph Editor to open the fuzzy finder. Go to Events > My Events. Select your Send My Custom Event node to add it to the graph. Connect the On Keyboard Input node's Trigger output port to the Send My Custom Event node's Input Trigger input port, as shown in the following image. Select Play from the Unity Editor's Toolbar to enter Play mode. Press and release the Spacebar in the Game view. The Custom Scripting Event Sender node triggers the Custom Scripting Event in your graph and sends the Event the value from My Value A. Next steps After you create a Custom Scripting Event Sender node, you can create a script to trigger your Event from code or create a script to listen to your Event."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-restore-backups.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-restore-backups.html",
    "title": "Create or restore a backup | Inventory System",
    "summary": "Create or restore a backup If you don't use a version control system, such as Unity Collaborate, Git, or Subversion, it's a good practice to create backups of your Visual Scripting assets and settings. Create a backup at any time from your Project Settings. Back up your data before you update Visual Scripting to a new version. For more information on the update process, see Update Visual Scripting. Create a new backup To create a new backup of your Visual Scripting assets and settings: Go to Edit > Project Settings. Select Visual Scripting. Select Create Backup, then select OK. Visual Scripting creates a .zip file, with a name in the format Assets_YYYY_MM_DD_HH_MM_SS, in a Backups folder inside the Unity Project. Restore an existing backup To restore an existing backup of your Visual Scripting assets and settings: Go to Edit > Project Settings. Select Visual Scripting. Select Restore Backup. Visual Scripting opens your Backups folder in your system's file explorer. You can extract a .zip back-up file and import graphs and settings back into Unity. For more information on how to import assets into Unity, see Importing assets in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-state.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-create-state.html",
    "title": "Create a new state | Inventory System",
    "summary": "Create a new state You can create three types of State nodes in a State Graph: Script States, Any States, and Super States. For more information on the types of State nodes, see State Graphs in Graphs. You can also add a Sticky Note to add comments to a graph. Create a Script State To create a new blank Script State: [!include[vs-open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Script State. Visual Scripting creates a new Script State node. Open the Graph Inspector. In the Graph Inspector, choose a source for the Script State node: Embed: The graph only exists on the Script State node. You can only modify the graph from the node in its parent State Graph. Graph: The graph exists in a separate file. You can modify the graph outside of its parent State Graph and reuse the graph in other areas of your application. If you chose Graph: Select New. Enter a name for the graph file. Choose where you want to save the new graph. Select Save. To create a Script State from an existing Script Graph: [!include[vs-open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Script State. Visual Scripting creates a new Script State node. Open the Graph Inspector. In the Graph Inspector, set the source for the Script State node to Graph. Do one of the following: Select the object picker (circle icon) and choose a compatible Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Tip Click and drag the Script Graph from your Project window into the Graph Editor to automatically create a Script State node. Create an Any State To create a new Any State node: With a State Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the context menu. Select Create Any State. Create a Super State To create a new blank Super State: [!include[vs-open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Super State. Visual Scripting creates a new Super State node. Open the Graph Inspector. In the Graph Inspector, choose a source for the Super State node: Embed: The graph only exists on the Super State node. You can only modify the graph from the node in its parent State Graph. Graph: The graph exists in a separate file. You can modify the graph outside of its parent State Graph and reuse the graph in other areas of your application. If you chose Graph: Select New. Enter a name for the graph file. Choose where you want to save the new graph. Select Save. To create a Super State from an existing State Graph: [!include[vs-open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Super State. Visual Scripting creates a new Super State node. Open the Graph Inspector. In the Graph Inspector, set the source for the Super State node to Graph. Do one of the following: Select the object picker (circle icon) and choose a compatible State Graph from your project. Click and drag a State Graph file from your Project window and release on the Graph field. Tip Click and drag the State Graph from your Project window into the Graph Editor to automatically create a Super State node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-creating-connections.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-creating-connections.html",
    "title": "Connect nodes in a Script Graph | Inventory System",
    "summary": "Connect nodes in a Script Graph Connections control the flow of logic and data in a Script Graph's nodes. To connect nodes in a Script Graph: With a Script Graph open in the Graph window, either find an existing node where you want to make a connection, or add a new node to your Script Graph. Do one of the following: Connect to a new node. Connect to an existing node. Connect to a new node Select a port and point to a blank area in your graph to start the connection. Select again to open the fuzzy finder. Select an entry to automatically add that node at the end of your connection. Connect to an existing node Select a port and point to an existing port on another node. Select the port to make the connection. Delete a connection To delete a connection between two nodes: With a Script Graph open in the Graph window, right-click the port at either end of a connection. Visual Scripting deletes the connection. Next steps After you've connected nodes together, you can continue to add nodes to your Script Graph. You can also create and add variables, create node groups, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-creating-transition.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-creating-transition.html",
    "title": "Create a transition between states | Inventory System",
    "summary": "Create a transition between states To switch between states in a State Graph, you must use a Script Graph called a transition. For more information on State Graphs, see State Graphs. Create a transition with an embedded Script Graph To create a new transition to another state with an embedded graph in a State Graph: With a State Graph open in the Graph window, do one of the following: Right-click on the state where you want to make a transition, then in the context menu, select Make Transition. Select the state where you want to make a transition, then press Ctrl+click and drag away from your selected state. Do one of the following: Select or release while on an existing state in your State Graph to connect the states with a transition. Select or release while on an empty space in the Graph Editor to automatically create a new blank Script State at the end of your transition. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Embed. In the (Title) field, enter a title for your transition's Script Graph. In the (Summary) field, enter a brief descriptive summary of your transition's Script Graph. Note If you choose to use an embedded transition Script Graph, Visual Scripting automatically provides the Trigger Transition node you need for the graph. Create a transition with an external Script Graph file To create a new transition with a graph asset file in a State Graph: With a State Graph open in the Graph window, do one of the following: Right-click on the state where you want to make a transition, then in the context menu, select Make Transition. Select the state where you want to make a transition, then press Ctrl+click and drag away from your selected state. Do one of the following: Select or release while on an existing state in your State Graph to connect the states with a transition. Select or release while on an empty space in the Graph Editor to automatically create a new blank Script State at the end of your transition. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: Select the object picker (circle icon). Select a Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Select New and create a new Script Graph. Double-click the new transition node to open the transition Script Graph. Create a self transition with an embedded Script Graph To create a new self transition for a state in a State Graph: With a State Graph open in the Graph window, right-click on the state where you want to make the transition. In the context menu, select Make Self Transition. Visual Scripting attaches a new Self Transition node to the state in the State Graph automatically. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Embed. In the (Title) field, enter a title for your transition's Script Graph. In the (Summary) field, enter a brief descriptive summary of your transition's Script Graph. Double-click the new self transition to open the transition Script Graph. Note If you choose to use an embedded transition Script Graph, Visual Scripting automatically provides the Trigger Transition node you need for your graph. Create a transition with an external Script Graph file To create a new transition with a graph asset file in a State Graph: With a State Graph open in the Graph window, right-click on the state where you want to make the transition. In the context menu, select Make Self Transition. Visual Scripting attaches a new Self Transition node to the state in the State Graph automatically. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: Select the object picker (circle icon). Select a Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Select New and create a new Script Graph. Double-click the new transition node to open the transition Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-custom-events.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-custom-events.html",
    "title": "Custom Events | Inventory System",
    "summary": "Custom Events Events trigger, or start, a chain of logic in a Script Graph based on a specific occurrence in your application. Some Event types, such as On Start or On Update, exist by default in Visual Scripting. These Event nodes tell Visual Scripting to run the nodes they're connected to after the Script Graph starts, or on every frame while the Script Graph is active. You can also create your own custom Scripting Events to specify conditions for when a Script Graph's logic runs. Visual Scripting has two types of custom Events: Custom Event nodes: Use Custom Event nodes and Custom Event Trigger nodes to raise simple custom Events that don't require complex logic. Custom Scripting Events: Create your own Custom Scripting Event nodes to raise more complex Event logic. Custom Event nodes Custom Event nodes are always accessible from the fuzzy finder. You don't need to write your own code to use these custom Events in a Script Graph. They don't require an event listener. You can use the Custom Event node to create multiple custom Events, as long as you give each Event a unique name. You can also customize the number of arguments that the Custom Event node can send. To configure a Custom Event node, you need to provide: A unique name. A GameObject. The number of arguments the Custom Event receives. For more information on how to configure and use a Custom Event node, see Add a Custom Event node. To trigger a Custom Event, use a Custom Event Trigger node and provide the unique name of the Event. For more information, see Add a Custom Event Trigger node. Visual Scripting displays errors in the Graph Inspector if the Custom Event node and a Custom Event Trigger node have different values for: The name of the Event. The provided GameObject for the Event. The number of arguments for the Event. All arguments on a Custom Event Trigger node must have values, even if the Custom Event node doesn't give those values to another node. In the following example, Visual Scripting displays an error for both Arg. 0 and Arg. 1, even though Arg. 1 isn't used. Custom Scripting Events You can create a Custom Scripting Event node with a C# script. With C#, you can customize all aspects of your Custom Scripting Event, such as which category or categories to use for your node in the fuzzy finder. For more information, see Create a Custom Scripting Event node. To use and trigger the Event, code a Custom Scripting Event Sender node or another C# script: For more information on how to send or trigger an Event with a node in a Script Graph, see Create a Custom Scripting Event Sender node. For more information on how to send or trigger an Event with code, see Trigger a Custom Scripting Event from a C# script. You can also use a C# script to listen to or receive your Event after you trigger it in a Script Graph. You can use your receiver script to trigger more logic in your application. For more information, see Listen to a Custom Scripting Event from a C# script."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-custom-types.html",
    "title": "Custom types | Inventory System",
    "summary": "Custom types Use a C# script file to create your own object types in Unity. These types are called classes. Classes are a blueprint for objects in your code. They decide what kind of data an object holds and what your code can do with that object. A class can hold multiple variables with different data types in a single object. Create a custom class to use it as a type for variables and other objects in a Visual Scripting Script graph. For more information on how to add and use your own custom types in Visual Scripting, see Use a custom type. The code you include in a C# script can also create new nodes to manipulate the data in your class. For example, you might write code to keep track of the characteristics of different player characters in your application. You can create a class, Player, and have different variables in that class for name, character type, favorite color, or player level: using System; using UnityEngine; using Unity.VisualScripting; [Serializable, Inspectable] public class PlayerCharacter { [Inspectable] public string name; [Inspectable] public string type; [Inspectable] public string color; [Inspectable] public int level; } Tip The variables in the example script above use the [Inspectable] attribute so they can display in Unity's Inspector window and the Visual Scripting Graph Inspector. Without the attribute, you can't assign a value to any variables that use the PlayerCharacter class in a Script Graph. For more information about the [Inspectable] attribute, see Use a custom type. These values can be different across different instances of Player objects in your code. Player1 can be Erin, a bard, who loves green and is level 5, and Player2 can be Sam, a mage, who loves black and is level 15. If you tried to represent the same data with basic variables, you must create a lot of nodes, as in the following example. With a custom class, you can create a single node to represent a player character's information, instead of four separate nodes."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-debug-messages.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-debug-messages.html",
    "title": "Working with debug messages | Inventory System",
    "summary": "Working with debug messages You can use debug nodes to see the result of a code segment inside the Unity console. For example, attaching a Debug node to a Variable node outputs the value of the variable. Tip Debugs are a useful tool when prototyping. To create a debug message Important Remove or disconnect the debugs from the graphs before producing the final executable. Add a Script Machine component to the GameObject. Select Edit Graph. Do one of the following: Use the starting events that are created with the script machine. Add an event node to the graph. Drag and release from the node port. The fuzzy finder appears. In the finder field, enter “Log”. A list of Debug nodes appears. Select the relevant debug message type you want to use (for example Log(Message), Log Error(Message) or Log Warning(Message)). The select Debug node is placed in the graph and linked to the event. Drag and release from the Debug green (output) port. The fuzzy finder appears. In the list, select the String node. A String node appears on the graph, connected to the Debug node.v Enter the debug message in the string node**.** Tip You can link variables or GameObjects other than a string to the port to see the value in the console. Whenever the graph is run and the Event is fired, the debug node executes and the text in the String appears in the console. Note The debug bar indicates the number of messages of each debug type (in the following order Message, Error, Warning)."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-debugging.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-debugging.html",
    "title": "Predictive and Live Debugging | Inventory System",
    "summary": "Predictive and Live Debugging Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting can predict and indicate nodes in the script that can cause an error before entering play mode. It also analyzes your graphs to anticipate missing components or null references. If an error occurs at runtime, visual scripting pin-points the source of the error by highlighting it in the graph. Predictive Debugging When a node is not properly configured or may cause an error, it is colored yellow. When a node is certain to cause an error, it is colored orange. In both cases you should examine the node and make the required changes until it turns back to its normal color. Example: The Log node is colored orange because it's missing the Message that it should output to the console. If you connect the result of A + B to Message, the Log node goes back to normal. However, the Add node turns orange, because it's missing its first operand, A. If values are provided for both operands, all colors return to normal. The B input port does not need to be connected as it has a default inline value. Null References Null reference exceptions are very common. They happen when a parameter expects a value, but it receives \"nothing\", or in scripting lingo, \"null\". Visual scripting attempts to predict null references if the Predict Potential Null References option is checked in Unity > Preferences > Visual Scripting > Flow Graph. Example: Even though the Destroy node has an inline value, as it is set to \"None\" (null), it is colored orange. There are some rarer nodes that allow for null parameters. Unfortunately, because there is no way to know that from codebase analysis, visual scripting colors them orange as a false positive. If this is a recurring issue, turn off Predict Potential Null References. Missing Components When nodes are used that require components and pass a game object or a component that does not have the specified component, the node is colored yellow as a warning. For example, even though there are default values for each value input of the Add Force node, visual scripting detects that the owner game object does not have a rigidbody and provides a warning. Visual scripting does not color the node orange because it is possible to add components to game objects at runtime, so the node is not guaranteed to cause a crash if you add the required component before calling it. If this use case happens often in the project, you can disable Predict Potential Missing Components debugging from Unity > Preferences > Visual Scripting > Flow Graphs. Live Debugging When in play mode, the currently active nodes are highlighted in blue. If an error occurs, the node that caused it is highlighted in red. Example: The following is an example of a faulty graph. The result logs \"my 3rd third favorite fruit\" to the console when you press space. Here's what happens when play is selected and the object is clicked. All nodes are highlighted in blue as soon as you click because they were activated. However, there was an error in the console. Visual scripting highlights the faulty node in red. A common mistake is to assume array indices start at 1, whereas they actually start at 0. In scripting, indices are always zero-based; the first item is at index 0, the second at index 1, the third at index 2, etc. To get third item, write 2 in the field."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-developers-guide.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-developers-guide.html",
    "title": "Developer's guide | Inventory System",
    "summary": "Developer's guide _Misc Node Description Formula Outputs the result of the formula entered, which has a user specified number of input ports. Can create vector 2,3,4 and access all variables by name (object, graph, scene, application, saved). GetApplicationVariable Gets an application variable by name. GetGraphVariable Gets a graph variable by name. GetMember Invokes a getter via reflection (field or property, static or instance). GetObjectVariable Gets an object variable by name. GetSavedVariable Gets a saved variable by name. GetSceneVariable Gets a scene variable by name. GetVariable Gets a graph variable by name. InvokeMember Invokes a method via reflection (static or instance). IsApplicationVariableDefined Returns true if the variable is defined. IsGraphVariableDefined Returns true if the variable is defined. IsObjectVariableDefined Returns true if the variable is defined. IsSavedVariableDefined Returns true if the variable is defined. IsSceneVariableDefined Returns true if the variable is defined. IsVariableDefined Returns true if the variable is defined. This (formerly Self) Provides a reference to the GameObject that has the Machine Component running the graph. SetApplicationVariable Sets an application variable by name. SetGraphVariable Sets a graph variable by name. SetMember Invokes a setter via reflection (field or property, static or instance). SetObjectVariable Sets an object variable by name. SetSavedVariable Sets a saved variable by name. SetSceneVariable Sets a scene variable by name. SetVariable Sets a variable by name. Collections Node Description CountItems Provides a count of the number of items in the collection. FirstItem Gets a reference to the first item in the collections. LastItem Gets a reference to the last item in the collection. Collections, Dictionaries Node Description AddDictionaryItem Adds Key/Value pair into dictionary. ClearDictionary Removes all elements from the dictionary. CreateDictionary Creates a local dictionary. DictionaryContainsKey Returns true if the dictionary contains an entry with a matching key. GetDictionaryItem Return value for a dictionary entry with the provided keys. MergeDictionaries Combines the contents of two dictionaries into a single dictionary. RemoveDictionaryItem Removes an entry from the dictionary with the provided key. SetDictionaryItem Replaces the value of an existing entry with the provided key. Collections, Lists Node Description AddListItem Adds an item to the list. ClearList Removes all elements from the list. CreateList Creates a local list. GetListItem Gets the item in a list at the specified position provided by the index. InsertListItem Inserts an item into a list at the specified position provided by the index. ListContainsItem Returns true if the item is contained in the list. MergeLists Combines the contents of two lists into a single list. RemoveListItem Removes the item from the list (if it is present). RemoveListItemAt Removes the item from the list that is at the specified position provided by the index. SetListItem Replaces the item in the list with a new item at the specified position provided by the index. Control Node Description If (Formerly Branch) Executes the True branch if the provided input is true, otherwise executes the False branch. Break Immediately exits the current loop. Cache Flow node reads its input value whenever a value from any source is entered and outputs it when its output port is pulled. For A loop control. The Body branch is executed, providing an Index equal to First. If execution isn't interrupted (for example, by Break), the Index is incremented by Step. If the Index is less than Last, the Body branch is executed again. This process repeats until the Index is greater than Last, at which point the Exit branch is executed and the loop terminates. ForEach A loop control that executes Body once for every item (provided as Item) contained in the provided collection. Once completed, the Exit branch is executed. Once Flow node with an internal state that triggers its output only the first time it is entered. Entering a second time does not trigger the output flow. After a reset, the next time you enter, will trigger the output flow. SelectOnEnum Provides the object associated to the enum value provided as an input. SelectOnFlow Provides the object associated to the incoming flow branch that triggered the node. SelectOnInteger Data branching based on an input integer. SelectOnString Data branching based on an input string. SelectUnit Data branching based on an input enum. Sequence Executes a series of branches in order. To determine the order, specify the number of steps in the sequence, labelled with their order (e.g. 0, 1, 2, 3). SwitchOnEnum Executes the branch associated to the provided enum value. SwitchOnInteger Flow branching based on an input integer. SwitchOnString Flow branching based on an input string. Throw Causes an exception with the provided message. ToggleFlow Flow branching based on whether the node is On or Off, with inputs to set or toggle its On/Off state. ToggleValue Flow branching based on whether a value got set to its associated On/Off value. TryCatch Executes the Try branch. If an exception occurs in that branch, execute the Catch branch. Once the Try branch completes without exceptions or the Catch branch completes, the Finally branch is executed. While Executes the Body branch. Repeat this step as long as the provide condition is true. When that condition is no longer true, execute the Exit branch. Events Node Description TriggerCustomEvent Triggers a custom event by name. Logic Node Description And Logical AND (equivalent to &&) returns true if both operands are true and returns false otherwise. Comparison All comparisons in one node: inputs A/B, outputs < <= > >= == !=, and so on. Equal Logical AND (equivalent to &&) returns true if both operands are true and returns false otherwise. ExclusiveOr Exclusive OR (equivalent to ^) compares the first operand to the second operand and returns true only when inputs differ (one is true, the other is false). Greater Greater than (equivalent to >) returns false if the relationship in the expression is false; otherwise, returns true. GreaterOrEqual Greater than or equal to (equivalent to >=) returns false if the relationship in the expression is false; otherwise, returns true. Less Less than (equivalent to <) returns false if the relationship in the expression is false; otherwise, returns true. LessOrEqual Less than or equal to (equivalent to <=) returns false if the relationship in the expression is false; otherwise, returns true. Negate Negation (equivalent to !) reverses the meaning of its operand. NotEqual The not equal to operator (equivalent to. !=) returns true if the operands don't have the same value; otherwise, it returns false. Or Logical OR (equivalent to ||) returns true if either or both operands is true and returns false otherwise. Math, Generic Node Description Add Calls the + operator on inputs. Divide Calls the / operator on inputs. Modulo Calls the % operator on inputs. Multiply Call the * operator on inputs. Subtract Calls the - operator on inputs. Math, Scalar Node Description Absolute Absolute returns the absolute value of an integer. Add Sum of two floats. Average Average of all float inputs. Divide Divides the first float by the second float and returns the result. Exponentiate Raises the base to an exponent. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns the remainder of a float divided by another float. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies two floats. Normalize Equivalent to MathF.Sign. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Root Calculates x to the root of n. Round Rounds a float - ceil, floor or closest integer. Subtract Subtracts the first float from the second float and returns the result. Sum Sum of multiple floats. Math, Vector2 Node Description Absolute Gives both the x and y values of a Vector2 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector2 value. Distance Distance between two Vector2 points. Divide Divide the components of one Vector2 by the corresponding components of a second Vector2. DotProduct Dot Product between two Vector2 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector2 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector2 values. Normalize Returns a Vector2 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector2 to closest integer value. Subtract Subtracts one Vector2 value from another Vector2 value. Sum Adds two Vector2 values. Math, Vector3 Node Description Absolute Gives both the x and y values of a Vector3 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector3 value. Distance Distance between two Vector3 points. Divide Divide the components of one Vector3 by the corresponding components of a second Vector3. DotProduct Dot Product between two Vector3 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector3 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector3 values. Normalize Returns a Vector3 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector3 to closest integer value. Subtract Subtracts one Vector3 value from another Vector3 value. Sum Adds two Vector3 values. Math, Vector4 Node Description Absolute Gives both the x and y values of a Vector4 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector4 value. Distance Distance between two Vector4 points. Divide Divide the components of one Vector4 by the corresponding components of a second Vector4. DotProduct Dot Product between two Vector4 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector4 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector4 values. Normalize Returns a Vector4 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector4 to closest integer value. Subtract Subtracts one Vector4 value from another Vector4 value. Sum Adds two Vector4 values. Nesting Node Description GraphInput Gets the value of a graph input when the graph is used as a Subgraph. GraphOutput Gets the value of a graph output when the graph is used as a Subgraph. StateUnit References another state machine graph as a state in the current graph. Subgraph References another flow graph as a Subgraph in the current graph. TriggerStateTransition In a transition graph, triggers the transition to the target graph in the parent state machine graph. Nulls Node Description Null Null literal. NullCheck Branching based on the input value being null. NullCoalesce Returns the input value or a default value if the input value is null. Time Node Description Cooldown Coroutine node that can re-trigger its output only after a certain cooldown time interval. Timer Coroutine node that triggers its output after a time interval. WaitForEndOfFrameUnit Coroutine node that yields return new WaitForEndOfFrame(). WaitForFlow Coroutine node that waits until the input flow port is triggered. WaitForNextFrameUnit Coroutine node that returns null. WaitForSecondsUnit Coroutine node that returns new WaitForSeconds(). WaitUntilUnit Coroutine node that returns new WaitUntill(() => value). WaitWhileUnit Coroutine node that returns new WaitUntill(() => !value). Variables Node Description SaveVariables Forces saved variables to be saved to the PlayerPrefs (this is useful on platforms that do not support automatic save on quit). Events Node Description UnityEvent Called when a UnityEvent is pointed to TriggerUnityEvent. CustomEvent Bolt's custom events, defined by name. Events, Animation Node Description Animation Event Called when an animation event points to TriggerAnimationEvent. This version allows you to use the string parameter as the event name Named Animation Event Called when an animation event points to TriggerAnimationEvent. This version allows you to use the string parameter as the event name. OnAnimatorIK https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnAnimatorIK.html OnAnimatorMove https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnAnimatorMove.html Events, Application Node Description OnApplicationFocus https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnApplicationFocus.html OnApplicationLostFocus Implements https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationFocus.html OnApplicationPause https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationPause.html OnpplicationQuit https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationQuit.html OnApplicationResume Implements https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationPause.html Events, Editor Node Description OnDrawGizmos https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDrawGizmos.html OnDrawGizmosSelected https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDrawGizmosSelected.html Events, GUI Node Description OnBeginDrag Implements IBeginDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IBeginDragHandler.html OnButtonClick Registers to a Button's onClick event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Button.html OnCancel Implements ICancelHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ICancelHandler.html OnDeselect Implements IDeselectHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDeselectHandler.html OnDrag Implements IDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDragHandler.html OnDrop Implements IDropHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDragHandler.html OnDropdownValueChanged Registers to a Dropdown's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Dropdown.html OnEndDrag Implements IEndDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IEndDragHandler.html OnGUI Triggers on MonoBehaviour.OnGUI https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ MonoBehaviour.OnGUI.html OnInputFieldEndEdit Registers to an InputField's onEndEdit event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.InputField.html OnInputFieldValueChanged Registers to an InputField's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.InputField.html OnMove Implements IMoveHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IMoveHandler.html OnPointerClick Implements IPointerClickHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerClickHandler.html OnPointerDown Implements IPointerDownHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerDownHandler.html OnPointerEnter Implements IPointerEnterHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerEnterHandler.html OnPointerExit Implements IPointerExitHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerExitHandler.html OnPointerUp Implements IPointerUpHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerUpHandler.html OnScroll Implements IPointerScrollHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerScrollHandler.html OnScrollbarValueChanged Registers to a Scrollbar's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Scrollbar.html OnScrollRectValueChanged Registers to a ScrollRect's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.ScrollRect.html OnSelect Implements ISelectHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ISelectHandler.html OnSliderValueChanged Registers to a Sliders's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Slider.html OnSubmit Implements ISubmitHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ISubmitHandler.html OnToggleValueChanged Registers to a Toggle's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Toggle.html Events, Hierarchy Node Description OnTransformChildrenChanged https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTransformChildrenChanged.html OnTransformParentChanged https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTransformParentChanged.html Events, Input Node Description OnButtonInput On Update, checks Input.GetButtonDown/GetButtonUp/GetButton based on the specified Action type https://docs.unity3d.com/2019.1/Documentation/ScriptReference/Input.html. OnKeyboardInput On Update, check Input.GetKeyDown/GetKeyUp/GetKey based on the specified action type https://docs.unity3d.com/2019.1/Documentation/ScriptReference/Input.html OnMouseDown https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseDown.html OnMouseDrag https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseDrag.html OnMouseEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseEnter.html OnMouseExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseExit.html OnMouseInput https://docs.unity3d.com/ScriptReference/ Input.GetMouseButton.html OnMouseOver https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseOver.html OnMouseUp https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseUp.html OnMouseUpAsButton https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseUpAsButton.html Events, Lifecycle Node Description FixedUpdate https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.FixedUpdate.html LateUpdate https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.LateUpdate.html OnDestroy https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDestroy.html OnDisable https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDisable.html OnEnable https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnEnable.html Start https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.Start.html Update https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.Update.html Events, Navigation Node Description OnDestinationReached Trigger if a NavMeshAgent's remaining distance to its target is less than the provided threshold and either has a current NavMeshPathStatus of PathComplete or requireSuccess is false. https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ AI.NavMeshAgent.html. Events, Physics Node Description OnCollisionEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionEnter.html OnCollisionExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionExit.html OnCollisionStay https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionStay.html OnControllerColliderHit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnControllerColliderHit.html OnJointBreak https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnJointBreak.html OnParticleCollision https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnParticleCollision.html OnTriggerEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerEnter.html OnTriggerExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerExit.html OnTriggerStay https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerStay.html Events, Physics 2D Node Description OnCollisionEnter2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionEnter2D.html OnCollisionExit2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionExit2D.html OnCollisionStay2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionStay2D.html OnControllerColliderHit2D https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnControllerColliderHit.html OnJointBreak2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnJointBreak2D.html OnParticleCollision2D https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnParticleCollision.html OnTriggerEnter2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerEnter2D.html OnTriggerExit2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerExit2D.html OnTriggerStay2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerStay2D.html Events, Rendering Node Description OnBecameInvisible https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnBecameInvisible.html OnBecameVisible https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnBecameVisible.html Events, State Node Description OnEnterState When a state is entered. OnExitState When a state is exited."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-editor-script-issues.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-editor-script-issues.html",
    "title": "Known Issues: Unity Editor script functions | Inventory System",
    "summary": "Known Issues: Unity Editor script functions If you use nodes that use Unity Editor script functions in any of the Visual Scripting graphs in your project, it causes errors when you try to build your project. Cause of the build errors Unity Visual Scripting (UVS) doesn't support preprocessor directives, so the use of Unity Editor script functions within graphs isn't possible. However, these functions can appear as node options within UVS because UVS uses C# reflection to generate nodes for your project based on your included assemblies. If you add one of these Unity Editor script nodes to a graph that's used in a build of your project, Unity generates an error when it attempts to build the project. An error message of the following format is displayed in the Unity Console: /<ProjectPath>/<CSharpFile>.cs: error CS0103: The name '<MissingApiName>' does not exist in the current context. The following code sample is an example of preprocessor directives for Unity Editor scripts : #if UNITY_EDITOR public static List<Type> GetAllVolumeComponents() { // TypeCache is only accessible in UnityEditor. // If you instantiate a GetAllVolumeComponents node in a graph // it prevents the project from being built. return TypeCache.GetTypesDerivedFrom<VolumeComponent>().ToList(); } #endif Find flagged packages Packages that contain editor scripts are flagged with a warning icon in the Node Library section of the Visual Scripting tab in the Project Settings window. To find the affected packages, do the following: Go to Edit > Project Settings. In the Project Settings window, select the Visual Scripting tab. On the Visual Scripting tab expand the Node Library section. A yellow warning flag is displayed next to any affected packages as shown in the following screenshot. Resolution To resolve this issue, go through your graphs and replace nodes that correspond to the API mentioned in the error message until you find the error no longer occurs."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-events-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-events-reference.html",
    "title": "Events node | Inventory System",
    "summary": "Events node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Scripting nodes listen for events. They are the starting point for all scripts and appear as special green nodes in graphs. There are many kinds of events, grouped in sub-categories under the root Events category (fuzzy finder > Events). Two simple common events are Start and Update, both located under Lifecycle. Start is called once when the graph or event handler is first created. Update is called at every frame while the graph or event handler is active. New script machines start with both these events by default. Inputs & Outputs All events have a single Trigger control output that starts the script when they are triggered. Value inputs are options that influence when the event is triggered. For example, some events have a Target setting that determines which object is listening to the event. Most often, you'll leave this setting at its default value of Self. The value outputs on events are arguments that are passed from the event, giving you more information about what actually happened. For example, on the On Trigger Enter event, the other collider that is involved in the collision is an output. Custom Events There is a special type of event, the Custom Event that triggers custom events across graphs, along with their custom arguments. For example, to create a custom event called On Damage that gets called so the character loses health, the event should have one integer argument that indicates the amount of damage to inflict. Listen to the event by creating a Custom Event node (under Events). Set the name to On Damage. The set the argument count, below the name, to 1. Note Indices are zero-based, so the first argument is labeled Arg. 0. To trigger the event from elsewhere, use the Trigger Custom Event node, located right under the Custom Event node in the fuzzy finder. Enter the name of the event exactly as it is sensitive to case and whitespace. For example, to create a script machine on a boulder that could hit the player, use the force of the impact as the damage. The collider that hit with the boulder is the target of our trigger; the On Damage event is triggered on all machines attached to that collider. Use the damage value to subtract health from the receiver object. Custom events do not require a receiver and do not cause an error if there isn't a listener to handle them. Animation Events Use animation events to trigger script graphs when you reach a certain point in your animation. Select an object with a machine and an animator. Then, from the animation window, add an animation event. With the event selected, choose TriggerAnimationEvent as the function from the inspector. Use any parameter from the inspector. In your script graph, add an Animation Event node (under Events >Animation). There are two types of events: a global animation event, and a named animation event. The difference is that the first type listens to all animation events on the object and return the string parameter. The second type's trigger is the string parameter that is equal to the specified name input. Unity Events Use Unity Events to trigger events that have been setup from the inspector. These are commonly found in GUI components like buttons, but they can also be created in your custom scripts. Configure them by selecting an object with a machine and select the Trigger Unity Event method. In the string field, type the event name to listen to in the graph and in the graph, add a UnityEvent node with a matching name. Additional arguments are not supported on Unity events. Events API Visual scripting provides a simple API to trigger custom events from C# script. Add the following usings to your C# script to access the API. using Unity.VisualScripting Triggering API A single method call is needed to trigger a custom event. Pass as many arguments as required. CustomEvent.Trigger(targetGameObject, argument1, argument2, ...) For example, this custom event node: Can be triggered with this line of code. CustomEvent.Trigger(enemy, \"Damage\", 30);"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-events.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-events.html",
    "title": "Events API | Inventory System",
    "summary": "Events API Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting provides a simple API to trigger custom events from C# script. Usings Add the following usings to your C# script to access the API. using Unity.VisualScripting; Triggering A single method call is needed to trigger a custom event. Pass as many arguments as required. CustomEvent.Trigger(targetGameObject, argument1, argument2, ...) For example, this custom event node: Can be triggered with this line of code. CustomEvent.Trigger(enemy, \"On Damage\", 30);"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-formula.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-formula.html",
    "title": "Formula node | Inventory System",
    "summary": "Formula node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Formula is a powerful node that evaluates logical and mathematical expressions directly via a textual Formula and a list of Arguments. Important Due to the binary tree traversal overhead (despite caching attempts), performance in using the formula node is significantly slower than using the operator nodes individually. It is preferable to avoid using this node at every frame. Although a formula can return either a boolean for logic, or a number for math, formulas can return any type of value. The first text field in the header is the formula itself. The second text field is the number of arguments. It's set to 2 by default, giving us A and B as inputs. Formulas can have up to 10 arguments, which are always ordered alphabetically. If more are required, they are called B, C, D, E, and so forth. For example, this formula returns a boolean indicating: whether, at a minimum, 10 seconds have elapsed since the start of the game and the current object's name is Player. Arguments Variable Names Variable names can be directly used in the formula. For example, a graph variable named health can return a boolean just by typing the formula health > 50. The argument names are evaluated in the following order of priority: Alphabetical argument names (a - z) Graph variable names Object variable names Scene variable names Application variable names Saved variable names Properties and Methods Retrieve the value of a property on an argument or variable by using the [arg.prop] notation. For example, if position is a Vector 3 object variable, check if it is equal to zero with: [position.x] = 0. Get the return value of parameterless methods with the [arg.Method()] notation. Note: Accessing properties and methods is not guaranteed to be compatible with AOT platforms, because the AOT pre-build cannot generate stubs for members that are only accessed by name. Literals Use the following literals for assigning fixed values. Literal Description Example Number An integer or float. 3.5 String A piece of text between apostrophes. \"Hello World!\" Boolean A boolean value. true, false Null The null constant. a != null Delta Time The Unity frame delta time. 30 * dt Invert Delta Time The inverse of the delta time. 30 / second Operators Every common logical and mathematical operator can be used in formulas, as well as the ones defined through custom operator overloading in script. Operator Operation Rank Result Example not, ! Logical Negation Unary The opposite of the operand. not true - Numerical Negation Unary The negative of the operand. -5 and, && Logical And Binary True if both operands are true. (a < 5) and (b > 3) or, || Logical Or Binary True if either operand is true (a < 5) or (b > 3) =, == Equality Binary True if the two operands are equal. a = b !=, <> Inequality Binary True if the two operands are not equal. a != b <, <=, >, >= Numeric Comparison Binary The result of a numeric comparison a >= 10 + Addition Binary The sum of the two operands. a + 5 - Subtraction Binary The difference between the two operands. b - 3 * Multiplication Binary The product of the two operands. 12 * a / Division Binary The quotient of the two operands. b / 2 % Modulo Binary The remainder of the division of the two operands. a % 2 ?: If Ternary The left operand if the condition is true, otherwise the right operand. (health > 0) ? \"Alive\" : \"Dead\" All common bitwise operators like ~ and >> are also supported. Functions You can also use any function from the following table. Name Result Example abs The absolute value of a specified number. abs(-1) acos The angle whose cosine is the specified number. acos(1) asin The angle whose sine is the specified number. asin(0) atan The angle whose tangent is the specified number. atan(0) ceiling The smallest integer greater than or equal to the specified number. ceiling(1.5) cos The cosine of the specified angle. cos(0) exp e raised to the specified power. exp(0) floor The largest integer less than or equal to the specified number. floor(1.5) log The logarithm of a specified number. log(1, 10) log10 The base 10 logarithm of a specified number. log10(1) max The larger of two specified numbers. max(1, 2) min The smaller of two numbers. min(1, 2) pow A specified number raised to the specified power. pow(3, 2) round Rounds a value to the nearest integer or specified number of decimal places. round(3.222, 2) sign 1 if the number is positive, -1 is if it negative. sign(-10) sin The sine of the specified angle. sin(0) sqrt The square root of a specified number. sqrt(4) tan The tangent of the specified angle. tan(0) truncate The integral part of a number. truncate(1.7) v2 Creates a 2D vector. v2(0, 0) v3 Creates a 3D vector. v3(0, 0, 0) v4 Creates a 4D vector. v4(0, 0, 0, 0)"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-graph-machine-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-graph-machine-types.html",
    "title": "Script Machines and State Machines | Inventory System",
    "summary": "Script Machines and State Machines A Script Machine is a GameObject component that lets you use a Script Graph in an application. You can't use a Script Graph unless it's attached to a Script Machine. For more information on components, see Introduction to components in the Unity User Manual. Script Machines can either link to a graph asset, or they can contain an embedded Script Graph asset. A State Machine is the same as a Script Machine, except it contains a State Graph. For more information on the difference between a Script Graph and a State Graph, see Graphs. Add a Script Machine or State Machine component to a GameObject and Visual Scripting automatically adds a Variables component. The Variables component holds any Object variables that you define in a Script Graph or State Graph attached to the GameObject. For more information on variables, see Variables. For more information on how to add a Script Machine or State Machine to a GameObject and attach a graph file, see Attach a graph file to a Script Machine or State Machine Source types Script Machines and State Machines have two options for their Source: a graph file (Graph), or an embedded asset (Embed). Set the Source for a Script Machine or State Machine at any time. If you switch the Source from Graph to Embed, the graph file still exists as a separate file from the State Machine or Script Machine inside of your project. Caution If you switch your Source from Embed to Graph, you will lose the embedded graph asset. You can copy the nodes from an embedded graph to a graph asset to avoid data loss. Other features of Visual Scripting, such as transitions, Super States, and Subgraphs, also have these source type options. The Graph source type Use the Graph source type to make your graphs faster to load and easier to maintain. Any changes made to a graph file apply to every Script Machine or State Machine that links to that graph file, even if those GameObjects don't use the same Prefab. To use the same graph across multiple GameObjects, use a Graph source type. You might encounter some situations where an embedded graph works best. The Embed source type An Embed graph exists only in the scene where it's created, if it isn't attached to a Prefab. This can cause problems with source control systems. If you delete a GameObject with an Embed graph asset, you will lose your graph. Changes made to an embedded graph aren't saved while the Editor is in Play mode. Use the Embed source type if: You need references to GameObjects from the current scene in the graph and the graph isn't on a Prefab. The graph is on a Prefab that you plan to instantiate in the application during runtime. You only need to use the logic in the graph once in the application. You can't reuse an embedded graph across multiple GameObjects unless the graph is on a Prefab. An embed graph only exists on the Script Machine or State Machine where you created it. This means you can share the graph across instances of a Prefab, but not on more than one GameObject. For more information about Prefabs, see Prefabs in the User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-graph-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-graph-types.html",
    "title": "Graphs | Inventory System",
    "summary": "Graphs A graph is a Visual Scripting asset that contains a visual representation of logic in an application. Visual Scripting has two different types of graphs: Script Graphs and State Graphs. You can use either graph type in specific situations to define and change how GameObjects in an application behave. Script Graphs and State Graphs must be attached to a Script Machine or State Machine to be used in a project. For more information on Script Machines and State Machines, see Script Machines and State Machines. Script Graphs Script Graphs control and connect specific actions and values. The actions in a Script Graph happen in a specific order. Actions can happen every frame, or when a specific event occurs. Visual Scripting represents the actions in a Script Graph through nodes. Connect nodes together with edges to tell your application what to do, and in what order. Script Graphs can access a large collection of nodes, which correspond to different features and functionality in the Unity Editor. Access these nodes through the fuzzy finder. Script Graphs define the specifics of what a GameObject does while your application runs. State Graphs A State Graph has states and gives the logic for when your application moves between states, through connections called transitions. Use State Graphs to design AI behavior or define scene and level structures. A state is any set of behaviors that you want a GameObject to perform, represented as a Script Graph. Visual Scripting represents states in State Graphs through State nodes. A State node can link to a Script Graph with logic for your application to follow, or give another State Graph with additional transitions and State nodes. States and transitions in a State Graph tell your application when to change its behavior, based on an event or after it fulfills a condition. For example, you might have an enemy character with Patrol and Chase states. The enemy character's actions can change from the actions in the Script Graph for the Patrol state to the actions for the Chase state after it detects the player character. The detection event for the enemy character triggers the transition between the two states. State Graphs don't use the fuzzy finder. They use a specific set of State nodes, which are in the Visual Scripting context menu: Script States contain a Script Graph. When an application triggers a Script State, Visual Scripting runs the logic in a Script State's attached Script Graph. Script States use On Enter State Event, On Update Event, and On Exit State Event nodes to control logic based on the current state. Super States contain another, nested State Graph. A Super State can help you better organize a State Graph, and reuse states and transitions across multiple graphs. Any States serve as a placeholder for any other state in a State Graph. You can use an Any State node and create a single transition to a new state, rather than create multiple transitions from other states. Transitions connect Script States, Any States, and Super States. Transitions contain Script Graphs that tell your application when to switch from one state to the next. For more information, see Transitions. You can set any Script State node or Super State node as a Start State. Any state marked as a Start State is automatically active when Visual Scripting runs a State Graph. You can also have multiple Start States in a single graph. The Super State, Start, and Script State nodes in the following example are all Start States."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-groups.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-groups.html",
    "title": "Create node groups | Inventory System",
    "summary": "Create node groups You can organize the nodes in your Script Graphs and State Graphs with node groups. Create a new group To create a new group: Open the graph where you want to create a new group. In an empty area of the Graph Editor, Ctrl+click (macOS: Cmd+click) and drag to create a selection. Release the mouse to create the group. After you create a group, you can: Change the group name Add a comment to the group Change the color of the group Resize the group Move the group Change a group name To change the name of the group in your graph: In the group header, click Group. Enter a new name for the group. Press Enter to save your changes. Add a comment to a group To add a comment to a group in a graph: Select the group where you want to add a comment. Open the Graph Inspector. In the (Comment) field in the Graph Inspector, enter comments or information about the group. Note Group comments are only visible in the Graph Inspector. To add comments to a graph that are always visible, use a Sticky Note. Change the color of a group To change the color of a group in a graph: Select the group you want to edit. Open the Graph Inspector. In the Graph Inspector, select the Color field. Select a new color for your group through one of the following methods: Use the color picker. Use the sliders or RGBA value fields. Enter a hexadecimal color value. Select the eyedropper icon and select a color from anywhere on your screen. Resize a group To resize a group in a graph: Click and drag from any edge or corner on the group. Move a group To move a group and its nodes: Click and drag the group's header to a new location in the Graph Editor. Note You can also move a group without moving any of the nodes inside, but the required input changes based on your chosen control scheme. For more information, see Choose a control scheme Next steps After you've created a node group, you can add nodes to your Script Graph, create and add variables, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-input-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-input-nodes.html",
    "title": "Input Event nodes | Inventory System",
    "summary": "Input Event nodes Input nodes are an Event node type that can read input from Unity's Input Manager or Input System package for use in a Script Graph. For more information about how to read and capture input in Visual Scripting, see Capture user input in an application. Input System package nodes The following nodes read and interact with Events from the Input System package: Node Description On Input System Event Button The On Input System Event Button node listens for a specific Input Action from a Player Input component. It doesn't send or read any other data. On Input System Event Float The On Input System Event Float node listens for a specific Input Action from a Player Input component. The node can output a single float value. On Input System Event Vector 2 The On Input System Event Vector 2 node listens for a specific Input Action from a Player Input component. The node can output two values as a Vector 2. Input Manager nodes The following nodes read and interact with Events from Unity's Input Manager: Node Description On Button Input The On Button Input node listens for a specified action on a virtual button from your Input Manager configuration. On Keyboard Input The On Keyboard Input node listens for a specified action on a keyboard key. On Mouse Down The On Mouse Down node listens for a mouse click action on a specific GameObject in your application. On Mouse Drag The On Mouse Drag node listens for a mouse click and hold on a specific GameObject in your application. It triggers the next node connected to it as long as the mouse button is held down on that GameObject. On Mouse Enter The On Mouse Enter node listens for the user's mouse pointer location to enter the Collider of a specified GameObject. When the mouse enters the Collider or GUI element, the node triggers the next node connected to it. On Mouse Exit The On Mouse Exit node listens for the user's mouse pointer location to exit the Collider of a specified GameObject. When the mouse exits the Collider or GUI element, the node triggers the next node connected to it. On Mouse Input The On Mouse Input node listens for a specific action on a user's mouse. The action doesn't need to happen on a specific GameObject's Collider. On Mouse Over The On Mouse Over node listens for a user's mouse to land over a specified GameObject's Collider. While the user's mouse is over the Collider, it triggers the next node connected to it once every frame. On Mouse Up As Button The On Mouse Up As Button node listens for a user to release their mouse button after they click a Collider in your application. To trigger the On Mouse Up As Button node, the user must release their mouse button over the same Collider they clicked. On Mouse Up The On Mouse Up node listens for a user to release their mouse button after they click a Collider in your application. The user can release their mouse button anywhere in your application to trigger the On Mouse Up node. Additional resources Capturing input in your application Capture input using the Input System package Capture input using the Input Manager"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-interface-overview.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-interface-overview.html",
    "title": "The interface | Inventory System",
    "summary": "The interface Visual Scripting's main window is the Graph window. The Graph window has five main elements: The Graph Editor, where you create, arrange, and connect nodes. The fuzzy finder, which you can use to find nodes and add them to your graph. The Graph toolbar, where you can change settings specific to your view in the Graph Editor and perform some common layout operations. The Graph Inspector, where you can view detailed information about your nodes and configure additional settings for your graph. The Blackboard, where you can define and edit variables to use in your graphs. The Graph Editor The Graph Editor is the center editing area of the Graph window. You can use the Graph Editor to create your Visual Scripting graphs. You can create nodes and connect them with edges. You can change some default shortcuts and behaviors in the Graph Editor through your control scheme. For more information on the available control schemes in Visual Scripting, see Choose a control scheme. The fuzzy finder The fuzzy finder is a searchable menu that lists every node available in Visual Scripting. Right-click anywhere in the Graph Editor to open the fuzzy finder. Search for a node by name with the Search bar, or open a category from the list to view related nodes. For example, nodes related to the creation or manipulation of variables are in the Variables category. You can add new nodes to Visual Scripting from your own code, from other packages, or from other Unity features. For more information on how to add nodes to the fuzzy finder, see Configure project settings. The Graph toolbar The Graph toolbar lets you display or hide the Graph Inspector and Blackboard. The Graph toolbar also includes a breadcrumb trail for navigation through nested graphs that displays your current location. Select a graph from the trail to return to that graph file. You can also configure some additional settings that control how nodes display in the Graph Editor. Property Description Lock Lock the current Script Graph or State Graph to the Graph window. Visual Scripting keeps the current graph open, even if you select another GameObject with a graph file in the Hierarchy window. Graph Inspector Display or hide the Graph Inspector. Blackboard Display or hide the Blackboard. Breadcrumb Location Displays the name of the current graph. If you open a Subgraph or State Unit, or a State node inside a State Graph, use the breadcrumbs to navigate back to the parent graph. Zoom Set a zoom level for your view of the Graph Editor. Relations Enable Relations to display inner flow connections for Script Graph nodes. For example, on a standard Multiply node, the Relations setting draws a line from each input port that merges into a single line on the output port. The lines display the flow of data inside the node. Disable Relations to hide these inner connections. Values Enable Values to display the input and output values sent between nodes while the Unity Editor is in Play mode. This can make it easier to debug your scripts. Disable Values to hide input and output values while in Play mode. For more information on Play mode, see The Game view in the Unity User Manual. NOTE This setting corresponds to the Show Connection Values setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Dim Enable Dim to dim any nodes in the Graph Editor that aren't yet connected to the control flow in your graph. The Dim setting provides you with a visual cue that a node isn't used in the current configuration of your graph. Disable Dim to display all nodes as active regardless of their connection state. NOTE This setting corresponds to the Dim Inactive Nodes setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Carry Enable Carry to move all connected child nodes when you move a parent node. Disable Carry to only move the currently selected node. NOTE This setting corresponds to the Carry Children setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Align Choose an alignment option to align any nodes in your current selection. Align Left Edges Align all nodes in the selection based on their left edge. Align Centers Align all nodes in the selection based on their vertical centers. Align Right Edges Align all nodes in the selection based on their right edges. Align Top Edges Align all nodes in the selection based on their top edges. Align Middles Align all nodes in the selection based on their horizontal middles. Align Bottom Edges Align all nodes in the selection based on their bottom edges. Distribute Choose a distribution option to evenly distribute space between any nodes in your current selection. Distribute Left Edges Distribute all nodes in the selection to leave an equal distance between the left edges of each node. Distribute Centers Distribute all nodes in the selection to leave an equal distance between the vertical centers of each node. Distribute Right Edges Distribute all nodes in the selection to leave an equal distance between the right edges of each node. Distribute Horizontal Gaps Distribute all nodes in the selection to leave an equal-sized horizontal gap between each node. This distribution affects the space between the left and right edges of nodes. Distribute Top Edges Distribute all nodes in the selection to leave an equal distance between the top edges of each node. Distribute Middles Distribute all nodes in the selection to leave an equal distance between the horizontal middles of each node. Distribute Bottom Edges Distribute all nodes in the selection to leave an equal distance between the bottom edges of each node. Distribute Vertical Gaps Distribute all nodes in the selection to leave an equal-sized vertical gap between each node. This distribution affects the space between the top and bottom edges of nodes. Overview Select Overview to automatically pan and zoom to fit all elements of your current graph within the Graph Editor. Full Screen Select Full Screen when the Graph window is docked in the Unity Editor to maximize the Graph window to the full size of the Editor window. Your Visual Scripting preferences can change some settings in the Graph toolbar or change how these settings behave. For example, you can control how fast the Graph Editor zooms in and out when you set a zoom level. For more information, see Configure your preferences. The Graph Inspector The Graph Inspector provides additional information about an open graph, or about any node you select in the Graph Editor. If a node requires additional configuration, you can use the Graph Inspector to set these values. To display or hide the Graph Inspector, select Graph Inspector () from the toolbar. To move the Graph Inspector to the other side of the Graph window, select either Dock Right () or Dock Left (). The Blackboard The Blackboard provides options to configure and manage variables in a graph. The Blackboard divides variables into five distinct scopes, across five tabs: Graph, Object, Scene, App, and Saved. For more information on the available variable scopes in Visual Scripting, see Variables. To display or hide the Blackboard, select Blackboard () from the toolbar. To move the Blackboard to the other side of the Graph window, select either Dock Right () or Dock Left ()."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-live-edit-runtime.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-live-edit-runtime.html",
    "title": "Live edit during runtime | Inventory System",
    "summary": "Live edit during runtime Live editing in visual scripting goes beyond adjusting values in real-time. Live editing also includes the ability to add and remove nodes as well as connectors; you can code while the game is playing and immediately affect the gameplay. Remember that: Changes you make to embed graphs are reverted when you exit play mode; they live inside components. Changes you make to graphs are saved when you exit play mode; they live inside assets. Graph variables are saved when not in an embed graph. The following variables are not saved: Object Scene App Saved Note If you’ve used an embed graph and do not want to lose your modifications, copy all the changes you made to the embed graph before exiting Play mode. Paste them back in when in edit mode. You can’t do this for any changed variables. As a visual aid, connectors in Live mode display their execution flow with animated directional droplets going in the direction of execution. The speed and number of droplets does not represent the frequency or speed of execution. To adjust the graph during runtime With a graph open do any or all of the following: In the Inspector, click in any field to change a component’s value. The values are not persistent and won’t save when you leave Play mode. Right-click in an empty spot in the graph and add a node. Connect nodes. Delete any connectors. Add an extension. Add and link Debug nodes. Change values directly in a node. Tip Select any GameObject that contains a script graph to see and work with the values of the selected GameObject during runtime. Note When you modify anything after a Start event during runtime you won’t get the update on the GameObject during that session. You need to restart the session for Unity to execute the new logic after the start event. The changes you make to a graph are instantly shared across all instances of that saved graph asset."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-live.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-live.html",
    "title": "Live edit | Inventory System",
    "summary": "Live edit Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual Scripting supports live editing. In live editing you can create and edit graphs while in play mode and see the Visual Scripting updates in real time. This provides a fast way to iterate and test ideas without the need to recompile project changes. Working in live edit Live editing is not limited to tweaking values — you can add and remove nodes, connections (edges), etc while live. Anything that can be done in a normal edit, can be done in a live edit. In accordance with the Unity convention: Changes made to embeds are reverted when you exit play mode - the changes live inside components. Changes made to graphs are saved when you exit play mode - the changes live inside assets Tip To preserve the changes made to a component graph, copy the modified nodes before exiting play mode. You'll then be able to paste back while in edit mode. When in live mode, Visual Scripting is displayed the flow as droplets on connections. To disable these animations on either the value connections, the control connections, or both, deselect the Animate Control Connections or the Animate Value Connections from the editor preferences window (Edit > Preferences > Visual Scripting > Script Graphs). Saving changes through persistence Visual Scripting graphs automatically save the changes made during play mode. Propagation across graphs Changes made to a graph are instantly shared across all instances of that graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-state-unit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-state-unit.html",
    "title": "Add a State Unit to a Script Graph | Inventory System",
    "summary": "Add a State Unit to a Script Graph Add a State Unit to a Script Graph to trigger a change of state. A state is any set of behaviors that you want a GameObject to perform. For more information on state in Visual Scripting, see Graphs. You can add a new State Graph to a State Unit node, or use an existing State Graph from the project. For more information on the State Unit node, see State Unit node. Add a new State Graph as a State Unit node To add a new blank State Graph as a State Unit node to a Script Graph: [!include[vs-with-graph-open-ff](./snippets/vs-with-graph-open-ff.md)] Go to Nesting. Select State Unit to add a State Unit node to the graph. Open the Graph Inspector. In the Graph Inspector, choose the source for the State Unit: Embed: The State Graph only exists on the State Unit node. You can only change the State Graph from the node in its parent graph. Graph: The State Graph exists in a separate file. You can change the State Graph outside of its parent graph and reuse the graph in other areas of an application. If you chose Graph: In the Graph Inspector, select New. Enter a name for the graph file. Choose where you want to save the graph file in the project. Select Save. Add an existing State Graph as a State Unit node To add an existing State Graph file as a State Unit node in a Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Go to Nesting. Select State Unit to add a State Unit node to the graph. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible State Graph from the project. Click and drag a State Graph file from the Project window and release on the Graph field. Tip For a faster way to add a State Graph as a State Unit node: Click and drag a State Graph asset from the Project window into the Graph Editor to automatically create a State Unit node. Right-click to open the fuzzy finder. Go to Graphs and select a graph file. Next steps Select Edit Graph in the Graph Inspector to edit the graph. For more information on how to create a State Graph, see Develop logic transitions with State Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-subgraph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-subgraph.html",
    "title": "Add a Subgraph to a Script Graph | Inventory System",
    "summary": "Add a Subgraph to a Script Graph A Subgraph is a Script Graph nested inside of another Script Graph. A Subgraph appears as a single node inside a parent Script Graph. For more information on the Subgraph node, see Subgraph node. You can add a Subgraph to a Script Graph in two ways: create a new Script Graph, or add an existing Script Graph file. Add a new Subgraph to a Script Graph To add a new blank Subgraph to an existing Script Graph: [!include[vs-with-graph-open-ff](./snippets/vs-with-graph-open-ff.md)] Go to Nesting. Select Subgraph to add a Subgraph node to the graph. Open the Graph Inspector. In the Graph Inspector, choose the source for the Subgraph: Embed: The Subgraph only exists on the Subgraph node. You can only change the Subgraph from the node in its parent graph. Graph: The Subgraph exists in a separate file. You can change the Subgraph outside of its parent graph and reuse the graph in other areas of an application. If you chose Graph: In the Graph Inspector, select New. Enter a name for the graph file. Choose where you want to save the graph file in the project. Select Save. Add an existing Script Graph as a Subgraph To add an existing graph file as a Subgraph in a Script Graph: Note You can't nest a Script Graph as a Subgraph in its own graph file. With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Go to Nesting. Select Subgraph to add the Subgraph node to the graph. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible Script Graph from the project. Click and drag a Script Graph file from the Project window and release on the Graph field. Tip For a faster way to add a Script Graph as a Subgraph: Click and drag a Script Graph asset from the Project window into the Graph Editor to automatically create a Subgraph node. Right-click to open the fuzzy finder. Go to Graphs and select a graph file. Next steps To open the new Subgraph and edit the graph, select Edit Graph. After you've added a Subgraph to a Script Graph, define its ports. For more information, see Add a Trigger or Data port to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-triggers-data-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-add-triggers-data-graph.html",
    "title": "Add a Trigger or Data port to a Script Graph | Inventory System",
    "summary": "Add a Trigger or Data port to a Script Graph A Script Graph used as a Subgraph can receive data and logic from its parent graph. Add and define ports on a graph to choose what data graphs can send and receive. For more information about Subgraphs, see Subgraphs and State Units. Add ports from a graph To add a Trigger Input, Trigger Output, Data Input, or Data Output port to a Script Graph: Open the Script Graph you want to edit in the Graph window. With no nodes or groups selected in the graph, open the Graph Inspector. Select Add (+) under the port type you want to add: Trigger Inputs Trigger Outputs Data Inputs Data Outputs In the Key field, enter a unique key name for the port. The Key value can't match the Key of any existing ports on the current Script Graph. NOTE If two Key values are the same on the same graph, Visual Scripting ignores the second port definition and displays a warning in the Graph Inspector. If you change the Key value for a port after you've made a connection to that port in a graph, the connections break and you must reconnect them. In the Label field, enter a label to display for the port. The label displays on the Subgraph node and its Input or Output node. NOTE If you don't set a Label, Visual Scripting uses the value from the Key field. In the Summary field, enter a brief summary of the port to display in the Graph Inspector when you select the Subgraph node, Input node, or Output node. Toggle Hide Label to do the following: Enable Hide Label to hide the port label on any Subgraph node, Input node, or Output node. Disable Hide Label to display the data from the Label field. (Data Inputs and Data Outputs Only) Set a data type for the port: Select the Type list to open the Type menu. Select a data type from the list to set the data type the port accepts. (Data Inputs Only) Enable Has Default Value to display the Default Value field. Disable Has Default Value to hide the Default Value field. In the Default Value field, enter the default value the port uses if it doesn't receive a data input while the Script Graph runs. Add ports with Input and Output nodes You can also use an Input node or an Output node to define ports on a Script Graph: Open the Script Graph you want to edit in the Graph window. [!include[vs-open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Nesting. Do one of the following: To add a Trigger Input or Data Input port to the graph, select Input. To add a Trigger Output or Data Output port to the graph, select Output. Select the new Input or Output node in the graph. Open the Graph Inspector. In the Key field, enter a unique key name for the port. The Key value can't match the Key of any existing ports on the current Script Graph. NOTE If two Key values are the same on the same graph, Visual Scripting ignores the second port definition and displays a warning in the Graph Inspector. If you change the Key value for a port after you've made a connection to that port in a graph, the connections break and you must reconnect them. In the Label field, enter a label to display for the port. The label displays on the Subgraph node and its Input or Output node. NOTE If you don't set a Label, Visual Scripting uses the value from the Key field. In the Summary field, enter a brief summary of the port to display in the Graph Inspector when you select the Subgraph node, Input node, or Output node. Toggle Hide Label to do the following: Enable Hide Label to hide the port label on any Subgraph node, Input node, or Output node. Disable Hide Label to display the data from the Label field. (Data Inputs and Data Outputs Only) Set a data type for the port: Select the Type list to open the Type menu. Select a data type from the list to set the data type the port accepts. (Data Inputs Only) Enable Has Default Value to display the Default Value field. Disable Has Default Value to hide the Default Value field. In the Default Value field, enter the default value the port uses if it doesn't receive a data input while the Script Graph runs. Next steps Add the Script Graph as a Subgraph in another Script Graph. For more information on how to add a Script Graph as a Subgraph, see Add a Subgraph to a Script Graph. For more information on the port types on a Script Graph, see Subgraph node. The defined Trigger and Data ports affect the ports on the Input and Output nodes in a Script Graph. For more information, see Input node and Output node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-input-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-input-node.html",
    "title": "Input node | Inventory System",
    "summary": "Input node Use an Input node to control the flow of logic and data from a Script Graph's Subgraph node. An Input node takes data from a parent graph and makes it available to a Subgraph. For more information on Subgraphs, see Subgraphs and State Units and Subgraph node. For more information on Script Graphs, see Graphs. Fuzzy finder category The Input node is in the Nesting category in the fuzzy finder. Available outputs By default, an Input node has no ports. An Input node can only have output ports. Define the number and specific data type for the output ports with the Graph Inspector. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port Type Description Trigger Input A control port. Make a connection to this port to tell Visual Scripting what node to run next in the graph. Visual Scripting triggers any node to this port after the matching Trigger Input port triggers on the Subgraph node in the parent Script Graph. Data Input A data port. Make a connection to this port to send a value or other data to another node in the graph. The data source is the matching Data Input port on the Subgraph node in a parent Script Graph. Example graph usage In the following example, the Character Move Subgraph uses an Input node to receive data from a parent graph. The Input node has one Trigger Input port and three Data Input ports. It uses the values from the parent graph and the values from two Input Get Axis nodes to create a new Vector 3 value that it sends back to its parent graph. The parent graph sends three values from the current GameObject's Transform component to the Input node. The Subgraph reduces the number of nodes in the parent graph. Related nodes Use an Input node with the following nodes: Subgraph node Output node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-nodes.html",
    "title": "Nesting nodes | Inventory System",
    "summary": "Nesting nodes Use the following nodes to work with nesting Subgraphs and State Units in a Script Graph. For more information on Subgraphs and State Units, see Subgraphs and State Units. Node Description Input node Use an Input node to control the flow of logic and data from a Script Graph's Subgraph node. An Input node takes data from a parent graph and makes it available to a Subgraph. Output node Use an Output node to control the flow of logic and data from a Script Graph's Subgraph node. An Output node sends data from a Subgraph and makes it available to a parent graph. State Unit node Use a State Unit node like a Subgraph. The node references and triggers a State Graph as a State Unit inside a Script Graph. Subgraph node Use a Subgraph node to reference and trigger another Script Graph's logic from inside a parent Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-output-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-output-node.html",
    "title": "Output node | Inventory System",
    "summary": "Output node Use an Output node to control the flow of logic and data from a Script Graph's Subgraph node. An Output node sends data from a Subgraph and makes it available to a parent graph. For more information on Subgraphs, see Subgraphs and State Units and Subgraph node. For more information on Script Graphs, see Graphs. Fuzzy finder category The Output node is in the Nesting category in the fuzzy finder. Available inputs By default, an Output node has no ports. The Output node can only have input ports. Define the number and specific data type for the input ports with the Graph Inspector. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port Type Description Trigger Output A control port. Make a connection to this port to tell Visual Scripting which node triggers its exit from the Subgraph and the return to the logic in a parent graph. After the Output node runs, Visual Scripting starts any connections made to the matching Trigger Output port on the Subgraph node. Data Output A data port. Make a connection to this port to send data from a Subgraph to its parent graph. Visual Scripting returns any value from a node connected to this port to any node connected to the matching Data Output port on the Subgraph node. Example graph usage In the following example, the Character Move Subgraph uses an Input node to receive data from a parent graph. The Subgraph uses three values from the parent graph and the values from two Input Get Axis nodes to create a new Vector 3 value. The graph sends the new Vector 3 value to the Output node and back to the parent Script Graph. The Subgraph reduces the number of nodes in the parent graph. The parent graph receives the Vector 3 value from the Output node. The parent graph uses that value to set a new position on the current GameObject's Transform component. Related nodes Use an Output node with the following nodes: Subgraph node Input node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-state-unit-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-state-unit-node.html",
    "title": "State Unit node | Inventory System",
    "summary": "State Unit node Use a State Unit node like a Subgraph. The node references and triggers a State Graph inside a Script Graph. A State Unit node: Can't send or receive any data from ports. Can only trigger its associated State Graph or other nodes inside its parent Script Graph. Can't change its number or type of ports. For more information on Subgraphs and State Units, see Subgraphs and State Units. For more information on State Graphs and Script Graphs, see Graphs. Fuzzy finder category The State Unit node is in the Nesting category in the fuzzy finder. You can go to the Graphs category and select any State Graph to create a State Unit node. For more information on how to create a State Unit node, see Add a State Unit to a Script Graph. Inputs The State Unit node has the following input ports: Name Type Description Start Input Trigger The first execution Input Trigger for the node. The connection made to this port indicates when Visual Scripting runs the nested State Graph. Visual Scripting makes all states marked as Start States in the State Graph active. Stop Input Trigger The second execution Input Trigger for the node. The connection made to this port indicates when Visual Scripting stops the nested State Graph. Visual Scripting makes all states and transitions in the State Graph inactive. Outputs The State Unit node has the following output ports: Name Type Description Started Output Trigger The first execution Output Trigger for the node. The connection made to this port indicates what Visual Scripting runs after the nested State Graph starts. Stopped Output Trigger The second execution Output Trigger for the node. The connection made to this port indicates what Visual Scripting runs after the nested State Graph stops. Example graph usage Tip A State Unit node can use a new blank State Graph or an existing State Graph from a project. For more information, see Add a State Unit to a Script Graph. In the following example, a State Unit node triggers when the Script Graph's GameObject enters a specific Collider marked as a trigger. After the State Unit node starts, the Script Graph uses a Debug Log node to log Started new state! to the console. When the GameObject leaves the Collider, the State Unit node stops, and the Script Graph uses another Debug Log node to log Exited state to the console."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-subgraph-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-subgraph-node.html",
    "title": "Subgraph node | Inventory System",
    "summary": "Subgraph node Use a Subgraph node to reference and trigger another Script Graph's logic from inside a parent Script Graph. For more information on Subgraphs, see Subgraphs and State Units. For more information on Script Graphs, see Graphs. Fuzzy finder category The Subgraph node is in the Nesting category in the fuzzy finder. You can go to the Graphs category and select any Script Graph to create a Subgraph node. For more information on how to create a Subgraph, see Add a Subgraph to a Script Graph. Available ports By default, a Subgraph node has no ports. Use the Graph Inspector to specify the following on a Script Graph: Trigger Inputs. Trigger Outputs. Data Inputs. Data Outputs. These determine the type and number of ports available on its Subgraph node. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port type Description Trigger Input Adds a control input port to the Subgraph node for the Script Graph. Use a Trigger Input to choose which node or nodes from a parent graph triggers Visual Scripting to run the logic in the Subgraph. Trigger Output Adds a control output port to the Subgraph node for the Script Graph. Use a Trigger Output to choose which node or nodes Visual Scripting triggers after the logic contained in the Subgraph finishes. Data Input Adds a data input port to the Subgraph node for the Script Graph. Use a Data Input to receive data from a parent graph. Data Output Adds a data output port to the Subgraph node for the Script Graph. Use a Data Output to send data back to a parent graph. Example graph usage Tip A Subgraph node can use a new blank Script Graph or an existing Script Graph from a project. For more information, see Add a Subgraph to a Script Graph. In the following example, the Subgraph node Character Move references a graph that makes a GameObject move based on a user's input. It has the following: One Trigger Input port. One Trigger Output port. Three Data Input ports. One Data Output port. After every Update Event in the application, the Character Move Subgraph node triggers and takes the X, Y, and Z coordinates of the current GameObject's Transform component. The Subgraph node then outputs a new Vector 3 value, which the parent graph assigns to the current GameObject with a Transform Set Position node. The Subgraph node reduces the number of nodes in the parent graph. Tip To see the Script Graph attached to the Subgraph node in this example, see either Input node or Output node. Related nodes Use a Subgraph node with the following nodes: Input node Output node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-subgraphs-state-units.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nesting-subgraphs-state-units.html",
    "title": "Subgraphs and State Units | Inventory System",
    "summary": "Subgraphs and State Units In a Script Graph, you can add a node that links directly to another Script Graph or State Graph. A nested Script Graph is a Subgraph. A nested State Graph is a State Unit. A nested Script Graph or State Graph helps you to organize and reuse logic across an application. A Subgraph or State Unit can exist as the node that adds it to a graph, or it can link to an external graph file. Subgraphs A Subgraph nests a Script Graph inside another Script Graph. Use a Subgraph node to reuse a set of logic across Script Graphs in an application. A Subgraph node can take inputs or send outputs back to its parent graph. Add ports to configure what data a Subgraph and its parent graph send to each other. Subgraph inputs and outputs With the Graph Inspector, you can choose and define the ports that appear when you use a Script Graph as a Subgraph. The port definitions for a Script Graph appear in the Graph Inspector when you have no other items selected in a graph. Defined ports appear on any Subgraph node that uses that Script Graph. In the following image, the Subgraph Rotate the Cube has: A Trigger Input port. An Data Input port. An Trigger Output port. An Data Output port. A port definition also changes the Input and Output nodes for a Subgraph. These nodes control the execution and flow between a Subgraph and its parent graph. In the following image, the Input and Output nodes have the same ports as the Rotate the Cube Subgraph node from the previous example. Note You can only use a single Input node and a single Output node in a Script Graph. If you add more Input or Output nodes, Visual Scripting only uses the first Input and Output nodes you added to the graph. For more information on how to add ports to a Script Graph, see Add a Trigger or Data port to a Script Graph. For more information on the different types of ports, see Subgraph node. For more information on how to use a Subgraph, see Add a Subgraph to a Script Graph. State Units A State Unit starts a State Graph from a Script Graph. You can't change the ports that appear on a State Unit node or send data between the State Graph and its parent Script Graph. The State Unit node starts different logic in a Script Graph, at different times in code execution: When the nested State Graph starts to run. While the nested State Graph runs. When the nested State Graph stops. After the nested State Graph stops. When you start a State Unit node's Start and Started ports in a parent graph, Visual Scripting marks all Start states inside the node's State Graph as active. When you start the Stop and Stopped ports, Visual Scripting marks all Start states as inactive. For more information on State Graphs and Start states, see State Graphs. For more information on the State Unit node, see State Unit node and Add a State Unit to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-button.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-button.html",
    "title": "On Input System Event Button node | Inventory System",
    "summary": "On Input System Event Button node Note The On Input System Event Button node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Button node listens for a specific Input Action from a Player Input component. It doesn't send or read any other data. Use this node when you want to read user input but don't require any other data from an Input Action. Fuzzy finder category The On Input System Event Button node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Button node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Button node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Button node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Button node has one output port: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Example graph usage In the following example, an On Input System Event Button node counts how many times the user has pressed a button from the Fire Input Action and logs the result to the console. When a user presses a button associated with the Fire Input Action, Visual Scripting gets the current value of the Count Object variable with a Get Variable node. The Get Variable node sends Count's current value to an Add Inputs node's A port. Then, the Float literal node sends a value of 1 to the Add Inputs node's B port. The On Input System Event Button node triggers the Set Variable node and assigns the value from the Add Inputs node's Sum port as the New Value of Count. The Set Variable node logs the value of Count to the console with the Debug Log node: Related nodes The following nodes are related or similar to the On Input System Event Button node: On Input System Event Float node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-float.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-float.html",
    "title": "On Input System Event Float node | Inventory System",
    "summary": "On Input System Event Float node Note The On Input System Event Float node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Float node lists for a specific Input Action from a Player Input component. The node can output a single float value. Use this node when you want to read user input and return a single value, such as an axis value or input from a trigger on a controller. Fuzzy finder category The On Input System Event Float node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Float node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Float node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Float node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Float node has the following output ports: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Float Value Float A float output port. Visual Scripting uses your chosen Input Action and its configuration in your Input Actions asset to determine the float value returned by this port. See the Example graph usage section for an example. For more information about how to configure Input Action settings and use an Input Action asset, see Input Action Assets in the Input System package documentation. Example graph usage In the following example, an On Input System Event Float node uses the bindings assigned to the Lift Input Action. When a user presses any key from the Lift binding, Visual Scripting takes the float value it receives from the Input System and sends it as an input to the Vector 3 Create node's Y input port. At the same time, Visual Scripting triggers the Transform Set Position node and uses the output from the Vector 3 Create node to set a new position for the Script Machine's GameObject. For this example, Lift uses a Right Trigger from a Gamepad input device as a binding. When a user presses the Right Trigger, the Y value of the GameObject's transform increases, which makes the GameObject move upwards in the scene. Related nodes The following nodes are related or similar to the On Input System Event Float node: On Input System Event Button node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-vector2.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-input-system-vector2.html",
    "title": "On Input System Event Vector 2 node | Inventory System",
    "summary": "On Input System Event Vector 2 node Note The On Input System Event Vector 2 node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Vector 2 node listens for a specific Input Action from a Player Input component. The node can output two values as a Vector 2. Use this node when you want to read input and return two values, such as a joystick or mouse position. Fuzzy finder category The On Input System Event Vector 2 node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Vector 2 node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Vector 2 node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Vector 2 node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Vector 2 node has the following output ports: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Vector 2 Value Vector 2 A Vector 2 output port. Visual Scripting uses your chosen Input Action and its configuration in your Input Actions asset to determine the Vector 2 value returned by this port. See the Example graph usage section for an example. For more information about how to configure Input Action settings and use an Input Action asset, see Input Action Assets in the Input System package documentation. Example graph usage In the following example, an On Input System Event Vector 2 node uses the bindings assigned to the Move Input Action. When a user presses a button from the Move binding, Visual Scripting takes the Vector 2 value it receives from the Input System and sends it as an input to the Transform Set Position node's Value input port. The Vector 2 value changes the position of the GameObject associated with the Target transform. For this example, Move uses the W, A, S, and D keys. The GameObject moves up in the scene when the user presses W, moves down when the user presses S, and moves left or right when the user presses A or D. Related nodes The following nodes are related or similar to the On Input System Event Vector 2 node: On Input System Event Button node On Input System Event Float node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-button-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-button-input.html",
    "title": "On Button Input node | Inventory System",
    "summary": "On Button Input node Note The On Button Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Button Input node listens for a specified action on a virtual button from your Input Manager configuration. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Button Input node is in the Events > Input category in the fuzzy finder. Inputs The On Button Input node has the following input ports: Name Type Description Name String The name of the button the node listens to for an Input event, as it appears in the Input Manager. Action Press State The specific press state of the button that the node listens for. Hold The user holds down the button. Down The user presses the button. Up The user releases the button. Additional node settings The On Button Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Button Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Button Input node listens for the user to press the button or key assigned to the Jump axes in the Input Manager. When the user presses the button, the On Button Input node triggers the Rigidbody Add Force node, which adds an Impulse Force to the Rigidbody's Y axis: The Add Force node makes the Target Rigidbody lift into the air. Related nodes The following nodes are related or similar to the to the On Button Input node: On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-keyboard-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-keyboard-input.html",
    "title": "On Keyboard Input node | Inventory System",
    "summary": "On Keyboard Input node Note The On Keyboard Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Keyboard Input node listens for a specified action on a keyboard key. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Keyboard Input node is in the Events > Input category in the fuzzy finder. Inputs The On Keyboard Input node has the following input ports: Name Type Description Key Key Code The name of the keyboard key the node listens to for an Input event. For a list of all available keys, see the KeyCode page's Properties section in the Unity User manual. Action Press State The specific press state of the key that the node listens for. Hold The user holds down the key. Down The user presses the key. Up The user releases the key. Additional node settings The On Keyboard Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Keyboard Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Keyboard Input node listens for when the user presses the Space key. When the user presses Space, the On Keyboard Input triggers the Transform Translate node and lifts the GameObject along its Y coordinate by 5 units. This makes the GameObject jump. Related nodes The following nodes are related or similar to the the On Keyboard Input node: On Button Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-down.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-down.html",
    "title": "On Mouse Down node | Inventory System",
    "summary": "On Mouse Down node Note The On Mouse Down node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Down node listens for a mouse click action on a specific GameObject in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Down node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Down node has one input port: Name Type Description Target GameObject The GameObject that the user needs to click with their mouse to trigger the On Mouse Down node. Additional node settings The On Mouse Down node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Down node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Down node listens for a click action on the GameObject where the graph runs. When a user clicks the GameObject, the On Mouse Down node triggers the GameObject Instantiate node. The Instantiate node creates a new GameObject, based on the Ball Prefab. It creates the Ball at a specific Position. It uses the Transform Get Local Rotation to match the new GameObject's Rotation to the GameObject where the Script Graph runs. Then, the graph adds a Rigidbody component to the new GameObject, and uses a Rigidbody Add Force node to add an Impulse force. When the user clicks the mouse button, the Script Graph creates a new Ball GameObject and sends it towards the camera. Related nodes The following nodes are related or similar to the On Mouse Down node: On Button Input node On Keyboard Input node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-drag.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-drag.html",
    "title": "On Mouse Drag node | Inventory System",
    "summary": "On Mouse Drag node Note The On Mouse Drag node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Drag node listens for a mouse click and hold on a specific GameObject in your application. It triggers the next node connected to it as long as the mouse button is held down on that GameObject. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Drag node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Drag node has one input port: Name Type Description Target GameObject The GameObject the user needs to click and hold with their mouse to trigger the On Mouse Drag node. Additional node settings The On Mouse Drag node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Drag node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Drag node triggers a Camera Screen To World Point node. When the user clicks and holds their mouse button over the Target GameObject from the On Mouse Drag node, the Script Graph gets the user's current mouse position with an Input Get Mouse Position node. The graph uses the X and Y values from the Get Mouse Position node's Vector 3 result to create a new Vector 3 value, with a fixed Z value. The Screen To World Point node uses the new Vector 3 and the camera saved in the Main Camera Scene variable to set the position of the Target GameObject's transform. The Script Graph allows the user to drag the Target GameObject around the scene when hold down their mouse button. Related nodes The following nodes are related or similar to the On Mouse Drag node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-enter.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-enter.html",
    "title": "On Mouse Enter node | Inventory System",
    "summary": "On Mouse Enter node Note The On Mouse Enter node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Enter node listens for the user's mouse pointer location to enter the Collider of a specified GameObject. When the mouse enters the Collider or GUI element, the node triggers the next node connected to it. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Enter node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Enter node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Enter node. Additional node settings The On Mouse Enter node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Enter node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Enter node triggers the Instantiate GameObject node when the user's mouse enters the Collider on the Script Machine's GameObject. The Instantiate node creates an instance of the Light Prefab, at the Prefab's Position and with the Prefab's Rotation. The graph saves the new instance of the GameObject to a Scene variable, Spotlight, so it can interact with the GameObject again later. The result is a spotlight that appears over the On Mouse Enter node's Target GameObject, when the user's mouse enters the Collider. Related nodes The following nodes are related or similar to the On Mouse Enter node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-exit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-exit.html",
    "title": "On Mouse Exit node | Inventory System",
    "summary": "On Mouse Exit node Note The On Mouse Exit node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Exit node listens for the user's mouse pointer location to exit the Collider of a specified GameObject. When the mouse exits the Collider or GUI element, the node triggers the next node connected to it. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Exit node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Exit node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Exit node. Additional node settings The On Mouse Exit node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Exit node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, continued from the example from the On Mouse Enter node, the On Mouse Exit node triggers a Destroy GameObject node when the user's mouse exits the Collider on the Script Machine's GameObject. The Destroy GameObject node destroys the GameObject assigned to the Spotlight Scene variable. The GameObject was created and assigned to the variable elsewhere in the graph. When the user's mouse leaves the Collider, the Target GameObject no longer has a spotlight. Related nodes The following nodes are related or similar to the On Mouse Exit node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-input.html",
    "title": "On Mouse Input node | Inventory System",
    "summary": "On Mouse Input node Note The On Mouse Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Input node listens for a specific action on a user's mouse. The action doesn't need to happen on a specific GameObject's Collider. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Input node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Input node has the following input ports: Name Type Description Button Mouse Button The name of the mouse button that triggers the On Mouse Input node. Action Press State The specific state of the mouse button that the node listens for. Hold The user holds down the mouse button. Down The user presses the mouse button. Up The user releases the mouse button. Additional node settings The On Mouse Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Input node listens for the user to hold the right mouse button and triggers an Instantiate Camera node. The Instantiate node clones the camera saved as the Camera1 Scene variable and assigns it to the NewCamera Scene variable. It sets a new position for the cloned camera with a Transform Set Position node, before it switches which camera renders in the Game view with the Camera Render node. When the application runs, the default view in the Game view displays all three spheres in the scene. When the user holds the right mouse button and triggers the On Mouse Input node, the Game view changes to focus on the middle sphere. Related nodes The following nodes are related or similar to the On Mouse Input node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-over.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-over.html",
    "title": "On Mouse Over node | Inventory System",
    "summary": "On Mouse Over node Note The On Mouse Over node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Over node listens for a user's mouse to land over a specified GameObject's Collider. While the user's mouse is over the Collider, it triggers the next node connected to it once every frame. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Over node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Over node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Over node. Additional node settings The On Mouse Over node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Over node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Over node triggers a Timer node when the user moves their mouse over the Target GameObject. The Timer runs for 2 seconds and triggers a Color Lerp node. For every Tick of the Timer node, the Color Lerp node uses the Elapsed value to calculate a new Color between Color A and Color B to make a smooth transition between colors. The Material Set Color node uses the Result from the Color Lerp node to set a new Color on the Object material. While the user's mouse is over the Target GameObject, the objects that use the Object material in the scene transition from red to blue over two seconds. The transition repeats until the user's mouse leaves the Target's Collider. Related nodes The following nodes are related or similar to the On Mouse Over node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-up-button.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-up-button.html",
    "title": "On Mouse Up As Button node | Inventory System",
    "summary": "On Mouse Up As Button node Note The On Mouse Up As Button node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Up As Button node listens for a user to release their mouse button after they click a Collider in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. To trigger the On Mouse Up As Button node, the user must release their mouse button over the same Collider they clicked. If you want the user to trigger the node after they release their mouse button at any location in your application, use the On Mouse Up node instead. Fuzzy finder category The On Mouse Up As Button node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Up As Button node has one input port: Name Type Description Target GameObject The GameObject the user must click and release with their mouse button to trigger the node. Additional node settings The On Mouse Up As Button node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Up As Button node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Up As Button node runs as a coroutine to load a new scene after the user clicks and releases their mouse button over the Target GameObject. The Script Graph loads the scene, makes the graph wait until the scene loads, then sets the loaded scene as the active scene in the application. When the application starts, the active scene contains a plane with three spheres. After the Script Graph runs, the scene changes to a plane with a single cube. Related nodes The following nodes are related or similar to the On Mouse Up As Button node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-up.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-events-on-mouse-up.html",
    "title": "On Mouse Up node | Inventory System",
    "summary": "On Mouse Up node Note The On Mouse Up node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Up node listens for a user to release their mouse button after they click a Collider in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. The user can release their mouse button anywhere in your application to trigger the On Mouse Up node. If you want the node to trigger after the user releases the mouse button over the same Collider specified in the node's Target, use the On Mouse Up As Button node instead. Fuzzy finder category The On Mouse Up node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Up node has one input port: Name Type Description Target GameObject The GameObject the user needs to click with their mouse button to have the On Mouse Up node listen for a mouse button release action. The user can release their mouse button anywhere to trigger the On Mouse Up node, but they must click the GameObject specified as the Target. Additional node settings The On Mouse Up node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Up node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Up node adds a force to a GameObject based on the user's mouse position when they release their mouse button. The On Mouse Up node triggers a Camera Screen To World Point node to get the user's mouse position, before it sends the X value of the mouse to a Rigidbody Add Force node to move the GameObject. When the user clicks on the sphere in the middle of the scene and releases their mouse button, the sphere moves towards their mouse location. Related nodes The following nodes are related or similar to the On Mouse Up node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes-reference.html",
    "title": "Node reference | Inventory System",
    "summary": "Node reference Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Nodes are the most basic element of computation in visual scripting. Nodes display the required information as text, but editing is done via the Inspector. To edit them, select any node and edit its properties in the Inspector. This node The This node returns the game object that owns the machine in which the graph runs. Control nodes Control nodes branch, loop and merge the flow. Time nodes Time nodes include timer, cooldown and wait nodes. Events Scripting nodes listen for events. They are the starting point for all scripts and appear as special green nodes in graphs. Variables These nodes get, set, and check variables. Nulls Nodes that deal with the nulls, a.k.a. \"nothing\" value. Formulas Formula evaluates logical and mathematical expressions directly via a textual Formula and match with multiple arguments."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nodes.html",
    "title": "Nodes | Inventory System",
    "summary": "Nodes Nodes are the most basic part of scripts in Visual Scripting. A node can listen for events, get the value of a variable, modify a component on a GameObject, and more. Nodes appear as blocks in the Graph Editor. You can arrange and connect these blocks with edges to create logic for an application. Add nodes with the fuzzy finder. Click and drag a node to move it in the Graph Editor. Node anatomy Visual Scripting highlights nodes in your current selection. All nodes have a header, which displays the node's name. Some node headers might contain additional information or controls. Select a node in your graph, the Visual Scripting Graph Inspector displays the following information: The node's name and type icon. A brief description of what the node does, if available. The current warning messages or errors for the node. The additional settings for the node, if available. The required type for each input port and a brief description, if available. The type for each output port and a brief description, if available. Connections and ports Connect a port from one node to a compatible port on another node to create an edge. Edges form the logic flow in a Visual Scripting graph. Click any port to create a new edge. Edges are color-coded: edges that control the logic flow in your graph are white. Data edges are colored based on their type. For more information about types, see Object types. When you create a new edge, Visual Scripting highlights ports on any other nodes in a graph where you can make a valid connection. If you enable Dim Incompatible Nodes, Visual Scripting also dims any nodes or ports without a valid connection. Ports on the left side of a node are Input Ports. Ports on the right side of a node are Output Ports. An input port or output port can be a Control Port or a Data Port: Control Ports control the logical flow in a graph. They tell Visual Scripting what order to execute the nodes in a graph, from left to right. The icon for a control port is always an arrow. These arrows display the direction of the flow of logic in a graph. Data Ports send and receive data, such as number values or GameObjects, between nodes. They have colors that correspond to the specific type they expect to receive as inputs, or send as outputs. Their icons change based on their type. You can make multiple connections to or from the same port, with some restrictions: You can connect a single Data Output port to multiple Data Input ports. You can't connect multiple Data Output ports to a single Data Input port. Visual Scripting can't choose which value to use. You can connect multiple Control Output ports to a single Control Input port. You can't connect a single Control Output port to multiple Control Input ports. Visual Scripting can't choose which node to run first. For more information on how to connect nodes, see Connect nodes in a Script Graph. More complex nodes can have more complex or specialized ports, outside of the ports described here. Node controls and inline values A node might have additional controls that display on its header or in the Graph Inspector. Controls can change the available ports or behavior of a node. Some ports might also use inline values. Element Example Description Control A control appears as a dropdown option on the header of a node. For example, a Container Type control might tell a node to expect to receive a GameObject instead of a Script Machine. Inline Value An inline value appears as an object picker field next to a port. You can use an inline value instead of a node connection to specify a value for a node. Not all Visual Scripting types support inline values. ## Node overloads Variations of a Visual Scripting node are called overloads. Overloads change the input and output data that a node can accept, and can change the number of input or output data ports on a node. For example, the Add node has four overloads, as shown in the following image of the fuzzy finder after a search for Add. You can distinguish each overload through its subcategory in the fuzzy finder. The Add node is a part of the Math category, but each overload is a part of a different subcategory: Generic, Scalar, Vector 2, Vector 3, or Vector 4. The specific node overload changes what input and output data the Add node can accept. While a Generic Add node can input and output any object type in Visual Scripting, a Vector 3 Add node can only take 3D vectors as an input, and can only output a single 3D vector: The default type and number of ports on the Add node stays consistent across its overloads. For the Rotate node, the type and number of ports varies. Based on the Rotate node you select, you might be able to specify the angle of rotation as a vector, as separate float values, or as an angle relative to each axis. You can also choose whether the node rotates the GameObject relative to itself, or relative to the center of the scene's world space."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nulls.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-nulls.html",
    "title": "Nulls node | Inventory System",
    "summary": "Nulls node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Null nodes deal with the null value, which is scripting lingo for \"nothing\". The null node The null node always returns null as a value. Leaving a Unity object reference field empty (\"None\") automatically means null. Null Check The null check is a shortcut for a branch on an equality comparison with null. It can be useful to direct the flow in different directions depending on whether a value is null. For example, it can be used to handle a situation differently whether a transform has a parent in the hierarchy or not. Null Coalesce The null coalesce node provides a fallback value in case the original input is null. For example, the null coalesce node defines a default fallback audio clip in case the one on the audio source is missing."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-open-graph-edit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-open-graph-edit.html",
    "title": "Open a graph file | Inventory System",
    "summary": "Open a graph file You can open a graph file from multiple locations, based on the graph type and its source type. For information on how to create a new graph file, see Create a new graph file. From the Project window To open a graph from the Project window: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Find the location in your Project window's folders where you saved the graph file you want to edit. Double-click the graph file to open it in the Graph window. From the Graph Inspector If you have a nested or embedded graph inside another graph file, you can open it from the Graph Inspector. In the Graph window, select the node that represents the graph you want to edit. This node could be a transition, Super State, Subgraph, or State Unit. Open the Graph Inspector. In the Graph Inspector, select Edit Graph. The graph opens in the same Graph window. From a Script Machine or State Machine If you've attached or embedded a graph in a Script Machine or State Machine on a GameObject, you can open the graph from the component on the GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject that has the Script Machine or State Machine with the graph you want to edit. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. On the Script Machine or State Machine component, select Edit Graph. Next steps After you open a graph file, you can add a node to the graph. For more information on how to add a node to a Script Graph, see Add a node to a Script Graph. For more information on how to edit a State Graph, see Develop logic transitions with State Graphs. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-refactor-add-attribute.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-refactor-add-attribute.html",
    "title": "Add the RenamedFrom attribute to a C# script | Inventory System",
    "summary": "Add the RenamedFrom attribute to a C# script To use nodes generated from a custom C# script in a project after you rename a member, class, struct, type, or enum, add the [RenamedFrom] attribute to the relevant API element in the script file. For more information on the [RenamedFrom] attribute, see Refactor a C# script with Visual Scripting. To add the attribute to a C# script: [!include[vs-open-project-window](./snippets/vs-open-project-window.md)] In the Project window, double-click the C# script file you want to refactor. Unity opens the file in the program you specified in your preferences, under External Script Editor. NOTE For more information on script editors in Unity, see Integrated development environment (IDE) support in the Unity User Manual. In your external editor, do the following: Add the [RenamedFrom] attribute above the definition of the part of the script you want to rename. Add the element's old name as a string to the [RenamedFrom] attribute, as its parameter. For example: using UnityEngine; using Unity.VisualScripting; [RenamedFrom(\"Character\")] public class Player : MonoBehaviour { [RenamedFrom(\"InflictDamage\")] public void TakeDamage(int damage) { //... } } [!include[vs-save-script](./snippets/vs-save-script.md)] [!include[vs-return-unity](./snippets/vs-return-unity.md)] [!include[vs-regen-node-library](./snippets/vs-regen-node-library.md)] Note If you change the namespace or namespaces used in your script, you must include the old namespace or namespaces to use the [RenamedFrom] attribute. Next steps Unity recommends that you leave the attribute in the script file, even after a successful recompile. Nodes that use your C# script no longer have errors related to a missing member, class, struct, type, or enum. Additional resources Refactor a C# script with Visual Scripting Configure project settings Add or remove types from your Type Options Custom C# nodes Custom events"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-refactoring.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-refactoring.html",
    "title": "Refactor a C# script with Visual Scripting | Inventory System",
    "summary": "Refactor a C# script with Visual Scripting Visual Scripting creates nodes from methods, fields, and properties from C# script in your project. Visual Scripting creates these nodes after you regenerate your Node Library and add any relevant types to your Type Options. For example, Visual Scripting created the following Take Damage node from a custom C# script that defines the Player class. Visual Scripting generated the node with the following code, which creates a Player class with a TakeDamage member. using UnityEngine; public class Player : MonoBehaviour { public void TakeDamage(int damage) { //... } } Tip You can create your own custom node or create a custom event to customize the ports and information displayed on your nodes. If you change the name of the TakeDamage member in the C# script, Visual Scripting displays an error in Script Graphs that use the Take Damage node. To rename a member, type, class, struct, enum, or other API element that a Visual Scripting node uses in a project, add the [RenamedFrom] attribute to the relevant API element in the script file. To avoid issues with Unity's serialization, the [RenamedFrom] attribute tells Visual Scripting that an API or one of its elements has been renamed. For more information on how to add the [RenamedFrom] attribute to a C# script, see Add the RenamedFrom attribute to a C# script. Additional resources Add the RenamedFrom attribute to a C# script Configure project settings Add or remove types from your Type Options Custom C# nodes Custom events"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-relations.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-relations.html",
    "title": "Use relations to debug | Inventory System",
    "summary": "Use relations to debug Relations are a useful tool to understand the dependencies between each port of a node. For example, to get the result of A + B with the Add node, you need to provide a value for A and B. Likewise, before invoking the Log node, you should provide a value for its Message input port. Visual scripting uses this information in the background for Predictive Debugging. For example, if you tried to get the value of A + B without providing a value for A, the node would show up as orange to indicate that it fails in play mode. When that happens, you can use the warnings shown in the Graph Inspector to know what is missing. Relations can also help understand the ports that are required and which ports are optional. For example, in the Get Child node (under fuzzy finder Codebase > Unity Engine > Transform), there is no need to connect the control ports if the goal is to get the transform value output. Enable the Relations toggle in the toolbar for the inner connections of each node to be displayed. Note You cannot edit relations. They are predefined for each type of node."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-script-graphs-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-script-graphs-intro.html",
    "title": "Develop application logic with Script Graphs | Inventory System",
    "summary": "Develop application logic with Script Graphs Use Script Graphs to create interactions and logic in your project. Create a graph file Create a graph file to get started. For more information, see Create a new graph file. Add and connect nodes After you have a graph file, add a node or connect nodes together to build logic. Create Subgraphs Reuse logic with Subgraphs. Debug your graphs You can use relations to help you debug your scripts, or use Visual Scripting's predictive debugging to help you catch problems."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-scripts-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-scripts-reference.html",
    "title": "Script Graph nodes | Inventory System",
    "summary": "Script Graph nodes Visual scripting has four nodes that you can use to identify and manipulate the Script Graphs assigned to a GameObject and its Script Machines: Set Script Graph Has Script Graph Get Script Graph Get Script Graphs Set Script Graph You can use the Set Script Graph node to assign a Script Graph to a specific Script Machine, or to the first Script Machine attached to a specific GameObject. Item Description Node Parameters Container Type Specifies whether the Target is a GameObject or Script Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or Script Machine) The GameObject or Script Machine where the node sets the Graph. Graph (Script Graph Asset) The Script Graph the node sets on the Target. Output Ports Exit (Output Trigger) The execution output trigger. Graph (Script Graph Asset; Optional) Outputs the Graph. Setting the required node parameters and inputs The Set Script Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and assigns the graph to the first Script Machine attached to that GameObject. If you choose Script Machine, the node expects to receive a Script Machine, and you can specify the exact Script Machine where you want to set your Script Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject Script Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Set Script Graph node. The other two ports collect the Set Script Graph node's required input data: The Target, or the GameObject or Script Machine where you want to set a Script Graph. The Graph, or the Script Graph to assign to the GameObject or Script Machine. Outputs The Set Script Graph node has two output ports, located on the right side. The first port, Exit, establishes the connection to the node that should execute after the Set Script Graph node has finished. The second port, Graph, can output the Script Graph that you assigned using the node. Has Script Graph The Has Script Graph node allows you to determine whether a GameObject or Script Machine has a specific Script Graph assigned to it. Item Description Node Parameters Container Type Specify whether the Target is a GameObject or Script Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or Script Machine) The GameObject or Script Machine where the node should check for the Graph. Graph (Script Graph Asset) The Script Graph to search for on the GameObject or Script Machine. Output Ports Exit (Output Trigger) The execution output trigger, which starts execution of the next node in the flow after checking for the specified Script Graph. Has Graph (Boolean) Outputs true if the node found the specified Script Graph, false if not. Setting the required node parameters and inputs The Has Script Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and checks for the graph on the first Script Machine attached to that GameObject. If you choose Script Machine, the node expects to receive a Script Machine, and you can specify the exact Script Machine where you want to check for the Script Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject Script Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Has Script Graph node. The other two ports collect the Has Script Graph node's required input data: The Target, or the GameObject or Script Machine where you want to check for a Script Graph. The Graph, or the Script Graph to search for on the GameObject or Script Machine. Outputs The Has Script Graph node returns true if it finds the specified Script Graph. Otherwise, it returns false. You can use a control node connected to the Has Script Graph's output port to change what your script does next, based on the result from Has Script Graph. For more information about control nodes, see Control nodes. Get Script Graph The Get Script Graph node returns the first Script Graph set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a set Script Graph. Output Ports Graph (Script Graph Asset) Outputs the first or only Script Graph set on the GameObject, or null if there is no set Script Graph. Setting the required node parameters and inputs The Get Script Graph node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve the Script Graph. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get Script Graph node has a single output port, located on the right side. The output port returns the GameObject's first set Script Graph, or null, if there is no set Script Graph. Note The Get Script Graph node returns only the first Script Graph set on a GameObject. To return all Script Graphs set on a GameObject, use the Get Script Graphs node. Get Script Graphs The Get Script Graphs node returns a list of all Script Graphs set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a list of set Script Graphs. Output Ports Graphs (List of Script Graph Assets) Outputs a list of all Script Graphs set on the GameObject, or an empty list if there are no set Script Graphs. Setting the required node parameters and inputs The Get Script Graphs node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve a list of Script Graphs. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get Script Graphs node has a single output port, located on the right side. The output port returns a list of all set Script Graphs for the GameObject, or an empty list, if there are no set Script Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-self.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-self.html",
    "title": "This node | Inventory System",
    "summary": "This node Use a This node to return a GameObject with a Script Machine component that has the Script Graph. If the Script Machine uses an Graph source and multiple GameObjects use the same graph, the returned GameObject can change. Many nodes default their target to This. For example, the following Transform nodes are the same: Not all nodes support the This inline value. Any node that doesn't support the This inline value displays None instead of This in the default value field. For example, the Destroy node displays None. In these cases, manually specify the connection if you want to use This. You can use the This node in a graph even if the graph isn't yet assigned to a GameObject. The This node represents the GameObject that owns the graph at runtime."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-set-preferences.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-set-preferences.html",
    "title": "Configure your preferences | Inventory System",
    "summary": "Configure your preferences You can configure specific preferences in Visual Scripting to control the behavior of the Graph window and your nodes. To configure your preferences for Visual Scripting: Go to Edit > Preferences. Select Visual Scripting. Core preferences The following preferences control general behaviors across all graph types in Visual Scripting. Preference Description Dim Inactive Nodes Enable Dim Inactive Nodes to dim any nodes in the Graph Editor that aren't connected to the logic flow in a graph. This provides you with a visual cue that a dimmed node isn't used in the graph in its current configuration. Disable Dim Inactive Nodes to display all nodes as active, regardless of their connection state. NOTE You can also control this preference from the Graph toolbar. For more information, see The interface. Dim Incompatible Nodes Enable Dim Incompatible Nodes to dim all nodes that don't have a compatible connection port when you create a new edge. Disable Dim Incompatible Nodes to display all nodes as active for a new edge. Show Variables Help Enable Show Variables Help to display a brief explanation of the selected variable scope in the Blackboard. Disable Show Variables Help to hide these explanations. Create Scene Variables Enable Create Scene Variables to automatically create a Scene Variables GameObject with a Variables component and a Scene Variables script component after you create a Scene variable. A GameObject with these components is required to use Scene variables in a project. Disable Create Scene Variables to create these components on a GameObject manually. Show Grid Enable Show Grid to display a grid on the background of the Graph Editor. Disable Show Grid to hide the grid. Snap to Grid Enable Snap to Grid to force nodes to stick or snap to points on a grid in the Graph Editor. Disable Snap to Grid to move nodes freely and disable the snap-to-point behavior. Pan Speed Set a Pan Speed to control how quickly the view in the Graph Editor moves when you pan vertically with the scroll wheel. Drag Pan Speed Set a Drag Pan Speed to control how quickly the view in the Graph Editor moves when you move a node to the edge of the Graph window. Zoom Speed Set a Zoom Speed to control how quickly the Graph Editor zooms in or zooms out while you change the zoom level in the Graph window. For more information on how to change the zoom level in the Graph Editor, see Choose a control scheme. Overview Smoothing Set an Overview Smoothing to control how gradually the Graph Editor zooms or pans after you select the Overview option in the Graph toolbar. Carry Children Enable Carry Children to move all connected child nodes when you move a parent node in the Graph Editor. Disable Carry Children to only move the currently selected node in the Graph Editor. NOTE You can also change this setting from the Graph toolbar in the Graph window. For more information, see The interface. Disable Playmode Tint Enable Disable Playmode Tint to display all nodes in the Graph window as normal while the Unity Editor is in Play mode. Disable Disable Playmode Tint to add a tint to all nodes in the Graph window while the Editor is in Play mode. For more information on Play mode, see The Game view in the Unity User Manual. Control Scheme Select a Visual Scripting control scheme. For more information, see Choose a control scheme. Default Use the Default Visual Scripting control scheme. Alternate Use the Alternate Visual Scripting control scheme. Clear Graph Selection Enable Clear Graph Selection to clear any graph displayed in the Graph window after you select a GameObject with no set graph or graphs. Disable Clear Graph Window to keep the last displayed graph if the selected GameObject has no set graph assets. NOTE Visual Scripting always updates the Graph window to display the set graph on a selected GameObject, regardless of your chosen Clear Graph Selection setting. Human Naming Enable Human Naming to convert all displayed method names from camel case to title case. For example, camelCase becomes Camel Case. Disable Human Naming to leave all names in camel case. Max Search Results Set a Max Search Results value to specify the maximum number of search results returned by the fuzzy finder after you use the search bar. Group Inherited Members Enable Group Inherited Members to group together inherited nodes from a parent or base class to your current search term in the fuzzy finder. For example, an Audio Source is a Component: it has its own specific methods and nodes, but you can interact with it as a Component with Component nodes. While you perform a search in the fuzzy finder, Visual Scripting groups the nodes inherited from Component and displays them in grey. Disable Group Inherited Members to display nodes in the search results without grouping these inherited nodes. Developer Mode Enable Developer Mode to display additional preferences in the Preferences window and add additional features in the Graph window and other areas of the Unity Editor. For more information on the additional Developer Mode preferences, see Additional Developer Mode preferences. AOT Safe Mode Enable AOT Safe Mode to exclude nodes from search results in the fuzzy finder that might cause problems for platforms that require ahead of time (AOT) compilation. For example, Visual Scripting excludes nodes that use the Generic type. Disable AOT Safe Mode to display all nodes and types in the fuzzy finder. Script Graphs preferences The following preferences change the behavior of Script Graphs in the Graph window. Preference Description Update Nodes Automatically NOTE This feature is experimental. Enable Update Nodes Automatically to let Visual Scripting automatically update your Node Library when it detects a change in any script inside your project's Assets folder. Disable Update Nodes Automatically to manually regenerate your Node Library after you make a change to a script. For more information on how to regenerate your Node Library, see Configure project settings. Predict Potential Null References A predictive debugging feature. Enable Predict Potential Null References to display warnings about potential null value inputs in your graphs. Disable Predict Potential Null References to disable these warnings. NOTE Sometimes, predictive debugging might return false positive results when you enable this setting. Predict Potential Missing Components A predictive debugging feature. Enable Predict Potential Missing Components to display warnings about potential missing components in your graphs, such as a missing node input. Disable Predict Potential Missing Components to disable these warnings. NOTE Sometimes, predictive debugging might return false positive results when you enable this setting. Show Connection Values Enable Show Connection Values to display the input and output values sent between nodes while the Editor is in Play mode. This can make it easier to debug your scripts. Disable Show Connection Values to hide these value labels while in Play mode. For more information on Play mode, see The Game view in the User Manual. NOTE You can also control this preference from the Graph toolbar. For more information, see The interface. Predict Connection Values Enable Predict Connection Values to have the Graph Editor predict what input and output values your graph sends between nodes while the Unity Editor is in Play mode. For example, Visual Scripting would display the value currently set for a variable in your script, though that value might change before it's used by a node. Disable Predict Connection Values to hide these predicted input and output values. Hide Port Labels Enable Hide Port Labels to hide the name labels for node input and output ports. Disable Hide Port Labels to display these name labels. Animate Control Connections Enable Animate Control Connections to display a droplet animation across node control port edges while the Editor is in Play mode. Disable Animate Control Connections to disable the animations. For more information about the different node port types and edges, see Nodes. For more information on Play mode, see The Game view in the User Manual. Animate Value Connections Enable Animate Value Connections to display a droplet animation across node data port edges while the Editor is in Play mode. Disable Animate Value Connections to disable the animations. For more information about the different node port types and edges, see Nodes. For more information on Play mode, see The Game view in the User Manual. Skip Context Menu Enable Skip Context Menu to always open the fuzzy finder when you right-click in the Graph Editor. To access the context menu, use Shift+right-click. Disable Skip Context Menu to open the fuzzy finder when you right-click with no nodes or groups selected in the Graph Editor. The context menu opens when you right-click with a node or group selected. State Graphs preferences The following preferences change the behavior of State Graphs in the Graph window. Preference Description States Reveal Use the dropdown to choose when a Script State node displays a list of events from its graph. If you have many Script State nodes in a State Graph, you might want to change this setting. Never Script State nodes never display their list of events. Always Script State nodes always display their list of events. On Hover Script State nodes only display their list of events when you hover over the node in the Graph window. On Hover with Alt Script State nodes only display their list of events when you hover over the node while you hold Alt. When Selected Script State nodes only display their list of events when you select the node in the Graph window. On Hover or Selected Script State nodes display their list of events when you hover over the node, or when you select the node in the Graph window. On Hover with Alt or Selected Script State nodes display their list of events when you hover over the node while you hold Alt, or when you select the node in the Graph window. Transitions Reveal Use the dropdown to choose when a transition displays a list of events from its graph. If you have many transitions in a State Graph, you might want to change this setting. Never Transitions never display a list of events. Always Transitions always display a list of events. On Hover Transitions only display a list of events when you hover over the transition in the Graph window. On Hover with Alt Transitions only display a list of events when you hover over the transition while you hold Alt. When Selected Transitions only display a list of events when you select the transition in the Graph window. On Hover or Selected Transitions display a list of events when you hover over the transition, or when you select the transition in the Graph window. On Hover with Alt or Selected Transitions display a list of events when you hover over the transition while you hold Alt, or when you select the transition in the Graph window. Transitions End Arrow Enable Transitions End Arrow to add an arrow to the end of each transition edge in a State Graph. Disable Transitions End Arrow to display edges between transitions as simple lines. If you have many transitions in your State Graphs, you might want to disable this setting. Animate Transitions Enable Animate Transitions to display a droplet animation across transition edges when the Editor is in Play mode. Disable Animate Transitions to disable the animations. For more information on Play mode, see The Game view in the User Manual. Additional Developer Mode preferences Note You can only access the following preferences after you have enabled *Developer Mode in your Core preferences. These Developer Mode preferences provide help with developing extensions or custom nodes for Visual Scripting. Their continued support in the Visual Scripting package isn't guaranteed. Preference Description Debug Enable Debug to add additional logging and visual overlays to help you debug element rendering in the Graph window. For example, if you created a custom node, use this setting to help debug your UI. Disable Debug to disable the logging and hide these overlays. Track Metadata State Enable Track Metadata State to add more information to logging. This can assist in debugging. Disable Track Metadata State to hide this additional information. Debug Inspector UI Enable Debug Inspector UI to add more overlays and additional details. The information available is greater than what Visual Scripting provides with the Debug setting, and affects more areas of the Editor's UI. Only enable this setting if you need more in-depth debugging feedback. Disable Debug Inspector UI to hide this information."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-state-graphs-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-state-graphs-intro.html",
    "title": "Develop logic transitions with State Graphs | Inventory System",
    "summary": "Develop logic transitions with State Graphs You can use State Graphs to change behaviors of GameObjects based on specific conditions. Create a new state After you create a new graph file for a State Graph, you can create states to tell Visual Scripting what a GameObject does, and when. Create a transition Use transitions to tell Visual Scripting when a GameObject changes states. There's no restriction on how many transitions you can create. State Unit nodes You can use a State Unit node to nest a State Graph inside a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-states-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-states-reference.html",
    "title": "State Graph nodes | Inventory System",
    "summary": "State Graph nodes Visual scripting has four nodes that you can use to identify and manipulate the State Graphs assigned to a GameObject and its State Machines: Set State Graph Has State Graph Get State Graph Get State Graphs Set State Graph You can use the Set State Graph node to assign a State Graph to a specific State Machine, or to the first State Machine attached to a specific GameObject. Item Description Node Parameters Container Type Specifies whether the Target is a GameObject or State Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or State Machine) The GameObject or State Machine where the node sets the Graph. Graph (State Graph Asset) The State Graph the node sets on the Target. Output Ports Exit (Output Trigger) The execution output trigger. Graph (State Graph Asset; Optional) Outputs the Graph. Setting the required node parameters and inputs The Set State Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and assigns the graph to the first State Machine attached to that GameObject. If you choose State Machine, the node expects to receive a State Machine, and you can specify the exact State Machine where you want to set your State Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject State Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Set State Graph node. The other two ports collect the Set State Graph node's required input data: The Target, or the GameObject or State Machine where you want to set a State Graph. The Graph, or the State Graph to assign to the GameObject or State Machine. Outputs The Set State Graph node has two output ports, located on the right side. The first port, Exit, establishes the connection to the node that should execute after the Set State Graph node has finished. The second port, Graph, can output the State Graph that you assigned using the node. Has State Graph The Has State Graph node allows you to determine whether a GameObject or State Machine has a specific State Graph assigned to it. Item Description Node Parameters Container Type Specify whether the Target is a GameObject or State Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or State Machine) The GameObject or State Machine where the node should check for the Graph. Graph (State Graph Asset) The State Graph to search for on the GameObject or State Machine. Output Ports Exit (Output Trigger) The execution output trigger, which starts execution of the next node in the flow after checking for the specified State Graph. Has Graph (Boolean) Outputs true if the node found the specified State Graph, false if not. Setting the required node parameters and inputs The Has State Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and checks for the graph on the first State Machine attached to that GameObject. If you choose State Machine, the node expects to receive a State Machine, and you can specify the exact State Machine where you want to check for the State Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject State Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Has State Graph node. The other two ports collect the Has State Graph node's required input data: The Target, or the GameObject or State Machine where you want to check for a State Graph. The Graph, or the State Graph to search for on the GameObject or State Machine. Outputs The Has State Graph node returns true if it finds the specified State Graph. Otherwise, it returns false. You can use a control node connected to the Has State Graph's output port to change what your script does next, based on the result from Has State Graph. For more information about control nodes, see Control nodes. Get State Graph The Get State Graph node returns the first State Graph set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a set State Graph. Output Ports Graph (State Graph Asset) Outputs the first or only State Graph set on the GameObject, or null if there is no set State Graph. Setting the required node parameters and inputs The Get State Graph node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve the State Graph. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get State Graph node has a single output port, located on the right side. The output port returns the GameObject's first set State Graph, or null, if there is no set State Graph. Note The Get State Graph node returns only the first State Graph set on a GameObject. To return all State Graphs set on a GameObject, use the Get State Graphs node. Get State Graphs The Get State Graphs node returns a list of all State Graphs set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a list of set State Graphs. Output Ports Graphs (List of State Graph Assets) Outputs a list of all State Graphs set on the GameObject, or an empty list if there are no set State Graphs. Setting the required node parameters and inputs The Get State Graphs node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve a list of State Graphs. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get State Graphs node has a single output port, located on the right side. The output port returns a list of all set State Graphs for the GameObject, or an empty list, if there are no set State Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-sticky-notes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-sticky-notes.html",
    "title": "Add comments to a graph | Inventory System",
    "summary": "Add comments to a graph Use Sticky Notes to add comments to a graph. Sticky Notes can: Describe how a section of your graph works. Leave a note for yourself or others who might work on your Unity project. You can add text to the title and body of a Sticky Note. You can use Sticky Notes in Script Graphs and State Graphs. Add a Sticky Note to a graph To add a Sticky Note to a graph: Open a graph file in the Graph window. Do one of the following: Right-click anywhere in the Graph Editor to open the fuzzy finder. Select Sticky Note. With no items selected in the graph, right-click an empty space in the Graph Editor. Select Create Sticky Note. Edit a Sticky Note To edit text in the title or body of a Sticky Note: Open a graph file in the Graph window. Do one of the following: To edit the title of the Sticky Note, double-click the title. To edit the body of the Sticky Note, double-click the body. Enter the new text for the Sticky Note. Click anywhere in the Graph Editor to close the Sticky Note text editor. Tip You can also edit the text in a Sticky Note with the Graph Inspector: Select the Sticky Note you want to edit. Select Graph Inspector () from the toolbar. Do one of the following: To edit the title of the Sticky Note, select the title. To edit the body of the Sticky Note, select (Body). Enter the new text for the Sticky Note. Move a Sticky Note To move a Sticky Note to a new location in a graph: Open a graph file in the Graph window. Click and drag the Sticky Note to a new location. Delete a Sticky Note To delete a Sticky Note from a graph: Open a graph file in the Graph window. Do one of the following: Right-click a Sticky Note and select Delete. Select a Sticky Note and press Delete (Del). Resize a Sticky Note To change the size of a Sticky Note in a graph: Open a graph file in the Graph window. Click and drag a corner of a Sticky Note. Change the color of a Sticky Note To change the color theme for a Sticky Note: Open a graph file in the Graph window. Select the Sticky Note you want to edit. Select Graph Inspector () from the toolbar. Select a Color Theme: Classic Black Dark Orange Green Blue Red Purple Teal"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-time.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-time.html",
    "title": "Time nodes | Inventory System",
    "summary": "Time nodes Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Time nodes include timer, cooldown and wait nodes. Wait Wait nodes delay the execution of the rest of the script. The delay can be a set amount of seconds or a condition that must be fulfilled before moving on. Asynchronicity (delayed execution) in Unity is handled by coroutines (not multithreading). You need to inform visual scripting to run the script as a coroutine in order to support wait nodes. To do this enable the Coroutine checkbox on the initial event that starts the script. Do this in the graph inspector. A small dual-arrow icon appears on the event, indicating that it runs as a coroutine. If the coroutine checkbox is not enabled, an error at runtime indicates a port 'can only be triggered in a coroutine' when reaching a wait node. All wait nodes are also used inside loops and sequences. Wait For Seconds The Wait For Seconds node is the simplest and most common wait node. It delays the execution by a certain number of seconds. Wait Until The Wait Until node stops execution until a given condition is met. For example, you could wait until an object is close enough. Wait While The Wait While node is the opposite of the Wait Until node: it stops execution as long as a given condition is met. For example, you can wait while an object is out of range. Wait For Frame As the name implies, Wait For End Of Frame and Wait For Next Frame nodes delays execution until a specific point in Unity's update loop is met. For more information, see: Execution Order of Events. Wait For Script The Wait For Script node delays execution until all input scripts have been entered at least once. It's a useful way of grouping conditions that occur over multiple events or frames. In other languages, this concept is sometimes called \"promises\". Cooldown The Cooldown node implements a time restriction when the input script can only be triggered a limited number of times. When the cooldown is available, the input script gets transferred to the Ready port. When it is not, it gets transferred to the Not Ready port. The Duration port determines how long it takes for the cooldown to become available again. Checking Unscaled makes it ignore the time scale. The Tick port gets called at every frame while a cooldown is active. It is a good place to update any GUI code that show an indicator of the remaining duration until the action can be called again. In order to get that value, you have two options: Remaining, which returns the number of seconds until ready, and Remaining %, which returns a value between 0 and 1, respectively from ready to not ready. As soon as the cooldown is ready, the Completed port is triggered. There is no need to constantly pass input script for this port to get triggered. Finally, you can force the cooldown to become ready and reset its internal timer by triggering the Reset port. For example, a simple cooldown firing mechanic with a masked sprite and text that indicates how much time is remaining until it can fire again. Timer The Timer node implements and monitors a time pausable progression. The Duration port determines how long it takes for the cooldown to become available again. Checking Unscaled makes it ignore the time scale. A timer is started by triggering the Start input, which in turn triggers the Started output. It can be paused and resumed with the Pause and Resume inputs, or it can alternate between these states with the Toggle input. The Tick port gets called at every frame while a timer is active. In order to get the time measurements, you have two options: Elapsed, which returns the time since the timer was started, or Remaining, which returns the time until the timer completes. You can get each of these measurements in absolute number of seconds, or in %, which returns a value between 0 and 1. This is useful for lerping. As soon as the timer finishes, the Completed port is triggered. For example, a simple autodestroy mechanic on a sprite that is progressively colored red before being destroyed."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-transitions.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-transitions.html",
    "title": "Transitions | Inventory System",
    "summary": "Transitions A transition is a connection between State nodes in a State Graph. A transition has a Script Graph that tells Visual Scripting when to switch states in a State Graph. A special transition type, called a self transition, can make a state transition to itself. You can embed the Script Graph for a transition in the Transition node itself, or link to an external graph asset file. Use Event nodes and a Trigger Transition node in the Script Graph you attach to a transition. These nodes specify which event or events must occur to trigger a change of state in your parent State Graph. For example, the following transition Script Graph switches states after a GameObject with the Player tag enters a trigger Collider. Any transition nodes with a transition Script Graph display the name of the event in the graph that triggers the state change. For example, the following parent State Graph displays the graph from the previous example as an On Trigger Enter Transition node. If you've assigned a name to a transition Script Graph, the assigned name appears on the Transition node. Tip To reduce the space taken up by transition nodes in a State Graph, you can hide their name labels. For more information, see Configure your preferences. You can create any number of transitions between states in a State Graph. For more information on how to create transitions, see Create a transition between states."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-types.html",
    "title": "Object types | Inventory System",
    "summary": "Object types All scripting in Unity is based on the C# programming language. C# is a \"strongly typed\" language. This means that all data and objects in Visual Scripting have a specific type. For example, a variable can be a number with an integer type, or the object provided by a node's output port can be a GameObject. Types help the computer run Visual Scripting code. Visual Scripting's behavior might not depend on the object type you give a node as an input, but sometimes, an object's type is important. For example, to add a new variable in the Blackboard, you must specify the variable's type to assign it a value. When you make a new edge in the Graph Editor, some nodes might have ports that only allow a connection if the data input is the correct type. Choose the type for an object with the Type menu. For example, you can choose the type for a Data Input port on a Script Graph with the Type menu from the Graph Inspector. Enter a search term in the Type menu to find a specific object type. You can also navigate through the namespaces listed in the Type menu to find a type. Visual Scripting identifies namespaces in the Type menu with an arrow (>). Select any namespace to view the other namespaces or available types within that namespace. Common object types Unity has hundreds of types. You can also add your own custom types. For more information on custom types, see Custom types. The following table includes some commonly used types in Visual Scripting. Type Description Float A float is a numeric value, with or without decimal places. For example, 0.25 or 13.1. Integer An integer is a numeric value without decimal places. For example, 3 or 200. Boolean A Boolean is a true or false value. Use a Boolean to create logic in a Script Graph and for toggles. For example, a Script Graph can trigger an event only if a condition is true. String A string is a sequence of characters or piece of text. For example, string, string123, and s. Char A char is a single alphanumeric character from a string. For example, s or 1. Enum An enum is a finite enumeration of options. Enums are usually represented as dropdowns. For example, a Force Mode enum can have a value of either Force, Impulse, Acceleration, or Velocity Change. Vector A vector represents a set of float coordinates. Unity uses vectors for positions or directions. Vector 2 A Vector 2 has X and Y values. You can use a Vector 2 for coordinates in 2D spaces. Vector 3 A Vector 3 has X, Y, and Z values. You can use a Vector 3 for coordinates in 3D spaces. Vector 4 A Vector 4 has X, Y, Z, and W values. You can use a Vector 4 for coordinates in 4D spaces, such as parameters for shaders. GameObject A GameObject is the basic entity used in Unity scenes. All GameObjects have a name, a transform for their position and rotation in the scene, and a list of components. List A list is an ordered collection of elements. The elements in a list can each have their own type or all have the same type. Visual Scripting indexes items in a list with the first position at 0. This means that the first element of a list is at the 0 index of the list. The second item is at the 1 index, the third is at the 2 index, and so on. Dictionary A dictionary is a collection of elements. Each element has a unique key and a value. Use a key to access and assign the values for an element in a dictionary. For example, you can use a dictionary to organize the names and ages of a group of people. The person's name is the key to the value of their age. A single element in the dictionary can be John and 33. Object An Object is a special type in Unity. If a data input port on a node has its type set to Object, the node doesn't need a specific type as an input. Supported type conversions Visual Scripting can automatically convert some data types passed between nodes. For example, the following graph gets the Transform from a child GameObject of the current GameObject, and triggers an Animator Controller to play an animation. Visual Scripting converts the Transform component sent by the Transform Get Child node to the Animator Controller component on the same GameObject. Visual Scripting can automatically perform the following type conversions: Number to Number (for example, you can convert an integer to a float, such as 5 to 5.0, or 5.0 to 5) Base class to child class Child class to base class Custom operators (for example, you can convert a Vector 2 to a Vector 3) GameObject to a component (for example, a GameObject to its Rigidbody component) Component to GameObject (for example, a Rigidbody component to its GameObject) Component to component on the same GameObject (for example, a Rigidbody component to a Transform component) Enum to array Enum to list"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-update.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-update.html",
    "title": "Update Visual Scripting | Inventory System",
    "summary": "Update Visual Scripting Tip Back up your data before you update to a new version of Visual Scripting. For more information on how to back up your Visual Scripting assets and settings, see Create or restore a backup. Before you update, confirm that the version of Visual Scripting is compatible with your current project and needs. For example, you shouldn't use a Preview version of Visual Scripting in a production environment. For more information on package states and the package lifecycle in Unity, see the Package state and lifecycle in the Unity User Manual. To update your current version of Visual Scripting: Go to Window > Package Manager. In the Packages drop-down menu, select In Project. In your list of packages, select Visual Scripting. Select Update to X.X.X, where X.X.X is the newest available version of Visual Scripting."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-using-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-using-custom-types.html",
    "title": "Use a custom type | Inventory System",
    "summary": "Use a custom type Visual Scripting supports every class and struct type available in Unity. By default, the most common are available in the fuzzy finder. Add additional Unity assemblies, such as custom types and classes, through your project settings. You must write some additional code to use a custom type or class in a graph. You can't assign a value to a variable with a custom type from Unity's Inspector window, or initialize it from inside the Unity Editor if this additional code isn't available. You must assign a default value for a custom type through the Inspector window to use that type for a variable in Visual Scripting. You have two options to enable variable assignment and initialization: If you have access to the source code, you can add the [Inspectable] attribute to the classes and fields that you want to display and modify in the Editor. If you don't have access to the source code, you must create a custom PropertyDrawer and generate the required property provider scripts. Add the [Inspectable] attribute Add the [Inspectable] attribute to the code for your custom class to display its available properties in the Inspector window and Visual Scripting's Graph Inspector. You can't view your classes and fields in the Inspector window without the [Inspectable] attribute. Unity provides a basic UI for your types in the Inspector window, which might not give the aesthetic results you want. If you or your users want to configure a property for a custom type with a slider, for example, don't use the [Inspectable] attribute method. For more information on how to add the [Inspectable] attribute to a custom class, see Add the Inspectable attribute to the source code for a custom type. Create a custom PropertyDrawer Create a custom PropertyDrawer to choose how to display each property for a custom class in the Inspector window. Without access to the source code, you must create a PropertyDrawer to interact with custom-typed variables in Visual Scripting. If you see an error in the Unity Editor's Inspector window when you try to use a type from a third-party package, you must create a custom PropertyDrawer. Note If you are a package developer, or plan to provide your custom classes and types to other users and want those types to be available in Visual Scripting, create a custom PropertyDrawer to get the best results for your users. For more information on how to create a custom PropertyDrawer, see Create a custom PropertyDrawer for a custom type. After you create a custom PropertyDrawer for a custom type, you must generate the necessary property provider scripts. For more information, see the Generate option in Configure project settings."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables-api.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables-api.html",
    "title": "Variables API | Inventory System",
    "summary": "Variables API Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting provides an easy API to handle variables, to get or set their value and verify if they are defined. All these operations are available from the Variables class. For example: Variables.Application.Set(\"score\", 100); Usings Add the following usings to your C# script to access the API: using Unity.VisualScripting; Scopes Graph To access variables on a graph, create a graph reference. This is basically a path to the nested graph from its root machine. To get the root graph on a machine: var graphReference = GraphReference.New(flowMachine, true); To access nested graphs, pass their parent nodes as additional parameters: var graphReference = GraphReference.New(flowMachine, new IGraphParentElement[] { subGraph }, true); To pass a graph reference: Variables.Graph(graphReference) Object To access variables on an object: Variables.Object(gameObject) Scene To access scene variables, do one of the following: Variables.Scene(scene) Or: Variables.Scene(gameObjectInScene) Or: Variables.ActiveScene Application To access application variables: Variables.Application Saved To access saved variables: Variables.Saved Operations In these examples, the lowercase scope refers to one of the previous scopes. Get To get the value of a variable, use the Get method with a name parameter: scope.Get(\"name\"); Note that variables are not strongly typed; they need to be cast manually. For example: int health = (int)Variables.Object(player).Get(\"health\") Set To set the value of a variable, use the Set method with the name and value parameters: scope.Set(\"name\", value); For example: Variables.Object(player).Set(\"health\", 100); Because variables are not strongly typed, pass any value to the second parameter, even if the variable currently is of a different type. Note Using the set method with a variable name that does not yet exist defines a new variable. Is Defined To check if a variable is defined, use the IsDefined method with a name parameter: scope.IsDefined(\"name\"); For example: if (Variables.Application.IsDefined(\"score\")) { // ... }"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables-reference.html",
    "title": "Variables node | Inventory System",
    "summary": "Variables node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. There are six kinds of variable nodes. Each of these variable nodes has three object nodes: Get, to retrieve the value of the variable Set, to assign a new value to the variable Is Defined, to check whether the variable is defined They are located under the Variables category in the fuzzy finder. Variable nodes are teal colored. Dynamic Typing For get / set nodes, variables are not statically typed, meaning their type can change at runtime. Their type displays as an object when defined from the blackboard window. Get Variable The get variable node requires the name of the variable as an input and returns the Value as an output. Set Variable The set variable nodes require the name of the variable and the new value assigned to it as inputs. For convenience in layouting, it returns this same value as an output. Connect the control input port to indicate when the variable should be assigned and, optionally, the control output port to indicate what to do after. Using a set node with a variable name that doesn't yet exist creates the variable. Has Variable The Has Variable nodes require the name of the variable as an input and returns an Is Defined boolean as an output. They're useful to check if a variable has been created, and often, provide a fallback value if it hasn't. Do the same thing more easily by checking the Fallback box in the graph inspector for a Get Variable node. This adds a Fallback input to the node that is returned if the variable hasn't been defined: Dynamic Variables As the name of the variable is a standard value input port, connect it to any other port that returns a string. Refer to \"dynamic variables\", that is, variables whose reference might change during play mode. Object Variables Object variable nodes require an additional input for the Source. That port indicates which game object the variable you're referring to is defined. When left to its default value, they look on the current object (self). For example, the Get Variable node gets the value of the health variable on the player2 object. Dropdowns The kind and the name dropdowns can quickly configure the variable nodes. The name suggestions are contextual and are based on the existing variables of this kind and on the other variable nodes in the current graph. Drag and Drop Drag and drop items from the blackboard window directly into the graph to create matching nodes. By default, a Get node is created. If the Alt key is held, a Set node is created. If the Shiftkey is held, an Is Defined node is created. Variables API Visual scripting provides an easy API to handle variables, to get or set their value and verify if they are defined. All these operations are available from the Variables class. For example: Variables.Application.Set(\"score\", 100); Usings Add the following usings to your C# script to access the API: using Unity.VisualScripting; Scope Graph To access variables on a graph, create a graph reference. This is basically a path to the nested graph from its root machine. To get the root graph on a machine: var graphReference = GraphReference.New(flowMachine, true); To access nested graphs, pass their parent nodes as additional parameters: var graphReference = GraphReference.New(flowMachine, new IGraphParentElement[] { superUnit }, true); To pass a graph reference: Variables.Graph(graphReference) Object To access variables on an object: Variables.Object(gameObject) Scene To access scene variables, do one of the following: Variables.Scene(scene) Or: Variables.Scene(gameObjectInScene) Or: Variables.ActiveScene Application To access application variables: Variables.Application Saved To access saved variables: Variables.Saved Operations In these examples, the lowercase scope refers to one of the previous scopes. Get To get the value of a variable, use the Get method with a name parameter: scope.Get(\"name\"); Note that variables are not strongly typed; they need to be cast manually. For example: int health = (int)Variables.Object(player).Get(\"health\") Set To set the value of a variable, use the Set method with the name and value parameters: scope.Set(\"name\", value); For example: Variables.Object(player).Set(\"health\", 100); Because variables are not strongly typed, pass any value to the second parameter, even if the variable currently is of a different type. Note Using the set method with a variable name that does not yet exist defines a new variable. Is Defined To check if a variable is defined, use the IsDefined method with a name parameter: scope.IsDefined(\"name\"); For example: if (Variables.Application.IsDefined(\"score\")) { // ... }"
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-variables.html",
    "title": "Variables | Inventory System",
    "summary": "Variables Variables act as a container for a piece of information that might change as an application runs. To define a variable, you need to provide: A name for the variable, such as MyVariable. The type of data the variable holds, such as int or string . A value for the variable, such as 1 or cat. In Visual Scripting, you can give a node the name of a variable, instead of a fixed value or text. Your Script Graph uses the variable's name to access its value. For example, you can use a variable called Count, with an int type and a value of 1. You can use an Add node in Visual Scripting to add 1 to the value of Count, and save the new value in Count to use again in another part of your Script Graph, or a different Script Graph. Variables also have scopes. A variable's scope determines what parts of your Script Graph can access which variables to read or modify their values. The scope can also decide whether another Script Graph can access a variable. You can create and manage variables in a graph from the Blackboard. For more information on the Blackboard, see The Blackboard. For more information on how to use variables, see Create and add a variable to a Script Graph. Variable scopes Each variable scope has its own tab on the Blackboard, except Flow variables. Visual Scripting has six variable scopes. Variable Scope Property Flow Variables Flow variables are like local variables in a scripting language: they have the smallest scope. You can't use a Flow variable if: The Flow variable doesn’t have a direct or indirect connection to the nodes where you want to use its value. The node where the variable is defined must be a part of the logical flow where you want to use its value. The Flow variable hasn’t been set before Visual Scripting tries to run any logic that needs its value. The node where the variable is defined must come before any other logic in your graph. You can't create a Flow variable from the Blackboard - you can create one with a Set Variable node and set the Scope to Flow. Graph Variables Graph variables belong to a specific Script Graph. You can't access or modify Graph variables outside the specific Script Graph where they're defined. You also can't create a new Graph variable unless you have a Script Graph open in the Graph window. Object Variables Object variables belong to a specific GameObject. You can edit an Object variable from the Unity Editor's Inspector for the GameObject, and the Object variable is accessible in all graphs attached to the GameObject. You can't create a new Object variable unless you've opened your Script Graph from a Script Machine component on a GameObject. Scene Variables Scene variables belong to the current scene. Visual Scripting creates a new GameObject in your scene to hold references to your Scene variables. You can access your Scene variables from any Script Graph attached to a different GameObject in a single scene, but can't access a Scene variable in another scene in your project. App or Application Variables Application variables belong to your entire application. You can access an Application variable across multiple scenes while your application runs, and the Application variable would hold your changes. Any values held in an Application variable reset to their default values after your application quits. Saved Variables Saved variables are like Application variables, but they persist even after your application quits. You can use a Saved variable as a simple but powerful save system. Unity stores Saved variables in its PlayerPrefs, and they don't refer to Unity objects, like GameObjects and components. For more information on PlayerPrefs, see PlayerPrefs in the Unity User Manual Scripting Reference. Note You can still access the Blackboard and create new variables with a State Graph open in the Graph window, but you can't add a variable node and use it inside a State Graph. For Saved variables, there are two additional tabs on the Blackboard: Initial and Saved: Values defined in the Initial tab apply to all new instances of your application as default values. Values defined in the Saved tab are the last modified values for those variables, based on when you last ran your application. You can edit them manually, or delete the values to reset them to the values defined in the Initial tab."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-version-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Documentation~/vs-version-control.html",
    "title": "Version control systems | Inventory System",
    "summary": "Version control systems To avoid any problems with automatically generated files, exclude some Visual Scripting files from your version control solution. To exclude files from version control, include a file or configure your settings to specify which files and folders to exclude: Create a new file at the root of your project directory. Tip The root of your project directory is at the level above your Assets folder. Name the file based on your chosen version control system: Git: .gitignore. For more information, see Git's documentation on gitignore. Unity Collab: .collabignore. For more information, see the Unity User Manual. Subversion: Ignore the files from your svn:ignore property or runtime configuration options. For more information, see Subversion's documentation on Ignoring Unversioned Items. Open the file in a text editor. Add the appropriate files or file patterns to your ignore file or configuration. For an example and more information, see Ignore file template. Note If you have an issue when you try to create a .gitignore file on Windows, refer to Microsoft's documentation on how to create a .gitignore file from the command line. Ignore file template The following template ignores all core Visual Scripting files, but preserves your project settings and variables. It also includes the standard Unity ignore directives for files that you can exclude from version control. For more information, see the Unity.gitignore file included in GitHub's gitignore template repository. Refer to the comments in the template for which lines to comment or remove. # Optionally exclude these transient (generated) files, # because they can be easily re-generated by the package Assets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db Assets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db.meta Assets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers Assets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers.meta ## Unity # From: https://github.com/github/gitignore/blob/master/Unity.gitignore /[Ll]ibrary/ /[Tt]emp/ /[Oo]bj/ /[Bb]uild/ /[Bb]uilds/ /[Ll]ogs/ /[Uu]ser[Ss]ettings/ # MemoryCaptures can get excessive in size. # They also could contain extremely sensitive data /[Mm]emoryCaptures/ # Asset meta data should only be ignored when the corresponding asset is also ignored !/[Aa]ssets/**/*.meta # Uncomment this line if you want to ignore the asset store tools plugin # /[Aa]ssets/AssetStoreTools* # Autogenerated Jetbrains Rider plugin /[Aa]ssets/Plugins/Editor/JetBrains* # Visual Studio cache directory .vs/ # Gradle cache directory .gradle/ # Autogenerated VS/MD/Consulo solution and project files ExportedObj/ .consulo/ *.csproj *.unityproj *.sln *.suo *.tmp *.user *.userprefs *.pidb *.booproj *.svd *.pdb *.opendb *.VC.db # Unity3D generated meta files *.pidb.meta *.pdb.meta *.mdb.meta # Unity3D Generated File On Crash Reports sysinfo.txt # Builds *.apk *.aab *.unitypackage # Crashlytics generated file crashlytics-build.properties # Packed Addressables /[Aa]ssets/[Aa]ddressable[Aa]ssets[Dd]ata/*.*.bin* # Temporary auto-generated Android Assets /[Aa]ssets/[Ss]treamingAssets/aa.meta /[Aa]ssets/[Ss]treamingAssets/aa/* Remove previously committed files If you committed any files to a version control solution that you want to exclude: See Git's documentation on the git-rm command. See Subversion's documentation on the svn delete command."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/LICENSE.html",
    "title": "| Inventory System",
    "summary": "com.unity.visualscripting copyright © 2020 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/README.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/README.html",
    "title": "Visual Scripting (com.unity.visualscripting) | Inventory System",
    "summary": "Visual Scripting (com.unity.visualscripting) Visual Scripting, previously known as BOLT, is an alternative workflow to design behaviours. Instead of the classic method of writing a C# script, visual scripting offers a way to design behaviours intuitively without code, by connecting events, actions, and data together in a graph. Both programmers and non-programmers can use node-based graphs to design final logic or to quickly create prototypes. This package also features an API that programmers can use for more advanced tasks, or to create custom nodes that can be used by other team members. Required Software Unity: Supported versions include 2021.1 Documentation Documentation is available here. For further discussion, visit the Discord or the Visual Scripting forum."
  },
  "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@6279e2b7c485/Third Party Notices.html",
    "title": "| Inventory System",
    "summary": "This package contains third-party software components governed by the license(s) indicated below: Component Name: AQN Parser License Type: Microsoft Public License Copyright © 2013 Christophe Bertrand https://www.codeproject.com/Tips/624300/AssemblyQualifiedName-Parser This license governs use of the accompanying software. If you use the software, you accept this license. If you do not accept the license, do not use the software. Definitions The terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law. A \"contribution\" is the original software, or any additions or changes to the software. A \"contributor\" is any person that distributes its contribution under this license. \"Licensed patents\" are a contributor's patent claims that read directly on its contribution. Grant of Rights (A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create. (B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software. Conditions and Limitations (A) No Trademark License- This license does not grant you rights to use any contributors' name, logo, or trademarks. (B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically. (C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software. (D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license. (E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement. Component Name: Deep Copy License Type: MIT Copyright © 2014 Alexey Burtsev https://github.com/Burtsev-Alexey/net-object-deep-copy Permission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the \"Software\"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included inall copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: DotNetZip License Type: Microsoft Public License Copyright © 2017 Ionic https://dotnetzip.codeplex.com/ This license governs use of the accompanying software. If you use the software, you accept this license. If you do not accept the license, do not use the software. Definitions The terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law. A \"contribution\" is the original software, or any additions or changes to the software. A \"contributor\" is any person that distributes its contribution under this license. \"Licensed patents\" are a contributor's patent claims that read directly on its contribution. Grant of Rights (A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create. (B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software. Conditions and Limitations (A) No Trademark License- This license does not grant you rights to use any contributors' name, logo, or trademarks. (B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically. (C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software. (D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license. (E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement. Component Name: FatCow Icons License Type: Creative Commons Attribution 3.0 Copyright © 2017 FatCow Web Hosting https://www.fatcow.com/free-icons THE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS CREATIVE COMMONS PUBLIC LICENSE (\"CCPL\" OR \"LICENSE\"). THE WORK IS PROTECTED BY COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS AUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED. BY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE TO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY BE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND CONDITIONS. Definitions \"Collective Work\" means a work, such as a periodical issue, anthology or encyclopedia, in which the Work in its entirety in unmodified form, along with one or more other contributions, constituting separate and independent works in themselves, are assembled into a collective whole. A work that constitutes a Collective Work will not be considered a Derivative Work (as defined below) for the purposes of this License.\"Derivative Work\" means a work based upon the Work or upon the Work and other pre-existing works, such as a translation, musical arrangement, dramatization, fictionalization, motion picture version, sound recording, art reproduction, abridgment, condensation, or any other form in which the Work may be recast, transformed, or adapted, except that a work that constitutes a Collective Work will not be considered a Derivative Work for the purpose of this License. For the avoidance of doubt, where the Work is a musical composition or sound recording, the synchronization of the Work in timed-relation with a moving image (\"synching\") will be considered a Derivative Work for the purpose of this License.\"Licensor\" means the individual, individuals, entity or entities that offers the Work under the terms of this License.\"Original Author\" means the individual, individuals, entity or entities who created the Work.\"Work\" means the copyrightable work of authorship offered under the terms of this License.\"You\" means an individual or entity exercising rights under this License who has not previously violated the terms of this License with respect to the Work, or who has received express permission from the Licensor to exercise rights under this License despite a previous violation.2. Fair Use Rights. Nothing in this license is intended to reduce, limit, or restrict any rights arising from fair use, first sale or other limitations on the exclusive rights of the copyright owner under copyright law or other applicable laws. License Grant. Subject to the terms and conditions of this License, Licensor hereby grants You a worldwide, royalty-free, non-exclusive, perpetual (for the duration of the applicable copyright) license to exercise the rights in the Work as stated below: to reproduce the Work, to incorporate the Work into one or more Collective Works, and to reproduce the Work as incorporated in the Collective Works;to create and reproduce Derivative Works provided that any such Derivative Work, including any translation in any medium, takes reasonable steps to clearly label, demarcate or otherwise identify that changes were made to the original Work. For example, a translation could be marked \"The original work was translated from English to Spanish,\" or a modification could indicate \"The original work has been modified.\";;to distribute copies or phonorecords of, display publicly, perform publicly, and perform publicly by means of a digital audio transmission the Work including as incorporated in Collective Works;to distribute copies or phonorecords of, display publicly, perform publicly, and perform publicly by means of a digital audio transmission Derivative Works.For the avoidance of doubt, where the Work is a musical composition: Performance Royalties Under Blanket Licenses. Licensor waives the exclusive right to collect, whether individually or, in the event that Licensor is a member of a performance rights society (e.g. ASCAP, BMI, SESAC), via that society, royalties for the public performance or public digital performance (e.g. webcast) of the Work.Mechanical Rights and Statutory Royalties. Licensor waives the exclusive right to collect, whether individually or via a music rights agency or designated agent (e.g. Harry Fox Agency), royalties for any phonorecord You create from the Work (\"cover version\") and distribute, subject to the compulsory license created by 17 USC Section 115 of the US Copyright Act (or the equivalent in other jurisdictions).Webcasting Rights and Statutory Royalties. For the avoidance of doubt, where the Work is a sound recording, Licensor waives the exclusive right to collect, whether individually or via a performance-rights society (e.g. SoundExchange), royalties for the public digital performance (e.g. webcast) of the Work, subject to the compulsory license created by 17 USC Section 114 of the US Copyright Act (or the equivalent in other jurisdictions).The above rights may be exercised in all media and formats whether now known or hereafter devised. The above rights include the right to make such modifications as are technically necessary to exercise the rights in other media and formats. All rights not expressly granted by Licensor are hereby reserved. Restrictions. The license granted in Section 3 above is expressly made subject to and limited by the following restrictions: You may distribute, publicly display, publicly perform, or publicly digitally perform the Work only under the terms of this License, and You must include a copy of, or the Uniform Resource Identifier for, this License with every copy or phonorecord of the Work You distribute, publicly display, publicly perform, or publicly digitally perform. You may not offer or impose any terms on the Work that restrict the terms of this License or the ability of a recipient of the Work to exercise the rights granted to that recipient under the terms of the License. You may not sublicense the Work. You must keep intact all notices that refer to this License and to the disclaimer of warranties. When You distribute, publicly display, publicly perform, or publicly digitally perform the Work, You may not impose any technological measures on the Work that restrict the ability of a recipient of the Work from You to exercise the rights granted to that recipient under the terms of the License. This Section 4(a) applies to the Work as incorporated in a Collective Work, but this does not require the Collective Work apart from the Work itself to be made subject to the terms of this License. If You create a Collective Work, upon notice from any Licensor You must, to the extent practicable, remove from the Collective Work any credit as required by Section 4(b), as requested. If You create a Derivative Work, upon notice from any Licensor You must, to the extent practicable, remove from the Derivative Work any credit as required by Section 4(b), as requested.If You distribute, publicly display, publicly perform, or publicly digitally perform the Work (as defined in Section 1 above) or any Derivative Works (as defined in Section 1 above) or Collective Works (as defined in Section 1 above), You must, unless a request has been made pursuant to Section 4(a), keep intact all copyright notices for the Work and provide, reasonable to the medium or means You are utilizing: (i) the name of the Original Author (or pseudonym, if applicable) if supplied, and/or (ii) if the Original Author and/or Licensor designate another party or parties (e.g. a sponsor institute, publishing entity, journal) for attribution (\"Attribution Parties\") in Licensor's copyright notice, terms of service or by other reasonable means, the name of such party or parties; the title of the Work if supplied; to the extent reasonably practicable, the Uniform Resource Identifier, if any, that Licensor specifies to be associated with the Work, unless such URI does not refer to the copyright notice or licensing information for the Work; and, consistent with Section 3(b) in the case of a Derivative Work, a credit identifying the use of the Work in the Derivative Work (e.g., \"French translation of the Work by Original Author,\" or \"Screenplay based on original Work by Original Author\"). The credit required by this Section 4(b) may be implemented in any reasonable manner; provided, however, that in the case of a Derivative Work or Collective Work, at a minimum such credit will appear, if a credit for all contributing authors of the Derivative Work or Collective Work appears, then as part of these credits and in a manner at least as prominent as the credits for the other contributing authors. For the avoidance of doubt, You may only use the credit required by this Section for the purpose of attribution in the manner set out above and, by exercising Your rights under this License, You may not implicitly or explicitly assert or imply any connection with, sponsorship or endorsement by the Original Author, Licensor and/or Attribution Parties, as appropriate, of You or Your use of the Work, without the separate, express prior written permission of the Original Author, Licensor and/or Attribution Parties.5. Representations, Warranties and Disclaimer UNLESS OTHERWISE MUTUALLY AGREED TO BY THE PARTIES IN WRITING, LICENSOR OFFERS THE WORK AS-IS AND ONLY TO THE EXTENT OF ANY RIGHTS HELD IN THE LICENSED WORK BY THE LICENSOR. THE LICENSOR MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE WORK, EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, WARRANTIES OF TITLE, MARKETABILITY, MERCHANTIBILITY, FITNESS FOR A PARTICULAR PURPOSE, NONINFRINGEMENT, OR THE ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OF ABSENCE OF ERRORS, WHETHER OR NOT DISCOVERABLE. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES, SO SUCH EXCLUSION MAY NOT APPLY TO YOU. Limitation on Liability. EXCEPT TO THE EXTENT REQUIRED BY APPLICABLE LAW, IN NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Termination This License and the rights granted hereunder will terminate automatically upon any breach by You of the terms of this License. Individuals or entities who have received Derivative Works (as defined in Section 1 above) or Collective Works (as defined in Section 1 above) from You under this License, however, will not have their licenses terminated provided such individuals or entities remain in full compliance with those licenses. Sections 1, 2, 5, 6, 7, and 8 will survive any termination of this License.Subject to the above terms and conditions, the license granted here is perpetual (for the duration of the applicable copyright in the Work). Notwithstanding the above, Licensor reserves the right to release the Work under different license terms or to stop distributing the Work at any time; provided, however that any such election will not serve to withdraw this License (or any other license that has been, or is required to be, granted under the terms of this License), and this License will continue in full force and effect unless terminated as stated above.8. Miscellaneous Each time You distribute or publicly digitally perform the Work (as defined in Section 1 above) or a Collective Work (as defined in Section 1 above), the Licensor offers to the recipient a license to the Work on the same terms and conditions as the license granted to You under this License.Each time You distribute or publicly digitally perform a Derivative Work, Licensor offers to the recipient a license to the original Work on the same terms and conditions as the license granted to You under this License.If any provision of this License is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this License, and without further action by the parties to this agreement, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.No term or provision of this License shall be deemed waived and no breach consented to unless such waiver or consent shall be in writing and signed by the party to be charged with such waiver or consent.This License constitutes the entire agreement between the parties with respect to the Work licensed here. There are no understandings, agreements or representations with respect to the Work not specified here. Licensor shall not be bound by any additional provisions that may appear in any communication from You. This License may not be modified without the mutual written agreement of the Licensor and You. Component Name: Full Serializer License Type: MIT Copyright © 2017 Jacob Dufault https://github.com/jacobdufault/fullserializer Permission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the \"Software\"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included inall copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Iconmonstr Icons License Type: Bespoke Copyright (c) 2020 iconmonstr Alexander Kahlkopf https://iconmonstr.com This license agreement (the “Agreement”) sets forth the terms by which Alexander Kahlkopf, the owner of iconmonstr (the “Licensor”), shall provide access to certain Work (defined below) to you (the “Licensee”, “you” or “your”). This Agreement regulates the free use of the icons, fonts, images and other media content (collectively, the “Work”), which is made available via the website iconmonstr.com (the “Website”). By downloading or copying a Work, you agree to be bound by the following terms and conditions. Grant of Rights The Works on the Website are copyrighted property of Licensor. Licensor hereby grants Licensee a perpetual, non-exclusive, non-transferrable single-user license for the use of the Work based on the conditions of this Agreement. You agree that the Work serves as part of the design and is not the basis or main component of the product, template or application distributed by the Licensee. Furthermore, you agree not to sell, redistribute, sublicense, share or otherwise transfer the Work to other people or entities. Permitted Uses Licensee may use the Work in non-commercial and commercial projects, services or products without attribution.Licensee may use the Work for any illustrative purposes in any media, including, but not limited to, websites, web banners, newsletters, PDF documents, blogs, emails, slideshows, TV and video presentations, smartphones, splash screens, movies, magazine articles, books, advertisements, brochures, document illustrations, booklets, billboards, business cards, packages, etc.Licensee may use the Work in template or application without attribution; provided, however, that the Work serves as part of the design and is not the basis or main component of the product, template or application distributed by Licensee and is not used contrary to the terms and conditions of this Agreement.Licensee may adapt or change the Work according to his or her requirements. Prohibited Uses Licensee may not sell, redistribute, sublicense, share or otherwise transfer the Work to other people or entities.Licensee may not use the Work as part of a logo, trademark or service mark.Licensee may not use the Work for pornographic, infringing, defamatory, racist or religiously offensive illustrations. Additional Information on Rights Certain Works, such as logos or brands, are subject to copyright and require the agreement of a third party for the assignment of these rights. Licensee is responsible for providing all rights, agreements, and licenses for the use of the Work. Termination This Agreement shall automatically terminate without notice if you do not comply with the terms or conditions specified in this Agreement. If you yourself wish to terminate this Agreement, destroy the Work, all copies and derivatives of the Work and any materials related to it. Indemnification You agree to indemnify Licensor for any and all claims, liability performances, damages, costs (including attorney fees) or other liabilities that are caused by or related to a breach of this Agreement, which are caused by the use of the Website or Work, by the non-compliance of the use restrictions of a Work or which are caused by the claims of third parties regarding the use of a Work. Warranty and Liability The Website and the Works are provided “as is.” Licensor does not accept any warranty or liability regarding a Work, the Website, the accuracy of the information or rights described therein or the licenses, which are subject to this Agreement. Licensor is not liable for damages, costs, losses or claims incurred by you, another person or entity by the use of the Website or the Works. Component Name: MD4 Managed Implementation License Type: MIT Copyright (C) 2003 Motus Technologies Inc. (http://www.motus.com) Copyright (C) 2004-2005,2010 Novell, Inc (http://www.novell.com) Author: Sebastien Pouliot (sebastien@ximian.com) https://github.com/mono/mono/blob/master/mcs/class/Mono.Security/Mono.Security.Cryptography/MD4Managed.cs Permission is hereby granted, free of charge, to any person obtaininga copy of this software and associated documentation files (the\"Software\"), to deal in the Software without restriction, includingwithout limitation the rights to use, copy, modify, merge, publish,distribute, sublicense, and/or sell copies of the Software, and topermit persons to whom the Software is furnished to do so, subject tothe following conditions: The above copyright notice and this permission notice shall beincluded in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OFMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE ANDNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BELIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTIONOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTIONWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Reorderable List License Type: MIT Copyright (c) 2013-2015 Rotorz Limited Author: Rotorz Limited https://bitbucket.org/rotorz/reorderable-list-editor-field-for-unity Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: SQLite License Type: Public Domain Copyright owner not applicable https://www.sqlite.org/index.html SQLite is in the public domain and does not require a license Component Name: SQLite .NET License Type: MIT Copyright (c) Krueger Systems Inc https://github.com/praeclarum/sqlite-net Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: YamlDotNet License Type: MIT Copyright (c) 2008, 2009, 2010, 2011, 2012, 2013, 2014 Antoine Aubry and contributors http://aaubry.net/pages/yamldotnet.html Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Ensure.That License Type: MIT Copyright (c) 2015 Daniel Wertheim https://github.com/danielwertheim/Ensure.That Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: NCalc License Type: MIT Copyright (c) 2011 Sebastien Ros https://github.com/ncalc/ncalc Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Antlr 3 Runtime License Type: BSD License Copyright (c) 2011 The ANTLR Project All rights reserved. https://github.com/antlr/antlrcs [The \"BSD license\"] Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "api/InventorySystem.EquipmentInventory.Armors.ArmorBase.html": {
    "href": "api/InventorySystem.EquipmentInventory.Armors.ArmorBase.html",
    "title": "Class ArmorBase | Inventory System",
    "summary": "Class ArmorBase Inheritance object ArmorBase Implements IEquipmentItem IItem ICopyable<IItem> IEquivalent<IItem> Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.EquipmentInventory.Armors Assembly: InventorySystem.dll Syntax public class ArmorBase : IEquipmentItem, IItem, ICopyable<IItem>, IEquivalent<IItem> Constructors | Edit this page View Source ArmorBase(ArmorData) Declaration public ArmorBase(ArmorData armorData) Parameters Type Name Description ArmorData armorData Properties | Edit this page View Source EquipmentType The EquipmentType in which this IEquipmentItem can be equipped in. Declaration public EquipmentType EquipmentType { get; } Property Value Type Description EquipmentType | Edit this page View Source ItemData Declaration public ItemData ItemData { get; } Property Value Type Description ItemData Methods | Edit this page View Source DeepCopy() Create a deep copy of this T. Declaration public IItem DeepCopy() Returns Type Description IItem A deep copy of this T. Remarks Deep Copy: A deep copy of an object is a copy whose properties do not share the same references (point to the same underlying values) as those of the source object from which the copy was made. https://developer.mozilla.org/en-US/docs/Glossary/Deep_copy | Edit this page View Source GetArmorValue() Declaration public float GetArmorValue() Returns Type Description float | Edit this page View Source IsEquivalentTo(IItem) Check if this is the same type T in the same internal state as other T. Declaration public bool IsEquivalentTo(IItem other) Parameters Type Name Description IItem other The object T to be compared against. Returns Type Description bool Whether this and other are equivalent in type and internal state. Implements IEquipmentItem IItem ICopyable<T> IEquivalent<T>"
  },
  "api/InventorySystem.EquipmentInventory.Armors.ArmorData.html": {
    "href": "api/InventorySystem.EquipmentInventory.Armors.ArmorData.html",
    "title": "Class ArmorData | Inventory System",
    "summary": "Class ArmorData UnityEngine.ScriptableObject defining data for an IEquipmentItem of type Armor. Inheritance object Object ScriptableObject ItemData ArmorData Inherited Members ItemData.Uid ItemData.ItemName ItemData.ItemDescription ItemData.MaxStackAmount ItemData.Prefab ItemData.Sprite ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Armors Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"Armor\", menuName = \"InventorySystem/Items/Armor\")] public class ArmorData : ItemData Fields | Edit this page View Source ArmorValue Declaration public float ArmorValue Field Value Type Description float"
  },
  "api/InventorySystem.EquipmentInventory.Armors.html": {
    "href": "api/InventorySystem.EquipmentInventory.Armors.html",
    "title": "Namespace InventorySystem.EquipmentInventory.Armors | Inventory System",
    "summary": "Namespace InventorySystem.EquipmentInventory.Armors Classes ArmorBase ArmorData UnityEngine.ScriptableObject defining data for an IEquipmentItem of type Armor."
  },
  "api/InventorySystem.EquipmentInventory.EquipmentInventory.html": {
    "href": "api/InventorySystem.EquipmentInventory.EquipmentInventory.html",
    "title": "Class EquipmentInventory | Inventory System",
    "summary": "Class EquipmentInventory Inheritance object EquipmentInventory Implements IEquipmentInventory ISerializationCallbackReceiver Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.EquipmentInventory Assembly: InventorySystem.dll Syntax [Serializable] public class EquipmentInventory : IEquipmentInventory, ISerializationCallbackReceiver Properties | Edit this page View Source EquippedItemList List of all currently equipped IEquipmentItems. Declaration public IReadOnlyList<IEquipmentItem> EquippedItemList { get; } Property Value Type Description IReadOnlyList<IEquipmentItem> Remarks Does not make a contract about the amount of items inside. Does not contain null values, but can be empty. Methods | Edit this page View Source Create() Create a new EquipmentInventory. Declaration public static EquipmentInventory Create() Returns Type Description EquipmentInventory | Edit this page View Source GetItem(EquipmentType) Get the IEquipmentItem for slot EquipmentType equipmentType. Declaration public IEquipmentItem GetItem(EquipmentType equipmentType) Parameters Type Name Description EquipmentType equipmentType The EquipmentType to check for. Returns Type Description IEquipmentItem Returns the equipped IEquipmentItem. Returns null, if no IEquipmentItem is equipped in this slot. | Edit this page View Source OnAfterDeserialize() Populate InventorySystem.EquipmentInventory.EquipmentInventory._equippedItems with all saved IEquipmentItems after deserialization. Declaration public void OnAfterDeserialize() | Edit this page View Source OnBeforeSerialize() We cannot serialize a Dictionary<TKey, TValue>, therefore we save our InventorySystem.EquipmentInventory.EquipmentInventory._equippedItems in the InventorySystem.EquipmentInventory.EquipmentInventory._equippedItemList. Declaration public void OnBeforeSerialize() | Edit this page View Source TryEquip(IItem) Try to equip an IItem. Returns false if the IItem is not an IEquipmentItem. Returns false if the EquipmentType is not allowed in this IEquipmentInventory. Returns false if an IItem of the same EquipmentType is already equipped. Declaration public bool TryEquip(IItem item) Parameters Type Name Description IItem item The IItem trying to be equipped. Returns Type Description bool Whether the IItem item was equipped. | Edit this page View Source Unequip(EquipmentType) Try to unequip an IEquipmentItem. Returns null if there was no IEquipmentItem equipped in the slot for EquipmentType equipmentType in EquippedItemList. Declaration public IEquipmentItem Unequip(EquipmentType equipmentType) Parameters Type Name Description EquipmentType equipmentType The slot that the IEquipmentItem is being removed from. Returns Type Description IEquipmentItem Returns the unequipped IEquipmentItem. Returns null, if there was no item in the EquipmentType in EquippedItemList. Events | Edit this page View Source ItemEquipped Event invoked when an IItem was successfully equipped. Returns the newly equipped IItem. Declaration public event Action<IItem> ItemEquipped Event Type Type Description Action<IItem> | Edit this page View Source ItemUnequipped Event invoked when an IItem was successfully unequipped. Returns the newly unequipped IItem. Declaration public event Action<IItem> ItemUnequipped Event Type Type Description Action<IItem> Implements IEquipmentInventory UnityEngine.ISerializationCallbackReceiver"
  },
  "api/InventorySystem.EquipmentInventory.EquipmentType.html": {
    "href": "api/InventorySystem.EquipmentInventory.EquipmentType.html",
    "title": "Enum EquipmentType | Inventory System",
    "summary": "Enum EquipmentType The type of equipment. Namespace: InventorySystem.EquipmentInventory Assembly: InventorySystem.dll Syntax [Serializable] public enum EquipmentType Fields Name Description Armor Weapon"
  },
  "api/InventorySystem.EquipmentInventory.IEquipmentInventory.html": {
    "href": "api/InventorySystem.EquipmentInventory.IEquipmentInventory.html",
    "title": "Interface IEquipmentInventory | Inventory System",
    "summary": "Interface IEquipmentInventory Namespace: InventorySystem.EquipmentInventory Assembly: InventorySystem.dll Syntax public interface IEquipmentInventory Properties | Edit this page View Source EquippedItemList List of all currently equipped IEquipmentItems. Declaration IReadOnlyList<IEquipmentItem> EquippedItemList { get; } Property Value Type Description IReadOnlyList<IEquipmentItem> Remarks Does not make a contract about the amount of items inside. Does not contain null values, but can be empty. Methods | Edit this page View Source GetItem(EquipmentType) Get the IEquipmentItem for slot EquipmentType equipmentType. Declaration IEquipmentItem GetItem(EquipmentType equipmentType) Parameters Type Name Description EquipmentType equipmentType The EquipmentType to check for. Returns Type Description IEquipmentItem Returns the equipped IEquipmentItem. Returns null, if no IEquipmentItem is equipped in this slot. | Edit this page View Source TryEquip(IItem) Try to equip an IItem. Returns false if the IItem is not an IEquipmentItem. Returns false if the EquipmentType is not allowed in this IEquipmentInventory. Returns false if an IItem of the same EquipmentType is already equipped. Declaration bool TryEquip(IItem item) Parameters Type Name Description IItem item The IItem trying to be equipped. Returns Type Description bool Whether the IItem item was equipped. | Edit this page View Source Unequip(EquipmentType) Try to unequip an IEquipmentItem. Returns null if there was no IEquipmentItem equipped in the slot for EquipmentType equipmentType in EquippedItemList. Declaration IEquipmentItem Unequip(EquipmentType equipmentType) Parameters Type Name Description EquipmentType equipmentType The slot that the IEquipmentItem is being removed from. Returns Type Description IEquipmentItem Returns the unequipped IEquipmentItem. Returns null, if there was no item in the EquipmentType in EquippedItemList. Events | Edit this page View Source ItemEquipped Event invoked when an IItem was successfully equipped. Returns the newly equipped IItem. Declaration event Action<IItem> ItemEquipped Event Type Type Description Action<IItem> | Edit this page View Source ItemUnequipped Event invoked when an IItem was successfully unequipped. Returns the newly unequipped IItem. Declaration event Action<IItem> ItemUnequipped Event Type Type Description Action<IItem>"
  },
  "api/InventorySystem.EquipmentInventory.IEquipmentItem.html": {
    "href": "api/InventorySystem.EquipmentInventory.IEquipmentItem.html",
    "title": "Interface IEquipmentItem | Inventory System",
    "summary": "Interface IEquipmentItem Interface for all IItems that can be equipped. Inherited Members IItem.ItemData ICopyable<IItem>.DeepCopy() IEquivalent<IItem>.IsEquivalentTo(IItem) Namespace: InventorySystem.EquipmentInventory Assembly: InventorySystem.dll Syntax public interface IEquipmentItem : IItem, ICopyable<IItem>, IEquivalent<IItem> Properties | Edit this page View Source EquipmentType The EquipmentType in which this IEquipmentItem can be equipped in. Declaration EquipmentType EquipmentType { get; } Property Value Type Description EquipmentType"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.IWeapon.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.IWeapon.html",
    "title": "Interface IWeapon | Inventory System",
    "summary": "Interface IWeapon Interface for any weapon. Always is an IEquipmentItem. Inherited Members IEquipmentItem.EquipmentType IItem.ItemData ICopyable<IItem>.DeepCopy() IEquivalent<IItem>.IsEquivalentTo(IItem) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax public interface IWeapon : IEquipmentItem, IItem, ICopyable<IItem>, IEquivalent<IItem> Properties | Edit this page View Source WeaponData Declaration WeaponData WeaponData { get; } Property Value Type Description WeaponData Methods | Edit this page View Source Use() Declaration void Use()"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.IWeaponFactory.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.IWeaponFactory.html",
    "title": "Interface IWeaponFactory | Inventory System",
    "summary": "Interface IWeaponFactory Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax public interface IWeaponFactory Methods | Edit this page View Source Create(WeaponData) Declaration IWeapon Create(WeaponData weaponData) Parameters Type Name Description WeaponData weaponData Returns Type Description IWeapon"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.MeleeAttackStrategy.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.MeleeAttackStrategy.html",
    "title": "Class MeleeAttackStrategy | Inventory System",
    "summary": "Class MeleeAttackStrategy Inheritance object Object ScriptableObject WeaponAttackStrategy MeleeAttackStrategy Inherited Members ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"MeleeAttackStrategy\", menuName = \"InventorySystem/WeaponStrategy/MeleeAttackStrategy\")] public class MeleeAttackStrategy : WeaponAttackStrategy Methods | Edit this page View Source Execute() Declaration public override void Execute() Overrides WeaponAttackStrategy.Execute()"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.RangedAttackStrategy.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.RangedAttackStrategy.html",
    "title": "Class RangedAttackStrategy | Inventory System",
    "summary": "Class RangedAttackStrategy Inheritance object Object ScriptableObject WeaponAttackStrategy RangedAttackStrategy Inherited Members ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"RangedAttackStrategy\", menuName = \"InventorySystem/WeaponStrategy/RangedAttackStrategy\")] public class RangedAttackStrategy : WeaponAttackStrategy Methods | Edit this page View Source Execute() Declaration public override void Execute() Overrides WeaponAttackStrategy.Execute()"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.ThrowableAttackStrategy.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.ThrowableAttackStrategy.html",
    "title": "Class ThrowableAttackStrategy | Inventory System",
    "summary": "Class ThrowableAttackStrategy Inheritance object Object ScriptableObject WeaponAttackStrategy ThrowableAttackStrategy Inherited Members ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"ThrowableAttackStrategy\", menuName = \"InventorySystem/WeaponStrategy/ThrowableAttackStrategy\")] public class ThrowableAttackStrategy : WeaponAttackStrategy Methods | Edit this page View Source Execute() Declaration public override void Execute() Overrides WeaponAttackStrategy.Execute()"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.WeaponAttackStrategy.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.WeaponAttackStrategy.html",
    "title": "Class WeaponAttackStrategy | Inventory System",
    "summary": "Class WeaponAttackStrategy Inheritance object Object ScriptableObject WeaponAttackStrategy MeleeAttackStrategy RangedAttackStrategy ThrowableAttackStrategy Inherited Members ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] public abstract class WeaponAttackStrategy : ScriptableObject Methods | Edit this page View Source Execute() Declaration public abstract void Execute()"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.WeaponBase.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.WeaponBase.html",
    "title": "Class WeaponBase | Inventory System",
    "summary": "Class WeaponBase Inheritance object WeaponBase Implements IWeapon IEquipmentItem IItem ICopyable<IItem> IEquivalent<IItem> Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] public class WeaponBase : IWeapon, IEquipmentItem, IItem, ICopyable<IItem>, IEquivalent<IItem> Constructors | Edit this page View Source WeaponBase(WeaponData) Declaration public WeaponBase(WeaponData weaponData) Parameters Type Name Description WeaponData weaponData Properties | Edit this page View Source EquipmentType The EquipmentType in which this IEquipmentItem can be equipped in. Declaration public EquipmentType EquipmentType { get; } Property Value Type Description EquipmentType | Edit this page View Source ItemData Declaration public ItemData ItemData { get; } Property Value Type Description ItemData | Edit this page View Source WeaponData Declaration public WeaponData WeaponData { get; } Property Value Type Description WeaponData Methods | Edit this page View Source DeepCopy() FIXME: This is a shallow copy regarding WeaponData. Declaration public IItem DeepCopy() Returns Type Description IItem | Edit this page View Source IsEquivalentTo(IItem) FIXME: Not fully implemented (should check individual values in weapon data or make weapon data IsEquivalentTo(IItem)). Declaration public bool IsEquivalentTo(IItem other) Parameters Type Name Description IItem other Returns Type Description bool | Edit this page View Source Use() Declaration public virtual void Use() Implements IWeapon IEquipmentItem IItem ICopyable<T> IEquivalent<T>"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.WeaponData.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.WeaponData.html",
    "title": "Class WeaponData | Inventory System",
    "summary": "Class WeaponData Inheritance object Object ScriptableObject ItemData WeaponData Inherited Members ItemData.Uid ItemData.ItemName ItemData.ItemDescription ItemData.MaxStackAmount ItemData.Prefab ItemData.Sprite ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"Weapon\", menuName = \"InventorySystem/Items/Weapon\")] public class WeaponData : ItemData Fields | Edit this page View Source Damage Declaration public float Damage Field Value Type Description float | Edit this page View Source Range Declaration public float Range Field Value Type Description float | Edit this page View Source WeaponAttackStrategy Declaration [SerializeReference] public WeaponAttackStrategy WeaponAttackStrategy Field Value Type Description WeaponAttackStrategy | Edit this page View Source WeaponType Declaration public WeaponType WeaponType Field Value Type Description WeaponType"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.WeaponFactory.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.WeaponFactory.html",
    "title": "Class WeaponFactory | Inventory System",
    "summary": "Class WeaponFactory Inheritance object WeaponFactory Implements IWeaponFactory Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax public class WeaponFactory : IWeaponFactory Methods | Edit this page View Source Create(WeaponData) Declaration public IWeapon Create(WeaponData weaponData) Parameters Type Name Description WeaponData weaponData Returns Type Description IWeapon Implements IWeaponFactory"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.WeaponType.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.WeaponType.html",
    "title": "Enum WeaponType | Inventory System",
    "summary": "Enum WeaponType Namespace: InventorySystem.EquipmentInventory.Weapons Assembly: InventorySystem.dll Syntax [Serializable] public enum WeaponType Fields Name Description Melee Ranged Throwable"
  },
  "api/InventorySystem.EquipmentInventory.Weapons.html": {
    "href": "api/InventorySystem.EquipmentInventory.Weapons.html",
    "title": "Namespace InventorySystem.EquipmentInventory.Weapons | Inventory System",
    "summary": "Namespace InventorySystem.EquipmentInventory.Weapons Classes MeleeAttackStrategy RangedAttackStrategy ThrowableAttackStrategy WeaponAttackStrategy WeaponBase WeaponData WeaponFactory Interfaces IWeapon Interface for any weapon. Always is an IEquipmentItem. IWeaponFactory Enums WeaponType"
  },
  "api/InventorySystem.EquipmentInventory.html": {
    "href": "api/InventorySystem.EquipmentInventory.html",
    "title": "Namespace InventorySystem.EquipmentInventory | Inventory System",
    "summary": "Namespace InventorySystem.EquipmentInventory Classes EquipmentInventory Interfaces IEquipmentInventory IEquipmentItem Interface for all IItems that can be equipped. Enums EquipmentType The type of equipment."
  },
  "api/InventorySystem.Inventory.IInventory.html": {
    "href": "api/InventorySystem.Inventory.IInventory.html",
    "title": "Interface IInventory | Inventory System",
    "summary": "Interface IInventory Interface for an Inventory. Namespace: InventorySystem.Inventory Assembly: InventorySystem.dll Syntax public interface IInventory Properties | Edit this page View Source Capacity Maximum amount of items that can be inside the IInventory. Declaration int Capacity { get; } Property Value Type Description int | Edit this page View Source InventorySlots Get all IInventorySlots in this. Declaration IReadOnlyList<IInventorySlot> InventorySlots { get; } Property Value Type Description IReadOnlyList<IInventorySlot> IReadOnlyList<T> of all IInventorySlots in this IInventory. Remarks WARNING: Also returns empty IInventorySlots. Thus, always returns a list of size equal to Capacity. | Edit this page View Source IsEmpty Whether the entire IInventory is empty meaning all IInventorySlots are empty. Declaration bool IsEmpty { get; } Property Value Type Description bool | Edit this page View Source Items Get all IItems in IInventory. Declaration IReadOnlyList<IItem> Items { get; } Property Value Type Description IReadOnlyList<IItem> IReadOnlyList<T> of all IItems in this IInventory. Remarks WARNING: Also returns empty IItems as null. Thus, always returns a list of size equal to Capacity. Methods | Edit this page View Source Clear() Clear the entire IInventory by clearing all IInventorySlots. Declaration void Clear() | Edit this page View Source IsSlotAvailable(IItem, out int) Whether an IItem item can be added into an IInventorySlot. Does not add the IItem. Declaration bool IsSlotAvailable(IItem item, out int addIndex) Parameters Type Name Description IItem item IItem to be checked. int addIndex First found index for the IItem item to be added into. Looks for index with equivalent, non-full IInventorySlot and empty slots second. Returns -1, if it cannot be added. Returns Type Description bool Whether the IItem can be added or not. Remarks Does not guarantee that the IItem can be added with a quantity greater than one. Only guarantees that there is either an empty IInventorySlot or a non-full IInventorySlot that is already occupied by the item that is to be added. It is still possible that the quantity of the IItem being added exceeds the ItemSO.maxStackAmount and thus needs to occupy additional Slots to be fully added. | Edit this page View Source RemoveItem(IItem, bool) Remove IItem item from the IInventory. If the IItem is in the IInventory, we call IInventorySlot.Clear on its IInventorySlot. Declaration void RemoveItem(IItem item, bool onlyFirstOccurence = false) Parameters Type Name Description IItem item IItem to be removed. bool onlyFirstOccurence Whether only the first occurence of the IItem in the IInventory gets removed (true) or all of its occurrences (i.e., we have the same IItem in multiple IInventorySlots). | Edit this page View Source TryAddItem(IItem, int) Try to add an IItem into the first possible IInventorySlot. Declaration bool TryAddItem(IItem item, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added. int quantity The number of IItem item to be added. Returns Type Description bool Whether the IItem item was added. Remarks Wrapper for TryAddItemAt(IItem, int, int). If the quantity exceeds the first found IInventorySlot capacity, it tries to find the next empty IInventorySlot and adds the leftover amount there. Loops recursively until all items are stored in the IInventory or until there is no more space available. If no more space is available, discards/ignores the remaining leftover. Returns true, even if any leftover is discarded. | Edit this page View Source TryAddItemAt(IItem, int, int) Try to add an IItem item into the IInventorySlot at index. Declaration bool TryAddItemAt(IItem item, int index, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added. int index The index of the IInventorySlot that the item is trying to be added into. int quantity The number of IItem item to be added. Returns Type Description bool Whether the IItem item was added. Remarks If the quantity exceeds the Quantity of the IInventorySlot capacity, it tries to find the next non-full occupied IInventorySlot by the same IItem item or the next empty IInventorySlot and adds the leftover amount there. Loops recursively until all items are stored in the IInventory or until there is no more space available. If no more space is available, discards/ignores the remaining leftover. Returns true, even if any leftover is discarded. WARNING: If InventorySystem.Inventory.Inventory._handlesOverflow is true, it only tries to add the item to the first found IInventorySlot and returns true if any amount was added. | Edit this page View Source TryClearSlotAt(int) Try to IInventorySlot.Clear the IInventorySlot, if it's valid. Declaration void TryClearSlotAt(int index) Parameters Type Name Description int index The index of the IInventorySlot to clear. | Edit this page View Source TryGetItemAt(int) Try to get IItem as index. Declaration IItem TryGetItemAt(int index) Parameters Type Name Description int index The index to look for IItem item. Returns Type Description IItem Returns IItem, if the index is inside the bounds of the Capacity. Otherwise, or if IInventorySlot IsEmpty, returns null. | Edit this page View Source TryGetSlotAt(int) Try to get the IInventorySlot at slotIndex. Declaration IInventorySlot TryGetSlotAt(int index) Parameters Type Name Description int index Index to look for the IInventorySlot Returns Type Description IInventorySlot IInventorySlot or null, if the index is higher than the Capacity. | Edit this page View Source TryInsertItemAtFront(IItem, int) Try to insert an IItem at the front of the IInventory, i.e., in IInventorySlot 0. Declaration bool TryInsertItemAtFront(IItem item, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added to the IInventory at the front. int quantity The quantity of IItem to be added. Returns Type Description bool Whether the IItem was added to the front. Remarks Pushed all other IItems already in the IInventory one slot up. FIXME: If the quantity exceeds ItemSO.maxStackAmount, it is possible that IItems that were previously in the IInventory get removed. Events | Edit this page View Source ItemsAdded Event invoked when IItems were successfully added to this. Returns the newly added IItem and the added quantity. Declaration event Action<IItem, int> ItemsAdded Event Type Type Description Action<IItem, int> Remarks Triggered per slot that receives items; each invocation returns the added IItem and the quantity placed into that slot. (i.e., if more IItems are added than MaxStackAmount for one slot, and items are added to a second slot, the event will fire again for the second slot.) | Edit this page View Source ItemsRemoved Event invoked when IItems were successfully removed from this. Returns the newly removed IItem and the removed quantity. Declaration event Action<IItem, int> ItemsRemoved Event Type Type Description Action<IItem, int> Remarks Fired per slot that loses items; each invocation returns the removed IItem and the quantity taken from that slot."
  },
  "api/InventorySystem.Inventory.IInventorySlot.html": {
    "href": "api/InventorySystem.Inventory.IInventorySlot.html",
    "title": "Interface IInventorySlot | Inventory System",
    "summary": "Interface IInventorySlot Namespace: InventorySystem.Inventory Assembly: InventorySystem.dll Syntax public interface IInventorySlot Properties | Edit this page View Source IsEmpty Whether an IItem is assigned to this IInventorySlot with a Quantity not equal 0. Declaration bool IsEmpty { get; } Property Value Type Description bool | Edit this page View Source IsFull Check if the Quantity greater than or equal to the assigned IItems ItemSO.maxStackAmount. Declaration bool IsFull { get; } Property Value Type Description bool | Edit this page View Source Item Get IItem assigned to this IInventorySlot. Declaration IItem Item { get; } Property Value Type Description IItem | Edit this page View Source Quantity Get quantity of Item in this IInventorySlot. Declaration int Quantity { get; } Property Value Type Description int Remarks Quantity is limited by ItemSO.maxStackAmount, which is enforced in TryAddQuantity."
  },
  "api/InventorySystem.Inventory.Inventory.html": {
    "href": "api/InventorySystem.Inventory.Inventory.html",
    "title": "Class Inventory | Inventory System",
    "summary": "Class Inventory Inheritance object Inventory Implements IInventory Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.Inventory Assembly: InventorySystem.dll Syntax [Serializable] public class Inventory : IInventory Properties | Edit this page View Source Capacity Maximum amount of items that can be inside the IInventory. Declaration public int Capacity { get; } Property Value Type Description int | Edit this page View Source InventorySlots Get all IInventorySlots in this. Declaration public IReadOnlyList<IInventorySlot> InventorySlots { get; } Property Value Type Description IReadOnlyList<IInventorySlot> IReadOnlyList<T> of all IInventorySlots in this IInventory. Remarks WARNING: Also returns empty IInventorySlots. Thus, always returns a list of size equal to Capacity. | Edit this page View Source IsEmpty Whether the entire IInventory is empty meaning all IInventorySlots are empty. Declaration public bool IsEmpty { get; } Property Value Type Description bool | Edit this page View Source Items Get all IItems in IInventory. Declaration public IReadOnlyList<IItem> Items { get; } Property Value Type Description IReadOnlyList<IItem> IReadOnlyList<T> of all IItems in this IInventory. Remarks WARNING: Also returns empty IItems as null. Thus, always returns a list of size equal to Capacity. Methods | Edit this page View Source Clear() Clear the entire IInventory by clearing all IInventorySlots. Declaration public void Clear() | Edit this page View Source Create(int, bool) Create a new Inventory. Also, creates and assigns capacity amount of InventorySystem.Inventory.InventorySlots. Declaration public static Inventory Create(int capacity = 2, bool handlesOverflow = true) Parameters Type Name Description int capacity Amount of IInventorySlot in this. bool handlesOverflow Whether overflow is handled or discarded. Returns Type Description Inventory A new Inventory. | Edit this page View Source IsSlotAvailable(IItem, out int) Whether an IItem item can be added into an IInventorySlot. Does not add the IItem. Declaration public bool IsSlotAvailable(IItem item, out int addIndex) Parameters Type Name Description IItem item IItem to be checked. int addIndex First found index for the IItem item to be added into. Looks for index with equivalent, non-full IInventorySlot and empty slots second. Returns -1, if it cannot be added. Returns Type Description bool Whether the IItem can be added or not. Remarks Does not guarantee that the IItem can be added with a quantity greater than one. Only guarantees that there is either an empty IInventorySlot or a non-full IInventorySlot that is already occupied by the item that is to be added. It is still possible that the quantity of the IItem being added exceeds the ItemSO.maxStackAmount and thus needs to occupy additional Slots to be fully added. | Edit this page View Source RemoveItem(IItem, bool) Remove IItem item from the IInventory. If the IItem is in the IInventory, we call IInventorySlot.Clear on its IInventorySlot. Declaration public void RemoveItem(IItem item, bool onlyFirstOccurence = false) Parameters Type Name Description IItem item IItem to be removed. bool onlyFirstOccurence Whether only the first occurence of the IItem in the IInventory gets removed (true) or all of its occurrences (i.e., we have the same IItem in multiple IInventorySlots). | Edit this page View Source TryAddItem(IItem, int) Try to add an IItem into the first possible IInventorySlot. Declaration public bool TryAddItem(IItem item, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added. int quantity The number of IItem item to be added. Returns Type Description bool Whether the IItem item was added. Remarks Wrapper for TryAddItemAt(IItem, int, int). If the quantity exceeds the first found IInventorySlot capacity, it tries to find the next empty IInventorySlot and adds the leftover amount there. Loops recursively until all items are stored in the IInventory or until there is no more space available. If no more space is available, discards/ignores the remaining leftover. Returns true, even if any leftover is discarded. | Edit this page View Source TryAddItemAt(IItem, int, int) Try to add an IItem item into the IInventorySlot at index. Declaration public bool TryAddItemAt(IItem item, int index, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added. int index The index of the IInventorySlot that the item is trying to be added into. int quantity The number of IItem item to be added. Returns Type Description bool Whether the IItem item was added. Remarks If the quantity exceeds the Quantity of the IInventorySlot capacity, it tries to find the next non-full occupied IInventorySlot by the same IItem item or the next empty IInventorySlot and adds the leftover amount there. Loops recursively until all items are stored in the IInventory or until there is no more space available. If no more space is available, discards/ignores the remaining leftover. Returns true, even if any leftover is discarded. WARNING: If InventorySystem.Inventory.Inventory._handlesOverflow is true, it only tries to add the item to the first found IInventorySlot and returns true if any amount was added. | Edit this page View Source TryClearSlotAt(int) Try to IInventorySlot.Clear the IInventorySlot, if it's valid. Declaration public void TryClearSlotAt(int index) Parameters Type Name Description int index The index of the IInventorySlot to clear. | Edit this page View Source TryGetItemAt(int) Try to get IItem as index. Declaration public IItem TryGetItemAt(int index) Parameters Type Name Description int index The index to look for IItem item. Returns Type Description IItem Returns IItem, if the index is inside the bounds of the Capacity. Otherwise, or if IInventorySlot IsEmpty, returns null. | Edit this page View Source TryGetSlotAt(int) Try to get the IInventorySlot at slotIndex. Declaration public IInventorySlot TryGetSlotAt(int index) Parameters Type Name Description int index Index to look for the IInventorySlot Returns Type Description IInventorySlot IInventorySlot or null, if the index is higher than the Capacity. | Edit this page View Source TryInsertItemAtFront(IItem, int) Try to insert an IItem at the front of the IInventory, i.e., in IInventorySlot 0. Declaration public bool TryInsertItemAtFront(IItem item, int quantity = 1) Parameters Type Name Description IItem item The IItem to be added to the IInventory at the front. int quantity The quantity of IItem to be added. Returns Type Description bool Whether the IItem was added to the front. Remarks Pushed all other IItems already in the IInventory one slot up. FIXME: If the quantity exceeds ItemSO.maxStackAmount, it is possible that IItems that were previously in the IInventory get removed. Events | Edit this page View Source ItemsAdded Event invoked when IItems were successfully added to this. Returns the newly added IItem and the added quantity. Declaration public event Action<IItem, int> ItemsAdded Event Type Type Description Action<IItem, int> Remarks Triggered per slot that receives items; each invocation returns the added IItem and the quantity placed into that slot. (i.e., if more IItems are added than MaxStackAmount for one slot, and items are added to a second slot, the event will fire again for the second slot.) | Edit this page View Source ItemsRemoved Event invoked when IItems were successfully removed from this. Returns the newly removed IItem and the removed quantity. Declaration public event Action<IItem, int> ItemsRemoved Event Type Type Description Action<IItem, int> Remarks Fired per slot that loses items; each invocation returns the removed IItem and the quantity taken from that slot. Implements IInventory"
  },
  "api/InventorySystem.Inventory.html": {
    "href": "api/InventorySystem.Inventory.html",
    "title": "Namespace InventorySystem.Inventory | Inventory System",
    "summary": "Namespace InventorySystem.Inventory Classes Inventory Interfaces IInventory Interface for an Inventory. IInventorySlot"
  },
  "api/InventorySystem.Items.ICopyable-1.html": {
    "href": "api/InventorySystem.Items.ICopyable-1.html",
    "title": "Interface ICopyable<T> | Inventory System",
    "summary": "Interface ICopyable<T> Make this able to be copied. Namespace: InventorySystem.Items Assembly: InventorySystem.dll Syntax public interface ICopyable<T> Type Parameters Name Description T Type of class implementing this that can be copied. Methods | Edit this page View Source DeepCopy() Create a deep copy of this T. Declaration T DeepCopy() Returns Type Description T A deep copy of this T. Remarks Deep Copy: A deep copy of an object is a copy whose properties do not share the same references (point to the same underlying values) as those of the source object from which the copy was made. https://developer.mozilla.org/en-US/docs/Glossary/Deep_copy"
  },
  "api/InventorySystem.Items.IEquivalent-1.html": {
    "href": "api/InventorySystem.Items.IEquivalent-1.html",
    "title": "Interface IEquivalent<T> | Inventory System",
    "summary": "Interface IEquivalent<T> Check if this is equivalent to another \"other\" object. This is not the same as Equals, as we do not compare the object instance but rather the state of this to \"other\". Namespace: InventorySystem.Items Assembly: InventorySystem.dll Syntax public interface IEquivalent<T> Type Parameters Name Description T Type of the class implementing this that can be checked for equivalence. Methods | Edit this page View Source IsEquivalentTo(T) Check if this is the same type T in the same internal state as other T. Declaration bool IsEquivalentTo(T other) Parameters Type Name Description T other The object T to be compared against. Returns Type Description bool Whether this and other are equivalent in type and internal state."
  },
  "api/InventorySystem.Items.IItem.html": {
    "href": "api/InventorySystem.Items.IItem.html",
    "title": "Interface IItem | Inventory System",
    "summary": "Interface IItem Base interface for anything regarded as an Item. Inherited Members ICopyable<IItem>.DeepCopy() IEquivalent<IItem>.IsEquivalentTo(IItem) Namespace: InventorySystem.Items Assembly: InventorySystem.dll Syntax public interface IItem : ICopyable<IItem>, IEquivalent<IItem> Properties | Edit this page View Source ItemData Declaration ItemData ItemData { get; } Property Value Type Description ItemData"
  },
  "api/InventorySystem.Items.ItemData.html": {
    "href": "api/InventorySystem.Items.ItemData.html",
    "title": "Class ItemData | Inventory System",
    "summary": "Class ItemData UnityEngine.ScriptableObject containing data for a base IItem. Can be inherited by other UnityEngine.ScriptableObjects to extend to more specific items. Inheritance object Object ScriptableObject ItemData ArmorData WeaponData Inherited Members ScriptableObject.SetDirty() ScriptableObject.CreateInstance(string) ScriptableObject.CreateInstance(Type) ScriptableObject.CreateInstance<T>() Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion, CancellationToken) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, CancellationToken) Object.InstantiateAsync<T>(T, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion, InstantiateParameters, CancellationToken) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>, InstantiateParameters, CancellationToken) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate<T>(T, InstantiateParameters) Object.Instantiate<T>(T, Vector3, Quaternion, InstantiateParameters) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Namespace: InventorySystem.Items Assembly: InventorySystem.dll Syntax [Serializable] [CreateAssetMenu(fileName = \"Item\", menuName = \"InventorySystem/Items/Item\")] public class ItemData : ScriptableObject Fields | Edit this page View Source ItemDescription Declaration [FormerlySerializedAs(\"itemDescription\")] public string ItemDescription Field Value Type Description string | Edit this page View Source ItemName Declaration [FormerlySerializedAs(\"itemName\")] public string ItemName Field Value Type Description string | Edit this page View Source MaxStackAmount Declaration [FormerlySerializedAs(\"maxStackAmount\")] public int MaxStackAmount Field Value Type Description int | Edit this page View Source Prefab Declaration [FormerlySerializedAs(\"prefab\")] public GameObject Prefab Field Value Type Description GameObject | Edit this page View Source Sprite Declaration [FormerlySerializedAs(\"sprite\")] public Sprite Sprite Field Value Type Description Sprite | Edit this page View Source Uid Declaration [FormerlySerializedAs(\"id\")] public int Uid Field Value Type Description int"
  },
  "api/InventorySystem.Items.html": {
    "href": "api/InventorySystem.Items.html",
    "title": "Namespace InventorySystem.Items | Inventory System",
    "summary": "Namespace InventorySystem.Items Classes ItemData UnityEngine.ScriptableObject containing data for a base IItem. Can be inherited by other UnityEngine.ScriptableObjects to extend to more specific items. Interfaces ICopyable<T> Make this able to be copied. IEquivalent<T> Check if this is equivalent to another \"other\" object. This is not the same as Equals, as we do not compare the object instance but rather the state of this to \"other\". IItem Base interface for anything regarded as an Item."
  },
  "api/InventorySystem.Utils.MathUtils.html": {
    "href": "api/InventorySystem.Utils.MathUtils.html",
    "title": "Class MathUtils | Inventory System",
    "summary": "Class MathUtils Static Utility for common math problems. Inheritance object MathUtils Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystem.Utils Assembly: InventorySystem.dll Syntax public static class MathUtils Methods | Edit this page View Source ClampWithLeftover(int, int) Clamps a value to a max limit and returns the clamped value and leftover. Declaration public static (int clampedValue, int leftover) ClampWithLeftover(int originalValue, int max) Parameters Type Name Description int originalValue The original value before clamping. int max The maximum allowed value. Returns Type Description (int clampedValue, int leftover) A tuple of (clampedValue, leftover)"
  },
  "api/InventorySystem.Utils.html": {
    "href": "api/InventorySystem.Utils.html",
    "title": "Namespace InventorySystem.Utils | Inventory System",
    "summary": "Namespace InventorySystem.Utils Classes MathUtils Static Utility for common math problems."
  },
  "api/InventorySystemTests.EquipmentInventoryTests.html": {
    "href": "api/InventorySystemTests.EquipmentInventoryTests.html",
    "title": "Class EquipmentInventoryTests | Inventory System",
    "summary": "Class EquipmentInventoryTests Comprehensive behaviour-level tests for any IEquipmentInventory implementation. Replace the TODO in CreateInventory() with your concrete inventory class or derive and override CreateInventory() for different configurations. Inheritance object EquipmentInventoryTests Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystemTests Assembly: InventorySystemTests.dll Syntax [TestFixture] public class EquipmentInventoryTests Methods | Edit this page View Source CreateInventory() Factory method for the System Under Test (SUT). Adapt this to build your own IEquipmentInventory (e.g. pass allowed slots, DI, etc.). Declaration protected virtual IEquipmentInventory CreateInventory() Returns Type Description IEquipmentInventory | Edit this page View Source Equip_DifferentInstancesOfSameTypeInSameSlot_Fails() Declaration [Test] public void Equip_DifferentInstancesOfSameTypeInSameSlot_Fails() | Edit this page View Source Equip_FailsIfSameInstanceAlreadyEquipped_ReturnsFalse() Declaration [Test] public void Equip_FailsIfSameInstanceAlreadyEquipped_ReturnsFalse() | Edit this page View Source EquippedItemList_IsReadOnly_ViewingDoesNotAllowMutation() Declaration [Test] public void EquippedItemList_IsReadOnly_ViewingDoesNotAllowMutation() | Edit this page View Source GetItem_DoesNotMutate_EquippedListRemainsUnchanged() Declaration [Test] public void GetItem_DoesNotMutate_EquippedListRemainsUnchanged() | Edit this page View Source GetItem_EmptySlot_ReturnsNull() Declaration [Test] public void GetItem_EmptySlot_ReturnsNull() | Edit this page View Source GetItem_ReturnsCorrectItem_WhenEquipped() Declaration [Test] public void GetItem_ReturnsCorrectItem_WhenEquipped() | Edit this page View Source NewInventory_InitiallyEmpty_EquippedListIsEmptyAndNoNulls() Declaration [Test] public void NewInventory_InitiallyEmpty_EquippedListIsEmptyAndNoNulls() | Edit this page View Source SetUp() Declaration [SetUp] public void SetUp() | Edit this page View Source TryEquip_DifferentSlots_BothSucceed() Declaration [Test] public void TryEquip_DifferentSlots_BothSucceed() | Edit this page View Source TryEquip_NonEquipmentItem_ReturnsFalseAndDoesNotFireEvent() Declaration [Test] public void TryEquip_NonEquipmentItem_ReturnsFalseAndDoesNotFireEvent() | Edit this page View Source TryEquip_Null_ReturnsFalseAndDoesNotMutate() Declaration [Test] public void TryEquip_Null_ReturnsFalseAndDoesNotMutate() | Edit this page View Source TryEquip_SameSlotTwice_SecondReturnsFalse_DoesNotDuplicate() Declaration [Test] public void TryEquip_SameSlotTwice_SecondReturnsFalse_DoesNotDuplicate() | Edit this page View Source TryEquip_ValidItem_ReturnsTrue_AddsToList_AndFiresEvent() Declaration [Test] public void TryEquip_ValidItem_ReturnsTrue_AddsToList_AndFiresEvent() | Edit this page View Source Unequip_EmptySlot_ReturnsNull_DoesNotFireEvent() Declaration [Test] public void Unequip_EmptySlot_ReturnsNull_DoesNotFireEvent() | Edit this page View Source Unequip_SlotWithItem_ReturnsItem_RemovesIt_AndFiresEvent() Declaration [Test] public void Unequip_SlotWithItem_ReturnsItem_RemovesIt_AndFiresEvent() | Edit this page View Source Unequip_Then_EquipAgain_Succeeds() Declaration [Test] public void Unequip_Then_EquipAgain_Succeeds()"
  },
  "api/InventorySystemTests.InventorySlotInterfaceTests.html": {
    "href": "api/InventorySystemTests.InventorySlotInterfaceTests.html",
    "title": "Class InventorySlotInterfaceTests | Inventory System",
    "summary": "Class InventorySlotInterfaceTests Behaviour-level tests of the observable contract of IInventorySlot, driven exclusively through IInventory operations. Does not assume any internal mutators on the slot itself. Inheritance object InventorySlotInterfaceTests Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystemTests Assembly: InventorySystemTests.dll Syntax [TestFixture] public class InventorySlotInterfaceTests Methods | Edit this page View Source AddingSingleItem_UpdatesSlotProperties() Declaration [Test] public void AddingSingleItem_UpdatesSlotProperties() | Edit this page View Source ClearingSlotViaInventory_MakesSlotEmpty() Declaration [Test] public void ClearingSlotViaInventory_MakesSlotEmpty() | Edit this page View Source FillingSlot_ToMaxMarksFull() Declaration [Test] public void FillingSlot_ToMaxMarksFull() | Edit this page View Source FullSlot_RemainsFull_WhenAttemptingToAddSameItemWithoutOverflowHandlingDisabled() Declaration [Test] public void FullSlot_RemainsFull_WhenAttemptingToAddSameItemWithoutOverflowHandlingDisabled() | Edit this page View Source InsertAtFront_ShiftsItems_SlotPropertiesFollow() Declaration [Test] public void InsertAtFront_ShiftsItems_SlotPropertiesFollow() | Edit this page View Source IsEmpty_FalseOnlyWhenQuantityPositiveAndItemAssigned() Declaration [Test] public void IsEmpty_FalseOnlyWhenQuantityPositiveAndItemAssigned() | Edit this page View Source NewSlot_IsEmpty_QuantityZero_ItemNull() Declaration [Test] public void NewSlot_IsEmpty_QuantityZero_ItemNull() | Edit this page View Source OverflowDistribution_PopulatesSecondSlotAndFirstIsFull() Declaration [Test] public void OverflowDistribution_PopulatesSecondSlotAndFirstIsFull() | Edit this page View Source RemovingItem_RemovesFromSlotAndReflectsEmpty() Declaration [Test] public void RemovingItem_RemovesFromSlotAndReflectsEmpty() | Edit this page View Source SetUp() Declaration [SetUp] public void SetUp()"
  },
  "api/InventorySystemTests.InventoryTests.html": {
    "href": "api/InventorySystemTests.InventoryTests.html",
    "title": "Class InventoryTests | Inventory System",
    "summary": "Class InventoryTests Behaviour-driven tests for Inventory that must satisfy the IInventory contract and the documented overflow / slot rules. Inheritance object InventoryTests Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystemTests Assembly: InventorySystemTests.dll Syntax [TestFixture] public class InventoryTests Methods | Edit this page View Source Clear_RemovesAllItems() Declaration [Test] public void Clear_RemovesAllItems() | Edit this page View Source IsSlotAvailable_PrefersEquivalentNonFullSlot() Declaration [Test] public void IsSlotAvailable_PrefersEquivalentNonFullSlot() | Edit this page View Source IsSlotAvailable_ReturnsEmptyIfEquivalentIsFullButOtherSlotFree() Declaration [Test] public void IsSlotAvailable_ReturnsEmptyIfEquivalentIsFullButOtherSlotFree() | Edit this page View Source IsSlotAvailable_ReturnsFalse_WhenNoRoomForDistinctItem() Declaration [Test] public void IsSlotAvailable_ReturnsFalse_WhenNoRoomForDistinctItem() | Edit this page View Source IsSlotAvailable_ReturnsFirstEmpty_WhenNoEquivalentFound() Declaration [Test] public void IsSlotAvailable_ReturnsFirstEmpty_WhenNoEquivalentFound() | Edit this page View Source ItemsAdded_Event_FiresPerSlot_WhenOverflowDistributed() Declaration [Test] public void ItemsAdded_Event_FiresPerSlot_WhenOverflowDistributed() | Edit this page View Source ItemsAdded_Event_FiresWithCorrectPayload_OnSimpleAdd() Declaration [Test] public void ItemsAdded_Event_FiresWithCorrectPayload_OnSimpleAdd() | Edit this page View Source ItemsRemoved_Event_FiresPerSlot_WhenRemovingAllOccurrences() Declaration [Test] public void ItemsRemoved_Event_FiresPerSlot_WhenRemovingAllOccurrences() | Edit this page View Source ItemsRemoved_Event_Fires_OnClearEntireInventory() Declaration [Test] public void ItemsRemoved_Event_Fires_OnClearEntireInventory() | Edit this page View Source ItemsRemoved_Event_Fires_OnRemoveItem() Declaration [Test] public void ItemsRemoved_Event_Fires_OnRemoveItem() | Edit this page View Source NewInventory_IsEmpty_AtCorrectCapacity() Declaration [Test] public void NewInventory_IsEmpty_AtCorrectCapacity() | Edit this page View Source RemoveItem_AllOccurrences_RemovesEverything() Declaration [Test] public void RemoveItem_AllOccurrences_RemovesEverything() | Edit this page View Source RemoveItem_OnlyFirstOccurence_RemovesSingleStack() Declaration [Test] public void RemoveItem_OnlyFirstOccurence_RemovesSingleStack() | Edit this page View Source SetUp() Declaration [SetUp] public void SetUp() | Edit this page View Source TryAddItemAt_InvalidIndex_ReturnsFalse() Declaration [Test] public void TryAddItemAt_InvalidIndex_ReturnsFalse() | Edit this page View Source TryAddItemAt_NonEquivalentInOccupiedSlot_ReturnsFalse() Declaration [Test] public void TryAddItemAt_NonEquivalentInOccupiedSlot_ReturnsFalse() | Edit this page View Source TryAddItemAt_PrefersTargetSlot_WhenEquivalentExistsElsewhere() Declaration [Test] public void TryAddItemAt_PrefersTargetSlot_WhenEquivalentExistsElsewhere() | Edit this page View Source TryAddItem_DiscardsRemainderBeyondCapacity_WhenHandlesOverflowTrue() Declaration [Test] public void TryAddItem_DiscardsRemainderBeyondCapacity_WhenHandlesOverflowTrue() | Edit this page View Source TryAddItem_DistributesOverflow_WhenHandlesOverflowTrue() Declaration [Test] public void TryAddItem_DistributesOverflow_WhenHandlesOverflowTrue() | Edit this page View Source TryAddItem_StopsAfterFirstSlot_WhenHandlesOverflowFalse() Declaration [Test] public void TryAddItem_StopsAfterFirstSlot_WhenHandlesOverflowFalse() | Edit this page View Source TryAddItem_WhenEquivalentExists_IncreasesQuantity() Declaration [Test] public void TryAddItem_WhenEquivalentExists_IncreasesQuantity() | Edit this page View Source TryAddItem_WhenNoSpace_ReturnsFalse() Declaration [Test] public void TryAddItem_WhenNoSpace_ReturnsFalse() | Edit this page View Source TryAddItem_WhenSlotFree_AddsToFirstFree() Declaration [Test] public void TryAddItem_WhenSlotFree_AddsToFirstFree() | Edit this page View Source TryClearSlotAt_InvalidIndex_NoThrowOrEffect() Declaration [Test] public void TryClearSlotAt_InvalidIndex_NoThrowOrEffect() | Edit this page View Source TryClearSlotAt_ValidIndex_ClearsSlot() Declaration [Test] public void TryClearSlotAt_ValidIndex_ClearsSlot() | Edit this page View Source TryGetItemAt_EmptySlot_ReturnsNull() Declaration [Test] public void TryGetItemAt_EmptySlot_ReturnsNull() | Edit this page View Source TryGetItemAt_OutOfBounds_ReturnsNull() Declaration [Test] public void TryGetItemAt_OutOfBounds_ReturnsNull() | Edit this page View Source TryGetSlotAt_OutOfBounds_ReturnsNull() Declaration [Test] public void TryGetSlotAt_OutOfBounds_ReturnsNull() | Edit this page View Source TryInsertItemAtFront_PushesExistingItemsForward() Declaration [Test] public void TryInsertItemAtFront_PushesExistingItemsForward() | Edit this page View Source TryInsertItemAtFront_WhenInventoryFull_Fails() Declaration [Test] public void TryInsertItemAtFront_WhenInventoryFull_Fails()"
  },
  "api/InventorySystemTests.MockItem.html": {
    "href": "api/InventorySystemTests.MockItem.html",
    "title": "Class MockItem | Inventory System",
    "summary": "Class MockItem Inheritance object MockItem Implements IItem ICopyable<IItem> IEquivalent<IItem> Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystemTests Assembly: InventorySystemTests.dll Syntax public class MockItem : IItem, ICopyable<IItem>, IEquivalent<IItem> Constructors | Edit this page View Source MockItem(ItemData) Declaration public MockItem(ItemData data) Parameters Type Name Description ItemData data Properties | Edit this page View Source ItemData Declaration public ItemData ItemData { get; } Property Value Type Description ItemData Methods | Edit this page View Source DeepCopy() Create a deep copy of this T. Declaration public IItem DeepCopy() Returns Type Description IItem A deep copy of this T. Remarks Deep Copy: A deep copy of an object is a copy whose properties do not share the same references (point to the same underlying values) as those of the source object from which the copy was made. https://developer.mozilla.org/en-US/docs/Glossary/Deep_copy | Edit this page View Source IsEquivalentTo(IItem) Check if this is the same type T in the same internal state as other T. Declaration public bool IsEquivalentTo(IItem other) Parameters Type Name Description IItem other The object T to be compared against. Returns Type Description bool Whether this and other are equivalent in type and internal state. Implements IItem ICopyable<T> IEquivalent<T>"
  },
  "api/InventorySystemTests.TestUtils.html": {
    "href": "api/InventorySystemTests.TestUtils.html",
    "title": "Class TestUtils | Inventory System",
    "summary": "Class TestUtils Inheritance object TestUtils Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Namespace: InventorySystemTests Assembly: InventorySystemTests.dll Syntax public class TestUtils Methods | Edit this page View Source CreateItemSO(string, int, int) Declaration public static ItemData CreateItemSO(string name, int maxStack, int id = 0) Parameters Type Name Description string name int maxStack int id Returns Type Description ItemData | Edit this page View Source CreateMockItem(string, int, int) Declaration public static IItem CreateMockItem(string name, int maxStack, int id = 0) Parameters Type Name Description string name int maxStack int id Returns Type Description IItem"
  },
  "api/InventorySystemTests.html": {
    "href": "api/InventorySystemTests.html",
    "title": "Namespace InventorySystemTests | Inventory System",
    "summary": "Namespace InventorySystemTests Classes EquipmentInventoryTests Comprehensive behaviour-level tests for any IEquipmentInventory implementation. Replace the TODO in CreateInventory() with your concrete inventory class or derive and override CreateInventory() for different configurations. InventorySlotInterfaceTests Behaviour-level tests of the observable contract of IInventorySlot, driven exclusively through IInventory operations. Does not assume any internal mutators on the slot itself. InventoryTests Behaviour-driven tests for Inventory that must satisfy the IInventory contract and the documented overflow / slot rules. MockItem TestUtils"
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Getting Started | Inventory System",
    "summary": "Getting Started"
  },
  "docs/introduction.html": {
    "href": "docs/introduction.html",
    "title": "Introduction | Inventory System",
    "summary": "Introduction"
  },
  "index.html": {
    "href": "index.html",
    "title": "This is the HOMEPAGE. | Inventory System",
    "summary": "This is the HOMEPAGE. Refer to Markdown for how to write markdown files. Quick Start Notes: Add images to the images folder if the file is referencing an image."
  }
}